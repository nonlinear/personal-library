# Personal Library MCP

> A BYOB (Bring Your Own Books) local MCP so you can consult your library as you build your projects.

> All local (books, embedding models, database). [Connect with your favorite AI provider](#5-ai-provider-integration) and [ask away](#4-usage)

## Possible topics

- âš–ï¸ **Compliance**: collect all compliance and regulation manuals to test a new idea the proper way
- ğŸ”§ **Troubleshooting**: move all your home devices and appliances' instruction manuals + warranties, ask troubleshooting questions
- ğŸŒ± **Garden**: permaculture, indigenous plant guides, water management books to redesign your garden with less trial-and-error
- ğŸ¸ **Music/Hobby**: wanna try a new hobby but have no idea of scope? collect authoritative books in the field you wanna learn, and reduce your confusion by asking freely questions
- ğŸ® **Game Dev**: design patterns, procedural generation, narrative theoryâ€”query mid-project to find exactly which book explained that algorithm
- ğŸŒ **Field Research**: anthropology, ethnography, linguisticsâ€”entire library indexed locally, works offline for weeks in remote locations
- ğŸ’¼ **Professional**: legal texts, industry whitepapers, case studiesâ€”cite exact sources during audits or client presentations
- ğŸ’ª **Health & Fitness**: training programs, nutrition guides, sports scienceâ€”get grounded advice without influence rabbit holes

---

## How it works

```mermaid
graph TD
    QUERY([research prompt+<br>specific book query]) --> MAP[Read metadata.json]
    MAP --> SIM[Semantic Similarity]

    SIM --> T1[Topic: philosophy<br/>Score: 0.89]
    SIM --> T2[Topic: AI<br/>Score: 0.32]

    T1 --> B1[Book: Psychopolitics<br/>Tags: power, discipline<br/>Score: 0.91]

    B1 --> DECISION1{Confident match?}
    T2 --> DECISION2{Confident match?}

    DECISION1 -->|Yes| VEC[Query Vector Store<br/>Scope: philosophy/Psychopolitics]
    DECISION2 -->|No| ASK[System asks for clarification]

    ASK --> CLARIFY[Clarification query]
    CLARIFY --> MAP

    VEC --> ANSWER([Precise answer from<br>relevant book chunks])
```

---

## Installation

### Clone this repo

### 1. Install Python 3.11 or higher

- macOS`brew install python@3.11`
- Ubuntu/Debian `sudo apt install python3.11`
- Windows [Download from python.org](https://www.python.org/downloads/)
- Verify: `python3.11 --version`

### 2. Setup

1. Run setup script: `bash ./scripts/setup.sh`
   - Installs Python dependencies
   - Downloads local embedding model (all-MiniLM-L6-v2, ~90MB)
   - Model saved in `models/` directory (not tracked by git)

### 3. BYOB (Bring Your Own Books)

1. Add your books to `books/TOPICNAME/*.epub`
   - Exactly 1 folder level below `books/`
   - `.epub` and `.pdf`
   - Each folder is a topic
2. Generate metadata: `bash python3.11 scripts/generate_metadata.py`
3. Build index (includes auto-partitioning): `bash python3.11 scripts/indexer.py`
   - Creates vector store in `storage/`
   - Auto-partitions by topic for MCP lazy-loading
   - ~90MB for 34 books (local embeddings)
4. Test: `bash python3.11 scripts/query_partitioned.py "what books discuss AI ethics?" --topic ai`

**Folder structure:**

```
books/
â”œâ”€â”€ topic_a/
â”‚   â”œâ”€â”€ book1.epub
â”‚   â””â”€â”€ book2.pdf
â”œâ”€â”€ topic_b/
â”‚   â””â”€â”€ book3.epub
```

### 4. Usage

- Use [/research prompt](https://github.com/nonlinear/personal-library/blob/main/.github/prompts/research.prompt.md) to consult Personal Library MCP on your AI conversations
- Make sure to specify topic or book name in your question. MCP will try to disambiguate based on metadata tags but the more focused the search, the better the results
- Without `/research`, your AI uses general knowledge. With it, you get precise citations from your library
- example 1: "`/research` what does Bogdanov say about Mars in Molecular Red?"
- example 2: "`/research` in my anthropocene books, what are the main critiques of geoengineering?"
- example 3: "`/research` what tarot spreads work best for decision-making under uncertainty?"

---

### 5. AI Provider Integration

The Personal Library MCP is **provider-agnostic**. Pick your favorite AI environment:

| Provider           | Status                                                                                                                                                                                                                |
| ------------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Terminal**       | âœ… `python3.11 scripts/query_partitioned.py "your question" --topic ai`                                                                                                                                               |
| **VS Code**        | âœ… `code --install-extension personal-library-mcp-latest.vsix` (or [download .vsix](https://github.com/nonlinear/personal-library/raw/main/.vscode/extensions/personal-library-mcp/personal-library-mcp-latest.vsix)) |
| **Claude Desktop** | ğŸ‘· Pending                                                                                                                                                                                                            |
| **OpenAI API**     | ğŸ‘· Pending                                                                                                                                                                                                            |
| **LM Studio**      | ğŸ‘· Pending                                                                                                                                                                                                            |
| **OpenWebUI**      | ğŸ‘· Pending                                                                                                                                                                                                            |

> ğŸ‘· Wanna collaborate? Connect via [Personal Library signal group](https://signal.group/#CjQKIKD7zJjxP9sryI9vE5ATQZVqYsWGN_3yYURA5giGogh3EhAWfvK2Fw_kaFtt-MQ6Jlp8)

## Project Status

- **[Roadmap](roadmap.md)** - Planned features and in-progress work
- **[Release Notes](release-notes.md)** - Completed features and deployments

> ğŸ’¡ **Want to add your idea?** Join [Personal Library signal group](https://signal.group/#CjQKIKD7zJjxP9sryI9vE5ATQZVqYsWGN_3yYURA5giGogh3EhAWfvK2Fw_kaFtt-MQ6Jlp8) and share your setup!
