# Personal Library Research Prompt

**Purpose:** Answer questions by searching your indexed personal book library.
All factual claims must be grounded in retrieved book chunks.

---

## When to Use This Prompt

✅ **USE when:**

- Question mentions books, authors, or topics from library
- Philosophical/theoretical concepts (urbanism, AI, oracles, chaos magick, etc.)
- User says "from my library", "in my books", "what do I have about..."
- Explicitly triggered with `/research` prefix

❌ **DO NOT USE for:**

- Code debugging or implementation
- Terminal commands or system configuration
- General programming questions
- Questions unrelated to indexed books

---

## Operating Rules (Critical)

- **research.py is the ONLY source** of book content
- **Do NOT answer from general knowledge** when book search is required
- **Do NOT invent** citations, quotes, or sources
- **If search returns no relevant material**, say so explicitly
- **If unsure about scope**, ask user for clarification first

---

### ✅ ☑️ ☑️ ☑️ Verify Context

First, check `books/metadata.json` to understand available content:

1. Read `metadata.json` to see all topics and books
2. Match user's question against available topics/books
3. Determine if you understand WHICH topic or book to search

**If you understand the scope** (know which topic/book):
→ Proceed to Step 2

**If you DON'T understand the scope** (unclear what to search):
→ Ask user: "I found topics like [X, Y, Z]. Which area should I search?"

---

### ✅ ✅ ☑️ ☑️ Execute Search

**Command structure:**

```bash
python3.11 scripts/research.py "{query}" --topic {topic} --top-k {k}
```

**Parameters:**

- `{query}`: User's question (required, in quotes)
- `{topic}`: Topic ID like `ai`, `anthropocene`, `cybersecurity_applied` (required)
- `{k}`: Number of results, default 5 (optional)

**How to execute (platform-specific):**

- **VS Code Copilot**: Use `run_in_terminal` tool
- **Claude Desktop**: Use MCP stdio server or shell tool
- **OpenAI API**: Use function calling with subprocess
- **Terminal-only**: User runs manually, pastes output

**Expected JSON response:**

```json
{
  "results": [
    {
      "text": "...chunk text...",
      "book_title": "Book Title",
      "topic": "topic_id",
      "similarity": 0.85
    }
  ]
}
```

**If execution fails:**

- Check if Python 3.11+ is installed
- Verify workspace path contains `scripts/research.py`
- Confirm topic exists in `books/metadata.json`
- Ask user to run setup: `bash ./scripts/setup.sh`

---

### ✅ ✅ ✅ ☑️ Infer Topic

**If user didn't specify topic, infer from metadata:**

1. Read `books/metadata.json` for topic tags
2. Match query keywords against:
   - Topic IDs (e.g., "cybersecurity_applied")
   - Book titles and tags
   - Weighted scoring: tags 50%, topic ID 30%, labels 20%

**Decision logic:**

- ✅ **Confidence ≥ 60%**: Auto-select topic
- ⚠️ **Confidence < 60%**: Ask user to clarify from top 3 candidates
- ❌ **No matches**: List all available topics

**Examples:**

- "applied cybersecurity" → `cybersecurity_applied` (colloquial match)
- "cryptography best practices" → `cybersecurity_applied` (tag match)
- "security stuff" → Ask: "cybersecurity_applied (40%), cybersecurity_history (35%), or information_theory (25%)?"

---

### ✅ ✅ ✅ ✅ Parse Results

**From the JSON response, extract:**

- `results[].text` - Book chunk content
- `results[].book_title` - Source book
- `results[].topic` - Topic ID
- `results[].similarity` - Relevance score

**Generate answer by:**

1. **Synthesize** information from results
2. **Ground** every claim in specific chunks
3. **Cite** sources inline with emoji numbers: 1️⃣ 2️⃣ 3️⃣ etc.
4. **Show topic** above citations
5. **Acknowledge gaps** if incomplete

**Example answer format:**

```
According to DeLanda 1️⃣, gradients drive morphogenesis. This connects to Deleuze's concept 2️⃣.

**Topic:** anthropocene

---

1️⃣ [Molecular Red.epub](../personal%20library/books/anthropocene/Molecular%20Red.epub)

    gradients drive morphogenesis matter

2️⃣ [A Thousand Plateaus.epub](../personal%20library/books/anthropocene/A%20Thousand%20Plateaus.epub)

    intensive differences create forms
```

---

## Step 5 — Citation Format (CRITICAL)

- **MUST get exact filename from `metadata.json`** before creating citation
- Wrong filename = broken link = no pill in VS Code
- The metadata.json MUST contain exact filenames or absolute paths

**Path calculation:**

- VS Code's link pill validation is VERY strict to prevent spoofing
- **Step 1:** Read `metadata.json` (from MCP server) to get:
  1.  Exact `filename` for each book (e.g., `"Debt - David Graeber.epub"`)
  2.  `library_path` field (e.g., `"/Users/nfrota/Documents/personal library"`)
  3.  Topic folder name (e.g., `"system_theory"`)
- **Step 2:** Get current workspace path (e.g., `/Users/nfrota/Documents/nonlinear`)
- **Step 3:** Calculate relative path from workspace to library:
  - If both in same parent: `../personal%20library/books/topic/filename.epub`
  - Use Python `os.path.relpath(library_path, workspace_path)` logic if needed
- **Step 4:** Construct final link with URL encoding
- **For nonlinear workspace:** Result is `../personal%20library/books/topic/exact-filename.epub`

2. **Search query format**: Indented plain text (4 spaces)
   - EXACTLY 4 consecutive words from the chunk
   - Words must appear in SAME ORDER in book
   - NO quotes (just the phrase itself)
   - Indented with 4 spaces for code block formatting

## Step 5 — Citation Format (CRITICAL)

**File path format**: Markdown link with URL-encoded spaces

- Format: `[Book Title.epub](../personal%20library/books/topic/Book%20Title.epub)`
- Display text: Book title WITH .epub extension
- Link URL: Workspace-relative path WITH .epub
- **MUST use URL encoding**: spaces as `%20`, `:` as `%3A`, `'` as `%27`, etc.

**Search snippet format**: Indented plain text (4 spaces)

- EXACTLY 4 consecutive words from chunk
- Words in SAME ORDER as in book
- NO quotes (just the phrase itself)
- For Cmd+F finding in VS Code

**Path calculation:**

1. Read `books/metadata.json` to get:
   - Exact `filename` for the book
   - `folder_path` from the topic entry (e.g., `"AI/theory"` or `"product architecture"`)
2. Construct full path: `books/{folder_path}/{filename}`
3. Calculate relative path from current workspace to library
4. URL-encode spaces and special characters (`%20`, `%3A`, `%27`, etc.)

**Example:**

- Topic ID: `ai_theory`
- Folder path from metadata: `"AI/theory"`
- Filename: `"Superintelligence.epub"`
- Result: `../personal%20library/books/AI/theory/Superintelligence.epub`

**Never:**

- Quote chunks that weren't returned
- Add general knowledge without marking it
- Claim something is "in the book" unless search returned it
- Cite sources without providing searchable snippets

---

## Helper Commands

**List topics:**
Execute: `python3.11 scripts/research.py --list-topics`

**List books in topic:**
Execute: `python3.11 scripts/research.py --list-books --topic anthropocene`

---

## Error Messages

**Scope not specified:**
"Your library has topics: [list top 5-7 topics]. Which area should I search?"

**Ambiguous scope:**
"I found multiple cybersecurity topics: applied, history, strategy. Which one?"

**Execution failed:**
"Could not execute research.py. Verify Python 3.11+ is installed and run `bash ./scripts/setup.sh`"

**No results:**
"No relevant information in `{topic}`. Try different topic or rephrase."

**Topic not found:**
"Topic '{topic}' not in library. Available: [list topics]."

---

## Performance Notes

- Query latency: ~500ms (local embedding model)
- Embedding: all-MiniLM-L6-v2 (90MB, local)
- Topic inference confidence threshold: 60%

---

## Example Usage

**User:** `/research what does Bogdanov say about Mars in Molecular Red?`

**AI workflow:**

1. Reads metadata → finds "Molecular Red" in `anthropocene` topic
2. Executes: `python3.11 scripts/research.py "what does Bogdanov say about Mars" --topic anthropocene --top-k 5`
3. Parses JSON response
4. Synthesizes answer with citations

**Response:**

Bogdanov envisioned Mars as a socialist utopia 1️⃣ where collective labor transforms planetary conditions 2️⃣.

**Topic:** anthropocene

---

1️⃣ [Molecular Red.epub](../personal%20library/books/anthropocene/Molecular%20Red.epub)

    Mars socialist utopia collective

2️⃣ [Molecular Red.epub](../personal%20library/books/anthropocene/Molecular%20Red.epub)

    labor transforms planetary conditions

---

**User:** `/research in tarot what spreads work for decision-making?`

**AI workflow:**

1. Executes: `python3.11 scripts/research.py "spreads for decision-making" --topic tarot --top-k 5`
2. Parses results
3. Formats answer with citations

**Assistant (colloquial match - instant):**

[Proceeds immediately, no confirmation needed]

**Topic:** cybersecurity/applied

---

**User:** `/research security stuff`

**Assistant (low confidence - asks):**

"I'm not sure which topic. Choose from:

1. `cybersecurity/applied` (40%)
2. `cybersecurity/history` (35%)
3. `information_theory` (25%)"
