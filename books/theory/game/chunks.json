[
  {
    "chunk_full": "JOURNAL OF LATEX CLASS FILES, VOL. X, NO. X, DECEMBER 2018\n1\nA Comprehensive Survey on Graph Neural\nNetworks\nZonghan Wu, Shirui Pan, Member, IEEE, Fengwen Chen, Guodong Long,\nChengqi Zhang, Senior Member, IEEE, Philip S. Yu, Fellow, IEEE\nAbstract—Deep learning has revolutionized many machine learning tasks in recent years, ranging from image classiﬁcation and video\nprocessing to speech recognition and natural language understanding. The data in these tasks are typically represented in the\nEuclidean space. However, there is an increasing number of applications where data are generated from non-Euclidean domains and\nare represented as graphs with complex relationships and interdependency between objects. The complexity of graph data has\nimposed signiﬁcant challenges on existing machine learning algorithms. Recently, many studies on extending deep learning\napproaches for graph data have emerged. In this survey, we provide a comprehensive overview of graph neural networks (GNNs) in\ndata mining and machine learning ﬁelds. We propose a new taxonomy to divide the state-of-the-art graph neural networks into different\ncategories. With a focus on graph convolutional networks, we review alternative architectures that have recently been developed; these\nlearning paradigms include graph attention networks, graph autoencoders, graph generative networks, and graph spatial-temporal\nnetworks. We further discuss the applications of graph neural networks across various domains and summarize the open source codes\nand benchmarks of the existing algorithms on different learning tasks. Finally, we propose potential research directions in this\nfast-growing ﬁeld.\nIndex Terms—Deep Learning, graph neural networks, graph convolutional networks, graph representation learning, graph\nautoencoder, network embedding\n!\n1\nINTRODUCTION\nT\nHE recent success of neural networks has boosted re-\nsearch on pattern recognition and data mining. Many\nmachine learning tasks such as object detection [1], [2], ma-\nchine translation [3], [4], and speech recognition [5], which\nonce heavily relied on handcrafted feature engineering to\nextract informative feature sets, has recently been revolu-\ntionized by various end-to-end deep learning paradigms,\ni.e., convolutional neural networks (CNNs) [6], long short-\nterm memory (LSTM) [7], and autoencoders. The success\nof deep learning in many domains is partially attributed to\nthe rapidly developing computational resources (e.g., GPU)\nand the availability of large training data, and is partially\ndue to the effectiveness of deep learning to extract latent\nrepresentation from Euclidean data (e.g., images, text, and\nvideo). Taking image analysis as an example, an image can\nbe represented as a regular grid in the Euclidean space.\nA convolutional neural network (CNN) is able to exploit\nthe shift-invariance, local connectivity, and compositionality\nof image data [8], and as a result, CNN can extract local\n•\nZ.\nWu,\nF.\nChen,\nG.\nLong,\nC.\nZhang\nare\nwith\nCentre\nfor\nArtiﬁcial\nIntelligence,\nFEIT,\nUniversity\nof\nTechnology\nSydney,\nNSW\n2007,\nAustralia\n(E-mail:\nzonghan.wu-3@student.uts.edu.au;\nfengwen.chen@student.uts.edu.au;\nguodong.long@uts.edu.au;\nchengqi.zhang@uts.edu.au).\n•\nS. Pan is with Faculty of Information Technology, Monash University,\nClayton, VIC 3800, Australia (Email: shirui.pan@monash.edu).\n•\nP. S. Yu is with Department of Computer Science, University of Illinois\nat Chicago, Chicago, IL 60607-7053, USA (Email: psyu@uic.edu)\n•\nCorresponding author: Shirui Pan.\nManuscript received Dec xx, 2018; revised Dec xx, 201x.\nmeaningful features that are shared with the entire datasets\nfor various image analysis tasks.\nWhile deep learning has achieved great success on Eu-\nclidean data, there is an increasing number of applications\nwhere data are generated from the non-Euclidean domain\nand need to be effctectively analyzed. For instance, in e-\ncommence, a graph-based learning system is able to exploit\nthe interactions between users and products [9], [10], [11]\nto make a highly accurate recommendations. In chemistry,\nmolecules are modeled as graphs and their bioactivity needs\nto be identiﬁed for drug discovery [12], [13]. In a citation\nnetwork, papers are linked to each other via citationship\nand they need to be categorized into different groups [14],\n[15]. The complexity of graph data has imposed signiﬁcant\nchallenges on existing machine learning algorithms. This is\nbecause graph data are irregular. Each graph has a variable\nsize of unordered nodes and each node in a graph has\na different number of neighbors, causing some important\noperations (e.g., convolutions), which are easy to compute\nin the image domain, but are not directly applicable to the\ngraph domain any more. Furthermore, a core assumption\nof existing machine learning algorithms is that instances are\nindependent of each other. However, this is not the case for\ngraph data where each instance (node) is related to others\n(neighbors) via some complex linkage information, which is\nused to capture the interdependence among data, including\ncitationship, friendship, and interactions.\nRecently, there is increasing interest in extending deep\nlearning approaches for graph data. Driven by the success\nof deep learning, researchers have borrowed ideas from\nconvolution networks, recurrent networks, and deep auto-\nencoders to design the architecture of graph neural net-\narXiv:1901.00596v1  [cs.LG]  3 Jan 2019\n",
    "book_id": "a_comprehensive_survey_on_graph_neural_net",
    "book_title": "A Comprehensive Survey on Graph Neural Net",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 0
  },
  {
    "chunk_full": "JOURNAL OF LATEX CLASS FILES, VOL. X, NO. X, DECEMBER 2018\n2\nworks. To handle the complexity of graph data, new gen-\neralizations and deﬁnitions for important operations have\nbeen rapidly developed over the past few years. For in-\nstance, Figure 1 illustrates how a kind of graph convolution\nis inspired by a standard 2D convolution. This survey aims\nto provide a comprehensive overview of these methods, for\nboth interested researchers who want to enter this rapidly\ndeveloping ﬁeld and experts who would like to compare\ngraph neural network algorithms.\nA Brief History of Graph Neural Networks The nota-\ntion of graph neural networks was ﬁrstly outlined in Gori et\nal. (2005) [16], and further elaborated in Scarselli et al. (2009)\n[17]. These early studies learn a target node’s representation\nby propagating neighbor information via recurrent neural\narchitectures in an iterative manner until a stable ﬁxed\npoint is reached. This process is computationally expensive,\nand recently there have been increasing efforts to overcome\nthese challenges [18], [19]. In our survey, we generalize the\nterm graph neural networks to represent all deep learning\napproaches for graph data.\nInspired by the huge success of convolutional networks\nin the computer vision domain, a large number of methods\nthat re-deﬁne the notation of convolution for graph data have\nemerged recently. These approaches are under the umbrella\nof graph convolutional networks (GCNs). The ﬁrst promi-\nnent research on GCNs is presented in Bruna et al. (2013),\nwhich develops a variant of graph convolution based on\nspectral graph theory [20]. Since that time, there have been\nincreasing improvements, extensions, and approximations\non spectral-based graph convolutional networks [12], [14],\n[21], [22], [23]. As spectral methods usually handle the\nwhole graph simultaneously and are difﬁcult to parallel\nor scale to large graphs, spatial-based graph convolutional\nnetworks have rapidly developed recently [24], [25], [26],\n[27]. These methods directly perform the convolution in the\ngraph domain by aggregating the neighbor nodes’ informa-\ntion. Together with sampling strategies, the computation can\nbe performed in a batch of nodes instead of the whole graph\n[24], [27], which has the potential to improve the efﬁciency.\nIn addition to graph convolutional networks, many alter-\nnative graph neural networks have been developed in the\npast few years. These approaches include graph attention\nnetworks, graph autoencoders, graph generative networks,\nand graph spatial-temporal networks. Details on the catego-\nrization of these methods are given in Section 3.\nRelated surveys on graph neural networks. There are\na limited number of existing reviews on the topic of graph\nneural networks. Using the notation geometric deep learning,\nBronstein et al. [8] give an overview of deep learning\nmethods in the non-Euclidean domain, including graphs\nand manifolds. While being the ﬁrst review on graph con-\nvolution networks, this survey misses several important\nspatial-based approaches, including [15], [19], [24], [26],\n[27], [28], which update state-of-the-art benchmarks. Fur-\nthermore, this survey does not cover many newly devel-\noped architectures which are equally important to graph\nconvolutional networks. These learning paradigms, includ-\ning graph attention networks, graph autoencoders, graph\ngenerative networks, and graph spatial-temporal networks,\nare comprehensively reviewed in this article. Battaglia et\n(a) 2D Convolution. Analo-\ngous to a graph, each pixel\nin an image is taken as a\nnode where neighbors are de-\ntermined by the ﬁlter size.\nThe 2D convolution takes a\nweighted average of pixel val-\nues of the red node along with\nits neighbors. The neighbors of\na node are ordered and have a\nﬁxed size.\n(b) Graph Convolution. To get\na hidden representation of the\nred node, one simple solution\nof graph convolution opera-\ntion takes the average value\nof node features of the red\nnode along with its neighbors.\nDifferent from image data, the\nneighbors of a node are un-\nordered and variable in size.\nFig. 1: 2D Convolution vs. Graph Convolution.\nal. [29] position graph networks as the building blocks for\nlearning from relational data, reviewing part of graph neu-\nral networks under a uniﬁed framework. However, their\ngeneralized framework is highly abstract, losing insights on\neach method from its original paper. Lee et al. [30] conduct\na partial survey on the graph attention model, which is\none type of graph neural network. Most recently, Zhang et\nal. [31] present a most up-to-date survey on deep learning\nfor graphs, missing those studies on graph generative and\nspatial-temporal networks. In summary, none of existing\nsurveys provide a comprehensive overview of graph neural\nnetworks, only covering some of the graph convolution\nneural networks and examining a limited number of works,\nthereby missing the most recent development of alternative\ngraph neural networks, such as graph generative networks\nand graph spatial-temporal networks.\nGraph neural networks vs. network embedding The\nresearch on graph nerual networks is closely related to\ngraph embedding or network embedding, another topic\nwhich attracts increasing attention from both the data min-\ning and machine learning communities [32] [33] [34] [35],\n[36], [37]. Network embedding aims to represent network\nvertices into a low-dimensional vector space, by preserving\nboth network topology structure and node content informa-\ntion, so that any subsequent graph analytics tasks such as\nclassiﬁcation, clustering, and recommendation can be easily\nperformed by using simple off-the-shelf learning machine\nalgorithm (e.g., support vector machines for classiﬁcation).\nMany network embedding algorithms are typically unsu-\npervised algorithms and they can be broadly classiﬁed into\nthree groups [32], i.e., matrix factorization [38], [39], ran-\ndom walks [40], and deep learning approaches. The deep\nlearning approaches for network embedding at the same\ntime belong to graph neural networks, which include graph\nautoencoder-based algorithms (e.g., DNGR [41] and SDNE\n[42]) and graph convolution neural networks with unsuper-\nvised training(e.g., GraphSage [24]). Figure 2 describes the\ndifferences between network embedding and graph neural\n",
    "book_id": "a_comprehensive_survey_on_graph_neural_net",
    "book_title": "A Comprehensive Survey on Graph Neural Net",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 1
  },
  {
    "chunk_full": "JOURNAL OF LATEX CLASS FILES, VOL. X, NO. X, DECEMBER 2018\n3\nFig. 2: Network Embedding v.s. Graph Neural Networks.\nnetworks in this paper.\nOur Contributions Our paper makes notable contribu-\ntions summarized as follows:\n•\nNew taxonomy In light of the increasing number of\nstudies on deep learning for graph data, we propose\na new taxonomy of graph neural networks (GCNs).\nIn this taxonomy, GCNs are categorized into ﬁve\ngroups: graph convolution networks, graph atten-\ntion networks, graph auto-encoders, graph genera-\ntive networks, and graph spatial-temporal networks.\nWe pinpoint the differences between graph neural\nnetworks and network embedding, and draw the\nconnections between different graph neural network\narchitectures.\n•\nComprehensive review This survey provides the\nmost comprehensive overview on modern deep\nlearning techniques for graph data. For each type of\ngraph neural network, we provide detailed descrip-\ntions on representative algorithms, and make neces-\nsary comparison and summarise the corresponding\nalgorithms.\n•\nAbundant resources This survey provides abundant\nresources on graph neural networks, which include\nstate-of-the-art\nalgorithms,\nbenchmark\ndatasets,\nopen-source codes, and practical applications. This\nsurvey can be used as a hands-on guide for under-\nstanding, using, and developing different deep learn-\ning approaches for various real-life applications.\n•\nFuture directions This survey also highlights the cur-\nrent limitations of the existing algorithms, and points\nout possible directions in this rapidly developing\nﬁeld.\nOrganization of Our Survey The rest of this survey\nis organized as follows. Section 2 deﬁnes a list of graph-\nrelated concepts. Section 3 clariﬁes the categorization of\ngraph neural networks. Section 4 and Section 5 provides\nan overview of graph neural network models. Section 6\npresents a gallery of applications across various domains.\nSection 7 discusses the current challenges and suggests\nfuture directions. Section 8 summarizes the paper.\nTABLE 1: Commonly used notations.\nNotations\nDescriptions\n| · |\nThe length of a set\n⊙\nElement-wise product.\nAT\nTranspose of vector/matrix A.\n[A, B]\nConcatenation of A and B.\nG\nA graph\nV\nThe set of nodes in a graph\nvi\nA node vi ∈V\nN(v)\nthe neighbors of node v\nE\nThe set of edges in a graph\neij\nAn edge eij ∈E\nX ∈RN×D The feature matrix of a graph.\nx ∈RN\nThe feature vector of a graph in case of D = 1.\nXi ∈RD\nThe feature vector of the node vi.\nN\nThe number of nodes, N = |V |.\nM\nThe number of edges, M = |E|.\nD\nThe dimension of a node vector.\nT\nThe total number of time steps in time series.\nFig. 3: Categorization of Graph Neural Networks.\n2\nDEFINITION\nIn this section, we provide deﬁnitions of basic graph con-\ncepts. For easy retrieval, we summarize the commonly used\nnotations in Table 1.\nDeﬁnition 1 (Graph). A Graph is G = (V, E, A) where V\nis the set of nodes, E is the set of edges, and A is the\nadjacency matrix. In a graph, let vi ∈V to denote a node\nand eij = (vi, vj) ∈E to denote an edge. The adjacency\nmatrix A is a N × N matrix with Aij = wij > 0 if\neij ∈E and Aij = 0 if eij /∈E. The degree of a node is\nthe number of edges connected to it, formally deﬁned as\ndegree(vi) = P Ai,:\nA graph can be associated with node attributes X\n1,\nwhere X ∈RN×D is a feature matrix with Xi ∈RD\nrepresenting the feature vector of node vi. In the case of\nD = 1, we replace x ∈RN with X to denote the feature\nvector of the graph.\nDeﬁnition 2 (Directed Graph). A directed graph is a graph\nwith all edges pointing from one node to another. For\na directed graph, Aij ̸= Aji. An undirected graph is a\n1. Such graph is referred to an attributed graph in literature.\n",
    "book_id": "a_comprehensive_survey_on_graph_neural_net",
    "book_title": "A Comprehensive Survey on Graph Neural Net",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 2
  },
  {
    "chunk_full": "JOURNAL OF LATEX CLASS FILES, VOL. X, NO. X, DECEMBER 2018\n4\nFig. 4: A Variant of Graph Convolution Networks with Mul-\ntiple GCN layers [14]. A GCN layer encapsulates each node’s\nhidden representation by aggregating feature information from\nits neighbors. After feature aggregation, a non-linear transfor-\nmation is applied to the resultant outputs. By stacking multiple\nlayers, the ﬁnal hidden representation of each node receives\nmessages from further neighborhood.\ngraph with all edges undirectional. For an undirected\ngraph, Aij = Aji.\nDeﬁnition 3 (Spatial-Temporal Graph). A spatial-temporal\ngraph is an attributed graph where the feature matrix X\nevolves over time. It is deﬁned as G = (V, E, A, X) with\nX ∈RT ×N×D where T is the length of time steps.\n3\nCATEGORIZATION AND FRAMEWORKS\nIn this section, we present our taxonomy of graph neural\nnetworks. We consider any differentiable graph models\nwhich incorporate neural architectures as graph neural net-\nworks. We categorize graph neural networks into graph con-\nvolution networks, graph attention networks, graph auto-\nencoders, graph generative networks and graph spatial-\ntemporal networks. Of these, graph convolution networks\nplay a central role in capturing structural dependencies.\nAs illustrated in Figure 3, methods under other categories\npartially utilize graph convolution networks as building\nblocks. We summarize the representative methods in each\ncategory in Table 2, and we give a brief introduction of each\ncategory in the following.\n3.1\nTaxonomy of GNNs\nGraph Convolution Networks (GCNs) generalize the oper-\nation of convolution from traditional data (images or grids)\nto graph data. The key is to learn a function f to generate\na node vi’s representation by aggregating its own features\nXi and neighbors’ features Xj, where j ∈N(vi). Figure 4\nshows the process of GCNs for node representation learn-\ning. Graph convolutional networks play a central role in\nbuilding up many other complex graph neural network\nmodels, including auto-encoder-based models, generative\nmodels, and spatial-temporal networks, etc. Figure 5 illus-\ntrates several graph neural network models building on\nGCNs.\nGraph Attention Networks are similar to GCNs and seek an\naggregation function to fuse the neighboring nodes, random\nwalks, and candidate models in graphs to learn a new\nrepresentation. The key difference is that graph attention\nnetworks employ attention mechanisms which assign larger\nweights to the more important nodes, walks, or models. The\nattention weight is learned together with neural network\n(a) Graph Convolution Networks with Pooling Modules for Graph\nClassiﬁcation [12]. A GCN layer [14] is followed by a pooling layer to\ncoarsen a graph into sub-graphs so that node representations on coars-\nened graphs represent higher graph-level representations. To calculate\nthe probability for each graph label, the output layer is a linear layer\nwith the SoftMax function.\n(b) Graph Auto-encoder with GCN [59]. The encoder uses GCN layers\nto get latent rerpesentations for each node. The decoder computes the\npair-wise distance between node latent representations produced by the\nencoder. After applying a non-linear activation function, the decoder\nreconstructs the graph adjacency matrix.\n(c) Graph Spatial-Temporal Networks with GCN [71]. A GCN layer is\nfollowed by a 1D-CNN layer. The GCN layer operates on At and Xt\nto capture spatial dependency, while the 1D-CNN layer slides over X\nalong the time axis to capture the temporal dependency. The output\nlayer is a linear transformation, generating a prediction for each node.\nFig. 5: Different Graph Neural Network Models built with\nGCNs.\nparameters within an end-to-end framework. Figure 6 illus-\ntrates the difference between graph convolutional networks\nand graph attention networks in aggregating the neighbor\nnode information.\nGraph Auto-encoders are unsupervised learning frame-\nworks which aim to learn a low dimensional node vectors\nvia an encoder, and then reconstruct the graph data via\na decoder. Graph autoencoders are a popular approach to\nlearn the graph embedding, for both plain graphs with-\nout attributed information [41], [42] as well as attributed\ngraphs [61], [62]. For plain graphs, many algorithms directly\nprepossess the adjacency matrix, by either constructing a\nnew matrix (i.e., pointwise mutual information matrix) with\nrich information [41], or feeding the adjacency matrix to\na autoencoder model and capturing both ﬁrst order and\nsecond order information [42]. For attributed graphs, graph\nautoencoder models tend to employ GCN [14] as a building\nblock for the encoder and reconstruct the structure informa-\ntion via a link prediction decoder [59], [61].\n",
    "book_id": "a_comprehensive_survey_on_graph_neural_net",
    "book_title": "A Comprehensive Survey on Graph Neural Net",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 3
  },
  {
    "chunk_full": "JOURNAL OF LATEX CLASS FILES, VOL. X, NO. X, DECEMBER 2018\n5\nTABLE 2: Representative Publications of Graph Neural Networks\nCategory\nPublications\nGraph Convolution Networks\nSpectral-based\n[12], [14], [20], [21], [22], [23], [43]\nSpatial-based\n[13], [17], [18], [19], [24], [25], [26], [27], [44], [45]\n[46], [47], [48], [49], [50], [51], [52], [53], [54]\nPooling modules\n[12], [21], [55], [56]\nGraph Attention Networks\n[15], [28], [57], [58]\nGraph Auto-encoder\n[41], [42], [59], [60], [61], [62], [63]\nGraph Generative Networks\n[64], [65], [66], [67], [68]\nGraph Spatial-Temporal Networks\n[69], [70], [71], [72], [73]\n(a) Graph Convolution Net-\nworks [14] explicitly assign a\nnon-parametric weight aij =\n1\n√\ndeg(vi)deg(vj) to the neigh-\nbor vj of vi during the aggre-\ngation process.\n(b) Graph Attention Networks\n[15]\nimplicitly\ncapture\nthe\nweight aij via an end to end\nneural network architecture,\nso that more important nodes\nreceive larger weights.\nFig. 6: Differences between graph convolutional networks\nand graph attention networks.\nGraph Generative Networks aim to generate plausible\nstructures from data. Generating graphs given a graph\nempirical distribution is fundamentally challenging, mainly\nbecause graphs are complex data structures. To address this\nproblem, researchers have explored to factor the generation\nprocess as forming nodes and edges alternatively [64], [65],\nto employ generative adversarial training [66], [67]. One\npromising application domain of graph generative networks\nis chemical compound synthesis. In a chemical graph, atoms\nare treated as nodes and chemical bonds are treated as\nedges. The task is to discover new synthesizable molecules\nwhich possess certain chemical and physical properties.\nGraph Spatial-temporal Networks aim to learn unseen pat-\nterns from spatial-temporal graphs, which are increasingly\nimportant in many applications such as trafﬁc forecasting\nand human activity prediction. For instance, the underlying\nroad trafﬁc network is a natural graph where each key loca-\ntion is a node whose trafﬁc data is continuously monitored.\nBy developing effective graph spatial temporal network\nmodels, we can accurately predict the trafﬁc status over\nthe whole trafﬁc system [70], [71]. The key idea of graph\nspatial-temporal networks is to consider spatial dependency\nand temporal dependency at the same time. Many current\napproaches apply GCNs to capture the dependency together\nwith some RNN [70] or CNN [71] to model the temporal\ndependency.\n3.2\nFrameworks\nGraph\nneural\nnetworks,\ngraph\nconvolution\nnetworks\n(GCNs) in particular, try to replicate the success of CNN\nin graph data by deﬁning graph convolutions via graph\nspectral theory or spatial locality. With graph structure and\nnode content information as inputs, the outputs of GCN\ncan focus on different graph analytics task with one of the\nfollowing mechanisms:\n•\nNode-level outputs relate to node regression and\nclassiﬁcation tasks. As a graph convolution module\ndirectly gives nodes’ latent representations, a multi-\nperceptron layer or softmax layer is used as the ﬁnal\nlayer of GCN. We review graph convolution modules\nin Section 4.1 and Section 4.2.\n•\nEdge-level outputs relate to the edge classiﬁca-\ntion and link prediction tasks. To predict the la-\nbel/connection strength of an edge, an additional\nfunction will take two nodes’ latent representations\nfrom the graph convolution module as inputs.\n•\nGraph-level outputs relate to the graph classiﬁcation\ntask. To obtain a compact representation on graph\nlevel, a pooling module is used to coarse a graph\ninto sub-graphs or to sum/average over the node\nrepresentations. We review graph pooling module in\nSection 4.3.\nIn Table 3, we list the details of the inputs and outputs\nof the main GCNs methods. In particular, we summarize\noutput mechanisms in between each GCN layer and in the\nﬁnal layer of each method. The output mechanisms may\ninvolve several pooling operations, which are discussed in\nSection 4.3.\nEnd-to-end Training Frameworks. Graph convolutional net-\nworks can be trained in a (semi-) supervised or purely un-\nsupervised way within an end-to-end learning framework,\ndepending on the learning tasks and label information avail-\nable at hand.\n•\nSemi-supervised learning for node-level classiﬁ-\ncation. Given a single network with partial nodes\nbeing labeled and others remaining unlabeled, graph\nconvolutional networks can learn a robust model that\neffectively identify the class labels for the unlabeled\nnodes [14]. To this end, an end-to-end framework can\nbe built by stacking a couple of graph convolutional\nlayers followed by a softmax layer for multi-class\nclassiﬁcation.\n•\nSupervised learning for graph-level classiﬁcation.\nGiven a graph dataset, graph-level classiﬁcation aims\nto predict the class label(s) for an entire graph [55],\n",
    "book_id": "a_comprehensive_survey_on_graph_neural_net",
    "book_title": "A Comprehensive Survey on Graph Neural Net",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 4
  },
  {
    "chunk_full": "JOURNAL OF LATEX CLASS FILES, VOL. X, NO. X, DECEMBER 2018\n6\n[56], [74], [75]. The end-to-end learning for this task\ncan be done with a framework which combines\nboth graph convolutional layers and the pooling\nprocedure [55], [56]. Speciﬁcally, by applying graph\nconvolutional layers, we obtain a representation with\na ﬁxed number of dimensions for each node in each\nsingle graph. Then, we can get the representation of\nan entire graph through pooling which summarizes\nthe representation vectors of all nodes in a graph.\nFinally, by applying the MLP layers and a softmax\nlayer which are commonly used in existing deep\nlearning frameworks, we can build an end-to-end\nframework for graph classiﬁcation. An example is\ngiven in Fig 5a.\n•\nUnsupervised learning for graph embedding. When\nno class labels are available in graphs, we can learn\nthe graph embedding in a purely unsupervised way\nin an end-to-end framework. These algorithms ex-\nploit the edge-level information in two ways. One\nsimple way is to adapt an autoencoder framework\nwhere the encoder employs graph convolutional lay-\ners to embed the graph into the latent representation\nupon which a decoder is used to reconstruct the\ngraph structure [59], [61]. Another way is to utilize\nthe negative sampling approach which samples a\nportion of node pairs as negative pairs while existing\nnode pairs with links in the graphs being positive\npairs. Then a logistic regression layer is applied after\nthe convolutional layers for end-to-end learning [24].\n4\nGRAPH CONVOLUTION NETWORKS\nIn this section, we review graph convolution networks\n(GCNs), the fundamental of many complex graph neural\nnetwork models. GCNs approaches fall into two categories,\nspectral-based and spatial-based. Spectral-based approaches\ndeﬁne graph convolutions by introducing ﬁlters from the\nperspective of graph signal processing [76] where the graph\nconvolution operation is interpreted as removing noise\nfrom graph signals. Spatial-based approaches formulate\ngraph convolutions as aggregating feature information from\nneighbors. While GCNs operate on the node level, graph\npooling modules can be interleaved with the GCN layer, to\ncoarsen graphs into high-level sub-structures. As shown in\nFig 5a, such an architecture design can be used to extract\ngraph-level representations and to perform graph classiﬁ-\ncation tasks. In the following, we introduce spectral-based\nGCNs, spatial-based GCNs, and graph pooling modules\nseparately.\n4.1\nSpectral-based Graph Convolutional Networks\nSpectral-based methods have a solid foundation in graph\nsignal processing [76]. We ﬁrst give some basic knowledge\nbackground of graph signal processing, after which we re-\nview the representative research on the spetral-based GCNs.\n4.1.1\nBackgrounds\nA robust mathematical representation of a graph is the\nnormalized graph Laplacian matrix, deﬁned as L = In −\nD−1\n2 AD−1\n2 , where D is a diagonal matrix of node de-\ngrees, Dii = P\nj(Ai,j). The normalized graph Laplacian\nmatrix possesses the property of being real symmetric\npositive semideﬁnite. With this property, the normalized\nLaplacian matrix can be factored as L = UΛUT , where\nU = [u0, u1, · · · , un−1] ∈RN×N is the matrix of eigenvec-\ntors ordered by eigenvalues and Λ is the diagonal matrix of\neigenvalues, Λii = λi. The eigenvectors of the normalized\nLaplacian matrix forms an orthonormal space, in mathemat-\nical words, UT U = I. In graph signal processing, a graph\nsignal x ∈RN is a feature vector of nodes of the graph\nwhere xi is the value of ith node. The graph Fourier transform\nto a signal x is deﬁned as F(x) = UT x and the inverse\ngraph Fourier transform is deﬁned as F −1(ˆx) = Uˆx,\nwhere ˆx represents the resulting signal from graph Fourier\ntransform. To understand graph Fourier transform, from its\ndeﬁnition we see that it indeed projects the input graph\nsignal to the orthonormal space where the basis is formed by\neigenvectors of the normalized graph Laplacian. Elements\nof the transformed signal ˆx are the coordinates of the graph\nsignal in the new space so that the input signal can be\nrepresented as x = P\ni ˆxiui, which is exactly the inverse\ngraph Fourier transform. Now the graph convolution of the\ninput signal x with a ﬁlter g ∈RN is deﬁned as\nx ∗G g = F −1(F(x) ⊙F(g))\n= U(UT x ⊙UT g)\n(1)\nwhere ⊙denotes the Hadamard product. If we denote a\nﬁlter as gθ = diag(UT g), then the graph convolution is\nsimpliﬁed as\nx ∗G gθ = UgθUT x\n(2)\nSpectral-based graph convolution networks all follow this\ndeﬁnition. The key difference lies in the choice of the ﬁlter\ngθ.\n4.1.2\nMethods of Spectral based GCNs\nSpectral CNN. Bruna et al. [20] propose the ﬁrst spectral\nconvolution neural network (Spectral CNN). Assuming the\nﬁlter gθ = Θk\ni,j is a set of learnable parameters and consid-\nering graph signals of multi-dimension, they deﬁne a graph\nconvolution layer as\nXk+1\n:,j\n= σ(\nfk−1\nX\ni=1\nUΘk\ni,jUT Xk\n:,i)\n(j = 1, 2, · · · , fk)\n(3)\nwhere Xk ∈RN×fk−1 is the input graph signal, N is the\nnumber of nodes, fk−1 is the number of input channels and\nfk is the number of output channels, Θk\ni,j is a diagonal\nmatrix ﬁlled with learnable parameters, and σ is a non-\nlinear transformation.\nChebyshev Spectral CNN (ChebNet). Defferrard et al.\n[12] propose ChebNet which deﬁnes a ﬁlter as Cheby-\nshev polynomials of the diagonal matrix of eigenvalues,\ni.e, gθ = PK\ni=1 θiTk(˜Λ), where ˜Λ = 2Λ/λmax −IN. The\nChebyshev polynomials are deﬁned recursively by Tk(x) =\n2xTk−1(x) −Tk−2(x) with T0(x) = 1 and T1(x) = x. As a\n",
    "book_id": "a_comprehensive_survey_on_graph_neural_net",
    "book_title": "A Comprehensive Survey on Graph Neural Net",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 5
  },
  {
    "chunk_full": "JOURNAL OF LATEX CLASS FILES, VOL. X, NO. X, DECEMBER 2018\n7\nTABLE 3: Summary of Graph Convolution Networks\nCategory\nApproach\nInputs\n(allow edge\nfeatures?)\nOutputs\nOutput Mechanisms\nIntermediate\nFinal\nSpectral\nBased\nSpectral CNN (2014) [20]\n\u0017\nGraph-level\ncluster+max pooling\nsoftmax function\nChebNet (2016) [12]\n\u0017\nGraph-level\nefﬁcient pooling\nmlp layer+softmax function\n1stChebNet (2017) [14]\n\u0017\nNode-level\nactivation function\nsoftmax function\nAGCN (2018) [22]\n\u0017\nGraph-level\nmax pooling\nsum pooling\nSpatial\nBased\nGNN (2009) [17]\n\u0013\nNode-level\n-\nmlp layer+softmax function\nGraph-level\n-\nadd a dummy super node\nGGNNs (2015) [18]\n\u0017\nNode-level\n-\nmlp layer/softmax function\nGraph-level\n-\nsum pooling\nSSE (2018) [19]\n\u0017\nNode-level\n-\nsoftmax function\nMPNN (2017) [13]\n\u0013\nNode-level\nsoftmax function\nGraph-level\n-\nsum pooling\nGraphSage (2017) [24]\n\u0017\nNode-level\nactivation function\nsoftmax function\nDCNN (2016) [44]\n\u0013\nNode-level\nactivation function\nsoftmax function\nGraph-level\n-\nmean pooling\nPATCHY-SAN (2016) [26]\n\u0013\nGraph-level\n-\nmlp layer+softmax function\nLGCN (2018) [27]\n\u0017\nNode-level\nskip connections\nmlp layer+softmax function\nresult, the convolution of a graph signal x with the deﬁned\nﬁlter gθ is\nx ∗G gθ = U(\nK\nX\ni=1\nθiTk(˜Λ))UT x\n=\nK\nX\ni=1\nθiTi(˜L)x\n(4)\nwhere ˜L = 2L/λmax −IN.\nFrom Equation 4, ChebNet implictly avoids the compu-\ntation of the graph Fourier basis, reducing the computation\ncomplexity from O(N 3) to O(KM). Since Ti(˜L) is a polyno-\nmial of ˜L of ith order, Ti(˜L)x operates locally on each node.\nTherefore, the ﬁlters of ChebNet are localized in space.\nFirst order of ChebNet (1stChebNet 2) Kipf et al. [14] in-\ntroduce a ﬁrst-order approximation of ChebNet. Assuming\nK = 1 and λmax = 2 , Equation 4 is simpliﬁed as\nx ∗G gθ = θ0x −θ1D−1\n2 AD−1\n2 x\n(5)\nTo restrain the number of parameters and avoid over-\nﬁtting, 1stChebNet further assumes θ = θ0 = −θ1, leading\nto the following deﬁnition of graph convolution,\nx ∗G gθ = θ(In + D−1\n2 AD−1\n2 )x\n(6)\nIn order to incorporate multi-dimensional graph input\nsignals, 1stChebNet proposes a graph convolution layer\nwhich modiﬁes Equation 6,\nXk+1 = ˜AXkΘ\n(7)\nwhere ˜A = IN + D−1\n2 AD−1\n2 .\nThe graph convolution deﬁned by 1stChebNet is local-\nized in space. It bridges the gap between spectral-based\nmethods and spatial-based methods. Each row of the output\nrepresents the latent representation of each node obtained\nby a linear transformation of aggregated information from\nthe node itself and its neighboring nodes with weights\nspeciﬁed by the row of ˜A. However, the main drawback\n2. Due to its impressive performance in many node classiﬁcation\ntasks, 1stChebNet is simply termed as GCN and is considered as a\nstrong baseline in the research community.\nof 1stChebNet is that the computation cost increases expo-\nnentially with the increase of the number of 1stChebNet\nlayers during batch training. Each node in the last layer\nhas to expand its neighborhood recursively across previous\nlayers. Chen et al. [45] assume the rescaled adjacent matrix\n˜A in Equation 7 comes from a sampling distribution. Under\nthis assumption, the technique of Monte Carlo and variance\nreduction techniques are used to facilitate the training pro-\ncess. Chen et al. [46] reduce the receptive ﬁeld size of the\ngraph convolution to an arbitrary small scale by sampling\nneighborhoods and using historical hidden representations.\nHuang et al. [54] propose an adaptive layer-wise sampling\napproach to accelerate the training of 1stChebNet, where\nsampling for the lower layer is conditioned on the top\none. This method is also applicable for explicit variance\nreduction.\nAdaptive Graph Convolution Network (AGCN). To ex-\nplore hidden structural relations unspeciﬁed by the graph\nLaplacian matrix, Li et al. [22] propose the adaptive graph\nconvolution network (AGCN). AGCN augments a graph\nwith a so-called residual graph, which is constructed by\ncomputing a pairwise distance of nodes. Despite being able\nto capture complement relational information, AGCN incurs\nexpensive O(N 2) computation.\n4.1.3\nSummary\nSpectral CNN [20] relys on the eigen-decomposition of the\nLaplacian matrix. It has three effects. First, any perturbation\nto a graph results in a change of eigen basis. Second, the\nlearned ﬁlters are domain dependent, meaning they cannot\nbe applied to a graph with a different structure. Third, eigen-\ndecomposition requires O(N 3) computation and O(N 2)\nmemory. Filters deﬁned by ChebNet [12] and 1stChebNet\n[14] are localized in space. The learned weights can be\nshared across different locations in a graph. However, a\ncommon drawback of spectral methods is they need to\nload the whole graph into the memory to perform graph\nconvolution, which is not efﬁcient in handling big graphs.\n4.2\nSpatial-based Graph Convolutional Networks\nImitating the convolution operation of a conventional con-\nvolution neural network on an image, spatial-based meth-\n",
    "book_id": "a_comprehensive_survey_on_graph_neural_net",
    "book_title": "A Comprehensive Survey on Graph Neural Net",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 6
  },
  {
    "chunk_full": "JOURNAL OF LATEX CLASS FILES, VOL. X, NO. X, DECEMBER 2018\n8\n!\"#$\n!\"#%\n!\"#&\n…\nℎ()\nℎ($\nℎ(%\nℎ(&\nℎ(&*$\n!\"#$\n!\"#$\n!\"#$\n…\nℎ()\nℎ($\nℎ(%\nℎ(&\nℎ(&*$\n(a) Recurrent-based\n(b) Composition-based\nFig. 7: Recurrent-based v.s. Composition-based Spatial\nGCNs.\nods deﬁne graph convolution based on a node’s spatial re-\nlations. To relate images with graphs, images can be consid-\nered as a special form of graph with each pixel representing\na node. As illustrated in Figure 1a, each pixel is directly\nconnected to its nearby pixels. With a 3 × 3 window, the\nneighborhood of each node is its surrounding eight pixels.\nThe positions of these eight pixels indicate an ordering of a\nnode’s neighbors. A ﬁlter is then applied to this 3 × 3 patch\nby taking the weighted average of pixel values of the central\nnode and its neighbors across each channel. Due to the spe-\nciﬁc ordering of neighboring nodes, the trainable weights\nare able to be shared across different locations. Similarly, for\na general graph, the spatial-based graph convolution takes\nthe aggregation of the central node representation and its\nneighbors representation to get a new representation for this\nnode, as depicted by Figure 1b. To explore the depth and\nbreadth of a node’s receptive ﬁeld, a common practice is to\nstack multiple graph convolution layer together. According\nto the different approaches of stacking convolution layers,\nspatial-based GCNs can be further divided into two cate-\ngories, recurrent-based and composition-based spatial GCNs.\nRecurrent-based methods apply a same graph convolution\nlayer to update hidden representations, while composition-\nbased methods apply a different graph convolution layer\nto update hidden representations. Figure 7 illustrates this\ndifference. In the following, we give an overview of these\ntwo branches.\n4.2.1\nRecurrent-based Spatial GCNs\nThe main idea of recurrent-based methods is to update a\nnode’s latent representation recursively until a stable ﬁxed\npoint is reached. This is done by imposing constraints on\nrecurrent functions [17], employing gate recurrent unit ar-\nchitectures [18], updating node latent representations asyn-\nchronously and stochastically [19]. In the following, we will\nintroduce these three methods.\nGraph Neural Networks(GNNs) Being one of the earli-\nest works on graph neural networks, GNNs recursively\nupdate node latent representations until convergence. In\nother words, from the perspective of the diffusion process,\neach node exchanges information with its neighbors until\nequilibrium is reached. To handle heterogeneous graphs, the\nspatial graph convolution of GNNs is deﬁned as\nht\nv = f(lv, lco[v], ht−1\nne [v], lne[v])\n(8)\nwhere lv denotes the label attributes of node v, lco[v] denotes\nthe label attributes of corresponding edges of node v, ht\nne[v]\ndenotes the hidden representations of node v’s neighbors at\ntime step t, and lne[v] denotes the label attributes of node\nv’s neighbors.\nTo ensure convergence, the recurrent function f(·) must\nbe a contraction mapping, which shrinks the distance be-\ntween two points after mapping. In case of f(·) is a neural\nnetwork, a penalty term has to be imposed on the Jacobian\nmatrix of parameters. GNNs used the Almeida-Pineda algo-\nrithm [77], [78] to train its model. The core idea is to run the\npropagation process to reach ﬁxed points and then perform\nthe backward procedure given the converged solution.\nGated Graph Neural Networks (GGNNs) GGNNs employs\ngated recurrent units(GRU) [79] as the recurrent function,\nreducing the recurrence to a ﬁxed number of steps. The\nspatial graph convolution of GGNNs is deﬁned as\nht\nv = GRU(ht−1\nv\n,\nX\nu∈N(v)\nWht\nu)\n(9)\nDifferent\nfrom\nGNNs,\nGGNNs\nuse\nback-propagation\nthrough time (BPTT) to learn the parameters. The adavan-\ntage is that it no longer needs to constrain parameters to\nensure convergence. However, the downside of training by\nBPTT is that it sacriﬁces efﬁciency both in time and memory.\nThis is especially problematic for large graphs, as GGNNs\nneed to run the recurrent function multiple times over all\nnodes, requring intermediate states of all nodes to be stored\nin memory.\nStochastic Steady-state Embedding (SSE). To improve the\nlearning efﬁciency, the SSE algorithm [19] updates the node\nlatent representations stochastically in an asynchronous\nfashion. As shown in Algorithm 1, SSE recursively estimates\nnode latent representations and updates the parameters\nwith sampled batch data. To ensure convergence to steady\nstates, the recurrent function of SSE is deﬁned as a weighted\naverage of the historical states and new states,\nhv\nt = (1 −α)hv\nt−1 + αW1σ(W2[xv,\nX\nu∈N(v)\n[hu\nt−1, xu]])\n(10)\nThough summing neighborhood information implicitly con-\nsiders node degree, it remains questionable whether the\nscale of this summation affects the stability of this algorithm.\n4.2.2\nComposition Based Spatial GCNs\nComposition-based methods update the nodes’ representa-\ntions by stacking multiple graph convolution layers.\nMessage Passing Neural Networks (MPNNs). Gilmer\net al. [13] generalizes several existing graph convolution\nnetworks including [12], [14], [18], [20], [53], [80], [81]\ninto a uniﬁed framework named Message Passing Neural\nNetworks (MPNNs). MPNNs consists of two phases, the\nmessage passing phase and the readout phase. The mes-\nsage passing phase actually run T-step spatial-based graph\nconvolutions. The graph convolution operation is deﬁned\nthrough a message function Mt(·) and an updating function\nUt(·) according to\nht\nv = Ut(ht−1\nv\n,\nX\nw∈N(v)\nMt(ht−1\nv\n, ht−1\nw , evw))\n(11)\n",
    "book_id": "a_comprehensive_survey_on_graph_neural_net",
    "book_title": "A Comprehensive Survey on Graph Neural Net",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 7
  },
  {
    "chunk_full": "JOURNAL OF LATEX CLASS FILES, VOL. X, NO. X, DECEMBER 2018\n9\nALGORITHM 1: Learning with Stochastic Fixed Point\nIteration [19]\nInitialize parameters,{h0\nv}v∈V\nfor k = 1 to K do\nfor t = 1 to T do\nSample n nodes from the whole node set V\nUse Equation 10 to update hidden\nrepresentations of sampled n nodes\nend\nfor p = 1 to P do\nSample m nodes from the labeled node set V\nForward model according to Equation 10\nBack-propagate gradients\nend\nend\nThe readout phase is actually a pooling operation which\nproduces a representation of the entire graph based on\nhidden representations of each individual node. It is deﬁned\nas\nˆy = R(hT\nv |v ∈G)\n(12)\nThrough the output function R(·), the ﬁnal representation ˆy\nis used to perform graph-level prediction tasks. The authors\npresent that several other graph convolution networks fall\ninto their framework by assuming different forms of Ut(·)\nand Mt(·).\nGraphSage [24] introduces the notion of the aggregation\nfunction to deﬁne graph convolution. The aggregation func-\ntion essentially assembles a node’s neighborhood informa-\ntion. It must be invariant to permutations of node orderings\nsuch as mean, sum and max function. The graph convolu-\ntion operation is deﬁned as,\nht\nv = σ(Wt · aggregatek(ht−1\nv\n, {hk−1\nu\n, ∀u ∈N(v)})\n(13)\nInstead of updating states over all nodes, GraphSage\nproposes a batch-training algorithm, which improves scal-\nability for large graphs. The learning process of GraphSage\nconsists of three steps. First, it samples a node’s local k-hop\nneighborhood with ﬁxed-size. Second, it derives the central\nnode’s ﬁnal state by aggregating its neighbors feature in-\nformation. Finally, it uses the central node’s ﬁnal state to\nmake predictions and backpropagate errors. This process is\nillustrated in Figure 8.\nAssuming the number of neighbors to be sampled at tth\nhop is st, the time complxity of GraphSage in one batch is\nO(QT\nt=1 st). Therefore the computation cost increases expo-\nnentially with the increase of t. This prevents GraphSage\nfrom having a deep architecture. However, in practice, the\nauthors ﬁnd that with t = 2 GraphSage already achieves\nhigh performance.\n4.2.3\nMiscellaneous Variants of Spatial GCNs\nDiffusion Convolution Neural Networks (DCNN) [44]\nproposed a graph convolution network which encapsulates\nthe graph diffusion process. A hidden node representation\nis obtained by independently convolving inputs with power\nFig. 8: Learning Process of GraphSage [24]\nseries of transition probability matrix. The diffusion convo-\nlution operation of DCNN is formulated as\nZm\ni,j,: = f(Wj,: ⊙Pm\ni,j,:Xm\ni,:)\n(14)\nIn Equation 14, zm\ni,j,: denotes the hidden representation\nof node i for hop j in graph m, Pm\n:,j,: denotes the prob-\nability transition matrix of hop j in graph m, and Xm\ni,:\ndenote the input features of node i in graph m, where\nzm ∈RNm×H×F , W ∈RH×F , Pm ∈RNm×H×Nm and\nXm ∈RNm×F .\nThough covering a larger receptive ﬁeld through higher\norders of transition matrix, the DCNN model needs\nO(N 2\nmH) memory, causing severe problems when applying\nit to large graphs.\nPATCHY-SAN [26] uses standard convolution neural net-\nwork (CNN) to solve graph classiﬁcation tasks. To do this,\nit converts graph-structured data into grid-structured data.\nFirst, it selects a ﬁxed number of nodes for each graph using\na graph labelling procedure. A graph labelling procedure\nessentially assigns a ranking to each node in the graph,\nwhich can be based on node-degree, centrality, Weisfeiler-\nLehman color [82] [83] etc. Second, as each node in a graph\ncan have a different number of neighbors, PATCHY-SAN\nselects and orders a ﬁxed number of neighbors for each\nnode according to their graph labellings. Finally, after the\ngrid-structured data with ﬁxed-size is formed, PATCHY-\nSAN employed standard CNN to learn the graph hidden\nrepresentations. Utilizing standard CNN in GCNs has the\nadvantage of keeping shift-invariance, which relies on the\nsorting function. As a result, the ranking criteria in the node\nselection and ordering process is of paramount importance.\nIn PATCHY-SAN, the ranking is based on graph labellings.\nHowever, graph labellings only take graph structures into\nconsideration, ignoring node feature information.\nLarge-scale Graph Convolution Networks (LGCN). In a\nfollow-up work, large-scale graph convolution networks\n(LGCN) [27] proposes a ranking method based on node fea-\nture information. Unlike PATCHY-SAN, LGCN uses stan-\ndard CNN to generate node-level outputs. For each node,\nLGCN assembles a feature matrix of its neigborhood and\nsortes this feature matrix along each column. The ﬁrst k\nrows of the sorted feature matrix are taken as the input\ngrid-data for the target node. In the end LGCN applies 1D\nCNN on the resultant inputs to get the target node’s hidden\nrepresentation. While deriving graph labellings in PATCHY-\nSAN requires complex pre-processing, sorting feature val-\nues in LGCN does not need a pre-processing step, making\nit more efﬁcient. To suit the scenario of large-scale graphs,\n",
    "book_id": "a_comprehensive_survey_on_graph_neural_net",
    "book_title": "A Comprehensive Survey on Graph Neural Net",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 8
  },
  {
    "chunk_full": "JOURNAL OF LATEX CLASS FILES, VOL. X, NO. X, DECEMBER 2018\n10\nLGCN proposes a subgraph training strategy, which puts\nthe sampled subgraphs into a mini-batch.\nMixture Model Network (MoNet) [25] uniﬁes standard\nCNN with convolutional architectures on non-Euclidean\ndomains. While several spatial-based approaches ignore the\nrelative positions between a node and its neighbors when\naggregating neighborhood feature information, MoNet in-\ntroduce pseudo-coordinates and weight functions to let the\nweight of a node’s neighbor be determined by the relative\nposition (pseudo-coordinates) between the node and its\nneighbor. Under such a framework, several approaches on\nmanifolds such as Geodesic CNN (GCNN) [84], Anisotropic\nCNN(ACNN) [85], Spline CNN [86], and on graphs such\nas GCN [14], DCNN [44] can be generalized as special\ninstances of MoNet. However these approaches under the\nframework of MoNet have ﬁxed weight functions. MoNet\ninstead proposes a Gaussian kernel with learnable parame-\nters to freely adjust the weight function.\n4.2.4\nSummary\nSpatial-based methods deﬁne graph convolutions via ag-\ngregating feature information from neighbors. According to\ndifferent ways of stacking graph convolution layers, spatial-\nbased methods are split into two groups, recurrent-based\nand composition-based. While recurrent-based approaches\ntry to obtain nodes’ steady states, composition-based ap-\nproaches try to incorporate higher orders of neighborhood\ninformation. In each layer, both two groups have to update\nhidden states over all nodes during training. However, it\nis not efﬁcient as it has to store all the intermediate states\ninto memory. To address this issue, several training strate-\ngies have been proposed, including sub-graph training for\ncomposition-based approaches such as GraphSage [24] and\nstochastically asynchronous training for recurrent-based ap-\nproaches such as SSE [19].\n4.3\nGraph Pooling Modules\nWhen generalizing convolutional neural networks to graph-\nstructured data, another key component, graph pooling\nmodule, is also of vital importance, particularly for graph-\nlevel classiﬁcation tasks [55], [56], [87]. According to Xu\net al. [88], pooling-assisted GCNs are as powerful as the\nWeisfeiler-Lehman test [82] in distinguishing graph struc-\ntures. Similar to the original pooling layer which comes\nwith CNNs, graph pooling module could easily reduce the\nvariance and computation complexity by down-sampling\nfrom original feature data. Mean/max/sum pooling is the\nmost primitive and most effective way of implementing this\nsince calculating the mean/max/sum value in the pooling\nwindow is rapid.\nhG = mean/max/sum(hT\n1 , hT\n2 , ..., hT\nn)\n(15)\nHenaff et al. [21] prove that performing a simple\nmax/mean pooling at the beginning of the network is espe-\ncially important to reduce the dimensionality in the graph\ndomain and mitigate the cost of the expensive graph Fourier\ntransform operation.\nDefferrard et al. optimize max/min pooling and devices\nan efﬁcient pooling strategy in their approach ChebNet [12].\nInput graphs are ﬁrst processed by the coarsening process\ndescribed in Fig 5a . After coarsening, the vertices of the\ninput graph and its coarsened versions are reformed in a\nbalanced binary tree. Arbitrarily ordering the nodes at the\ncoarsest level then propagating this ordering to the lower\nlevel in the balanced binary tree would ﬁnally produce a\nregular ordering in the ﬁnest level. Pooling such a rear-\nranged 1D signal is much more efﬁcient than the original.\nZhang et al. also propose a framework DGCNN [55]\nwith a similar pooling strategy named SortPooling which\nperforms pooling by rearranging vertices to a meaningful\norder. Different to ChebNet [12], DGCNN sorts vertices\naccording to their structural roles within the graph. The\ngraph’s unordered vertex features from spatial graph con-\nvolutions are treated as a continuous WL colors [82], and\nthey are then used to sort vertices. In addition to sorting\nthe vertex features, it uniﬁes the graph size to k by truncat-\ning/extending the graph’s feature tensor. The last n−k rows\nare deleted if n > k, otherwise k −n zero rows are added.\nThis method enhances the pooling network to improve the\nperformance of GCNs by solving one challenge underlying\ngraph structured tasks which is referred to as permutation\ninvariant. Verma and Zhang propose graph capsule net-\nworks [89] which further explore the permutation invariant\nfor graph data.\nRecently a pooling module, DIFFPOOL [56], is proposed\nwhich can generate hierarchical representations of graphs\nand can be combined with not only CNNs, but also var-\nious graph neural network architectures in an end-to-end\nfashion. Compared to all previous coarsening methods,\nDIFFPOOL does not simply cluster the nodes in one graph,\nbut provide a general solution to hierarchically pool nodes\nacross a broad set of input graphs. This is done by learning\na cluster assignment matrix S at layer l referred to as\nS(l) ∈Rnl×nl+1. Two separate GNNs with both input\ncluster node features X(l) and coarsened adjacency matrix\nA(l) are being used to generate the assignment matrix S(l)\nand embedding matrices Z(l) as follows:\nZ(l) = GNNl,embed(A(l), X(l))\n(16)\nS(l) = softmax(GNNl,pool(A(l), X(l)))\n(17)\nEquation\n16 and\n17 can be implemented with any\nstandard GNN module, which processes the same input\ndata but has distinct parametrizations since the roles they\nplay in the framework are different. The GNNl,embed will\nproduce new embeddings while the GNNl,pool generates a\nprobabilistic assignment of the input nodes to nl+1 clusters.\nThe Softmax function is applied in a row-wise fashion in\nEquation 17. As a result, each row of S(l) corresponds to one\nof the nl nodes(or clusters) at layer l, and each column of\nS(l) corresponds to one of the nl at the next layer. Once we\nhave Z(l) and S(l), the pooling operation comes as follows:\nX(l+1) = S(l)T Z(l) ∈Rnl+1×d\n(18)\nA(l+1) = S(l)T A(l)S(l) ∈Rnl+1×nl+1\n(19)\nEquation 18 takes the cluster embeddings Z(l) then\naggregates these embeddings according to the cluster as-\nsignments S(l) to calculate embedding for each of the nl+1\n",
    "book_id": "a_comprehensive_survey_on_graph_neural_net",
    "book_title": "A Comprehensive Survey on Graph Neural Net",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 9
  },
  {
    "chunk_full": "JOURNAL OF LATEX CLASS FILES, VOL. X, NO. X, DECEMBER 2018\n11\nclusters. Initial cluster embedding would be node repre-\nsentation. Similarly, Equation 19 takes the adjacency matrix\nA(l) as inputs and generates a coarsened adjacency matrix\ndenoting the connectivity strength between each pair of the\nclusters.\nOverall, DIFFPOOL [56] redeﬁnes the graph pooling\nmodule by using two GNNs to cluster the nodes. Any\nstandard GCN module is able to combine with DIFFPOOL,\nto not only achieve enhanced performance, but also to speed\nup the convolution operation.\n4.4\nComparison Between Spectral and Spatial Models\nAs the earliest convolutional networks for graph data,\nspectral-based models have achieved impressive results in\nmany graph related analytics tasks. These models are ap-\npealing in that they have a theoretical foundation in graph\nsignal processing. By designing new graph signal ﬁlters\n[23], we can theoretically design new graph convolution\nnetworks. However, there are several drawbacks to spectral-\nbased models. We illustrate this in the following from three\naspects, efﬁciency, generality and ﬂexibility.\nIn terms of efﬁciency, the computational cost of spectral-\nbased models increases dramatically with the graph size\nbecause they either need to perform eigenvector compu-\ntation [20] or handle the whole graph at the same time,\nwhich makes them difﬁcult to parallel or scale to large\ngraphs. Spatial based models have the potential to handle\nlarge graphs as they directly perform the convolution in\nthe graph domain via aggregating the neighbor nodes. The\ncomputation can be performed in a batch of nodes instead\nof the whole graph. When the number of neighbor nodes\nincreases, sampling techniques [24], [27] can be developed\nto improve efﬁciency.\nIn terms of generality, spectral-based models assumed\na ﬁxed graph, making them generalize poorly to new or\ndifferent graphs. Spatial-based models on the other hand\nperform graph convolution locally on each node, where\nweights can be easily shared across different locations and\nstructures.\nIn terms of ﬂexibility, spectral-based models are limited\nto work on undirected graphs. There is no clear deﬁnition\nof the Laplacian matrix on directed graphs so that the only\nway to apply spectral-based models to directed graphs is to\ntransfer directed graphs to undirected graphs. Spatial-based\nmodels are more ﬂexible to deal with multi-source inputs\nsuch as edge features and edge directions because these\ninputs can be incorporated into the aggregation function\n(e.g. [13], [17], [51], [52], [53]).\nAs a result, spatial models have attracted increasing\nattention in recent years [25].\n5\nBEYOND GRAPH CONVOLUTIONAL NETWORKS\nIn this section, we review other graph neural networks\nincluding graph attention neural networks, graph auto-\nencoder, graph generative networks, and graph spatial-\ntemporal networks. In Table 4, we provide a summary of\nmain approaches under each category.\n5.1\nGraph Attention Networks\nAttention mechanisms have almost become a standard in\nsequence-based tasks [90]. The virtue of attention mecha-\nnisms is their ability to focus on the most important parts\nof an object. This specialty has been proven to be useful\nfor many tasks, such as machine translation and natural\nlanguage understanding. Thanks to the increased model\ncapacity of attention mechanisms, graph neural networks\nalso beneﬁt from this by using attention during aggregation,\nintegrating outputs from multiple models, and generating\nimportance-oriented random walks. In this section, we will\ndiscuss how attention mechanisms are being used in graph\nstructured data.\n5.1.1\nMethods of Graph Attention Networks\nGraph Attention Network (GAT) [15] is a spatial-based\ngraph convolution network where the attention mechanism\nis involved in determining the weights of a node’s neighbors\nwhen aggregating feature information. The graph convolu-\ntion operation of GAT is deﬁned as,\nht\ni = σ(\nX\nj∈Ni\nα(ht−1\ni\n, ht−1\nj\n)Wt−1ht−1\nj\n)\n(20)\nwhere α(·) is an attention function which adaptively con-\ntrols the contribution of a neighbor j to the node i. In order\nto learn attention weights in different subspaces, GAT uses\nmulti-head attentions.\nht\ni =∥K\nk=1 σ(\nX\nj∈Ni\nαk(ht−1\ni\n, ht−1\nj\n)W t−1\nk\nht−1\nj\n)\n(21)\nwhere ∥denotes concatenation.\nGated Attention Network (GAAN) [28] also employs\nthe multi-head attention attention mechanism in updat-\ning a node’s hidden state. However rather than assigning\nan equal weight to each head, GAAN introduces a self-\nattention mechanism which computes a different weight for\neach head. The updating rule is deﬁned as,\nht\ni = φo(xi⊕∥K\nk=1 gk\ni\nX\nj∈Ni\nαk(ht−1\ni\n, ht−1\nj\n)φv(ht−1\nj\n))\n(22)\nwhere φo(·) and φv(·) denotes feedforward neural networks\nand gk\ni is the attention weight of the kth attention head.\nGraph Attention Model (GAM) [57] proposes a recur-\nrent neural network model to solve graph classiﬁcation\nproblems, which processes informative parts of a graph\nby adaptively visiting a sequence of important nodes. The\nGAM model is deﬁned as\nht = fh(fs(rt−1, vt−1, g; θs), ht−1; θh)\n(23)\nwhere fh(·) is a LSTM network, fs is the step network\nwhich takes a step from the current node vt−1 to one of\nits neighbors ct, prioritizing those whose type have higher\nrank in vt−1 which is generated by a policy network:\nrt = fr(ht; θr)\n(24)\nwhere rt is a stochastic rank vector which indicates which\nnode is more important and thus should be further explored\n",
    "book_id": "a_comprehensive_survey_on_graph_neural_net",
    "book_title": "A Comprehensive Survey on Graph Neural Net",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 10
  },
  {
    "chunk_full": "JOURNAL OF LATEX CLASS FILES, VOL. X, NO. X, DECEMBER 2018\n12\nTABLE 4: Summary of Alternative Graph Neural Networks (Graph Convolutional Networks Excluded). We summarize\nmethods based on their inputs, outputs, targeted tasks, and whether a method is GCN-based. Inputs indicate whether a\nmethod suits attributed graphs (A), directed graphs (D), and spatial-temporal graphs (S).\nCategory\nApproaches\nInputs\nOutputs\nTasks\nGCN\nBased\nA\nD\nS\nGraph\nAttention\nNetworks\nGAT (2017) [15]\n\u0013\n\u0013\n\u0017\nnode labels\nnode classiﬁcation\n\u0013\nGAAN (2018) [28]\n\u0013\n\u0013\n\u0017\nnode labels\nnode classiﬁcation\n\u0013\nGAM (2018) [57]\n\u0013\n\u0013\n\u0017\ngraph labels\ngraph classiﬁcation\n\u0017\nAttention Walks (2018) [58]\n\u0017\n\u0017\n\u0017\nnode embedding\nnetwork embedding\n\u0017\nGraph\nAuto-encoder\nGAE (2016) [59]\n\u0013\n\u0017\n\u0017\nreconstructed adajacency matrix\nnetwork embedding\n\u0013\nARGA (2018) [61]\n\u0013\n\u0017\n\u0017\nreconstructed adajacency matrix\nnetwork embedding\n\u0013\nNetRA (2018) [62]\n\u0017\n\u0017\n\u0017\nreconstructed sequences of\nrandom walks\nnetwork embedding\n\u0017\nDNGR (2016) [41]\n\u0017\n\u0017\n\u0017\nreconstructed PPMI matrix\nnetwork embedding\n\u0017\nSDNE (2016) [42]\n\u0017\n\u0013\n\u0017\nreconstructed adajacency matrix\nnetwork embedding\n\u0017\nDNRE (2018) [63]\n\u0013\n\u0017\n\u0017\nreconstructed node embedding\nnetwork embedding\n\u0017\nGraph\nGenerative\nNetworks\nMolGAN (2018) [66]\n\u0013\n\u0017\n\u0017\nnew graphs\ngraph generation\n\u0013\nDGMG (2018) [65]\n\u0017\n\u0017\n\u0017\nnew graphs\ngraph generation\n\u0013\nGraphRNN (2018) [64]\n\u0017\n\u0017\n\u0017\nnew graphs\ngraph generation\n\u0017\nNetGAN (2018) [67]\n\u0017\n\u0017\n\u0017\nnew graphs\ngraph generation\n\u0017\nGraph\nSpatial-Temporal\nNetworks\nDCRNN (2018) [70]\n\u0017\n\u0017\n\u0013\nnode value vectors\nspatial-temporal\nforecasting\n\u0013\nCNN-GCN (2017) [71]\n\u0017\n\u0017\n\u0013\nnode value vectors\nspatial-temporal\nforecasting\n\u0013\nST-GCN (2018) [72]\n\u0017\n\u0017\n\u0013\ngraph labels\nspatial-temporal\nclassiﬁcation\n\u0013\nStructural RNN (2016) [73]\n\u0017\n\u0017\n\u0013\nnode labels/value vectors\nspatial-temporal\nforecasting\n\u0017\nwith high priority, ht contains historical information that the\nagent has aggregated from exploration of the graph, and is\nused to make a prediction for the graph label.\nAttention Walks [58] learns node embeddings through\nrandom walks. Unlike DeepWalk [40] using ﬁxed apriori,\nAttention Walks factorizes the co-occurance matrix with\ndifferentiable attention weights.\nE[D] = ˜P(0)\nC\nX\nk=1\nak(P)k\n(25)\nwhere D denotes the cooccurence matrix, ˜P(0) denotes\nthe initial position matrix, and P denotes the probability\ntransition matrix.\n5.1.2\nSummary\nAttention mechanisms contribute to graph neural networks\nin three different ways, namely assigning attention weights\nto different neighbors when aggregating feature informa-\ntion, ensembling multiple models according to attention\nweights, and using attention weights to guide random\nwalks. Despite categorizing GAT [15] and GAAN [28] under\nthe umbrella of graph attention networks, they can also be\nconsidered as spatial-based graph convolution networks at\nthe same time. The advantage of GAT [15] and GAAN [28]\nis that they can adpatively learn the importance weights of\nneighbors as illustrated in Fig 6. However, the computa-\ntion cost and memory consumption increase rapidly as the\nattention weights between each pair of neighbors must be\ncomputed.\n5.2\nGraph Auto-encoders\nGraph auto-encoders are one class of network embedding\napproaches which aim at representing network vertices into\na low-dimensional vector space by using neural network\narchitectures. A typical solution is to leverage multi-layer\nperceptrons as the encoder to obtain node embeddings,\nwhere a decoder reconstructs a node’s neighborhood statis-\ntics such as positive pointwise mutual information (PPMI)\n[41] or the ﬁrst and second order of proximities [42]. Re-\ncently, researchers have explored the use of GCN [14] as an\nencoder, combining GCN [14] with GAN [91], or combining\nLSTM [7] with GAN [91] in designing a graph auto-encoder.\nWe will ﬁrst review GCN based autoencoder and then\nsummarize other variants in this category.\n5.2.1\nGCN Based Auto-encoders\nGraph Auto-encoder (GAE) [59] ﬁrstly integrates GCN\n[14] into a graph auto encoder framework. The encoder is\ndeﬁned as\nZ = GCN(X, A)\n(26)\nwhile the decoder is deﬁned as\nˆA = σ(ZZT)\n(27)\nThe framework of GAE is also dipicted in Fig 5b. The GAE\ncan be trained in a variational manner, i.e., to minimize the\nvariational lower bound L:\nL = Eq(Z|X,A)[logp(A|Z)] −KL[q(Z|X, A)||p(Z)]\n(28)\nAdversarially Regularized Graph Autoencoder (ARGA)\n[61] employs the training scheme of generative adversarial\nnetworks (GANs) [91] to regularize a graph auto-encoder. In\nARGA, an encoder encodes a node’s structural information\nwith its features into a hidden representation by GCN [14],\nand a decoder reconstructs the adjacency matrix from the\noutputs of the encoder. The GANs play a min-max game be-\ntween a generator and a discriminator in training generative\nmodels. A generator generates “faked samples” as real as\npossible while a discriminator makes its best to distinguish\n",
    "book_id": "a_comprehensive_survey_on_graph_neural_net",
    "book_title": "A Comprehensive Survey on Graph Neural Net",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 11
  },
  {
    "chunk_full": "JOURNAL OF LATEX CLASS FILES, VOL. X, NO. X, DECEMBER 2018\n13\nthe “faked samples” from the real ones. GAN helps ARGA\nto regularize the learned hidden representations of nodes to\nfollow a prior distribution. In detail, the encoder, working\nas a generator, tries to make the learned node hidden rep-\nresentations indistinguishable from a real prior distribution.\nA discriminator, on the other side, tries to identify whether\nthe learned node hidden representations are generated from\nthe encoder or from a real prior distribution.\n5.2.2\nMiscellaneous Variants of Graph Auto-encoders\nNetwork Representations with Adversarially Regularized\nAutoencoders (NetRA) [62] is a graph auto-encoder frame-\nwork which shares a similar idea with ARGA. It also\nregularizes node hidden representations to comply with a\nprior distribution via adversarial training. Instead of recon-\nstructing the adjacency matrix, they recover node sequences\nsampled from random walks by a sequence-to-sequence\narchitecture [92].\nDeep\nNeural\nNetworks\nfor\nGraph\nRepresentations\n(DNGR) [41] uses the stacked denoising autoencoder\n[93] to reconstruct the pointwise mutual information ma-\ntrix(PPMI). The PPMI matrix intrinsically captures nodes\nco-occurence information when a graph is serialized as\nsequences by random walks. Formally, the PPMI matrix is\ndeﬁned as\nPPMIv1,v2 = max(log( count(v1, v2) · |D|\ncount(v1)count(v2)), 0)\n(29)\nwhere |D| = P\nv1,v2 count(v1, v2) and v1, v2 ∈V . The\nstacked denoising autoencoder is able to learn highly non-\nlinear regularity behind data. Different from conventional\nneural autoencoders, it adds noise to inputs by randomly\nswitching entries of inputs to zero. The learned latent repre-\nsentation is more robust especially when there are missing\nvalues present.\nStructural Deep Network Embedding (SDNE) [42] uses\nstacked auto encoder to preserve nodes ﬁrst-order proximity\nand second-order proximity jointly. The ﬁrst-order proxim-\nity is deﬁned as the distance between a node’s hidden rep-\nresentation and its neighbor’s hidden representation. The\ngoal for the ﬁrst-order proximity is to drive representations\nof adjacent nodes close to each other as much as possible.\nSpeciﬁcally, the loss function L1st is deﬁned as\nL1st =\nn\nX\ni,j=1\nAi,j||h(k)\ni\n−h(k)\nj ||2\n(30)\nThe second-order proximity is deﬁned as the distance be-\ntween a node’s input and its reconstructed inputs where\nthe input is the corresponding row of the node in the\nadjacent matrix. The goal for the second-order proximity is\nto preserve a node’s neighborhood information. Concretely,\nthe loss function L2nd is deﬁned as\nL2nd =\nn\nX\ni=1\n||( ˆxi −xi) ⊙bi||2\n(31)\nThe role of vector bi is to penalize non-zero elements more\nthan zero elements since the inputs are highly sparse. In\ndetail, bi,j = 1 if Ai,j = 0 and bi,j = β > 1 if Ai,j = 1.\nOverall, the objective function is deﬁned as\nL = L2nd + αL1st + λLreg\n(32)\nwhere Lreg is the L2 regularization term.\nDeep Recursive Network Embedding (DRNE) [63] di-\nrectedly reconstructs a node’s hidden state instead of the\nwhole graph statistics. Using an aggregation function as the\nencoder, DRNE designs the loss function as,\nL =\nX\nv∈V\n||hv −aggregate(hu|u ∈N(v))||2\n(33)\nOne inovation of DRNE is that it choose LSTM as aggrega-\ntion function where the neighbors sequence is ordered by\ntheir node degree.\n5.2.3\nSummary\nDNGR and SDNE learn node embeddings only given the\ntopological structures, while GAE, ARGA, NetRA, DRNE\nlearn node embeddings when both topological information\nand node content features are available. One challenge of\ngraph auto-encoders is the sparsity of the adjacency matrix\nA, causing the number of positive entries of the decoder to\nbe far less than the negative ones. To tackle this issue, DNGR\nreconstructs a denser matrix namely the PPMI matrix, SDNE\nimposes a penalty to zero entries of the adjacency matrix,\nGAE reweights the terms in the adjacency matrix, and\nNetRA linearizes Graphs into sequences.\n5.3\nGraph Generative Networks\nThe goal of graph generative networks is to generate graphs\ngiven an observed set of graphs. Many approaches to graph\ngenerative networks are domain speciﬁc. For instance, in\nmolecular graph generation, some works model a string\nrepresentation of molecular graphs called SMILES [94], [95],\n[96], [97]. In natural language processing, generating a se-\nmantic or a knowledge graph is often conditioned on a given\nsentence [98], [99]. Recently, several general approaches\nhave been proposed. Some works factor the generation\nprocess as forming nodes and edges alternatively [64], [65]\nwhile others employ generative adversarial training [66],\n[67]. The methods in this category either employ GCN as\nbuilding blocks or use different architectures.\n5.3.1\nGCN Based Graph Generative Networks\nMolecular Generative Adversarial Networks (MolGAN)\n[66] integrates relational GCN [100], improved GAN [101]\nand reinforcement lerarning (RL) objective to generate\ngraphs with desired properties. The GAN consists of a\ngenerator and a discriminator, competing with each other\nto improve the authenticity of the generator. In MolGAN,\nthe generator tries to propose a faked graph along with its\nfeature matrix while the discriminator aims to distinguish\nthe faked sample from the empirical data. Additionally\na reward network is introduced in parallel with the dis-\ncriminator to encourage the generated graphs to possess\ncertain properties according to an external evaluator. The\nframework of MolGAN is described in Fig 9.\n",
    "book_id": "a_comprehensive_survey_on_graph_neural_net",
    "book_title": "A Comprehensive Survey on Graph Neural Net",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 12
  },
  {
    "chunk_full": "JOURNAL OF LATEX CLASS FILES, VOL. X, NO. X, DECEMBER 2018\n14\nFig. 9: Framework of MolGAN [67]. A generator ﬁrst samples an initial vector from a standard normal distribution. Passing\nthis initial vector through a neural network, the generator outputs a dense adjacency matrix A and a corresponding feature\nmatrix X. Next, the generator produces a sampled discrete ˜A and ˜X from categorical distributions based on A and X.\nFinally, GCN is used to derive a vector representation of the sampled graph. Feeding this graph representation to two\ndistinct neural networks, a discriminator and a reward network outputs a score between zero and one separately, which\nwill be used as feedback to update the model parameters.\nDeep Generative Models of Graphs (DGMG)\n[65] uti-\nlizes spatial-based graph convolution networks to obtain\na hidden representation of an existing graph. The decision\nprocess of generating nodes and edges is conditioned on the\nresultant graph representation. Brieﬂy, DGMG recursively\nproposes a node to a growing graph until a stopping criteria\nis evoked. In each step after adding a new node, DGMG\nrepeatedly decides whether to add an edge to the added\nnode until the decision turns to false. If the decision is true,\nit evaluates the probability distribution of connecting the\nnewly added node to all existing nodes and samples one\nnode from the probability distribution. After a new node\nand its connections are added to the existing graph, DGMG\nupdates the graph representation again.\n5.3.2\nMiscellaneous Graph Generative Networks\nGraphRNN [64] exploits deep graph generative models\nthrough two-level recurrent neural networks. The graph-\nlevel RNN adds a new node each time to a node sequence\nwhile the edge level RNN produces a binary sequence\nindicating connections between the newly added node and\npreviously generated nodes in the sequence. To linearize\na graph into a sequence of nodes for training the graph\nlevel RNN, GraphRNN adopts the breadth-ﬁrst-search (BFS)\nstrategy. To model the binary sequence for training the edge-\nlevel RNN, GraphRNN assumes multivariate Bernoulli or\nconditional Bernoulli distribution.\nNetGAN [67] combines LSTM [7] with Wasserstein GAN\n[102] to generate graphs from a random-walk-based ap-\nproach. The GAN framework consists of two modules, a\ngenerator and a discriminator. The generator makes its best\neffort to generate plausible random walks through a LSTM\nnetwork while the discriminator tries to distinguish faked\nrandom walks from the real ones. After training, a new\ngraph is obtained by normalizing a co-occurence matrix of\nnodes which occur in a set of random walks.\n5.3.3\nSummary\nEvaluating generated graphs remains a difﬁcult problem.\nUnlike synthesized images or audios, which can be di-\nrectly assessed by human experts, the quality of generated\ngraphs is difﬁcult to inspect visually. MolGAN and DGMG\nmake use of external knowledge to evaluate the validity\nof generated molecule graphs. GraphRNN and NetGAN\nevaluate generated graphs by graph statistics (e.g. node\ndegrees). Whereas DGMG and GraphRNN generate nodes\nand edges sequentially, MolGAN and NetGAN generate\nnodes and edges jointly. According to [68], the disadvantage\nof the former approaches is that when graphs become large,\nmodelling a long sequence is not realistic. The challenge\nof the later approaches is that global properties of the\ngraph are difﬁcult to control. A recent approach [68] adopts\nvariational auto-encoder to generate a graph by proposing\nthe adjacency matrix, imposing penalty terms to address\nvalidity constraints. However as the output space of a graph\nwith n nodes is n2, none of these methods is scalable to large\ngraphs.\n5.4\nGraph Spatial-Temporal Networks\nGraph spatial-temporal networks capture spatial and tem-\nporal dependencies of a spatial-temporal graph simultane-\nously. Spatial-temporal graphs have a global graph structure\nwith inputs to each node which are changing across time.\nFor instance, in trafﬁc networks, each sensor taken as a\nnode records the trafﬁc speed of a certain road continuously\nwhere the edges of the trafﬁc network are determined by\nthe distance between pairs of sensors. The goal of graph\nspatial-temporal networks can be forecasting future node\nvalues or labels, or predicting spatial-temporal graph labels.\nRecent studies have explored the use of GCNs [72] solely,\na combination of GCNs with RNN [70] or CNN [71], and\na recurrent architecture tailored to graph structures [73]. In\nthe following, we introduce these methods.\n5.4.1\nGCN Based Graph Spatial-Temporal Networks\nDiffusion\nConvolutional\nRecurrent\nNeural\nNetwork\n(DCRNN) [70] introduces diffusion convolution as graph\nconvolution for capturing spatial dependency and uses\nsequence-to-sequence architecture [92] with gated recurrent\nunits (GRU) [79] to capture temporal dependency.\nDiffusion convolution models a truncated diffusion pro-\ncess with forward and backward directions. Formally, the\ndiffusion convolution is deﬁned as\n",
    "book_id": "a_comprehensive_survey_on_graph_neural_net",
    "book_title": "A Comprehensive Survey on Graph Neural Net",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 13
  },
  {
    "chunk_full": "JOURNAL OF LATEX CLASS FILES, VOL. X, NO. X, DECEMBER 2018\n15\nX:,p ⋆G f(θ) =\nK−1\nX\nk=0\n(θk1(D−1\nO A)k + θk2(D−1\nI AT )k)X:,p\n(34)\nwhere DO is the out-degree matrix and DI is the in-\ndegree matrix. To allow multiple input and output channels,\nDCRNN proposes a diffusion convolution layer, deﬁned as\nZ:,q = σ(\nP\nX\np=1\nX:,p ⋆G f(Θq,p,:,:))\n(35)\nwhere X ∈RN×P and Z ∈RN×Q, Θ ∈RQ×P ×K×2, Q\nis the number of output channels and P is the number of\ninput channels.\nTo capture temporal dependency, DCRNN processes the\ninputs of GRU using a diffusion convolution layer so that\nthe recurrent unit simultaneously receives history informa-\ntion from the last time step and neighborhood information\nfrom graph convolution. The modiﬁed GRU in DCRNN is\nnamed as the diffusion convolutional gated recurrent Unit\n(DCGRU),\nr(t) = sigmoid(Θr ⋆G [X(t), H(t−1)] + br)\nu(t) = sigmoid(Θu ⋆G [X(t), H(t−1)] + bu)\nC(t) = tanh(ΘC ⋆G [X(t), (r(t) ⊙H(t−1))] + br)\nH(t) = u(t) ⊙H(t−1) + (1 −u(t)) ⊙C(t)\n(36)\nTo meet the demands of multi-step forecasting, DCGRN\nadopts sequence-to-sequence architecture [92] where the\nrecurrent unit is replaced by DCGRU.\nCNN-GCN [71] interleaves 1D-CNN with GCN [14] to\nlearn spatial-temporal graph data. For an input tensor\nX ∈RT ×N×D, the 1D-CNN layer slides over X[:,i,:] along\nthe time axis to aggregate temporal information for each\nnode while the GCN layer operates on X[i,:,:] to aggregate\nspatial information at each time step. The output layer is a\nlinear transformation, generating a prediction for each node.\nThe framework of CNN-GCN is depicted in Fig 5c.\nSpatial Temporal GCN (ST-GCN) [72] adopts a different\napproach by extending the temporal ﬂow as graph edges so\nthat spatial and temporal information can be extracted using\na uniﬁed GCN model at the same time. ST-GCN deﬁnes\na labelling function to assign a label to each edge of the\ngraph according to the distance of the two related nodes.\nIn this way, the adjacency matrix can be represented as a\nsummation of K adjacency matrices where K is the number\nof labels. Then ST-GCN applies GCN [14] with a different\nweight matrix to each of the K adjacency matrix and sums\nthem.\nfout =\nX\nj\nΛ\n−1\n2\nj\nAjΛ\n−1\n2\nj\nfinWj\n(37)\n5.4.2\nMiscellaneous Variants\nStructural-RNN. Jain et al. [73] propose a recurrent struc-\ntured framework named Structural-RNN. The aim of\nStructural-RNN is to predict node labels at each time step. In\nStructural-RNN, it comprises of two kinds of RNNs, namely\nnodeRNN and edgeRNN. The temporal information of each\nnode and each edge is passed through a nodeRNN and\nan edgeRNN respectively. Since assuming different RNNs\nfor different nodes and edges increases model complex-\nity dramantically, they instead split nodes and edges into\nsemantic groups. For example, a human-object interaction\ngraph consists of two groups of nodes, human nodes and\nobject nodes, and three groups of edges, human-human\nedges, object-object edges, and human-object edges. Nodes\nor edges in a same semantic group share the same RNN\nmodel. To incorporate the spatial information, a nodeRNN\nwill take the outputs of edgeRNNs as inputs.\n5.4.3\nSummary\nThe advantage of DCRNN is that it is able to handle long-\nterm dependencies because of the recurrent network archi-\ntectures. Though simpler than DCRNN, CNN-GCN pro-\ncesses spatial-temporal graphs more efﬁciently owing to the\nfast implementation of 1D CNN. ST-GCN considers tempo-\nral ﬂow as graph edges, resulting in the size of the adjacency\nmatrix growing quadratically. On the one hand, it increases\nthe computation cost of the graph convolution layer. On the\nother hand, to capture the long-term dependency, the graph\nconvolution layer has to be stacked many times. Structural-\nRNN improves model efﬁciency by sharing the same RNN\nwithin the same semantic group. However, Structural-RNN\ndemands human prior knowledge to split the semantic\ngroups.\n6\nAPPLICATIONS\nGraph neural networks have a wide variety of applications.\nIn this section, we ﬁrst summarize the benchmark datasets\nfrequently used in the literature. Then we report the bench-\nmark performance on four commonly used datasets and\nlist the available open source implementations of graph\nneural networks. Finally, we provide practical applications\nof graph neural networks in various domains.\n6.1\nDatasets\nIn our survey, we count the frequency of each dataset which\noccurs in the papers reviewed in this work, and report in\nTable 5 the datasets which occur at least twice.\nCitation Networks consist of papers, authors and their\nrelationship such as citation, authorship, co-authorship. Al-\nthough citation networks are directed graphs, they are often\ntreated as undirected graphs in evaluating model perfor-\nmance with respect to node classiﬁcation, link prediction,\nand node clustering tasks. There are three popular datasets\nfor paper-citation networks, Cora, Citeseer and Pubmed.\nThe Cora dataset contains 2708 machine learning publi-\ncations grouped into seven classes. The Citeseer dataset\ncontains 3327 scientiﬁc papers grouped into six classes.\nEach paper in Cora and Citeseer is repesented by a one-hot\nvector indicating the presence or absence of a word from\na dictionary. The Pubmed dataset contains 19717 diabetes-\nrelated publications. Each paper in Pubmed is represented\nby a term frequency-inverse document frequency (TF-IDF)\nvector. Furthermore, DBLP is a large citation dataset with\nmillions of papers and authors which have been collected\nfrom computer science bibliographies. The raw dataset of\n",
    "book_id": "a_comprehensive_survey_on_graph_neural_net",
    "book_title": "A Comprehensive Survey on Graph Neural Net",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 14
  },
  {
    "chunk_full": "JOURNAL OF LATEX CLASS FILES, VOL. X, NO. X, DECEMBER 2018\n16\nDBLP can be found on https://dblp.uni-trier.de. A pro-\ncessed version of the DBLP paper-citation network is up-\ndated continuously by https://aminer.org/citation.\nSocial Networks are formed by user interactions from\nonline services such as BlogCatalog, Reddit, and Epinions.\nThe BlogCatalog dataset is a social network which con-\nsists of bloggers and their social relationships. The labels\nof bloggers represent their personal interests. The Reddit\ndataset is an undirected graph formed by posts collected\nfrom the Reddit discussion forum. Two posts are linked if\nthey contain comments by the same user. Each post has a\nlabel indicating the community to which it belongs. The\nEpinions dataset is a multi-relation graph collected from an\nonline product review website where commenters can have\nmore than one type of relation, such as trust, distrust, co-\nreview, and co-rating.\nChemical/Biological Graphs Chemical molecules and com-\npounds can be represented by chemical graphs with atoms\nas nodes and chemical bonds as edges. This category of\ngraphs is often used to evaluate graph classiﬁcation perfor-\nmance. The NCI-1 and NCI-9 dataset contains 4100 and 4127\nchemical compounds respectively, labeled as to whether\nthey are active to hinder the growth of human cancer cell\nlines. The MUTAG dataset contains 188 nitro compounds,\nlabeled as to whether they are aromatic or heteroaromatic.\nThe D&D dataset contains 1178 protein structures, labeled\nas to whether they are enzymes or non-enzymes. The QM9\ndataset contains 133885 molecules labeled with 13 chemical\nproperties. The Tox21 dataset contains 12707 chemical com-\npounds labeled with 12 types of toxicity. Another important\ndataset is the Protein-Protein Interaction network(PPI). It\ncontains 24 biological graphs with nodes represented by\nproteins and edges represented by the interactions between\nproteins. In PPI, each graph is associated with a human\ntissue. Each node is labeled with its biological states.\nUnstructured Graphs To test the generalization of graph\nneural networks to unstructured data, the k nearest neigh-\nbor graph(k-NN graph) has been widely used. The MNIST\ndataset contains 70000 images of size 28×28 labeled with 10\ndigits. A typical way to convert a MNIST image to a graph\nis to construct a 8-NN graph based on its pixel locations.\nThe Wikipedia dataset is a word co-occurence network ex-\ntracted from the ﬁrst million bytes of the Wikipedia dump.\nLabels of words represent part-of-speech (POS) tags. The 20-\nNewsGroup dataset consists of around 20,000 News Group\n(NG) text documents categorized by 20 news types. The\ngraph of the 20-NewsGroup is constructed by representing\neach document as a node and using the similarities between\nnodes as edge weights.\nOthers There are several other datasets worth mentioning.\nThe METR-LA is a trafﬁc dataset collected from the high-\nways of Los Angeles County. The MovieLens-1M dataset\nfrom the MovieLens website contains 1 million item rat-\nings given by 6k users. It is a benchmark dataset for\nrecommender systems. The NELL dataset is a knowledge\ngraph obtained from the Never-Ending Language Learning\nproject. It consist of facts represented by a triplet which\ninvolves two entities and their relation.\n6.2\nBenchmarks & Open-source Implementations\nOf the datasets listed in Table 5, Cora, Pubmed, Citeseer,\nand PPI are the most frequently used datasets. They are\noften tested to compare the performance of graph convo-\nlution networks in node classiﬁcation tasks. In Table 6, we\nreport the benchmark performance of these four datasets,\nall of which use standard data splits. Open-source imple-\nmentations facilitate the work of baseline experiments in\ndeep learning research. Due to the vast number of hyper-\nparameters, it is difﬁcult to achieve the same results as\nreported in the literature without using published codes.\nIn Table 7, we provide the hyperlinks of open-source imple-\nmentations of the graph neural network models reviewed in\nSection 4-5. Noticeably, Fey et al. [86] published a geometric\nlearning library in PyTorch named PyTorch Geometric 3,\nwhich implements serveral graph neural networks includ-\ning ChebNet [12], 1stChebNet [14], GraphSage [24], MPNNs\n[13], GAT [15] and SplineCNN [86]. Most recently, the Deep\nGraph Library (DGL) 4 is released which provides a fast\nimplementation of many graph neural networks with a set\nof functions on top of popular deep learning platforms such\nas PyTorch and MXNet.\n6.3\nPractical Applications\nGraph neural networks have a wide range of applications\nacross different tasks and domains. Despite general tasks at\nwhich each category of GNNs is specialized, including node\nclassiﬁcation, node representation learning, graph classiﬁ-\ncation, graph generation, and spatial-temporal forecasting,\nGNNs can also be applied to node clustering, link predic-\ntion [119], and graph partition [120]. In this section, we\nmainly introduce practical applications according to general\ndomains to which they belong.\nComputer Vision One of biggest application areas for graph\nneural networks is computer vision. Researchers have ex-\nplored leveraging graph structures in scene graph gener-\nation, point clouds classiﬁcation and segmentation, action\nrecognition and many other directions.\nIn scene graph generation, semantic relationships be-\ntween objects facilitate the understanding of the semantic\nmeaning behind a visual scene. Given an image, scene\ngraph generation models detect and recognize objects and\npredict semantic relationships between pairs of objects [121],\n[122], [123]. Another application inverses the process by\ngenerating realistic images given scene graphs [124]. As\nnatural language can be parsed as semantic graphs where\neach word represents an object, it is a promising solution to\nsynthesize images given textual descriptions.\nIn point clouds classiﬁcation and segmentation, a point\ncloud is a set of 3D points recorded by LiDAR scans.\nSolutions for this task enable LiDAR devices to see the\nsurrounding environment, which is typically beneﬁcial for\nunmanned vehicles. To identify objects depicted by point\nclouds, [125], [126], [127] convert point clouds into k-nearest\nneighbor graphs or superpoint graphs, and use graph con-\nvolution networks to explore the topological structure.\n3. https://github.com/rusty1s/pytorch geometric\n4. https://www.dgl.ai/\n",
    "book_id": "a_comprehensive_survey_on_graph_neural_net",
    "book_title": "A Comprehensive Survey on Graph Neural Net",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 15
  },
  {
    "chunk_full": "JOURNAL OF LATEX CLASS FILES, VOL. X, NO. X, DECEMBER 2018\n17\nTABLE 5: Summary of Commonly Used Datasets\nCategory\nDataset\nSource\n# Graphs\n# Nodes\n# Edges\n#Features\n# Labels\nCitation\nCitation\nNetworks\nCora\n[103]\n1\n2708\n5429\n1433\n7\n[14], [15], [23], [27], [45]\n[44], [46], [49], [58], [59]\n[61], [104]\nCiteseer\n[103]\n1\n3327\n4732\n3703\n6\n[14], [15], [27], [46], [49]\n[58], [59], [61]\nPubmed\n[103]\n1\n19717\n44338\n500\n3\n[14], [15], [27], [44], [45]\n[48], [49], [59], [61], [67]\nDBLP\ndblp.uni-trier.de\n[105](aminer.org\n/citation)\n1\n-\n-\n-\n-\n[62], [67], [104], [106]\nSocial\nNetworks\nBlogCatalog\n[107]\n1\n10312\n333983\n-\n39\n[42], [48], [62], [108]\nReddit\n[24]\n1\n232965\n11606919\n602\n41\n[24], [28], [45], [46]\nEpinions\nwww.epinions.com\n1\n-\n-\n-\n-\n[50], [106]\nChemical/\nBiological\nGraphs\nPPI\n[109]\n24\n56944\n818716\n50\n121\n[15], [19], [24], [27], [28]\n[46], [48], [62]\nNCI-1\n[110]\n4100\n-\n-\n37\n2\n[26], [44], [47], [52], [57]\nNCI-109\n[110]\n4127\n-\n-\n38\n2\n[26], [44], [52]\nMUTAG\n[111]\n188\n-\n-\n7\n2\n[26], [44], [52]\nD&D\n[112]\n1178\n-\n-\n-\n2\n[26], [47], [52]\nQM9\n[113]\n133885\n-\n-\n-\n13\n[13], [66]\ntox21\ntripod.nih.gov/\ntox21/challenge/\n12707\n-\n-\n-\n12\n[22], [53]\nUnstruct-\nured\nGraphs\nMNIST\nyann.lecun.com\n/exdb/mnist/\n70000\n-\n-\n-\n10\n[12], [20], [23], [52]\nWikipedia\nwww.mattmahoney\n.net/dc/textdata\n1\n4777\n184812\n-\n40\n[62], [108]\n20NEWS\n[114]\n1\n18846\n-\n-\n20\n[12], [41]\nOthers\nMETR-LA\n[115]\n-\n-\n-\n-\n-\n[28], [70]\nMovie-Lens1M\n[116]\ngrouplens.org/\ndatasets/\nmovielens/1m/\n1\n10000\n1 Million\n-\n-\n[23], [108]\nNell\n[117]\n1\n65755\n266144\n61278\n210\n[14], [46], [49]\nTABLE 6: Benchmark performance of four most frequently\nused datasets. The listed methods use the same training,\nvalidation, and test data for evaluation.\nMethod\nCora\nCiteseer\nPubmed\nPPI\n1stChebnet (2016) [14]\n81.5\n70.3\n79.0\n-\nGraphSage (2017) [24]\n-\n-\n-\n61.2\nGAT (2017) [15]\n83.0±0.7\n72.5±0.7\n79.0±0.3\n97.3±0.2\nCayleynets (2017) [23]\n81.9±0.7\n-\n-\n-\nStoGCN (2018) [46]\n82.0±0.8\n70.9±0.2\n79±0.4\n97.9+.04\nDualGCN (2018) [49]\n83.5\n72.6\n80.0\n-\nGAAN (2018) [28]\n-\n-\n-\n98.71±0.02\nGraphInfoMax (2018) [118]\n82.3±0.6\n71.8±0.7\n76.8±0.6\n63.8±0.2\nGeniePath (2018) [48]\n-\n-\n78.5\n97.9\nLGCN (2018) [27]\n83.3±0.5\n73.0±0.6\n79.5±0.2\n77.2±0.2\nSSE (2018) [19]\n-\n-\n-\n83.6\nIn action recognition, recognizing human actions con-\ntained in videos facilitates a better understanding of video\ncontent from a machine aspect. One group of solutions\ndetects the locations of human joints in video clips. Human\njoints which are linked by skeletons naturally form a graph.\nGiven the time series of human joint locations, [72], [73]\napplies spatial-temporal neural networks to learn human\naction patterns.\nIn addition, the number of possible directions in which\nto apply graph neural networks in computer vision is still\ngrowing. This includes few-shot image classiﬁcation [128],\n[129], semantic segmentation [130], [131], visual reasoning\n[132] and question answering [133].\nRecommender Systems Graph-based recommender sys-\ntems take items and users as nodes. By leveraging the\nrelations between items and items, users and users, users\nand items, as well as content information, graph-based\nrecommender systems are able to produce high-quality\nrecommendations. The key to a recommender system is to\nscore the importance of an item to an user. As a result,\nit can be cast as a link prediction problem. The goal is\nto predict the missing links between users and items. To\naddress this problem, Van et al. [9] and Ying et al. [11] et al.\npropose a GCN-based graph auto-encoder. Monti et al. [10]\ncombine GCN and RNN to learn the underlying process that\ngenerates the known ratings.\nTrafﬁc Trafﬁc congestion has become a hot social issue in\nmodern cities. Accurately forecasting trafﬁc speed, volume\nor the density of roads in trafﬁc networks is fundamentally\nimportant in route planning and ﬂow control. [28], [70], [71],\n[134] adopt a graph-based approach with spatial-temporal\nneural networks. The input to their models is a spatial-\ntemporal graph. In this spatial-temporal graph, nodes are\nrepresented by sensors placed on roads, edges are repre-\nsented by the distance of pair-wise nodes above a threshold\nand each node contains a time series as features. The goal\nis to forecast the average speed of a road within a time\ninterval. Another interesting application is taxi-demand pre-\ndiction. This greatly helps intelligent transportation systems\nmake use of resources and save energy effectively. Given\nhistorical taxi demands, location information, weather data,\nand event features, Yao et al. [135] incorporate LSTM, CNN\nand node embeddings trained by LINE [136] to form a joint\nrepresentation for each location to predict the number of\ntaxis demanded for a location within a time interval.\nChemistry In chemistry, researchers apply graph neural\n",
    "book_id": "a_comprehensive_survey_on_graph_neural_net",
    "book_title": "A Comprehensive Survey on Graph Neural Net",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 16
  },
  {
    "chunk_full": "JOURNAL OF LATEX CLASS FILES, VOL. X, NO. X, DECEMBER 2018\n18\nTABLE 7: A Summary of Open-source Implementations\nModel\nFramework\nGithub Link\nChebNet (2016) [12]\ntensorﬂow\nhttps://github.com/mdeff/cnn graph\n1stChebNet (2017) [14]\ntensorﬂow\nhttps://github.com/tkipf/gcn\nGGNNs (2015) [18]\nlua\nhttps://github.com/yujiali/ggnn\nSSE (2018) [19]\nc\nhttps://github.com/Hanjun-Dai/steady state embedding\nGraphSage (2017) [24]\ntensorﬂow\nhttps://github.com/williamleif/GraphSAGE\nLGCN (2018) [27]\ntensorﬂow\nhttps://github.com/divelab/lgcn/\nSplineCNN (2018) [86]\npytorch\nhttps://github.com/rusty1s/pytorch geometric\nGAT (2017) [15]\ntensorﬂow\nhttps://github.com/PetarV-/GAT\nGAE (2016) [59]\ntensorﬂow\nhttps://github.com/limaosen0/Variational-Graph-Auto-Encoders\nARGA (2018) [61]\ntensorﬂow\nhttps://github.com/Ruiqi-Hu/ARGA\nDNGR (2016) [41]\nmatlab\nhttps://github.com/ShelsonCao/DNGR\nSDNE (2016) [42]\npython\nhttps://github.com/suanrong/SDNE\nDRNE (2016) [63]\ntensorﬂow\nhttps://github.com/tadpole/DRNE\nGraphRNN (2018) [64]\ntensorﬂow\nhttps://github.com/snap-stanford/GraphRNN\nDCRNN (2018) [70]\ntensorﬂow\nhttps://github.com/liyaguang/DCRNN\nCNN-GCN (2017) [71]\ntensorﬂow\nhttps://github.com/VeritasYin/STGCN IJCAI-18\nST-GCN (2018) [72]\npytorch\nhttps://github.com/yysijie/st-gcn\nStructural RNN (2016) [73]\ntheano\nhttps://github.com/asheshjain399/RNNexp\nnetworks to study the graph strcutures of molecules. In\na molecular graph, atoms function as nodes and chem-\nical bonds function as edges. Node classiﬁcation, graph\nclassiﬁcation and graph generation are three main tasks\ntargeting at molecular graphs in order to learn molecular\nﬁngerprints [53], [80], to predict molecular properties [13],\nto infer protein interfaces [137], and to synthesize chemical\ncompounds [65], [66], [138].\nOthers There have been initial explorations into applying\nGNNs to other problems such as program veriﬁcation [18],\nprogram reasoning [139], social inﬂuence prediction [140],\nadversarial attacks prevention [141], electrical health records\nmodeling [142], [143], event detection [144] and combinato-\nrial optimization [145].\n7\nFUTURE DIRECTIONS\nThough graph neural networks have proven their power\nin learning graph data, challenges still exist due to the\ncomplexity of graphs. In this section, we provide four future\ndirections of graph neural networks.\nGo Deep The success of deep learning lies in deep neu-\nral architectures. In image classiﬁcation, for example, an\noutstanding model named ResNet [146] has 152 layers.\nHowever, when it comes to graphs, experimental studies\nhave shown that with the increase in the number of layers,\nthe model performance drops dramatically [147]. According\nto [147], this is due to the effect of graph convolutions in\nthat it essentially pushes representations of adjacent nodes\ncloser to each other so that, in theory, with an inﬁnite times\nof convolutions, all nodes’ representations will converge to a\nsingle point. This raises the question of whether going deep\nis still a good strategy for learning graph-structured data.\nReceptive Field The receptive ﬁeld of a node refers to a\nset of nodes including the central node and its neighbors.\nThe number of neighbors of a node follows a power law\ndistribution. Some nodes may only have one neighbor,\nwhile other nodes may neighbors as many as thousands.\nThough sampling strategies have been adopted [24], [26],\n[27], how to select a representative receptive ﬁeld of a node\nremains to be explored.\nScalability Most graph neural networks do not scale well\nfor large graphs. The main reason for this is when stacking\nmultiple layers of a graph convolution, a node’s ﬁnal state\ninvolves a large number of its neighbors’ hidden states,\nleading to high complexity of backpropagation. While sev-\neral approaches try to improve their model efﬁciency by fast\nsampling [45], [46] and sub-graph training [24], [27], they are\nstill not scalable enough to handle deep architectures with\nlarge graphs.\nDynamics and Heterogeneity The majority of current graph\nneural networks tackle with static homogeneous graphs. On\nthe one hand, graph structures are assumed to be ﬁxed.\nOn the other hand, nodes and edges from a graph are\nassumed to come from a single source. However, these two\nassumptions are not realistic in many scenarios. In a social\nnetwork, a new person may enter into a network at any time\nand an existing person may quit the network as well. In\na recommender system, products may have different types\nwhere their inputs may have different forms such as texts\nor images. Therefore, new methods should be developed to\nhandle dynamic and heterogeneous graph structures.\n8\nCONCLUSION\nIn this survey, we conduct a comprehensive overview of\ngraph neural networks. We provide a taxonomy which\ngroups graph neural networks into ﬁve categories: graph\nconvolutional networks, graph attention networks, graph\nautoencoders and graph generative networks. We provide\na thorough review, comparisons, and summarizations of the\nmethods within or between categories. Then we introduce\na wide range of applications of graph neural networks.\nDatasets, open source codes, and benchmarks for graph\nneural networks are summarized. Finally, we suggest four\nfuture directions for graph neural networks.\nACKNOWLEDGMENT\nThis research was funded by the Australian Government\nthrough the Australian Research Council (ARC) under\ngrants 1) LP160100630 partnership with Australia Govern-\nment Department of Health and 2) LP150100671 partnership\n",
    "book_id": "a_comprehensive_survey_on_graph_neural_net",
    "book_title": "A Comprehensive Survey on Graph Neural Net",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 17
  },
  {
    "chunk_full": "JOURNAL OF LATEX CLASS FILES, VOL. X, NO. X, DECEMBER 2018\n19\nwith Australia Research Alliance for Children and Youth\n(ARACY) and Global Business College Australia (GBCA).\nWe acknowledge the support of NVIDIA Corporation and\nMakeMagic Australia with the donation of GPU used for\nthis research.\nREFERENCES\n[1]\nJ. Redmon, S. Divvala, R. Girshick, and A. Farhadi, “You only\nlook once: Uniﬁed, real-time object detection,” in Proceedings of\nthe IEEE conference on computer vision and pattern recognition, 2016,\npp. 779–788.\n[2]\nS. Ren, K. He, R. Girshick, and J. Sun, “Faster r-cnn: Towards\nreal-time object detection with region proposal networks,” in\nAdvances in neural information processing systems, 2015, pp. 91–99.\n[3]\nM.-T. Luong, H. Pham, and C. D. Manning, “Effective approaches\nto attention-based neural machine translation,” in Proceedings of\nthe Conference on Empirical Methods in Natural Language Processing,\n2015, pp. 1412–1421.\n[4]\nY. Wu, M. Schuster, Z. Chen, Q. V. Le, M. Norouzi, W. Macherey,\nM. Krikun, Y. Cao, Q. Gao, K. Macherey et al., “Google’s neural\nmachine translation system: Bridging the gap between human\nand machine translation,” arXiv preprint arXiv:1609.08144, 2016.\n[5]\nG. Hinton, L. Deng, D. Yu, G. E. Dahl, A.-r. Mohamed, N. Jaitly,\nA. Senior, V. Vanhoucke, P. Nguyen, T. N. Sainath et al., “Deep\nneural networks for acoustic modeling in speech recognition:\nThe shared views of four research groups,” IEEE Signal processing\nmagazine, vol. 29, no. 6, pp. 82–97, 2012.\n[6]\nY. LeCun, Y. Bengio et al., “Convolutional networks for images,\nspeech, and time series,” The handbook of brain theory and neural\nnetworks, vol. 3361, no. 10, p. 1995, 1995.\n[7]\nS. Hochreiter and J. Schmidhuber, “Long short-term memory,”\nNeural computation, vol. 9, no. 8, pp. 1735–1780, 1997.\n[8]\nM. M. Bronstein, J. Bruna, Y. LeCun, A. Szlam, and P. Van-\ndergheynst, “Geometric deep learning: going beyond euclidean\ndata,” IEEE Signal Processing Magazine, vol. 34, no. 4, pp. 18–42,\n2017.\n[9]\nR. van den Berg, T. N. Kipf, and M. Welling, “Graph convolu-\ntional matrix completion,” stat, vol. 1050, p. 7, 2017.\n[10]\nF. Monti, M. Bronstein, and X. Bresson, “Geometric matrix com-\npletion with recurrent multi-graph neural networks,” in Advances\nin Neural Information Processing Systems, 2017, pp. 3697–3707.\n[11]\nR. Ying, R. He, K. Chen, P. Eksombatchai, W. L. Hamilton, and\nJ. Leskovec, “Graph convolutional neural networks for web-\nscale recommender systems,” in Proceedings of the ACM SIGKDD\nInternational Conference on Knowledge Discovery and Data Mining.\nACM, 2018, pp. 974–983.\n[12]\nM. Defferrard, X. Bresson, and P. Vandergheynst, “Convolutional\nneural networks on graphs with fast localized spectral ﬁltering,”\nin Advances in Neural Information Processing Systems, 2016, pp.\n3844–3852.\n[13]\nJ. Gilmer, S. S. Schoenholz, P. F. Riley, O. Vinyals, and G. E. Dahl,\n“Neural message passing for quantum chemistry,” in Proceedings\nof the International Conference on Machine Learning, 2017, pp. 1263–\n1272.\n[14]\nT. N. Kipf and M. Welling, “Semi-supervised classiﬁcation with\ngraph convolutional networks,” in Proceedings of the International\nConference on Learning Representations, 2017.\n[15]\nP. Velickovic, G. Cucurull, A. Casanova, A. Romero, P. Lio,\nand Y. Bengio, “Graph attention networks,” in Proceedings of the\nInternational Conference on Learning Representations, 2017.\n[16]\nM. Gori, G. Monfardini, and F. Scarselli, “A new model for\nlearning in graph domains,” in Proceedings of the International Joint\nConference on Neural Networks, vol. 2.\nIEEE, 2005, pp. 729–734.\n[17]\nF. Scarselli, M. Gori, A. C. Tsoi, M. Hagenbuchner, and G. Mon-\nfardini, “The graph neural network model,” IEEE Transactions on\nNeural Networks, vol. 20, no. 1, pp. 61–80, 2009.\n[18]\nY. Li, D. Tarlow, M. Brockschmidt, and R. Zemel, “Gated graph\nsequence neural networks,” in Proceedings of the International\nConference on Learning Representations, 2015.\n[19]\nH. Dai, Z. Kozareva, B. Dai, A. Smola, and L. Song, “Learning\nsteady-states of iterative algorithms over graphs,” in Proceedings\nof the International Conference on Machine Learning, 2018, pp. 1114–\n1122.\n[20]\nJ. Bruna, W. Zaremba, A. Szlam, and Y. LeCun, “Spectral net-\nworks and locally connected networks on graphs,” in Proceedings\nof International Conference on Learning Representations, 2014.\n[21]\nM. Henaff, J. Bruna, and Y. LeCun, “Deep convolutional networks\non graph-structured data,” arXiv preprint arXiv:1506.05163, 2015.\n[22]\nR. Li, S. Wang, F. Zhu, and J. Huang, “Adaptive graph convolu-\ntional neural networks,” in Proceedings of the AAAI Conference on\nArtiﬁcial Intelligence, 2018, pp. 3546–3553.\n[23]\nR. Levie, F. Monti, X. Bresson, and M. M. Bronstein, “Cayleynets:\nGraph convolutional neural networks with complex rational\nspectral ﬁlters,” arXiv preprint arXiv:1705.07664, 2017.\n[24]\nW. Hamilton, Z. Ying, and J. Leskovec, “Inductive representation\nlearning on large graphs,” in Advances in Neural Information\nProcessing Systems, 2017, pp. 1024–1034.\n[25]\nF. Monti, D. Boscaini, J. Masci, E. Rodola, J. Svoboda, and M. M.\nBronstein, “Geometric deep learning on graphs and manifolds\nusing mixture model cnns,” in Proceedings of the IEEE Conference\non Computer Vision and Pattern Recognition, vol. 1, no. 2, 2017, p. 3.\n[26]\nM. Niepert, M. Ahmed, and K. Kutzkov, “Learning convolutional\nneural networks for graphs,” in Proceedings of the International\nConference on Machine Learning, 2016, pp. 2014–2023.\n[27]\nH. Gao, Z. Wang, and S. Ji, “Large-scale learnable graph convolu-\ntional networks,” in Proceedings of the ACM SIGKDD International\nConference on Knowledge Discovery & Data Mining.\nACM, 2018,\npp. 1416–1424.\n[28]\nJ. Zhang, X. Shi, J. Xie, H. Ma, I. King, and D.-Y. Yeung, “Gaan:\nGated attention networks for learning on large and spatiotem-\nporal graphs,” in Proceedings of the Uncertainty in Artiﬁcial Intelli-\ngence, 2018.\n[29]\nP. W. Battaglia, J. B. Hamrick, V. Bapst, A. Sanchez-Gonzalez,\nV. Zambaldi, M. Malinowski, A. Tacchetti, D. Raposo, A. Santoro,\nR. Faulkner et al., “Relational inductive biases, deep learning, and\ngraph networks,” arXiv preprint arXiv:1806.01261, 2018.\n[30]\nJ. B. Lee, R. A. Rossi, S. Kim, N. K. Ahmed, and E. Koh, “Attention\nmodels in graphs: A survey,” arXiv preprint arXiv:1807.07984,\n2018.\n[31]\nZ. Zhang, P. Cui, and W. Zhu, “Deep learning on graphs: A\nsurvey,” arXiv preprint arXiv:1812.04202, 2018.\n[32]\nP. Cui, X. Wang, J. Pei, and W. Zhu, “A survey on network em-\nbedding,” IEEE Transactions on Knowledge and Data Engineering,\n2017.\n[33]\nW. L. Hamilton, R. Ying, and J. Leskovec, “Representation learn-\ning on graphs: Methods and applications,” in Advances in Neural\nInformation Processing Systems, 2017, pp. 1024–1034.\n[34]\nD. Zhang, J. Yin, X. Zhu, and C. Zhang, “Network representation\nlearning: A survey,” IEEE Transactions on Big Data, 2018.\n[35]\nH. Cai, V. W. Zheng, and K. Chang, “A comprehensive survey of\ngraph embedding: problems, techniques and applications,” IEEE\nTransactions on Knowledge and Data Engineering, 2018.\n[36]\nP. Goyal and E. Ferrara, “Graph embedding techniques, applica-\ntions, and performance: A survey,” Knowledge-Based Systems, vol.\n151, pp. 78–94, 2018.\n[37]\nS. Pan, J. Wu, X. Zhu, C. Zhang, and Y. Wang, “Tri-party deep\nnetwork representation,” in Proceedings of the International Joint\nConference on Artiﬁcial Intelligence.\nAAAI Press, 2016, pp. 1895–\n1901.\n[38]\nX. Shen, S. Pan, W. Liu, Y.-S. Ong, and Q.-S. Sun, “Discrete\nnetwork embedding,” in Proceedings of the International Joint Con-\nference on Artiﬁcial Intelligence, 7 2018, pp. 3549–3555.\n[39]\nH. Yang, S. Pan, P. Zhang, L. Chen, D. Lian, and C. Zhang,\n“Binarized attributed network embedding,” in IEEE International\nConference on Data Mining.\nIEEE, 2018.\n[40]\nB. Perozzi, R. Al-Rfou, and S. Skiena, “Deepwalk: Online learning\nof social representations,” in Proceedings of the ACM SIGKDD\ninternational conference on Knowledge discovery and data mining.\nACM, 2014, pp. 701–710.\n[41]\nS. Cao, W. Lu, and Q. Xu, “Deep neural networks for learning\ngraph representations,” in Proceedings of the AAAI Conference on\nArtiﬁcial Intelligence, 2016, pp. 1145–1152.\n[42]\nD. Wang, P. Cui, and W. Zhu, “Structural deep network embed-\nding,” in Proceedings of the ACM SIGKDD International Conference\non Knowledge Discovery and Data Mining.\nACM, 2016, pp. 1225–\n1234.\n[43]\nA. Susnjara, N. Perraudin, D. Kressner, and P. Vandergheynst,\n“Accelerated ﬁltering on graphs using lanczos method,” arXiv\npreprint arXiv:1509.04537, 2015.\n[44]\nJ. Atwood and D. Towsley, “Diffusion-convolutional neural net-\nworks,” in Advances in Neural Information Processing Systems, 2016,\npp. 1993–2001.\n",
    "book_id": "a_comprehensive_survey_on_graph_neural_net",
    "book_title": "A Comprehensive Survey on Graph Neural Net",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 18
  },
  {
    "chunk_full": "JOURNAL OF LATEX CLASS FILES, VOL. X, NO. X, DECEMBER 2018\n20\n[45]\nJ. Chen, T. Ma, and C. Xiao, “Fastgcn: fast learning with graph\nconvolutional networks via importance sampling,” in Proceedings\nof the International Conference on Learning Representations, 2018.\n[46]\nJ. Chen, J. Zhu, and L. Song, “Stochastic training of graph\nconvolutional networks with variance reduction,” in Proceedings\nof the International Conference on Machine Learning, 2018, pp. 941–\n949.\n[47]\nF. P. Such, S. Sah, M. A. Dominguez, S. Pillai, C. Zhang,\nA. Michael, N. D. Cahill, and R. Ptucha, “Robust spatial ﬁlter-\ning with graph convolutional neural networks,” IEEE Journal of\nSelected Topics in Signal Processing, vol. 11, no. 6, pp. 884–896, 2017.\n[48]\nZ. Liu, C. Chen, L. Li, J. Zhou, X. Li, and L. Song, “Geniepath:\nGraph neural networks with adaptive receptive paths,” arXiv\npreprint arXiv:1802.00910, 2018.\n[49]\nC. Zhuang and Q. Ma, “Dual graph convolutional networks for\ngraph-based semi-supervised classiﬁcation,” in Proceedings of the\nWorld Wide Web Conference on World Wide Web.\nInternational\nWorld Wide Web Conferences Steering Committee, 2018, pp. 499–\n508.\n[50]\nT. Derr, Y. Ma, and J. Tang, “Signed graph convolutional net-\nwork,” arXiv preprint arXiv:1808.06354, 2018.\n[51]\nT. Pham, T. Tran, D. Q. Phung, and S. Venkatesh, “Column\nnetworks for collective classiﬁcation,” in Proceedings of the AAAI\nConference on Artiﬁcial Intelligence, 2017, pp. 2485–2491.\n[52]\nM. Simonovsky and N. Komodakis, “Dynamic edgeconditioned\nﬁlters in convolutional neural networks on graphs,” in Proceed-\nings of the IEEE conference on computer vision and pattern recognition,\n2017.\n[53]\nS. Kearnes, K. McCloskey, M. Berndl, V. Pande, and P. Riley,\n“Molecular graph convolutions: moving beyond ﬁngerprints,”\nJournal of computer-aided molecular design, vol. 30, no. 8, pp. 595–\n608, 2016.\n[54]\nW. Huang, T. Zhang, Y. Rong, and J. Huang, “Adaptive sampling\ntowards fast graph representation learning,” in Advances in Neu-\nral Information Processing Systems, 2018, pp. 4563–4572.\n[55]\nM. Zhang, Z. Cui, M. Neumann, and Y. Chen, “An end-to-end\ndeep learning architecture for graph classiﬁcation,” in Proceedings\nof the AAAI Conference on Artiﬁcial Intelligence, 2018.\n[56]\nZ. Ying, J. You, C. Morris, X. Ren, W. Hamilton, and J. Leskovec,\n“Hierarchical graph representation learning with differentiable\npooling,” in Advances in Neural Information Processing Systems,\n2018, pp. 4801–4811.\n[57]\nJ. B. Lee, R. Rossi, and X. Kong, “Graph classiﬁcation using struc-\ntural attention,” in Proceedings of the ACM SIGKDD International\nConference on Knowledge Discovery & Data Mining.\nACM, 2018,\npp. 1666–1674.\n[58]\nS. Abu-El-Haija, B. Perozzi, R. Al-Rfou, and A. A. Alemi, “Watch\nyour step: Learning node embeddings via graph attention,” in\nAdvances in Neural Information Processing Systems, 2018, pp. 9197–\n9207.\n[59]\nT. N. Kipf and M. Welling, “Variational graph auto-encoders,”\narXiv preprint arXiv:1611.07308, 2016.\n[60]\nC. Wang, S. Pan, G. Long, X. Zhu, and J. Jiang, “Mgae: Marginal-\nized graph autoencoder for graph clustering,” in Proceedings of\nthe ACM on Conference on Information and Knowledge Management.\nACM, 2017, pp. 889–898.\n[61]\nS. Pan, R. Hu, G. Long, J. Jiang, L. Yao, and C. Zhang, “Adver-\nsarially regularized graph autoencoder for graph embedding.”\nin Proceedings of the International Joint Conference on Artiﬁcial\nIntelligence, 2018, pp. 2609–2615.\n[62]\nW. Yu, C. Zheng, W. Cheng, C. C. Aggarwal, D. Song, B. Zong,\nH. Chen, and W. Wang, “Learning deep network representations\nwith adversarially regularized autoencoders,” in Proceedings of\nthe ACM SIGKDD International Conference on Knowledge Discovery\n& Data Mining.\nACM, 2018, pp. 2663–2671.\n[63]\nK. Tu, P. Cui, X. Wang, P. S. Yu, and W. Zhu, “Deep recursive\nnetwork embedding with regular equivalence,” in Proceedings of\nthe ACM SIGKDD International Conference on Knowledge Discovery\nand Data Mining.\nACM, 2018, pp. 2357–2366.\n[64]\nJ. You, R. Ying, X. Ren, W. L. Hamilton, and J. Leskovec,\n“Graphrnn: A deep generative model for graphs,” Proceedings of\nInternational Conference on Machine Learning, 2018.\n[65]\nY. Li, O. Vinyals, C. Dyer, R. Pascanu, and P. Battaglia, “Learning\ndeep generative models of graphs,” in Proceedings of the Interna-\ntional Conference on Machine Learning, 2018.\n[66]\nN. De Cao and T. Kipf, “Molgan: An implicit generative model\nfor small molecular graphs,” arXiv preprint arXiv:1805.11973,\n2018.\n[67]\nA. Bojchevski, O. Shchur, D. Z¨ugner, and S. G¨unnemann, “Net-\ngan: Generating graphs via random walks,” in Proceedings of the\nInternational Conference on Machine Learning, 2018.\n[68]\nT. Ma, J. Chen, and C. Xiao, “Constrained generation of semanti-\ncally valid graphs via regularizing variational autoencoders,” in\nAdvances in Neural Information Processing Systems, 2018, pp. 7110–\n7121.\n[69]\nY. Seo, M. Defferrard, P. Vandergheynst, and X. Bresson, “Struc-\ntured sequence modeling with graph convolutional recurrent\nnetworks,” arXiv preprint arXiv:1612.07659, 2016.\n[70]\nY. Li, R. Yu, C. Shahabi, and Y. Liu, “Diffusion convolutional\nrecurrent neural network: Data-driven trafﬁc forecasting,” in\nProceedings of International Conference on Learning Representations,\n2018.\n[71]\nB. Yu, H. Yin, and Z. Zhu, “Spatio-temporal graph convolutional\nnetworks: A deep learning framework for trafﬁc forecasting,”\nin Proceedings of the International Joint Conference on Artiﬁcial\nIntelligence, 2017, pp. 3634–3640.\n[72]\nS. Yan, Y. Xiong, and D. Lin, “Spatial temporal graph con-\nvolutional networks for skeleton-based action recognition,” in\nProceedings of the AAAI Conference on Artiﬁcial Intelligence, 2018.\n[73]\nA. Jain, A. R. Zamir, S. Savarese, and A. Saxena, “Structural-rnn:\nDeep learning on spatio-temporal graphs,” in Proceedings of the\nIEEE Conference on Computer Vision and Pattern Recognition, 2016,\npp. 5308–5317.\n[74]\nS. Pan, J. Wu, X. Zhu, C. Zhang, and P. S. Yu, “Joint structure\nfeature exploration and regularization for multi-task graph clas-\nsiﬁcation,” IEEE Transactions on Knowledge and Data Engineering,\nvol. 28, no. 3, pp. 715–728, 2016.\n[75]\nS. Pan, J. Wu, X. Zhu, G. Long, and C. Zhang, “Task sensitive fea-\nture exploration and learning for multitask graph classiﬁcation,”\nIEEE transactions on cybernetics, vol. 47, no. 3, pp. 744–758, 2017.\n[76]\nD. I. Shuman, S. K. Narang, P. Frossard, A. Ortega, and P. Van-\ndergheynst, “The emerging ﬁeld of signal processing on graphs:\nExtending high-dimensional data analysis to networks and other\nirregular domains,” IEEE Signal Processing Magazine, vol. 30,\nno. 3, pp. 83–98, 2013.\n[77]\nL. B. Almeida, “A learning rule for asynchronous perceptrons\nwith feedback in a combinatorial environment.” in Proceedings of\nthe International Conference on Neural Networks, vol. 2. IEEE, 1987,\npp. 609–618.\n[78]\nF. J. Pineda, “Generalization of back-propagation to recurrent\nneural networks,” Physical review letters, vol. 59, no. 19, p. 2229,\n1987.\n[79]\nK. Cho, B. Van Merri¨enboer, C. Gulcehre, D.\nBahdanau,\nF. Bougares, H. Schwenk, and Y. Bengio, “Learning phrase rep-\nresentations using rnn encoder-decoder for statistical machine\ntranslation,” in Proceedings of the Conference on Empirical Methods\nin Natural Language Processing, 2014, pp. 1724–1734.\n[80]\nD. K. Duvenaud, D. Maclaurin, J. Iparraguirre, R. Bombarell,\nT. Hirzel, A. Aspuru-Guzik, and R. P. Adams, “Convolutional\nnetworks on graphs for learning molecular ﬁngerprints,” in\nAdvances in Neural Information Processing Systems, 2015, pp. 2224–\n2232.\n[81]\nK. T. Sch¨utt, F. Arbabzadah, S. Chmiela, K. R. M¨uller, and\nA. Tkatchenko, “Quantum-chemical insights from deep tensor\nneural networks,” Nature communications, vol. 8, p. 13890, 2017.\n[82]\nB. Weisfeiler and A. Lehman, “A reduction of a graph to a\ncanonical form and an algebra arising during this reduction,”\nNauchno-Technicheskaya Informatsia, vol. 2, no. 9, pp. 12–16, 1968.\n[83]\nB. L. Douglas, “The weisfeiler-lehman method and graph isomor-\nphism testing,” arXiv preprint arXiv:1101.5211, 2011.\n[84]\nJ. Masci, D. Boscaini, M. Bronstein, and P. Vandergheynst,\n“Geodesic convolutional neural networks on riemannian mani-\nfolds,” in Proceedings of the IEEE International Conference on Com-\nputer Vision Workshops, 2015, pp. 37–45.\n[85]\nD. Boscaini, J. Masci, E. Rodol`a, and M. Bronstein, “Learning\nshape correspondence with anisotropic convolutional neural net-\nworks,” in Advances in Neural Information Processing Systems, 2016,\npp. 3189–3197.\n[86]\nM. Fey, J. E. Lenssen, F. Weichert, and H. M¨uller, “Splinecnn: Fast\ngeometric deep learning with continuous b-spline kernels,” in\nProceedings of the IEEE Conference on Computer Vision and Pattern\nRecognition, 2018, pp. 869–877.\n[87]\nS. Pan, J. Wu, and X. Zhu, “Cogboost: Boosting for fast cost-\nsensitive graph classiﬁcation,” IEEE Transactions on Knowledge &\nData Engineering, no. 1, pp. 1–1, 2015.\n",
    "book_id": "a_comprehensive_survey_on_graph_neural_net",
    "book_title": "A Comprehensive Survey on Graph Neural Net",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 19
  },
  {
    "chunk_full": "JOURNAL OF LATEX CLASS FILES, VOL. X, NO. X, DECEMBER 2018\n21\n[88]\nK. Xu, W. Hu, J. Leskovec, and S. Jegelka, “How powerful are\ngraph neural networks,” arXiv preprint arXiv:1810.00826, 2018.\n[89]\nS. Verma and Z.-L. Zhang, “Graph capsule convolutional neural\nnetworks,” arXiv preprint arXiv:1805.08090, 2018.\n[90]\nA. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N.\nGomez, Ł. Kaiser, and I. Polosukhin, “Attention is all you need,”\nin Advances in Neural Information Processing Systems, 2017, pp.\n5998–6008.\n[91]\nI. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-\nFarley, S. Ozair, A. Courville, and Y. Bengio, “Generative adver-\nsarial nets,” in Advances in neural information processing systems,\n2014, pp. 2672–2680.\n[92]\nI. Sutskever, O. Vinyals, and Q. V. Le, “Sequence to sequence\nlearning with neural networks,” in Advances in Neural Information\nProcessing Systems, 2014, pp. 3104–3112.\n[93]\nP. Vincent, H. Larochelle, Y. Bengio, and P.-A. Manzagol, “Ex-\ntracting and composing robust features with denoising autoen-\ncoders,” in Proceedings of the international conference on Machine\nlearning.\nACM, 2008, pp. 1096–1103.\n[94]\nG. L. Guimaraes, B. Sanchez-Lengeling, C. Outeiral, P. L. C.\nFarias, and A. Aspuru-Guzik, “Objective-reinforced generative\nadversarial networks (organ) for sequence generation models,”\narXiv preprint arXiv:1705.10843, 2017.\n[95]\nM. J. Kusner, B. Paige, and J. M. Hern´andez-Lobato, “Grammar\nvariational autoencoder,” arXiv preprint arXiv:1703.01925, 2017.\n[96]\nH. Dai, Y. Tian, B. Dai, S. Skiena, and L. Song, “Syntax-directed\nvariational autoencoder for molecule generation,” in Proceedings\nof the International Conference on Learning Representations, 2018.\n[97]\nR. G´omez-Bombarelli, J. N. Wei, D. Duvenaud, J. M. Hern´andez-\nLobato,\nB.\nS´anchez-Lengeling,\nD.\nSheberla,\nJ.\nAguilera-\nIparraguirre, T. D. Hirzel, R. P. Adams, and A. Aspuru-Guzik,\n“Automatic chemical design using a data-driven continuous\nrepresentation of molecules,” ACS central science, vol. 4, no. 2,\npp. 268–276, 2018.\n[98]\nB. Chen, L. Sun, and X. Han, “Sequence-to-action: End-to-end\nsemantic graph generation for semantic parsing,” in Proceedings of\nthe Annual Meeting of the Association for Computational Linguistics,\n2018, pp. 766–777.\n[99]\nD. D. Johnson, “Learning graphical state transitions,” in Proceed-\nings of the International Conference on Learning Representations, 2016.\n[100] M. Schlichtkrull, T. N. Kipf, P. Bloem, R. van den Berg, I. Titov,\nand M. Welling, “Modeling relational data with graph convolu-\ntional networks,” in European Semantic Web Conference.\nSpringer,\n2018, pp. 593–607.\n[101] I. Gulrajani, F. Ahmed, M. Arjovsky, V. Dumoulin, and A. C.\nCourville, “Improved training of wasserstein gans,” in Advances\nin Neural Information Processing Systems, 2017, pp. 5767–5777.\n[102] M. Arjovsky, S. Chintala, and L. Bottou, “Wasserstein gan,” arXiv\npreprint arXiv:1701.07875, 2017.\n[103] P. Sen, G. Namata, M. Bilgic, L. Getoor, B. Galligher, and T. Eliassi-\nRad, “Collective classiﬁcation in network data,” AI magazine,\nvol. 29, no. 3, p. 93, 2008.\n[104] X. Zhang, Y. Li, D. Shen, and L. Carin, “Diffusion maps for textual\nnetwork embedding,” in Advances in Neural Information Processing\nSystems, 2018.\n[105] J. Tang, J. Zhang, L. Yao, J. Li, L. Zhang, and Z. Su, “Arnetminer:\nextraction and mining of academic social networks,” in Proceed-\nings of the ACM SIGKDD International Conference on Knowledge\nDiscovery and Data Mining.\nACM, 2008, pp. 990–998.\n[106] Y. Ma, S. Wang, C. C. Aggarwal, D. Yin, and J. Tang, “Multi-\ndimensional graph convolutional networks,” arXiv preprint\narXiv:1808.06099, 2018.\n[107] L. Tang and H. Liu, “Relational learning via latent social dimen-\nsions,” in Proceedings of the ACM SIGKDD International Conference\non Knowledge Ciscovery and Data Mining.\nACM, 2009, pp. 817–\n826.\n[108] H. Wang, J. Wang, J. Wang, M. Zhao, W. Zhang, F. Zhang, X. Xie,\nand M. Guo, “Graphgan: Graph representation learning with\ngenerative adversarial nets,” in Proceedings of the AAAI Conference\non Artiﬁcial Intelligence, 2017.\n[109] M. Zitnik and J. Leskovec, “Predicting multicellular function\nthrough multi-layer tissue networks,” Bioinformatics, vol. 33,\nno. 14, pp. i190–i198, 2017.\n[110] N. Wale, I. A. Watson, and G. Karypis, “Comparison of descrip-\ntor spaces for chemical compound retrieval and classiﬁcation,”\nKnowledge and Information Systems, vol. 14, no. 3, pp. 347–375,\n2008.\n[111] A. K. Debnath, R. L. Lopez de Compadre, G. Debnath, A. J.\nShusterman, and C. Hansch, “Structure-activity relationship of\nmutagenic aromatic and heteroaromatic nitro compounds. cor-\nrelation with molecular orbital energies and hydrophobicity,”\nJournal of medicinal chemistry, vol. 34, no. 2, pp. 786–797, 1991.\n[112] P. D. Dobson and A. J. Doig, “Distinguishing enzyme structures\nfrom non-enzymes without alignments,” Journal of molecular biol-\nogy, vol. 330, no. 4, pp. 771–783, 2003.\n[113] R. Ramakrishnan, P. O. Dral, M. Rupp, and O. A. Von Lilien-\nfeld, “Quantum chemistry structures and properties of 134 kilo\nmolecules,” Scientiﬁc data, vol. 1, p. 140022, 2014.\n[114] T. Joachims, “A probabilistic analysis of the rocchio algorithm\nwith tﬁdf for text categorization.” Carnegie-mellon univ pitts-\nburgh pa dept of computer science, Tech. Rep., 1996.\n[115] H. Jagadish, J. Gehrke, A. Labrinidis, Y. Papakonstantinou, J. M.\nPatel, R. Ramakrishnan, and C. Shahabi, “Big data and its tech-\nnical challenges,” Communications of the ACM, vol. 57, no. 7, pp.\n86–94, 2014.\n[116] B. N. Miller, I. Albert, S. K. Lam, J. A. Konstan, and J. Riedl,\n“Movielens unplugged: experiences with an occasionally con-\nnected recommender system,” in Proceedings of the international\nconference on Intelligent user interfaces.\nACM, 2003, pp. 263–266.\n[117] A. Carlson, J. Betteridge, B. Kisiel, B. Settles, E. R. Hruschka Jr,\nand T. M. Mitchell, “Toward an architecture for never-ending\nlanguage learning.” in Proceedings of the AAAI Conference on\nArtiﬁcial Intelligence, 2010, pp. 1306–1313.\n[118] P. Veliˇckovi´c, W. Fedus, W. L. Hamilton, P. Li`o, Y. Ben-\ngio, and R. D. Hjelm, “Deep graph infomax,” arXiv preprint\narXiv:1809.10341, 2018.\n[119] M. Zhang and Y. Chen, “Link prediction based on graph neural\nnetworks,” in Advances in Neural Information Processing Systems,\n2018.\n[120] T. Kawamoto, M. Tsubaki, and T. Obuchi, “Mean-ﬁeld theory\nof graph neural networks in graph partitioning,” in Advances in\nNeural Information Processing Systems, 2018, pp. 4362–4372.\n[121] D. Xu, Y. Zhu, C. B. Choy, and L. Fei-Fei, “Scene graph generation\nby iterative message passing,” in Proceedings of the IEEE Confer-\nence on Computer Vision and Pattern Recognition, vol. 2, 2017.\n[122] J. Yang, J. Lu, S. Lee, D. Batra, and D. Parikh, “Graph r-cnn\nfor scene graph generation,” in European Conference on Computer\nVision.\nSpringer, 2018, pp. 690–706.\n[123] Y. Li, W. Ouyang, B. Zhou, J. Shi, C. Zhang, and X. Wang, “Fac-\ntorizable net: an efﬁcient subgraph-based framework for scene\ngraph generation,” in European Conference on Computer Vision.\nSpringer, 2018, pp. 346–363.\n[124] J. Johnson, A. Gupta, and L. Fei-Fei, “Image generation from\nscene graphs,” arXiv preprint, 2018.\n[125] Y. Wang, Y. Sun, Z. Liu, S. E. Sarma, M. M. Bronstein, and J. M.\nSolomon, “Dynamic graph cnn for learning on point clouds,”\narXiv preprint arXiv:1801.07829, 2018.\n[126] L. Landrieu and M. Simonovsky, “Large-scale point cloud seman-\ntic segmentation with superpoint graphs,” in Proceedings of the\nIEEE Conference on Computer Vision and Pattern Recognition, 2018.\n[127] G. Te, W. Hu, Z. Guo, and A. Zheng, “Rgcnn: Regular-\nized graph cnn for point cloud segmentation,” arXiv preprint\narXiv:1806.02952, 2018.\n[128] V. G. Satorras and J. B. Estrach, “Few-shot learning with graph\nneural networks,” in Proceedings of the International Conference on\nLearning Representations, 2018.\n[129] M. Guo, E. Chou, D.-A. Huang, S. Song, S. Yeung, and L. Fei-\nFei, “Neural graph matching networks for fewshot 3d action\nrecognition,” in European Conference on Computer Vision. Springer,\n2018, pp. 673–689.\n[130] X. Qi, R. Liao, J. Jia, S. Fidler, and R. Urtasun, “3d graph neural\nnetworks for rgbd semantic segmentation,” in Proceedings of the\nIEEE Conference on Computer Vision and Pattern Recognition, 2017,\npp. 5199–5208.\n[131] L. Yi, H. Su, X. Guo, and L. J. Guibas, “Syncspeccnn: Synchro-\nnized spectral cnn for 3d shape segmentation.” in Proceedings of\nthe IEEE Conference on Computer Vision and Pattern Recognition,\n2017, pp. 6584–6592.\n[132] X. Chen, L.-J. Li, L. Fei-Fei, and A. Gupta, “Iterative visual reason-\ning beyond convolutions,” in Proceedings of the IEEE Conference on\nComputer Vision and Pattern Recognition, 2018.\n[133] M. Narasimhan, S. Lazebnik, and A. Schwing, “Out of the\nbox: Reasoning with graph convolution nets for factual visual\nquestion answering,” in Advances in Neural Information Processing\nSystems, 2018, pp. 2655–2666.\n",
    "book_id": "a_comprehensive_survey_on_graph_neural_net",
    "book_title": "A Comprehensive Survey on Graph Neural Net",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 20
  },
  {
    "chunk_full": "JOURNAL OF LATEX CLASS FILES, VOL. X, NO. X, DECEMBER 2018\n22\n[134] Z. Cui, K. Henrickson, R. Ke, and Y. Wang, “High-order graph\nconvolutional recurrent neural network: a deep learning frame-\nwork for network-scale trafﬁc learning and forecasting,” arXiv\npreprint arXiv:1802.07007, 2018.\n[135] H. Yao, F. Wu, J. Ke, X. Tang, Y. Jia, S. Lu, P. Gong, J. Ye,\nand Z. Li, “Deep multi-view spatial-temporal network for taxi\ndemand prediction,” in Proceedings of the AAAI Conference on\nArtiﬁcial Intelligence, 2018, pp. 2588–2595.\n[136] J. Tang, M. Qu, M. Wang, M. Zhang, J. Yan, and Q. Mei, “Line:\nLarge-scale information network embedding,” in Proceedings of\nthe International Conference on World Wide Web.\nInternational\nWorld Wide Web Conferences Steering Committee, 2015, pp.\n1067–1077.\n[137] A. Fout, J. Byrd, B. Shariat, and A. Ben-Hur, “Protein interface\nprediction using graph convolutional networks,” in Advances in\nNeural Information Processing Systems, 2017, pp. 6530–6539.\n[138] J. You, B. Liu, R. Ying, V. Pande, and J. Leskovec, “Graph\nconvolutional policy network for goal-directed molecular graph\ngeneration,” in Advances in Neural Information Processing Systems,\n2018.\n[139] M. Allamanis, M. Brockschmidt, and M. Khademi, “Learning to\nrepresent programs with graphs,” in Proceedings of the Interna-\ntional Conference on Learning Representations, 2017.\n[140] J. Qiu, J. Tang, H. Ma, Y. Dong, K. Wang, and J. Tang, “Deepinf:\nSocial inﬂuence prediction with deep learning,” in Proceedings of\nthe ACM SIGKDD International Conference on Knowledge Discovery\n& Data Mining.\nACM, 2018, pp. 2110–2119.\n[141] D. Z¨ugner, A. Akbarnejad, and S. G¨unnemann, “Adversarial\nattacks on neural networks for graph data,” in Proceedings of the\nACM SIGKDD International Conference on Knowledge Discovery and\nData Mining.\nACM, 2018, pp. 2847–2856.\n[142] E. Choi, M. T. Bahadori, L. Song, W. F. Stewart, and J. Sun, “Gram:\ngraph-based attention model for healthcare representation learn-\ning,” in Proceedings of the ACM SIGKDD International Conference on\nKnowledge Discovery and Data Mining.\nACM, 2017, pp. 787–795.\n[143] E. Choi, C. Xiao, W. Stewart, and J. Sun, “Mime: Multilevel\nmedical embedding of electronic health records for predictive\nhealthcare,” in Advances in Neural Information Processing Systems,\n2018, pp. 4548–4558.\n[144] T. H. Nguyen and R. Grishman, “Graph convolutional networks\nwith argument-aware pooling for event detection,” in Proceedings\nof the AAAI Conference on Artiﬁcial Intelligence, 2018, pp. 5900–\n5907.\n[145] Z. Li, Q. Chen, and V. Koltun, “Combinatorial optimization\nwith graph convolutional networks and guided tree search,” in\nAdvances in Neural Information Processing Systems, 2018, pp. 536–\n545.\n[146] K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning\nfor image recognition,” in Proceedings of the IEEE conference on\ncomputer vision and pattern recognition, 2016, pp. 770–778.\n[147] Q. Li, Z. Han, and X.-M. Wu, “Deeper insights into graph convo-\nlutional networks for semi-supervised learning,” in Proceedings of\nthe AAAI Conference on Artiﬁcial Intelligence, 2018.\n",
    "book_id": "a_comprehensive_survey_on_graph_neural_net",
    "book_title": "A Comprehensive Survey on Graph Neural Net",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 21
  },
  {
    "chunk_full": "arXiv:1805.11965v4  [hep-th]  7 Dec 2018\nA Mini-Introduction To Information Theory\nEdward Witten\nSchool of Natural Sciences, Institute for Advanced Study\nEinstein Drive, Princeton, NJ 08540 USA\nAbstract\nThis article consists of a very short introduction to classical and quantum information theory.\nBasic properties of the classical Shannon entropy and the quantum von Neumann entropy are\ndescribed, along with related concepts such as classical and quantum relative entropy, conditional\nentropy, and mutual information. A few more detailed topics are considered in the quantum case.\n",
    "book_id": "a_mini-introduction_to_information_theory",
    "book_title": "A Mini-Introduction To Information Theory",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 22
  },
  {
    "chunk_full": "Contents\n1\nIntroduction\n2\n2\nClassical Information Theory\n2\n2.1\nShannon Entropy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n2\n2.2\nConditional Entropy\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4\n2.3\nRelative Entropy\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n6\n2.4\nMonotonicity of Relative Entropy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n7\n3\nQuantum Information Theory: Basic Ingredients\n10\n3.1\nDensity Matrices\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n10\n3.2\nQuantum Entropy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n14\n3.3\nConcavity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n16\n3.4\nConditional and Relative Quantum Entropy . . . . . . . . . . . . . . . . . . . . . . . .\n17\n3.5\nMonotonicity of Relative Entropy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n20\n3.6\nGeneralized Measurements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n22\n3.7\nQuantum Channels . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n23\n3.8\nThermodynamics And Quantum Channels . . . . . . . . . . . . . . . . . . . . . . . . .\n26\n4\nMore On Quantum Information Theory\n27\n4.1\nQuantum Teleportation and Conditional Entropy\n. . . . . . . . . . . . . . . . . . . . .\n28\n4.2\nQuantum Relative Entropy And Hypothesis Testing . . . . . . . . . . . . . . . . . . . .\n32\n4.3\nEncoding Classical Information In A Quantum State\n. . . . . . . . . . . . . . . . . . .\n36\n1\n",
    "book_id": "a_mini-introduction_to_information_theory",
    "book_title": "A Mini-Introduction To Information Theory",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 23
  },
  {
    "chunk_full": "1\nIntroduction\nThis article is intended as a very short introduction to basic aspects of classical and quantum information\ntheory.1\nSection 2 contains a very short introduction to classical information theory, focusing on the deﬁnition\nof Shannon entropy and related concepts such as conditional entropy, relative entropy, and mutual\ninformation. Section 3 describes the corresponding quantum concepts – the von Neumann entropy and\nthe quantum conditional entropy, relative entropy, and mutual information. Section 4 is devoted to\nsome more detailed topics in the quantum case, chosen to explore the extent to which the quantum\nconcepts match the intuition that their names suggest.\nThere is much more to say about classical and quantum information theory than can be found here.\nThere are several excellent introductory books, for example [1–3]. Another excellent place to start is\nthe lecture notes [4], especially chapter 10.\n2\nClassical Information Theory\n2.1\nShannon Entropy\nWe begin with a basic introduction to classical information theory. Suppose that one receives a message\nthat consists of a string of symbols a or b, say\naababbaaaab · · ·\n(2.1)\nAnd let us suppose that a occurs with probability p, and b with probability 1 −p. How many bits of\ninformation can one extract from a long message of this kind, say with N letters?\nFor large N, the message will consist very nearly of pN occurrences of a and (1 −p)N occurrences\nof b. The number of such messages is\nN!\n(pN)!((1 −p)N)! ∼\nNN\n(pN)pN((1 −p)N)(1−p)N\n=\n1\nppN(1 −p)(1−p)N = 2NS\n(2.2)\n1The article is based on a lecture at the 2018 summer program Prospects in Theoretical Physics at the Institute for\nAdvanced Study.\n2\n",
    "book_id": "a_mini-introduction_to_information_theory",
    "book_title": "A Mini-Introduction To Information Theory",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 24
  },
  {
    "chunk_full": "where S is the Shannon entropy per letter [5]\nS = −p log p −(1 −p) log(1 −p).\n(2.3)\n(In information theory, one usually measures entropy in bits and uses logarithms in base 2.)\nThe total number of messages of length N, given our knowledge of the relative probability of letters\na and b, is roughly\n2NS\n(2.4)\nand so the number of bits of information one gains in actually observing such a message is\nNS.\n(2.5)\nThis is an asymptotic formula for large S, since we used only the leading term in Stirling’s formula to\nestimate the number of possible messages, and we ignored ﬂuctuations in the frequencies of the letters.\nSuppose more generally that the message is taken from an alphabet with k letters a1, a2, · · · , ak,\nwhere the probability to observe ai is pi, for i = 1, · · · , k. We write A for this probability distribution.\nIn a long message with N ≫1 letters, the symbol ai will occur approximately Npi times, and the\nnumber of such messages is asymptotically\nN!\n(p1N)!(p2N)! · · · (pkN)! ∼\nNN\nQk\ni=1(piN)piN = 2NSA\n(2.6)\nwhere now the entropy per letter is\nSA = −\nk\nX\ni=1\npi log pi.\n(2.7)\nThis is the general deﬁnition of the Shannon entropy of a probability distribution for a random\nvariable A that takes values a1, . . . , ak with probabilities p1, . . . , pk. The number of bits of information\nthat one can extract from a message with N symbols is again\nNSA.\n(2.8)\nFrom the derivation, since the number 2NSA of possible messages is certainly at least 1, we have\nSA ≥0\n(2.9)\nfor any probability distribution. To get SA = 0, there has to be only 1 possible message, meaning that\none of the letters has probability 1 and the others have probability 0. The maximum possible entropy,\nfor an alphabet with k letters, occurs if the pi are all 1/k and is\nSA = −\nk\nX\ni=1\n(1/k) log(1/k) = log k.\n(2.10)\n3\n",
    "book_id": "a_mini-introduction_to_information_theory",
    "book_title": "A Mini-Introduction To Information Theory",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 25
  },
  {
    "chunk_full": "The reader can prove this by using the method of Lagrange multipliers to maximize SA = −P\ni pi log pi\nwith the constraint P\ni pi = 1.\nIn engineering applications, NSA is the number of bits to which a message with N letters can be\ncompressed. In such applications, the message is typically not really random but contains information\nthat one wishes to convey. However, in “lossless encoding,” the encoding program does not understand\nthe message and treats it as random. It is easy to imagine a situation in which one can make a better\nmodel by incorporating short range correlations between the letters. (For instance, the “letters” might\nbe words in a message in the English language; then English grammar and syntax would dictate short\nrange correlations.) A model incorporating such correlations would be a 1-dimensional classical spin\nchain of some kind with short range interactions. Estimating the entropy of a long message of N letters\nwould be a problem in classical statistical mechanics. But in the ideal gas limit, in which we ignore\ncorrelations, the entropy of a long message is just NS where S is the entropy of a message consisting\nof only one letter.\nEven in the ideal gas model, we are making statements that are only natural in the limit of large N.\nTo formalize the analogy with statistical mechanics, one could introduce a classical Hamiltonian H whose\nvalue for the ith symbol ai is −log pi, so that the probability of the ith symbol in the thermodynamic\nensemble is 2−H(ai) = pi. Notice then that in estimating the number of possible messages for large\nN, we ignored the diﬀerence between the canonical ensemble (deﬁned by probabilities 2−H) and the\nmicrocanonical ensemble (in which one speciﬁes the precise numbers of occurrences of diﬀerent letters).\nAs is usual in statistical mechanics, the diﬀerent ensembles are equivalent for large N. The equivalence\nbetween the diﬀerent ensembles is important in classical and quantum information theory.\n2.2\nConditional Entropy\nNow let us consider the following situation. Alice is trying to communicate with Bob, and she sends a\nmessage that consists of many letters, each being an instance of a random variable2 X whose possible\nvalues are x1, · · · , xk. She sends the message over a noisy telephone connection, and what Bob receives\nis many copies of a random variable Y , drawn from an alphabet with letters y1, · · · , yr. (Bob might\nconfuse some of Alice’s letters and misunderstand others.) How many bits of information does Bob gain\nafter Alice has transmitted a message with N letters?\nTo analyze this, let us suppose that PX,Y (xi, yj) is the probability that, in a given occurrence, Alice\nsends X = xi and Bob hears Y = yj. The probability that Bob hears Y = yj, summing over all choices\n2Generically, a random variable will be denoted X, Y, Z, etc. The probability to observe X = x is denoted PX(x), so\nif xi, i = 1, · · · , n are the possible values of X, then P\ni PX(xi) = 1. Similarly, if X, Y are two random variables, the\nprobability to observe X = x, Y = y will be denoted PX,Y (x, y).\n4\n",
    "book_id": "a_mini-introduction_to_information_theory",
    "book_title": "A Mini-Introduction To Information Theory",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 26
  },
  {
    "chunk_full": "of what Alice intended, is\nPY (yj) =\nX\ni\nPX,Y (xi, yj).\n(2.11)\nIf Bob does hear Y = yj, his estimate of the probability that Alice sent xi is the conditional proba-\nbility\nPX|Y (xi|yj) = PX,Y (xi, yj)\nPY (yj)\n.\n(2.12)\nFrom Bob’s point of view, once he has heard Y = yj, his estimate of the remaining entropy in Alice’s\nsignal is the Shannon entropy of the conditional probability distribution. This is\nSX|Y =yj = −\nX\ni\nPX|Y (xi|yj) log(PX|Y (xi|yj)).\n(2.13)\nAveraging over all possible values of Y , the average remaining entropy, once Bob has heard Y , is\nX\nj\nPY (yj)SX|Y =yj = −\nX\nj\nPY (yj)\nX\ni\nPX,Y (xi, yj)\nPY (yj)\nlog\n\u0012PX,Y (xi, yj)\nPY (yj)\n\u0013\n= −\nX\ni,j\nPX,Y (xi, yj) log PX,Y (xi, yj) +\nX\ni,j\nPX,Y (xi, yj) log PY (yj)\n= SXY −SY .\n(2.14)\nHere SXY is the entropy of the joint distribution PX,Y (xi, yj) for the pair X, Y and SY is the entropy of\nthe probability distribution PY (yj) = P\ni PX,Y (xi, yj) for Y only.\nThe left hand side of eqn. (2.14), which as we see equals SXY −SY , is called the conditional\nentropy SX|Y or S(X|Y ); it is the entropy that remains in the probability distribution X once Y is\nknown. Since it was obtained as a sum of ordinary entropies SX|Y =yj with positive coeﬃcients, it is\nclearly positive:\nSXY −SY ≥0.\n(2.15)\n(The analogous statement is not true quantum mechanically!) Since SX is the total information content\nin Alice’s message, and SXY −SY is the information content that Bob still does not have after observing\nY , it follows that the information about X that Bob does gain when he receives Y is the diﬀerence or\nI(X; Y ) = SX −SXY + SY .\n(2.16)\nHere I(X; Y ) is called the mutual information between X and Y . It measures how much we learn\nabout X by observing Y .\nThis interpretation convinces us that I(X; Y ) must be nonnegative. One can prove this directly but\ninstead I want to deduce it from the properties of one more quantity, the relative entropy. This will\ncomplete our cast of characters.\n5\n",
    "book_id": "a_mini-introduction_to_information_theory",
    "book_title": "A Mini-Introduction To Information Theory",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 27
  },
  {
    "chunk_full": "2.3\nRelative Entropy\nOne can motivate the deﬁnition of relative entropy as follows. Suppose that we are observing a random\nvariable X, for example the ﬁnal state in the decays of a radioactive nucleus. We have a theory that\npredicts a probability distribution QX for the ﬁnal state, say the prediction is that the probability to\nobserve ﬁnal state X = xi, where i runs over a set of possible outcomes {1, 2, · · ·s}, is qi = QX(xi). But\nmaybe our theory is wrong and the decay is actually described by some diﬀerent probability distribution\nPX, such that the probability of X = xi is pi = PX(xi). After observing the decays of N atoms, how\nsure could we be that the initial hypothesis is wrong?\nIf the correct probability distribution is PX, then after observing N decays, we will see outcome xi\napproximately piN times. Believing QX to be the correct distribution, we will judge the probability of\nwhat we have seen to be3\nP =\nsY\ni=1\nqpiN\ni\nN!\nQs\nj=1(pjN)!.\n(2.17)\nWe already calculated that for large N\nN!\nQs\nj=1(pjN)! ∼2−N P\ni pi log pi\n(2.18)\nso\nP ∼2−N P\ni pi(log pi−log qi).\n(2.19)\nThis is 2−NS(P ||Q) where the relative entropy (per observation) or Kullback-Liebler divergence is deﬁned\nas\nS(PX||QX) =\nX\ni\npi(log pi −log qi).\n(2.20)\nFrom the derivation, S(PX||QX) is clearly nonnegative, and zero only if PX = QX, that is if the initial\nhypothesis is correct. If the initial hypothesis is wrong, we will be sure of this once\nNS(PX||QX) ≫1.\n(2.21)\nThe chance of falsely excluding a correct hypothesis, because of a large ﬂuctuation that causes\nthe data to be more accurately simulated by PX than by QX, decays for large N as 2−NS(PX||QX).\n(Later we will more loosely say that the conﬁdence in excluding the wrong hypothesis is controlled by\n2−NS(PX||QX).) In this analysis, we have ignored noise in the observations. What we learned earlier\nabout conditional entropy would give us a start in including the eﬀects of noise.\nS(PX||QX) is an important measure of the diﬀerence between two probability distributions PX and\nQX, but notice that it is asymmetric in PX and QX. We broke the symmetry by assuming that QX was\nour initial hypothesis and PX was the correct answer.\n3Here\nN!\nQs\nj=1(pjN)! is the number of sequences in which outcome xi occurs piN times, and Qs\ni=1 qpiN\ni\nis the probability\nof any speciﬁc such sequence, assuming that the initial hypothesis QX is correct.\n6\n",
    "book_id": "a_mini-introduction_to_information_theory",
    "book_title": "A Mini-Introduction To Information Theory",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 28
  },
  {
    "chunk_full": "Now we will use positivity of the relative entropy to prove positivity of the mutual information. We\nconsider a pair of random variables X, Y and we consider two diﬀerent probability distributions. One,\nwhich we will call PX,Y , is deﬁned by a possibly correlated joint probability distribution\nPX,Y (xi, yj).\n(2.22)\nGiven such a joint probability distribution, the separate probability distributions for X and for Y are\nobtained by “integrating out” or summing over the other variable:\nPX(xi) =\nX\nj\nPX,Y (xi, yj),\nPY (yj) =\nX\ni\nPX,Y (xi, yj).\n(2.23)\nThis is an important operation which will frequently recur. We deﬁne a second probability distribution\nfor X, Y by ignoring the correlations between them:\nQX,Y (xi, yj) = PX(xi)PY (yj).\n(2.24)\nNow we calculate the relative entropy between these two distributions:\nS(PX,Y ||QX,Y ) =\nX\ni,j\nPX,Y (xi, yj)(log PX,Y (xi, yj) −log(PX(xi)PY (yj)))\n=\nX\ni,j\nPX,Y (xi, yj)(log PX,Y (xi, yj) −log PX(xi) −log PY (yj))\n=SX + SY −SXY = I(X; Y ).\n(2.25)\nThus I(X; Y ) ≥0, with equality only if the two distributions are the same, meaning that X and Y\nwere uncorrelated to begin with.\nThe property\nSX + SY −SXY ≥0\n(2.26)\nis called subadditivity of entropy.\n2.4\nMonotonicity of Relative Entropy\nNow there is one more very important property of relative entropy that I want to explain, and this\nwill more or less conclude our introduction to classical information theory. Suppose that X and Y\nare two random variables. Let PX,Y and QX,Y be two probability distributions, described by functions\nPX,Y (xi, yj) and QX,Y (xi, yj). If we start with a hypothesis QX,Y for the joint probability, then after\nmany trials in which we observe X and Y , our conﬁdence that we are wrong (assuming that PX,Y is the\n7\n",
    "book_id": "a_mini-introduction_to_information_theory",
    "book_title": "A Mini-Introduction To Information Theory",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 29
  },
  {
    "chunk_full": "correct answer) is determined by S(PX,Y ||QX,Y ). But suppose that we only observe X and not Y . The\nreduced distributions PX and QX for X only are described by functions\nPX(xi) =\nX\nj\nPX,Y (xi, yj),\nQX(xi) =\nX\nj\nQX,Y (xi, yj).\n(2.27)\nIf we observe X only, then the conﬁdence after many trials that the initial hypothesis is wrong is\ncontrolled by S(PX||QX).\nIt is harder to disprove the initial hypothesis if we observe only X, so\nS(PX,Y ||QX,Y ) ≥S(PX||QX).\n(2.28)\nThis is called monotonicity of relative entropy.\nConcretely, if we observe a sequence xi1, xi2, . . . xiN in N trials, then to estimate how unlikely this\nis, we will imagine a sequence of y’s that minimizes the unlikelihood of the joint sequence\n(xi1, yi1), (xi2, yi2), · · · , (xiN, yiN).\n(2.29)\nAn actual sequence of y’s that we might observe can only be more unlikely than this. So observing Y\nas well as X can only increase our estimate of how unlikely the outcome was, given the sequence of the\nx’s. Thus, the relative entropy only goes down upon “integrating out” some variables and not observing\nthem.\nHopefully, the reader has found this explanation compelling, but it is also not diﬃcult to give a\nproof in formulas. The inequality S(PX,Y ||QX,Y ) −S(PX||QX) ≥0 can be written\nX\ni,j\nPX,Y (xi, yj)\n\u0012\nlog\n\u0012 PX,Y (xi, yj)\nQX,Y (xi, yj)\n\u0013\n−log\n\u0012 PX(xi)\nQX(xi)\n\u0013\u0013\n≥0.\n(2.30)\nEquivalently\nX\ni\nPX(xi)\nX\nj\nPX,Y (xi, yj)\nPX(xi)\nlog\n\u0012 PX,Y (xi, yj)/PX(xi)\nQX,Y (xi, yj)/QX(xi)\n\u0013\n≥0.\n(2.31)\nThe left hand side is a sum of positive terms, since it is\nX\ni\nPX(xi)S(PY |X=xi||QY |X=xi),\n(2.32)\nwhere we deﬁne probability distributions PY |X=xi, QY |X=xi conditional on observing X = xi:\nPY |X=xi(yj) = PX,Y (xi, yj)/PX(xi),\nQY |X=xi(yj) = QX,Y (xi, yj)/QX(xi).\n(2.33)\n8\n",
    "book_id": "a_mini-introduction_to_information_theory",
    "book_title": "A Mini-Introduction To Information Theory",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 30
  },
  {
    "chunk_full": "So this establishes monotonicity of relative entropy.4 An important special case is strong subad-\nditivity of entropy. For this, we consider three random variables X, Y, Z. The combined system has a\njoint probability distribution PX,Y,Z(xi, yj, zk). Alternatively, we could forget the correlations between\nX and Y Z, deﬁning a probability distribution QX,Y,Z for the system XY Z by\nQX,Y,Z(xi, yj, zk) = PX(xi)PY,Z(yj, zk)\n(2.34)\nwhere as usual\nPX(xi) =\nX\nj,k\nPX,Y,Z(xi, yj, zk),\nPY,Z(yj, zk) =\nX\ni\nPX,Y,Z(xi, yj, zk).\n(2.35)\nThe relative entropy is S(PX,Y,Z||QX,Y,Z). But what if we only observe the subsystem XY ? Then we\nreplace PX,Y,Z and QX,Y,Z by probability distributions PX,Y , QX,Y with\nPX,Y (xi, yj) =\nX\nk\nPX,Y,Z(xi, yj, zk),\nQX,Y (xi, yj) =\nX\nk\nQX,Y,Z(xi, yj, zk) = PX(xi)PY (yj)\n(2.36)\nand we can deﬁne the relative entropy S(PX,Y ||QX,Y ). Monotonicity of relative entropy tells us that\nS(PX,Y,Z||QX,Y,Z) ≥S(PX,Y ||QX,Y ).\n(2.37)\nBut the relation between relative entropy and mutual information that we discussed a moment ago\ngives\nS(PX,Y,Z||QX,Y,Z) = I(X; Y Z) = SX −SXY Z + SY Z\n(2.38)\nand\nS(PX,Y ||QX,Y ) = I(X; Y ) = SX −SXY + SY .\n(2.39)\nSo\nSX −SXY Z + SY Z ≥SX −SXY + SY\n(2.40)\nor\nSXY + SY Z ≥SY + SXY Z,\n(2.41)\nwhich is called strong subadditivity. Remarkably, the same statement turns out to be true in quantum\nmechanics, where it is both powerful and surprising.\nEquivalently, the comparison of eqns. (2.38) and (2.39) gives\nI(X; Y Z) ≥I(X; Y ),\n(2.42)\n4What we have described is not the most general statement of monotonicity of relative entropy in classical information\ntheory. More generally, relative entropy is monotonic under an arbitrary stochastic map. We will not explain this here,\nthough later we will explain the quantum analog (quantum relative entropy is monotonic in any quantum channel).\n9\n",
    "book_id": "a_mini-introduction_to_information_theory",
    "book_title": "A Mini-Introduction To Information Theory",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 31
  },
  {
    "chunk_full": "which is called monotonicity of mutual information. The intuition is that what one learns about a\nrandom variable X by observing both Y and Z is at least as much as one could learn by observing Y\nonly.\nWe conclude this mini-introduction to classical information theory with one last remark. We re-\npeatedly made use of the ability to deﬁne a conditional probability distribution, conditional on some\nobservation. This has no really close analog in the quantum mechanical case5 and it is something of\na miracle that many of the conclusions nonetheless have quantum mechanical analogs. The greatest\nmiracle is strong subadditivity of quantum entropy.\n3\nQuantum Information Theory: Basic Ingredients\n3.1\nDensity Matrices\nNow we turn to quantum information theory. Quantum mechanics always deals with probabilities, but\nthe real quantum analog of a classical probability distribution is not a quantum state but a density\nmatrix. Depending on one’s view of quantum mechanics, one might believe that the whole universe is\ndescribed by a quantum mechanical pure state that depends on all the available degrees of freedom.\nEven if this is true, one usually studies a subsystem that cannot be described by a pure state.\nFor an idealized case, let A be a subsystem of interest, with Hilbert space HA.\nAnd let B be\neverything else of relevance, or possibly all of the rest of the universe, with Hilbert space HB. The\ncombined Hilbert space is the tensor product HAB = HA ⊗HB. The simple case is that a state vector\nψAB of the combined system is the tensor product of a state vector ψA ∈HA and another state vector\nψB ∈HB:\nψAB = ψA ⊗ψB.\n(3.1)\nIf ψAB is a unit vector, we can choose ψA and ψB to also be unit vectors. In the case of such a product\nstate, predictions about the A system can be made by forgetting about the B system and using the state\nvector ψA. Indeed, if OA is any operator on HA, then the corresponding operator on HAB is OA ⊗1B,\nand its expectation value in a factorized state ψAB = ψA ⊗ψB is\n⟨ψAB|OA ⊗1B|ψAB⟩= ⟨ψA|OA|ψA⟩⟨ψB|1B|ψB⟩= ⟨ψA|OA|ψA⟩.\n(3.2)\nHowever, a generic pure state ψAB ∈HAB is not a product state; instead it is “entangled.” If HA\nand HB have dimensions N and M, then a generic state in HAB can be presented as an N × M matrix,\nfor example in the 2 × 3 case\nψAB =\n\u0012\n∗\n∗\n∗\n∗\n∗\n∗\n\u0013\n.\n(3.3)\n5See, however, [6] for a partial substitute.\n10\n",
    "book_id": "a_mini-introduction_to_information_theory",
    "book_title": "A Mini-Introduction To Information Theory",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 32
  },
  {
    "chunk_full": "By unitary transformations on HA and on HB, we can transform ψAB to\nψAB →UψABV\n(3.4)\nwhere U and V are N × N and M × M unitaries. The canonical form of a matrix under that operation\nis a diagonal matrix, with positive numbers on the diagonal, and extra rows or columns of zeroes, for\nexample\n\u0012√p1\n0\n0\n0\n√p2\n0\n\u0013\n.\nA slightly more invariant way to say this is that any pure state can be written\nψAB =\nX\ni\n√piψi\nA ⊗ψi\nB,\n(3.5)\nwhere we can assume that ψi\nA and ψi\nB are orthonormal,\n⟨ψi\nA, ψj\nA⟩= ⟨ψi\nB, ψj\nB⟩= δij\n(3.6)\nand that pi > 0. (The ψi\nA and ψi\nB may not be bases of HA or HB, because there may not be enough of\nthem.) The condition for ψAB to be a unit vector is that\nX\ni\npi = 1,\n(3.7)\nso we can think of the pi as probabilities. Eqn. (3.5) is called the Schmidt decomposition.\nWhat is the expectation value in such a state of an operator OA that only acts on A? It is\n⟨ψAB|OA ⊗1B|ψAB⟩=\nX\ni,j\n√pipj⟨ψi\nA|OA|ψj\nA⟩⟨ψi\nB|1B|ψj\nB⟩\n=\nX\ni\npi⟨ψi\nA|OA|ψi\nA⟩.\n(3.8)\nThis is the same as\nTrHA ρAOA,\n(3.9)\nwhere ρA is the density matrix\nρA =\nX\ni\npi|ψi\nA⟩⟨ψi\nA|.\n(3.10)\nThus, if we are only going to make measurements on system A, we do not need a wavefunction of the\nuniverse: it is suﬃcient to have a density matrix for system A.\nFrom the deﬁnition\nρA =\nX\ni\npi|ψi\nA⟩⟨ψi\nA|\n(3.11)\n11\n",
    "book_id": "a_mini-introduction_to_information_theory",
    "book_title": "A Mini-Introduction To Information Theory",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 33
  },
  {
    "chunk_full": "we see that ρA is hermitian and positive semi-deﬁnite. Because P\ni pi = 1, ρA has trace 1:\nTrHA ρA = 1.\n(3.12)\nConversely, every matrix with those properties can be “puriﬁed,” meaning that it is the density matrix\nof some pure state on some “bipartite” (or two-part) system AB. For this, we ﬁrst observe that any\nhermitian matrix ρA can be diagonalized, meaning that in a suitable basis it takes the form of eqn.\n(3.11); moreover, if ρA ≥0, then the pi are likewise positive (if one of the pi vanishes, we omit it from\nthe sum). Having gotten this far, to realize ρA as a density matrix we simply introduce another Hilbert\nspace HB with orthonormal states ψi\nB and observe that ρA is the density matrix of the pure state\nψAB =\nX\ni\n√piψi\nA ⊗ψi\nB ∈HA ⊗HB.\n(3.13)\nIn this situation, ψAB is called a “puriﬁcation” of the density matrix ρA. The existence of puriﬁcations\nis a nice property of quantum mechanics that has no classical analog: the classical analog of a density\nmatrix is a probability distribution, and there is no notion of purifying a probability distribution.\nThe puriﬁcation ψAB of a density matrix ρA is far from unique (even if the auxiliary system B is\nspeciﬁed), because there is freedom in choosing the orthonormal states ψi\nB in eqn. (3.13). However,\nany other set of orthonormal vectors in HB can be obtained from a given choice ψi\nB by a unitary\ntransformation of HB, so we learn the following important fact: any two puriﬁcations of the same\ndensity matrix ρA on system A by pure states of a bipartite system AB are equivalent under a unitary\ntransformation of system B.\nIf there is more than one term in the expansion\nψAB =\nX\ni\n√piψi\nA ⊗ψi\nB ∈HA ⊗HB,\n(3.14)\nwe say that systems A and B are entangled in the state ψAB. If there is only one term, the expansion\nreduces to\nψAB = ψA ⊗ψB,\n(3.15)\nan “unentangled” tensor product state. Then system A can be described by the pure state ψA and the\ndensity matrix is of rank 1:\nρA = |ψA⟩⟨ψA|.\nIf ρA has rank higher than 1, we say that system A is in a mixed state. If ρA is a multiple of the identity,\nwe say that A is maximally mixed.\nIn the general case\nρA =\nX\ni\npi|ψi\nA⟩⟨ψi\nA|\n(3.16)\none will describe all measurements of system A correctly if one says that system A is in the state ψi\nA\nwith probability pi. However, one has to be careful here because the decomposition of eqn. (3.16) is\n12\n",
    "book_id": "a_mini-introduction_to_information_theory",
    "book_title": "A Mini-Introduction To Information Theory",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 34
  },
  {
    "chunk_full": "not unique. It is unique if the pi are all distinct and one wants the number of terms in the expansion to\nbe as small as possible, or equivalently if one wants the ψi\nA to be orthonormal. But if one relaxes those\nconditions, then (except for a pure state) there are many ways to make this expansion. This means that\nif Alice prepares a quantum system to be in the pure state ψi\nA with probability pi, then there is no way\nto determine the pi or the ψi\nA by measurements, even if one is provided with many identical copies to\nmeasure. Any measurement of the system will depend only on ρA = P\ni pi|ψi\nA⟩⟨ψi\nA|. There is no way to\nget additional information about how the system was prepared.\nSo far, when we have discussed a bipartite system AB, we have assumed that the combined system\nis in a pure state ψAB, and we have discussed density matrices ρA and ρB for systems A and B. More\ngenerally, we should allow for the possibility that the combined system AB is described to begin with by\na density matrix ρAB. Consideration of this situation leads to the following very fundamental deﬁnition.\nJust as for classical probability distributions, for density matrices we can always “integrate out” an\nunobserved system and get a reduced density matrix for a subsystem. Classically, given a joint prob-\nability distribution PX,Y (xi, yj) for a bipartite system XY , we “integrated out” Y to get a probability\ndistribution for X only:\nPX(xi) =\nX\nj\nPX,Y (xi, yj).\n(3.17)\nThe quantum analog of that is a partial trace. Suppose that AB is a bipartite system with Hilbert\nspace HA ⊗HB and a density matrix ρAB. Concretely, if |i⟩A, i = 1, . . . , n are an orthonormal basis of\nHA and |α⟩B, α = 1, . . . , m are an orthonormal basis of HB, then a density matrix for AB takes the\ngeneral form\nρAB =\nX\ni,i′,α,α′\ncii′αα′|i⟩A ⊗|α⟩B A⟨i′| ⊗B⟨α′|.\n(3.18)\nThe reduced density matrix for measurements of system A only is obtained by setting α = α′, replacing\n|α⟩B B⟨α| by its trace, which is 1, and summing:\nρA =\nX\ni,i′,α\nci,i′,α,α|i⟩A A⟨i′|.\n(3.19)\nIn other words, if we are going to measure system A only, we sum over all of the unobserved states of\nsystem B. This is usually written as a partial trace:\nρA = TrHB ρAB,\n(3.20)\nthe idea being that one has “traced out” HB, leaving a density operator on HA. Likewise (summing\nover i to eliminate HA)\nρB = TrHA ρAB.\n(3.21)\nBefore going on, perhaps I should give a simple example of a concrete situation in which it is\nimpractical to not use density matrices. Consider an isolated atom interacting with passing photons. A\n13\n",
    "book_id": "a_mini-introduction_to_information_theory",
    "book_title": "A Mini-Introduction To Information Theory",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 35
  },
  {
    "chunk_full": "photon might be scattered, or absorbed and reemitted, or might pass by without interacting with the\natom. Regardless, after a certain time, the atom is again alone. After n photons have had the chance to\ninteract with the atom, to give a pure state description, we need a joint wavefunction for the atom and\nall the outgoing photons. The mathematical machinery gets bigger and bigger, even though (assuming\nwe observe only the atom) the physical situation is not changing. By using a density matrix, we get\na mathematical framework for describing the state of the system that does not change regardless of\nhow many photons have interacted with the atom in the past (and what else those photons might have\ninteracted with). All we need is a density matrix for the atom.\n3.2\nQuantum Entropy\nThe von Neumann entropy6 of a density matrix ρA is deﬁned by a formula analogous to the Shannon\nentropy of a probability distribution:\nS(ρA) = −Tr ρA log ρA.\n(3.22)\nAs an immediate comment, we note that S(ρA) is manifestly invariant under a unitary transformation\nρA →UρAU−1.\n(3.23)\nQuantum conditional and relative entropy, which will be introduced in section 3.4, are similarly invariant\nunder a suitable class of unitaries.\nBy a unitary transformation, we can diagonalize ρA, putting it in the form\nρA =\nX\ni\npi|ψi\nA⟩⟨ψi\nA|,\n(3.24)\nwith ψi\nA being orthonormal and pi > 0. Then in an obvious basis\nρA log ρA =\n\n\n\n\n\np1 log p1\np2 log p2\np3 log p3\n...\n\n\n\n\n\n(3.25)\nand so\nS(ρA) = −\nX\ni\npi log pi,\n(3.26)\nthe same as the Shannon entropy of the probability distribution {pi}.\n6The von Neumann entropy is the most important quantum entropy, but generalizations such as the R´enyi entropies\nSα(ρA) =\n1\n1−α log Tr ρα\nA can also be useful.\n14\n",
    "book_id": "a_mini-introduction_to_information_theory",
    "book_title": "A Mini-Introduction To Information Theory",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 36
  },
  {
    "chunk_full": "An immediate consequence is that, just as for the Shannon entropy,\nS(ρA) ≥0,\n(3.27)\nwith equality only for a pure state (one of the p’s being 1 and the others 0). The formula S(ρA) =\n−P\ni pi log pi also implies the same upper bound that we had classically for a system with k states\nS(ρA) ≤log k,\n(3.28)\nwith equality only if ρA is a multiple of the identity:\nρA = 1\nk\n\n\n\n\n\n1\n1\n1\n...\n\n\n\n\n.\n(3.29)\nIn this case, we say that A is in a maximally mixed state. In fact, the von Neumann entropy has many\nproperties analogous to the Shannon entropy, but the explanations required are usually more subtle and\nthere are key diﬀerences.\nHere is a nice property of the von Neumann entropy that does not have a classical analog. If a\nbipartite system AB is in a pure state\nψAB =\nX\ni\n√piψi\nA ⊗ψi\nB ∈HA ⊗HB,\n(3.30)\nthen the density matrices of systems A and B are\nρA =\nX\ni\npi|ψi\nA⟩⟨ψi\nA|,\n(3.31)\nand likewise\nρB =\nX\ni\npi|ψi\nB⟩⟨ψi\nB|.\n(3.32)\nThe same constants pi appear in each, so clearly\nS(ρA) = S(ρB).\n(3.33)\nThus a system A and a purifying system B always have the same entropy. Note that in this situation,\nsince the combined system AB is in a pure state, its entropy SAB vanishes.\n15\n",
    "book_id": "a_mini-introduction_to_information_theory",
    "book_title": "A Mini-Introduction To Information Theory",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 37
  },
  {
    "chunk_full": "3.3\nConcavity\nThe von Neumann entropy – like its antecedents in classical thermodynamics and statistical mechanics\n– has the important property of concavity. Suppose that ρ1 and ρ2 are two density matrices, and set\nρ(t) = tρ1 + (1 −t)ρ2, for 0 ≤t ≤1. We will write ˙ρ(t), ¨ρ(t) for dρ(t)/dt, d2ρ(t)/dt2. Then\nd2\ndt2S(ρ(t)) ≤0.\n(3.34)\nTo prove this, we ﬁrst compute that7\nd\ndtS(ρ(t)) = −Tr ˙ρ log ρ.\n(3.35)\nThen as\nlog ρ =\nZ ∞\n0\nds\n\u0012\n1\ns + 1 −\n1\ns + ρ(t)\n\u0013\n(3.36)\nand ¨ρ = 0, we have\nd2\ndt2S(ρ(t)) = −\nZ ∞\n0\ndsTr ˙ρ\n1\ns + ρ(t) ˙ρ\n1\ns + ρ(t).\n(3.37)\nThe integrand is positive, as it is Tr B2, where B is the self-adjoint operator (s+ρ(t))−1/2 ˙ρ(t)(s+ρ(t))−1/2.\nSo\nd2\ndt2 S(ρ(t)) ≤0.\nIn other words, the function S(ρ(t)) is concave. Like any concave function, S(ρ(t)) has the property\nthat the straight line connecting two points on its graph lies below the graph. Explicitly, this gives\ntS(ρ1) + (1 −t)S(ρ2) ≤S(tρ1 + (1 −t)ρ2) = S(ρ(t)).\n(3.38)\nMore generally, let ρi, i = 1, . . . , n be density matrices and pi, i = 1, . . . , n nonnegative numbers with\nP\ni pi = 1. Then by induction starting with (3.38), or because this is a general property of concave\nfunctions, we have\nX\ni\npiS(ρi) ≤S(ρ),\nρ =\nX\ni\npiρi.\n(3.39)\nThis may be described by saying that entropy can only increase under mixing. The nonnegative quantity\nthat appears here is known as the Holevo information or Holevo χ [7]:\nχ = S(ρ) −\nX\ni\npiS(ρi).\n(3.40)\n7 For this, consider an arbitrary density matrix ρ and a ﬁrst order perturbation ρ →ρ + δρ. After diagonalizing ρ, one\nobserves that to ﬁrst order in δρ, the oﬀ-diagonal part of δρ does not contribute to the trace in the deﬁnition of S(ρ+ δρ).\nTherefore, S(ρ(t)) can be diﬀerentiated assuming that ρ and ˙ρ commute. So it suﬃces to check (3.35) for a diagonal\nfamily of density matrices ρ(t) = diag(λ1(t), λ2(t), · · · , λn(t)), with P\ni λi(t) = 1. Another approach is to use (3.36) to\nsubstitute for log ρ(t) in the deﬁnition S(ρ(t)) = −Tr ρ(t) log ρ(t). Diﬀerentiating with respect to t, observing that ρ(t)\ncommutes with 1/(s + ρ(t)), and then integrating over s, one arrives at (3.35). In either approach, one uses that Tr ˙ρ = 0\nsince Tr ρ(t) = 1.\n16\n",
    "book_id": "a_mini-introduction_to_information_theory",
    "book_title": "A Mini-Introduction To Information Theory",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 38
  },
  {
    "chunk_full": "An interesting special case is the following. Let ρ be any density matrix on a Hilbert space H.\nPick a basis of H, and let ρD be the diagonal density matrix obtained in that basis by dropping the\noﬀ-diagonal matrix elements from ρ and keeping the diagonal ones. Let ρ(t) = (1 −t)ρD + tρ. We see\nthat\nd\ndtS(ρ(t))\n\f\f\f\f\nt=0\n= 0,\n(3.41)\nby virtue of (3.35), because ρ(0) and log ρ(0) are diagonal while the diagonal matrix elements of dρ/dt\nvanish at t = 0. When we combine this with d2S(ρ(t))/dt2 ≤0, we get S(ρ(1)) ≤S(ρ(0)) or\nS(ρD) ≥S(ρ).\n(3.42)\nThus, dropping the oﬀ-diagonal part of a density matrix (in any basis) can only increase the entropy.\nEqn. (3.42) is a strict inequality unless ρ = ρD, because eqn. (3.37) shows that\nd2\ndt2S(ρ(t))\n\f\f\f\nt=0 is strictly\nnegative unless ρ = ρD.\nAn alternative proof of eqn. (3.42), again using the inequality (3.39), is as follows. For an N state\nsystem, there are 2N matrices that are diagonal matrices (in some chosen basis) with diagonal matrix\nelements that are all ±1. Let Ui be any of these and set ρi = UiρU−1\ni\n. Of course, ρi is also a density\nmatrix, since Ui is unitary. The average of the ρi, over all 2N choices of Ui, is the diagonal density\nmatrix ρD. So eqn. (3.39) says that the average of S(ρi) is less than or equal to S(ρD). But S(ρi) is\nindependent of i and equal to S(ρ), since the von Neumann entropy is invariant under conjugation by\na unitary matrix such as Ui. So in fact the average of the S(ρi) is just S(ρ) and the inequality (3.39)\nbecomes S(ρ) ≤S(ρD).\nSomewhat similarly to what we have explained here, concavity of the function f(q) = −q log q could\nhave been used in the classical arguments in section 2, though we circumvented this by using Stirling’s\nformula instead.\n3.4\nConditional and Relative Quantum Entropy\nIt is now possible to formally imitate some of the other deﬁnitions that we made in the classical case.\nFor example, if AB is a bipartite system, we deﬁne what is called quantum conditional entropy\nS(A|B) = SAB −SB.\n(3.43)\nThis name is potentially misleading because there is not a good quantum notion of conditional probabil-\nities. Unlike the classical case, quantum conditional entropy is not an entropy conditional on something.\nNevertheless, in section 4.1, we will discuss at least one sense in which quantum conditional entropy\nbehaves in a way analogous to classical conditional entropy.\n17\n",
    "book_id": "a_mini-introduction_to_information_theory",
    "book_title": "A Mini-Introduction To Information Theory",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 39
  },
  {
    "chunk_full": "There is also a fundamental diﬀerence from the classical case: quantum mechanically, S(A|B) can\nbe negative. In fact, suppose that system AB is in an entangled pure state. Then SAB = 0 but as\nsystem B is in a mixed state, SB > 0. So in this situation S(A|B) < 0.\nAnother classical deﬁnition that is worth imitating is the mutual information. Given a bipartite\nsystem AB with density matrix ρAB, the mutual information is deﬁned just as it is classically:\nI(A; B) = SA −SAB + SB.\n(3.44)\nHere, however, we are more fortunate, and the quantum mutual information is nonnegative:\nI(A; B) ≥0.\n(3.45)\nMoreover, I(A; B) = 0 if and only if the density matrix factorizes, in the sense that\nρAB = ρA ⊗ρB.\n(3.46)\nPositivity of mutual information is also called subadditivity of entropy. To begin with, quantum mutual\ninformation is a formal deﬁnition and it is not obvious how it is related to information that one can\ngain about system A by observing system B. We will explore at least one aspect of this question in\nsection 4.3.\nBefore proving positivity of mutual information, I will explain an interesting corollary. Although\nconditional entropy S(A|B) can be negative, the possibility of “purifying” a density matrix gives a lower\nbound on S(A|B). Let C be such that ABC is in a pure state. Remember that in general if XY is in\na pure state then SX = SY . So if ABC is in a pure state then SAB = SC and SB = SAC. Thus\nSAB −SB = SC −SAC ≥−SA,\n(3.47)\nwhere the last step is positivity of mutual information. So\nS(A|B) = SAB −SB ≥−SA.\n(3.48)\nReversing the roles of A and B in the derivation, we get the Araki-Lieb inequality [8]\nSAB ≥|SA −SB|.\n(3.49)\nIt is saturated if SAB = 0, which implies SB = SA. What has just been explained is a typical argument\nexploiting the existence of puriﬁcations.\nJust as in the classical case, to understand positivity of the mutual information, it helps to ﬁrst\ndeﬁne the relative entropy [9]. Suppose that ρ and σ are two density matrices on the same Hilbert space\nH. The relative entropy can be deﬁned by imitating the classical formula:\nS(ρ||σ) = Trρ(log ρ −log σ).\n(3.50)\n18\n",
    "book_id": "a_mini-introduction_to_information_theory",
    "book_title": "A Mini-Introduction To Information Theory",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 40
  },
  {
    "chunk_full": "For now, this is just a formal deﬁnition, but we will learn in section 4.2 that S(ρ||σ) has the same\ninterpretation quantum mechanically that it does classically: if one’s hypothesis is that a quantum\nsystem is described by a density matrix σ, and it is actually described by a diﬀerent density matrix ρ,\nthen to learn that one is wrong, one needs to observe N copies of the system where NS(ρ||σ) >> 1.\nJust as classically, it turns out that S(ρ||σ) ≥0 for all density matrices ρ, σ, with equality precisely\nif ρ = σ. To prove this, ﬁrst diagonalize σ. In general ρ is not diagonal in the same basis. Let ρD be\nthe diagonal density matrix obtained from ρ by dropping the oﬀ-diagonal matrix elements in the basis\nin which σ is diagonal, and keeping the diagonal ones. Since Tr ρ log σ = Tr ρD log σ, it follows directly\nfrom the deﬁnitions of von Neumann entropy and relative entropy that\nS(ρ||σ) = S(ρD||σ) + S(ρD) −S(ρ).\n(3.51)\nThis actually exhibits S(ρ||σ) as the sum of two nonnegative terms.\nWe showed in eqn.\n(3.42)\nthat S(ρD) −S(ρ) ≥0.\nAs for S(ρD||σ), it is nonnegative, because if σ = diag(q1, . . . , qn), ρD =\ndiag(p1, . . . , pn), then\nS(ρD||σ) =\nX\ni\npi(log pi −log qi),\n(3.52)\nwhich can be interpreted as a classical relative entropy and so is nonnegative. To get equality in these\nstatements, we need σ = ρD and ρD = ρ, so S(ρ||σ) vanishes only if ρ = σ.\nNow we can use positivity of the relative entropy to prove that I(A; B) ≥0 for any density matrix\nρAB. Imitating the classical proof, we deﬁne\nσAB = ρA ⊗ρB,\n(3.53)\nand we observe that\nlog σAB = log ρA ⊗1B + 1A ⊗log ρB,\n(3.54)\nso\nS(ρAB||σAB) = TrABρAB(log ρAB −log σAB)\n= TrABρAB(log ρAB −log ρA ⊗1B −1B ⊗log ρB)\n= SA + SB −SAB = I(A; B).\n(3.55)\nSo just as classically, positivity of the relative entropy implies positivity of the mutual information\n(which is also called subadditivity of entropy).\nThe inequality (3.39) that expresses the concavity of the von Neumann entropy can be viewed as a\nspecial case of the positivity of mutual information. Let B be a quantum system with density matrices\nρi\nB and let C be an auxiliary system C with an orthonormal basis |i⟩C. Endow CB with the density\nmatrix:\nρCB =\nX\ni\npi|i⟩C C⟨i| ⊗ρi\nB.\n(3.56)\n19\n",
    "book_id": "a_mini-introduction_to_information_theory",
    "book_title": "A Mini-Introduction To Information Theory",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 41
  },
  {
    "chunk_full": "The mutual information between C and B if the combined system is described by ρCB is readily com-\nputed to be\nI(C; B) = S(ρB) −\nX\ni\npiS(ρi\nB),\n(3.57)\nso positivity of mutual information gives our inequality.\n3.5\nMonotonicity of Relative Entropy\nSo relative entropy is positive, just as it is classically. Do we dare to hope that relative entropy is also\nmonotonic, as classically? Yes it is, as ﬁrst proved by Lieb and Ruskai [10], using a lemma of Lieb [11].\nHow to prove strong subadditivity will not be described here; this has been explored in a companion\narticle [12], sections 3 and 4.\nMonotonicity of quantum relative entropy is something of a miracle, because, as there is no such thing\nas a joint probability distribution for general quantum observables, the intuition behind the classical\nstatement is not applicable in any obvious way. Rather, strong subadditivity is ultimately used to prove\nthat quantities such as quantum conditional entropy and quantum relative entropy and quantum mutual\ninformation do have properties somewhat similar to the classical case. We will explore some of this in\nsection 4.\nThere are diﬀerent statements of monotonicity of relative entropy, but a very basic one (and actually\nthe version proved in [10]) is monotonicity under partial trace. If AB is a bipartite system with two\ndensity matrices ρAB and σAB, then we can take a partial trace on B to get reduced density matrices\non A:\nρA = TrBρAB,\nσA = TrBσAB.\n(3.58)\nMonotonicity of relative entropy under partial trace is the statement that taking a partial trace can\nonly reduce the relative entropy:\nS(ρAB||σAB) ≥S(ρA||σA).\n(3.59)\n(This is also called the Data Processing Inequality.)\nBy imitating what we said classically in section 2, one can deduce strong subadditivity of quantum\nentropy from monotonicity of relative entropy.\nWe consider a tripartite system ABC with density\nmatrix ρABC. There are reduced density matrices such as ρA = TrBCρABC, ρBC = TrAρABC, etc., and\nwe deﬁne a second density matrix\nσABC = ρA ⊗ρBC.\n(3.60)\nThe reduced density matrices of ρABC and σABC, obtained by tracing out C, are\nρAB = TrCρABC,\nσAB = TrCσABC = ρA ⊗ρB.\n(3.61)\n20\n",
    "book_id": "a_mini-introduction_to_information_theory",
    "book_title": "A Mini-Introduction To Information Theory",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 42
  },
  {
    "chunk_full": "Monotonicity of relative entropy under partial trace says that\nS(ρABC||σABC) ≥S(ρAB||σAB).\n(3.62)\nBut (as in our discussion of positivity of mutual information)\nS(ρABC||σABC) = S(ρABC||ρA ⊗ρBC) = I(A; BC) = SA + SBC −SABC\n(3.63)\nand similarly\nS(ρAB||σAB) = S(ρAB||ρA ⊗ρB) = I(A; B) = SA + SB −SAB.\n(3.64)\nSo eqn. (3.62) becomes monotonicity of mutual information\nI(A; BC) ≥I(A; B)\n(3.65)\nor equivalently strong subadditivity [10]\nSAB + SBC ≥SB + SABC.\n(3.66)\nAll of these steps are the same as they were classically. Using puriﬁcations, one can ﬁnd various\nequivalent statements. If ABCD is in a pure state then SAB = SCD, SABC = SD so the inequality\nbecomes\nSCD + SBC ≥SB + SD.\n(3.67)\nSo for instance S(C|D) = SCD −SD can be negative, or S(C|B) = SBC −SB can be negative, but\nS(C|D) + S(C|B) ≥0.\n(3.68)\n(This is related to “monogamy of entanglement”: a given qubit in C can be entangled with D, reducing\nSCD, or with B, reducing SBC, but not both.)\nClassically, the intuition behind monotonicity of mutual information was explained in section 2; one\nlearns at least as much about system A by observing B and C as one could learn by observing B only.\nQuantum mechanically, it is just not clear a priori that the formal deﬁnition I(A; B) = SA −SAB + SB\nwill lead to something consistent with that intuition. The rather subtle result of monotonicity of relative\nentropy [10] shows that it does.\nIn general, strong subadditivity (or monotonicity of relative entropy) is the key to many interesting\nstatements in quantum information theory. Many of the most useful statements that are not more\nelementary are deduced from strong subadditivity.\n21\n",
    "book_id": "a_mini-introduction_to_information_theory",
    "book_title": "A Mini-Introduction To Information Theory",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 43
  },
  {
    "chunk_full": "3.6\nGeneralized Measurements\nOnce we start using density matrices, there are a few more tools we should add to our toolkit. First let\nus discuss measurements. Textbooks begin with “projective measurements,” which involve projection\nonto orthogonal subspaces of a Hilbert space H of quantum states.\nWe pick orthogonal hermitian\nprojection operators πs, s = 1, · · · , k obeying\nX\ns\nπs = 1,\nπ2\ns = πs,\nπsπs′ = 0,\ns ̸= s′.\n(3.69)\nA measurement of a state ψ involving these projection operators has outcome s with probability\nps = ⟨ψ|πs|ψ⟩.\n(3.70)\nThese satisfy P\ns ps = 1 since P\ns πs = 1. If instead of a pure state ψ the system is described by a\ndensity matrix ρ, then the probability of outcome s is\nps = TrH πsρ.\n(3.71)\nAfter the measurement is made, if outcome s has been found, the system can be described by a new\ndensity matrix\nρs = 1\nps\nπsρπs.\n(3.72)\nBut Alice can make a more general type of measurement using an auxiliary system C (sometimes\ncalled an ancillary system) with Hilbert space C. We suppose that C is k-dimensional with a basis of\nstates |s⟩, s = 1, · · · , k. Alice initializes C in the state |1⟩. Then she acts on the combined system\nC ⊗H with a unitary transformation U, which she achieves by suitably adjusting a time-dependent\nHamiltonian. She chooses U so that for any ψ ∈H\nU(|1⟩⊗ψ) =\nk\nX\ns=1\n|s⟩⊗Esψ\n(3.73)\nfor some linear operators Es. (She does not care what U does on other states.) Unitarity of U implies\nthat\nk\nX\ns=1\nE†\nsEs = 1,\n(3.74)\nbut otherwise the Es are completely arbitrary.\nThen Alice makes a projective measurement of the system C ⊗H, using the commuting projection\noperators\nπs = |s⟩⟨s| ⊗1,\n(3.75)\n22\n",
    "book_id": "a_mini-introduction_to_information_theory",
    "book_title": "A Mini-Introduction To Information Theory",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 44
  },
  {
    "chunk_full": "which have all the appropriate properties. The probability of outcome s is\nps = |Es|ψ⟩|2 = ⟨ψ|E†\nsEs|ψ⟩.\n(3.76)\nMore generally, if the system H is described initially by a density matrix ρ, then the probability of\noutcome s is\nps = Tr E†\nsEsρ.\n(3.77)\nThe numbers ps are nonnegative because E†\nsEs is nonnegative, and P\ns ps = 1 because P\ns E†\nsEs = 1.\nBut the E†\nsEs are not orthogonal projection operators; they are just nonnegative hermitian operators\nthat add to 1. What we have described is a more general kind of quantum mechanical measurement of\nthe original system. (In the jargon, this is a “positive operator-valued measurement” or POVM.)\nAccording to eqn. (3.72), after Alice’s measurement, if the outcome s has been found, then the\ncombined system C ⊗H can be described by the density matrix\n1\nps|s⟩⟨s| ⊗Es|ψ⟩⟨ψ|E†\ns. Taking the\npartial trace over system C, we learn that, after the generalized measurement, the original system H\ncan be described by the density matrix\nX\ns\n1\nps\nEs|ψ⟩⟨ψ|E†\ns\n(3.78)\nor more generally (if the original system was in a mixed state with density matrix ρ)\nX\ns\n1\nps\nEsρE†\ns.\n(3.79)\nOne can slightly generalize this construction as follows.8 Suppose that the initial system actually\nhad for its Hilbert space a direct sum H ⊕H′, but it is known that the initial state of the system is\nvalued in H, in other words the initial state ψ has the form χ ⊕0 with χ ∈H, and 0 the zero vector in\nH′. Then Alice couples H ⊕H′ to her auxiliary system C, so she describes the combined system by a\nHilbert space C ⊗(H⊕H′). Now she picks U so that it maps a vector |1⟩⊗(χ⊕0) to P\ns |s⟩⊗(0⊕Esχ),\nwhere Es is a linear transformation Es : H →H′. (As before, Alice does not care what U does on other\nvectors.) After applying U, Alice makes a projective measurement using the same projection operators\nπs = |s⟩⟨s| ⊗1 as before (of course, 1 is now the identity on H ⊕H′). The linear transformations Es\nstill obey eqn. (3.74), the probability of outcome s is still given by eqn. (3.77), and the density matrix\nafter a measurement that gives outcome s is still given by eqn. (3.78).\n3.7\nQuantum Channels\nNow let us view this process from another point of view. How can a density matrix evolve? The usual\nHamiltonian evolution of a state ψ is ψ →Uψ for a unitary operator U, and on the density matrix it\n8The following paragraph may be omitted on ﬁrst reading. It is included to make possible a more general statement\nin section 3.7.\n23\n",
    "book_id": "a_mini-introduction_to_information_theory",
    "book_title": "A Mini-Introduction To Information Theory",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 45
  },
  {
    "chunk_full": "corresponds to\nρ →UρU−1.\n(3.80)\nAs we remarked earlier (eqn. (3.23)), such unitary evolution preserves the von Neumann entropy of a\ndensity matrix, and similarly it preserves the relative entropy between two density matrices.\nBut let us consider Alice again with her extended system C ⊗H. She initializes the extended system\nwith the density matrix\nbρ = |1⟩⟨1| ⊗ρ\n(3.81)\nwhere ρ is a density matrix on H. Then she applies the same unitary U as before, mapping bρ to\nbρ′ = U bρU−1 =\nk\nX\ns,s′=1\n|s⟩⟨s′| ⊗EsρE†\ns′.\n(3.82)\nThe induced density matrix on the original system H is obtained by a partial trace and is\nρ′ = TrCbρ′ =\nk\nX\ns=1\nEsρE†\ns.\n(3.83)\nWe have found a more general way that density matrices can evolve. The operation\nρ →\nk\nX\ns=1\nEsρE†\ns,\nX\ns\nE†\nsEs = 1\n(3.84)\nis called a “quantum channel,” and the Es are called Kraus operators. Unitary evolution is the special\ncase in which there is only one Kraus operator.\nThe notion of a quantum channel is axiomatized in more complete treatments than we will give\nhere.9\nThe upshot of a general analysis is that the most general physically sensible evolution of a\ndensity matrix takes the form (3.84), provided one allows the generalization described at the end of\nsection 3.6 in which the Es are linear transformations from one Hilbert space H to another Hilbert\nspace H′.\nNow let ρ and σ be two diﬀerent density matrices on H. Let us ask what happens to the relative\nentropy S(ρ||σ) when we apply a quantum channel, mapping ρ and σ to\nρ′ =\nX\ns\nEsρE†\ns,\nσ′ =\nX\ns\nEsσE†\ns.\n(3.85)\nThe ﬁrst step of initialization, replacing ρ and σ by |1⟩⟨1| ⊗ρ and |1⟩⟨1| ⊗σ, does not change anything.\nThe second step, conjugating by a unitary matrix U, also does not change anything since relative entropy\n9In the most general case, a quantum channel is a “completely positive trace-preserving” (CPTP) map from density\nmatrices on one Hilbert space H to density matrices on another Hilbert space H′.\n24\n",
    "book_id": "a_mini-introduction_to_information_theory",
    "book_title": "A Mini-Introduction To Information Theory",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 46
  },
  {
    "chunk_full": "is invariant under conjugation. Finally, the last step was a partial trace, which can only reduce the\nquantum relative entropy. So relative entropy can only go down under a quantum channel:\nS(ρ||σ) ≥S(ρ′||σ′).\nThis is the most general statement of monotonicity of quantum relative entropy.\nWe conclude this section with some exercises to familiarize oneself with quantum channels.\n(1) Let ψ be any pure state of a given system. Find Kraus operators of a quantum channel that\nmaps any density matrix ρ to |ψ⟩⟨ψ|. (One way to implement this is to turn on a Hamiltonian for which\nψ is the ground state, and wait until the system relaxes to its ground state by releasing energy to the\nenvironment.)\n(2) Find Kraus operators of a quantum channel that maps any density matrix for a given system\n(with ﬁnite-dimensional Hilbert space) to a maximally mixed one, a multiple of the identity. (This can\narise as the outcome of suﬃciently random interaction of the system with its environment.)\n(3) Do the same for a quantum channel that, in a given basis, maps any k×k density matrix ρ = (ρij)\nto the corresponding diagonal density matrix ρD = diag(ρ11, ρ22, · · · , ρkk). (An idealized description of\na physical realization is as follows. A cavity is probed by atoms. Denote as |n⟩the state of the cavity\nwhen it contains n photons. Suppose that n is unchanged when an atom passes through the cavity, but\nthe ﬁnal state of the atom depends on n. The probability to ﬁnd the cavity in state |n⟩is unchanged by\nthe interaction with a passing atom, so in the basis {|n⟩}, the diagonal elements of the density matrix\nare unchanged. After many atoms have passed through the cavity, an observation of the atoms would\nreveal with high conﬁdence the number of photons in the cavity. Therefore, tracing over the atomic\nstates, the ﬁnal density matrix of the cavity is diagonal in the basis {|n⟩}. Regardless of what state the\ncavity begins in, it will end up with high probability in an eigenstate of the photon number operator,\nthough one cannot say what the eigenvalue will be.)\n(4) Show that the composition of two quantum channels is a quantum channel. If the ﬁrst channel\nhas Kraus operators Es, s = 1, · · · , p, and the second has Kraus operators E′\nt, t = 1, · · · , q, what are\nthe Kraus operators of the composite channel?\n(5) This and the next exercise involve quantum channels that map one Hilbert space to another.\nThe goal is to show that natural operations that are well-motivated in other ways can also be viewed\nas special cases of the evolution described in eqn. (3.84). First, given a Hilbert space H, construct a\nrather trivial quantum channel that maps density matrices on H to density matrices on a 1-dimensional\nHilbert space H0. Note that, since a density matrix is hermitian, positive-deﬁnite, and of trace 1, there\nis a unique density matrix on H0, namely the unit density matrix 1. Thus, given a Hilbert space H,\nﬁnd Kraus operators Es : H →H0 for a quantum channel that maps any density matrix ρ on H to\nthe density matrix 1 on H0. Once you have done this, show that a partial trace is a quantum channel\nin the following sense. If AB is a bipartite system with Hilbert space HA ⊗HB, ﬁnd Kraus operators\n25\n",
    "book_id": "a_mini-introduction_to_information_theory",
    "book_title": "A Mini-Introduction To Information Theory",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 47
  },
  {
    "chunk_full": "Es : HA ⊗HB →HA that implement the partial trace ρAB →ρA = TrBρAB. In other words, ﬁnd\noperators Es : HA ⊗HB →HA, satisfying P\ns E†\nsEs = 1 and P\ns EsρABE†\ns = TrB ρAB, for any ρAB.\n(6) Let A be a quantum system with Hilbert space HA, and let B be a second quantum system with\nHilbert space HB and some given density matrix ρB. Find Kraus operators Es : HA →HA ⊗HB for a\nquantum channel that combines a quantum system A with some other system B by mapping any given\ndensity matrix ρA on A to the density matrix ρA ⊗ρB on AB. (You might want to consider ﬁrst the\ntrivial case that HA is 1-dimensional.) An example of this is what happens whenever a system A under\nstudy is combined with some experimental apparatus B, which has been initialized in the state ρB.\n3.8\nThermodynamics And Quantum Channels\nAs an example of these considerations, let us suppose that σ is a thermal density matrix at some\ntemperature T = 1/β\nσ = 1\nZ exp(−βH).\n(3.86)\nSo log σ = −βH −log Z and therefore the relative entropy between any density matrix ρ and σ is\nS(ρ||σ) =Tr ρ(log ρ −log σ) = −S(ρ) + Trρ(βH + log Z)\n=β(E(ρ) −TS(ρ)) + log Z\n(3.87)\nwhere the average energy computed in the density matrix ρ is\nE(ρ) = Tr ρH.\n(3.88)\nWe deﬁne the free energy\nF(ρ) = E(ρ) −TS(ρ).\n(3.89)\nThe log Z term in eqn (3.87) is independent of ρ and gives a constant that ensures that S(σ||σ) = 0. So\nS(ρ||σ) = β(F(ρ) −F(σ)).\n(3.90)\nNow consider any evolution of the system, that is any quantum channel, that preserves thermal\nequilibrium at temperature β. Thus, this channel maps σ to itself, but it maps ρ to a generally diﬀerent\ndensity matrix ρ′. The relative entropy can only go down under a quantum channel, so\nS(ρ||σ) ≥S(ρ′||σ),\n(3.91)\nand therefore\nF(ρ) ≥F(ρ′).\n(3.92)\n26\n",
    "book_id": "a_mini-introduction_to_information_theory",
    "book_title": "A Mini-Introduction To Information Theory",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 48
  },
  {
    "chunk_full": "In other words, a quantum channel that preserves thermal equilibrium can only reduce the free\nenergy. This is an aspect of the second law of thermodynamics. If you stir a system in a way that maps\nthermal equilibrium at temperature T to thermal equilibrium at the same temperature, then it moves\nany density matrix closer to thermal equilibrium at temperature T.\nTo specialize further, take the temperature T = ∞, β = 0. (This makes sense for a system with a\nﬁnite-dimensional Hilbert space.) The thermal density matrix σ is then maximally mixed, a multiple of\nthe identity. For T →∞, F(ρ) ∼−TS(ρ). So in this case, reducing the free energy means increasing\nthe entropy. Thus a quantum channel that maps a maximally mixed density matrix to itself can only\nincrease the entropy. The condition that a channel maps a maximally mixed density matrix to itself\nis P\ns EsE†\ns = 1.\n(A channel satisfying this condition is called unital.\nBy contrast, the condition\nP\ns E†\nsEs = 1 is satisﬁed by all quantum channels.)\nAn example of a quantum channel that maps a maximally mixed density matrix to itself is the\nchannel that maps any density matrix ρ to the corresponding diagonal density matrix ρD (in some\nchosen basis). The fact that the entropy can only increase under such a channel implies the inequality\nS(ρ) ≤S(ρD) (eqn. (3.42)).\n4\nMore On Quantum Information Theory\nFrom this point, one could pursue many diﬀerent directions toward a deeper understanding of quantum\ninformation theory. This article will conclude with three topics that the author found helpful in gaining\ninsight about the meaning of formal deﬁnitions such as quantum conditional entropy and quantum rela-\ntive entropy. These concepts were deﬁned by formally imitating the corresponding classical deﬁnitions,\nand it is not really clear a priori what to expect of such formal deﬁnitions.\nA secondary reason for the choice of topics is to help the reader appreciate the importance of\nmonotonicity of quantum relative entropy – and its close cousin, strong subadditivity. At several points,\nwe will have to invoke monotonicity of relative entropy to prove that quantities like quantum mutual\ninformation and quantum relative entropy that have been deﬁned in a formal way do behave in a fashion\nsuggested by their names.\nThe three topics that we will consider are quantum teleportation and conditional entropy, relative\nentropy and quantum hypothesis testing, and the use of a quantum state to encode classical information.\n27\n",
    "book_id": "a_mini-introduction_to_information_theory",
    "book_title": "A Mini-Introduction To Information Theory",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 49
  },
  {
    "chunk_full": "4.1\nQuantum Teleportation and Conditional Entropy\nWe start with quantum teleportation [13]. For a ﬁrst example, imagine that Alice has in her pos-\nsession a qubit A0, a quantum system with a two-dimensional Hilbert space. Alice would like to help\nBob create in his lab a qubit in a state identical to A0. However, it is too diﬃcult to actually send a\nqubit; she can only communicate by sending a classical message over the telephone. If Alice knows the\nstate of her qubit, there is no problem: she tells Bob the state of her qubit and he creates one like it\nin his lab. If, however, Alice does not know the state of her qubit, she is out of luck. All she can do is\nmake a measurement, which will give some information about the prior state of qubit A0. She can tell\nBob what she learns, but the measurement will destroy the remaining information about A0 and it will\nnever be possible for Bob to recreate A0.\nSuppose, however, that Alice and Bob have previously shared a qubit pair A1B1 (Alice has A1, Bob\nhas B1) in a known entangled state, for example\nΨA1B1 = 1\n√\n2 (|0 0⟩+ |1 1⟩)A1B1 .\n(4.1)\nMaybe Alice created this pair in her lab and then Bob took B1 on the road with him, leaving A1 in\nAlice’s lab. In this case, Alice can solve the problem. To do so she makes a joint measurement of her\nsystem A0A1 in a basis that is chosen so that no matter what the answer is, Alice learns nothing about\nthe prior state of A0. In the process, she also loses no information about A0, since she had none before.\nBut as we will see, after getting her measurement outcome, she can tell Bob what to do to recreate A0.\nTo see how this works, let us describe a speciﬁc measurement that Alice can make on A0A1 that will\nshed no light on the state of A0. She can project A0A1 on the basis of four states\n1\n√\n2\n(|0 0⟩± |1 1⟩)A0A1 and\n1\n√\n2\n(|0 1⟩± |1 0⟩)A0A1.\n(4.2)\nTo see the result of a measurement, suppose the unknown state of qubit A0 is α|0⟩+ β|1⟩. So the initial\nstate of A0A1B1 is\nΨA0A1B1 = 1\n√\n2 (α|0 0 0⟩+ α|0 1 1⟩+ β|1 0 0⟩+ β|1 1 1⟩)A0A1B1 .\n(4.3)\nSuppose that the outcome of Alice’s measurement is to learn that A0A1 is in the state\n1\n√\n2(|0 0⟩−|1 1⟩)A0A1.\n(4.4)\nAfter the measurement, B1 will be in the state (α|0⟩−β|1⟩)B1. Knowing this, Alice can tell Bob that\nhe can recreate the initial state by acting on his qubit by\nΨB1 →\n\u00121\n0\n0\n−1\n\u0013\nΨB1\n(4.5)\n28\n",
    "book_id": "a_mini-introduction_to_information_theory",
    "book_title": "A Mini-Introduction To Information Theory",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 50
  },
  {
    "chunk_full": "in the basis |0⟩, |1⟩. The other cases are similar, as the reader can verify.\nWe will analyze a generalization, but ﬁrst it is useful to formalize in a diﬀerent way the idea that\nAlice is trying to teleport an arbitrary unknown quantum state. For this, we add another system R,\nto which Alice and Bob do not have access. We assume that R is maximally entangled with A0 in a\nknown state, say\nΨRA0 = 1\n√\n2 (|0 0⟩+ |1 1⟩)RA0 .\n(4.6)\nIn this version of the problem, Alice’s goal is to manipulate her system A0A1 in some way, and then tell\nBob what to do to his system B = B1 so that in the end the system RB1 will be in the same state\nΨRB1 = 1\n√\n2\n(|0 0⟩+ |1 1⟩)RB1\n(4.7)\nthat RA0 was previously – with R never being touched. In this version of the problem, the combined\nsystem RAB1 = RA0A1B1 starts in a pure state ΨRAB1 = ΨRA0 ⊗ΨA1B1. The solution of this version\nof the problem is the same as the other one: Alice makes the same measurements and sends the same\ninstructions as before.\nWe can understand better what is happening if we take a look at the conditional entropy of the\nsystem AB = A0A1B1. Since A1B1 is in a pure state, it does not contribute to SAB, so SAB = SA0 = 1\n(A0 is maximally mixed, since it is maximally entangled with R).\nAlso SB = 1 since B = B1 is\nmaximally entangled with A1. Hence\nS(A|B) = SAB −SB = 1 −1 = 0.\n(4.8)\nIt turns out that this is the key to quantum teleportation: teleportation, in a suitably generalized sense,\nis possible when and only when\nS(A|B) ≤0.\n(4.9)\nLet us explain ﬁrst why this is a necessary condition. We start with an arbitrary system RAB in\na pure state ΨRAB; Alice has access to A, Bob has access to B, and neither one has access to R. For\nteleportation, Alice might measure her system A using some rank 1 orthogonal projection operators\nπi. (If she makes a more general measurement, for example using projection operators of higher rank,\nthe system RB does not end up in a known pure state and she will not be able to give appropriate\ninstructions to Bob.) No matter what answer she gets, after the measurement, system A is in a pure\nstate and therefore RB is also in a pure state χRB, generally entangled. For teleportation, Alice has\nto choose the πi so that, no matter what outcome she gets, the density matrix ρR of R is the same as\nbefore. If this is so, then after her measurement, the state χRB of RB is a puriﬁcation of the original ρR.\nSince she knows her measurement outcome, Alice knows which entangled state is χRB and can convey\nthis information to Bob. Bob is then in possession of part B of a known puriﬁcation χRB of system R.\nHe makes in his lab a copy A′ of Alice’s original system A, initialized in a known pure state ΩA′, so\nnow he has part A′B of a known puriﬁcation eΨRA′B = ΩA′ ⊗χRB of ρR. By a unitary transformation of\n29\n",
    "book_id": "a_mini-introduction_to_information_theory",
    "book_title": "A Mini-Introduction To Information Theory",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 51
  },
  {
    "chunk_full": "system A′B, which Bob can implement in his lab, eΨRA′B can be converted into any other pure state of\nRA′B that puriﬁes the same ρR. (This was explained following eqn. (3.13).) So Bob can convert eΨRA′B\nto a copy of the original ΨRAB.\nBut do there exist projection operators of Alice’s system with the necessary properties? The initial\nstate ΨABR is pure so it has\nSAB = SR.\n(4.10)\nBob’s density matrix at the beginning is\nρB = TrRA ρRAB\n(4.11)\nwhere ρRAB is the initial pure state density matrix. By deﬁnition\nSB = S(ρB).\n(4.12)\nIf Alice gets measurement outcome i, then Bob’s density matrix after the measurement is\nρi\nB = 1\npi\nTrRA πiρRAB.\n(4.13)\nNote that\nρB =\nX\ni\npiρi\nB,\n(4.14)\nsince P\ni πi = 1. After the measurement, since A is in a pure state, RB is also in a pure state Ψi\nRB, so\nS(ρi\nB) = SR. But by hypothesis, the measurement did not change ρR, so SR is unchanged and so equals\nthe original SAB. Hence\nS(ρi\nB) = SAB.\n(4.15)\nIf all this is possible\nSAB = S(ρi\nB) =\nX\ni\npiS(ρi\nB).\n(4.16)\nThe concavity inequality (3.39) or equivalently positivity of the Holevo information (3.40) says that if\nρB = P\ni piρi\nB then\nS(ρB) ≥\nX\ni\npiS(ρi\nB).\n(4.17)\nSo if teleportation can occur,\nSAB =\nX\ni\npiS(ρi\nB) ≤S(ρB) = SB\n(4.18)\nand hence S(A|B) = SAB −SB ≤0.\nActually, S(A|B) ≤0 is suﬃcient as well as necessary for teleportation, in the following sense [14].\n(In this generality, what we are calling teleportation is known as state merging.) One has to consider the\n30\n",
    "book_id": "a_mini-introduction_to_information_theory",
    "book_title": "A Mini-Introduction To Information Theory",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 52
  },
  {
    "chunk_full": "problem of teleporting not a single system but N copies of the system for large N. (This is a common\ndevice in quantum information theory. It is a rough analog of the fact that to get simple statements in\nthe classical case in section 2, we had to consider a long message, obtained by sampling N times from\na probability distribution.) So one takes N copies of system RAB for large N, thus replacing RAB\nby R⊗NA⊗NB⊗N. This multiplies all the entropies by N, so it preserves the condition S(A|B) ≤0.\nNow Alice tries to achieve teleportation by making a complete projective measurement on her system\nA⊗N. It is very hard to ﬁnd an explicit set of projection operators πi with the right properties, but it\nturns out, remarkably, that for large N, a random choice will work (in the sense that with a probability\napproaching 1, the error in state merging is vanishing for N →∞). This statement actually has strong\nsubadditivity as a corollary [14]. This approach to strong subadditivity has been described in sections\n10.8-9 of [4].\nWe actually can now give a good explanation of the meaning of quantum conditional entropy S(A|B).\nRemember that classically S(A|B) measures how many additional bits of information Alice has to send\nto Bob after he has already received B, so that he will have full knowledge of A. We will ﬁnd a quantum\nanalog of this, but now involving qubits rather than classical bits. Suppose that S(A|B) > 0 and Alice\nnevertheless wants to share her state with Bob. Now we have to assume that Alice is capable of quantum\ncommunication, that is of sending a quantum system to Bob while maintaining its quantum state, but\nthat she wishes to minimize the amount of quantum communication she will need. She ﬁrst creates\nsome maximally entangled qubit pairs and sends half of each pair to Bob. Each time she sends Bob half\nof a pair, SAB is unchanged but SB goes up by 1, so S(A|B) = SAB −SB goes down by 1. So S(A|B),\nif positive, is the number of such qubits that Alice must send to Bob to make S(A|B) nonpositive and\nso make teleportation or state merging possible without any further quantum communication.\nIf S(A|B) is negative, teleportation or state merging is possible to begin with and −S(A|B) is the\nnumber of maximally entangled qubit pairs that Alice and Bob can be left with afterwards [14]. This\nmay be seen as follows. Alice creates an auxiliary system A′A′′, where A′ consists of n qubits that\nare completely entangled with another set of n qubits that comprise system A′′. Alice considers the\nproblem of teleporting to Bob the combined system A = A′′A, while leaving A′ untouched.\nSince\nS(A|B) = n + S(A|B), Alice observes that S(A|B) < 0 provided n < −S(A|B). Given this inequality,\nAlice can teleport A = A′′A to Bob, keeping A′ in reserve. At the end of this, Alice and Bob share n\nmaximally entangled qubit pairs, namely Alice’s system A′ and Bob’s copy of A′′. This description is a\nshorthand; it is implicit that at each stage, we are free to replace the system under consideration by the\ntensor product of N copies of itself, for some large N. As a result, integrality of n is not an important\nconstraint. A more precise statement of the conclusion is that for large N, after teleportation to Bob of\npart A⊗N of a composite system A⊗NB⊗N, Alice and Bob can be left with up to −NS(A|B) maximally\nentangled qubit pairs.\n31\n",
    "book_id": "a_mini-introduction_to_information_theory",
    "book_title": "A Mini-Introduction To Information Theory",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 53
  },
  {
    "chunk_full": "4.2\nQuantum Relative Entropy And Hypothesis Testing\nIn a somewhat similar way, we can give a physical meaning to the relative entropy S(ρ||σ) between\ntwo density matrices ρ, σ. Recall from section 2.3 that classically, if we believe a random variable is\ngoverned by a probability distribution Q but it is actually governed by a probability distribution P,\nthen after N trials the ability to disprove the wrong hypothesis is controlled by\n2−NS(P ||Q).\n(4.19)\nA similar statement holds quantum mechanically: if our initial hypothesis is that a quantum system\nX has density matrix σ, and the actual answer is ρ, then after N trials with an optimal measurement\nused to test the initial hypothesis, the conﬁdence that the initial hypothesis was wrong is controlled in\nthe same sense by\n2−NS(ρ||σ).\n(4.20)\nLet us ﬁrst see that monotonicity of relative entropy implies that one cannot do better than that [15].\nA measurement is a special case of a quantum channel, in the following sense. To measure a system X,\none lets it interact quantum mechanically with some other system Y C where Y is any quantum system\nand C is the measuring device. After they interact, one looks at the measuring device and forgets the\nrest. Forgetting the rest is a partial trace that maps a density matrix βXY C to βC = TrXY βXY C. If C\nis a good measuring device with n distinguishable quantum states, this means that in a distinguished\nbasis |α⟩, α = 1, · · · , n, its density matrix βC will have a diagonal form\nβC =\nX\nα\nbα|α⟩⟨α|.\n(4.21)\nThe “measurement” converts the original density matrix into the probability distribution {bα}.\nSo when we try to distinguish ρ from σ, we use a quantum channel plus partial trace (or simply a\nquantum channel, since a partial trace can be viewed as a quantum channel) that maps ρ and σ into\ndensity matrices for C\nρC =\nX\nα\nrα|α⟩⟨α|\nσC =\nX\nα\nsα|α⟩⟨α|,\n(4.22)\nand thereby into classical probability distributions R = {rα} and S = {sα}. We can learn that ρ and σ\nare diﬀerent is by observing that R and S are diﬀerent, a process controlled by\n2−NScl(R||S),\n(4.23)\nwhere Scl(R||S) is the classical relative entropy between R and S.\nThis is the same as the relative entropy between ρC and σC:\nS(ρC||σC) = Scl(R||S).\n(4.24)\n32\n",
    "book_id": "a_mini-introduction_to_information_theory",
    "book_title": "A Mini-Introduction To Information Theory",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 54
  },
  {
    "chunk_full": "And monotonicity of relative entropy gives\nS(ρ||σ) ≥S(ρC||σC).\n(4.25)\nSo if we follow this procedure, then S(ρ||σ) gives a bound on how well we can do:\n2−NScl(R||S) ≥2−NS(ρ||σ).\n(4.26)\nActually, quantum mechanics allows us to do something more sophisticated than making N repeated\nmeasurements of the system of interest. We could more generally make a joint measurement on all N\ncopies. Taking N copies replaces the Hilbert space H of the system under study by H⊗N, and replaces\nthe density matrices σ and ρ by σ⊗N and ρ⊗N. All entropies and relative entropies are multiplied by\nN. A joint measurement on N copies would convert a density matrix σ⊗N or ρ⊗N to a probability\ndistribution S[N] or R[N]. We will not learn much from a single joint measurement on N copies, since it\nwill just produce a random answer. But given NN′ copies of the system, we could repeat N′ times a joint\nmeasurement of N copies. The ability to distinguish S[N] from R[N] in N′ tries is controlled for large\nN′ by 2−N′Scl(R[N]||S[N]). The monotonicity of relative entropy gives 2−N′Scl(R[N]||S[N]) ≥2−N′S(ρ⊗N||σ⊗N) =\n2−b\nNS(ρ||σ), where b\nN = NN′. So also with such a more general procedure, the ability to disprove in b\nN\ntrials an initial hypothesis σ for a system actually described by ρ is bounded by 2−b\nNS(ρ||σ).\nIn the limit of large b\nN, it is actually possible to saturate this bound, as follows [16,17]. If ρ is diagonal\nin the same basis in which σ is diagonal, then by making a measurement that involves projecting on\n1-dimensional eigenspaces of σ, we could convert the density matrices ρ, σ into classical probability\ndistributions R, S with S(ρ||σ) = Scl(R||S). The quantum problem would be equivalent to a classical\nproblem, even without taking many copies. As usual the subtlety comes because the matrices are not\nsimultaneously diagonal. By dropping from ρ the oﬀ-diagonal matrix elements in some basis in which\nσ is diagonal, we can always construct a diagonal density matrix ρD. Then a measurement projecting\non 1-dimensional eigenspaces of σ will give probability distributions R, S satisfying\nS(ρD||σ) = Scl(R||S).\n(4.27)\nThis is not very useful, because it is hard to compare S(ρD||σ) to S(ρ||σ). That is why it is necessary\nto consider a joint measurement on N copies, for large N, which makes possible an easier alternative to\ncomparing S(ρD||σ) to S(ρ||σ), as we will see.\nLet us recall the deﬁnition of relative entropy:\nS(ρ⊗N||σ⊗N) = Tr ρ⊗N log ρ⊗N −Tr ρ⊗N log σ⊗N.\n(4.28)\nThe second term Tr ρ⊗N log σ⊗N is unchanged if we replace ρ⊗N by its counterpart ρ⊗N\nD\nthat is diagonal\nin the same basis as σ⊗N. So\nS(ρ⊗N||σ⊗N) −S(ρ⊗N\nD ||σ⊗N) = Trρ⊗N log ρ⊗N −Trρ⊗N\nD\nlog ρ⊗N\nD .\n(4.29)\n33\n",
    "book_id": "a_mini-introduction_to_information_theory",
    "book_title": "A Mini-Introduction To Information Theory",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 55
  },
  {
    "chunk_full": "For large N, we will be able to get a useful bound on the right hand side.\nRoughly speaking, there is simpliﬁcation for large N because group theory can be used to simulta-\nneously put ρ⊗N and σ⊗N in a block diagonal form with relatively small blocks. This will make possible\nthe comparison we need. In more detail, the group SN of permutations of N objects acts in an obvious\nway on H⊗N. It commutes with the action on H⊗N of U(k), the group of unitary transformations of\nthe k-dimensional Hilbert space H. Schur-Weyl duality gives the decomposition of H⊗N in irreducible\nrepresentations of SN ×U(k). Every Young diagram Y with N boxes and at most k rows determines an\nirreducible representation λY of SN and an irreducible representation µY of U(k). The decomposition\nof H⊗N in irreducibles of SN × U(k) is\nH⊗N = ⊕YλY ⊗µY.\n(4.30)\nThe λY of distinct Y are non-isomorphic, and the same is true of the µY. Let aY and bY be, respectively,\nthe dimension of λY and of µY. The maximum value of bY is bounded10 by a power of N:\nbmax ≤(N + 1)k(k−1)/2.\n(4.31)\nThe important point will be that bmax grows only polynomially for N →∞, not exponentially. In\ncontrast, the numbers aY can be exponentially large for large N.\nEqn. (4.30) gives a decomposition of H⊗N as the direct sum of subspaces of dimension aYbY. Since\nρ⊗N and σ⊗N commute with SN, they are block diagonal with respect to this decomposition. But more\nspeciﬁcally, the fact that ρ⊗N and σ⊗N commute with SN means that each aYbY × aYbY block is just\nthe direct sum of aY identical blocks of size bY × bY. So ρ⊗N has a decomposition\nρ⊗N =\n\n\n\n\n\np1ρ1\np2ρ2\np3ρ3\n...\n\n\n\n\n\n(4.32)\nin blocks of size bY ⊗bY, with each such block occurring aY times, for all possible Y. (The total number\nof blocks is P\nY aY.) The ρi are density matrices and the pi are nonnegative numbers adding to 1. In\n10See eqn.\n(6.16) of [17].\nOne approach to this upper bound is as follows.\nIn general, the highest weight of an\nirreducible representation of the group SU(k) is a linear combination of certain fundamental weights with nonnegative\ninteger coeﬃcients ai, i = 1, · · · , k−1. In the case of a representation associated to a Young diagram with N boxes, the ai\nare bounded by N. The dimension of an irreducible representation with highest weights (a1, a2, · · · , ak−1) is a polynomial\nin the ai of total degree k(k−1)/2, so if all ai are bounded by N, the dimension is bounded by a constant times N k(k−1)/2.\nOne way to prove that the dimension is a polynomial in the ai of the stated degree is to use the Borel-Weil-Bott theorem.\nAccording to this theorem, a representation with highest weights (a1, a2, · · · , ak−1) can be realized as H0(F, ⊗k−1\ni=1 Lai\ni ),\nwhere F = SU(k)/U(1)k−1 is the ﬂag manifold of the group SU(k) and Li →F are certain holomorphic line bundles.\nBecause F has complex dimension k(k −1)/2, the Riemann-Roch theorem says that the dimension of H0(F, ⊗k−1\ni=1 Lai\ni ) is\na polynomial in the ai of that degree.\n34\n",
    "book_id": "a_mini-introduction_to_information_theory",
    "book_title": "A Mini-Introduction To Information Theory",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 56
  },
  {
    "chunk_full": "the same basis, σ⊗N has just the same sort of decomposition:\nσ⊗N =\n\n\n\n\n\nq1σ1\nq2σ2\nq3σ3\n...\n\n\n\n\n.\n(4.33)\nWe can furthermore make a unitary transformation in each block to diagonalize σ⊗N. This will generi-\ncally not diagonalize ρ⊗N. But because ρ⊗N is block diagonal with relatively small blocks, its entropy\ncan be usefully compared with that of the diagonal density matrix (ρ⊗N)D that is obtained by setting\nto 0 the oﬀ-diagonal matrix elements of ρ⊗N in a basis in which σ⊗N is diagonal within each block and\nkeeping the diagonal ones:\n(ρ⊗N)D =\n\n\n\n\n\np1ρ1,D\np2ρ2,D\np3ρ3,D\n...\n\n\n\n\n.\n(4.34)\nOne ﬁnds then\nTrρ⊗N log ρ⊗N −Tr(ρ⊗N)D log(ρ⊗N\nD ) =\nX\ni\npi(S(ρiD) −S(ρi)).\n(4.35)\nIt is important that a potentially large term P\ni pi log pi cancels out here. Any density matrix on an\nn-dimensional space has an entropy S bounded by 0 ≤S ≤log n. Because the sizes of the blocks are\nbounded above by bmax ∼Nk(k−1)/2, and P\ni pi = 1, the right hand side11 of eqn. (4.35) is bounded by\nlog bmax ∼1\n2k(k −1) log N, which for large N is negligible compared to N.\nCombining this with eqns. (4.27) and (4.29), we see that for large N, a measurement that projects\nonto 1-dimensional eigenspaces of σi within each block maps the density matrices ρ⊗N and σ⊗N to\nclassical probability distributions R[N] and S[N] such that the quantum relative entropy S(ρ⊗N||σ⊗N) and\nthe classical relative entropy S(R[N]||S[N]) are asymptotically equal. To be more precise, S(ρ⊗N||σ⊗N) =\nNS(ρ||σ) is of order N for large N, and diﬀers from S(R[N]||S[N]) by at most a constant times log N.\nIn other words\nS(ρ||σ) = 1\nN S(ρ⊗N||σ⊗N) = 1\nN S(R[N]||S[N]) + O\n\u0012log N\nN\n\u0013\n.\n(4.36)\nOnce we have identiﬁed a measurement that converts the quantum relative entropy (for N copies of\nthe original system) to a classical relative entropy, we take many copies again and invoke the analysis\nof classical relative entropy in section 2.3. In more detail, consider a composite system consisting of\n11The right hand side is actually positive because of the inequality (3.42).\n35\n",
    "book_id": "a_mini-introduction_to_information_theory",
    "book_title": "A Mini-Introduction To Information Theory",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 57
  },
  {
    "chunk_full": "N copies of the original system. Suppose that we observe N′ copies of this composite system (making\nNN′ copies of the original system), for very large N′. On each copy of the composite system, we make\nthe above-described measurement. This means that we sample N′ times from the classical probability\ndistribution S[N] (if the original hypothesis σ was correct) or R[N] (if the original system was actually\ndescribed by ρ). According to the classical analysis in section 2.3, the ability to distinguish between R[N]\nand S[N] in N′ trials is controlled by 2−N′S(R[N]||S[N]). According to eqn. (4.36), this is asymptotically\nthe same as 2−N′S(ρ⊗N||σ⊗N) = 2−NN′S(ρ||σ). In short, we learn that after a suitable measurement on\nb\nN = NN′ copies of the original system, we can distinguish between the hypotheses σ and ρ with a\npower\n2−b\nNS(ρ||σ),\n(4.37)\nsaturating the upper bound (4.26) (with the total number of trials now being b\nN rather than N). In the\nexponent, there are errors of order N′ log N (from the logarithmic correction in (4.36)) and N log N′\n(coming from the fact that the classical analysis of section 2.3, which for instance used only the leading\nterm in Stirling’s formula, has corrections of relative order\n1\nN′ log N′).\nThis conﬁrms that quantum relative entropy has the same interpretation as classical relative entropy:\nit controls the ability to show, by a measurement, that an initial hypothesis is incorrect. A noteworthy\nfact [16] is that the measurement that must be made on the composite system to accomplish this depends\nonly on σ (the initial hypothesis) and not on ρ (the unknown answer).\nAt the outset, we assumed monotonicity of relative entropy and deduced from it an upper bound\n(4.20) on how well one can distinguish two density matrices in N trials. Actually, now that we know\nthat the upper bound is attainable, one can reverse the argument and show that this upper bound\nimplies monotonicity of relative entropy. Suppose that AB is a bipartite system with density matrices\nρAB, σAB that we want to distinguish by a measurement. One thing that we can do is to forget system\nB and just make measurements on A. The above argument shows that, after taking N copies, the\nreduced density matrices ρA = TrB ρAB, σA = TrB σAB can be distinguished at the rate 2−NS(ρA||σA).\nBut since measurements of subsystem A are a special case of measurements of AB, this implies that\nρAB and σAB can be distinguished at the rate 2−NS(ρA||σA). If therefore we know the bound (4.20),\nwhich says that ρAB and σAB cannot be distinguished at a faster rather than 2−NS(ρAB||σAB), then the\nmonotonicity inequality S(ρAB||σAB) ≥S(ρA||σA) follows. In [18], monotonicity of relative entropy has\nbeen proved by giving an independent proof of the upper bound on how well two density matrices can\nbe distinguished.\n4.3\nEncoding Classical Information In A Quantum State\nFinally, we will address the following question: how many bits of information can Alice send to Bob by\nsending him a quantum system X with a k-dimensional Hilbert space H? (See [4], especially section\n10.6, for more on this and related topics.)\n36\n",
    "book_id": "a_mini-introduction_to_information_theory",
    "book_title": "A Mini-Introduction To Information Theory",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 58
  },
  {
    "chunk_full": "One thing Alice can do is to send one of k orthogonal basis vectors in H. Bob can ﬁnd which one\nshe sent by making a measurement. So in that way Alice can send log k bits of information. We will\nsee that in fact it is not possible to do better.\nWe suppose that Alice wants to encode a random variable that takes the values xi, i = 1, . . . , n with\nprobability pi. When the value is xi, she writes down this fact in her notebook C and creates a density\nmatrix ρi\nX on system X. If |i⟩is the state of the notebook when Alice has written the value xi, then on\nthe combined system CX, Alice has created the density matrix\nρCX =\nX\ni\npi|i⟩⟨i| ⊗ρi\nX\n(4.38)\nThen Alice sends the system X to Bob. Bob’s task is to somehow extract information by making a\nmeasurement.\nBefore worrying about what Bob can do, let us observe that the density matrix ρCX of the system\nCX is the one (eqn. (3.56)) that was used earlier in discussing the entropy inequality for mixing. It\nis sometimes called a classical-quantum density matrix. The reduced density matrix of X is ρX =\nTrC ρCX = P\ni piρi\nX. As before, the mutual information between C and X is the Holevo information\nI(C; X) = S(ρX) −\nX\ni\npiS(ρi\nX).\n(4.39)\nSince S(ρi\nX) ≥0 and S(ρX) ≤log k, it follows that\nI(C; X) ≤log k.\n(4.40)\nIf we knew that quantum mutual information has a similar interpretation to classical mutual information,\nwe would stop here and say that since I(C; X) ≤log k, at most log k bits of information about the\ncontents of Alice’s notebook have been encoded in X. However, we aim to demonstrate that quantum\nmutual information behaves like classical mutual information, at least in this respect, not to assume it.\nAs we will see, what we want is precisely what monotonicity of mutual information says, in the present\ncontext.\nWhat can Bob do on receiving system X? The best he can do is to combine it with some other\nsystem which may include a quantum system Y and a measuring apparatus C′. He acts on the combined\nsystem XY C′ with some unitary transformation or more general quantum channel and then reads C′.\nThe combined operation is a quantum channel. As in our discussion of relative entropy, the outcome of\nthe channel is a density matrix of the form\nρC′ =\nr\nX\nα=1\nqα|α⟩⟨α|,\n(4.41)\nwhere |α⟩are distinguished states of C′ – the states that one reads in a classical sense. The outcome of\nBob’s measurement is a probability distribution {qα} for a random variable whose values are labeled by\n37\n",
    "book_id": "a_mini-introduction_to_information_theory",
    "book_title": "A Mini-Introduction To Information Theory",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 59
  },
  {
    "chunk_full": "α. What Bob learns about the contents of Alice’s notebook is the classical mutual information between\nAlice’s probability distribution {pi} and Bob’s probability distribution {qα}. Diﬀerently put, what Bob\nlearns is the mutual information I(C; C′).\nTo analyze this, we note that before Bob does anything, I(C; X) is the same as I(C; XY C′) because\nY C′ (Bob’s auxiliary quantum system Y and his measuring apparatus C′) is not coupled to CX. In\nmore detail, the initial description of the combined system CXY C′ is by the tensor product of a density\nmatrix ρCX for CX and a density matrix ρY C′ for Y C′. As one can deduce immediately from the\ndeﬁnitions, the mutual information between C and XY C′ if the full system CXY C′ is described by\nρCX ⊗ρY C′ is the same as the mutual information between C and X if the subsystem CX is described\nby ρCX. Bob then acts on XY C′ with a unitary transformation, or maybe a more general quantum\nchannel, which can only reduce the mutual information. Then he takes a partial trace over XY , which\nalso can only reduce the mutual information, since monotonicity of mutual information under partial\ntrace tells us that\nI(C; XY C′) ≥I(C; C′).\n(4.42)\nSo\nlog k ≥I(C; X) = I(C; XY C′)before ≥I(C; XY C′)after ≥I(C; C′)after,\n(4.43)\nwhere “before” and “after” mean before and after Bob’s manipulations. More brieﬂy, any way that\nBob processes the signal he receives can only reduce the mutual information. Thus Alice cannot encode\nmore than log k bits of classical information in an k-dimensional quantum state, though it takes strong\nsubadditivity (or its equivalents) to prove this.\nThe problem that we have discussed also has a more symmetrical variant. In this version, Alice and\nBob share a bipartite state AB; Alice has access to A and Bob has access to B. The system is initially\ndescribed by a density matrix ρAB.\nAlice makes a generalized measurement of A and Bob makes\na generalized measurement of B. What is the maximum amount of information that Alice’s results\nmay give her about Bob’s measurements, and vice-versa?\nAn upper bound is given by the mutual\ninformation I(A; B) in the initial density matrix ρAB. Alice’s measurements amount to a quantum\nchannel mapping her system A to her measurement apparatus C; Bob’s measurements amount to a\nquantum channel mapping his system B to his measurement apparatus C′. The mutual information\nbetween their measurement outcomes is simply the mutual information I(C; C′) in the ﬁnal state.\nMonotonicity of mutual information in any quantum channel says that this can only be less than the\ninitial I(A; B).\nA more subtle issue is the extent to which these upper bounds can be saturated. For an introduction\nto such questions see [4], section 10.6.\nResearch supported in part by NSF Grant PHY-1606531. I thank N. Arkani-Hamed, J. Cotler, B.\nCzech, M. Headrick, and R. Witten for discussions. I also thank M. Hayashi, as well as the referees, for\nsome explanations and helpful criticisms and for a careful reading of the manuscript.\n38\n",
    "book_id": "a_mini-introduction_to_information_theory",
    "book_title": "A Mini-Introduction To Information Theory",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 60
  },
  {
    "chunk_full": "References\n[1] M. A. Nielsen and I. L. Chuang, Quantum Computation And Quantum Information (Cambridge\nUniversity Press, 2000).\n[2] T. M. Cover and J. A. Thomas, Elements Of Information Theory (John Wiley & Sons, second\nedition, 2006).\n[3] M. M. Wilde, Quantum Information Theory (Cambridge University Press, second edition, 2017).\n[4] J. Preskill, lecture notes, available at http://www.theory.caltech.edu/~preskill/ph219/index.html#lec\n[5] C. E. Shannon, “A Mathematical Theory Of Communication,” Bell System Technical Journal 27\n(1918) 379-423 and 623-656.\n[6] M. F. Leifer and R. W. Spekkens, “Towards A Formulation Of Quantum Theory As A Causally\nNeutral Theory of Bayesian Inference,” Phys. Rev. A88 (2013) 052130, arXiv:1107.5849.\n[7] A. S. Holevo, “Bounds For The Quantity of Information Transmitted By A Quantum Communi-\ncation Channel,” Problems of Information Transmission 9 (1973) 177-83.\n[8] H. Araki and E. H. Lieb, “Entropy Inequalities,” Commun. Math. Phys. 18 (1970) 160-70.\n[9] H. Umegaki, “Conditional Expectation in an Operator Algebra,”’ Kodai Math. Sem. Rep. 14 (1962)\n59-85.\n[10] E. H. Lieb and M. B. Ruskai, “Proof Of The Strong Subadditivity Of Quantum Mechanical En-\ntropy,” J. Math. Phys. 14 (1973) 1938.\n[11] E. H. Lieb, “Convex Trace Functions and the Wigner-Yanase-Dyson Conjecture,” Adv. Math. 11\n(1973) 267-88.\n[12] E. Witten, “Notes On Some Entanglement Properties Of Quantum Field Theory,” Rev. Mod. Phys.\n90 (2018) 045003, arXiv:1803.04993.\n[13] C. H. Bennett, G. Brassard, C. Cr´epeau, R. Jozsa, A. Peres, and W. K. Wootters, “Teleporting an\nUnknown Quantum State Via Dual Classical and Einstein-Podolsky-Rosen Channels,” Phys. Rev.\nLett. 70 (1993) 1895-9.\n[14] M. Horodecki, J. Oppenheim, and A. Winter, “Quantum State Merging And Negative Information,”\nCommun. Math. Phys. 269 (2007) 107-36, arXiv:quant-ph/0512247.\n[15] F. Hiai and D. Petz, “The Proper Formula For Relative Entropy And Its Asymptotics in Quantum\nProbability,” Commun. Math. Phys. 143 (1991) 99-114.\n[16] M. Hayashi, “Asymptotics of Quantum Relative Entropy From Representation Theoretical View-\npoint,” J. Phys. A34 (2001) 3413-20.\n[17] M. Hayashi, A Group Theoretic Approach To Quantum Information (Springer, 2017).\n[18] I. Bjelakovic and R. Siegmund-Schultze, “Quantum Stein’s Lemma Revisited, Inequalities For\nQuantum Entropies, and a Concavity Theorem of Lieb,” quant-ph/0307170.\n39\n",
    "book_id": "a_mini-introduction_to_information_theory",
    "book_title": "A Mini-Introduction To Information Theory",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 61
  },
  {
    "chunk_full": "Complexity Theory, Game Theory,\nand Economics\nLecture Notes for the 29th McGill Invitational\nWorkshop on Computational Complexity\nLectures by Tim Roughgarden, with a guest lecture by Omri Weinstein\nBellairs Institute\nHoletown, Barbados\n \nISSN 1433-8092 \nElectronic Colloquium on Computational Complexity, Report No. 1 (2018)\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 62
  },
  {
    "chunk_full": "Foreword\nThis document collects the lecture notes from my mini-course “Complexity Theory, Game Theory, and\nEconomics,” taught at the Bellairs Research Institute of McGill University, Holetown, Barbados, February\n19–23, 2017, as the 29th McGill Invitational Workshop on Computational Complexity.\nThe goal of this mini-course is twofold:\n(i) to explain how complexity theory has helped illuminate several barriers in economics and game theory;\nand\n(ii) to illustrate how game-theoretic questions have led to new and interesting complexity theory, including\nseveral breakthroughs in the past few months!\nIt consists of two ﬁve-lecture sequences: the Solar Lectures, focusing on the communication and computa-\ntional complexity of computing equilibria; and the Lunar Lectures, focusing on applications of complexity\ntheory in game theory and economics.1 No background in game theory is assumed.\nThanks are due to many people: Denis Therien and Anil Ada for organizing the workshop and for\ninviting me to lecture; Omri Weinstein, for giving a guest lecture on simulation theorems in communication\ncomplexity; Alex Russell, for coordinating the scribe notes; the scribes2, for putting together a terriﬁc\nﬁrst draft of these notes; and all of the workshop attendees, for making the experience so unforgettable (if\nintense!).\nThe writing of these notes was supported in part by NSF award CCF-1524062, a Google Faculty Research\nAward, and a Guggenheim Fellowship. I would be very happy to receive any comments or corrections from\nreaders.\nTim Roughgarden\nBracciano, Italy\nDecember 2017\n1Cris Moore: “So when are the stellar lectures?”\n2Anil Ada, Amey Bhangale, Shant Boodaghians, Sumegha Garg, Valentine Kabanets, Antonina Kolokolova, Michal Koucký,\nCristopher Moore, Pavel Pudlák, Dana Randall, Jacobo Torán, Salil Vadhan, Joshua R. Wang, and Omri Weinstein.\n2\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 63
  },
  {
    "chunk_full": "Contents\nI\nSolar Lectures\n5\n1\nIntroduction, Wish List, and Two-Player Zero-Sum Games\n6\n1.1\nThe Plan . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n6\n1.2\nNash Equilibria in Two-Player Zero-Sum Games . . . . . . . . . . . . . . . . . . . . . . . .\n8\n1.3\nUncoupled Dynamics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n12\n1.4\nGeneral Bimatrix Games . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n18\n1.5\nApproximate Nash Equilibria in Bimatrix Games . . . . . . . . . . . . . . . . . . . . . . .\n19\n2\nCommunication Complexity Lower Bound for Computing an Approximate Nash Equilibrium\nof a Bimatrix Game (Part I)\n22\n2.1\nPreamble\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n22\n2.2\nNaive Approach: Reduction From Disjointness . . . . . . . . . . . . . . . . . . . . . . . .\n23\n2.3\nFinding Brouwer Fixed Points (The ϵ-BFP Problem)\n. . . . . . . . . . . . . . . . . . . . .\n24\n2.4\nThe End-of-the-Line (EoL) Problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n26\n2.5\nRoad Map for the Proof of Theorem 2.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n28\n2.6\nStep 1: Query Lower Bound for EoL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n29\n2.7\nStep 2: Communication Complexity Lower Bound for 2EoL via a Simulation Theorem . . .\n30\n3\nCommunication Complexity Lower Bound for Computing an Approximate Nash Equilibrium\nof a Bimatrix Game (Part II)\n33\n3.1\nStep 3: 2EoL ≤ϵ-2BFP\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n33\n3.2\nStep 4: ϵ-2BFP ≤ϵ-NE . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n38\n4\nTFNP, PPAD & All That\n43\n4.1\nPreamble\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n43\n4.2\nTFNP and Its Subclasses\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n44\n4.3\nPPAD and Its Complete Problems\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n46\n4.4\nEvidence of Hardness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n49\n5\nThe Computational Complexity of Computing an Approximate Nash Equilibrium\n53\n5.1\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n53\n5.2\nProof of Theorem 5.1: An Impressionistic Treatment . . . . . . . . . . . . . . . . . . . . .\n54\n3\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 64
  },
  {
    "chunk_full": "II\nLunar Lectures\n61\n1\nHow Computer Science Has Inﬂuenced Real-World Auction Design.\nCase Study: The 2016–2017 FCC Incentive Auction\n62\n1.1\nPreamble\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n62\n1.2\nReverse Auction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n62\n1.3\nForward Auction\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n65\n2\nCommunication Barriers to Near-Optimal Equilibria\n69\n2.1\nWelfare Maximization in Combinatorial Auctions . . . . . . . . . . . . . . . . . . . . . . .\n69\n2.2\nCommunication Lower Bounds for Approximate Welfare Maximization . . . . . . . . . . .\n70\n2.3\nLower Bounds on the Price of Anarchy of Simple Auctions . . . . . . . . . . . . . . . . . .\n73\n2.4\nAn Open Question\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n77\n2.5\nAppendix: Proof of Theorem 2.2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n78\n3\nWhy Prices Need Algorithms\n79\n3.1\nMarkets with Indivisible Items . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n79\n3.2\nComplexity Separations Imply Non-Existence of Walrasian Equilibria . . . . . . . . . . . .\n82\n3.3\nProof of Theorem 3.5 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n83\n3.4\nBeyond Walrasian Equilibria . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n85\n4\nThe Borders of Border’s Theorem\n87\n4.1\nOptimal Single-Item Auctions\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n87\n4.2\nBorder’s Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n89\n4.3\nBeyond Single-Item Auctions: A Complexity-Theoretic Barrier . . . . . . . . . . . . . . . .\n94\n4.4\nAppendix: A Combinatorial Proof of Border’s Theorem\n. . . . . . . . . . . . . . . . . . .\n97\n5\nTractable Relaxations of Nash Equilibria\n99\n5.1\nPreamble\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n99\n5.2\nUncoupled Dynamics Revisited . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n99\n5.3\nCorrelated and Coarse Correlated Equilibria . . . . . . . . . . . . . . . . . . . . . . . . . . 101\n5.4\nComputing an Exact Correlated or Coarse Correlated Equilibrium . . . . . . . . . . . . . . 102\n5.5\nThe Price of Anarchy of Coarse Correlated Equilibria . . . . . . . . . . . . . . . . . . . . . 105\nBibliography\n107\n4\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 65
  },
  {
    "chunk_full": "Part I\nSolar Lectures\n5\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 66
  },
  {
    "chunk_full": "Solar Lecture 1\nIntroduction, Wish List, and Two-Player Zero-Sum Games\nLecturer: Tim Roughgarden\nScribe: Anil Ada and Shant Boodaghians\n1.1\nThe Plan\nThe topic of the week is Complexity Theory, Game Theory, and Economics. The theme is two-fold:\n(i) how complexity theory has illuminated barriers in economics and game theory;\n(ii) how studying fundamental complexity questions about game-theoretic concepts has led to the devel-\nopment of new and interesting complexity theory (including some major breakthroughs in the past few\nmonths!).\nThere will be 5 solar lectures and 5 lunar lectures. The solar lectures will focus on the communication\nand computational complexity of computing an (approximate) Nash equilibrium. The lunar lectures are\nmeant to be understandable even after consuming a rum punch; they focus on applications of computational\ncomplexity theory to game theory and economics.\n1.1.1\nThe Solar Lectures: Complexity of Equilibria\nLecture 1: Introduction and wish list.\nThe goal of the ﬁrst lecture is to get the lay of the land. We’ll focus\non the types of positive results about equilibria that we want, like fast algorithms and quickly converging\ndistributed processes. Such positive results are possible in special cases (like zero-sum games), and the\nchallenge for complexity theory is to prove that they cannot be extended to the general case. The topics in\nthis lecture are mostly classical.\nLectures 2 and 3: The communication complexity of Nash equilibria.\nThese two lectures cover the\nmain ideas in the brand-new (STOC ’17) paper of Babichenko and Rubinstein [9], which proves strong\ncommunication complexity lower bounds for computing an approximate Nash equilibrium. Discussing the\nproof will also give us an excuse to talk about “simulation theorems” in the spirit of Raz and McKenzie [120],\nwhich lift query complexity lower bounds to communication complexity lower bounds and have recently\nfound a number of exciting applications.\n6\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 67
  },
  {
    "chunk_full": "Lecture 4: TFNP, PPAD, and all that.\nIn this lecture we begin our study of the computational complexity\nof computing a Nash equilibrium, where we want conditional but super-polynomial lower bounds. To prove\nanalogs of NP-completeness results, we will need to develop customized complexity classes appropriate for\nthe study of equilibrium computation.1 We will also discuss the existing evidence for the intractability of\nthese complexity classes, including some very recent developments.\nLecture 5: The computational complexity of computing an approximate Nash equilibrium of a bima-\ntrix game.\nThe goal of this lecture is to give a high-level overview of Rubinstein’s recent breakthrough\nresult [135] that an ETH-type assumption for PPAD implies a quasi-polynomial-time lower bound for the\nproblem of computing an approximate Nash equilibrium (which is tight, by Corollary 1.17).\n1.1.2\nThe Lunar Lectures: Complexity-Theoretic Barriers in Economics\nMost of the lunar lectures have the ﬂavor of “applied complexity theory.”2 While the solar lectures build on\neach other to some extent, the lunar lectures will be episodic, and each can be read independently.\nLecture 1: The 2016 FCC Incentive Auction.\nThis is a great case study of how computer science has\ninﬂuenced real-world auction design. It is also the only lecture that gives a broader glimpse of the vibrant ﬁeld\ncalled algorithmic game theory, only about 10% of which concerns the complexity of computing equilibria.\nLecture 2: Barriers to near-optimal equilibria [126].\nThis lecture concerns the “price of anarchy,”\nmeaning the extent to which Nash equilibria approximate an optimal outcome. It turns out that nondeter-\nministic communication complexity lower bounds can be translated, in black-box fashion, to lower bounds\non the price of anarchy. We’ll see how this translation enables a theory of “optimal simple auctions.”\nLecture 3: Barriers in markets [131].\nYou’ve surely heard of the idea of “market-clearing prices,” which\nare prices in a market such that supply equals demand. When the goods are divisible (milk, wheat, etc.),\nmarket-clearing prices exist under relatively mild technical assumptions. With indivisible goods (houses,\nspectrum licenses, etc.), market-clearing prices may or may not exist. It turns out complexity considerations\nplay a huge role in when prices exist and when they do not. This is cool and surprising because the issue\nof equilibrium existence seems to have nothing to do with computation (in contrast to the Solar Lectures,\nwhere the questions studied are explicitly about computation).\nLecture 4: The borders of Border’s theorem. [68].\nBorder’s theorem is a famous result in auction theory\nfrom 1991, about single-item auctions. Despite its fame, no one has been able to generalize it to signiﬁcantly\nmore general settings. We’ll see that complexity theory explains this mystery: signiﬁcantly generalizing\nBorder’s theorem would imply that the polynomial hierarchy collapses!\nLecture 5: Tractable Relaxations of Nash Equilibria.\nHaving spent the week largely on negative results\nfor computing Nash equilibria, for an epilogue we’ll switch to positive results for relaxations of Nash\nequilibria, such as for correlated equilibria.\n1Why can’t we just use the theory of NP-completeness?\nBecause the guaranteed existence (Theorem 1.14) and eﬃcient\nveriﬁability of a Nash equilibrium imply that computing one is an easier task than solving an NP-complete problems, under\nappropriate complexity assumption (see Theorem 4.1).\n2Not an oxymoron!\n7\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 68
  },
  {
    "chunk_full": "1.2\nNash Equilibria in Two-Player Zero-Sum Games\n1.2.1\nPreamble\nTo an algorithms person (like your lecturer), complexity theory is the science of why you can’t get what you\nwant. So what is it we want? Let’s start with some cool positive results for a very special class of games—\ntwo-player zero-sum games—and then we can study whether or not they extend to more general games. For\nthe ﬁrst positive result, we’ll review the famous Minimax theorem, and see how it leads to a polynomial-time\nalgorithm for computing a Nash equilibrium of a two-player zero-sum game. Then we’ll show that there\nare natural “dynamics” (basically, a distributed algorithm) that converge rapidly to an approximate Nash\nequilibrium.\n1.2.2\nRock-Paper-Scissors\nRecall the game rock-paper-scissors (or roshambo, if you like)3: there are two players, each simultaneously\npicks a strategy from {rock, paper, scissors}. If both players choose the same strategy then the game is a\ndraw; otherwise, rock beats scissors, scissors beats paper, and paper beats rock.4\nHere’s an idea: how about we play rock-paper-scissors, and you go ﬁrst? This is clearly unfair—no\nmatter what strategy you choose, I have a response that guarantees victory. But what if you only have to\ncommit to a probability distribution over your three strategies (called a mixed strategy)? To be clear, the\norder of operations is: (i) you pick a distribution; (ii) I pick a response; (iii) nature ﬂips coins to sample a\nstrategy from your distribution. Now you can protect yourself—by picking a strategy uniformly at random,\nno matter what I do, you have an equal chance of a win, a loss, or a draw.\nThe Minimax theorem states that, in any game of “pure competition” like rock-paper-scissors, a player\ncan always protect herself with a suitable randomized strategy—there is no disadvantage of having to move\nﬁrst. The proof of the Minimax theorem will also give as a byproduct a polynomial-time algorithm for\ncomputing a Nash equilibrium (by linear programming).\n1.2.3\nFormalism\nWe specify a two-player zero-sum game with an m × n payoﬀmatrix A of numbers. The rows correspond to\nthe possible choices of Alice (the “row player”) and the columns correspond to possible choices for Bob (the\n“column player”). Entry Ai j contains Alice’s payoﬀwhen Alice chooses row i and Bob chooses column j.\nIn a zero-sum game, Bob’s payoﬀis automatically deﬁned to be −Ai j (when Alice chooses row i and Bob\nchooses column j). Throughout the solar lectures, we normalize the payoﬀmatrix so that |Ai j| ≤1 for all i\nand j.5\nFor example, the payoﬀmatrix corresponding to rock-paper-scissors is:\n3https://en.wikipedia.org/wiki/Rock-paper-scissors\n4Here are some fun facts about rock-paper-scissors. There’s a World Series of RPS every year, with a top prize of at least $50K.\nIf you watch some videos of them, you will see pure psychological welfare. Maybe this explains why some of the same players seem\nto end up in the later rounds of the tournament every year.\nThere’s also a robot hand, built at the University of Tokyo, that plays rock-paper-scissors with a winning probability of 100%\n(check out the video). No surprise, a very high-speed camera is involved.\n5This is without loss of generality, by scaling.\n8\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 69
  },
  {
    "chunk_full": "R\nP\nS\nR\n0\n-1\n1\nP\n1\n0\n-1\nS\n-1\n1\n0\nMixed strategies for Alice and Bob correspond to probability distributions x and y over rows and\ncolumns, respectively. When speaking about Nash equilibria, one always assumes that players randomize\nindependently. For a two-player zero-sum game A and mixed strategies x, y, we can write Alice’s expected\npayoﬀas\nx⊤Ay =\nX\ni, j\nAi j xiyj .\nBob’s expected payoﬀis the negative of this quantity.\n1.2.4\nThe Minimax Theorem\nThe question that the Minimax theorem addresses is the following:\nIf two players make choices sequentially in a zero-sum game, is it better to go ﬁrst or second?\nIn a zero-sum game, there can only be a ﬁrst-mover disadvantage. Going second gives a player the opportunity\nto adapt to what the other player does ﬁrst. And the second player always has the option of choosing whatever\nmixed strategy she would have chosen had she gone ﬁrst. But does going second ever strictly help? The\nMinimax theorem gives an amazing answer to the question above: it doesn’t matter!\nTheorem 1.1 (Minimax Theorem). Let A be the payoﬀmatrix of a two-player zero-sum game. Then\nmax\nx\n \nmin\ny\nx⊤Ay\n!\n= min\ny\n\u0012\nmax\nx\nx⊤Ay\n\u0013\n,\n(1.1)\nwhere x ranges over probability distributions over the rows of A and y ranges over probability distributions\nover the columns of A.\nOn the left-hand side of (1.1), the row player moves ﬁrst and the column player second. The column\nplayer plays optimally given the strategy chosen by the row player, and the row player plays optimally\nanticipating the column player’s response. On the right-hand side of (1.1), the roles of the two players are\nreversed. The Minimax theorem asserts that, under optimal play, the expected payoﬀof each player is the\nsame in the two scenarios.\nThe ﬁrst proof of the Minimax theorem was due to von Neumann [148] and used ﬁxed-point-type\narguments (which we’ll have much more to say about later). von Neumann and Morgenstern [149], inspired\nby Ville [147], later realized that the Minimax theorem can be deduced from strong linear programming\nduality.6\n6Dantzig [40, p.5] describes meeting John von Neumann on October 3, 1947: “In under a minute I slapped the geometric and\nthe algebraic version of the [linear programming] problem on the blackboard. Von Neumann stood up and said ’Oh that!’ Then for\nthe next hour and a half, he proceeded to give me a lecture on the mathematical theory of linear programs.\n“At one point seeing me sitting there with my eyes popping and my mouth open (after all I had searched the literature and found\nnothing), von Neumann said: ’I don’t want you to think I am pulling all this out of my sleeve on the spur of the moment like a\nmagician. I have just recently completed a book with Oskar Morgenstern on the Theory of Games. What I am doing is conjecturing\nthat the two problems are equivalent.”\nThis equivalence between strong linear programming duality and the Minimax theorem is made precise in Dantzig [39], Gale et\nal. [58], and Adler [2].\n9\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 70
  },
  {
    "chunk_full": "Proof. The idea is to formulate the problem faced by the ﬁrst player as a linear program. The theorem will\nthen follow from linear programming duality.\nFirst, the player who moves second always has an optimal deterministic strategy—given the probability\ndistribution chosen by the ﬁrst player, the second player can just play the strategy with the highest expected\npayoﬀ. This means the inner min and max in (1.1) may as well range over columns and rows, respectively,\nrather than over all probability distributions. The left expression in (1.1) then translates to the following\nlinear program:\nmax\nv\ns.t.\nv ≤\nm\nX\ni=1\nAi j xi\nfor all columns j,\nx is a probability distribution over rows.\nIf the optimal point is (v∗, x∗), then v∗equals the left-hand-side of (1.1) and x∗belongs to the corresponding\narg-max. In plain terms, x∗is what Alice should play if she has to move ﬁrst, and v∗is the consequent\nexpected payoﬀ(assuming Bob responds optimally).\nSimilarly, we can write a second linear program that computes the optimal point (w∗, y∗) from Bob’s\nperspective, where w∗equals the right-hand-side of (1.1) and y∗is in the corresponding arg-min:\nmin\nw\ns.t.\nw ≥\nn\nX\nj=1\nAi j yj\nfor all rows i,\ny is a probability distribution over columns.\nIt is straightforward to verify that these two linear programs are in fact duals of each other (left to the reader,\nor see Chvátal [38]). By strong linear programming duality, we know that the two linear programs have equal\noptimal objective function value and hence v∗= w∗. This means that the payoﬀthat Alice can guarantee\nherself if she goes ﬁrst is the same as the payoﬀthat Bob can guarantee himself if he goes ﬁrst, and this\ncompletes the proof.\n□\nDeﬁnition 1.2 (Value of a two-player zero-sum game; min-max pair). Let A be a payoﬀmatrix of a two-player\nzero-sum game. Then the value of the game is deﬁned to be the common value of\nmax\nx\n \nmin\ny\nx⊤Ay\n!\nand min\ny\n\u0012\nmax\nx\nx⊤Ay\n\u0013\n.\nA min-max strategy is a strategy x∗in the arg-max of the left-hand side or a strategy y∗in the arg-min of the\nright-hind side. A min-max pair is a pair (x∗, y∗) where x∗and y∗are both min-max strategies.\nFor example, the value of the rock-paper-scissors game is 0 and (u, u) is its unique min-max pair, where\nu denotes the uniform probability distribution.\nThe min-max pairs are the optimal solutions of the two linear programs in the proof of Theorem 1.1.\nSince the optimal solution of a linear program can be computed in polynomial time, so can a min-max pair.\n10\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 71
  },
  {
    "chunk_full": "1.2.5\nNash Equilibrium\nIn zero-sum games, a min-max pair is closely related to the notion of a Nash equilibrium, deﬁned next.7\nDeﬁnition 1.3 (Nash equilibrium in a two-player zero-sum game). Let A be a payoﬀmatrix of a two-player\nzero-sum game. The pair ( ˆx, ˆy) is a Nash equilibrium if\n(i) ˆx⊤Aˆy ≥x⊤Aˆy for all x (given that Bob plays ˆy, Alice cannot increase her expected payoﬀby deviating\nunilaterally to a strategy diﬀerent from ˆx, i.e., given ˆy, ˆx is optimal);\n(ii) ˆx⊤Aˆy ≤ˆx⊤Ay for all y (given ˆx, ˆy is an optimal strategy for Bob).\nThe pairs in Deﬁnition 1.3 are sometimes called mixed Nash equilibria, to stress that players are allowed\nto randomize. (As opposed to a pure Nash equilibrium, where both players play deterministically.) Unless\notherwise noted, we will always be concerned with mixed Nash equilibria.\nClaim 1.4. In a two-player zero-sum game, a pair (x∗, y∗) is a min-max pair if and only if it is a Nash\nequilibrium.\nProof. Suppose (x∗, y∗) is a min-max pair, and so Alice’s expected payoﬀis v∗, the value of the game. Since\nAlice plays her min-max strategy, Bob cannot make her payoﬀsmaller than v∗via some other strategy. Since\nBob plays his min-max strategy, Alice cannot make her payoﬀlarger than v∗. Since neither player can do\nbetter with a unilateral deviation, (x∗, y∗) is a Nash equilibrium.\nConversely, suppose (x∗, y∗) is not a min-max pair with, say, Alice not playing a min-max strategy.\nIf Alice’s expected payoﬀis less than v∗, then (x∗, y∗) is not a Nash equilibrium (she could do better by\ndeviating to a min-max strategy). Otherwise, since x∗is not a min-max strategy, Bob has a response y such\nthat Alice’s expected payoﬀwould be strictly less than v∗. Thus Bob could do better by deviating unilaterally\nto y, and (x∗, y∗) is not a Nash equilibrium.\n□\nThere are several interesting consequences of Theorem 1.1 and Proposition 1.4:\n1. The set of all Nash equilibria is a convex set, as the optimal solutions of a linear program form a\nconvex set.\n2. All Nash equilibria (x, y) lead to the same value of x⊤Ay. That is, each player receives the same\nexpected payoﬀacross all Nash equilibria.\n3. Most importantly, since the proof of Theorem 1.1 uses linear programming duality and gives us a\npolynomial-time algorithm to compute a min-max pair (x∗, y∗), we have a polynomial-time algorithm\nto compute a Nash equilibrium of a two-player zero-sum game.\nCorollary 1.5. A Nash equilibrium of a two-player zero-sum game can be computed in polynomial time.\n1.2.6\nBeyond Zero-Sum Games\nThere’s no reason to be content with our positive results so far. Two-player zero-sum games are important—\ne.g., von Neumann was largely focused on them, with applications ranging from poker to war—but most\ngame-theoretic situations are not purely oppositional.8 Can we generalize any of their nice properties to\n7If you think you learned this deﬁnition from the movie A Beautiful Mind, it’s time to learn the correct deﬁnition!\n8They can even be cooperative, for example if you and I want to meet at some intersection in Manhattan. Our strategies are\nintersections, and either we both get a high payoﬀ(if we choose the same strategy) or we both get a low payoﬀ(otherwise).\n11\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 72
  },
  {
    "chunk_full": "games with more players or without the zero-sum property? For example, what about bimatrix games, where\nthere are still two players but the game is not necessarily zero-sum?9 Solar Lectures 4 and 5 are devoted to\nthis question, and provide evidence that there is no analog of Corollary 1.5 for bimatrix games.\n1.2.7\nWho Cares?\nBefore proceeding to our second cool fact about two-player zero-sum games, let’s take a step back and be\nclear about what we’re trying to accomplish. Why do we care about computing equilibria in games, anyway?\n1. We might want fast algorithms to actually use in practice. The demand for equilibrium computation\nalgorithms is signiﬁcantly less than that for, say, linear programming solvers, but your lecturer reg-\nularly meets researchers who would make good use of better oﬀ-the-shelf solvers for computing an\nequilibrium of a game.\n2. Perhaps most relevant for this week’s audience, the study of equilibrium computation naturally leads\nto interesting and new complexity theory (e.g., deﬁnitions of new complexity classes, such as PPAD).\nAs we’ll see this week, the most celebrated results in the area are quite deep and draw on ideas from\nall across theoretical computer science.\n3. Complexity considerations can be used to support or critique the practical relevance of an equilibrium\nconcept such as the Nash equilibrium. It is tempting to interpret a polynomial-time algorithm for\ncomputing an equilibrium as a plausibility argument that players can ﬁgure one out quickly, and an\nintractability result as evidence that players will not generally reach an equilibrium in a reasonable\namount of time.\nOf course, the real story is more complex. First, computational intractability is not necessarily ﬁrst\non the list of the Nash equilibrium’s issues. For example, its non-uniqueness in non-zero-sum games\nalready limits its predictive power.10\nSecond, it’s not particularly helpful to critique a deﬁnition without suggesting an alternative. Lunar\nLecture 5 partially addresses this issue by discussing two tractable equilibrium concepts, correlated\nequilibria and coarse correlated equilibria.\nThird, does an arbitrary polynomial-time algorithm, such as one based on solving a non-trivial\nlinear program, really suggest that independent play by strategic players will actually converge to\nan equilibrium? Algorithms for linear programming do not resemble how players typically make\ndecisions in games.\nA stronger positive result would involve a behaviorally plausible distributed\nalgorithm that players can use to eﬃciently converge to a Nash equilibrium through repeated play over\ntime. We discuss such a result for two-player zero-sum games next.\n1.3\nUncoupled Dynamics\nIn the ﬁrst half of the lecture, we saw that a Nash equilibrium of a two-player zero-sum game can be\ncomputed in polynomial time. This was done by interpreting the Minimax Theorem in the framework of\nlinear programming duality.\n9Notice that three-player zero-sum games are already more general than bimatrix games—to turn one of the latter into one of\nthe former, add a dummy third player with only one strategy whose payoﬀis the negative of the combined payoﬀof the original two\nplayers. Thus the most compelling negative results would be for the case of bimatrix games.\n10Recall our “meeting in Manhattan” example—every intersection is a Nash equilibrium!\n12\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 73
  },
  {
    "chunk_full": "It would be more compelling, however, to come up with a deﬁnition of a plausible process by which\nplayers can learn a Nash equilibrium. Such a result requires a behavioral model for what players do when not\nat equilibrium. The goal is then to investigate whether or not the process converges to a Nash equilibrium\n(for an appropriate notion of convergence), and if so, how quickly.\n1.3.1\nThe Setup\nUncoupled dynamics refers to a class of processes with the properties mentioned above. The idea is that\neach player initially knows only her own payoﬀs (and not those of the other players), a la the number-in-hand\nmodel in communication complexity. The game is then played repeatedly, with each player picking a strategy\nin each time step as a function only of her own payoﬀs and what transpired in the past.\nUncoupled Dynamics (Two-Player Version)\nAt each time step t = 1, 2, 3, . . .:\n1. Alice chooses a strategy xt as a function only of her own payoﬀs and the previously chosen\nstrategies x1, . . ., xt−1 and y1, . . ., yt−1.\n2. Bob simultaneously chooses a strategy yt as a function only of his own payoﬀs and the previously\nchosen strategies x1, . . ., xt−1 and y1, . . ., yt−1.\n3. Alice learns yt and Bob learns xt.11\nUncoupled dynamics have been studied at length in both the game theory and computer science literatures\n(often under diﬀerent names). Specifying such dynamics boils down to a deﬁnition of how Alice and Bob\nchoose strategies as a function of their payoﬀs and the joint history of play. Let’s look at some famous\nexamples.\n1.3.2\nFictitious Play\nOne natural idea is to best respond to the observed behavior of your opponent.\nExample 1.6 (Fictitious Play). In ﬁctitious play, each player assumes that the other player will mix according\nto the relative frequencies of their past actions (i.e., the empirical distribution of their past play), and plays a\nbest response.\nFictitious Play (Two-Player Version)\nAt each time step t = 1, 2, 3, . . .:\n1. Alice chooses a strategy xt that is a best response against ˆyt−1 =\n1\nt−1\nPt−1\ns=1 ys, the past actions\nof Bob (breaking ties arbitrarily).\n2. Bob simultaneously chooses a strategy yt that is a best response against ˆxt−1 =\n1\nt−1\nPt−1\ns=1 xs, the\npast actions of Alice (breaking ties arbitrarily).\n11When Alice and Bob use mixed strategies, there are actually two diﬀerent natural feedback models, one where each player\nlearns the actual mixed strategy chosen by the other player, and one where each learns only a sample (a pure strategy) from the other\nplayer’s chosen distribution. It’s generally easier to prove results in the ﬁrst model, but such proofs usually can be extended with\nsome additional work to hold (with high probability over the strategy realizations) in the second model as well.\n13\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 74
  },
  {
    "chunk_full": "3. Alice learns yt and Bob learns xt.\nOne way to interpret ﬁctitious play is to imagine that each player assumes that the other is using the\nsame mixed strategy every time step, and estimates this time-invariant mixed strategy with the empirical\ndistribution of past actions.\nNote that each player picks a pure strategy in each time step (modulo tie-breaking in the case of multiple\nbest responses).\nFictitious play has an interesting history:\n1. It was ﬁrst proposed by G. W. Brown in 1949 (published in 1951 [20]) as a computer algorithm to\ncompute a Nash equilibrium of a two-player zero-sum game. Note this is not so long after the birth of\neither game theory or computers!\n2. In 1951, Julia Robinson (better known for her contributions to the resolution of Hilbert’s tenth problem\nabout Diophantine equations) proved that, in two-player zero-sum games, the time-averaged payoﬀs\nof the players converges to the value of the game [122]. Robinson’s proof only gives an exponential\n(in the number of strategies) bound on the number of iterations required for convergence. In 1959,\nSamuel Karlin [84] conjectured that a polynomial bound should be possible (in two-player zero-sum\ngames). Relatively recently (2014), Daskalakis and Pan [41] refuted the conjecture and proved an\nexponential lower bound for the case of adversarial (and not necessarily consistent) tie-breaking.\n3. It is still an open question whether or not ﬁctitious play converges quickly for natural (or even just\nconsistent) tie-breaking rules! The goal here would be to show that poly(n, 1/ϵ) time steps suﬃce for\nthe time-averaged payoﬀs to be within ϵ of the value of the game (where n is the number of strategies).\n4. The situation for non-zero-sum games was murky until 1964, when Lloyd Shapley [138] discovered a\n3 × 3 game (a non-zero-sum variation on rock-paper-scissors) where ﬁctitious play never converges to\na Nash equilibrium (which foreshadowed future developments on zero-sum vs. non-zero-sum games).\nNext we’ll look at a diﬀerent choice of dynamics that has much better convergence properties.\n1.3.3\nSmooth Fictitious Play\nFictitious play is “all-or-nothing”—even if two strategies have almost the same expected payoﬀagainst the\nopponent’s empirical distribution, the slightly worse one is completely ignored in favor of the slightly better\none. A more stable approach, and perhaps a more behaviorally plausible one, is to assume that players\nrandomize, biasing their decision toward the strategies with the highest expected payoﬀs (again, against the\nempirical distribution of the opponent). In other words, each player plays a “noisy best response” against the\nobserved play of the other player. For example, already in 1957 Hannan [70] considered dynamics where\neach player chooses a strategy with probability proportional to its expected payoﬀ(against the empirical\ndistribution of the other player’s past play), and proved polynomial convergence to the Nash equilibrium\npayoﬀs in two-player zero-sum games.\nEven better convergence properties are possible if poorly performing strategies are abandoned more\naggressively—this will correspond to a “softmax” version of ﬁctitious play.\nExample 1.7 (Smooth Fictitious Play). In time t of smooth ﬁctitious play, a player (Alice, say) computes\nthe empirical distribution ˆyt−1 = Pt−1\ns=1 xs of the other player’s past play, computes the expected payoﬀπt\ni of\neach pure strategy i under the assumption that Bob plays ˆyt−1, and chooses xt by playing each strategy with\n14\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 75
  },
  {
    "chunk_full": "probability proportional to eηt πt\ni . Here ηt is a tunable parameter that interpolates between always playing\nuniformly at random (when η = 0) and ﬁctitious play (when η = +∞). The choice ηt ≈√t is often the best\none for proving convergence results.\nSmooth Fictitious Play (Two-Player Version)\nGiven: parameter family {ηt ∈[0, ∞) : t = 1, 2, 3, . . .}.\nAt each time step t = 1, 2, 3, . . .:\n1. Alice chooses a strategy xt by playing each strategy i with probability proportional to eηt πt\ni ,\nwhere πt\ni denotes the expected payoﬀof strategy i when Bob plays the mixed strategy ˆyt−1 =\n1\nt−1\nPt−1\ns=1 ys.\n2. Bob simultaneously chooses a strategy yt by playing each strategy j with probability proportional\nto eηt ρt\nj, where ρt\nj is the expected payoﬀof strategy j when Alice plays the mixed strategy\nˆxt−1 =\n1\nt−1\nPt−1\ns=1 xs.\n3. Alice learns yt and Bob learns xt.\nVersions of smooth ﬁctitious play have been studied independently in the game theory literature (beginning\nwith Fudenberg and Levine [57]) and the computer science literature (beginning with Freund and Schapire\n[56]). It converges extremely quickly.\nTheorem 1.8 ([57, 56]). For a zero-sum two-player game with m rows and n columns and a parameter ϵ > 0,\nafter T = O(log(n + m)/ϵ2) time steps of smooth ﬁctitious play, the empirical distributions ˆx = 1\nT\nPT\nt=1 xt\nand ˆy = 1\nT\nPT\nt=1 yt constitute an ϵ-approximate Nash equilibrium.\nThe ϵ-approximate Nash equilibrium condition in Theorem 1.8 is exactly what it sounds like: neither\nplayer can improve their expected payoﬀby more than ϵ via a unilateral deviation (see also Deﬁnition 1.12,\nbelow). (Recall that payoﬀs are assumed scaled to lie in [−1, 1].)\nThere are two steps in the proof of Theorem 1.8: (i) the noisy best response in smooth ﬁctitious play is\nequivalent to the “Multiplicative Weights” algorithm, which has “vanishing regret;” and (ii) in a two-player\nzero-sum game, vanishing-regret guarantees translate to (approximate) Nash equilibrium convergence. The\noptional Sections 1.3.5–1.3.7 provide more details for the interested reader.\n1.3.4\nImplications for Communication Complexity\nTheorem 1.8 implies that smooth ﬁctitious play can be used to deﬁne a randomized O(log2(n + m)/ϵ2)-bit\ncommunication protocol for computing an ϵ-NE.12 The goal of the next two lectures is to prove that there\nis no analogously eﬃcient communication protocol for computing an approximate Nash equilibrium of a\nnon-zero-sum game.13\nRuling out low-communication protocols will in particular rule out any type of\nquickly converging uncoupled dynamics.\n12Actually, this is for the variant of smooth ﬁctitious play where Alice (respectively, Bob) only learns a random sample from yt\n(respectively, xt); see footnote 11. Each such sample can be communicated to the other player in log(n + m) bits. Theorem 1.8\ncontinues to hold (with high probability over the samples) for this variant of smooth ﬁctitious play [57, 56].\n13The communication complexity of computing anything about a two-player zero-sum game is a silly problem—Alice knows\nthe entire game at the beginning (since Bob’s payoﬀis the negative of hers) and can unilaterally compute whatever she wants. But it\nstill makes sense to ask if the communication bound implied by smooth ﬁctitious play can be replicated in non-zero-games (where\nAlice and Bob initially know only their own payoﬀmatrices).\n15\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 76
  },
  {
    "chunk_full": "1.3.5\nProof of Theorem 1.8, Part 1: Multiplicative Weights (Optional)\nTo elaborate on the ﬁrst step of the proof of Theorem 1.8, we need to explain the standard setup for online\ndecision-making.\nOnline Decision-Making\nAt each time step t = 1, 2, . . .,T:\na decision-maker picks a probability distribution pt over her actions Λ\nan adversary picks a reward vector rt : Λ →[−1, 1]\nan action at is chosen according to the distribution pt, and the decision-maker receives\nreward rt (at)\nthe decision-maker learns rt, the entire reward vector\nIn smooth ﬁctitious play, each of Alice and Bob are in eﬀect solving the online decision-making problem\n(with actions corresponding to the game’s strategies). For Alice, the reward vector rt is induced by Bob’s\naction at time step t (if Bob plays strategy j, then rt corresponds to the jth column of the game matrix A),\nand similarly for Bob (with the ith row multiplied by −1). Next we interpret Alice and Bob’s behavior in\nsmooth ﬁctitious play as algorithms for online decision-making.\nAn online decision-making algorithm speciﬁes for each t the probability distribution pt, as a function of\nthe reward vectors r1, . . ., rt−1 and realized actions a1, . . ., at−1 of the ﬁrst t −1 time steps. An adversary for\nsuch an algorithm A speciﬁes for each t the reward vector rt, as a function of the probability distributions\np1, . . ., pt used by A on the ﬁrst t days and the realized actions a1, . . ., at−1 of the ﬁrst t −1 days.\nHere is a famous online decision-making algorithm, the “Multiplicative Weights (MW)” algorithm\n(see [100, 55, 27]).\nMultiplicative Weights (MW) Algorithm\ninitialize w1(a) = 1 for every a ∈Λ\nfor each time step t = 1, 2, 3, . . . do\nuse the distribution pt := wt/Γt over actions, where Γt = P\na∈Λ wt (a) is the sum of the\nweights\ngiven the reward vector rt, for every action a ∈Λ use the formula\nwt+1(a) = wt (a) · (eηt r t (a)) to update its weight (ηt is a parameter, canonically ≈√t)\nThe MW algorithm maintains a weight, intuitively a “credibility,” for each action. At each time step the\nalgorithm chooses an action with probability proportional to its current weight. The weight of each action\nevolves over time according to the action’s past performance.\nInspecting the descriptions of smooth ﬁctitious play and the MW algorithm, we see that we can rephrase\nthe former as follows:\nSmooth Fictitious Play (Rephrased)\nGiven: parameter family {ηt ∈[0, ∞) : t = 1, 2, 3, . . .}.\nAt each time step t = 1, 2, 3, . . .:\n16\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 77
  },
  {
    "chunk_full": "1. Alice uses an instantiation of the MW algorithm to choose a mixed strategy xt.\n2. Bob uses a diﬀerent instantiation of the MW algorithm to choose a mixed strategy yt.\n3. Alice learns yt and Bob learns xt.\n4. Alice feeds her MW algorithm a reward vector rt with rt (i) equal to the expected payoﬀof\nplaying row i, given Bob’s mixed strategy yt over columns; and similarly for Bob.\nHow should we assess the performance of an online decision-making algorithm like the MW algorithm,\nand do guarantees for the algorithm have any implications for smooth ﬁctitious play?\n1.3.6\nProof of Theorem 1.8, Part 2: Vanishing Regret (Optional)\nOne of the big ideas in online learning is to compare the time-averaged reward earned by an online algorithm\nwith that earned by the best ﬁxed action in hindsight.14\nDeﬁnition 1.9 ((Time-Averaged) Regret). Fix reward vectors r1, . . ., rT. The regret of the action sequence\na1, . . ., aT is\n1\nT max\na∈Λ\nT\nX\nt=1\nrt (a)\n|              {z              }\nbest ﬁxed action\n−1\nT\nT\nX\nt=1\nrt (at)\n|         {z         }\nour algorithm\n.\n(1.2)\nNote that, by linearity, there is no diﬀerence between considering the best ﬁxed action and the best ﬁxed\ndistribution over actions (there is always an optimal pure action in hindsight).\nWe’d like an online decision-making algorithm that achieves low regret, as close to 0 as possible. Since\nrewards lie in [−1, 1], the regret can never be larger than 2. We think of regret Ω(1) (as T →∞) as an epic\nfail for an algorithm.\nIt turns out that the MW algorithm has the best-possible worst-case regret guarantee (up to constant\nfactors).15\nTheorem 1.10. For every adversary, the MW algorithm has expected regret O(\np\n(log n)/T).\nSee e.g. the book of Cesa-Bianchi and Lugosi [26] for a proof of Theorem 1.10, which is not overly\ndiﬃcult.\nAn immediate corollary is that the number of time steps needed to drive the expected regret down to a\nsmall constant is only logarithmic in the number of actions—this is surprisingly fast!\nCorollary 1.11. There is an online decision-making algorithm that, for every adversary and ϵ > 0, has\nexpected regret at most ϵ after O((log n)/ϵ2) time steps.\n14There is no hope of competing with the best action sequence in hindsight: consider two actions and an adversary that ﬂips a\ncoin each time step to choose between the reward vectors (1, 0) and (0, 1).\n15For the matching lower bound, with n actions, consider an adversary that sets the reward of each action uniformly at random\nfrom {−1, 1} at each time step. Every online algorithm earns expected cumulative reward 0, while the expected reward of the best\naction in hindsight is Θ(\n√\nT · √log n).\n17\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 78
  },
  {
    "chunk_full": "1.3.7\nProof of Theorem 1.8, Part 3: Vanishing Regret Implies Convergence (Optional)\nWe now sketch the rest of the proof of Theorem 1.8. Consider a zero-sum game A with payoﬀs in [−1, 1]\nand some ϵ > 0. Let n denote the number of rows or the number of columns, whichever is larger, and\nset T = Θ((log n)/ϵ2) so that the guarantee in Corollary 1.11 holds with error ϵ/2. Let x1, . . ., xT and\ny1, . . ., yT be the mixed strategies used by Alice and Bob throughout T steps of smooth ﬁctitious play. Let\nˆx = 1\nT\nPT\nt=1 xt and ˆy = 1\nT\nPT\nt=1 yt denote the time-averaged strategies of Alice and Bob, respectively. We\nclaim that ( ˆx, ˆy) is an ϵ-NE.\nIn proof, let\nv = 1\nT\nT\nX\nt=1\n(xt)⊤Ayt\ndenote Alice’s time-averaged payoﬀ. Since both Alice and Bob eﬀectively used the MW algorithm to choose\ntheir strategies, we can apply the vanishing regret guarantee in Corollary 1.11 once for each player and use\nlinearity to obtain\nv ≥*\n,\nmax\nx\n1\nT\nT\nX\nt=1\nx⊤Ayt+\n-\n−ϵ\n2 =\n\u0012\nmax\nx\nx⊤Aˆy\n\u0013\n−ϵ\n2\n(1.3)\nand\nv ≤*\n,\nmin\ny\n1\nT\nT\nX\nt=1\n(xt)⊤Ay+\n-\n+ ϵ\n2 =\n \nmin\ny\nˆx⊤Ay\n!\n+ ϵ\n2.\n(1.4)\nIn particular, taking x = ˆx in (1.3) and y = ˆy in (1.4) shows that\nˆx⊤Aˆy ∈\n\u0014\nv −ϵ\n2, v + ϵ\n2\n\u0015\n.\n(1.5)\nNow consider a (pure) deviation from ( ˆx, ˆy), say by Alice to the row i. Denote this deviation by ei. By\ninequality (1.3) (with x = ei) we have\ne⊤\ni Aˆy ≤v + ϵ\n2.\n(1.6)\nSince Alice receives expected payoﬀat least v −ϵ\n2 in ( ˆx, ˆy) (by (1.5)) and at most v + ϵ\n2 from any deviation\n(by (1.6)), her ϵ-NE conditions are satisﬁed. A symmetric argument applies to Bob, completing the proof.\n1.4\nGeneral Bimatrix Games\nUnlike a zero-sum game, a general bimatrix game has two independent payoﬀmatrices, an m × n matrix A\nfor Alice and an m × n matrix B for Bob. (In a zero-sum game, B = −A.) The deﬁnition of an (approximate)\nNash equilibrium is what you’d think it would be:\nDeﬁnition 1.12 (ϵ-Approximate Nash Equilibrium). For a bimatrix game (A, B), row and column mixed\nstrategies ˆx and ˆy constitute an ϵ-NE if\nˆx⊤Aˆy ≥x⊤Aˆy −ϵ\n∀x , and\n(1.7)\nˆx⊤B ˆy ≥ˆx⊤By −ϵ\n∀y .\n(1.8)\nIt has long been known that many of the nice properties of zero-sum games break down in general\nbimatrix games.16\n16We already mentioned Shapley’s 1964 example showing that ﬁctitious play need not converge [138].\n18\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 79
  },
  {
    "chunk_full": "Example 1.13 (Strange Bimatrix Behavior). Suppose two friends, Alice and Bob, want to go for dinner,\nand are trying to settle on a choice of restaurant. Alice prefers Italian over Thai, and Bob prefers Thai over\nItalian, but both would rather eat together than eat alone. Supposing the rows and columns are indexed by\nItalian and Thai, in that order, and Alice is the row player, we get the following payoﬀmatrices:\nA =\n\"2\n0\n0\n1\n#\n,\nB =\n\"1\n0\n0\n2\n#\n,\nor, in shorthand,\n(A, B) =\n\"(2, 1)\n(0, 0)\n(0, 0)\n(1, 2)\n#\n.\nThere are two obvious Nash equilibria, both pure: either Alice and Bob go to the Italian restaurant, or they\nboth go to the Thai restaurant. But there’s a third Nash equilibrium, a mixed one17: Alice chooses Italian\nover Thai with probability 2\n3, and Bob chooses Thai over Italian with probability 2\n3. This is an undesirable\nNash equilibrium, with Alice and Bob eating alone more than half the time.\nExample 1.13 shows that, unlike in zero-sum games, diﬀerent Nash equilibria can result in diﬀerent\nexpected player payoﬀs. Similarly, the Nash equilibria of a bimatrix game do not generally form a convex\nset (unlike in the zero-sum case).\nNash equilibria of bimatrix games are not completely devoid of nice properties, however. For starters,\nwe have guaranteed existence.\nTheorem 1.14 (Nash’s Theorem [114, 113]). Every bimatrix game has at least one (mixed) Nash equilibrium.\nThe proof is a ﬁxed-point argument that we will have more to say about in Solar Lecture 2.18 Nash’s\ntheorem holds more generally for games with any ﬁnite number of players and strategies.\nNash equilibria of bimatrix games have nicer structure than those in games with three or more players.\nFirst, in bimatrix games with integer payoﬀs, there is a Nash equilibrium in which all probabilities are rational\nnumbers with bit complexity polynomial in that of the game.19 Second, there is a simplex-type pivoting\nalgorithm, called the Lemke-Howson algorithm [96], which computes a Nash equilibrium of a bimatrix game\nin a ﬁnite number of steps (see von Stengel [150] for a survey). Like the simplex method, the Lemke-Howson\nalgorithm takes an exponential number of steps in the worst case [109, 136]. Nevertheless, the similarities\nbetween Nash equilibria of bimatrix games and optimal solutions of linear programs originally led to some\noptimism that a polynomial-time algorithm might exist. Alas, as we’ll see, this does not seem to be the case.\n1.5\nApproximate Nash Equilibria in Bimatrix Games\nThe last topic of this lecture is some semi-positive results about approximate Nash equilibria in general\nbimatrix games. While simple, these results are important and will show up repeatedly in the rest of the\nlectures.\n1.5.1\nSparse Approximate Nash Equilibria\nHere is a crucial result for us: there are always sparse approximate Nash equilibria.20,21\n17Fun fact: outside of degenerate cases, every game has an odd number of Nash equilibria (see also Solar Lecture 4).\n18Von Neumann’s alleged reaction when Nash told him his theorem [112, P.94]: “That’s trivial, you know. That’s just a ﬁxed\npoint theorem.”\n19Exercise: prove this by showing that, after you’ve guessed the two support sets of a Nash equilibrium, you can recover the\nexact probabilities using two linear programs.\n20Althöfer [4] and Lipton and Young [98] independently proved a precursor to this result in the special case of zero-sum games.\nThe focus of the latter paper is applications in complexity theory (like “anticheckers”).\n21Exercise: there are arbitrarily large games where every exact Nash equilibrium has full support. Hint: generalize rock-paper-\nscissors. Alternatively, see Section 5.2.6 of Solar Lecture 5.\n19\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 80
  },
  {
    "chunk_full": "Theorem 1.15 (Lipton et al. [99]). For every ϵ > 0 and every n × n bimatrix game, there exists an ϵ-NE in\nwhich each player randomizes uniformly over a multi-set of O((log n)/ϵ2) pure strategies.22\nProof idea. Fix an n × n bimatrix game (A, B).\n1. Let (x∗, y∗) be an exact Nash equilibrium of (A, B). (One exists, by Theorem 1.14.)\n2. As a thought experiment, sample Θ((log n)/ϵ2) pure strategies for Alice i.i.d. (with replacement)\nfrom x∗, and similarly for Bob i.i.d. from y∗.\n3. Let ˆx, ˆy denote the empirical distributions of the samples (with probabilities equal to frequencies in\nthe sample)—equivalently, the uniform distributions over the two multi-sets of pure strategies.\n4. Use Chernoﬀbounds to argue that ( ˆx, ˆy) is an ϵ-NE (with high probability). Speciﬁcally, because of\nour choice of the number of samples, the expected payoﬀof each row strategy w.r.t. ˆy diﬀers from that\nw.r.t. y∗by at most ϵ/2 (w.h.p.). Since every strategy played with non-zero probability in x∗is an exact\nbest response to y∗, every strategy played with non-zero probability in ˆx is within ϵ of a best response\nto ˆy. Similarly with the roles of ˆx and ˆy reversed. This is a suﬃcient condition for being an ϵ-NE.23\n□\n1.5.2\nImplications for Communication Complexity\nTheorem 1.15 immediately implies the existence of an ϵ-NE of an n×n bimatrix game with description length\nO((log2 n)/ϵ2), with ≈log n bits used to describe each of the O((log n)/ϵ2) pure strategies in the multi-sets\npromised by the theorem. Moreover, if an all-powerful prover writes down an alleged such description on\na publicly observable blackboard, then Alice and Bob can privately verify that the described pair of mixed\nstrategies is indeed an ϵ-NE. For example, Alice can use the (publicly viewable) description of Bob’s mixed\nstrategy to compute the expected payoﬀof her best response and check that it is at most ϵ more than her\nexpected payoﬀwhen playing the mixed strategy suggested by the prover. Summarizing:\nCorollary 1.16. The nondeterministic communication complexity of computing an ϵ-NE of an n×n bimatrix\ngame is O((log2 n)/ϵ2).\nThus, if there is a polynomial lower bound on the deterministic or randomized communication complexity\nof computing an approximate Nash equilibrium, the only way to prove it is via techniques that don’t\nautomatically apply also to the problem’s nondeterministic communication complexity. This observation\nrules out many of the most common lower bound techniques. In Solar Lectures 2 and 3, we’ll see how to\nthread the needle using a simulation theorem, which lifts a deterministic or random query (i.e., decision tree)\nlower bound to an analogous communication complexity lower bound.\n1.5.3\nImplications for Computational Complexity\nThe second important consequence of Theorem 1.15 is a limit on the worst-possible computational hardness\nwe could hope to prove for the problem of computing an approximate Nash equilibrium of a bimatrix game:\nat worst, the problem is quasi-polynomial-hard.\n22By a padding argument, there is no loss of generality in assuming that Alice and Bob have the same number of strategies.\n23This suﬃcient condition has its own name: a well-supported ϵ-NE.\n20\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 81
  },
  {
    "chunk_full": "Corollary 1.17. There is an algorithm that, given as input a description of an n × n bimatrix game and a\nparameter ϵ, outputs an ϵ-NE in O(n(log n)/ϵ2) time.\nProof. The algorithm enumerates all O(n(log n)/ϵ2) possible choices for the multi-sets promised by The-\norem 1.15.\nIt is easy to check whether or not the mixed strategies induced by a choice constitute an\nϵ-NE—just compute the expected payoﬀs of each strategy and of the players’ best responses, as in the proof\nof Corollary 1.16.\n□\nThe quasi-polynomial-time approximation scheme (QPTAS) in Corollary 1.17 initially led to optimism\nthat there should be a PTAS for the problem, in light of the paucity of natural problems for which the best-\npossible running time is quasi-polynomial. Also, if there were a reduction showing quasi-polynomial-time\nhardness for computing an approximate Nash equilibrium, what would it look like? Solar Lectures 4 and 5\nwill answer this question.\n21\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 82
  },
  {
    "chunk_full": "Solar Lecture 2\nCommunication Complexity Lower Bound for Computing an Approximate Nash Equilibrium of a\nBimatrix Game (Part I)\nLecturer: Tim Roughgarden\nScribe: Valentine Kabanets and Antonina Kolokolova\nThis lecture and the next consider the communication complexity of computing an approximate Nash\nequilibrium, culminating with a proof of the very recent breakthrough polynomial lower bound of Babichenko\nand Rubinstein [9]. This lower bound rules out the possibility of quickly converging uncoupled dynamics in\ngeneral bimatrix games (see Section 1.3).\n2.1\nPreamble\nRecall the setup: there are two players, Alice and Bob, each with their own payoﬀmatrices A and B. Without\nloss of generality (by padding), the two players have the same number N of strategies. We consider a\ntwo-party model where, initially, Alice only knows A and Bob only knows B. The goal is then for Alice and\nBob to compute an approximate Nash equilibrium (Deﬁnition 1.12) with as little communication as possible.\nThis lecture and the next explain all of the main ideas behind the following result:\nTheorem 2.1 (Babichenko and Rubinstein [9]). There is a constant c > 0 such that, for all suﬃciently small\nconstants ϵ > 0 and suﬃciently large N, the randomized communication complexity of computing an ϵ-NE\nis Ω(Nc).\nFor our purposes, a randomized protocol with communication cost b always uses at most b bits of\ncommunication, and terminates with at least one player knowing an ϵ-NE of the game with probability at\nleast 1\n2 (over the protocol’s coin ﬂips).\nThus, while there are lots of obstacles to players reaching an equilibrium of a game (see also Section 1.2.7),\ncommunication alone is already a signiﬁcant bottleneck. A corollary of Theorem 2.1 is that there can be no\nuncoupled dynamics (Section 1.3) that converge to an approximate Nash equilibrium in a sub-polynomial\nnumber of rounds in general bimatrix games (cf., the guarantee in Theorem 1.8 for smooth ﬁctitious play in\nzero-sum games). This is because uncoupled dynamics can be simulated by a randomized communication\nprotocol with logarithmic overhead (to communicate which strategy gets played each round).1 This corollary\nshould be regarded as a fundamental contribution to pure game theory and economics.\nThe goal of this and the next lecture is to sketch a full proof of the lower bound in Theorem 2.1 for\ndeterministic communication protocols. We do really care about randomized protocols, however, as these\nare the types of protocols induced by uncoupled dynamics (see Section 1.3.4).\nThe good news is that\n1See also footnote 12 in Solar Lecture 1.\n22\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 83
  },
  {
    "chunk_full": "“YES” \n“NO” \nDisjointness \nε-Nash Equilibria \nEvery \nequilibrium \nsatisfies π  \nNo \nequilibrium \nsatisfies π  \nFigure 2.1: A naive attempt to reduce the Disjointness problem to the problem of computing an approximate\nNash equilibrium.\nthe argument for the deterministic case will already showcase all of the conceptual ideas in the proof of\nTheorem 1.8. Extending the proof to randomized protocols requires substituting a simulation theorem for\nrandomized protocols (we’ll use only a simulation theorem for deterministic protocols, see Theorem 2.7)\nand a few other minor tweaks.2\n2.2\nNaive Approach: Reduction From Disjointness\nTo illustrate the diﬃculty of proving a result like Theorem 2.1, consider a naive attempt that tries to\nreduce, say, the Disjointness problem to the problem of computing an ϵ-NE, with YES-instances mapped\nto games in which all equilibria have some property Π, and NO-instances mapped to games in which no\nequilibrium has property Π (Figure 2.1).3 For the reduction to be useful, Π needs to be some property\nthat can be checked with little to no communication, such as “Alice plays her ﬁrst strategy with positive\nprobability” or “Bob’s strategy has full support.” The only problem is that this is impossible! The reason\nis that the problem of computing an approximate Nash equilibrium has polylogarithmic nondeterministic\ncommunication complexity (because of the existence of sparse approximate equilibria, see Theorem 1.15\nand Corollary 1.16), while the Disjointness function does not (for 1-inputs). A reduction of the proposed\nform would translate a nondeterministic lower bound for the latter problem to one for the former, and hence\ncannot exist.\nOur failed reduction highlights two diﬀerent challenges. The ﬁrst is to resolve the typechecking error\nthat we encountered between a standard decision problem, where there might or might not be a witness\n2When Babichenko and Rubinstein [9] ﬁrst proved their result (in late 2016), the state-of-the-art in simultaneous theorems for\nrandomized protocols was much more primitive than for deterministic protocols. This forced Babichenko and Rubinstein [9] to use\na relatively weak simulation theorem for the randomized case (by Göös et al. [65]), which led to a number of additional technical\ndetails in the proof. Amazingly, a full-blown randomized simulation theorem was published shortly after this workshop [67, 5]!\nWith this in hand, extending the argument here for deterministic protocols to randomized protocols is relatively straightforward.\n3Recall the Disjointness function: Alice and Bob have input strings a, b ∈{0, 1}n, and the output of the function is “0” if there\nis a coordinate i ∈{1, 2, . . ., n} with ai = bi = 1 and “1” otherwise. One of the ﬁrst things you learn in communication complexity\nis that the nondeterministic communication complexity of Disjointness (for certifying 1-inputs) is n (see e.g. [93, 130]). And of\ncourse one of the most famous and useful results in communication complexity is that the function’s randomized communication\ncomplexity (with two-sided error) is Ω(n) [83, 121].\n23\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 84
  },
  {
    "chunk_full": "(like Disjointness, where a witness is an element in the intersection), and a total search problem where\nthere is always a witness (like computing an approximate Nash equilibrium, which is guaranteed to exist\nby Nash’s theorem).\nThe second challenge is to ﬁgure out how to prove a strong lower bound on the\ndeterministic or randomized communication complexity of computing an approximate Nash equilibrium\nwithout inadvertently proving the same (non-existent) lower bound for nondeterministic protocols.\nTo\nresolve the second challenge, we’ll make use of simulation theorems that lift query complexity lower bounds\nto communication complexity lower bounds (see Section 2.7); these are tailored to a speciﬁc computational\nmodel, like deterministic or randomized protocols. For the ﬁrst challenge, we need to identify a total search\nproblem with high communication complexity. That is, for total search problems, which should be the analog\nof 3SAT or Disjointness? The correct answer turns out to be ﬁxed-point computation.\n2.3\nFinding Brouwer Fixed Points (The ϵ-BFP Problem)\nThis section and the next describe reductions from computing Nash equilibria to computing ﬁxed points,\nand from computing ﬁxed points to a path-following problem. These reductions are classical. The content\nof the proof in Theorem 2.1 are reductions in the opposite direction; these are discussed in Solar Lecture 3.\n2.3.1\nBrouwer’s Fixed-Point Theorem\nBrouwer’s ﬁxed-point theorem states that whenever you stir your coﬀee, there will be a point that ends up\nexactly where it began. Or if you prefer a more formal statement:\nTheorem 2.2 (Brouwer’s Fixed-Point Theorem (1910)). IfC is a compact convex subset of Rd, and f : C →C\nis continuous, then there exists a ﬁxed point: a point x ∈C with f (x) = x.\nAll of the hypotheses are necessary.4 We will be interested in a computational version of Brouwer’s\nﬁxed-point theorem, the ϵ-BFP problem:\nThe ϵ-BFP Problem (Generic Version)\ngiven a description of a compact convex set C ⊆Rd and a continuous function f : C →C, output an\nϵ-approximate ﬁxed point, meaning a point x ∈C such that ∥f (x) −x∥< ϵ.\nThe ϵ-BFP problem, in its many diﬀerent forms, plays a starring role in the study of equilibrium computation.\nThe set C is typically ﬁxed in advance, for example to the d-dimensional hypercube. While much of the work\non the ϵ-BFP problem has focused on the ℓ∞norm (e.g. [74]), one innovation in the proof of Theorem 2.1\nis to instead use a normalized version of the ℓ2 norm (following Rubinstein [135]).\nNailing down the problem precisely requires committing to a family of succinctly described continuous\nfunctions f . The description of the family used in the proof of Theorem 2.1 is technical and best left to\nSection 3.1. Often (and in these lectures), the family of functions considered contains only O(1)-Lipschitz\nfunctions.5 In particular, this guarantees the existence of an ϵ-approximate ﬁxed point with description\nlength polynomial in the dimension and log 1\nϵ (by rounding an exact ﬁxed point to its nearest neighbor on a\nsuitably deﬁned grid).\n4If convexity is dropped, consider rotating an annulus centered at the origin. If boundedness is dropped, consider x 7→x + 1\non R. If closedness is dropped, consider x 7→x\n2 on (0, 1]. If continuity is dropped, consider x 7→(x + 1\n2 ) mod 1 on [0, 1]. Many\nmore general ﬁxed-point theorems are known, and ﬁnd applications in economics and elsewhere; see e.g. [15, 103].\n5Recall that a function f deﬁned on a metric space (X, d) is λ-Lipschitz if d( f (x), f (y)) ≤λ · d(x, y) for all x, y ∈X. That is,\nthe function can only amplify distances between points by a λ factor.\n24\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 85
  },
  {
    "chunk_full": "2.3.2\nFrom Brouwer to Nash\nFixed-point theorems have long been used to prove equilibrium existence results, including the original proofs\nof the Minimax theorem (Theorem 1.1) and Nash’s theorem (Theorem 1.14).6 Analogously, algorithms for\ncomputing (approximate) ﬁxed points can be used to compute (approximate) Nash equilibria.\nFact 2.3. Existence/computation of ϵ-NE reduces to that of ϵ-BFP.\nTo provide further details, let’s sketch why Nash’s theorem (Theorem 1.14) reduces to Brouwer’s ﬁxed-\npoint theorem (Theorem 2.2), following the version of the argument in Geanakoplos [60].7 Consider a\nbimatrix game (A, B) and let S1, S2 denote the strategy sets of Alice and Bob (i.e., the rows and columns).\nThe relevant convex compact set is C = ∆1 × ∆2, where ∆i is the simplex representing the mixed strategies\nover Si. We want to deﬁne a continuous function f : C →C, from mixed strategy proﬁles to mixed strategy\nproﬁles, such that the ﬁxed points of f are the Nash equilibria of this game. We deﬁne f separately for\neach component fi : C →∆i for i = 1, 2. A natural idea is to set fi to be a best response of player i to the\nmixed strategy of the other player. This does not lead to a continuous, or even well deﬁned, function. We\ncan instead use a “regularized” version of this idea, deﬁning\nf1(x1, x2) = argmax\nx′\n1∈∆1\ng1(x′\n1, x2),\n(2.1)\nwhere\ng1(x′\n1, x2) = Ej∼x′\n1,ℓ∼x2\nf\nAjℓ\ng\n|              {z              }\nlinear in x′\n1\n−∥x′\n1 −x1∥2\n2\n|       {z       }\nstrictly convex\n,\n(2.2)\nand similarly for f2 and g2 (with Bob’s payoﬀmatrix B). The ﬁrst term of the function gi encourages a\nbest response while the second “penalty term” discourages big changes to player i’s mixed strategy. Because\nthe function gi is strictly concave in x′\ni, fi is well deﬁned. The function f = ( f1, f2) is continuous (as\nyou should check). By deﬁnition, every Nash equilibrium of the given game is a ﬁxed point of f . For the\nconverse, suppose that (x1, x2) is not a Nash equilibrium, with Alice (say) able to increase her expected\npayoﬀby deviating unilaterally from x1 to x′\n1. A simple computation shows that, for suﬃciently small ϵ > 0,\ng1((1 −ϵ)x1 + ϵx′\n1, x2) > g1(x1, x2), and hence (x1, x2) is not a ﬁxed point of f (as you should check).\nSummarizing, an oracle for computing Brouwer ﬁxed points immediately gives an oracle for computing\na Nash equilibrium of a bimatrix game. The same argument applies to games with any (ﬁnite) number of\nplayers. The same argument also shows that an oracle for computing an ϵ-approximate ﬁxed point in the ℓ∞\nnorm can be used to compute an O(ϵ)-approximate Nash equilibrium of a game. The ﬁrst high-level goal of\nthe proof of Theorem 2.1 is to reverse the direction of the reduction—to show that the problem of computing\nan approximate Nash equilibrium is as general as computing an approximate ﬁxed point, rather than merely\nbeing a special case.\nGoal #1\nϵ-BFP ≤ϵ-NE\n6In fact, the story behind von Neumann’s original proof of the Minimax theorem is a little more complicated and nuanced; see\nKjeldsen [89] for a fascinating and detailed discussion.\n7This discussion is borrowed from [129, Lecture 20].\n25\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 86
  },
  {
    "chunk_full": "witnesses\ncanonical source\nFigure 2.2: An instance of the EoL problem corresponds to a directed graph with all in- and out-degrees at\nmost 1. Solutions correspond to sink vertices and source vertices other than the given one.\nThis goal follows in the tradition of a sequence of celebrated computational hardness results last decade\nfor computing an exact Nash equilibrium (or an ϵ-approximate Nash equilibrium with ϵ polynomial in\n1\nn) [44, 34].\nThere are a couple of immediate issues. First, it’s not clear how to meaningfully deﬁne the ϵ-BFP\nproblem in a two-party communication model—what are Alice’s and Bob’s inputs? We’ll address this issue\nin Section 3.1. Second, even if we ﬁgure out how to deﬁne the ϵ-BFP problem and implement goal #1, so\nthat the ϵ-NE problem is at least as hard as the ϵ-BFP problem, what makes us so sure that the latter is hard?\nThis brings us to our next topic—a “generic” total search problem that is hard almost by deﬁnition and can\nbe used to transfer hardness to other problems (like ϵ-BFP) via reductions.8\n2.4\nThe End-of-the-Line (EoL) Problem\nFor equilibrium and ﬁxed-point computation problems, it turns out that the appropriate “generic” problem\ninvolves following a path in a large graph; see also Figure 2.2.\nThe EoL Problem (Generic Version)\ngiven a description of a directed graph G with maximum in- and out-degree 1, and a source vertex s\nof G, ﬁnd either a sink vertex of G or a source vertex other than s.\nThe restriction on the in- and out-degrees forces the graph G to consist of vertex-disjoint paths and cycles,\nwith at least one path (starting at the source s). The EoL problem is a total search problem—there is always\na solution, if nothing else the other end of the path that starts at s. Thus an instance of EoL can always be\nsolved by rotely following the path from s; the question is whether or not there is a more clever algorithm\nthat always avoids searching the entire graph.\nIt should be plausible that the EoL problem is hard, in the sense that there is no algorithm that always\nimproves over rote path-following; see also Section 2.6. But what does it have to do with the ϵ-BFP problem?\nA lot, it turns out.\n8For an analogy, a “generic” hard problem for the complexity class NP is: given a description of a polynomial-time veriﬁer,\ndoes there exist a witness (i.e., an input accepted by the veriﬁer)?\n26\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 87
  },
  {
    "chunk_full": "Figure 2.3: The proof of Sperner’s lemma, in action.\nFact 2.4. The problem of computing an approximate Brouwer ﬁxed point reduces to the EoL problem (i.e.,\nϵ-BFP ≤EoL).\nThe basic reason that ﬁxed-point computation reduces to path-following is Sperner’s Lemma.\nLemma 2.5 (Sperner’s Lemma). Consider a triangle with vertices A, B, C and a triangulation T of it.\nSuppose the vertices S of the triangulation T are 3-colored so that (1) A, B, and C receive distinct colors;\nand (2) each vertex on the boundary of ABC is colored with one of the two colors of the endpoints of its side\nof the triangle. Then, there exists an odd number of triangles of T for which all three corners have distinct\ncolors.\nFigure 2.3 illustrates the proof of Sperner’s lemma: starting at a source vertex outside the triangle, one\ncan continue moving through the triangulation (entering via a bichromatic edge) until one ﬁnally hits a\ntrichromatic triangle; in the picture, one enters each time via a red-yellow edge. In other words, ﬁnding a\ntrichromatic triangle reduces to the EoL problem.9\nNext we’ll use Sperner’s lemma to prove Brouwer’s ﬁxed-point theorem for a 2-dimensional simplex ∆.\nLet f : ∆→∆be a λ-Lipschitz function (with respect to the ℓ2 norm, say).\n1. Subdivide ∆into sub-triangles with side length at most ϵ/λ. Think of the points of ∆as parameterized\nby three coordinates (x, y, z), with x, y, z ≥0 and x + y + z = 1.\n2. Associate each of the three coordinates with a distinct color. To color a point (x, y, z), consider its\nimage (x′, y′, z′) under f and choose the color of a coordinate that strictly decreased (if there are\nnone, then (x, y, z) is a ﬁxed point and we’re done). Note that the conditions of Sperner’s Lemma are\nsatisﬁed.\n9We’re glossing over some details of the reduction. First, there is a canonical way to direct the edges of the graph induced by a\ncoloring, resulting in a directed graph as required for the EoL problem. Second, the source vertex outside the triangle can have odd\ndegree 2k −1 larger than 1; splitting it into k vertices (a source vertex with out-degree 1 and k −1 vertices with in- and out-degree\n1) yields a graph of the required form.\n27\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 88
  },
  {
    "chunk_full": "3. We claim that the center ( ¯x, ¯y, ¯z) of a trichromatic triangle must be an O(ϵ)-ﬁxed point (in the ℓ∞\nnorm). Because some corner of the triangle has its x-coordinate go down under f , ( ¯x, ¯y, ¯z) is at\ndistance at most ϵ/λ from this corner, and f is λ-Lipschitz, the x-coordinate of f ( ¯x, ¯y, ¯z) is at most\n¯x + O(ϵ). The same argument applies to ¯y and ¯z, which implies that each of the coordinates of\nf ( ¯x, ¯y, ¯z) is within ±O(ϵ) of the corresponding coordinate of ( ¯x, ¯y, ¯z).\nBy an inductive argument, Sperner’s Lemma extends to simplices in any (ﬁnite) number of dimensions.\nThe number of colors is one more than the number of dimensions, and a path-following argument implies\nthe existence of (an odd number of) sub-simplices for which every corner has a diﬀerent color. Analogs of\nSperner’s Lemma can also be proved by similar arguments for other natural sets, like hypercubes.10\nThis brings us to the second high-level goal of the proof of Theorem 2.1: to reverse the direction of\nthe above reduction from ϵ-BFP to EoL. That is, we would like to show that the problem of computing an\napproximate Brouwer ﬁxed point is as general as every path-following problem (of the form in EoL), and is\nnot merely a special case.\nGoal #2\nEoL ≤ϵ-BFP\nIf we succeed in implementing goals #1 and #2, and also prove directly that the EoL problem is hard, then\nwe’ll have proven hardness for the problem of computing an approximate Nash equilibrium.\n2.5\nRoad Map for the Proof of Theorem 2.1\nThe high-level plan for the proof in the rest of this and the next lecture is to show that\na low-cost communication protocol for ϵ-NE\nimplies\na low-cost communication protocol for ϵ-2BFP,\nwhere ϵ-2BFP is a two-party version of the problem of computing a ﬁxed point (to be deﬁned), which then\nimplies\na low-cost communication protocol for 2EoL,\nwhere 2EoL is a two-party version of the End-of-the-Line problem (to be deﬁned), which then implies\na low-query algorithm for EoL.\nFinally, we’ll prove directly that the EoL problem does not admit a low-query algorithm. This gives us four\nthings to prove (hardness of EoL and the three implications); we’ll tackle them one-by-one in reverse order.\nThe ﬁrst step (Section 2.6)) is easy. The second step (Section 2.7) follows directly from one of the simulation\ntheorems alluded to in Section 2.1. The last two steps, which correspond to goals #2 and #1, respectively,\nare harder and deferred to Solar Lecture 3.\n10Brouwer’s ﬁxed-point theorem in its full generality follows easily from Sperner’s Lemma. To prove Brouwer’s ﬁxed-point\ntheorem for simplices (of any dimension), take the limit ϵ →0 in the argument above and use the continuity of f . Because every\ncompact convex subset of ﬁnite-dimensional Euclidean space is homeomorphic to a simplex of the same dimension (by scaling and\nradial projection, essentially), Brouwer’s ﬁxed-point theorem carries over to all compact convex subsets of Euclidean space.\n28\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 89
  },
  {
    "chunk_full": "Most of the ingredients in this road map were already present in a paper by Omri Weinstein and your\nlecturer [133], which was the ﬁrst paper to deﬁne and study two-party versions of ﬁxed-point computation\nproblems, and to propose the use of simulation theorems in the context of equilibrium computation. One\nmajor innovation in Babichenko and Rubinstein [9] is the use of the generic EoL problem as the base of\nthe reduction, thereby eluding the tricky interactions in [133] between simulation theorems (which seem\ninherently combinatorial) and ﬁxed-point problems (which seem inherently geometric). Roughgarden and\nWeinstein [133] applied a simulation theorem directly to a ﬁxed-point problem (relying on strong query\ncomplexity lower bounds for ﬁnding ﬁxed points [74, 8]), which yielded a hard but unwieldy version of a\ntwo-party ﬁxed-point problem. It is not clear how to reduce this version to the problem of computing an\napproximate Nash equilibrium. Babichenko and Rubinstein [9] instead apply a simulation theorem directly\nto the EoL problem, which results in a reasonably natural two-party version of the problem (see Section 2.7).\nThere is signiﬁcant ﬂexibility in how to interpret this problem as a two-party ﬁxed-point problem, and the\ninterpretation in Babichenko and Rubinstein [9] (see Section 3.1) yields a version of the problem that is\nhard and yet structured enough to be solved using approximate Nash equilibrium computation. A second\ninnovation in [9] is the reduction from ϵ-2BFP to ϵ-NE (see Section 3.2) which, while not diﬃcult, is both\nnew and clever.\n2.6\nStep 1: Query Lower Bound for EoL\nWe consider the following “oracle” version of the EoL problem. The vertex set V is ﬁxed to be {0, 1}n. Let\nN = |V | = 2n. Algorithms are allowed to access the graph only through vertex queries. A query to the vertex\nv reveals its predecessor pred(v) (if any, otherwise pred(v) is NULL) and its successor succ(v) (or NULL\nif it has no successor). The interpretation is that the directed edge (v, w) belongs to the implicitly deﬁned\ndirected graph G = (V, E) if and only if both succ(v) = w and pred(w) = v. These semantics guarantee\nthat the graph has in- and out-degree at most 1. We also assume pred(0n) = NULL, and interpret the vertex\n0n as the a priori known source vertex of the graph.\nThe version of the EoL problem for this oracle model is:\nThe EoL Problem (Query Version)\ngiven an oracle as above, ﬁnd a vertex v ∈V that satisﬁes one of the following:\n(i) succ(v) is NULL;\n(ii) pred(v) is NULL and v , 0n;\n(iii) v , pred(succ(v)); or\n(iv) v , succ(pred(v)) and v , 0n.\nAccording to our semantics, cases (iii) and (iv) imply that v is a sink and source vertex, respectively. A\nsolution is guaranteed to exist—if nothing else, the other end of the path of G that originates with the\nvertex 0n.\nIt will sometimes be convenient to restrict ourselves to a “promise” version of the EoL problem (which\ncan only be easier), where the graph G is guaranteed to be a single Hamiltonian path. Even in this special\ncase, because every vertex query reveals information about only three vertices or less, we have the following.\n29\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 90
  },
  {
    "chunk_full": "Proposition 2.6. Every deterministic algorithm that solves the EoL problem requires Ω(N) queries in the\nworst case, even for instances that consist of a single Hamiltonian path.\nSlightly more formally, consider an adversary that always responds with values of succ(v) and pred(v)\nthat are never-before-seen vertices (except as necessary to maintain the consistency of all of the adversary’s\nanswers, so that cases (iii) and (iv) never occur). After only o(N) queries, the known parts of G constitute a\nbunch of vertex-disjoint paths, and G could still be (among other things) any Hamiltonian path of V consistent\nwith these. The end of this Hamiltonian path could be any of Ω(N) diﬀerent vertices, and the algorithm has\nno way of knowing which one.11\n2.7\nStep 2: Communication Complexity Lower Bound for 2EoL via a Simu-\nlation Theorem\nOur next step is to use a “simulation theorem” to transfer our query lower bound for the EoL problem to a\ncommunication complexity lower bound for a two-party version of the problem, 2EoL.12 The exact deﬁnition\nof the 2EoL problem will be determined by the output of the simulation theorem.\n2.7.1\nThe Query Model\nConsider an arbitrary function f : ΣN →Σ, where Σ denotes a ﬁnite alphabet. There is an input z =\n(z1, . . ., zN ) ∈ΣN, initially unknown to an algorithm. The algorithm can query the input z adaptively, with\neach query revealing zi for a coordinate i of the algorithm’s choosing. It is trivial to evaluate f (z) using N\nqueries; the question is whether or not there is an algorithm that always does better (for some function f\nof interest). For example, the query version of the EoL problem in Proposition 2.6 can be viewed as a\nspecial case of this model, with Σ = {0, 1}n × {0, 1}n (to encode pred(v) and succ(v)) and f (z) encoding\nthe (unique) vertex at the end of the Hamiltonian path.\n2.7.2\nSimulation Theorems\nWe now describe how a function f : ΣN →Σ as above induces a two-party communication problem. The\nidea is to “factor” the input z = (z1, . . ., zN ) to the query version of the problem between Alice and Bob, so\nthat neither player can unilaterally ﬁgure out any coordinate of z. We use an Index gadget for this purpose,\nas follows. (See also Figure 2.4.)\nTwo-Party Problem Induced by f : ΣN →Σ\nAlice’s input: N “blocks” A1, . . ., AN. Each block has M = poly(N) entries (with each entry in Σ).\n(Say, M = N20.)\nBob’s input: N indices y1, . . ., yN ∈[M].\nCommunication problem: compute f (A1[y1], . . ., AN[yN]).\n11A similar argument, based on choosing a Hamiltonian path of V at random, implies an Ω(N) lower bound for the randomized\nquery complexity as well.\n12These notes do not reﬂect a beautiful lecture given by Omri Weinstein on the history and applications of simulation theorems\n(e.g., to the ﬁrst non-trivial lower bounds for the clique vs. independent set problem [64]). Contact him for his slides!\n30\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 91
  },
  {
    "chunk_full": "A1 \nA2 \nAN \ny1 \ny2 \nyN \nAlice \nBob \nFigure 2.4: A query problem induces a two-party communication problem. Alice receives N blocks, each\ncontaining a list of possible values for a given coordinate of the input. Bob receives N indices, specifying\nwhere in Alice’s blocks the actual coordinates of the input reside.\nNote that the yith entry of Ai—Bob’s index into Alice’s block—is playing the role of zi in the original\nproblem. Thus each block Ai of Alice’s input can be thought of as a “bag of garbage;” it tells Alice a huge\nnumber of possible values for the ith coordinate of the input, without any clue about which is the “real one.”\nMeanwhile, Bob’s indices tell him the locations of the real values, without any clues about what these values\nare.\nIf f can be evaluated with a query algorithm that always uses at most q queries, then the induced\ntwo-party problem can be solved using O(q log N) bits of communication. For Alice can just simulate the\nquery algorithm; whenever it needs to query the ith coordinate of the input, Alice asks Bob for his index\nyi and supplies the query algorithm with Ai[yi]. Each of the at most q questions posed by Alice can be\ncommunicated with ≈log N bits, and each answer from Bob with ≈log M = O(log N) bits.\nThere could also be communication protocols for the two-party problem that look nothing like the\nstraightforward simulation. For example, Alice and Bob could send each other the exclusive-or of all of\ntheir input bits. While it may not clear why this would be useful, it’s equally unclear how to prove that it\ncan’t be useful. The remarkable Raz-McKenzie simulation theorem asserts that there are no communication\nprotocols for the two-party problem that improve over the straightforward simulation of a query algorithm.\nTheorem 2.7 (Raz-McKenzie Simulation Theorem [120, 66]). If every deterministic query algorithm for f\nrequires at least q queries in the worst case, then every deterministic communication protocol for the induced\ntwo-party problem has cost Ω(q log N).\nThe proof, which is not easy but also not unreadable, shows how to extract a good query algorithm from\nan arbitrary low-cost communication protocol (essentially by a potential function argument).\nThe original Raz-McKenzie theorem [120] and the streamlined version by Göös et al. [66] are both\nrestricted to deterministic algorithms and protocols, and this is the version we’ll use in these notes. Very\nrecently, Göös et al. [67] and Anshu et al. [5] proved the analog of Theorem 2.7 for randomized query\nalgorithms and randomized communication protocols (with two-sided error).13 This randomized simulation\n13Open question: prove a simulation theorem for quantum computation.\n31\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 92
  },
  {
    "chunk_full": "theorem simpliﬁes the original proof of Theorem 2.1 (which pre-dated [67, 5]) to the point that it’s almost\nthe same as the argument given here for the deterministic case.14\nThe Raz-McKenzie theorem provides a generic way to generate a hard communication problem from a\nhard query problem. We can apply it in particular to the EoL problem, and we call the induced two-party\nproblem 2EoL.15\nThe EoL Problem (Two-Party Version, 2EoL)\n• Let V = {0, 1}n and N = |V | = 2n.\n• Alice’s input consists of N blocks, one for each vertex of V, and each block Av contains M\nentries, each encoding a possible predecessor-successor pair for v.\n• Bob’s input consists of one index yv ∈{1, 2, . . ., M} for each vertex v ∈V, encoding the entry\nof the corresponding block holding the “real” predecessor-successor pair for v.\n• The goal is to identify a vertex v ∈V that satisﬁes one of the following:\n(i) the successor in Av[yv] is NULL;\n(ii) the predecessor in Av[yv] is NULL and v , 0n;\n(iii) Av[yv] encodes the successor w but Aw[yw] does not encode the predecessor v; or\n(iv) Av[yv] encodes the predecessor u but Au[yu] does not encode the successor v, and v , 0n.\nThe next statement is an immediate consequence of Claim 2.6 and Theorem 2.7.\nCorollary 2.8. The deterministic communication complexity of the 2EoL problem is Ω(N log N), even for\ninstances that consist of a single Hamiltonian path.\nA matching upper bound of O(N log N) is trivial, as Bob always has the option of sending Alice his\nentire input.\nCorollary 2.8 concludes the second step of the proof of Theorem 2.1 and furnishes a generic hard total\nsearch problem. The next order of business is to transfer this communication complexity lower bound to the\nmore natural ϵ-BFP and ϵ-NE problems via reductions.\n14For typechecking reasons, the argument for randomized protocols needs to work with a decision version of the EoL problem,\nsuch as “is the least signiﬁcant bit of the vertex at the end of the Hamiltonian path equal to 1?”\n15Raz and McKenzie [120] stated their result for the binary alphabet and for total functions. Göös et al. [66] note that it applies\nmore generally to arbitrary alphabets and partial functions, which is important for its application here. For further proof details of\nthese extensions, see Roughgarden and Weinstein [133].\n32\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 93
  },
  {
    "chunk_full": "Solar Lecture 3\nCommunication Complexity Lower Bound for Computing an Approximate Nash Equilibrium of a\nBimatrix Game (Part II)\nLecturer: Tim Roughgarden\nScribe: Michal Koucký and Pavel Pudlák\nThis lecture completes the proof of Theorem 2.1. As a reminder, this result states that if Alice’s and Bob’s\nprivate inputs are the two payoﬀmatrices of an N × N bimatrix game, and ϵ is a suﬃciently small constant,\nthen NΩ(1) communication is required to compute an ϵ-approximate Nash equilibrium (Deﬁnition 1.12), even\nwhen randomization is allowed. In terms of the proof road map in Section 2.5, it remains to complete steps 3\nand 4. This corresponds to implementing Goals #1 and #2 introduced in the last lecture—reversing the\ndirection of the classical reductions from the ϵ-BFP problem to path-following and from the ϵ-NE problem\nto (a two-party version of) the ϵ-BFP problem.\n3.1\nStep 3: 2EoL ≤ϵ-2BFP\n3.1.1\nPreliminaries\nWe know from Corollary 2.8 that 2EoL, the two-party version of the End-of-the-Line problem deﬁned in\nSection 2.7, has large communication complexity. This section transfers this lower bound to a two-party\nversion of an approximate ﬁxed point problem, by reducing the 2EoL problem to it.\nWe next deﬁne our two-party version of the ϵ-BFP problem, the ϵ-2BFP problem. The problem is\nparameterized by the dimension d and an approximation parameter ϵ. The latter should be thought of as a\nsuﬃciently small constant (independent of d).\nThe ϵ-BFP Problem (Informal Two-Party Version)\n• Let H = [0, 1]d denote the d-dimensional hypercube.\n• Alice and Bob possess private inputs that, taken together, implicitly deﬁne a continuous function\nf : H →H.\n• The goal is to identify an ϵ-approximate ﬁxed point, meaning a point x ∈H such that\n∥f (x) −x∥< ϵ, where ∥· ∥denotes the normalized ℓ2 norm:\n∥a∥=\nv\nu\nt\n1\nd\nd\nX\ni=1\na2\ni .\n33\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 94
  },
  {
    "chunk_full": "The normalized ℓ2 norm of a point in the hypercube (or the diﬀerence between two such points) is always\nbetween 0 and 1. If a point x ∈H is not an ϵ-approximate ﬁxed point with respect to this norm, then f (x)\nand x diﬀer by a constant amount in a constant fraction of the coordinates. This version of the problem can\nonly be easier than the more traditional version, which uses the ℓ∞norm.\nTo ﬁnish the description of the ϵ-2BFP problem, we need to explain how Alice and Bob interpret their\ninputs as jointly deﬁning a continuous function.\n3.1.2\nGeometric Intuition\nOur reduction from 2EoL to ϵ-2BFP will use no communication—Alice and Bob will simply reinterpret\ntheir 2EoL inputs as ϵ-2BFP inputs in a speciﬁc way, and a solution to the 2EoL instance will be easy to\nrecover from any approximate ﬁxed point.\nFigure 3.1 shows the key intuition: graphs of paths and cycles naturally lead to continuous functions,\nwhere the gradient of the function “follows the line” and ﬁxed points correspond to sources and sinks of the\ngraph.\nFigure 3.1: Directed paths and cycles can be converted to continuous functions that “follow the line.” Points\nfar from the path are moved by f is some canonical direction. (Figure courtesy of Yakov Babichenko.)\nThis idea originates in Hirsch et al. [74], who considered approximate ﬁxed points in the ℓ∞norm.\nRubinstein [135] showed how to modify the construction so that it works even for the normalized ℓ2 norm.\nBabichenko and Rubinstein [9] used the construction from [135] in their proof of Theorem 2.1; our treatment\nhere includes some simpliﬁcations.\n3.1.3\nEmbedding a Graph in the Hypercube\nBefore explaining exactly how to interpret graphs as continuous functions, we need to set up an embedding\nof every possible graph on a given vertex set into the hypercube.\nLet V = {0, 1}n and N = |V | = 2n. Let K denote the complete undirected graph with vertex set V—all\nedges that could conceivably be present in an EoL instance (ignoring their orientations). Decide once and\n34\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 95
  },
  {
    "chunk_full": "for all on an embedding σ of K into H = [0, 1]d, where d = Θ(n) = Θ(log N), with two properties:1\n(P1) The images of the vertices are well separated: for every v, w ∈V (with v , w), ∥σ(v) −σ(w)∥is at\nleast some constant (say 1\n10).\n(P2) The images of the edges are well separated. More precisely, a point x ∈H is close (within distance\n10−3, say) to the images σ(e) and σ(e′) of distinct edges e and e′ only if x is close to the image of a\nshared endpoint of e and e′. (In particular, if e and e′ have no endpoints in common, then no x ∈H is\nclose to both σ(e) and σ(e′).)\nProperty (P1) asserts that the images of two diﬀerent vertices diﬀer by a constant amount in a constant\nfraction of their coordinates.2 One natural way to achieve this property is via an error-correcting code with\nconstant rate. The simplest way to achieve both properties is to take a random straight-line embedding. Each\nvertex v ∈V is mapped to a point in { 1\n4, 3\n4}d, with each coordinate set to 1\n4 or 3\n4 independently with 50/50\nprobability.3 Each edge is mapped to a straight line between the images of its endpoints. Provided d = cn\nfor a suﬃciently large constant c, properties (P1) and (P2) both hold with high probability.4\nThe point of properties (P1) and (P2) is to classify the points of H into three categories: (i) those close\nto the image of a (unique) vertex of K; (ii) those not close to the image of any vertex but close to the image\nof a (unique) edge of K; and (iii) points not close to the image of any vertex or edge of K. Accordingly, each\npoint x ∈H can be “decoded” to a unique vertex v of K, a unique edge (v, w) of K, or ⊥. Don’t forget that\nthis classiﬁcation of points of H is made in advance of receiving any particular EoL input. In the ϵ-2BFP\nproblem, since Alice and Bob both know the embedding in advance, they can decode points at will without\nany communication.5\n3.1.4\nInterpreting Paths as Continuous Functions\nGiven the embedding above, we can now describe how to interpret a directed graph G = (V, E) induced\nby an instance of EoL as a continuous function on the hypercube, with approximate ﬁxed points of the\nfunction corresponding only to sources and sinks of G. Write a function f : H →H as f (x) = x + g(x)\nfor the “displacement function” g : H →[−1, 1]d. (The ﬁnal construction will take care to deﬁne g so that\nx + g(x) ∈H for every x ∈H.) An ϵ-approximate ﬁxed point is a point x with ∥g(x)∥< ϵ, so it’s crucial for\nour reduction that our deﬁnition of g satisﬁes ∥g(x)∥≥ϵ whenever x is not close to the image of a source\nor sink of G.\nConsider for simplicity a directed graph G = (V, E) of an EoL instance that has no 2-cycles and no\n1By an embedding, we mean a function σ that maps each edge (v, w) of K to a continuous path in H with endpoints σ(v) and\nσ(w).\n2In the original construction of Hirsch et al. [74], vertices of K could potentially be mapped to points of H that diﬀer signiﬁcantly\nin only one coordinate. This construction is good enough to prevent spurious approximate ﬁxed points in the ℓ∞norm, but not in\nthe normalized ℓ2 norm.\n3For reasons related to the omitted technical details,, it’s convenient to have a “buﬀer zone” between the embedding of the graph\nand the boundary of the hypercube.\n4In the two-party communication model, we need not be concerned about eﬃciently constructing such an embedding. Since\nAlice and Bob have unbounded computational power, they can both compute the lexicographically ﬁrst such embedding in advance\nof the protocol. When we consider computational lower bounds in Solar Lecture 5, we’ll need an eﬃcient construction.\n5As suggested by Figure 3.1, in the ﬁnal construction it’s important to use a more nuanced classiﬁcation that “interpolates”\nbetween points in the three diﬀerent categories. It will still be the case that Alice and Bob can classify any point of x ∈H\nappropriately without any communication.\n35\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 96
  },
  {
    "chunk_full": "isolated vertices.6 A rough description of the displacement function g(x) induced by G is as follows, where\nδ > 0 is a parameter (cf., Figure 3.1):\n1. If x is close to σ(e), where the endpoints of e are u and v, then\ng(x) = δ ·\n\ndirection of the line segment σ(e), oriented from u to v\nif directed edge (u, v) ∈E\ndirection of the line segment σ(e), oriented from v to u\nif directed edge (v, u) ∈E\nsome default direction\notherwise.\n2. For x close to σ(v), for v ∈G,\n(a) if v has an incoming edge (u, v) and an outgoing edge (v, w), then deﬁne g(x) by interpolating\nthe displacement vectors corresponding to the edges (u, v) and (v, w) (i.e., “turn slowly” as in\nFigure 3.1);\n(b) otherwise (i.e., v is a source or sink of G), set g(x) to interpolate the direction of the incoming\nor outgoing edge (whichever one exists) and the all-0 vector.\n3. For x that are not close to any σ(v) or σ(e), set g(x) to δ times the default direction.\nFor points x “in between” the three cases (e.g., almost but not quite close enough to the image of an edge),\ng(x) is deﬁned by interpolation (e.g., a weighted average of the direction of the edge and the default direction,\nwith weights determined by just how close x is to the image of the edge).\nThe default direction can be implemented by doubling the number of dimensions to 2d, and deﬁning\nthe displacement direction as the vector (0, 0, . . ., 0, 1, 1, . . ., 1). Special handling (not detailed here) is then\nrequired at points x with value close to 1 in one of these extra coordinates, to ensure that x + g(x) remains in\nH while also not introducing any unwanted approximate ﬁxed points. Similarly, special handling is required\nfor the source vertex 0n, to prevent σ(0n) from being a ﬁxed point. Roughly, this can be implemented by\nmapping the vertex 0n to one corner of the hypercube and deﬁning g to point in the opposite direction. The\nparameter δ is a constant, bigger than ϵ by a constant factor. (For example, one can assume that ϵ ≤10−12\nand take δ ≈10−6.) This ensures that whenever the normalized ℓ2 norm of a direction vector y is at least\na suﬃciently large constant, δ · y has norm larger than ϵ. This completes our sketch of how to interpret an\ninstance of EoL as a continuous function on the hypercube.\n3.1.5\nProperties of the Construction\nProperly implemented, the construction in Sections 3.1.3 and 3.1.4 has the following properties:\n1. Provided ϵ is at most a suﬃciently small constant, a point x ∈H satisﬁes ∥g(x)∥< ϵ only if it is close\nto the image of a source or sink of G diﬀerent from the canonical source 0n. (Intuitively, this should\nbe true by construction.)\n2. There is a constant λ, independent of d, such that the function f (x) = x + g(x) is λ-Lipschitz. In\nparticular, f is continuous. (Intuitively, this is because we take care to linearly interpolate between\nregions of H with diﬀerent displacement vectors.)\n6Recall from Corollary 2.8 that the 2EoL problem is already hard in the special case where the induced graph G is guaranteed\nto be a Hamiltonian path.\n36\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 97
  },
  {
    "chunk_full": "Sections 3.1.3 and 3.1.4, together with Figure 3.1, provide a plausibility argument that a construction with\nthese two properties is possible along the proposed lines. Readers interested in further details are encouraged\nto start with the carefully written two-dimensional construction in [74, Section 4]—where many of these ideas\noriginate—before proceeding to the general case in [74, Section 5] for the ℓ∞norm and ﬁnally Babichenko\nand Rubinstein [9] for the version tailored to the normalized ℓ2 norm (which is needed here).\n3.1.6\nThe ϵ-2BFP Problem and Its Communication Complexity\nWe can now formally deﬁne the two-party version of the ϵ-BFP problem that we consider, denoted ϵ-2BFP.\nThe problem is parameterized by a positive integer n and a constant ϵ > 0.\nThe ϵ-2BFP Problem\n• Alice and Bob begin with private inputs to the 2EoL problem: Alice with N = 2n “blocks”\nA1, . . ., AN, each with M = poly(N) entries from the alphabet Σ = {0, 1}n × {0, 1}n, and Bob\nwith N indices y1, . . ., yN ∈[M].\n• Let G be the graph induced by these inputs (with V = {0, 1}n and Av[yv] encoding\n(pred(v), succ(v)).\n• Let f denote the continuous function f : H →H induced by G, as per the construction in\nSections 3.1.3 and 3.1.4, where H = [0, 1]d is the d-dimensional hypercube with d = Θ(n).\n• The goal is to compute a point x ∈H such that ∥f (x) −x∥< ϵ, where ∥·∥denotes the normalized\nℓ2 norm.\nThe two properties in Section 3.1.5 imply a communication complexity lower bound for the ϵ-2BFP\nproblem and implement step 3 of the road map in Section 2.5.\nTheorem 3.1 ([9]). For every suﬃciently small constant ϵ > 0, the deterministic communication complexity\nof the ϵ-2BFP problem is Ω(N log N), even for O(1)-Lipschitz functions.\nProof. If there is a deterministic communication protocol with cost c for the ϵ-2BFP problem, then there is\nalso one for the 2EoL problem: Alice and Bob interpret their 2EoL inputs as inputs to the ϵ-2BFP problem,\nrun the assumed protocol to compute an ϵ-approximate ﬁxed point x, and (using no communication)\ndecode x to a source or sink vertex v of G (that is diﬀerent from 0n). The theorem follows immediately from\nCorollary 2.8.\n□\n3.1.7\nLocal Decodability of ϵ-2BFP Functions\nThere is one more important property of the functions f constructed in Sections 3.1.3 and 3.1.4: they are\nlocally decodable in a certain sense. Suppose Alice and Bob want to compute the value of f (x) at some\ncommonly known point x ∈H. If x decodes to ⊥(i.e., is not close to the image of any vertex or edge of the\ncomplete graph K on vertex set V), then Alice and Bob know the value of f (x) without any communication\nwhatsoever: f (x) is x plus δ times the default direction (or a known customized displacement if x is too\nclose to certain boundaries of H). If x decodes to the edge e = (u, v) of the complete graph K, then Alice and\nBob can compute f (x) as soon as they know whether or not edge e belongs to the directed graph G induced\nby their inputs, along with its orientation. This requires Alice and Bob to exchange predecessor-successor\ninformation about only two vertices (u and v). Analogously, if x decodes to the vertex v of K, then Alice and\nBob can compute f (x) after exchanging information about at most three vertices (v, pred(v), and succ(v)).\n37\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 98
  },
  {
    "chunk_full": "3.2\nStep 4: ϵ-2BFP ≤ϵ-NE\nThis section completes the proof of Theorem 2.1 by reducing the ϵ-2BFP problem to the ϵ-NE problem,\nwhere ϵ is a suﬃciently small constant.\n3.2.1\nThe McLennan-Tourky Analytic Reduction\nThe starting point for our reduction is a purely analytic reduction of McLennan and Tourky [104], which\nreduces the existence of (exact) Brouwer ﬁxed points to the existence of (exact) Nash equilibria.7 Subsequent\nsections explain the additional ideas needed to implement this reduction for approximate ﬁxed points and\nNash equilibria in the two-party communication model.\nTheorem 3.2 (McLennan and Tourky [104]). Nash’s theorem (Theorem 1.14) implies Brouwer’s ﬁxed-point\ntheorem (Theorem 2.2).\nProof. Consider an arbitrary continuous function f : H →H, where H = [0, 1]d is the d-dimensional\nhypercube (for some positive integer d).8 Deﬁne a two-player game as follows. The pure strategies of Alice\nand Bob both correspond to points of H. For pure strategies x, z ∈H, Alice’s payoﬀis deﬁned as\n1 −∥x −z∥2 = 1 −1\nd\nd\nX\ni=1\n(xi −zi)2\n(3.1)\nand Bob’s payoﬀas\n1 −∥z −f (x)∥2 = 1 −1\nd\nd\nX\ni=1\n(zi −f (x)i)2.\n(3.2)\nAlice wants to imitate Bob’s strategy, while Bob wants to imitate the image of Alice’s strategy under the\nfunction f .\nFor any mixed strategy σ of Bob (i.e., a distribution over points of the hypercube), Alice’s unique best\nresponse is the corresponding center of gravity Ez∼σ[z] (as you should check). Thus in any Nash equilibrium,\nAlice plays a pure strategy x. Bob’s unique best response to such a pure strategy is the pure strategy z = f (x).\nThat is, every Nash equilibrium is pure, with x = z = f (x) a ﬁxed point of f . Since a Nash equilibrium\nexists, so does a ﬁxed point of f .9\n□\nAn extension of the argument above shows that, for λ-Lipschitz functions f , an ϵ ′-approximate ﬁxed\npoint (in the normalized ℓ2 norm) can be extracted easily from any ϵ-approximate Nash equilibrium, where ϵ ′\nis a function of ϵ and λ only.10\n7This reduction was popularized in a Leisure of the Theory Class blog post by Eran Shmaya (https://theoryclass.\nwordpress.com/2012/01/05/brouwer-implies-nash-implies-brouwer/), who heard about the result from Rida Laraki.\n8If ﬁxed points are guaranteed for hypercubes in every dimension, then they are also guaranteed for all compact convex subsets\nof ﬁnite-dimensional Euclidean space; see footnote 10 in Solar Lecture 2.\n9Strictly speaking, we’re assuming a more general form of Nash’s theorem that asserts the existence of a pure Nash equilibrium\nwhenever every player has a convex compact strategy set (like H) and a continuous concave payoﬀfunction (like (3.1) and (3.2)).\n(The version in Theorem 1.14 corresponds to the special case where each strategy set corresponds to a ﬁnite-dimensional simplex\nof mixed strategies, and where all payoﬀfunctions are linear.) Most proofs of Nash’s theorem—including the one outlined in\nSection 2.3.2—are straightforward to generalize in this way.\n10It is not clear how to easily extract an approximate ﬁxed point in the ℓ∞norm from an approximate Nash equilibrium without\nlosing a super-constant factor in the parameters. The culprit is the “ 1\nd ” factor in (3.1) and (3.2)—needed to ensure that payoﬀs are\nbounded—which allows each player to behave in an arbitrarily crazy way in a few coordinates without violating the ϵ-approximate\nNash equilibrium conditions. (Recall ϵ > 0 is constant while d →∞.) This is one of the primary reasons why Rubinstein [135]\nand Babichenko and Rubinstein [9] needed to modify the construction in Hirsch et al. [74] to obtain their results.\n38\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 99
  },
  {
    "chunk_full": "3.2.2\nThe Two-Party Reduction: A Naive Attempt\nWe now discuss how to translate the McLennan-Tourky analytic reduction to an analogous reduction in the\ntwo-party model. First, we need to discretize the hypercube. Deﬁne Hϵ as the set of ≈\n\u0010 1\nϵ\n\u0011n points of\n[0, 1]d for which all coordinates are multiples of ϵ. Every O(1)-Lipschitz function f is guaranteed to have an\nO(ϵ)-approximate ﬁxed point at some point of the discretized hypercube (by rounding an exact ﬁxed point\nto its nearest neighbor in Hϵ). This also means that the corresponding game (with payoﬀs deﬁned as in (3.1)\nand (3.2)) has an O(ϵ)-approximate Nash equilibrium in which each player deterministically chooses a point\nof Hϵ.\nThe obvious attempt at a two-party version of the McLennan-Tourky reduction is:\n1. Alice and Bob start with inputs to the ϵ-2BFP problem.\n2. The players interpret these inputs as a two-player game, with strategies corresponding to points of the\ndiscretized hypercube Hϵ, and with Alice’s payoﬀs given by (3.1) and Bob’s payoﬀs by (3.2).\n3. The players run the assumed low-cost communication protocol for computing an approximate Nash\nequilibrium.\n4. The players extract an approximate ﬁxed point of the ϵ-2BFP function from the approximate Nash\nequilibrium.\nJust one problem: this doesn’t make sense. The issue is that Bob needs to be able to compute f (x) to\nevaluate his payoﬀfunction in (3.2), and his ϵ-2BFP input (just a bunch of indices into Alice’s blocks) does\nnot provide suﬃcient information to do this. Thus, the proposed reduction does not produce a well-deﬁned\ninput to the ϵ-NE problem.\n3.2.3\nDescription of the Two-Party Reduction\nThe consolation prize is that Bob can compute the function f at a point x after a brief conversation with Alice.\nRecall from Section 3.1.7 that computing f at a point x ∈H requires information about at most three vertices\nof the 2EoL input that underlies the ϵ-2BFP input (in addition to x). Alice can send x to Bob, who can then\nsend the relevant indices to Alice (after decoding x to some vertex or edge of K), and Alice can respond\nwith the corresponding predecessor-successor pairs. This requires O(log N) bits of communication, where\nN = 2n is the number of vertices in the underlying 2EoL instance. (We are suppressing the dependence on\nthe constant ϵ in the big-O notation.) Denote this communication protocol by P.\nAt this point, it’s convenient to restrict the problem to the hard instances of 2EoL used to prove\nCorollary 2.8, where in particular, succ(v) = w if and only if v = pred(w). (I.e., cases (iii) and (iv) in the\ndeﬁnition of the 2EoL problem in Section 2.7 never come up.) For this special case, P can be implemented\nas a two-round protocol where Alice and Bob exchange information about one relevant vertex v (if x decodes\nto v) or two relevant vertices u and v (if x decodes to the edge (u, v)).11\nHow can we exploit the local decodability of ϵ-2BFP functions? The idea is to enlarge the strategy\nsets of Alice and Bob, beyond the discretized hypercube Hϵ, so that the players’ strategies at equilibrium\n11If x decodes to the edge (u, v), then Alice and Bob exchange information about u and v in two rounds. If x decodes to the\nvertex v, they exchange information about v in two rounds. This reveals v’s opinion of its predecessor u and successor w. In the\ngeneral case, Alice and Bob would still need to exchange information about u and w using two more rounds of communication to\nconﬁrm that succ(u) = pred(w) = v. (Recall our semantics: directed edge (u, v) belongs to G if and only if both succ(u) = v\nand pred(v) = u.) In the special case of instances where succ(v) = w if and only if v = pred(w), these two extra rounds of\ncommunication are redundant.\n39\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 100
  },
  {
    "chunk_full": "eﬀectively simulate the protocol P. Alice’s pure strategies are the pairs (x, α), where x ∈Hϵ is a point of\nthe discretized hypercube and α is a possible transcript of Alice’s communication in the protocol P. Thus α\nconsists of at most two predecessor-successor pairs. Bob’s pure strategies are the pairs (z, β), where z ∈Hϵ\nand β is a transcript that could be generated by Bob in P—a speciﬁcation of at most two diﬀerent vertices\nand his corresponding indices for them.12 Crucially, because the protocol P has cost O(log N), there are\nonly NO(1) possible α’s and β’s. There are also only NO(1) possible choices of x and z—since ϵ is a constant\nand d = Θ(n) in the ϵ-2BFP problem, |Hϵ| ≈\n\u0010 1\nϵ\n\u0011d is polynomial in N = 2n. We conclude that the size of\nthe resulting game is polynomial in the length of the given ϵ-2BFP (or 2EoL) inputs.\nWe still need to deﬁne the payoﬀs of the game. Let A1, . . ., AN and y1, . . ., yN denote Alice’s and Bob’s\nprivate inputs in the given ϵ-2BFP (equivalently, 2EoL) instance and f the corresponding function. Call an\noutcome (x, α, z, β) consistent if α and β are the transcripts generated by Alice and Bob when they honestly\nfollow the protocol P to compute f (x). Precisely, a consistent outcome is one that meets the following two\nconditions:\n(i) for each of the (zero, one, or two) vertices v named in β, and corresponding index ˆyv announced by\nBob in β, α contains the correct response Av[ˆyv];\n(ii) β speciﬁes the names of the vertices relevant for Alice’s announced point x ∈Hϵ, and for each such\nvertex v, β speciﬁes the correct index yv.\nObserve that Alice can privately check if condition (i) holds (using her private input A1, . . ., AN and the\nvertex names and indices in Bob’s announced strategy β), and Bob can privately check condition (ii) (using\nhis private input y1, . . ., yN and the point x announced by Alice).\nFor an outcome (x, z, α, β), we deﬁne Alice’s payoﬀs by\n( −1 −1\nd\nPd\ni=1(xi −zi)2\nif (i) fails\n1 −1\nd\nPd\ni=1(xi −zi)2\notherwise.\n(3.3)\n(Compare (3.3) with (3.1).) This deﬁnition makes sense because Alice can privately check whether or not (i)\nholds and hence can privately compute her payoﬀ.13\nFor Bob’s payoﬀs, we need a preliminary deﬁnition.\nLet fα(x) denote the value that the induced\nfunction f would take on if α was consistent with x and with Alice’s and Bob’s private inputs. That is, to\ncompute fα(x):\n1. Decode x to a vertex or an edge (or ⊥).\n2. Interpret α as the predecessor-successor pairs for the vertices relevant for evaluating f at x.\n3. Output x plus the displacement gα(x) deﬁned as in Sections 3.1.3 and 3.1.4 (with α supplying any\npredecessor-successor pairs that are necessary).\nTo review, f is the ϵ-2BFP function that Alice and Bob want to ﬁnd a ﬁxed point of, and f (x) generally\ndepends on the private inputs A1, . . ., AN and y1, . . ., yN of both Alice and Bob. The function fα is a\nspeculative version of f , predicated on Alice’s announced predecessor-successor pairs in her strategy α.\nCrucially, the deﬁnition of fα does not depend at all on Alice’s private input, only on Alice’s announced\n12In the protocol P, Bob does not need to communicate the names of any vertices—Alice can decode x privately. But it’s\nconvenient for the reduction to include the names of the vertices relevant for x in the β part of Bob’s strategy.\n13If you want to be a stickler and insist on payoﬀs in [0, 1], then shift and scale the payoﬀs in (3.3) appropriately.\n40\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 101
  },
  {
    "chunk_full": "strategy. Thus given α, Bob can privately execute the three steps above and evaluate fα(x) for any x ∈Hϵ.\nThe other crucial property of fα is that, if α happens to be the actual predecessor-successor pairs {Av[yv]}\nfor the vertices relevant for x (given Alice’s and Bob’s private inputs), then fα(x) agrees with the value f (x)\nof the true ϵ-2BFP function.\nWe can now deﬁne Bob’s payoﬀs as follows (compare with (3.2)):\n(\n−1\nif (ii) fails\n1 −1\nd\nPd\ni=1(zi −fα(x)i)2\notherwise.\n(3.4)\nBecause Bob can privately check condition (ii) and compute fα(x) (given x and α), Bob can privately\ncompute his payoﬀ. This completes the description of the reduction from the ϵ-2BFP problem to the ϵ-NE\nproblem.\nAlice and Bob can carry out this reduction with no communication—by construction, their ϵ-2BFP inputs\nfully determine their payoﬀmatrices. As noted earlier, because ϵ is a constant, the sizes of the produced\nϵ-NE inputs are polynomial in those of the ϵ-2BFP inputs.\n3.2.4\nAnalysis of the Two-Party Reduction\nFinally, we need to show that the reduction “works,” meaning that Alice and Bob can recover an approximate\nﬁxed point of the ϵ-2BFP function f from any approximate Nash equilibrium of the game produced by the\nreduction.\nFor intuition, let’s think ﬁrst about the case where Alice’s and Bob’s strategies are points of the hyper-\ncube H (rather than the discretized hypercube Hϵ) and the case of exact ﬁxed points and Nash equilibria.\n(Cf., Theorem 3.2.) What could a Nash equilibrium of the game look like? Consider mixed strategies by\nAlice and Bob.\n1. Alice’s payoﬀin (3.3) includes a term −1\nd\nPd\ni=1(xi −zi)2 that is independent of her choice of α or Bob’s\nchoice of β, and the other term (either 1 or -1) is independent of her choice of x (since condition (i)\ndepends only on α and β). Thus, analogous to the proof of Theorem 3.2, in every one of Alice’s best\nresponses, she deterministically chooses x = Ez∼σ[z], where σ denotes the marginal distribution of z\nin Bob’s mixed strategy.\n2. Given that Alice is playing deterministically in her x-coordinate, in every one of Bob’s best responses,\nhe deterministically chooses β to name the vertices relevant for Alice’s announced point x and his\nindices for these vertices (to land in the second case of (3.4) with probability 1).\n3. Given that Bob is playing deterministically in his β-coordinate, Alice’s unique best response is to\nchoose x as before and also deterministically choose the (unique) message α that satisﬁes condition (i),\nso that she will be in the more favorable second case of (3.3) with probability 1.\n4. Given that Alice is playing deterministically in both her x- and α-coordinates, Bob’s unique best\nresponse is to choose β as before and set z = fα(x) (to maximize his payoﬀin the second case\nof (3.4)).\nThese four steps imply that every (exact) Nash equilibrium (x, z, α, β) of the game is pure, with α and β\nconsistent with x and Alice’s and Bob’s private information about the corresponding relevant vertices, and\nwith x = z = fα(x) = f (x) a ﬁxed point of f .\nAs with Theorem 3.2, a more technical version of the same argument implies that an approximate ﬁxed\npoint—a point x satisfying ∥f (x) −x∥< ϵ ′ with respect to the normalized ℓ2 norm—can be easily extracted\n41\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 102
  },
  {
    "chunk_full": "by Alice and Bob from any ϵ-approximate Nash equilibrium, where ϵ ′ depends only on ϵ (e.g., ϵ ′ = O(ϵ1/4)\nsuﬃces). For example, the ﬁrst step of the proof becomes: in an ϵ-approximate Nash equilibrium, Alice\nmust choose a point x ∈Hϵ that is close to E[z] except with small probability (otherwise she could increase\nher expected payoﬀby more than ϵ by switching to the point of Hϵ closest to E[z]). And so on. Carrying\nout approximate versions of all four steps above, while keeping careful track of the epsilons, completes the\nproof of Theorem 2.1.\nWe conclude that computing an approximate Nash equilibrium of a general bimatrix game takes a\npolynomial amount of communication, and in particular there are no uncoupled dynamics guaranteed to\nconverge to in a polylogarithmic number of iterations.\n42\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 103
  },
  {
    "chunk_full": "Solar Lecture 4\nTFNP, PPAD & All That\nLecturer: Tim Roughgarden\nScribe: Amey Bhangale\nHaving resolved the communication complexity of computing an approximate Nash equilibrium of a\nbimatrix game, we turn our attention to the computational complexity of the problem. Here, the goal will be to\nprove a super-polynomial lower bound on the amount of computation required, under appropriate complexity\nassumptions. The techniques developed in the last two lectures for our communication complexity lower\nbound will again prove useful for this goal, but we will also need several additional ideas.\nThis lecture identiﬁes the appropriate complexity class for characterizing the computational complexity\nof computing an exact or approximate Nash equilibrium of a bimatrix game, namely PPAD. Solar Lecture 5\nsketches some of the ideas in Rubinstein’s recent proof [135] of a quasi-polynomial-time lower bound for\nthe problem, assuming an analog of the Exponential Time Hypothesis for PPAD.\nSection 4.1 explains why customized complexity classes are needed to reason about equilibrium com-\nputation and other total search problems. Section 4.2 deﬁnes the class TFNP and some of its syntactic\nsubclasses, including PPAD.1\nSection 4.3 reviews a number of PPAD-complete problems. Section 4.4\ndiscusses the existing evidence that TFNP and its important subclasses are hard, and proves that the class\nTFNP is hard on average assuming that NP is hard on average.\n4.1\nPreamble\nWe consider two-player (bimatrix) games, where each player has (at most) n strategies. The n × n payoﬀ\nmatrices for Alice and Bob A and B are described explicitly, with Ai j and Bi j indicating Alice’s and Bob’s\npayoﬀs when Alice plays her ith strategy and Bob his jth strategy. Recall from Deﬁnition 1.12 that an ϵ-NE\nis a pair ˆx, ˆy of mixed strategies such that neither player can increase their payoﬀwith a unilateral deviation\nby more than ϵ.\nWhat do we know about the complexity of computing an ϵ-NE of a bimatrix game? Let’s start with the\nexact case (ϵ = 0), where no subexponential-time (let alone polynomial-time) algorithm is known for the\nproblem. (This contrasts with the zero-sum case, see Corollary 1.5.) It is tempting to speculate that no such\nalgorithm exists. How would we amass evidence that the problem is intractable? Since we’re interested in\nsuper-polynomial lower bounds, communication complexity is of no direct help.\nCould the problem be NP-complete?2 The following theorem by Megiddo and Papadimitriou rules out\nthis possibility (unless NP = co-NP).\n1Some of the discussion in these two sections is drawn from [129, Lecture 20].\n2Technically, we’re referring to the search version of NP (sometimes called FNP, where the “F” stands for “functional”), where\nthe goal is to either exhibit a witness or correctly deduce that no witness exists.\n43\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 104
  },
  {
    "chunk_full": "Instance   \nϕ of SAT \nBimatrix \ngame A1(ϕ)  \nA1 \nA2 \nAlgorithm     \nfor computing \nMNE \nMNE of A1(ϕ) \nsolution       \nto ϕ \nAlgorithm for SAT \n“no solution” \nFigure 4.1: A reduction from the search version of the SAT problem to the problem of computing a Nash\nequilibrium of a bimatrix game would yield a polynomial-time veriﬁer for the unsatisﬁability problem.\nTheorem 4.1 ([105]). The problem of computing a Nash equilibrium of a bimatrix game is NP-hard only if\nNP = co-NP.\nProof. The proof is short but a bit of a mind-bender, analogous to the argument back in Section 2.2. Suppose\nthere is a reduction from, say, (the search version of) satisﬁability to the problem of computing a Nash\nequilibrium of a bimatrix game. By deﬁnition, the reduction comprises two algorithms:\n1. A polynomial-time algorithm A1 that maps every SAT formula φ to a bimatrix game A1(φ).\n2. A polynomial-time algorithm A2 that maps every Nash equilibrium ( ˆx, ˆy) of a game A1(φ) to a\nsatisfying assignment A2( ˆx, ˆy) of φ, if one exists, and to the string “no” otherwise.\nWe claim that the existence of these algorithms A1 and A2 imply that NP = co-NP (see also Figure 4.1).\nIn proof, consider an unsatisﬁable SAT formula φ, and an arbitrary Nash equilibrium ( ˆx, ˆy) of the game\nA1(φ).3 We claim that ( ˆx, ˆy) is a short, eﬃciently veriﬁable proof of the unsatisﬁability of φ, implying that\nNP = co-NP. Given an alleged certiﬁcate ( ˆx, ˆy) that φ is unsatisﬁable, the veriﬁer performs two checks:\n(1) compute the game A1(φ) using algorithm A1 and verify that ( ˆx, ˆy) is a Nash equilibrium of A1(φ); (2)\nuse the algorithm A2 to verify that A2( ˆx, ˆy) is the string “no.” This veriﬁer runs in time polynomial in the\ndescription lengths of φ and ( ˆx, ˆy). If ( ˆx, ˆy) passes both of these tests, then correctness of the algorithms A1\nand A2 implies that φ is unsatisﬁable.\n□\n4.2\nTFNP and Its Subclasses\n4.2.1\nTFNP\nWhat’s really going on in the proof of Theorem 4.1 is a mismatch between the search version of an NP-\ncomplete problem like SAT, where an instance may or may not have a witness, and a problem like computing\na Nash equilibrium, where every instance has at least one witness. While the correct answer to a SAT\ninstance might well be “no,” a correct answer to an instance of Nash equilibrium computation is always a\nNash equilibrium. It seems that if the problem of computing a Nash equilibrium is going to be complete for\nsome complexity class, it must be a class smaller than NP.\n3Crucially, A1(φ) has at least one Nash equilibrium (Theorem 1.14), including one whose description length is polynomial in\nthat of the game (see the discussion following Theorem 1.14)).\n44\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 105
  },
  {
    "chunk_full": "The subset of NP (search) problems for which every instance has at least one witness is called TFNP,\nfor “total functional NP.” The proof of Theorem 4.1 shows more generally that if any TFNP problem is\nNP-complete, then NP = co-NP. Thus a fundamental barrier to NP-completeness is the guaranteed existence\nof a witness.\nSince computing a Nash equilibrium does not seem to be NP-complete, the sensible reﬁned goal is to\nprove that the problem is TFNP-complete—as hard as any other NP problem with a guaranteed witness.\n4.2.2\nSyntactic vs. Semantic Complexity Classes\nUnfortunately, TFNP-completeness is also too ambitious a goal. The reason is that TFNP does not seem to\nhave complete problems. Think about the complexity classes that are known to have complete problems—NP\nof course, and also classes like P and PSPACE. What do these complexity classes have in common? They are\n“syntactic,” meaning that membership can be characterized via acceptance by some concrete computational\nmodel, such as polynomial-time or polynomial-space deterministic or nondeterministic Turing machines. In\nthis sense, there is a generic reason for membership in these complexity classes.\nSyntactically deﬁned complexity classes always have a “generic” complete problem, where the input is\na description of a problem in terms of the accepting machine and an instance of the problem, and the goal is\nto solve the given instance of the given problem. For example, the generic NP-complete problem takes as\ninput a description of a veriﬁer, a polynomial time bound, and an encoding of an instance, and the goal is to\ndecide whether or not there is a witness, meaning a string that causes the given veriﬁer to accept the given\ninstance in at most the given number of steps.\nTFNP has no obvious generic reason for membership, and as such is called a “semantic” class.4 For\nexample, the problem of computing a Nash equilibrium of a bimatrix game belongs to TFNP because of\nthe topological arguments that guarantee the existence of a Nash equilibrium (see Section 2.3). Another\nproblem in TFNP is factoring: given a positive integer, output its factorization. Here, membership in TFNP\nhas a number-theoretic explanation.5 Can the guaranteed existence of a Nash equilibrium of a game and of\na factorization of an integer be regarded as separate instantiations of some “generic” TFNP argument? No\none knows the answer.\n4.2.3\nSyntactic Subclasses of TFNP\nGiven that the problem of computing a Nash equilibrium appears too speciﬁc to be complete for TFNP,\nwe must reﬁne our goal again, and try to prove that the problem is complete for a still smaller complexity\nclass. Papadimitriou [117] initiated the search for syntactic subclasses of TFNP that contain interesting\nproblems not known to belong to P. His proposal was to categorize TFNP problems according to the type of\nmathematical proof used to prove the guaranteed existence of a witness. Interesting subclasses include the\nfollowing:\n• PPAD (for polynomial parity argument, directed version): Problems that can be solved by path-\nfollowing in a (exponential-size) directed graph with in- and out-degree at most 1 and a known source\nvertex (speciﬁcally, the problem of identifying a sink or source vertex other than the given one).\n• PPA (for polynomial parity argument, undirected version): Problems that can be solved by path-\nfollowing in an undirected graph (speciﬁcally, given an odd-degree vertex, the problem of identifying\n4There are many other interesting examples of classes that appear to be semantic in this sense, such as RP and NP ∩co-NP.\n5There are many more natural examples of TFNP problems, including computing a local minimum of a function, computing an\napproximate Brouwer ﬁxed point, and inverting a one-way permutation.\n45\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 106
  },
  {
    "chunk_full": "a diﬀerent odd-degree vertex).\n• PLS (for polynomial local search): Problems that can be solved by path-following in a directed acyclic\ngraph (speciﬁcally, given such a graph, the problem of identifying a sink vertex).6\n• PPP (for polynomial pigeonhole principle): Problems that reduce to the following: given a function f\nmapping {1, 2, . . ., n} to {1, 2, . . ., n −1}, ﬁnd i , j such that f (i) = f (j).\nAll of these complexity classes can be viewed as intermediate to P and NP. The conjecture, supported by\noracle separations [10], is that all four of these classes are distinct (Figure 4.2).\nTFNP\nPLS\nPPAD\nFigure 4.2: Conjectured relationships between subclasses of TFNP.\nSection 2.3 outlined the argument that the guaranteed existence of Nash equilibria reduces to the\nguaranteed existence of Brouwer ﬁxed points, and Section 2.4 showed (via Sperner’s Lemma) that Brouwer’s\nﬁxed-point theorem reduces to path-following in a directed graph with in- and out-degrees at most 1. Thus,\nPPAD would seem to be the subclass of TFNP with the best chance of capturing the complexity of computing\na Nash equilibrium.\n4.3\nPPAD and Its Complete Problems\n4.3.1\nEoL: The Generic Problem for PPAD\nWe can formally deﬁne the class PPAD by deﬁning its generic problem. (A problem is then in PPAD if it\nreduces to the generic problem.) Just as the End-of-the-Line (EoL) problem served as the starting point of\nour communication complexity lower bound (see Section 2.4), a succinct version of the problem will be the\nbasis for our computational hardness results.\nThe EoL Problem (Succinct Version)\nGiven two circuits S and P (for “successor” and “predecessor”), each mapping {0, 1}n to {0, 1}n ∪\n{NULL} and with size polynomial in n, and with P(0n) = NULL, ﬁnd an input v ∈{0, 1}n that\nsatisﬁes one of the following:\n(i) S(v) is NULL;\n(ii) P(v) is NULL and v , 0n;\n(iii) v , P(S(v)); or\n6PLS was actually deﬁned prior to TFNP, by Johnson et al. [81].\n46\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 107
  },
  {
    "chunk_full": "(iv) v , S(P(v)) and v , 0n.\nAnalogous to Section 2.4, we can view the circuits S and P as deﬁning a graph G with in- and out-degree\nat most 1 (with edge (u, v) in G if and only if S(u) = v and P(v) = u), and with a given source vertex 0n.\nThe EoL problem then corresponds to identifying either a sink vertex of G or a source vertex other than 0n.7\nA solution is guaranteed to exist—if nothing else, the other end of the path of G that originates with the\nvertex 0n. Thus EoL does indeed belong to TFNP, and PPAD ⊆TFNP. Note also that the class is syntactic\nand by deﬁnition has a complete problem, namely the EoL problem.\n4.3.2\nProblems in PPAD\nThe class PPAD contains several natural problems (in addition to the EoL problem). For example, it contains\na computational version of Sperner’s Lemma—given a succinct description (e.g., polynomial-size circuits)\nof a legal coloring of an exponentially large triangulation of a simplex, ﬁnd a sub-simplex such that its\nvertices showcase all possible colors. This problem can be regarded as a special case of the EoL problem\n(see Section 2.4), and hence belongs to PPAD.\nAnother example is the problem of computing an approximate ﬁxed point. Here the input is a succinct\ndescription of a λ-Lipschitz function f (on the hypercube in d dimensions, say) and a parameter ϵ, and the\ngoal is to compute a point x with ∥f (x) −x∥< ϵ (with respect to some norm). The description length of x\nshould be polynomial in that of the function f . Such a point is guaranteed to exist provided ϵ is not too\nsmall.8 The reduction from Brouwer’s ﬁxed-point theorem to Sperner’s Lemma (with colors corresponding\nto directions of movement, see Section 2.3) shows that this problem can also be regarded as a special case of\nthe EoL problem, and hence belongs to PPAD.\nThe problem of computing an exact or approximate Nash equilibrium of a bimatrix game also belongs\nto PPAD. For the problem of computing an ϵ-approximate Nash equilibrium (with ϵ no smaller than inverse\nexponential in n), this follows from the proof of Nash’s theorem outlined in Section 2.3.2. That proof shows\nthat computing an ϵ-NE is a special case of computing an approximate ﬁxed point (of the regularized best-\nresponse function deﬁned in (2.1) and (2.2)), and hence the problem belongs to PPAD. The same argument\nshows that this is true more generally for any number of players (and not just for bimatrix games).\nThe problem of computing an exact Nash equilibrium (ϵ = 0) also belongs to PPAD in the case of\ntwo-player (bimatrix) games.9 One way to prove this is via the Lemke-Howson algorithm [96] (see also\nSection 1.4), which reduces the computation of an (exact) Nash equilibrium of a bimatrix game to a path-\nfollowing problem, much in the way that the simplex algorithm reduces computing an optimal solution of\na linear program to following a path of improving edges along the boundary of the feasible region. All\nknown proofs of the Lemke-Howson algorithm’s inevitable convergence use parity arguments akin to the\none in the proof of Sperner’s lemma. These convergence proofs show that the problem of computing a Nash\nequilibrium of a bimatrix game belongs to PPAD.\n7The undirected version of the problem can be used to deﬁne the class PPA. The version of the problem where only sink vertices\ncount as witnesses seems to give rise to a diﬀerent (larger) complexity class called PPADS.\n8For example, for the ℓ∞norm, ϵ can be as small as (λ+1)\n2n\n, where n is the description length of f . This follows from rounding\neach coordinate of an exact ﬁxed point to its nearest multiple of 2−n.\n9Etessami and Yannakakis [49] proved that, with 3 or more players, the problem of computing an exact Nash equilibrium of a\ngame appears to be strictly harder than any problem in PPAD.\n47\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 108
  },
  {
    "chunk_full": "4.3.3\nPPAD-Complete Fixed-Point Problems\nThe EoL problem is PPAD-complete by construction. What about “more natural” problems? Papadimitriou\n[117] built evidence that PPAD is a fundamental complexity class by showing that ﬁxed-point problems are\ncomplete for it.\nTo be precise, let Brouwer(∥·∥, d, F, ϵ) denote the following problem: given a (succinct description of\na) function f ∈F, with f : [0, 1]d →[0, 1]d, compute a point x ∈[0, 1]d such that ∥f (x) −x∥< ϵ. The\noriginal hardness result from [117] is the following.\nTheorem 4.2 (Papadimitriou [117]). The Brouwer(∥·∥, d, F, ϵ) problem is PPAD-complete, even when\nd = 3, the functions in F are O(1)-Lipschitz, ∥·∥is the ℓ∞norm, and ϵ is exponentially small in the\ndescription length n of a function f ∈F.\nThe high-level idea of the proof is similar to the construction in Section 3.1 that shows how to interpret\nEoL instances as implicitly deﬁned Lipschitz functions on the hypercube. Given descriptions of the circuits\nS and P in an instance of the generic EoL problem, it is possible to deﬁne an (eﬃciently computable) function\nthat “follows the line” of an embedding of the induced directed graph into the hypercube. Three dimensions\nare needed in the construction in [117] to ensure that the images of diﬀerent edges do not intersect (except at\na shared endpoint). Some time later, Chen and Deng [31] used a somewhat diﬀerent approach to prove that\nTheorem 4.2 holds even when d = 2.10\nMuch more recently, with an eye toward hardness results for ϵ-approximate Nash equilibria with constant ϵ\n(see Solar Lecture 5), Rubinstein [135] proved the following.11\nTheorem 4.3 (Rubinstein [135]). The Brouwer(∥·∥, d, F, ϵ) problem is PPAD-complete even when the\nfunctions in F are O(1)-Lipschitz functions, d is linear in the description length n of a function in F, ∥·∥is\nthe normalized ℓ2 norm (with ∥x∥=\nq\n1\nd\nPd\ni=1 x2\ni ), and ϵ is a suﬃciently small constant.\nThe proof of Theorem 4.3 is closely related to the third step of our communication complexity lower\nbound (Section 3.1), and in particular makes use of a similar embedding of graphs into the hypercube with\nthe properties (P1) and (P2) described in Sections 3.1.3 and 3.1.4.12 One major diﬀerence is that our proof\nof existence of the embedding in Section 3.1 used the probabilistic method and hence is not constructive\n(which is not an issue in the two-party communication model), while the computational lower bound in\nTheorem 4.3 requires a constructive version. In particular, the reduction from EoL to Brouwer(∥·∥, d, F, ϵ)\nmust eﬃciently produce a succinct description of the function f induced by an instance of EoL, and it should\nbe possible to eﬃciently evaluate f , presumably while using the given EoL circuits S and P only as black\nboxes. For example, it should be possible to eﬃciently decode points of the hypercube (to a vertex, edge, or\n⊥, see Section 3.1.3).\nConceptually, the ﬁxes for these problems are relatively simple. First, rather than mapping the vertices\nrandomly into the hypercube, the reduction in the proof of Theorem 4.3 embeds the vertices using an\nerror-correcting code (with constant rate and eﬃcient encoding and decoding algorithms). This enforces\nproperty (P1) of Section 3.1.3.\nSecond, rather than using a straight-line embedding, the reduction is\nmore proactive about making the images of diﬀerent edges stay far apart (except for at shared endpoints).\n10The one-dimensional case can be solved in polynomial time, essentially by binary search.\n11Theorem 4.2 proves hardness in the regime where d and ϵ are both small, Theorem 4.3 when both are large. This is not an\naccident; if d is small (i.e., constant) and ϵ is large (i.e., constant), the problem can be solved in polynomial time by exhaustively\nchecking a constant number of evenly spaced grid points.\n12We have reversed the chronology; Theorem 2.1 was proved after Theorem 4.3 and used the construction in [135] more or less\nas a black box.\n48\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 109
  },
  {
    "chunk_full": "Speciﬁcally, an edge of the directed graph induced by the given EoL instance is now mapped to 5 straight\nline segments, and along each line segment, two-thirds of the coordinates stay ﬁxed. (This requires blowing\nup the number of dimensions by a constant factor.) For example, the directed edge (u, v) can be mapped to\nthe path\n(σ(u), σ(u), 1\n4) 7→(σ(u), σ(v), 1\n4) 7→(σ(u), σ(v), 3\n4) 7→(σ(v), σ(v), 3\n4) 7→(σ(v), σ(v), 1\n4),\nwhere σ denotes the error-correcting code used to map the vertices to the hypercube and the boldface 1\n4 and 3\n4\nindicate the value of the last third of the coordinates. This maneuver enforces property (P2) of Section 3.1.3.\nIt also ensures that it is easy to decode points of the hypercube that are close to the image of an edge of the\ngraph—at least one of the edge’s endpoints can be recovered from the values of the frozen coordinates, and\nthe other endpoint can be recovered using the given predecessor and successor circuits.13\n4.3.4\nPPAD-Complete Equilibrium Computation Problems\nPapadimitriou [117] deﬁned the class PPAD in large part to capture the complexity of computing a Nash\nequilibrium, conjecturing that the problem is in fact PPAD-complete. Over a decade later, a ﬂurry of papers\nconﬁrmed this conjecture. First, Daskalakis, Goldberg, and Papadimitriou [43, 63] proved that computing\nan ϵ-NE of a four-player game, with ϵ inverse exponential in the size of the game, is PPAD-complete. This\napproach was quickly reﬁned [29, 42], culminating in the proof of Chen and Deng [30] that computing a\nNash equilibrium (or even an ϵ-NE with exponentially small ϵ) of a bimatrix game is PPAD-complete. Thus\nthe nice properties possessed by Nash equilibria of bimatrix games (see Section 1.4) are not enough to elude\ncomputational intractability. Chen et al. [32] strengthened this result to hold even for values of ϵ that are\nonly inverse polynomial in the size of the game.14 The papers by Daskalakis et al. [44] and Chen et al. [34]\ngive a full account of this breakthrough sequence of results.\nTheorem 4.4 (Daskalakis et al. [44], Chen et al. [34]). The problem of computing an ϵ-NE of an n × n\nbimatrix game is PPAD-complete, even when ϵ = 1/poly(n).\nThe proof of Theorem 4.4, which is a tour de force, is also outlined in the surveys by Johnson [80],\nPapadimitriou [118], Daskalakis et al. [45], and Roughgarden [125]. Fundamentally, the proof shows how\nto use a bimatrix game to perform a gate-by-gate simulation of the circuits of an EoL instance.\nTheorem 4.4 left open the possibility that, for every constant ϵ > 0, an ϵ-NE of a bimatrix game can\nbe computed in polynomial time. (Recall from Corollary 1.17 that it can be computed in quasi-polynomial\ntime.) A decade later, Rubinstein [135] ruled out this possibility (under suitable complexity assumptions)\nby proving a quasi-polynomial-time hardness result for the problem when ϵ is a suﬃciently small constant.\nWe will have much more to say about this result in Solar Lecture 5.\n4.4\nEvidence of Hardness\n4.4.1\nBasing the Hardness of TFNP on Cryptographic Assumptions\nIt’s all ﬁne and good to prove that a problem is as hard as any other problem in PPAD, but what makes\nus so sure that PPAD problems (or even TFNP problems) are hard? The initial evidence was exponential\n13This embedding is deﬁned only for the directed edges that are present in the given EoL instance, rather than for all possible\nedges (in contrast to the embedding in Sections 3.1.3 and 3.1.4).\n14In particular, under standard complexity assumptions, this rules out an algorithm with smoothed polynomial complexity in\nthe sense of Spielman and Teng [141]. Thus the parallels between the simplex method and the Lemke-Howson algorithm (see\nSection 1.4) only go so far.\n49\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 110
  },
  {
    "chunk_full": "lower bounds for functions given as “block boxes,” or equivalently query complexity lower bounds, as in\nProposition 2.6 for the EoL problem or Hirsch et al. [74] for the Brouwer problem.\nCan we relate the hardness of TFNP and its subclasses to other standard complexity assumptions?\nTheorem 4.1 implies that we can’t base hardness of TFNP on the assumption that P , NP, unless NP = co-NP.\nWhat about cryptographic assumptions? After all, the problem of inverting a one-way permutation belongs\nto TFNP (and even the subclass PPP). Thus, suﬃciently strong cryptographic assumptions imply hardness\nof TFNP.\nCan we prove hardness also for all of the interesting subclasses of TFNP, or can we establish the hardness\nof TFNP under weaker assumptions (like the existence of one-way functions)? Along the former lines,\na recent sequence of papers (not discussed here) show that strong assumptions about indistinguishability\nobfuscation (i.o.) imply that PPAD is hard [13, 59, 123, 75]. The rest of this lecture covers a recent result in\nthe second direction by Hubáček et al. [76], who show that the average-case hardness of TFNP can be based\non the average-case hardness of NP. (Even though the worst-case hardness of TFNP cannot be based on that\nof NP, unless NP = co-NP!) Note that assuming that NP is hard on average is only weaker than assuming\nthe existence of one-way functions.\nTheorem 4.5 ([76]). If there exists a hard-on-average language in NP, then there exists a hard-on-average\nsearch problem in TFNP.\nThere is some ﬁne print in the precise statement of the result (see Remarks 4.7 and 4.8), but the statement\nin Theorem 4.5 is the gist of it.\n4.4.2\nProof Sketch of Theorem 4.5\nLet L be a language in NP which is hard on average w.r.t. some family of distributions Dn on input strings\nof length n.\nAverage-case hardness of (L, Dn) means that there is no polynomial-time algorithm with\nan advantage of 1/poly(n) over random guessing when the input is sampled according to Dn (for any\npolynomial). Each Dn should be eﬃciently sampleable, so that hardness cannot be baked into the input\ndistribution.\nOne natural candidate for a hard-on-average problem in NP is that of inverting a one-way function on a\nrandom range element. Since a one-way function is generally not surjective, this problem is not total and\nhence does not belong to TFNP. Can we convert it into a problem that is total and yet retains its average-case\nhardness?\nHere’s an initial attempt:\nAttempt #1\nInput: l independent samples x1, x2, . . ., xl from Dn.\nOutput: a witness for some xi ∈L.\nAs l →∞, this problem is “almost total.” Because (L, Dn) is hard-on-average, random instances are nearly\nequally likely to be “yes” or “no” instances (otherwise a constant response would beat random guessing).\nThus, except with probability ≈2−l, at least one of the sampled instances xi is a “yes” instance and has a\nwitness. Taking l polynomial in n, we get a problem that is total except with exponentially small probability.\nHow can we make it “totally total?”\nThe idea is to sample the xi’s in a correlated way, using a random shifting trick reminiscent of Lautemann’s\nproof that BPP ⊆Σ2 ∩Π2 [94]. This will give a non-uniform version of Theorem 4.5; Remark 4.8 sketches\nthe changes necessary to get a uniform version.\n50\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 111
  },
  {
    "chunk_full": "Fix n. Let Dn(r) denote the output of the sampling algorithm for Dn, given the random seed r ∈{0, 1}n.\n(By padding, we can assume that the input length and the random seed length both equal n.) Call a set\ncontaining the strings s1, s2, . . ., sl ∈{0, 1}n good if for every seed r ∈{0, 1}n there exists an index i ∈[l]\nsuch that D(r ⊕si) ∈L. We can think of the si’s as masks; goodness then means that there is always a mask\nwhose application yields a “yes” instance.\nClaim 4.6. If s1, s2, . . ., s2n ∼{0, 1}n are sampled uniformly and independently, then {s1, . . ., s2n} is good\nwith high probability.\nProof. Fix a seed r ∈{0, 1}n. The distribution of r ⊕si (over si) is uniform, so Dn(r ⊕si) has a roughly 50%\nchance of being a “yes” instance (since (L, Dn) is hard on average). Thus the probability (over s1, . . ., s2n)\nthat Dn(r ⊕si) is a “no” instance for every si is ≈2−2n. Taking a union bound over the 2n choices for r\ncompletes the proof.\n□\nConsider now the following reduction, from the assumed hard-on-average NP problem (L, Dn) to a\nhopefully hard-on-average TFNP problem.\nAttempt 2 (non-uniform)\nChosen in advance: A good set of strings {s1, s2, . . ., s2n}.\nInput: an instance x of (L, Dn), in the form of the random seed ˆr used to generate x = Dn(ˆr).\nOutput: a witness for one of the instances D(ˆr ⊕s1), . . ., D(ˆr ⊕s2n).\nBy the deﬁnition of a good set of strings, there is always at least one witness of the desired form, and so the\noutput of this reduction is a TFNP problem (or more accurately, a TFNP/poly problem, with s1, . . ., s2n given\nas advice). Let D′ denote the distribution over instances of this problem induced by the uniform distribution\nover ˆr. It remains to show how a (non-uniform) algorithm that solves this TFNP/poly problem (with respect\nto D′) can be used to beat random guessing (with inverse polynomial advantage) for (L, Dn) in a comparable\namount of time. Given an algorithm A for the former problem (and the corresponding good set of strings),\nconsider the following algorithm B for (L, Dn).\nAlgorithm Bs1,s2,...,s2n\nInput: A random instance x of (L, Dn) and the random seed ˆr that generated it (so x = Dn(ˆr)).\n1. Choose i ∈[2n] uniformly at random.\n2. Set r⋆= ˆr ⊕si.\n3. Use the algorithm A to generate a witness w for one of the instances\nD(r⋆⊕s1), D(r⋆⊕s2), . . ., D(r⋆⊕s2n).\n(Note that the ith problem is precisely the one we want to solve.)\n4. If w is a witness for D(r⋆⊕si), then output “yes.”\n5. Otherwise, randomly answer “yes” or “no” (with 50/50 probability).\n51\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 112
  },
  {
    "chunk_full": "Consider a “yes” instance Dn(ˆr) of L. If algorithm A happens to output a witness to the ith instance\nDn(r⋆⊕si) = Dn(ˆr), then algorithm B correctly decides the problem. The worry is that the algorithm A\nsomehow conspires to always output a witness for an instance other than the “real” one.\nSuppose algorithm A, when presented with the instances D(r⋆⊕s1), D(r⋆⊕s2), . . ., D(r⋆⊕s2n),\nexhibits a witness for the jth instance D(r⋆⊕sj). This collection of instances could have been produced by\nthe reduction in exactly 2n diﬀerent ways: with i = 1 and ˆr = r⋆⊕s1, with i = 2 and ˆr = r⋆⊕s2, and so\non. Since i and ˆr were chosen independently and uniformly at random, each of these 2n outcomes is equally\nlikely, and algorithm A has no way of distinguishing between them. Thus whatever j is, A’s witness has at\nleast a 1/2n chance of being a witness for the true problem Dn(ˆr) (where the probability is over both ˆr and i).\nWe conclude that, for “yes” instances of L, algorithm B has advantage\n1\n2n over random guessing. Since\nroughly 50% of the instances Dn(ˆr) are “yes” instances (since (L, Dn) is average-case hard), algorithm B\nhas advantage roughly\n1\n4n over random guessing for (L, Dn). This contradicts our assumption that (L, Dn)\nis hard on average.\nWe have completed the proof of Theorem 4.5, modulo two caveats.\nRemark 4.7 (Public vs. Private Coins). The algorithm B used in the reduction above beats random guessing\nfor (L, Dn), provided the algorithm receives as input the random seed ˆr used to generate an instance of (L, Dn).\nThat is, our current proof of Theorem 4.5 assumes that (L, Dn) is hard on average even with public coins.\nWhile there are problems in NP conjectured to be average-case hard in this sense (like randomized SAT near\nthe phase transition), it would be preferable to have a version of Theorem 4.5 that allows for private coins.\nHappily, Hubáček et al. [76] prove that there exists a private-coin average-case hard problem in NP only if\nthere is also a public-coin such problem. This implies that Theorem 4.5 holds also in the private-coin case.\nRemark 4.8 (Uniform vs. Non-Uniform). Our proof of Theorem 4.5 only proves hardness for the non-uniform\nclass TFNP/poly. (The good set {s1, . . ., s2n} of strings is given as “advice” separately for each n.) It is\npossible to extend the argument to (uniform) TFNP, under some additional (reasonably standard) complexity\nassumptions. The idea is to use techniques from derandomization. We already know from Claim 4.6 that\nalmost all sets of 2n strings from {0, 1}n are good. Also, the problem of checking whether or not a set\nof strings is good is a Π2 problem (for all r ∈{0, 1}n there exists i ∈[2n] such that Dn(r ⊕si) has a\nwitness). Assuming that there is a problem in E with exponential-size Π2 circuit complexity, it is possible\nto derandomize the probabilistic argument and eﬃciently compute a good set {s1, . . ., sl} of strings (with l\nlarger than 2n but still polynomial in n), à la Impagliazzo and Wigderson [77].\nAn important open research direction is to extend Theorem 4.5 to subclasses of TFNP, such as PPAD.\nOpen Problem: Does an analogous average-case hardness result hold for PPAD?\n52\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 113
  },
  {
    "chunk_full": "Solar Lecture 5\nThe Computational Complexity of Computing an Approximate Nash Equilibrium\nLecturer: Tim Roughgarden\nScribe: Salil Vadhan\n5.1\nIntroduction\nLast lecture we stated without proof the result by Daskalakis et al. [44] and Chen et al. [34] that computing an\nϵ-approximate Nash equilibrium of a bimatrix game is PPAD-complete, even when ϵ is an inverse polynomial\nfunction of the game size (Theorem 4.4). Thus, it would be surprising if there were a polynomial-time (or\neven subexponential-time) algorithm for this problem. Recall from Corollary 1.17 in Solar Lecture 1 that\nthe story is diﬀerent for constant values of ϵ, where an ϵ-approximate Nash equilibrium can be computed in\nquasi-polynomial (i.e., nO(log n)) time.\nThe Pavlovian response of a theoretical computer scientist to a quasi-polynomial-time algorithm is to\nconjecture that a polynomial-time algorithm must also exist. (There are only a few known natural problems\nthat appear to have inherently quasi-polynomial time complexity.) But recall that the algorithm in the proof\nof Corollary 1.17 is just exhaustive search over all probability distributions that are uniform over a multi-set\nof logarithmically many strategies (which is good enough, by Theorem 1.15). Thus the algorithm reveals\nno structure of the problem other than the fact that the natural search space for it has quasi-polynomial size.\nIt is easy to imagine that there are no “shortcuts” to searching this space, in which case a quasi-polynomial\namount of time would indeed be necessary. How would we ever prove such a result? Presumably by a\nnon-standard super-polynomial reduction from some PPAD-complete problem like succinct EoL (deﬁned in\nSection 4.3.1). This might seem hard to come by, but in a recent breakthrough, Rubinstein [135] provided\njust such a reduction!\nTheorem 5.1 ([135]). For all suﬃciently small constants ϵ > 0, for every constant δ > 0, there is no\nnlog1−δ n-time algorithm for computing an ϵ-approximate Nash equilibrium of a bimatrix game, unless the\nsuccinct EoL problem has a 2n1−δ′\n-time algorithm for some constant δ′ > 0.\nIn other words, assuming an analog of the Exponential Time Hypothesis (ETH) [78] for PPAD, the\nquasi-polynomial-time algorithm in Corollary 1.17 is essentially optimal!1,2\nThree previous papers that used an ETH assumption (for NP) along with PCP machinery to prove\nquasi-polynomial-time lower bounds for NP problems are:\n1To obtain a quantitative lower bound like the conclusion of Theorem 5.1, it is necessary to make a quantitative complexity\nassumption (like an analog of ETH). This approach belongs to the tradition of “ﬁne-grained” complexity theory.\n2How plausible is the assumption that the ETH holds for PPAD, even after assuming that the ETH holds for NP and that PPAD\nhas no polynomial-time algorithms? The answer is far from clear, although there are exponential query lower bounds for PPAD\nproblems (e.g. [74]) and no known techniques that show promise for a subexponential-time algorithm for the succinct EoL problem.\n53\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 114
  },
  {
    "chunk_full": "1. Aaronson et al. [1], for the problem of computing the value of free games (i.e., two-prover proof\nsystems with stochastically independent questions), up to additive error ϵ;\n2. Braverman et al. [18], for the problem of computing the ϵ-approximate Nash equilibrium with the\nhighest expected sum of player payoﬀs; and\n3. Braverman et al. [19] for the problem of distinguishing graphs with a k-clique from those that only\nhave k-vertex subgraphs with density at most 1 −ϵ.\nIn all three cases, the hardness results apply when ϵ > 0 is a suﬃciently small constant. Quasi-polynomial-\ntime algorithms are known for all three problems.\nThe main goal of this lecture is to convey some of the ideas in the proof of Theorem 5.1. The proof is a\ntour de force and the paper [135] is 57 pages long, so our treatment will necessarily be impressionistic. We\nhope to explain the following:\n1. What the reduction in Theorem 5.1 must look like. (Answer: a blow-up from size n to size ≈2\n√n.)\n2. How a n 7→≈2\n√n-type blowup can naturally arise in a reduction to the problem of computing an\napproximate Nash equilibrium.\n3. Some of the tricks used in the reduction.\n4. Why these tricks naturally lead to the development and application of PCP machinery.\n5.2\nProof of Theorem 5.1: An Impressionistic Treatment\n5.2.1\nThe Necessary Blow-Up\nThe goal is to reduce length-n instances of the succinct EoL problem to length- f (n) instances of the\nproblem of computing an ϵ-approximate Nash equilibrium with constant ϵ, so that a sub-quasi-polynomial-\ntime algorithm for the latter implies a subexponential-time algorithm for the former. Thus the mapping\nn 7→f (n) should satisfy 2n ≈f (n)log f (n) and hence f (n) ≈2\n√n. That is, we should be looking to encode\na length-n instance of succinct EoL as a 2\n√n × 2\n√n bimatrix game. The √n will essentially come from the\n“birthday paradox,” with random subsets of [n] of size s likely to intersect once s exceeds √n. The blow-up\nfrom n to 2\n√n will come from PCP-like machinery, as well as a game-theoretic gadget (“Althöfer games,”\nsee Section 5.2.6) that forces players to randomize nearly uniformly over size-√n subsets of [n] in every\napproximate Nash equilibrium.\n5.2.2\nThe Starting Point: ϵ-BFP\nThe starting point of the reduction is the PPAD-complete version of the ϵ-BFP problem in Theorem 4.3. We\nrestate that result here.\nTheorem 5.2 (Rubinstein [135]). The Brouwer(∥·∥, d, F, ϵ) problem is PPAD-complete when the functions\nin F are O(1)-Lipschitz functions from the d-dimensional hypercube H = [0, 1]d to itself, d is linear in the\ndescription length n of a function in F, ∥·∥is the normalized ℓ2 norm (with ∥x∥=\nq\n1\nd\nPd\ni=1 x2\ni ), and ϵ is a\nsuﬃciently small constant.\n54\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 115
  },
  {
    "chunk_full": "The proof is closely related to the reduction from 2EoL to ϵ-2BFP outlined in Section 3.1, and Sec-\ntion 4.3.3 describes the additional ideas needed to prove Theorem 5.2. As long as the error-correcting\ncode used to embed vertices into the hypercube (see Section 4.3.3) has linear-time encoding and decoding\nalgorithms (as in [140], for example), the reduction can be implemented in linear time. In particular, our\nassumption that the succinct EoL problem has no subexponential-time algorithms automatically carries over\nto this version of the ϵ-BFP problem. In addition to the properties of the functions in F that are listed in\nthe statement of Theorem 5.2, the proof of Theorem 5.1 crucially uses the “locally decodable” properties of\nthese functions (see Section 5.2.8).\n5.2.3\nϵ-BFP ≤ϵ-NE (Attempt #1): Discretize McLennan-Tourky\nOne natural starting point for a reduction from ϵ-BFP to ϵ-NE is the McLennan-Tourky analytic reduction\nin Section 3.2.1. Given a description of an O(1)-Lipschitz function f : [0, 1]d →[0, 1]d, with d linear in\nthe length n of the function’s description, the simplest reduction would proceed as follows. Alice and Bob\neach have a strategy set corresponding to the discretized hypercube Hϵ (points of [0, 1]d such that every\ncoordinate is a multiple of ϵ). Alice’s and Bob’s payoﬀs are deﬁned as in the proof of Theorem 3.2: for\nstrategies x, y ∈Hϵ, Alice’s payoﬀis\n1 −∥x −y∥2 = 1 −1\nd\nd\nX\ni=1\n(xi −yi)2\n(5.1)\nand Bob’s payoﬀis\n1 −∥y −f (x)∥2 = 1 −1\nd\nd\nX\nj=1\n(yj −f (x)j)2.\n(5.2)\n(Here ∥·∥denotes the normalized ℓ2 norm.) Thus Alice wants to imitate Bob’s strategy, while Bob wants to\nimitate the image of Alice’s strategy under the function f .\nThis reduction is correct in that in every ϵ-approximate Nash equilibrium of this game, Alice’s and\nBob’s strategies are concentrated around an O(ϵ)-approximate ﬁxed point of the given function f (in the\nnormalized ℓ2 norm). See also the discussion in Section 3.2.1.\nThe issue is that the reduction is not eﬃcient enough. Alice and Bob each have Θ((1/ϵ)d) pure strategies;\nsince d = Θ(n), this is exponential in the size n of the given ϵ-BFP instance, rather than exponential in √n.\nThis exponential blow-up in size means that this reduction has no implications for the problem of computing\nan approximate Nash equilibria.\n5.2.4\nSeparable Functions\nHow can we achieve a blow-up exponential in √n rather than in n? We might guess that the birthday paradox\nis somehow involved. To build up our intuition, we’ll discuss at length a trivial special case of the ϵ-BFP\nproblem. It turns out that the hard functions used in Theorem 5.2 are in some sense surprisingly close to this\ntrivial case.\nFor now, we consider only instances f of ϵ-BFP where f is separable. That is, f has the form\nf (x1, . . ., xd) = ( f1(x1), . . ., fd(xd))\n(5.3)\nfor eﬃciently computable functions f1, . . ., fd : [0, 1] →[0, 1]. Separable functions enjoy the ultimate form\nof “local decodability”—to compute the ith coordinate of f (x), you only need to know the ith coordinate\n55\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 116
  },
  {
    "chunk_full": "of x. Finding a ﬁxed point of a separable function is easy: the problem decomposes into d one-dimensional\nﬁxed point problems (one per coordinate), and each of these can be solved eﬃciently by a form of binary\nsearch. The hard functions used in Theorem 5.2 possess a less extreme form of “local decodability,” in that\neach coordinate of f (x) can be computed using only a small amount of “advice” about f and x (cf., the\nϵ-2BFP ≤ϵ-NE reduction in Section 3.2.3).\n5.2.5\nϵ-BFP ≤ϵ-NE (Attempt #2): Coordinatewise Play\nLet’s try to at least compute ﬁxed points of separable functions with approximate Nash equilibria using a\nreduction with only subexponential blow-up. The key idea is, instead of Alice and Bob each picking one of\nthe (exponentially many) points of the discretized hypercube Hϵ, each will pick only a single coordinate of\npoints x and y. Thus a pure strategy of Alice comprises an index i ∈[d] and a number xi ∈[0, 1] that is a\nmultiple of ϵ, and similarly Bob chooses j ∈[d] and yj ∈[0, 1]. Given choices (i, xi) and (j, yj), Alice’s\npayoﬀis deﬁned as\n\n1 −(xi −yi)2\nif i = j\n0\nif i , j\nand Bob’s payoﬀis\n\n1 −(yi −fi(xi))2\nif i = j\n0\nif i , j.\nThus Alice and Bob receive payoﬀ0 unless they “interact,” meaning choose the same coordinate to play\nin, in which case their payoﬀs are analogous to (5.1) and (5.2). Note that Bob’s payoﬀis well deﬁned only\nbecause we have assumed that f is separable (Bob only knows the coordinate xi proposed by Alice, but this\nis enough to compute the ith coordinate of the output of f and hence his payoﬀ). Each player has only ≈d\nϵ\nstrategies, so this is a polynomial-time reduction, with no blow-up.\nThe good news is that (approximate) ﬁxed points give rise to (approximate) Nash equilibria of this game.\nSpeciﬁcally, if ˆx = ˆy = f ( ˆx) is a ﬁxed point of f , then the following is a Nash equilibrium (as you should\ncheck): Alice and Bob pick their coordinates i, j uniformly at random and set xi = ˆxi and yj = ˆyj. The\nproblem is that the game also has equilibria other than the intended ones, for example where Alice and Bob\nchoose pure strategies with i = j and xi = yi = fi(xi).\n5.2.6\nϵ-BFP ≤ϵ-NE (Attempt #3): Gluing Althöfer Games\nOur second attempt failed because Alice and Bob were not forced to randomize their play over all d\ncoordinates. We can address this issue with a game-theoretic gadget called an Althöfer game [4].3 For a\npositive and even integer k, this k ×\n\u0010 k\nk/2\n\u0011\ngame is deﬁned as follows.\n• Alice chooses an index i ∈[k].\n• Bob chooses a subset S ⊆[k] of size k/2.\n• Alice’s payoﬀis 1 if i ∈S, and -1 otherwise.\n• Bob’s payoﬀis -1 if i ∈S, and 1 otherwise.\n3Similar ideas have been used previously, including in the proofs that computing an ϵ-approximate Nash equilibrium with ϵ\ninverse polynomial in n is a PPAD-complete problem [44, 34].\n56\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 117
  },
  {
    "chunk_full": "For example, here is the payoﬀmatrix for the k = 4 case (with only Alice’s payoﬀs shown):\n*....\n,\n1\n1\n1\n−1\n−1\n−1\n1\n−1\n−1\n−1\n1\n1\n−1\n1\n−1\n1\n−1\n1\n−1\n−1\n1\n1\n1\n−1\n+////\n-\nEvery Althöfer game is a zero-sum game with value 0: for both players, choosing a uniformly random strategy\nguarantees expected payoﬀ0. The following claim proves a robust converse for Alice’s play. Intuitively, if\nAlice deviates much from the uniform distribution, Bob is well-positioned to punish her.4\nClaim 5.3. In every ϵ-approximate Nash equilibrium of an Althöfer game, Alice’s strategy is ϵ-close to\nuniformly random in statistical distance (a.k.a. total variation distance).\nProof. Suppose that Alice plays strategy i ∈[k] with probability pi. After sorting the coordinates so that\npi1 ≤pi2 ≤· · · ≤pik, Bob’s best response is to play the subset S = {i1, i2, . . ., ik/2}. We must have\neither pik/2 ≤1/k or pik/2+1 ≥1/k (or both). Suppose that pik/2 ≤1/k (the other case can be handled\nsymmetrically). Then Bob’s expected payoﬀfrom playing S is:\nX\nj>k/2\npi j −\nX\nj ≤k/2\npi j\n=\nX\nj>k/2\n(pi j −1/k) +\nX\nj ≤k/2\n(1/k −pi j )\n=\nX\nj:pi j >1/k\n(pi j −1/k) +\nX\nj>k/2:pi j ≤1/k\n(pi j −1/k) +\nX\nj ≤k/2\n(1/k −pi j )\n≥\nX\nj:pi j >1/k\n(pi j −1/k),\nwhere the last inequality holds because the pi j’s are sorted in increasing order and pik/2 ≤1/k. The ﬁnal\nexpression above equals the statistical distance between Alice’s mixed strategy ⃗p and the uniform distribution.\nThe claim now follows from that fact that Bob cannot achieve a payoﬀlarger than ϵ in any ϵ-approximate\nNash equilibrium (otherwise, Alice could increase her expected payoﬀby more than ϵ by switching to the\nuniform distribution).\n□\nIn Claim 5.3, it’s important that the loss in statistical distance (as a function of ϵ) is independent of the\nsize k of the game. For example, straightforward generalizations of rock-paper-scissors do not achieve the\nguarantee in Claim 5.3.\nGluing Games.\nWe incorporate Althöfer games into our coordinatewise play game as follows. Let\n• G1 = the d\nϵ × d\nϵ coordinatewise game of Section 5.2.5,\n• G2 = a d ×\n\u0010 d\nd/2\n\u0011\nAlthöfer game, and\n• G3 = a\n\u0010 d\nd/2\n\u0011\n× d Althöfer game, with the roles of Alice and Bob reversed.\nConsider the following game, where Alice and Bob eﬀectively play all three games simultaneously:\n• A pure strategy of Alice comprises an index i ∈[d], a multiple xi of ϵ in [0, 1], and a set T ⊆[d] of\nsize d/2. The interpretation is that she plays (i, xi) in G1, i in G2, and T in G3.\n4The statement and proof here include a constant-factor improvement, due to Salil Vadhan, over those in [135].\n57\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 118
  },
  {
    "chunk_full": "• A pure strategy of Bob comprises an index j ∈[d], a multiple yj of ϵ in [0, 1], and a set S ⊆[d] of\nsize d/2, interpreted as playing (j, yj) in G1, S in G2 and j in G3.\n• Each player’s payoﬀis a weighted sum of their payoﬀs in the three games,\n1\n100 ·G1 + 99\n200 ·G2 + 99\n200 ·G3.\nThe good news is that, in every exact Nash equilibrium of the combined game, Alice and Bob mix uniformly\nover their choices of i and j. Intuitively, because deviating from the uniform strategy can be punished by\nthe other player at a rate linear in the deviation (Claim 5.3), it is never worth doing (no matter what happens\nin G1). Given this, à la the McLennan-Tourky reduction (Theorem 3.2), the xi’s and yj’s must correspond\nto a ﬁxed point of f (for each i, Alice must set xi to the center of mass of Bob’s distribution over yi’s, and\nthen Bob must set yi = fi(xi)).\nThe bad news is that this argument breaks down for ϵ-approximate Nash equilibria with constant ϵ. The\nreason is that, even when the distributions of i and j are perfectly uniform, the two players interact (i.e.,\nchoose i = j) only with probability 1/d. This means that the contribution of the game G1 to the expected\npayoﬀs is at most 1/d ≪ϵ, freeing the players to choose their xi’s and yj’s arbitrarily. Thus we need another\nidea to force Alice and Bob to interact more frequently.\nA second problem is that the sizes of the Althöfer games are too big—exponential in d rather than in\n√\nd.\n5.2.7\nϵ-BFP ≤ϵ-NE (Attempt #4): Blockwise Play\nTo solve both of the problems with the third attempt, we force Alice and Bob to play larger sets of coordinates\nat a time. Speciﬁcally, we view [d] as a\n√\nd ×\n√\nd grid, and any x, y ∈[0, 1]d as\n√\nd ×\n√\nd matrices. Now Alice\nand Bob will play a row and column of their matrices, respectively, and their payoﬀs will be determined by\nthe entry where the row and column intersect. That is, we replace the coordinatewise game of Section 5.2.5\nwith the following blockwise game:\n• A pure strategy of Alice comprises an index i ∈\nf√\nd\ng\nand a row xi∗∈[0, 1]\n√\nd. (As usual, every xi j\nshould be a multiple of ϵ.)\n• A pure strategy of Bob comprises an index j ∈\nf√\nd\ng\nand a column y∗j ∈[0, 1]\n√\nd.\n• Alice’s payoﬀin the outcome (xi∗, y∗j) is\n1 −(xi j −yi j)2.\n• Bob’s payoﬀin the outcome (xi∗, y∗j) is\n1 −(yi j −fi j(xi j))2.\n(5.4)\nNow glue this game together with k ×\n\u0010 k\nk/2\n\u0011\nand\n\u0010 k\nk/2\n\u0011\n× k Althöfer games with k =\n√\nd, as in Section 5.2.6.\n(For example, Alice’s index i ∈\nf√\nd\ng\nis identiﬁed with a row in the ﬁrst Althöfer game, and now Alice\nalso picks a subset S ⊆\nf√\nd\ng\nin the second Althöfer game, in addition to i and xi∗.) This construction\nyields exactly what we want: a game of size exp( ˜O(k)) = exp( ˜O(\n√\nd)) in which every ϵ-approximate Nash\nequilibrium can be easily translated to a δ-approximate ﬁxed point of f (in the normalized ℓ2 norm), where\nδ depends only on ϵ.5,6\n5The ˜O(·) notation suppresses logarithmic factors.\n6In more detail, in every ϵ-approximate Nash equilibrium of the game, Alice and Bob both randomize nearly uniformly over i\nand j; this is enforced by the Althöfer games as in Section 5.2.6. Now think of each player as choosing its strategy in two stages,\n58\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 119
  },
  {
    "chunk_full": "5.2.8\nBeyond Separable Functions\nWe now know how to use an ϵ-approximate Nash equilibrium of a subexponential-size game (with constant ϵ)\nto compute a δ-approximate ﬁxed point of a function that is separable in the sense of (5.3). This is not\nimmediately interesting, because a ﬁxed point of a separable function is easy to ﬁnd by doing binary search\nindependently in each coordinate. The hard Brouwer functions identiﬁed in Theorem 5.2 have lots of nice\nproperties, but they certainly aren’t separable.\nConceptually, the rest of the proof of Theorem 5.1 involves pushing in two directions: ﬁrst, identifying\nhard Brouwer functions that are even “closer to separable” than the functions in Theorem 5.2; and second,\nextending the reduction in Section 5.2.7 to accommodate “close-to-separable” functions. We already have\nan intuitive feel for what the second step looks like, from Step 4 of our communication complexity lower\nbound (Section 3.2.3 in Lunar Lecture 3), where we enlarged the strategy sets of the players so that they\ncould smuggle “advice” about how to decode a hard Brouwer function f at a given point. We conclude the\nlecture with one key idea for the further simpliﬁcation of the hard Brouwer functions in Theorem 5.2.\n5.2.9\nLocal EoL\nRecall the hard Brouwer functions constructed in our communication complexity lower bound (see Sec-\ntion 3.1), which “follow the line” of an embedding of an EoL instance, as well as the additional tweaks\nneeded to prove Theorem 5.2 (see Section 4.3.3). We are interested in the “local decodability” properties\nof these functions. That is, if Bob needs to compute the jth coordinate of f (x) (to evaluate the jth term in\nhis payoﬀin (5.2)), how much does he need to know about x? For a separable function f = ( f1, . . ., fd),\nhe only needs to know x j. For the hard Brouwer functions in Theorem 5.2, Bob needs to know whether\nor not x is close to an edge (of the embedding of the succinct EoL instance into the hypercube) and, if so,\nwhich edge (or pair of edges, if x is close to a vertex). Ultimately, this requires evaluating the successor\ncircuit S and predecessor circuit P of the succinct EoL instance that deﬁnes the hard Brouwer function. It\nis therefore in our interest to force S and P to be as simple as possible, subject to the succinct EoL problem\nremaining PPAD-complete. In a perfect world, minimal advice (say, O(1) bits) would be enough to compute\nS(v) and P(v) from v.7 The following lemma implements this idea. It shows that a variant of the succinct\nEoL problem, called Local EoL, remains PPAD-complete even when S and P are guaranteed to change\nonly O(1) bits of the input, and when S and P are NC0 circuits (and hence each output bit depends on\nonly O(1) input bits).\nLemma 5.4 (Rubinstein [135]). The following Local EoL problem is PPAD-complete:\n1. the vertex set V is a subset of {0, 1}n, with membership in V speciﬁed by a given AC0 circuit;\nﬁrst the index i or j and then the corresponding values xi∗or y∗j in the row or column. Whenever Alice plays i, her best response\n(conditioned on i) is to play E\nf\nyi j\ng\nin every column j, where the expectation is over the distribution of yi j conditioned on Bob\nchoosing index j. In an ϵ-approximate Nash equilibrium, in most coordinates, Alice must usually choose xi j’s that are close to this\nbest response. Given this, for most indices j ∈\nf√\nd\ng\n, whenever Bob chooses j, he must usually choose a value of yi j that is close\nto E\nf\nxi j\ng\n(for each i). It can be shown that this implies that Alice’s strategy corresponds to a δ-approximate ﬁxed point (in the\nnormalized ℓ2 norm), where δ is a function of ϵ only.\n7It is also important that minimal advice suﬃces to translate between points x of the hypercube and vertices v of the underlying\nsuccinct EoL instance (as f is deﬁned on the former, while S and P operate on the latter). This can be achieved by using a\nstate-of-the-art locally decodable error-correcting code (with query complexity do(1), similar to that in Kopparty et al. [91]) to\nembed the vertices into the hypercube (as described in Section 4.3.3). Incorporating the advice that corresponds to local decoding\ninto the game produced by the reduction results in a further blow-up of 2do(1). This is eﬀectively absorbed by the 2\n√\nd blow-up that\nis already present in the reduction in Section 5.2.7.\n59\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 120
  },
  {
    "chunk_full": "2. the successor and predecessor circuits S, P are computable in NC0;\n3. for every vertex v ∈V, S(v) and P(v) diﬀer from v in O(1) coordinates.\nThe proof idea is to start from the original circuits S and P of a succinct EoL instance and form circuits\nS′ and P′ that operate on partial computation transcripts, carrying out the computations performed by the\ncircuits S or P one gate/line at a time (with O(1) bits changing in each step of the computation). The vertex\nset V then corresponds to the set of valid partial computation transcripts. The full proof is not overly diﬃcult;\nsee [135, Section 5] for the details. This reduction from succinct EoL to Local EoL can be implemented in\nlinear time, so our assumption that the former problem has no subexponential-time algorithms carries over\nto the latter problem.\nIn the standard succinct EoL problem, every n-bit string v ∈{0, 1}n is a legitimate vertex. In the Local\nEoL problem, only elements of {0, 1}n that satisfy the given AC0 circuit are legitimate vertices. In our\nreduction, we need to produce a game that also incorporates checking membership in V, also with only a\ndo(1) blow-up in how much of x we need to access. This is the reason why Rubinstein [135] needs to develop\ncustomized PCP machinery in his proof of Theorem 5.1. These PCP proofs can then be incorporated into\nthe blockwise play game (Section 5.2.7), analogous to how we incorporated the interactive protocol P into\nthe game in our reduction from 2EoL to ϵ-NE in Section 3.2.3.\n60\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 121
  },
  {
    "chunk_full": "Part II\nLunar Lectures\n61\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 122
  },
  {
    "chunk_full": "Lunar Lecture 1\nHow Computer Science Has Inﬂuenced Real-World Auction Design.\nCase Study: The 2016–2017 FCC Incentive Auction\nLecturer: Tim Roughgarden\nScribe: Dana Randall\n1.1\nPreamble\nComputer science is changing the way auctions are designed and implemented. For over 20 years, the US\nand other countries have used spectrum auctions to sell licenses for wireless spectrum to the highest bidder.\nWhat’s diﬀerent this decade, and what necessitated a new auction design, is that in the US the juiciest parts\nof the spectrum for next-generation wireless applications are already accounted for, owned by over-the-air\ntelevision broadcasters.\nThis led Congress to authorize the FCC in the fall of 2012 to design a novel\nauction (the FCC Incentive Auction) that would repurpose spectrum—procuring licenses from television\nbroadcasters (a relatively low-value activity) and selling them to parties that put them to better use (e.g.,\ntelecommunication companies who want to roll out the next generation of wireless broadband services). Thus\nthe new auction is really a double auction, comprising two stages: a reverse auction, where the government\nbuys back licenses for spectrum from their current owners; and then a forward auction, where the government\nsells the procured licenses to the highest bidder. Computer science techniques played a crucial role in the\ndesign of the new reverse auction. The main aspects of the forward auction have been around a long time;\nhere, theoretical computer science has contributed on the analysis side, and to understanding when and why\nsuch forward auctions work well. Sections 1.2 and 1.3 give more details on the reverse and forward parts of\nthe auction, respectively.\nThe FCC Incentive Auction ﬁnished around the end of March 2017, and so the numbers are in. The\ngovernment spent roughly 10 billion USD in the reverse part of the auction buying back licenses from\ntelevision broadcasters, and earned 20 billion USD of revenue in the forward auction. Most of the 10 billion\nUSD proﬁt was used to reduce the US deﬁcit!1\n1.2\nReverse Auction\n1.2.1\nDescending Clock Auctions\nThe reverse auction is the part of the FCC Incentive Auction that was totally new, and where computer science\ntechniques played a crucial role in the design. The auction format, proposed by Milgrom and Segal [108],\n1This was the plan all along, which is probably one of the reasons the bill didn’t have trouble passing through a notoriously\npartisan Congress. Another reason might be the veto-proof title of the bill: “The Middle Class Tax Relief and Job Creation Act.”\n62\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 123
  },
  {
    "chunk_full": "is what’s called a descending clock auction. By design, the auction is very simple from the perspective of\nany one participant. The auction is iterative, and operates in rounds. In each round of the auction, each\nremaining broadcaster is asked a question of the form: “Would you or would you not be willing to sell your\nlicense for (say) 1 million dollars?” The broadcaster is allowed to say “no,” with the consequence of getting\nkicked out of the auction forevermore (the station will keep its license and remain on the air, and will receive\nno compensation from the government). The broadcaster is also allowed to say “yes” and accept the buyout\noﬀer. In the latter case, the government will not necessarily buy the license for 1 million dollars—in the next\nround, the broadcaster might get asked the same question, with a lower buyout price (e.g., 950,000 USD).\nIf a broadcaster is still in the auction when it ends (more on how it ends in a second), then the government\ndoes indeed buy their license, at the most recent (and hence lowest) buyout oﬀer. Thus a broadcaster just\nhas to answer a sequence of “yes/no” questions for some decreasing sequence of buyout oﬀers. The obvious\nstrategy for a broadcaster is to formulate the lowest acceptable oﬀer for their license, and to drop out of the\nauction once the buyout price drops below this threshold.\nThe auction begins with very high buyout oﬀers, so that every broadcaster would be ecstatic to sell their\nlicense at the initial price. Intuitively, the auction then tries to reduce the buyout prices as much as possible,\nsubject to clearing a target amount of spectrum. Spectrum is divided into channels which are blocks of 6\nMHz each. For example, one could target broadcasters assigned to channels 38–51, and insist on clearing\n10 out of these 14 channels (60 MHz overall).2 By “clearing a channel,” we mean clearing it nationwide.\nOf course, in the descending clock auction, bidders will drop out in an uncoordinated way—perhaps the ﬁrst\nstation to drop out is channel 51 in Arizona, then channel 41 in western Massachusetts, and so on. To clear\nseveral channels nationwide without buying out essentially everybody, it was essential for the government\nto use its power to reassign the channels of the stations that remain on the air. Thus while a station that\ndrops out of the auction is guaranteed to retain its license, it is not guaranteed to retain its channel—a station\nbroadcasting on channel 51 before the auction might be forced to broadcast on channel 41 after the auction.\nThe upshot is that the auction maintains the invariant that the stations that have dropped out of the auction\n(and hence remain on the air) can be assigned channels so that at most a target number of channels get used\n(in our example, 4 channels). This is called the repacking problem. Naturally, two stations with overlapping\nbroadcasting regions cannot be assigned the same channel (otherwise they would interfere with each other).\nSee Figure 1.1.\n1.2.2\nSolving the Repacking Problem\nAny properly trained computer scientist will recognize the repacking problem as the NP-complete graph\ncoloring problem in disguise.3 For the proposed auction format to be practically viable, it must quickly solve\nthe repacking problem. Actually, make that thousands of repacking problems every round of the auction!4\nThe responsibility of quickly solving repacking problems fell to a team led by Kevin Leyton-Brown\n(see [54, 97]). The FCC gave the team a budget of one minute per repacking problem, ideally with most\ninstances solved within one second. The team’s approach was to build on state-of-the-art solvers for the\nsatisﬁability (SAT) problem. As you can imagine, it’s straightforward to translate an instance of the repacking\n2The FCC Incentive Auction would up clearing 84 MHz of spectrum (14 channels).\n3The actual repacking problem was more complicated—overlapping stations cannot even be assigned adjacent channels, and\nthere are idiosyncratic constraints at the borders with Canada and Mexico. See Leyton-Brown et al. [97] for more details. But the\nessence of the repacking problem really is graph coloring.\n4Before the auction makes a lower oﬀer to some remaining broadcaster in the auction, it needs to check that it would be OK\nfor the broadcaster to drop out of the auction. If a station’s dropping out would render the repacking problem infeasible, then that\nstation’s buyout price remains frozen until the end of the auction.\n63\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 124
  },
  {
    "chunk_full": "Figure 1.1: Diﬀerent TV stations with overlapping broadcasting areas must be assigned diﬀerent channels\n(indicated by shades of gray). Checking whether or not a given subset of stations can be assigned to a given\nnumber of channels without interference is an NP-hard problem.\nproblem into a SAT formula (even with the idiosyncratic constraints).5 Oﬀ-the-shelf SAT solvers did pretty\nwell, but still timed out on too many representative instances.6 Leyton-Brown’s team added several new\ninnovations, including taking advantage of the advance knowledge of the interference constraints (as station’s\nbroadcasting regions are public), and implementing a number of eﬀective caching techniques (reusing work\ndone solving previous instances to quickly solve closely related new instances). In the end, they were able to\nsolve more than 99% of the relevant repacking problems in under a minute.\nHopefully the high-level point is clear:\nwithout cutting-edge techniques for solving NP-complete problems, the FCC would have had\nto use a diﬀerent auction format.\n1.2.3\nReverse Greedy Algorithms\nOne ﬁnal twist: the novel reverse auction format motivates some basic algorithmic questions (and thus ideas\nﬂow from computer science to auction theory and back). We can think of the auction as an algorithm, a\nheuristic that tries to maximize the value of the stations that remain on the air, subject to clearing the target\namount of spectrum. Milgrom and Segal [108] prove that, ranging over all ways of implementing the auction\n(i.e., of choosing the sequences of descending prices), the corresponding algorithms are exactly the reverse\ngreedy algorithms.7 This result gives the ﬁrst extrinsic reason to study the power and limitations of reverse\n5A typical representative instance would have thousands of variables and tens of thousands of constraints.\n6Every time the repacking algorithm fails to ﬁnd a repacking when one exists, money is left on the table—the auction has to\nconservatively leave the current station’s buyout oﬀer frozen, even though it could have safely lowered it.\n7For example, Kruskal’s algorithm for the minimum spanning tree problem (start with the empty set, go through the edges of the\ngraph from cheapest to most expensive, adding an edge as long as it doesn’t create a cycle) is a standard (forward) greedy algorithm.\nThe reverse version is: start with the entire edge set, go through the edges in reverse sorted order, and remove an edge whenever it\n64\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 125
  },
  {
    "chunk_full": "greedy algorithms, a research direction explored by Dütting et al. [48] and Gkatzelis et al. [62].\n1.3\nForward Auction\nComputer science did not have an opportunity to inﬂuence the design of the forward auction used in the FCC\nIncentive Auction, which resembles the formats used over the past 20+ years. Still, the theoretical computer\nscience toolbox turns out to be ideally suited for explaining when and why these auctions work well.8\n1.3.1\nBad Auction Formats Cost Billions\nSpectrum auction design is stressful, because small mistakes can be extremely costly.\nOne cautionary\ntale is provided by an auction run by the New Zealand government in 1990 (before governments had much\nexperience with auctions). For sale were 10 essentially identical national licenses for television broadcasting.\nFor some reason, lost to the sands of time, the government decided to sell these licenses by running 10 second-\nprice auctions in parallel. Recall that a second-price or Vickrey auction for a single good is a sealed-bid\nauction that awards the item to the highest bidder and charges her the highest bid by someone else (the\nsecond-highest bid overall). When selling a single item, the Vickrey auction is often a good solution. In\nparticular, each bidder has a dominant strategy (always at least as good as all alternatives), which is to bid\nher true maximum willingness-to-pay.9\nThe nice properties of a second-price auction evaporate if many of them are run simultaneously. It is\nno longer clear how a bidder should bid. For example, imagine you want one of the licenses, but only one.\nHow should you bid? One legitimate strategy is to pick one of the licenses—at random, say—and go for it.\nAnother strategy is to bid less aggressively on multiple licenses, hoping that you get one at a bargain price,\nand that you don’t inadvertently win extra licenses that you don’t want. The diﬃculty is trading oﬀthe risk\nof winning too many licenses with the risk of winning too few.\nThe challenge of bidding intelligently in simultaneous sealed-bid auctions makes the auction format\nprone to poor outcomes. The revenue in the 1990 New Zealand auction was only $36 million, a paltry\nfraction of the projected $250 million. On one license, the high bid was $100,000 while the second-highest\nbid (and selling price) was $6! On another, the high bid was $7 million and the second-highest was $5,000.\nTo add insult to injury, the winning bids were made available to the public, who could then see just how\nmuch money was left on the table!\n1.3.2\nSimultaneous Ascending Auctions\nModern forward auctions are simultaneous ascending auctions (SAAs), following 1993 proposals by McAfee\nand by Milgrom and Wilson. You’ve seen—in the movies, at least—the call-and-response format of an\nascending single-item auction, where an auctioneer asks for takers at successively higher prices. Such an\nauction ends when there’s only one person left accepting the currently proposed price (who then wins, at\nthis price). Conceptually, SAAs are like a bunch of single-item English auctions being run in parallel in the\nsame room, with one auctioneer per item.\ndoesn’t disconnect the graph. For the minimum spanning tree problem (and more generally for ﬁnding the minimum-weight basis\nof a matroid), the reverse greedy algorithm is just as optimal as the forward one. In general (and even for e.g. bipartite matching),\nthe reverse version of a good forward greedy algorithm can be bad [48].\n8Much of the discussion in Sections 1.3.1–1.3.3 is from [129, Lecture 8], which in turn draws heavily from Milgrom [107].\n9Intuitively, a second-price auction shades your bid optimally after the fact, so there’s no reason to try to game it.\n65\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 126
  },
  {
    "chunk_full": "The primary reason that SAAs work better than sequential or sealed-bid auctions is price discovery.\nAs a bidder acquires better information about the likely selling prices of licenses, she can implement mid-\ncourse corrections: abandoning licenses for which competition is ﬁercer than anticipated, snapping up\nunexpected bargains, and rethinking which packages of licenses to assemble. The format typically resolves\nthe miscoordination problems that plague simultaneous sealed-bid auctions.\n1.3.3\nIneﬃciency in SAAs\nSAAs have two big vulnerabilities. The ﬁrst problem is demand reduction, and this is relevant even when\nitems are substitutes.10 Demand reduction occurs when a bidder asks for fewer items than it really wants, to\nlower competition and therefore the prices paid for the items that it gets.\nTo illustrate, suppose there are two identical items and two bidders. The ﬁrst bidder has valuation 10 for\none of the items and valuation 20 for both. The second bidder has valuation 8 for one of the items and does\nnot want both (i.e., her valuation remains 8 for both). The socially optimal outcome is to give both licenses\nto the ﬁrst bidder. Now consider how things play out in an SAA. The second bidder would be happy to have\neither item at any price less than 8. Thus, the second bidder drops out only when both items have price at\nleast 8. If the ﬁrst bidder stubbornly insists on winning both items, her utility is 20 −16 = 4. An alternative\nstrategy for the ﬁrst bidder is to simply concede the second item and never bid on it. The second bidder takes\nthe second item and (since it only wants one license) withdraws interest in the ﬁrst, leaving it for the ﬁrst\nbidder. Both bidders get their item essentially for free, and the utility of the ﬁrst bidder has jumped to 10.\nThe second big problem with SAAs is relevant when items can be complements, and is called the\nexposure problem.11 As an example, consider two bidders and two nonidentical items. The ﬁrst bidder only\nwants both items—they are complementary items for the bidder—and her valuation is 100 for them (and 0\notherwise). The second bidder is willing to pay 75 for either item but only wants one item. The socially\noptimal outcome is to give both items to the ﬁrst bidder. But in an SAA, the second bidder will not drop out\nuntil the price of both items reaches 75. The ﬁrst bidder is in a no-win situation: to get both items it would\nhave to pay 150, more than her value. The scenario of winning only one item for a nontrivial price could be\neven worse. Thus the exposure problem leads to economically ineﬃcient allocations for two reasons. First,\nan overly aggressive bidder might acquire unwanted items. Second, an overly tentative bidder might fail to\nacquire items for which it has the highest valuation.\n1.3.4\nWhen Do SAAs Work Well?\nIf you ask experts who design or consult for bidders in real-world SAAs, a rough consensus emerges about\nwhen they are likely to work well.\nFolklore Belief 1. Without strong complements, SAAs work pretty well. Demand reduction does happen,\nbut it is not a deal-breaker because the loss of eﬃciency appears to be small.\nFolklore Belief 2. With strong complements, simple auctions like SAAs are not good enough. The exposure\nproblem is a deal-breaker because it can lead to very poor outcomes (in terms of both economic eﬃciency\nand revenue).\n10Items are substitutes if they provide diminishing returns—having one item only makes others less valuable. For two items A\nand B, for example, the substitutes condition means that v(AB) ≤v(A) + v(B). In a spectrum auction context, two licenses for the\nsame area with equal-sized frequency ranges are usually substitute items.\n11Items are complements if there are synergies between them, so that possessing one makes others more valuable. With two\nitems A and B, this translates to the property v(AB) > v(A) + v(B). Complements arise naturally in wireless spectrum auctions, as\nsome bidders want a collection of licenses that are adjacent, either in their geographic areas or in their frequency ranges.\n66\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 127
  },
  {
    "chunk_full": "There are a number of beautiful and useful theoretical results about spectrum auctions in the economics\nliterature, but none map cleanly to these two folklore beliefs. A possible explanation: translating these\nbeliefs into theorems seems to fundamentally involve approximate optimality guarantees, a topic right in the\nwheelhouse of theoretical computer science.\nIn the standard model of combinatorial auctions, there are n bidders (e.g., telecoms) and m items (e.g.,\nlicenses). Bidder i has a nonnegative valuation vi(S) for each subset S of items it might receive. Note that\neach bidder has 2m parameters. Each bidder wants to maximize its utility, which is the value of the items\nreceived minus the price it pays for them. From a social perspective, we’d like to award bundles of items\nT1, . . .,Tn to the bidders to maximize the social welfare Pn\ni=1 vi(Ti).\nTo make the ﬁrst folklore belief precise, we need to commit to a deﬁnition of “without strong comple-\nments” and to a speciﬁc auction format. We’ll focus on simultaneous ﬁrst-price auctions (S1As), where\neach bidder submits a separate bid for each item, for each item the winner is the highest bidder, and winning\nbidders pay their bid on each item won.12 One relatively permissive deﬁnition of “complement-free” is to\nrestrict bidders to have subadditive valuations. This means what it sounds like: if A and B are two bundles\nof items, then bidder i’s valuation vi(A ∪B) of their union should be at most that of the sum vi(A) + vi(B).\nObserve the subadditivity is violated in our exposure problem example above.\nWe also need to deﬁne what we mean by “the outcome of an auction” like S1As. Remember that bidders\nare strategic, and will bid to maximize their utility (value of items won minus the price paid). Thus we\nshould prove approximation guarantees for the equilibria of auctions. Happily, computer scientists have been\nworking hard since 1999 to prove approximation guarantees for game-theoretic equilibria, also known as\nbounds on the price of anarchy [92, 124, 132]. In the early days, price-of-anarchy bounds appeared somewhat\nad hoc and problem-speciﬁc. Fast forwarding to the present, we now have a powerful and user-friendly theory\nfor proving price-of-anarchy bounds, which combine “extension theorems” and “composition theorems” to\nbuild up bounds for complex settings (including S1As) from bounds for simple settings.13 In particular,\nFeldman et al. [52] proved the following translation of Folklore Belief #1.14\nTheorem 1.1 (Feldman et al. [52]). When every bidder has a subadditive valuation, every equilibrium of an\nS1A has social welfare at least 50% of the maximum possible.\nOne version of Theorem 1.1 concerns (mixed) Nash equilibria, as studied in the Solar Lectures. Even\nhere, the bound in Theorem 1.1 is tight in the worst case [37]. The approximation guarantee in Theorem 1.1\nholds more generally for Bayes-Nash equilibria, the standard equilibrium notion for games of incomplete\ninformation.15\nMoving on to the second folklore belief, let’s now drop the subadditivity restriction. S1As no longer\nwork well.\nTheorem 1.2 (Hassidim et al. [73]). When bidders have arbitrary valuations, an S1A can have a mixed Nash\nequilibrium with social welfare arbitrarily smaller than the maximum possible.\n12Similar results hold for other auction formats, like simultaneous second-price auctions. Directly analyzing what happens in\niterative auctions like SAAs when there are multiple items has proved diﬃcult.\n13We will say more about this theory in Lunar Lecture 5. See also Roughgarden et al. [134] for a recent survey.\n14To better appreciate this result, we note that multi-item auctions like S1As are so strategically complex that they have historically\nbeen seen as unanalyzable. For example, we have no idea what their equilibria look like in general. Nevertheless, we can prove\ngood approximation guarantees for them!\n15In more detail, there is a commonly known prior distribution over bidders’ valuations. In a Bayes-Nash equilibrium, every\nbidder bids to maximize its expected utility given its information at the time: its own valuation, its posterior belief about other\nbidders’ valuations, and the bidding strategies (mapping valuations to bids) used by the other bidders. Theorem 1.1 continues to\nhold for every Bayes-Nash equilibrium of an S1A, as long as bidders’ valuations are drawn independently (but not necessarily\nidentically).\n67\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 128
  },
  {
    "chunk_full": "Thus for S1As, the perspective of worst-case approximation conﬁrms the dichotomy between the cases\nof substitutes and complements. But the lower bound in Theorem 1.2 holds for just one auction format.\nCould we do better with a diﬀerent (but still relatively simple) auction format? Folklore Belief #2 asserts\nthe stronger statement that no “simple” auction works well with general valuations. This stronger statement\ncan also be translated into a theorem (using nondeterministic communication complexity), and this will be\nthe main subject of Lunar Lecture 2.\nTheorem 1.3 (Roughgarden [126]). With general valuations, every simple auction can have arbitrarily bad\nequilibria.\nThe deﬁnition of “simple” used in Theorem 1.3 is quite generous: it requires only that the number of\nstrategies available to each player is sub-doubly-exponential in the number of items m. For example, running\nseparate single-item auctions provides each player with only an exponential number of strategies (assuming\na bounded number of possible bid values). Thus Theorem 1.3 makes use of the theoretical computer science\ntoolbox to provide solid footing for Folklore Belief #2.\n68\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 129
  },
  {
    "chunk_full": "Lunar Lecture 2\nCommunication Barriers to Near-Optimal Equilibria\nLecturer: Tim Roughgarden\nScribe: Omri Weinstein\nThis lecture is about the communication complexity of the welfare-maximization problem in combina-\ntorial auctions and its implications for the price of anarchy of simple auctions. After deﬁning the model in\nSection 2.1, Section 2.2 proves lower bounds for nondeterministic communication protocols and Section 2.3\ngives a black-box translation of these lower bounds to equilibria of simple auctions. In particular, Section 2.3\nprovides the proof of Theorem 1.3 from last lecture. Section 2.4 concludes with a juicy open problem on the\ntopic.1\n2.1\nWelfare Maximization in Combinatorial Auctions\nRecall from Section 1.3.4 the basic setup in the study of combinatorial auctions.\n1. There are k players. (In a spectrum auction, these are the telecoms.)\n2. There is a set M of m items. (In a spectrum auction, these are the licenses.)\n3. Each player i has a valuation vi : 2M →R+. The number vi(T) indicates i’s value, or willingness to\npay, for the items T ⊆M. The valuation is the private input of player i — i knows vi but none of the\nother vj’s. (I.e., this is a number-in-hand model.) We assume that vi(∅) = 0 and that the valuations\nare monotone, meaning vi(S) ≤vi(T) whenever S ⊆T. (The more items, the better.) To avoid\nbit complexity issues, we’ll also assume that all of the vi(T)’s are integers with description length\npolynomial in k and m. We sometimes impose additional restrictions on the valuations to study special\ncases of the general problem.\nNote that we may have more than two players—more than just Alice and Bob. (For example, you might want\nto think of k as ≈m1/3.) Also note that the description length of a player’s valuation is exponential in the\nnumber of items m.\nIn the welfare-maximization problem, the goal is to partition the items M into setsT1, . . .,Tk to maximize,\nat least approximately, the welfare\nk\nX\ni=1\nvi(Ti),\n(2.1)\n1Much of this lecture is drawn from [130, Lecture 7].\n69\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 130
  },
  {
    "chunk_full": "using communication polynomial in n and m. Note this amount of communication is logarithmic in the sizes\nof the private inputs. Maximizing social welfare (2.1) is the most commonly studied objective function in\ncombinatorial auctions, and it is the one we will focus on in this lecture.\n2.2\nCommunication Lower Bounds for Approximate Welfare Maximization\nThis section studies the communication complexity of computing an approximately welfare-maximizing\nallocation in a combinatorial auction. For reasons that will become clear in Section 2.3, we are particularly\ninterested in the problem’s nondeterministic communication complexity.2\n2.2.1\nLower Bound for General Valuations\nWe begin with a result of Nisan [115] showing that, alas, computing even a very weak approximation of the\nwelfare-maximizing allocation requires exponential communication. To make this precise, it is convenient\nto turn the optimization problem of welfare maximization into a decision problem.\nIn the Welfare-\nMaximization(k) problem, the goal is to correctly identify inputs that fall into one of the following two\ncases:\n(1) Every partition (T1, . . .,Tk) of the items has welfare at most 1.\n(0) There exists a partition (T1, . . .,Tk) of the items with welfare at least k.\nArbitrary behavior is permitted on inputs that fail to satisfy either (1) or (0). Clearly, communication lower\nbounds for Welfare-Maximization(k) apply to the more general problem of obtaining a better-than-k-\napproximation of the maximum welfare.3\nTheorem 2.1 ([115]). The nondeterministic communication complexity of Welfare-Maximization(k) is\nexp{Ω(m/k2)}, where k is the number of players and m is the number of items.\nThis lower bound is exponential in m, provided that m = Ω(k2+ϵ) for some ϵ > 0. Since communication\ncomplexity lower bounds apply even to players who cooperate perfectly, this impossibility result holds even\nwhen all of the (tricky) incentive issues are ignored.\n2.2.2\nThe Multi-Disjointness Problem\nThe plan for the proof of Theorem 2.1 is to reduce a multi-party version of the Disjointness problem to\nit. There is some ambiguity about how to deﬁne a version of Disjointness for three or more players. For\nexample, suppose there are three players, and among the three possible pairings of them, two have disjoint\nsets while the third have intersecting sets. Should this count as a “yes” or “no” instance? We’ll skirt this\nissue by worrying only about unambiguous inputs, that are either “totally disjoint” or “totally intersecting.”\nFormally, in the Multi-Disjointness problem, each of the k players i holds an input xi ∈{0, 1}n.\n(Equivalently, a set Si ⊆{1, 2, . . ., n}.) The task is to correctly identify inputs that fall into one of the\nfollowing two cases:\n2For basic background on nondeterministic multi-party communication protocols, see Kushilevitz and Nisan [93] or Roughgar-\nden [130].\n3Achieving a k-approximation is trivial: every player communicates their value vi (M) for the whole set of items, and the entire\nset of items is awarded to the bidder with the highest value for them.\n70\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 131
  },
  {
    "chunk_full": "(1) “Totally disjoint,” with Si ∩Si′ = ∅for every i , i′.\n(0) “Totally intersecting,” with ∩k\ni=1Si , ∅.\nWhen k = 2, this is just Disjointness. When k > 2, there are inputs that are neither 1-inputs nor 0-inputs.\nWe let protocols oﬀthe hook on such ambiguous inputs — they can answer “1” or “0” with impunity.\nThe following communication complexity lower bound for Multi-Disjointness is credited to Jaikumar\nRadhakrishnan and Venkatesh Srinivasan in [115]. (The proof is elementary, and for completeness is given\nin Section 2.5.)\nTheorem 2.2. The nondeterministic communication complexity of Multi-Disjointness, with k players with\nn-bit inputs, is Ω(n/k).\nThis nondeterministic lower bound is for verifying a 1-input. (It is easy to verify a 0-input—the prover\njust suggests the index of an element r in ∩k\ni=1Si.)4\n2.2.3\nProof of Theorem 2.1\nThe proof of Theorem 2.1 relies on Theorem 2.2 and a combinatorial gadget. We construct this gadget using\nthe probabilistic method. As a thought experiment, consider t random partitions P1, . . ., Pt of M, where t is\na parameter to be deﬁned later. By a random partition Pj = (Pj\n1, . . ., Pj\nk), we just mean that each of the m\nitems is assigned to exactly one of the k players, independently and uniformly at random.\nWe are interested in the probability that two classes of diﬀerent partitions intersect: for all i , i′ and\nj , ℓ, since the probability that a given item is assigned to i in Pj and also to i′ in Pℓis 1\nk2 , we have\nPr\nf\nPj\ni ∩Pℓ\ni′ = ∅\ng\n=\n \n1 −1\nk2\n!m\n≤e−m/k2.\nTaking a Union Bound over the k choices for i and i′ and the t choices for j and ℓ, we have\nPr\nf\n∃i , i′, j , ℓs.t. Pj\ni ∩Pℓ\ni′ = ∅\ng\n≤k2t2e−m/k2.\n(2.2)\nCall P1, . . ., Pt an intersecting family if Pj\ni ∩Pℓ\ni′ , ∅whenever i , i′, j , ℓ. By (2.2), the probability that\nour random experiment fails to produce an intersecting family is less than 1 provided t < 1\nk em/2k2. The\nfollowing lemma is immediate.\nLemma 2.3. For every m, k ≥1, there exists an intersecting family of partitions P1, . . ., Pt with t =\nexp{Ω(m/k2)}.\nA simple combination of Theorem 2.2 and Lemma 2.3 now proves Theorem 2.1.\nProof. (of Theorem 2.1) The proof is a reduction from Multi-Disjointness. Fix k and m. (To be interesting,\nm should be signiﬁcantly bigger than k2.) Let (S1, . . ., Sk) denote an input to Multi-Disjointness with t-bit\ninputs, where t = exp{Ω(m/k2)} is the same value as in Lemma 2.3. We can assume that the players have\n4To prove Theorem 2.1, we’ll be interested in the case where k is much smaller than n, such as k = Θ(log n). Intuition might\nsuggest that the lower bound should be Ω(n) rather than Ω(n/k), but this is incorrect — a slightly non-trivial argument shows that\nTheorem 2.2 is tight for nondeterministic protocols (for all small enough k, like k = O(√n)). This factor-k diﬀerence won’t matter\nfor our applications, however.\n71\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 132
  },
  {
    "chunk_full": "coordinated in advance on an intersecting family of t partitions of a set M of m items. Each player i uses this\nfamily and its input Si to form the following valuation:\nvi(T) =\n(\n1\nif T ⊇Pj\ni for some j ∈Si\n0\notherwise.\nThat is, player i is either happy (value 1) or unhappy (value 0), and is happy if and only if it receives\nall of the items in the corresponding class Pj\ni of some partition Pj with index j belonging to its input to\nMulti-Disjointness. The valuations v1, . . ., vk deﬁne an input to Welfare-Maximization(k). Forming\nthis input requires no communication between the players.\nConsider the case where the input to Multi-Disjointness is a 1-input, with Si ∩Si′ = ∅for every\ni , i′. We claim that the induced input to Welfare-Maximization(k) is a 1-input, with maximum welfare\nat most 1. To see this, consider a partition (T1, . . .,Tk) in which some player i is happy (with vi(Ti) = 1).\nFor some j ∈Si, player i receives all the items in Pj\ni . Since j < Si′ for every i′ , i, the only way to make\na second player i′ happy is to give it all the items in Pℓ\ni′ in some other partition Pℓwith ℓ∈Si′ (and hence\nℓ, j). Since P1, . . ., Pt is an intersecting family, this is impossible — Pj\ni and Pℓ\ni′ overlap for every ℓ, j.\nWhen the input to Multi-Disjointness is a 0-input, with an element r in the mutual intersection ∩k\ni=1Si,\nwe claim that the induced input to Welfare-Maximization(k) is a 0-input, with maximum welfare at least k.\nThis is easy to see: for i = 1, 2, . . ., k, assign the items of Pr\ni to player i. Since r ∈Si for every i, this makes\nall k players happy.\nThis reduction shows that a (deterministic, nondeterministic, or randomized) protocol for Welfare-\nMaximization(k) yields one for Multi-Disjointness (with t-bit inputs) with the same communication. We\nconclude that the nondeterministic communication complexity of Welfare-Maximization(k) is Ω(t/k) =\nexp{Ω(m/k2)}.\n□\n2.2.4\nSubadditive Valuations\nTo an algorithms person, Theorem 2.1 is depressing, as it rules out any non-trivial positive results. A natural\nidea is to seek positive results by imposing additional structure on players’ valuations. Many such restrictions\nhave been studied. We consider here the case of subadditive valuations (see also Section 1.3.4 from last\nlecture), where each vi satisﬁes vi(S ∪T) ≤vi(S) + vi(T) for every pair S,T ⊆M.\nOur reduction in Theorem 2.1 immediately yields a weaker inapproximability result for welfare maxi-\nmization with subadditive valuations. Formally, deﬁne the Welfare-Maximization(2) problem as that of\nidentifying inputs that fall into one of the following two cases:\n(1) Every partition (T1, . . .,Tk) of the items has welfare at most k + 1.\n(0) There exists a partition (T1, . . .,Tk) of the items with welfare at least 2k.\nCommunication lower bounds for Welfare-Maximization(2) apply also to the more general problem of\nobtaining a better-than-2-approximation of the maximum welfare.\nTheorem 2.4(Dobzinski et al. [47]). The nondeterministiccommunicationcomplexityofWelfare-Maximization(2)\nis exp{Ω(m/k2)}, even when all players have subadditive valuations.\nThis theorem follows from a modiﬁcation of the proof of Theorem 2.1. The 0-1 valuations used in that\nproof are not subadditive, but they can be made subadditive by adding 1 to each bidder’s valuation vi(T)\nof each non-empty set T. The social welfare obtained in inputs corresponding to 1- and 0-inputs of Multi-\nDisjointness become k + 1 and 2k, respectively, and this completes the proof of Theorem 2.4.\n72\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 133
  },
  {
    "chunk_full": "There is also a quite non-trivial matching upper bound of 2 for deterministic, polynomial-communication\nprotocols [50].\n2.3\nLower Bounds on the Price of Anarchy of Simple Auctions\nThe lower bounds of the previous section show that every protocol for the welfare-maximization problem\nthat interacts with the players and then explicitly computes an allocation has either a bad approximation\nratio or high communication cost. Over the past decade, many researchers have aimed to shift the work\nfrom the protocol to the players, by analyzing the equilibria of simple auctions. Can such equilibria bypass\nthe communication complexity lower bounds proved in Section 2.2? The answer is not obvious, because\nequilibria are deﬁned non-constructively, and not through a low-cost communication protocol.\n2.3.1\nAuctions as Games\nWhat do we mean by a “simple” auction? For example, recall the simultaneous ﬁrst-price auctions (S1As)\nintroduced in Section 1.3.4 of the preceding lecture. Each player i chooses a strategy bi1, . . ., bim, with one\nbid per item.5 Each item is sold separately in parallel using a “ﬁrst-price auction”—the item is awarded to\nthe highest bidder, and the price is whatever that player bid.6 The payoﬀof a player in a given outcome (i.e.,\ngiven a choice of strategy for each player) is then her utility:\nvi(Ti)\n|{z}\nvalue of items won\n−\nX\nj ∈Si\nbi j\n|  {z  }\nprice paid for them\n,\nwhere Ti denotes the items on which i is the highest bidder (given the bids of the others).\nBidders strategize already in a ﬁrst-price auction for a single item—a bidder certainly doesn’t want to\nbid her actual valuation (this would guarantee utility 0), and instead will “shade” her down to a lower value.\n(How much to shade is a tricky question, and depends on what the other bidders are doing.) Thus it makes\nsense to assess the performance of an auction by its equilibria. As usual, a Nash equilibrium comprises a\n(randomized) strategy for each player, so that no player can unilaterally increase her expected payoﬀthrough\na unilateral deviation to some other strategy (given how the other players are bidding).\n2.3.2\nThe Price of Anarchy\nSo how good are the equilibria of various games, such as S1As? To answer this question, we use an analog of\nthe approximation ratio, adapted for equilibria. Given a game (like an S1A) and a nonnegative maximization\nobjective function on the outcomes (like the social welfare), the price of anarchy (POA) Koutsoupias and\nPapadimitriou [92] is deﬁned as the ratio between the objective function value of an optimal solution, and\nthat of the worst equilibrium:\nPoA(G) :=\nf (OPT(G))\nminµ is an equilibrium of G f (µ),\n5To keep the game ﬁnite, let’s agree that each bid has to be an integer between 0 and some known upper bound B.\n6You may have also heard of the Vickrey or second-price auction, where the winner does not pay their own bid, but rather the\nhighest bid by someone else (the second-highest overall). We’ll stick with S1As for simplicity, but similar results are known for\nsimultaneous second-price auctions, as well.\n73\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 134
  },
  {
    "chunk_full": "where G denotes a game, f denotes a (maximization) objective function, and OPT(G) is the optimal outcome\nof G (with respect to f ).7 Thus the price of anarchy of a game quantiﬁes the ineﬃciency of selﬁsh behavior.8\nThe POA of a game and a maximization objective function is always at least 1. It is common to identify\n“good performance” of a system with strategic participants as having a POA close to 1.9\nThe POA depends on the choice of equilibrium concept. For example, the POA with respect to approx-\nimate Nash equilibria can only be worse (i.e., bigger) than for exact Nash equilibria (since there are only\nmore of the former).\n2.3.3\nThe Price of Anarchy of S1As\nAs we saw in Theorem 1.1 of the preceding lecture, the equilibria of simple auctions like S1As can be\nsurprisingly good.10 We restate that result here.11\nTheorem 2.5 (Feldman et al. [52]). In every S1A with subadditive bidder valuations, the POA is at most 2.\nThis result is particularly impressive because achieving an approximation factor of 2 for the welfare-\nmaximization problem with subadditive bidder valuations by any means (other than brute-force search) is\nnot easy (see [50]).\nAs mentioned last lecture, a recent result shows that the analysis of [52] is tight.\nTheorem 2.6 (Christodoulou et al. [37]). The worst-case POA of S1As with subadditive bidder valuations is\nat least 2.\nThe proof of Theorem 2.6 is an ingenious explicit construction—the authors exhibit a choice of subaddi-\ntive bidder valuations and a Nash equilibrium of the corresponding S1A so that the welfare of this equilibrium\nis only half of the maximum possible. One reason that proving results like Theorem 2.6 is challenging is\nthat it can be diﬃcult to solve for a (bad) equilibrium of a complex game like a S1A.\n2.3.4\nPrice-of-Anarchy Lower Bounds from Communication Complexity\nTheorem 2.5 motivates an obvious question: can we do better? Theorem 2.6 implies that the analysis in [52]\ncannot be improved, but can we reduce the POA by considering a diﬀerent auction? Ideally, the auction\nwould still be “reasonably simple” in some sense. Alternatively, perhaps no “simple” auction could be better\nthan S1As? If this is the case, it’s not clear how to prove it directly—proving lower bounds via explicit\nconstructions auction-by-auction does not seem feasible.\nPerhaps it’s a clue that the POA upper bound of 2 for S1As (Theorem 2.5) gets stuck at the same threshold\nfor which there is a lower bound for protocols that use polynomial communication (Theorem 2.4). It’s not\nclear, however, that a lower bound for low-communication protocols has anything to do with equilibria. Can\nwe extract a low-communication protocol from an equilibrium?\n7If µ is a probability distribution over outcomes, as in a mixed Nash equilibrium, then f (µ) denotes the expected value of f\nw.r.t. µ.\n8Games generally have multiple equilibria. Ideally, we’d like an approximation guarantee that applies to all equilibria, so that\nwe don’t need to worry about which one is reached—this is the point of the POA.\n9One caveat is that it’s not always clear that a system will reach an equilibrium in a reasonable amount of time. A natural\nsolution to this is to relax the notion of equilibrium enough so that it become relatively easy to reach an equilibrium. See Lunar\nLecture 5 for more on this point.\n10The ﬁrst result of this type, for simultaneous second-price auctions and bidders with submodular valuations, is due to\nChristodoulou et al. [36].\n11For a proof, see the original paper [52] or course notes by your lecturer [127, Lecture 17.5].\n74\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 135
  },
  {
    "chunk_full": "Theorem 2.7 (Roughgarden [126]). Fix a class V of possible bidder valuations.\nSuppose there exists\nno nondeterministic protocol with subexponential (in m) communication for the 1-inputs of the following\npromise version of the welfare-maximization problem with bidder valuations in V:\n(1) Every allocation has welfare at most W∗/α.\n(0) There exists an allocation with welfare at least W∗.\nLet ϵ be bounded below by some inverse polynomial function of n and m. Then, for every auction with\nsub-doubly-exponential (in m) strategies per player, the worst-case POA of ϵ-approximate Nash equilibria\nwith bidder valuations in V is at least α.\nTheorem 2.7 says that lower bounds for nondeterministic protocols carry over to all “suﬃciently simple”\nauctions, where “simplicity” is measured by the number of strategies available to each player. These POA\nlower bounds follow automatically from communication complexity lower bounds, and do not require any\nnew explicit constructions.\nTo get a feel for the simplicity constraint, note that S1As with integral bids between 0 and B have (B+1)m\nstrategies per player—singly exponential in m. On the other hand, in a “direct-revelation” auction, where\neach bidder is allowed to submit a bid on each bundle S ⊆M of items, each player has a doubly-exponential\n(in m) number of strategies.12\nThe POA lower bound promised by Theorem 2.7 is only for approximate Nash equilibria; since the POA\nis a worst-case measure and the set of ϵ-NE is nondecreasing with ϵ, this is weaker than a lower bound for\nexact Nash equilibria. It is an open question whether or not Theorem 2.7 holds also for the POA of exact\nNash equilibria.13\nTheorem 2.7 has a number of interesting corollaries. First, consider the case where V is the set of\nsubadditive valuations. Since S1As have only a singly-exponential (in m) number of strategies per player,\nTheorem 2.7 applies to them. Thus, combining it with Theorem 2.4 recovers the POA lower bound of\nTheorem 2.6—modulo the exact vs. approximate Nash equilibria issue—and shows the optimality of the\nupper bound in Theorem 2.5 without an explicit construction. Even more interestingly, this POA lower bound\nof 2 applies not only to S1As, but more generally to all auctions in which each player has a sub-doubly-\nexponential number of strategies. Thus, S1As are in fact optimal among the class of all such auctions when\nbidders have subadditive valuations (w.r.t. the worst-case POA of ϵ-approximate Nash equilibria).\nWe can also take V to be the set of all (monotone) valuations, and then combine Theorem 2.7 with\nTheorem 2.1 to deduce that no “simple” auction gives a non-trivial (i.e., better-than-k) approximation for\ngeneral bidder valuations. We conclude that with general valuations, complexity is essential to any auction\nformat that oﬀers good equilibrium guarantees. This completes the proof of Theorem 1.3 from the preceding\nlecture and formalizes the second folklore belief in Section 1.3.4; we restate that result here.\nTheorem 2.8 ([126]). With general valuations, every simple auction can have equilibria with social welfare\narbitrarily worse than the maximum possible.\n2.3.5\nProof of Theorem 2.7\nPresumably, the proof of Theorem 2.7 extracts a low-communication protocol from a good POA bound. The\nhypothesis of Theorem 2.7 oﬀers the clue that we should be looking to construct a nondeterministic protocol.\n12Equilibria can achieve the optimal welfare in a direct-revelation auction, so the bound in Theorem 2.7 on the number of\nstrategies is necessary.\n13Arguably, Theorem 2.7 is good enough for all practical purposes—a POA upper bound that holds for exact Nash equilibria and\ndoes not hold (at least approximately) for approximate Nash equilibria with very small ϵ is too brittle to be meaningful.\n75\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 136
  },
  {
    "chunk_full": "(i)  OPT'≤'W/α'\n(ii)  OPT'≥'W'\nprover'writes''\ndown'an'ε9NE'x'\nplayers'privately'\nverify'ε9NE'condi@ons'\nplayers'compute'\nexpected'welfare'of'x'\nif'E[welfare(x)]'≤'W/α'\nthen'OPT'≤'ρW/α'<'W'\n(so'case'(i))'\nif'E[welfare(x)]'>'W/α'\nthen'OPT'>'W/α''\n(so'case'(ii))'\nFigure 2.1: Proof of Theorem 2.7. How to extract a low-communication nondeterministic protocol from a\ngood price-of-anarchy bound.\nSo what could we use an all-powerful prover for? We’ll see that a good role for the prover is to suggest a\nNash equilibrium to the players.\nUnfortunately, it’s too expensive for the prover to even write down the description of a Nash equilibrium,\neven in S1As. Recall that a mixed strategy is a distribution over pure strategies, and that each player has an\nexponential (in m) number of pure strategies available in a S1A. Specifying a Nash equilibrium thus requires\nan exponential number of probabilities. To circumvent this issue, we resort to approximate Nash equilibria,\nwhich are guaranteed to exist even if we restrict ourselves to distributions with small descriptions. We proved\nthis for two-player games in Solar Lecture 1 (Theorem 1.15); the same argument works with games with any\nnumber of players.\nLemma 2.9 (Lipton et al. [99]). For every ϵ > 0 and every game with k players with strategy sets A1, . . ., Ak,\nthere exists an approximate Nash equilibrium with description length polynomial in k, log(maxk\ni=1 |Ai|),\nand 1\nϵ .\nIn particular, every game with a sub-doubly-exponential number of strategies admits an approximate\nNash equilibrium with subexponential description length.\nWe now proceed to the proof of Theorem 2.7.\nProof. (of Theorem 2.7) Fix an auction withatmost Astrategiesperplayer, andavaluefor ϵ = Ω(1/poly(k, m)).\nAssume that, no matter what the bidder valuations v1, . . ., vk ∈V are, the POA of ϵ-approximate Nash equi-\nlibria of the auction is at most ρ < α. We will show that A must be doubly-exponential in m.\nConsider the following nondeterministic protocol for verifying a 1-input of the welfare-maximization\nproblem—for convincing the k players that every allocation has welfare at most W∗/α. See also Figure 2.1.\nThe prover writes on a publicly visible blackboard an ϵ-approximate Nash equilibrium (σ1, . . ., σk) of the\nauction, with description length polynomial in k, log A, and 1\nϵ = O(poly(k, m)) as guaranteed by Lemma 2.9.\nThe prover also writes down the expected welfare contribution E[vi(S)] of each bidder i in this equilibrium.\nGiven this advice, each player i veriﬁes that σi is indeed an ϵ-approximate best response to the other\nσj’s and that its expected welfare is as claimed when all players play the mixed strategies σ1, . . ., σk.\nCrucially, player i is fully equipped to perform both of these checks without any communication—it knows\n76\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 137
  },
  {
    "chunk_full": "its valuation vi (and hence its utility in each outcome of the game) and the mixed strategies used by all\nplayers, and this is all that is needed to verify its ϵ-approximate Nash equilibrium conditions and compute\nits expected contribution to the welfare.14 Player i accepts if and only if the prover’s advice passes these two\ntests, and if the expected welfare of the equilibrium is at most W∗/α.\nFor the protocol correctness, consider ﬁrst the case of a 1-input, where every allocation has welfare\nat most W∗/α. If the prover writes down the description of an arbitrary ϵ-approximate Nash equilibrium\nand the appropriate expected contributions to the social welfare, then all of the players will accept (the\nexpected welfare is obviously at most W∗/α). We also need to argue that, for the case of a 0-input—where\nsome allocation has welfare at least W∗—there is no proof that causes all of the players to accept. We can\nassume that the prover writes down an ϵ-approximate Nash equilibrium and its correct expected welfare W,\nsince otherwise at least one player will reject. Since the maximum-possible welfare is at least W∗and (by\nassumption) the POA of ϵ-approximate Nash equilibria is at most ρ < α, the expected welfare of the given\nϵ-approximate Nash equilibrium must satisfy W ≥W∗/ρ > W/α. Since the players will reject such a proof,\nwe conclude that the protocol is correct. Our assumption then implies that the protocol has communication\ncost exponential in m. Since the cost of the protocol is polynomial in k, m, and log A, A must be doubly\nexponential in m.\n□\nConceptually, the proof of Theorem 2.7 argues that, when the POA of ϵ-approximate Nash equilibria is\nsmall, every ϵ-approximate Nash equilibrium provides a privately veriﬁable proof of a good upper bound\non the maximum-possible welfare. When such upper bounds require large communication, the equilibrium\ndescription length (and hence the number of available strategies) must be large.\n2.4\nAn Open Question\nWhile Theorems 2.4, 2.5, and 2.7 pin down the best-possible POA achievable by simple auctions with\nsubadditive bidder valuations, there are still open questions for other valuation classes. For example, a\nvaluation vi is submodular if it satisﬁes\nvi(T ∪{j}) −vi(T) ≤vi(S ∪{j}) −vi(S)\nfor every S ⊆T ⊂M and j < T. This is a “diminishing returns” condition for set functions. Every\nsubmodular function is also subadditive, so welfare-maximization with the former valuations is only easier\nthan with the latter.\nThe worst-case POA of S1As is exactly\ne\ne−1 ≈1.58 when bidders have submodular valuations. The\nupper bound was proved in [143], the lower bound in [37]. It is an open question whether or not there\nis a simple auction with a smaller worst-case POA. The best lower bound known—for nondeterministic\nprotocols and hence, by Theorem 1.3, for the POA of ϵ-approximate Nash equilibria of simple auctions—is\n2e\n2e−1 ≈1.23 [46]. Intriguingly, there is an upper bound (very slightly) better than\ne\ne−1 for polynomial-\ncommunication protocols [51]—can this better upper bound also be realized as the POA of a simple auction?\nWhat is the best-possible approximation guarantee, either for polynomial-communication protocols or for\nthe POA of simple auctions? Resolving this question would require either a novel auction format (better than\nS1As), a novel lower bound technique (better than Theorem 2.7), or both.\n14These computations may take a super-polynomial amount of time, but they do not contribute to the protocol’s cost.\n77\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 138
  },
  {
    "chunk_full": "2.5\nAppendix: Proof of Theorem 2.2\nThe proof of Theorem 2.2 proceeds in three easy steps.\nStep 1: Every nondeterministic protocol with communication cost c induces a cover of the 1-inputs of\nM( f ) by at most 2c monochromatic boxes. By “M( f ),” we mean the k-dimensional array in which the ith\ndimension is indexed by the possible inputs of player i, and an array entry contains the value of the function f\non the corresponding joint input. By a “box,” we mean the k-dimensional generalization of a rectangle—a\nsubset of inputs that can be written as a product A1 × A2 × · · · × Ak. By “monochromatic,” we mean a box\nthat does not contain both a 1-input and a 0-input. (Recall that for the Multi-Disjointness problem there\nare also inputs that are neither 1 nor 0—a monochromatic box can contain any number of these.) The proof\nof this step is the same as the standard one for the two-party case (see e.g. [93]).\nStep 2: The number of 1-inputs in M( f ) is (k + 1)n. In a 1-input (x1, . . ., xk), for every coordinate ℓ, at\nmost one of the k inputs has a 1 in the ℓth coordinate. This yields k + 1 options for each of the n coordinates,\nthereby generating a total of (k + 1)n 1-inputs.\nStep 3: The number of 1-inputs in a monochromatic box is at most kn. Let B = A1 × A2 × · · · × Ak be a\n1-box. The key claim here is: for each coordinate ℓ= 1, . . ., n, there is a player i ∈{1, . . ., k} such that, for\nevery input xi ∈Ai, the ℓth coordinate of xi is 0. That is, to each coordinate we can associate an “ineligible\nplayer” that, in this box, never has a 1 in that coordinate. This is easily seen by contradiction: otherwise,\nthere exists a coordinate ℓsuch that, for every player i, there is an input xi ∈Ai with a 1 in the ℓth coordinate.\nAs a box, B contains the input (x1, . . ., xk). But this is a 0-input, contradicting the assumption that B is a\n1-box.\nThe claim implies the stated upper bound. Every 1-input of B can be generated by choosing, for each\ncoordinate ℓ, an assignment of at most one “1” in this coordinate to one of the k −1 eligible players for this\ncoordinate. With only k choices per coordinate, there are at most kn 1-inputs in the box B.\nConclusion: Steps 2 and 3 imply that covering the 1s of the k-dimensional array of the Multi-Disjointness\nfunction requires at least (1 + 1\nk )n 1-boxes. By the discussion in Step 1, this implies a lower bound of\nn log2(1 + 1\nk ) = Θ(n/k) on the nondeterministic communication complexity of the Multi-Disjointness\nfunction (and output 1). This concludes the proof of Theorem 2.2.\n78\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 139
  },
  {
    "chunk_full": "Lunar Lecture 3\nWhy Prices Need Algorithms\nLecturer: Tim Roughgarden\nScribe: Sumegha Garg & Joshua R. Wang\nYou’ve probably heard about “market-clearing prices,” which equate the supply and demand in a market.\nWhen are such prices guaranteed to exist? In the classical setting with divisible goods (milk, wheat, etc.),\nmarket-clearing prices exist under reasonably weak conditions [6]. But with indivisible goods (houses,\nspectrum licenses, etc.), such prices may or may not exist.\nAs you can imagine, many papers in the\neconomics and operations research literatures study necessary and suﬃcient conditions for existence. The\npunchline of today’s lecture, based on joint work with Inbal Talgam-Cohen [131], is that computational\ncomplexity considerations in large part govern whether or not market-clearing prices exist in a market of\nindivisible goods. This is cool and surprising because the question (existence of equilibria) seems to have\nnothing to do with computation (cf., the questions studied in the Solar Lectures).\n3.1\nMarkets with Indivisible Items\nThe basic setup is the same as in the preceding lecture, when we were studying price-of-anarchy bounds for\nsimple combinatorial auctions (Section 2.1). To review, there are k players, a set M of m items, and each\nplayer i has a valuation vi : 2M →R+ describing its maximum willingness to pay for each bundle of items.\nFor simplicity, we also assume that vi(∅) = 0 and that vi is monotone (with vi(S) ≤vi(T) whenever S ⊆T).\nAs in last lecture, we will often vary the class V of allowable valuations to make the setting more or less\ncomplex.\n3.1.1\nWalrasian Equilibria\nNext is the standard deﬁnition of “market-clearing prices” in a market with multiple indivisible items.\nDeﬁnition 3.1 (Walrasian Equilibrium). A Walrasian equilibrium is an allocation S1, . . ., Sk of the items\nof M to the players and nonnegative prices p1, p2, ..., pm for the items such that:\n(W1) All buyers are as happy as possible with their respective allocations, given the prices: for every i =\n1, 2, . . ., k, Si ∈argmaxT (vi(T) −P\nj ∈T pj).\n(W2) Feasibility: Si ∩Sj = ∅for i , j.\n(W3) The market clears: for every j ∈M, j ∈Si for some i.1\n1The most common deﬁnition of a Walrasian equilibrium asserts instead that an item j is not awarded to any player only\nif pj = 0. With monotone valuations, there is no harm in insisting that every item is allocated.\n79\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 140
  },
  {
    "chunk_full": "Note that Si might be the empty set, if the prices are high enough for (W1) to hold for player i. Also,\nproperty (P3) is crucial for the deﬁnition to be non-trivial (otherwise set pj = +∞for every j).\nWalrasian equilibria are remarkable: even though each player optimizes independently (modulo tie-\nbreaking) and gets exactly what it wants, somehow the global feasibility constraint is respected.\n3.1.2\nThe First Welfare Theorem\nRecall from last lecture that the social welfare of an allocation S1, . . ., Sk is deﬁned as Pk\ni=1 vi(S). Walrasian\nequilibria automatically maximize the social welfare, a result known as the “First Welfare Theorem.”\nTheorem 3.2 (First Welfare Theorem). If the prices p1, p2, . . ., pm and allocation S1, S2, . . ., Sk of items\nconstitute a Walrasian equilibrium, then\n(S1, S2, ..., Sk) ∈argmax(T1,T2,...,Tk )\nk\nX\ni=1\nvi(Ti),\nwhere (T1, . . .,Tk) ranges over all feasible allocations (with Ti ∩Tj = ∅for i , j).\nIf one thinks of a Walrasian equilibrium as the natural outcome of a market, then Theorem 3.2 can be\ninterpreted as saying “markets are eﬃcient.”2 There are many “First Welfare Theorems,” and all have this\nﬂavor.\nProof. Let (S∗\n1, . . ., S∗\nk) denote a welfare-maximizing feasible allocation. We can apply property (W1) of\nWalrasian equilibria to obtain\nvi(Si) −\nX\nj ∈Si\npj ≥vi(S∗\ni ) −\nX\nj ∈S∗\ni\npj\nfor each player i = 1, 2, . . ., k. Summing over i, we have\nk\nX\ni=1\nvi(Si) −\nk\nX\ni=1\n*.\n,\nX\nj ∈Si\npj+/\n-\n≥\nk\nX\ni=1\nvi(S∗\ni ) −\nk\nX\ni=1\n*.\n,\nX\nj ∈S∗\ni\npj+/\n-\n.\n(3.1)\nProperties (W2) and (W3) imply that the second term on the left-hand side of (3.1) equals the sum Pm\nj=1 pj\nof all the item prices. Since (S∗\n1, . . ., S∗\nn) is a feasible allocation, each item is awarded at most once and\nhence the second term on the right-hand side is at most Pm\nj=1 pj. Adding Pm\nj=1 pj to both sides gives\nk\nX\ni=1\nvi(Si) ≥\nk\nX\ni=1\nvi(S∗\ni ),\nwhich proves that (S1, . . ., Sk) is also welfare-maximizing.\n□\n3.1.3\nExistence of Walrasian Equilibria\nThe First Welfare Theorem says that Walrasian equilibria are great when they exist. But when do they exist?\n2Needless to say, much blood and ink has been spilled over this interpretation over the past couple of centuries.\n80\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 141
  },
  {
    "chunk_full": "Example 3.3. Suppose M contains only one item. Consider the allocation that awards the item to the player i\nwith the highest value for it, and a price that is between the i’s value and the highest value of some other\nplayer (the second-highest overall). This is a Walrasian equilibrium: the price is low enough that bidder i\nprefers receiving the item to receiving nothing, and high enough that all the other bidders prefer the opposite.\nA simple case analysis shows that these are all of the Walrasian equilibria.\nExample 3.4. Consider a market with two items, A and B. Suppose the valuation of the ﬁrst player is\nv1(T) =\n\n3\nfor T = {A, B}\n0\notherwise\nand that of the second player is\nv2(T) =\n\n2\nwhen T is A or B\n0\notherwise.\nThe ﬁrst bidder is called a “single-minded” or “AND” bidder, who is only happy if she gets both items. The\nsecond bidder is called a “unit-demand” or “OR” bidder, and only wants one of the items.\nWe claim that there is no Walrasian equilibrium in this market. From the First Welfare Theorem, we\nknow what such an equilibrium must allocate the items to maximize the social welfare, which in this case\nmeans awarding both items to the ﬁrst player. For the second player to be happy getting neither item, the\nprice of each item must be at least 2. But then the ﬁrst player pays 4 and has negative utility, and would\nprefer to receive nothing.\nThese examples suggest a natural question: under what conditions is a Walrasian equilibrium guaranteed\nto exist? There is a well-known literature on this question in economics (e.g. [87, 69, 106]); here are the\nhighlights.\n1. If every player’s valuation vi satisﬁes the “gross substitutes (GS)” condition, then a Walrasian equilib-\nrium is guaranteed to exist. We won’t need the precise deﬁnition of the GS condition in this lecture.\nGS valuations are closely related to weighted matroid rank functions, and hence are a subclass of the\nsubmodular valuations deﬁned at the end of last lecture in Section 2.4.3 A unit-demand (a.k.a. “OR”)\nvaluation, like that of the second player in Example 3.4, satisﬁes the GS condition (corresponding to\nthe 1-uniform matroid). It follows that single-minded (a.k.a. “AND”) valuations, like that of the ﬁrst\nplayer in Example 3.4, do not in general satisfy the GS condition (otherwise the market in Example 3.4\nwould have a Walrasian equilibrium).\n2. If V is a class of valuations that contains all unit-demand valuations and also some valuation that\nviolates the GS condition, then there is a market with valuations in V that does not possess a Walrasian\nequilibrium.\nThese results imply that GS valuations are a maximal class of valuations subject to the guaranteed existence\nof Walrasian equilibria.\nThese results do, however, leave open the possibility of guaranteed existence\nfor classes V that contain non-GS valuations but not all unit-demand valuations, and a number of recent\npapers in economics and operations research have pursued this direction (e.g. [11, 24, 25, 142]). All of the\nnon-existence results in this line of work use explicit constructions, like in Example 3.4.\n3A weighted matroid rank function f is deﬁned using a matroid (E, I) and nonnegative weights on the elements E, with f (S)\ndeﬁned as the maximum weight of an independent set (i.e., a member of I) that lies entirely in S.\n81\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 142
  },
  {
    "chunk_full": "3.2\nComplexity Separations Imply Non-Existence of Walrasian Equilibria\n3.2.1\nStatement of Main Result\nNext we describe a completely diﬀerent approach to ruling out the existence of Walrasian equilibria, based\non complexity theory rather than explicit constructions. The main result is the following.\nTheorem 3.5 (Roughgarden and Talgam-Cohen [131]). Let V denote a class of valuations. Suppose the\nwelfare-maximization problem for V does not reduce to the utility-maximization problem for V. Then, there\nexists a market with all player valuations in V that has no Walrasian equilibrium.\nIn other words, a necessary condition for the guaranteed existence of Walrasian equilibria is that welfare-\nmaximization is no harder than utility-maximization. This connects a purely economic question (when do\nequilibria exist?) to a purely algorithmic one.\nTo ﬁll in some of the details in the statement of Theorem 3.5, by “does not reduce to,” we mean that there\nis no polynomial-time Turing reduction from the former problem to the latter. By “the welfare-maximization\nproblem for V,” we mean the problem of, given player valuations v1, . . ., vk ∈V, computing an allocation\nthat maximizes the social welfare Pk\ni=1 vi(Si).4 By “the utility-maximization problem for V,” we mean the\nproblem of, given a valuation v ∈V and nonnegative prices p1, . . ., pm, computing a utility-maximizing\nbundle S ∈argmaxT ⊆M)v(T) −P\nj ∈T pj.\nThe utility-maximization problem, which involves only one player, can generally only be easier than the\nmulti-player welfare-maximization problem. Thus the two problems either have the same computational\ncomplexity, or welfare-maximization is strictly harder. Theorem 3.5 asserts that whenever the second case\nholds, Walrasian equilibria need not exist.\n3.2.2\nExamples\nBefore proving Theorem 3.5, let’s see how to apply it. For most natural valuation classes V, a properly\ntrained theoretical computer scientist can identify the complexity of the utility- and welfare-maximization\nproblems in a matter of minutes.\nExample 3.6 (AND Valuations). Let Vm denote the class of “AND” valuations for markets where |M| = m.\nThat is, each v ∈Vm has the following form, for some α ≥0 and T ⊆M:\nv(S) =\n\nα\nif S ⊇T\n0\notherwise.\nThe utility-maximization problem for Vm is trivial: for a single player with an AND valuation with parameters\nα and T, the better of ∅or T is a utility-maximizing bundle. The welfare-maximization problem for Vm is\nessentially set packing and is NP-hard (with m →∞).5 We conclude that the welfare-maximization problem\nfor V does not reduce to the utility-maximization problem for V (unless P = NP). Theorem 3.5 then implies\nthat, assuming P , NP, there are markets with AND valuations that do not have any Walrasian equilibria.6\n4For concreteness, think about the case where every valuation vi has a succinct description and can be evaluated in polynomial\ntime. Analogous results hold when an algorithm has only oracle access to the valuations.\n5For example, given an instance G = (V, E) of the Independent Set problem, take M = E, make one player for each vertex\ni ∈V, and give player i an AND valuation with parameters α = 1 and T equal to the edges that are incident to i in G.\n6It probably seems weird to have a conditional result ruling out equilibrium existence. A conditional non-existence result can\nof course be made unconditional through an explicit example. A proof that the welfare-maximization problem for V is NP-hard will\n82\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 143
  },
  {
    "chunk_full": "Of course, Example 3.4 already shows, without any complexity assumptions, that markets with AND\nbidders do not generally have Walrasian equilibria.7 Our next example addresses a class of valuations for\nwhich the status of Walrasian equilibria was not previously known.\nExample 3.7 (Capped Additive Valuations). A capped additive valuation v is parameterized by m + 1\nnumbers c, α1, α2, . . ., αm and is deﬁned as\nv(S) = min\n\nc,\nX\nj ∈S\nαj\n\n.\nThe αj’s indicate each item’s value, and c the “cap” on the maximum value that can be attained. Capped\nadditive valuations were proposed in Lehmann et al. [95] as a natural subclass of submodular valuations, and\nhave been studied previously from a welfare-maximization standpoint.\nLet Vm,d denote the class of capped additive valuations in markets with |M| = m and with c and\nα1, . . ., αm restricted to be positive integers between 1 and md. (Think of d as ﬁxed and m →∞.) A\nKnapsack-type dynamic programming algorithm shows that the utility-maximization problem for Vm,d can\nbe solved in polynomial time (using that c and the αj’s are polynomially bounded). For d a suﬃciently large\nconstant, however, the welfare-maximization problem for Vm,d is NP-hard (it includes the strongly NP-hard\nBin Packing problem). Theorem 3.5 then implies that, assuming P , NP, there are markets with valuations\nin Vm,d with no Walrasian equilibrium.\n3.3\nProof of Theorem 3.5\n3.3.1\nThe Plan\nHere’s the plan for proving Theorem 3.5. Fix a class V of valuations, and assume that a Walrasian equilibrium\nexists in every market with player valuations in V. We will show, in two steps, that the welfare-maximization\nproblem for V (polynomial-time Turing) reduces to the utility-maximization problem for V.\nStep 1:\nThe “fractional” version of the welfare-maximization problem for V reduces to the utility-\nmaximization problem for V.\nStep 2: A market admits a Walrasian equilibrium if and only if the fractional welfare-maximization problem\nhas an optimal integral solution. (We’ll only need the “only if” direction.)\nSince every market with valuations in V admits a Walrasian equilibrium (by assumption), these two steps\nimply that the integral welfare-maximization problem reduces to utility-maximization.\ngenerally suggest candidate markets to check for non-existence.\nThe following analogy may help: consider computationally tractable linear programming relaxations of NP-hard optimization\nproblems. Conditional on P , NP, such relaxations cannot be exact (i.e., have no integrality gap) for all instances. NP-hardness\nproofs generally suggest instances that can be used to prove directly (and unconditionally) that a particular linear programming\nrelaxation has an integrality gap.\n7Replacing the OR bidder in Example 3.4 with an appropriate pair of AND bidders extends the example to markets with only\nAND bidders.\n83\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 144
  },
  {
    "chunk_full": "3.3.2\nStep 1: Fractional Welfare-Maximization Reduces to Utility-Maximization\nThis step is folklore, and appears for example in Nisan and Segal [116]. Consider the following linear\nprogram (often called the conﬁguration LP), with one variable xiS for each player i and bundle S ⊆2M:\nmax\nk\nX\ni=1\nX\nS ⊆M\nvi(S)xiS\ns.t.\nk\nX\ni=1\nX\nS ⊆M : j ∈S\nxiS ≤1\nfor j = 1, 2, . . ., m\nX\nS ⊆M\nxiS = 1\nfor i = 1, 2, . . ., k.\nThe intended semantics are\nxiS =\n\n1\nif i gets the bundle S\n0\notherwise.\nThe ﬁrst set of constraints enforces that each item is awarded only once (perhaps fractionally), and the second\nset enforces that every player receives one bundle (perhaps fractionally). Every feasible allocation induces a\n0-1 feasible solution to this linear program according to the intended semantics, and the objective function\nvalue of this solution is exactly the social welfare of the allocation.\nThis linear program has an exponential (in m) number of variables. The good news is that it has only a\npolynomial number of constraints. This means that the dual linear program will have a polynomial number\nof variables and an exponential number of constraints, which is right in the wheelhouse of the ellipsoid\nmethod.\nPrecisely, the dual linear program is:\nmin\nk\nX\ni=1\nui +\nm\nX\nj=1\npj\ns.t.\nui +\nX\nj ∈S\npj ≥vi(S)\nfor all i = 1, 2, . . ., k and S ⊆M\npj ≥0\nfor j = 1, 2, . . ., m,\nwhere ui and pj corresponds to the primal constraints that bidder i receives one bundle and item j is allocated\nat most once, respectively.\nRecall that the ellipsoid method [88] can solve a linear program in time polynomial in the number of\nvariables, as long as there is a polynomial-time separation oracle that can verify whether or not a given\npoint is feasible and, if not, produce a violated constraint. For the dual linear program above, this separation\noracle boils down to solving the following problem: for each player i = 1, 2, . . ., k, check that\nui ≥max\nS ⊆M\n\nvi(S) −\nX\nj ∈S\npj\n\n.\n84\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 145
  },
  {
    "chunk_full": "But this reduces immediately to the utility-maximization problem for V! Thus the ellipsoid method can\nbe used to solve the dual linear program to optimality, using a polynomial number of calls to a utility-\nmaximization oracle. The optimal solution to the original fractional welfare-maximization problem can then\nbe eﬃciently extracted from the optimal dual solution.8\n3.3.3\nStep 2: Walrasian Equilibria and Exact Linear Relaxations\nWe now proceed with the second step, which is based on Bikhchandani and Mamer [12] and follows from\nstrong linear programming duality. Recall from linear programming theory (see e.g. [38]) that a pair of primal\nand dual feasible solutions are both optimal if and only if the “complementary slackness” conditions hold.9\nThese conditions assert that every non-zero decision variable in one of the linear programs corresponds to a\ntight constraint in the other. For our primal-dual pair of linear programs, these conditions are:\n(i) xiS > 0 implies that ui = vi(S) −P\nj ∈S pj (i.e., only utility-maximizing bundles are used);\n(ii) pj > 0 implies that P\ni\nP\nS:j ∈S xiS = 1 (i.e., item j is not fully sold only if it is worthless).\nComparing the deﬁnition of Walrasian equilibria (Deﬁnition 3.1) with conditions (i) and (ii), we see that\na 0-1 primal feasible solution x (corresponding to an allocation) and a dual solution p (corresponding to\nitem prices) constitute a Walrasian equilibrium if and only if the complementary slackness conditions hold\n(where ui is understood to be set to maxS ⊆M vi(S) −P\nj ∈S pj). Thus a Walrasian equilibrium exists if and\nonly if there is a feasible 0-1 solution to the primal linear program and a feasible solution to the dual linear\nproblem that satisfy the complementary slackness conditions, which in turn holds if and only if the primal\nlinear program has an optimal 0-1 feasible solution.10 We conclude that a Walrasian equilibrium exists if\nand only if the fractional welfare-maximization problem has an optimal integral solution.11\n3.4\nBeyond Walrasian Equilibria\nFor valuation classes V that do not always possess Walrasian equilibria, is it possible to deﬁne a more general\nnotion of “market-clearing prices” so that existence is guaranteed? For example, what if we use prices that are\nmore complex than item prices? This section shows that complexity considerations provide an explanation\nof why interesting generalizations of Walrasian equilibria have been so hard to come by.\nConsider a class V of valuations, and a class P of pricing functions. A pricing function, just like a\nvaluation, is a function p : 2M →R+ from bundles to nonnegative numbers. The item prices p1, . . ., pm\nused to deﬁne Walrasian equilibria correspond to additive pricing functions, with p(S) = P\nj ∈S pj. The next\ndeﬁnition articulates the appropriate generalization of Walrasian equilibria to more general classes of pricing\nfunctions.\n8In more detail, consider the (polynomial number of) dual constraints generated by the ellipsoid method when solving the dual\nlinear program. Form a reduced version of the original primal problem, retaining only the (polynomial number of) variables that\ncorrespond to this subset of dual constraints. Solve this polynomial-size reduced version of the primal linear program using your\nfavorite polynomial-time linear programming algorithm.\n9If you’ve never seen or have forgotten about complementary slackness, there’s no need to be afraid. To derive them, just\nwrite down the usual proof of weak LP duality (which is a chain of inequalities), and back out the conditions under which all the\ninequalities hold with equality.\n10This argument re-proves the First Welfare Theorem (Theorem 3.2). It also proves the Second Welfare Theorem, which states\nthat for every welfare-maximizing allocation, there exist prices that render it a Walrasian equilibrium—any optimal solution to the\ndual linear program furnishes such prices.\n11Recall our analogy with integrality gaps of linear programs (footnote 6). NP-hardness implies an integrality gap (assuming\nP , NP), and we now see that integrality gaps and non-existence of Walrasian equilibria go together.\n85\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 146
  },
  {
    "chunk_full": "Deﬁnition 3.8 (Price Equilibrium). A price equilibrium (w.r.t. pricing functions P) is an allocation S1, . . ., Sk\nof the items of M to the players and a pricing function p ∈P such that:\n(P1) All buyers are as happy as possible with their respective allocations, given the prices: for every i =\n1, 2, . . ., k, Si ∈argmaxT (vi(T) −p(T)).\n(P2) Feasibility: Si ∩Sj = ∅for i , j.\n(P3) Revenue maximizing, given the prices: (S1, S2, ..., Sk) ∈argmax(T1,T2,...,Tk )\nPk\ni=1 p(Ti).\nCondition (P3) is the analog of the market-clearing condition (W3) in Deﬁnition 3.1. It is not enough\nto assert that all items are sold, because with a general pricing function, diﬀerent ways of selling all of the\nitems can lead to diﬀerent amounts of revenue. Under conditions (P1)–(P3), the First Welfare Theorem\n(Theorem 3.2) still holds, with essentially the same proof, and so every price equilibrium maximizes the\nsocial welfare.\nFor which choices of valuations V and pricing functions P is Deﬁnition 3.8 interesting? Ideally, the\nfollowing properties should hold.\n1. Guaranteed existence: for every set M of items and valuations v1, . . ., vk ∈V, there exists a price\nequilibrium with respect to P.\n2. Eﬃcient recognition: there is a polynomial-time algorithm for checking whether or not a given\nallocation and pricing function constitute a price equilibrium.\nThis boils down to assuming that\nutility-maximization (with respect to V and P) and revenue-maximization (with respect to P) are\npolynomial-time solvable problems (to check (W1) and (W3), respectively).12\n3. Markets with valuations in V do not always have a Walrasian equilibrium. (Otherwise, why bother\ngeneralizing item prices?)\nWe can now see why there are no known natural choices of V and P that meet these three requirements.\nThe ﬁrst two requirements imply that the welfare-maximization problem belongs to NP ∩co-NP. To certify\na lower bound of W∗on the maximum social welfare, one can exhibit an allocation with social welfare at\nleast W∗. To certify an upper bound of W∗, one can exhibit a price equilibrium that has welfare at most W∗—\nthis is well deﬁned by the ﬁrst condition, eﬃciently veriﬁable by the second condition, and correct by the\nFirst Welfare Theorem.\nProblems in (NP∩co-NP) \\P appear to be rare, especially in combinatorial optimization. The preceding\nparagraph gives a heuristic argument that interesting generalizations of Walrasian equilibria are possible\nonly for valuation classes for which welfare-maximization is polynomial-time solvable. For every natural\nsuch class known, the linear programming relaxation in Section 3.3 has an optimal integral solution; in\nthis sense, solving the conﬁguration LP appears to be a “universal algorithm” for polynomial-time welfare-\nmaximization. But the third requirement asserts that a Walrasian equilibrium does not always exist in markets\nwith valuations in V and so, by the second step of the proof of Theorem 3.5 (in Section 3.3.3), there are\nmarkets for which the conﬁguration LP sometimes has only fractional optimal solutions.\nThe upshot is that interesting generalizations of Walrasian equilibria appear possible only for valuation\nclasses where a non-standard algorithm is necessary and suﬃcient to solve the welfare-maximization problem\nin polynomial time. It is not clear if there are any natural valuation classes for which this algorithmic barrier\ncan be overcome.13\n12One could require the stronger property that a price equilibrium can be computed (not just veriﬁed) in polynomial time. Using\nthe weaker requirement makes our negative results stronger.\n13See [131, Section 5.3.2] for an unnatural such class.\n86\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 147
  },
  {
    "chunk_full": "Lunar Lecture 4\nThe Borders of Border’s Theorem\nLecturer: Tim Roughgarden\nScribe: Cristopher Moore\nBorder’s theorem [16] is a famous result in auction theory about the design space of single-item auctions,\nand it provides an explicit linear description of the single-item auctions that are “feasible” in a certain sense.\nDespite the theorem’s fame, there have been few generalizations of it. This lecture, based on joint work with\nParikshit Gopalan and Noam Nisan [68], uses complexity theory to explain why: if there were signiﬁcant\ngeneralizations of Border’s theorem, the polynomial hierarchy would collapse!\n4.1\nOptimal Single-Item Auctions\n4.1.1\nThe Basics of Single-Item Auctions\nSingle-item auctions have made brief appearances in previous lectures; let’s now study the classic model,\ndue to Vickrey [146], in earnest. There is a single seller of a single item. There are n bidders, and each\nbidder i has a valuation vi for the item (its maximum willingness to pay). Valuations are private, meaning\nthat vi is known a priori to bidder i but not to the seller or the other bidders. Each bidder wants to maximize\nthe value obtained from the auction (vi if it wins, 0 otherwise) minus the price it has to pay. In the presence\nof randomization (either in the input or internal to the auction), we assume that bidders are risk-neutral,\nmeaning they act to maximize their expected utility.\nThis lecture is our only one on the classical Bayesian model of auctions, which can be viewed as a form\nof average-case analysis. The key assumption is that each valuation vi is drawn from a distribution Fi that is\nknown to the seller and possibly the other bidders. The actual realization vi remains unknown to everybody\nother than bidder i. For simplicity we’ll work with discrete distributions, and let Vi denote the support\nof Fi and fi(vi) the probability that bidder i’s valuation is vi ∈Vi. Typical examples include (discretized\nversions of) the uniform distribution, the lognormal distribution, the exponential distribution, and power-law\ndistributions. We also assume that bidders’ valuations are stochastically independent.\nWhen an economist speaks of an “optimal auction,” they usually mean the auction that maximizes the\nseller’s expected revenue with respect to a known prior distribution.1 Before identifying optimal auctions,\nwe need to formally deﬁne the design space. The auction designer needs to decide who wins and how much\nthey pay. Thus they must deﬁne two (possibly randomized) functions of the bid vector ⃗b: an allocation\n1One advantage of assuming a distribution over inputs is that there is an unequivocal way to compare the performance of\ndiﬀerent auctions (by their expected revenues), and hence an unequivocal way to deﬁne an optimal auction. One auction generally\nearns more revenue than another on some inputs and less on others, so in the absence of a prior distribution, it’s not clear which one\nto prefer.\n87\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 148
  },
  {
    "chunk_full": "rule ⃗x(⃗b) which determines which bidder wins the item, where xi = 1 and if i wins and xi = 0 otherwise,\nand a payment rule ⃗p(⃗b) where pi is how much i pays. We impose the constraint that whenever bidder i\nbids bi, the expected payment E\nf\npi(⃗b)\ng\nof the bidder is at most bi times the probability xi(⃗b) that it wins.\n(The randomization is over the bids by the other bidders and any randomness internal to the auction.) This\nparticipation constraint ensures that a bidder who does not overbid will obtain nonnegative expected utility\nfrom the auction. (Without it, an auction could just charge +∞to every bidder.) The revenue of an auction\non the bid vector ⃗b is Pn\ni=1 pi(⃗b).\nFor example, in the Vickrey or second-price auction, the allocation rule awards the item to the highest\nbidder, and the payment rule charges the second-highest bid. This auction is truthful, meaning that for each\nbidder, truthful bidding (i.e., setting bi = vi) is a dominant strategy that maximizes its utility no matter what\nthe other bidders do. With a truthful auction, there is no need to assume that the distributions F1, . . ., Fn are\nknown to the bidders. The beauty of the Vickrey auction is that it delegates underbidding to the auctioneer,\nwho determines the optimal bid for the winner on their behalf.\nA ﬁrst-price auction has the same allocation rule as a second-price auction (give the item to the highest\nbidder), but the payment rule charges the winner its bid. Bidding truthfully in a ﬁrst-price auction guarantees\nzero utility, so strategic bidders will underbid. Because bidders do not have dominant strategies—the optimal\namount to underbid depends on the bids of the others—it is non-trivial to reason about the outcome of ﬁrst-\nprice auctions. The traditional solution is to assume that the distributions F1, . . ., Fn are known in advance to\nthe bidders, and to consider Bayes-Nash equilibria. Formally, a strategy of a bidder i in a ﬁrst-price auction is\na predetermined plan for bidding—a function bi(·) that maps its valuation vi to a bid bi(vi) (or a distribution\nover bids). The semantics are: “when my valuation is vi, I will bid bi(vi).” We assume that bidders’\nstrategies are common knowledge, with bidders’ valuations (and hence induced bids) private as usual. A\nstrategy proﬁle b1(·), · · · , bn(·) is a Bayes-Nash equilibrium if every bidder always bids optimally given its\ninformation—if for every bidder i and every valuation vi, the bid bi(vi) maximizes i’s expected utility, where\nthe expectation is with respect to the distribution over the bids of other bidders induced by F1, . . ., Fn and\ntheir bidding strategies.2 Note that the set of Bayes-Nash equilibria of an auction generally depends on the\nprior distributions F1, . . ., Fn.\nAn auction is called Bayesian incentive compatible (BIC) if truthful bidding (with bi(vi) = vi for all\ni and vi) is a Bayes-Nash equilibrium. That is, as a bidder, if all other bidders bid truthfully, then you\nalso want to bid truthfully. A second-price auction is BIC, while a ﬁrst-price auction is not.3 However,\nfor every choice of F1, . . ., Fn, there is a BIC auction that is equivalent to the ﬁrst-price auction. Speciﬁ-\ncally: given bids a1, . . ., an, implement the outcome of the ﬁrst-price auction with bids b1(a1), . . ., bn(an),\nwhere b1(·), . . ., bn(·) denotes a Bayes-Nash equilibrium of the ﬁrst-price auction (with prior distributions\nF1, . . ., Fn). Intuitively, this auction makes the following pact with each bidder: “you promise to tell me\nyour true valuation, and I promise to bid on your behalf as you would in a Bayes-Nash equilibrium.” More\ngenerally, this simulation argument shows that for every auction A, distributions F1, . . ., Fn, and Bayes-Nash\nequilibrium of A (w.r.t. F1, . . ., Fn), there is a BIC auction A′ whose (truthful) outcome (and hence expected\nrevenue) matches that of the chosen Bayes-Nash equilibrium of A. This result is known as the Revelation\nPrinciple.\nThis principle implies that, to identify an optimal auction, there is no loss of generality in\nrestricting to BIC auctions.4\n2Straightforward exercise: if there are n bidders with valuations drawn i.i.d. from the uniform distribution on [0, 1], then setting\nbi (vi) = n−1\nn\n· vi for every i and vi yields a Bayes-Nash equilibrium.\n3The second-price auction is in fact dominant-strategy incentive compatible (DSIC)—truthful bidding is a dominant strategy\nfor every bidder, not merely a Bayes-Nash equilibrium.\n4Of course, non-BIC auctions like ﬁrst-price auctions are still useful in practice. For example, the description of the ﬁrst-price\nauction does not depend on bidders’ valuation distributions F1, . . ., Fn and can be deployed without knowledge of them. This is not\n88\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 149
  },
  {
    "chunk_full": "4.1.2\nOptimal Auctions\nIn optimal auction design, the goal is to identify an expected revenue-maximizing auction, as a function\nof the prior distributions F1, . . ., Fn. For example, suppose that n = 1, and we restrict attention to truthful\nauctions. The only truthful auctions are take-it-or-leave-it oﬀers (or a randomization over such oﬀers). That\nis, the selling price must be independent of the bidder’s bid, as any dependence would result in opportunities\nfor the bidder to game the auction. The optimal truthful auction is then the take-it-or-leave-it oﬀer at the\nprice r that maximizes\nr\n|{z}\nrevenue of a sale\n·\n(1 −F(r))\n|       {z       }\nprobability of a sale\n,\nwhere F denotes the bidder’s valuation distribution. Given a distribution F, it is usually a simple matter to\nsolve for the best r. An optimal oﬀer price is called a monopoly price of the distribution F. For example,\nif F is the uniform distribution on [0, 1], then the monopoly price is 1\n2.\nMyerson [111] gave a complete solution to the optimal single-item auction design problem, in the form\nof a generic compiler that takes as input prior distributions F1, . . ., Fn and outputs a closed-form description\nof the optimal auction for F1, . . ., Fn. The optimal auction is particularly easy to interpret in the symmetric\ncase, when bidders’ valuations are drawn i.i.d. from a common distribution F. Here, the optimal auction is\njust a second-price auction with a reserve price r equal to the monopoly price of F (i.e., an eBay auction\nwith a suitably chosen opening bid).5,6 For example, with any number n of bidders with valuations drawn\ni.i.d. from the uniform distribution on [0, 1], the optimal single-item auction is a second-price auction with\na reserve price of 1\n2. This is a pretty amazing conﬂuence of theory and practice—we optimized over the\nspace of all imaginable auctions (which includes some very strange specimens), and discovered that the\ntheoretically optimal auction format is one that is already in widespread use!7\nMyerson’s theory of optimal auctions extends to the asymmetric case where bidders have diﬀerent\ndistributions (where the optimal auction is no longer so simple), and also well beyond single-item auctions.8\nThe books by Hartline [72] and your lecturer [129, Lectures 3 and 5] describe this theory from a computer\nscience perspective.\n4.2\nBorder’s Theorem\n4.2.1\nContext\nBorder’s theorem identiﬁes a tractable description of all BIC single-item auctions, in the form of a polytope\nin polynomially many variables. (See Section 4.1.1 for the deﬁnition of a BIC auction.) This goal is in some\nsense more ambitious than merely identifying the optimal auction, since with this tractable description in\nhand, one can eﬃciently compute the optimal auction for any given set F1, . . ., Fn of prior distributions.\nEconomists are interested in Border’s theorem because it can be used to extend the reach of Myerson’s\noptimal auction theory (Section 4.1.2) to more general settings, such as the case of risk-adverse bidders\nthe case for the simulating auction.\n5The winner is the highest bidder who clears the reserve (if any). The winner (if any) pays either the reserve price or the\nsecond-highest bid, whichever is higher.\n6Technically, this requires a mild “regularity” condition on the distribution F, which holds for all of the most common parametric\ndistributions.\n7In particular, there is always an optimal auction in which truthful bidding is a dominant strategy (as opposed to merely being\na BIC auction). This is also true in the asymmetric case.\n8The theory applies more generally to “single-parameter problems.” These include problems where in each outcome a bidder\nis either a “winner” or a “loser,” with private valuation vi for winning and 0 for losing (and with multiple winners allowed).\n89\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 150
  },
  {
    "chunk_full": "studied by Maskin and Riley [101]. Matthews [102] conjectured the precise result that was proved by Border\n[16]. Computer scientists have used Border’s theorem for orthogonal extensions to Myerson’s theory, like\ncomputationally tractable descriptions of the expected-revenue maximizing auction in settings with multiple\nnon-identical items [3, 21]. While there is no hope of deriving a closed-form solution to the optimal auction\ndesign problem with risk-adverse bidders or with multiple items, Border’s theorem at least enables an eﬃcient\nalgorithm for computing a description of an optimal auction (given descriptions of the prior distributions).\n4.2.2\nAn Exponential-Size Linear Program\nAs a lead-in to Border’s theorem, we show how to formulate the space of BIC single-item auctions as an\n(extremely big) linear program. The decision variables of the linear program encode the allocation and\npayment rules of the auction (assuming truthful bidding, as appropriate for BIC auctions). There is one\nvariable xi(⃗v) ∈[0, 1] that describes the probability (over any randomization in the auction) that bidder i\nwins the item when bidders’ valuations (and hence bids) are ⃗v. Similarly, pi(⃗v) ∈R+ denotes the expected\npayment made by bidder i when bidders’ valuations are ⃗v.\nBefore describing the linear program, we need some odd but useful notation (which is standard in game\ntheory and microeconomics).\nSome Notation\nFor an n-vector ⃗z and a coordinate i ∈[n], let ⃗z−i denote the (n −1)-vector obtained by removing the\nith component from ⃗z. We also identify (zi,⃗z−i) with ⃗z.\nAlso, recall that Vi denotes the possible valuations of bidder i, and that we assume that this set is ﬁnite.\nOur linear program will have three sets of constraints. The ﬁrst set enforces the property that truthful\nbidding is in fact a Bayes-Nash equilibrium (as required for a BIC mechanism). For every bidder i, possible\nvaluation vi ∈Vi for i, and possible false bid v′\ni ∈Vi,\nvi · E⃗v−i∼⃗F−i\n\u0002xi(⃗v)\u0003 −E⃗v−i∼⃗F−i\n\u0002pi(⃗v)\u0003\n|                                              {z                                              }\nexpected utility of truthful bid vi\n≥vi · E⃗v−i∼⃗F−i\nf\nxi(v′\ni,⃗v−i)\ng\n−E⃗v−i∼⃗F−i\nf\npi(v′\ni,⃗v−i)\ng\n|                                                           {z                                                           }\nexpected utility of false bid v′\ni\n.\n(4.1)\nThe expectation is over both the randomness in ⃗v−i and internal to the auction. Each of the expectations\nin (4.1) expands to a sum over all possible ⃗v−i ∈⃗V−i, weighted by the probability Q\nj,i f j(vj). Since all of\nthe f j(vj)’s are numbers known in advance, each of these constraints is linear (in the xi(⃗v)’s and pi(⃗v)’s).\nThe second set of constraints encode the participation constraints from Section 4.1.1, also known as the\ninterim individually rational (IIR) constraints. For every bidder i and possible valuation vi ∈Vi,\nvi · E⃗v−i∼⃗F−i\n\u0002xi(⃗v)\u0003 −E⃗v−i∼⃗F−i\n\u0002pi(⃗v)\u0003 ≥0.\n(4.2)\nThe ﬁnal set of constraints assert that, with probability 1, the item is sold to at most one bidder: for every\n⃗v ∈⃗V,\nn\nX\ni=1\nxi(⃗v) ≤1.\n(4.3)\nBy construction, feasible solutions to the linear system (4.1)–(4.3) correspond to the allocation and\npayment rules of BIC auctions with respect to the distributions F1, . . ., Fn. This linear program has an\nexponential number of variables and constraints, and is not immediately useful.\n90\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 151
  },
  {
    "chunk_full": "4.2.3\nReducing the Dimension with Interim Allocation Rules\nIs it possible to re-express the allocation and payment rules of BIC auctions with a small number of decision\nvariables?\nLooking at the constraints (4.1) and (4.2), a natural idea is use only the decision variables\n{yi(vi)}i∈[n],vi ∈Vi and {qi(vi)}i∈[n],vi ∈Vi, with the intended semantics that\nyi(vi) = E⃗v−i\n\u0002xi(vi,⃗v−i)\u0003\nand\nqi(vi) = E⃗v−i\n\u0002pi(vi,⃗v−i)\u0003 .\nIn other words, yi(vi) is the probability that bidder i wins when it bids vi, and qi(vi) is the expected amount\nthat it pays; these were the only quantities that actually mattered in (4.1) and (4.2). (As usual, the expectation\nis over both the randomness in ⃗v−i and internal to the auction.) In auction theory, the yi(vi)’s are called an\ninterim allocation rule, the qi(vi)’s an interim payment rule.9\nThere are only 2 Pn\ni=1 |Vi| such decision variables, far fewer than the 2 Qn\ni=1 |Vi| variables in (4.1)–(4.3).\nWe’ll think of the |Vi|’s (and hence the number of decision variables) as polynomially bounded. For example,\nVi could be the multiples of some small ϵ that lie in some bounded range like [0, 1].\nWe can then express the BIC constraints (4.1) in terms of this smaller set of variables by\nvi · yi(vi) −qi(vi)\n|                 {z                 }\nexpected utility of truthful bid vi\n≥\nvi · yi(v′\ni) −qi(v′\ni)\n|                 {z                 }\nexpected utility of false bid v′\ni\n(4.4)\nfor every bidder i and vi, v′\ni ∈Vi. Similarly, the IIR constraints (4.2) become\nvi · yi(vi) −qi(vi) ≥0\n(4.5)\nfor every bidder i and vi ∈Vi.\nJust one problem. What about the feasibility constraints (4.3), which reference the individual xi(⃗v)’s and\nnot just their expectations? The next deﬁnition articulates what feasibility means for an interim allocation\nrule.\nDeﬁnition 4.1 (Feasible Interim Allocation Rule). An interim allocation rule {yi(vi)}i∈[n],vi ∈Vi is feasible\nif there exist nonnegative values for {xi(⃗v)}i∈[n],⃗v∈⃗V such that\nn\nX\ni=1\nxi(⃗v) ≤1\nfor every ⃗v (i.e., the xi(⃗v)’s constitute a feasible allocation rule), and\nyi(vi) =\nX\n⃗v−i ∈⃗V−i\n*.\n,\nY\nj,i\nf j(vj)+/\n-\n· xi(vi,⃗v−i)\nfor every i ∈[n] and vi ∈Vi (i.e., the intended semantics are respected).\nIn other words, the feasible interim allocation rules are exactly the projections (onto the yi(vi)’s) of the\nfeasible (ex post) allocation rules.\nThe big question is: how can we translate interim feasibility into our new, more economical vocabulary?10\nAs we’ll see, Border’s theorem [16] provides a crisp and computationally useful solution.\n9Auction theory generally thinks about three informational scenarios: ex ante, where each bidder knows the prior distributions\nbut not even its own valuation; ex interim, where each bidder knows its own valuation but not those of the others; and ex post, where\nall of the bidders know everybody’s valuation. Bidders typically choose their bids at the interim stage.\n10In principle, we know this is possible. The feasible (ex post) allocation rules form a polytope, the projection of a polytope is\nagain a polytope, and every polytope can be described by a ﬁnite number of linear inequalities. So the real question is whether or\nnot there’s a computationally useful description of interim feasibility.\n91\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 152
  },
  {
    "chunk_full": "(v1, v2)\nx1(v1, v2)\nx2(v1, v2)\n(1, 1)\n(1, 2)\n(2, 1)\n(2, 2)\nTable 4.1: Certifying feasibility of an interim allocation rule is analogous to ﬁlling in the table entries while\nrespecting constraints on the sums of certain subsets of entries.\n4.2.4\nExamples\nTo get a better feel for the issue of checking the feasibility of an interim allocation rule, let’s consider a\ncouple of examples. A necessary condition for interim feasibility is that the item is awarded to at most one\nbidder in expectation (over the randomness in the valuations and internal to the auction):\nn\nX\ni=1\nX\nvi ∈Vi\nfi(vi)yi(vi)\n|                {z                }\nPr[i wins]\n≤1.\n(4.6)\nCould this also be a suﬃcient condition? That is, is every interim allocation rule {yi(vi)}i∈[n],vi ∈Vi that\nsatisﬁes (4.6) induced by a bone ﬁde (ex post) allocation rule?\nExample 4.2. Suppose there are n = 2 bidders. Assume that v1, v2 are independent and each is equally likely\nto be 1 or 2. Consider the interim allocation rule given by\ny1(1) = 1\n2, y1(2) = 7\n8, y2(1) = 1\n8, and y2(2) = 1\n2.\n(4.7)\nSince fi(v) = 1\n2 for all i = 1, 2 and v = 1, 2, the necessary condition in (4.6) is satisﬁed. Can you ﬁnd an (ex\npost) allocation rule that induces this interim rule? Answering this question is much like solving a Sudoko\nor KenKen puzzle—the goal is to ﬁll in the table entries in Table 4.1 so that each row sums to at most 1 (for\nfeasibility) and that the constraints (4.7) are satisﬁed. For example, the average of the top two entries in the\nﬁrst column of Table 4.1 should be y1(1) = 1\n2. In this example, there are a number of such solutions; one is\nshown in Table 4.2. Thus, the given interim allocation rule is feasible.\nExample 4.3. Suppose we change the interim allocation rule to\ny1(1) = 1\n4, y1(2) = 7\n8, y2(1) = 1\n8, and y2(2) = 3\n4.\nThe necessary condition (4.6) remains satisﬁed. Now, however, the interim rule is not feasible. One way to\nsee this is to note that y1(2) = 7\n8 implies that x1(2, 2) ≥3\n4 and hence x2(2, 2) ≤1\n4. Similarly, y2(2) = 3\n4\nimplies that x2(2, 2) ≥1\n2, a contradictory constraint.\n(v1, v2)\nx1(v1, v2)\nx2(v1, v2)\n(1, 1)\n1\n0\n(1, 2)\n0\n1\n(2, 1)\n3/4\n1/4\n(2, 2)\n1\n0\nTable 4.2: One solution to Example 4.2.\n92\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 153
  },
  {
    "chunk_full": "The ﬁrst point of Examples 4.2 and 4.3 is that it is not trivial to check whether or not a given interim\nallocation rule is feasible—the problem corresponds to solving a big linear system of equations and in-\nequalities. The second point is that (4.6) is not a suﬃcient condition for feasibility. In hindsight, trying to\nsummarize the exponentially many ex post feasibility constraints (4.3) with a single interim constraint (4.6)\nseems naive. Is there a larger set of linear constraints—possibly an exponential number—that characterizes\ninterim feasibility?\n4.2.5\nBorder’s Theorem\nBorder’s theorem states that a collection of “obvious” necessary conditions for interim feasibility are also\nsuﬃcient. To state these conditions, assume for notational convenience that the valuation sets V1, . . ., Vn\nare disjoint.11 Let {xi(⃗v)}i∈[n],⃗v∈⃗V be a feasible (ex post) allocation rule and {yi(vi)}i∈[n],vi ∈Vi the induced\n(feasible) interim allocation rule. Fix for each bidder i a set Si ⊆Vi of valuations. Call the valuations ∪n\ni=1Si\nthe distinguished valuations. Consider ﬁrst the probability, over the random valuation proﬁle ⃗v ∼⃗F and any\ncoin ﬂips of the ex post allocation rule, that the winner of the auction (if any) has a distinguished valuation.\nBy linearity of expectations, this probability can be expressed in terms of the interim allocation rule:\nn\nX\ni=1\nX\nvi ∈Si\nfi(vi)yi(vi).\n(4.8)\nThe expression (4.8) is linear in the yi(vi)’s.\nThe second quantity we study is the probability, over ⃗v ∼⃗F, that there is a bidder with a distinguished\nvaluation. This has nothing to do with the allocation rule, and is a function of the prior distributions only:\n1 −\nn\nY\ni=1\n*.\n,\n1 −\nX\nvi ∈Si\nfi(vi)+/\n-\n.\n(4.9)\nSince there can only be a winner with a distinguished valuation if there is a bidder with a distinguished\nvaluation, the quantity in (4.8) can only be less than (4.9). Border’s theorem asserts that these conditions,\nranging over all choices of S1 ⊆V1, . . ., Sn ⊆Vn, are also suﬃcient for the feasibility of an interim allocation\nrule.\nTheorem 4.4 (Border’s theorem [16]). An interim allocation rule {yi(vi)}i∈[n],vi ∈Vi is feasible if and only if\nfor every choice S1 ⊆V1, . . ., Sn ⊆Vn of distinguished valuations,\nn\nX\ni=1\nX\nvi ∈Si\nfi(vi)yi(vi) ≤1 −\nn\nY\ni=1\n*.\n,\n1 −\nX\nvi ∈Si\nfi(vi)+/\n-\n.\n(4.10)\nBorder’s theorem can be derived from the max-ﬂow/min-cut theorem (following [17, 28]); we include\nthe proof in Section 4.4 for completeness.\n11This is without loss of generality, since we can simply “tag” each valuation vi ∈Vi with the “name” i (i.e., view each vi ∈Vi\nas the set {vi, i}).\n93\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 154
  },
  {
    "chunk_full": "Border’s theorem yields an explicit description as a linear system of the feasible interim allocation rules\ninduced by BIC single-item auctions. To review, this linear system is\nvi · yi(vi) −qi(vi) ≥vi · yi(v′\ni) −qi(v′\ni)\n∀i and vi, v′\ni ∈Vi\n(4.11)\nvi · yi(vi) −qi(vi) ≥0\n∀i and vi ∈Vi\n(4.12)\nn\nX\ni=1\nX\nvi ∈Si\nfi(vi)yi(vi) ≤1 −\nn\nY\ni=1\n*.\n,\n1 −\nX\nvi ∈Si\nfi(vi)+/\n-\n∀S1 ⊆V1, . . ., Sn ⊆Vn.\n(4.13)\nFor example, optimizing the objective function\nmax\nn\nX\ni=1\nfi(vi) · qi(vi)\n(4.14)\nover the linear system (4.11)–(4.13) computes the expected revenue of an optimal BIC single-item auction\nfor the distributions F1, . . ., Fn.\nThe linear system (4.11)–(4.13) has only a polynomial number of variables (assuming the |Vi|’s are\npolynomially bounded), but it does have an exponential number of constraints of the form (4.13). One\nsolution is to use the ellipsoid method, as the linear system does admit a polynomial-time separation\noracle [3, 21].12\nAlternatively, Alaei et al. [3] provide a polynomial-size extended formulation of the\npolytope of feasible interim allocation rules (with a polynomial number of additional decision variables and\nonly polynomially many constraints). In any case, we conclude that there is a computationally tractable\ndescription of the feasible interim allocation rules of BIC single-item auctions.\n4.3\nBeyond Single-Item Auctions: A Complexity-Theoretic Barrier\nMyerson’s theory of optimal auctions (Section 4.1.2) extends beyond single-item auctions to all “single-\nparameter” settings (see Section 4.3.1 for two examples). Can Border’s theorem be likewise extended? There\nare analogs of Border’s theorem in settings modestly more general than single-item auctions, including k-unit\nauctions with unit-demand bidders [3, 21, 28], and approximate versions of Border’s theorem exist fairly\ngenerally [21, 22]. Can this state-of-the-art be improved upon? We next use complexity theory to develop\nevidence for a negative answer.\nTheorem 4.5 (Gopalan et al. [68]). (Informal) There is no exact Border’s-type theorem for settings signiﬁ-\ncantly more general than the known special cases (unless PH collapses).\nWe proceed to deﬁning what we mean by “signiﬁcantly more general” and a “Border’s-type theorem.”\n4.3.1\nTwo Example Settings\nThe formal version of Theorem 4.5 conditionally rules out “Border’s-type theorems” for several speciﬁc\nsettings that are representative of what a more general version of Border’s theorem might cover. We mention\ntwo of these here (more are in [68]).\nIn a public project problem, there is a binary decision to make: whether or not to undertake a costly\nproject (like building a new school). Each bidder i has a private valuation vi for the outcome where the project\n12This is not immediately obvious, as the max-ﬂow/min-cut argument in Section 4.4 involves an exponential-size graph.\n94\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 155
  },
  {
    "chunk_full": "is built, and valuation 0 for the outcome where it is not. If the project is built, then everyone can use it. In this\nsetting, feasibility means that all bidders receive the same allocation: x1(⃗v) = x2(⃗v) = · · · = xn(⃗v) ∈[0, 1]\nfor every valuation proﬁle ⃗v.\nIn a matching problem, there is a set M of items, and each bidder is only interested in receiving a speciﬁc\npair j, ℓ∈M of items. (Cf., the AND bidders of the preceding lecture.) For each bidder, the corresponding\npair of items is known in advance, and the bidder’s valuation for the pair is private as usual. Feasible\noutcomes correspond to (distributions over) matchings in the graph with vertices M and edges given by\nbidders’ desired pairs.\nPublic project and matching problems are both “single-parameter” problems (i.e., each bidder has only\none private parameter). As such, Myerson’s optimal auction theory (Section 4.1.2) can be used to characterize\nthe expected revenue-maximizing auction. Do these settings also admit analogs of Border’s theorem?\n4.3.2\nBorder’s-Type Theorems\nWhat do we actually mean by a “Border’s-type theorem?” Since we aim to prove impossibility results,\nwe should adopt a deﬁnition that is as permissive as possible. Border’s theorem (Theorem 4.4) gives a\ncharacterization of the feasible interim allocation rules of a single-item auction as the solutions to a ﬁnite\nsystem of linear inequalities. This by itself is not impressive—since the set is a polytope, it is guaranteed\nto have such a characterization. The appeal of Border’s theorem is that the characterization uses only the\n“nice” linear inequalities in (4.10). Our “niceness” requirement is that the characterization use only linear\ninequalities that can be eﬃciently recognized and tested. This is a weak necessary condition for such a\ncharacterization to be computationally useful.\nDeﬁnition 4.6 (Border’s-Type Theorem). A Border’s-type theorem holds for an auction design setting if, for\nevery instance of the setting (specifying the number of bidders and their prior distributions, etc.), there is a\nsystem of linear inequalities such that the following properties hold.\n1. (Characterization) The feasible solutions of the linear system are precisely the feasible interim alloca-\ntion rules of the instance.\n2. (Eﬃcient recognition) There is a polynomial-time algorithm that can decide whether or not a given\nlinear inequality belongs to the linear system.\n3. (Eﬃcient testing) The bit complexity of each linear inequality is polynomial in the description of the\ninstance. (The number of inequalities can be exponential.)\nFor example, consider the original Border’s theorem, for single-item auctions (Theorem 4.4).\nThe\nrecognition problem is straightforward: the left-side of (4.10) encodes the Si’s, from which the right-hand\nside can be computed and checked in polynomial time. It is also evident that every inequality in (4.10) has a\npolynomial-length description.13\n4.3.3\nConsequences of a Border’s-Type Theorem\nThe high-level idea behind the proof of Theorem 4.5 is to show that a Border’s-type theorem puts a certain\ncomputational problem low in the polynomial hierarchy, and then to show that this problem is #P-hard for\n13The characterization in Theorem 4.4 and the extensions in [3, 21, 28] have additional features not required or implied by\nDeﬁnition 4.6, such as polynomial-time separation oracles (and even a compact extended formulation in the single-item case [3]).\nThe impossibility results in Section 4.3.4 rule out analogs of Border’s theorem that merely satisfy Deﬁnition 4.6, let alone these\nstronger properties.\n95\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 156
  },
  {
    "chunk_full": "the public project and matching settings deﬁned in Section 4.3.1.14 The computational problem is: given\na description of an instance (including the prior distributions), compute the maximum-possible expected\nrevenue that can be obtained by a feasible and BIC auction.15\nWhat use is a Border’s-type theorem? For starters, it implies that the problem of testing the feasibility\nof an interim allocation rule is in co-NP. To prove the infeasibility of such a rule, one simply exhibits an\ninequality of the characterizing linear system that the rule fails to satisfy. Verifying this failure reduces to\nthe recognition and testing problems, which by Deﬁnition 4.6 are polynomial-time solvable.\nProposition 4.7. If a Border’s-type theorem holds for an auction design setting, then the membership problem\nfor the polytope of feasible interim allocation rules belongs to co-NP.\nCombining Proposition 4.7 with the ellipsoid method puts the problem of computing the maximum-\npossible expected revenue in PNP.\nTheorem 4.8. If a Border’s-type theorem holds for an auction design setting, then the maximum expected\nrevenue of a feasible BIC auction can be computed in PNP.\nProof. We compute the optimal expected revenue of a BIC auction via linear programming, as follows.\nThe decision variables are the same yi(vi)’s and qi(vi)’s as in (4.11)–(4.13), and we retain the BIC con-\nstraints (4.11) and the IIR constraints (4.12). By assumption, we can replace the single-item interim feasibility\nconstraints (4.13) with a linear system that satisﬁes the properties of Deﬁnition 4.6. The maximum expected\nrevenue of a feasible BIC auction can then be computed by optimizing a linear objective function (in the\nqi(vi)’s, as in (4.14)) subject to these constraints. Using the ellipsoid method [88], this can be accomplished\nwith a polynomial number of invocations of a separation oracle (which either veriﬁes feasibility or exhibits\na violated constraint). Proposition 4.7 implies that we can implement this separation oracle in co-NP, and\nthus compute the maximum expected revenue of a BIC auction in PNP.16\n□\n4.3.4\nImpossibility Results from Computational Intractability\nTheorem 4.8 concerns the problem of computing the maximum expected revenue of a feasible BIC auction,\ngiven a description of an instance. It is easy to classify the complexity of this problem in the public project\nand matching settings introduced in Section 4.3.1 (and several other settings, see [68]).\nProposition 4.9. Computing the maximum expected revenue of a feasible BIC auction of a public project\ninstance is a #P-hard problem.\nProposition 4.9 is a straightforward reduction from the #P-hard problem of computing the number of\nfeasible solutions to an instance of the Knapsack problem.17\nProposition 4.10. Computing the maximum expected revenue of a feasible BIC auction of a matching\ninstance is a #P-hard problem.\n14Recall that Toda’s theorem [144] implies that a #P-hard problem is contained in the polynomial hierarchy only if PH collapses.\n15Sanity check: this problem turns out to be polynomial-time solvable in the setting of single-item auctions [68].\n16One detail: Proposition 4.7 only promises solutions to the “yes/no” question of feasibility, while a separation oracle needs to\nproduce a violated constraint when given an infeasible point. But under mild conditions (easily satisﬁed here), an algorithm for the\nformer problem can be used to solve the latter problem as well [137, P.189].\n17An aside for aﬁcionados of the analysis of Boolean functions: Proposition 4.9 is essentially equivalent to the #P-hardness of\nchecking whether or not given Chow parameters can be realized by some bounded function on the hypercube. See [68] for more\ndetails on the surprisingly strong correspondence between Myerson’s optimal auction theory (in the context of public projects) and\nthe analysis of Boolean functions.\n96\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 157
  },
  {
    "chunk_full": "s\nt\nv1\nv2\nvn\n1, v1\n2, v2\nn, vn\nno sale\nX\nY\nf(v1)\nf(v2)\nf(vn)\ny1(v1) · f1(v1)\ny1(v2) · f1(v2)\nyn(vn) · fn(vn)\nresidual probability\n(a)\ns\nt\nA\nB\n¯A\n¯B\n(b)\nFigure 4.1: The max-ﬂow/min-cut proof of Border’s theorem.\nProposition 4.10 is a straightforward reduction from the #P-hard Permanent problem.\nWe reiterate that Myerson’s optimal auction theory applies to the public project and matching settings,\nand in particular gives a polynomial-time algorithm that outputs a description of an optimal auction (for given\nprior distributions). Moreover, the optimal auction can be implemented as a polynomial-time algorithm.\nThus it’s not hard to ﬁgure out what the optimal auction is, nor to implement it—what’s hard is ﬁguring out\nexactly how much revenue it makes on average!\nCombining Theorem 4.8 with Propositions 4.9 and 4.10 gives the following corollaries, which indicate\nthat there is no Border’s-type theorem signiﬁcantly more general than the ones already known.\nCorollary 4.11. If #P ⊈PH, then there is no Border’s-type theorem for the setting of public projects.\nCorollary 4.12. If #P ⊈PH, then there is no Border’s-type theorem for the matching setting.\n4.4\nAppendix: A Combinatorial Proof of Border’s Theorem\nProof. (of Theorem 4.4) We have already argued the “only if” direction, and now prove the converse. The\nproof is by the max-ﬂow/min-cut theorem—given the statement of the theorem and this hint, the proof writes\nitself.\nSuppose the interim allocation rule {yi(vi)}i∈[n],vi ∈Vi satisﬁes (4.10) for every S1 ⊆V1, . . ., Sn ⊆Vn.\nForm a four-layer s-t directed ﬂow network G as follows (Figure 4.1(a)). The ﬁrst layer is the source s, the\nlast the sink t. In the second layer X, vertices correspond to valuation proﬁles ⃗v. We abuse notation and\nrefer to vertices of X by the corresponding valuation proﬁles. There is an arc (s,⃗v) for every ⃗v ∈X, with\ncapacity Qn\ni=1 fi(vi). Note that the total capacity of these edges is 1.\nIn the third layerY, vertices correspond to winner-valuation pairs; there is also one additional “no winner”\nvertex. We use (i, vi) to denote the vertex representing the event that bidder i wins the item and also has\nvaluation vi. For each i and vi ∈Vi, there is an arc ((i, vi), t) with capacity fi(vi)yi(vi). There is also an arc\nfrom the “no winner” vertex to t, with capacity 1 −Pn\ni=1\nP\nvi ∈Vi fi(vi)yi(vi).18\n18If Pn\ni=1\nP\nvi ∈Vi fi (vi)yi (vi) > 1, then the interim allocation rule is clearly infeasible (recall (4.6)). Alternatively, this would\nviolate Border’s condition for the choice Si = Vi for all i.\n97\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 158
  },
  {
    "chunk_full": "Finally, each vertex ⃗v ∈X has n+1 outgoing arcs, all with inﬁnite capacity, to the vertices (1, v1), (2, v2),\n. . ., (n, vn) of Y and also to the “no winner” vertex.\nBy construction, s-t ﬂows of G with value 1 correspond to ex post allocation rules with induced\ninterim allocation rule {yi(vi)}i∈[n],vi ∈Vi, with xi(⃗v) equal to the amount of ﬂow on the arc (⃗v, (i, vi)) times\n(Qn\ni=1 fi(vi))−1.\nTo show that there exists a ﬂow with value 1, it suﬃces to show that every s-t cut has value at least 1 (by\nthe max-ﬂow/min-cut theorem). So ﬁx an s-t cut. Let this cut include the vertices A from X and B from Y.\nNote that all arcs from s to X \\ A and from B to t are cut (Figure 4.1(b)). For each bidder i, deﬁne Si ⊆Vi\nas the possible valuations of i that are not represented among the valuation proﬁles in A. Then, for every\nvaluation proﬁle ⃗v containing at least one distinguished valuation, the arc (s,⃗v) is cut. The total capacity of\nthese arcs is the right-hand side (4.9) of Border’s condition.\nNext, we can assume that every vertex of the form (i, vi) with vi < Si is in B, since otherwise an\n(inﬁnite-capacity) arc from A to Y \\ B is cut. Similarly, unless A = ∅—in which case the cut has value at\nleast 1 and we’re done—we can assume that the “no winner” vertex lies in B. Thus, the only edges of the\nform ((i, vi), t) that are not cut involve a distinguished valuation vi ∈Si. It follows that the total capacity\nof the cut edges incident to t is at least 1 minus the left-hand size (4.8) of Border’s condition. Given our\nassumption that (4.8) is at most (4.9), this s-t cut has value at least 1. This completes the proof of Border’s\ntheorem.\n□\n98\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 159
  },
  {
    "chunk_full": "Lunar Lecture 5\nTractable Relaxations of Nash Equilibria\nLecturer: Tim Roughgarden\nScribe: Jacobo Torán\n5.1\nPreamble\nWe’ve spent much of this week proving several types of impossibility results for the eﬃcient computation of\nexact and approximate Nash equilibria. How should we respond to such rampant computational intractability?\nWhat should be the message to economists—should they change the way they do economic analysis in some\nway?1\nOne approach, familiar from coping with NP-hard problems, is to look for tractable special cases. For\nexample, Solar Lecture 1 proved tractability results for two-player zero-sum games. Some interesting tractable\ngeneralizations of zero-sum games have been identiﬁed (see [23] for a recent example), and polynomial-time\nalgorithms are also known for some relatively narrow classes of games (see e.g. [85]). Still, for the lion’s\nshare of games that we might care about, no polynomial-time algorithms for computing exact or approximate\nNash equilibria are known.\nA diﬀerent approach, which has been more fruitful, is to continue to work with general games and look for\nan equilibrium concept that is more computationally tractable than exact or approximate Nash equilibria. The\nequilibrium concepts that we’ll consider—the correlated equilibrium and the coarse correlated equilibrium—\nwere originally invented by game theorists, but computational complexity considerations are now shining a\nmuch brighter spotlight on them.\nWhere do these alternative equilibrium concepts come from? They arise quite naturally from the study\nof uncoupled dynamics, which we last saw in Solar Lecture 1.\n5.2\nUncoupled Dynamics Revisited\nSection 1.3 of Solar Lecture 1 introduced uncoupled dynamics in the context of two-player games. In this\nlecture we work with the analogous setup for a general number k of players. We use Si to denote the (pure)\nstrategies of player i, si ∈Si a speciﬁc strategy, σi a mixed strategy, ⃗s and ⃗σ for proﬁles (i.e., k-vectors) of\npure and mixed strategies, and ui(⃗s) for player i’s payoﬀin the outcome ⃗s.\n1Recall the discussion in Section 1.2.7 of Solar Lecture 1: a critique of a widely used concept like the Nash equilibrium is not\nparticularly helpful unless accompanied by a proposed alternative.\n99\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 160
  },
  {
    "chunk_full": "Uncoupled Dynamics (k-Player Version)\nAt each time step t = 1, 2, 3, . . .:\n1. Each player i = 1, 2, . . ., k simultaneously chooses a mixed strategy σt\ni over Si as a function\nonly of her own payoﬀs and the strategies chosen by players in the ﬁrst t −1 time steps.\n2. Every player learns all of the strategies ⃗σt chosen at time t.\n“Uncoupled” refers to the fact that each player initially knows only her own payoﬀfunction ui(·), while\n“dynamics” means a process by which players learn how to play in a game.\nOne of the only positive algorithmic results that we’ve seen this week concerned smooth ﬁctitious play\n(SFP). The k-player version of SFP is as follows.\nSmooth Fictitious Play (k-Player Version)\nGiven: parameter family {ηt ∈[0, ∞) : t = 1, 2, 3, . . .}.\nAt each time step t = 1, 2, 3, . . .:\n1. Every player i simultaneously chooses the mixed strategy σt\ni by playing each strategy si with\nprobability proportional to eηt πt\ni , where πt\ni is the time-averaged expected payoﬀplayer i would\nhave earned by playing si at every previous time step. Equivalently, πt\ni is the expected pay-\noﬀof strategy si when the other players’ strategies ⃗s−i are drawn from the joint distribution\n1\nt−1\nPt−1\nh=1 ⃗σh\n−i.2\n2. Every player learns all of the strategies ⃗σt chosen at time t.\nA typical choice for the ηt’s is ηt ≈√t.\nIn Theorem 1.8 in Solar Lecture 1 we proved that, in an m × n two-player zero-sum game, after\nO(log(m + n)/ϵ2) time steps, the empirical distributions of the two players constitute an ϵ-approximate\nNash equilibrium.3 An obvious question is: what is the outcome of a logarithmic number of rounds of\nsmooth ﬁctitious play in a non-zero-sum game? Our communication complexity lower bound in Solar\nLectures 2 and 3 implies that it cannot in general be an ϵ-approximate Nash equilibrium. Does it have some\nalternative economic meaning? The answer to this question turns out to be closely related to some classical\ngame-theoretic equilibrium concepts, which we discuss next.\n2Recall from last lecture that for an n-vector ⃗z and a coordinate i ∈[k], ⃗z−i denotes the (k −1)-vector obtained by removing\nthe ith component from ⃗z, and we identify (zi,⃗z−i) with ⃗z.\n3Recall the proof idea: smooth ﬁctitious play corresponds to running the vanishing-regret “multiplicative weights” algorithm\n(with reward vectors induced by the play of others), and in a two-player zero-sum game, the vanishing-regret guarantee (i.e., with\ntime-averaged payoﬀat least that of the best ﬁxed action in hindsight, up to o(1) error) implies the ϵ-approximate Nash equilibrium\ncondition.\n100\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 161
  },
  {
    "chunk_full": "5.3\nCorrelated and Coarse Correlated Equilibria\n5.3.1\nCorrelated Equilibria\nThe correlated equilibrium is a well-known equilibrium concept deﬁned by Aumann [7]. We deﬁne it, then\nexplain the standard semantics, and then oﬀer an example.4\nDeﬁnition 5.1 (Correlated Equilibrium). A joint distribution ρ on the set S1 × · · · × Sk of outcomes of a\ngame is a correlated equilibrium if for every player i ∈{1, 2, . . ., k}, strategy si ∈Si, and deviation s′\ni ∈Si,\nE⃗s∼ρ\n\u0002ui(⃗s) | si\n\u0003 ≥E⃗s∼ρ\nf\nui(s′\ni,⃗s−i) | si\ng\n.\n(5.1)\nImportantly, the distribution ρ in Deﬁnition 5.1 need not be a product distribution; in this sense, the\nstrategies chosen by the players are correlated. The Nash equilibria of a game correspond to the correlated\nequilibria that are product distributions.\nThe usual interpretation of a correlated equilibrium involves a trusted third party. The distribution ρ\nover outcomes is publicly known. The trusted third party samples an outcome ⃗s according to ρ. For each\nplayer i = 1, 2, . . ., k, the trusted third party privately suggests the strategy si to i. The player i can follow the\nsuggestion si, or not. At the time of decision making, a player i knows the distribution ρ and one component\nsi of the realization ⃗s, and accordingly has a posterior distribution on others’ suggested strategies ⃗s−i. With\nthese semantics, the correlated equilibrium condition (5.1) requires that every player minimizes her expected\ncost by playing the suggested strategy si. The expectation is conditioned on i’s information—ρ and si—and\nassumes that other players play their recommended strategies ⃗s−i.\nDeﬁnition 5.1 is a bit of a mouthful. But you are intimately familiar with a good example of a correlated\nequilibrium that is not a mixed Nash equilibrium—a traﬃc light! Consider the following two-player game,\nwith each matrix entry listing the payoﬀs of the row and column players in the corresponding outcome:\nStop\nGo\nStop\n0,0\n0,1\nGo\n1,0\n-5,-5\nThis game has two pure Nash equilibria, the outcomes (Stop, Go) and (Go, Stop). Deﬁne ρ by randomizing\nuniformly between these two Nash equilibria. This is not a product distribution over the game’s four outcomes,\nso it cannot correspond to a Nash equilibrium of the game. It is, however, a correlated equilibrium.5\n5.3.2\nCoarse Correlated Equilibria\nThe outcome of smooth ﬁctitious play in non-zero-sum games relates to a still more permissive equilibrium\nconcept, the coarse correlated equilibrium, which was ﬁrst studied by Moulin and Vial [110].\nDeﬁnition 5.2 (Coarse Correlated Equilibrium). A joint distribution ρ on the set S1 × · · · × Sk of outcomes\nof a game is a coarse correlated equilibrium if for every player i ∈{1, 2, . . ., k} and every unilateral deviation\ns′\ni ∈Si,\nE⃗s∼ρ\n\u0002ui(⃗s)\u0003 ≥E⃗s∼ρ\nf\nui(s′\ni,⃗s−i)\ng\n.\n(5.2)\n4This section draws from [129, Lecture 13].\n5For example, consider the row player. If the trusted third party (i.e., the traﬃc light) recommends the strategy “Go” (i.e., is\ngreen), then the row player knows that the column player was recommended “Stop” (i.e., has a red light). Assuming the column\nplayer plays her recommended strategy and stops at the red light, the best strategy for the row player is to follow her recommendation\nand to go.\n101\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 162
  },
  {
    "chunk_full": "NE\nCE\nCCE\nFigure 5.1: The relationship between Nash equilibria (NE), correlated equilibria (CE), and coarse correlated\nequilibria (CCE). Enlarging the set of equilibria increases computational tractability but decreases predictive\npower.\nThe condition (5.2) is the same as that for the Nash equilibrium (Deﬁnition 1.3), except without the\nrestriction that ρ is a product distribution. In this condition, when a player i contemplates a deviation s′\ni,\nshe knows only the distribution ρ and not the component si of the realization. That is, a coarse correlated\nequilibrium only protects against unconditional unilateral deviations, as opposed to the unilateral deviations\nconditioned on si that are addressed in Deﬁnition 5.1. It follows that every correlated equilibrium is also a\ncoarse correlated equilibrium (Figure 5.1).\nAs you would expect, ϵ-approximate correlated and coarse correlated equilibria are deﬁned by adding\na “−ϵ” to the right-hand sides of (5.1) and (5.2), respectively. We can now answer the question about\nsmooth ﬁctitious play in general games: the time-averaged history of joint play under smooth ﬁctitious play\nconverges to the set of coarse correlated equilibria.\nProposition 5.3. For every k-player game in which every player has at most m strategies, after T =\nO((log m)/ϵ2) time steps of smooth ﬁctitious play, the time-averaged history of play 1\nT\nPT\nt=1 ⃗σt is an ϵ-\napproximate coarse correlated equilibrium.\nProposition 5.3 follows straightforwardly from the deﬁnition of ϵ-approximate coarse correlated equilibria\nand the vanishing regret guarantee of smooth ﬁctitious play that we proved in Solar Lecture 1. Precisely, by\nCorollary 1.11 of that lecture, after O((log m)/ϵ2) time steps of smooth ﬁctitious play, every player has at\nmost ϵ regret (with respect to the best ﬁxed strategy in hindsight, see Deﬁnition 1.9 in Solar Lecture 1). This\nregret guarantee is equivalent to the conclusion of Proposition 5.3 (as you should check).\nWhat about correlated equilibria? While the time-averaged history of play in smooth ﬁctitious play does\nnot in general converge to the set of correlated equilibria, Foster and Vohra [53] and Hart and Mas-Colell\n[71] show that the time-averaged play of other reasonably simple types of uncoupled dynamics is guaranteed\nto be an ϵ-correlated equilibrium after a polynomial (rather than logarithmic) number of time steps.\n5.4\nComputing an Exact Correlated or Coarse Correlated Equilibrium\n5.4.1\nNormal-Form Games\nSolar Lecture 1 showed that approximate Nash equilibria of two-player zero-sum games can be learned (and\nhence computed) eﬃciently (Theorem 1.8). Proposition 5.3 and the extensions in [53, 71] show analogs\nof this result for approximate correlated and coarse correlated equilibria of general games. Solar Lecture 1\nalso showed that an exact Nash equilibrium of a two-player zero-sum game can be computed in polynomial\n102\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 163
  },
  {
    "chunk_full": "time by linear programming (Corollary 1.5). Is the same true for an exact correlated or coarse correlated\nequilibrium of a general game?\nConsider ﬁrst the case of coarse correlated equilibria, and introduce one decision variable x⃗s per outcome\n⃗s of the game, representing the probability assigned to ⃗s in a joint distribution ρ. The feasible solutions to\nthe following linear system are then precisely the coarse correlated equilibria of the game:\nX\n⃗s\nui(⃗s)x⃗s ≥\nX\n⃗s\nui(s′\ni,⃗s−i)x⃗s\nfor every i ∈[k] and s′\ni ∈Si\n(5.3)\nX\n⃗s∈⃗S\nx⃗s = 1\n(5.4)\nx⃗s ≥0\nfor every ⃗s ∈⃗S.\n(5.5)\nSimilarly, correlated equilibria are captured by the following linear system:\nX\n⃗s : si=j\nui(⃗s)x⃗s ≥\nX\n⃗s : si=j\nui(s′\ni,⃗s−i)x⃗s\nfor every i ∈[k] and j, s′\ni ∈Si\n(5.6)\nX\n⃗s∈⃗S\nx⃗s = 1\n(5.7)\nx⃗s ≥0\nfor every ⃗s ∈⃗S.\n(5.8)\nThe following proposition is immediate.\nProposition 5.4 (Gilboa and Zemel [61]). An exact correlated or coarse correlated equilibrium of a game\ncan be computed in time polynomial in the number of outcomes of the game.\nMore generally, any linear function (such as the sum of players’ expected payoﬀs) can be optimized over\nthe set of correlated or coarse correlated equilibria in time polynomial in the number of outcomes.\nFor games described in normal form, with each player i’s payoﬀs {ui(⃗s)}⃗s∈⃗S given explicitly in the input,\nProposition 5.4 provides an algorithm with running time polynomial in the input size. However, the number\nof outcomes of a game scales exponentially with the number k of players.6 The computationally interesting\nmulti-player games, and the multi-player games that naturally arise in computer science applications, are\nthose with a succinct description. Can we compute an exact correlated or coarse correlated equilibrium in\ntime polynomial in the size of a game’s description?\n5.4.2\nSuccinctly Represented Games\nFor concreteness, let’s look at one concrete example of a class of succinctly represented games: graphical\ngames [86, 90]. A graphical game is described by an undirected graph G = (V, E), with players corresponding\nto vertices, and a local payoﬀmatrix for each vertex. The local payoﬀmatrix for vertex i speciﬁes i’s payoﬀ\nfor each possible choice of its strategy and the strategies chosen by its neighbors in G. By assumption, the\npayoﬀof a player is independent of the strategies chosen by non-neighboring players. When the graph G\nhas maximum degree ∆, the size of the game description is exponential in ∆but polynomial in the number k\nof players. The most interesting cases are when ∆= O(1) or perhaps ∆= O(log k). In these cases, the\n6This fact should provide newfound appreciation for the distributed learning algorithms that compute an approximate coarse\ncorrelated equilibrium (in Proposition 5.3) and an approximate correlated equilibrium (in [53, 71]), where the total amount of\ncomputation is only polynomial in k (and in m and 1\nϵ ).\n103\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 164
  },
  {
    "chunk_full": "number of outcomes (and hence the size of the game’s normal-form description) is exponential in the size of\nthe succinct description of the game, and solving the linear system (5.3)–(5.5) or (5.6)–(5.8) does not result\nin a polynomial-time algorithm.\nWe next state a result showing that, quite generally, an exact correlated (and hence coarse correlated)\nequilibrium of a succinctly represented game can be computed in polynomial time. The key assumption is\nthat the following Expected Utility problem can be solved in time polynomial in the size of the game’s\ndescription.7\nThe Expected Utility Problem\nGiven a succinct description of a player’s payoﬀfunction ui and mixed strategies σ1, . . ., σk for all of\nthe players, compute the player’s expected utility:\nE⃗s∼⃗σ\n\u0002ui(⃗s)\u0003 .\nFor most of the succinctly represented multi-player games that come up in computer science applications,\nthe Expected Utility problem can be solved in polynomial time. For example, in a graphical game it\ncan be solved by brute force—summing over the entries in player i’s local payoﬀmatrix, weighted by the\nprobabilities in the given mixed strategies. This algorithm takes time exponential in ∆but polynomial in k,\nand hence is polynomial in the size of the game’s succinct representation.\nTractability of solving the Expected Utility problem is a suﬃcient condition for the tractability of\ncomputing an exact correlated equilibrium.\nTheorem 5.5 (Papadimitriou and Roughgarden [119], Jiang and Leyton-Brown [79]). There is a polynomial-\ntime Turing reduction from the problem of computing a correlated equilibrium of a succinctly described game\nto the Expected Utility problem.\nTheorem 5.5 applies to a long list of succinctly described games that have been studied in the computer\nscience literature, with graphical games serving as one example.8\nThe starting point of the proof of Theorem 5.5 is the exponential-size linear system (5.6)–(5.8). We know\nthat this linear system is feasible (by Nash’s Theorem, since the system includes all Nash equilibria). With\nexponentially many variables, however, it’s not clear how to eﬃciently compute a feasible solution. The dual\nlinear system, meanwhile, has a polynomial number of variables (corresponding to the constraints in (5.6))\nand an exponential number of inequalities (corresponding to game outcomes). By Farkas’s Lemma—or,\nequivalently, strong linear programming duality (see e.g. [38])—we know that this dual linear system is\ninfeasible.\nThe key idea is to run the ellipsoid algorithm [88] on the infeasible dual linear system—called the\n“ellipsoid against hope” in [119]. A polynomial-time separation oracle must produce, given an alleged\nsolution (which we know is infeasible), a violated inequality. It turns out that this separation oracle reduces\nto solving a polynomial number of instances of the Expected Utility problem (which is polynomial-time\nsolvable by assumption) and computing the stationary distribution of a polynomial number of polynomial-\nsize Markov chains (also polynomial-time solvable, e.g. by linear programming). The ellipsoid against hope\nterminates after a polynomial number of invocations of its separation oracle, necessarily with a proof that\nthe dual linear system is infeasible. To recover a primal feasible solution (i.e., a correlated equilibrium), one\n7Some kind of assumption is necessary to preclude baking an NP-complete problem into the game’s description.\n8For the speciﬁc case of graphical games, Kakade et al. [82] were the ﬁrst to develop a polynomial-time algorithm for computing\nan exact correlated equilibrium.\n104\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 165
  },
  {
    "chunk_full": "can retain only the primal decision variables corresponding to the (polynomial number of) dual constraints\ngenerated by the separation oracle, and solve directly this polynomial-size reduced version of the primal\nlinear system.9\n5.5\nThe Price of Anarchy of Coarse Correlated Equilibria\n5.5.1\nBalancing Computational Tractability with Predictive Power\nWe now understand senses in which Nash equilibria are computationally intractable (Solar Lectures 2–\n5) while correlated equilibria are computationally tractable (Sections 5.3 and 5.4).\nFrom an economic\nperspective, these results suggest that it could be prudent to study the correlated equilibria of a game, rather\nthan just its Nash equilibria.10\nPassing from Nash equilibria to the larger set of correlated equilibria is a two-edged sword. Computational\ntractability increases, and with it the plausibility that actual game play will conform to the equilibrium notion.\nBut whatever criticisms we had about the Nash equilibrium’s predictive power (recall Section 1.2.7 in Solar\nLecture 1), they are even more severe for the correlated equilibrium (since there are only more of them). The\nworry is that games typically have far too many correlated equilibria to say anything interesting about them.\nOur ﬁnal order of business for the week is to dispel this worry, at least in the context of price-of-anarchy\nanalyses.\nRecall from Lunar Lecture 2 that the price of anarchy (POA) is deﬁned as the ratio between the objective\nfunction value of an optimal solution, and that of the worst equilibrium:\nPoA(G) :=\nf (OPT(G))\nminµ is an equilibrium of G f (µ),\nwhere G denotes a game, f denotes a maximization objective function (with f (µ) = E⃗s∼µ\n\u0002 f (⃗s)\u0003 when µ is\na probability distribution), and OPT(G) is the optimal outcome of G with respect to f . Thus the POA of a\ngame is always at least 1, and the closer to 1, the better.\nThe POA of a game depends on the choice of equilibrium concept. Since it is deﬁned with respect to the\nworst equilibrium, the POA only degrades as the set of equilibria grows larger. Thus, the POA with respect\nto coarse correlated equilibria can only be worse (i.e., larger) than that with respect to correlated equilibria,\nwhich can in turn only be worse than the POA with respect to Nash equilibria (recall Figure 5.1).\nThe hope is that there’s a “sweet spot” equilibrium concept—permissive enough to be computationally\ntractable, yet stringent enough to allow good worse-case approximation guarantees. Happily, the coarse\ncorrelated equilibrium is just such a sweet spot!\n5.5.2\nSmooth Games and Extension Theorems\nAfter the ﬁrst ten years of price-of-anarchy analyses (roughly 1999-2008), it was clear to researchers in the\narea that many such analyses across diﬀerent application domains share a common architecture (in routing\ngames, facility location games, scheduling games, auctions, etc.). The concept of “proofs of POA bounds\n9As a bonus, this means that the algorithm will output a “sparse” correlated equilibrium, with support size polynomial in the\nsize of the game description.\n10This is not a totally unfamiliar idea to economists. According to Solan and Vohra [139], Roger Myerson, winner of the 2007\nNobel Prize in Economics, asserted that “if there is intelligent life on other planets, in a majority of them, they would have discovered\ncorrelated equilibrium before Nash equilibrium.”\n105\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 166
  },
  {
    "chunk_full": "that follow the standard template” was made precise in the theory of smooth games [128].11,12 One can then\ndeﬁne the robust price of anarchy as the best (i.e., smallest) bound on a game’s POA that can be proved by\nfollowing the standard template.\nThe proof template formalized by smooth games superﬁcially appears to be relevant only for the POA\nwith respect to pure Nash equilibria, as the deﬁnition involves no randomness (let alone correlation). The\ngood news is that the template’s simplicity makes it relatively easy to use. One would expect the bad news to\nbe that bounds on the POA of more permissive equilibrium concepts require diﬀerent proof techniques, and\nthat the corresponding POA bounds would be much worse. This is not the case—every POA bound proved\nusing the canonical template automatically applies not only to the pure Nash equilibria of a game, but more\ngenerally to all of the game’s coarse correlated equilibria (and hence all of its correlated and mixed Nash\nequilibria).13\nTheorem 5.6 (Roughgarden [128]). In every game, the POA with respect to coarse correlated equilibria is\nbounded above by its robust POA.\nFor ϵ-approximate coarse correlated equilibria—as guaranteed by a logarithmic number of rounds of\nsmooth ﬁctitious play (Proposition 5.3)—the POA bound in Theorem 5.6 degrades by an additive O(ϵ) term.\n11The formal deﬁnition is a bit technical, and we won’t need it here. Roughly, it requires that the best-response condition is\ninvoked in an equilibrium-independent way and that a certain restricted type of charging argument is used.\n12There are several important precursors to this theory, including Blum et al. [14], Christodoulou and Koutsoupias [35], and\nVetta [145]. See [128] for a detailed history.\n13Smooth games and the “extension theorem” in Theorem 5.6 are the starting point for the modular and user-friendly toolbox\nfor proving POA bounds in complex settings mentioned in Section 1.3.4 of Lunar Lecture 1. Generalizations of this theory to\nincomplete-information games (like auctions) and to the composition of smooth games (like simultaneous single-item auctions) lead\nto good POA bounds for simple auctions [143]. (These generalizations also brought together two historically separate subﬁelds of\nalgorithmic game theory, namely algorithmic mechanism design and price-of-anarchy analyses.) See [134] for a user’s guide to this\ntoolbox.\n106\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 167
  },
  {
    "chunk_full": "Bibliography\n[1] S. Aaronson, R. Impagliazzo, and D. Moshkovitz. AM with multiple Merlins. In Proceedings of the\n29th IEEE Conference on Computational Complexity (CCC), pages 44–55, 2014. 54\n[2] I. Adler. The equivalence of linear programs and zero-sum games. International Journal of Game\nTheory, 42(1):165–177, 2013. 9\n[3] S. Alaei, H. Fu, N. Haghpanah, J. D. Hartline, and A. Malekian. Bayesian optimal auctions via multi-\nto single-agent reduction. In Proceedings of the 13th Annual ACM Conference on Economics and\nComputation (EC), page 17, 2012. 90, 94, 95\n[4] I. Althöfer. On sparse approximations to randomized strategies and convex combinations. Linear\nAlgebra and Its Applications, 199(1):339–355, 1994. 19, 56\n[5] A. Anshu, N. Goud, R. Jain, S. Kundu, and P. Mukhopadhyay. Lifting randomized query complexity\nto randomized communication complexity. Technical Report TR17-054, ECCC, 2017. 23, 31, 32\n[6] K. J. Arrow and G. Debreu. Existence of an equilibrium for a competitive economy. Econometrica,\n22:265–290, 1954. 79\n[7] R. J. Aumann.\nSubjectivity and correlation in randomized strategies.\nJournal of Mathematical\nEconomics, 1(1):67–96, 1974. 101\n[8] Y. Babichenko. Query complexity of approximate Nash equilibria. Journal of the ACM, 63(4):36,\n2016. 29\n[9] Y. Babichenko and A. Rubinstein. Communication complexity of approximate Nash equilibria. In\nProceedings of 49th Annual ACM Symposium on Theory of Computing (STOC), pages 878–889, 2017.\n6, 22, 23, 29, 34, 37, 38\n[10] P. Beame, S. Cook, J. Edmonds, R. Impagliazzo, and T. Pitassi. The relative complexity of NP search\nproblems. Journal of Computer and System Sciences, 57(1):3–19, 1998. 46\n[11] O. Ben-Zwi, R. Lavi, and I. Newman. Ascending auctions and Walrasian equilibrium. Working paper,\n2013. 81\n[12] S. Bikhchandani and J. W. Mamer. Competitive equilibrium in an exchange economy with indivisi-\nbilities. Journal of Economic Theory, 74:385–413, 1997. 85\n[13] N. Bitansky, O. Paneth, and A. Rosen. On the cryptographic hardness of ﬁnding a Nash equilibrium.\nIn Proceedings of the 56th Annual Symposium on Foundations of Computer Science (FOCS), pages\n1480–1498, 2015. 50\n107\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 168
  },
  {
    "chunk_full": "[14] A. Blum, M. T. Hajiaghayi, K. Ligett, and A. Roth. Regret minimization and the price of total anarchy.\nIn Proceedings of the 40th Annual ACM Symposium on Theory of Computing (STOC), pages 373–382,\n2008. 106\n[15] K. C. Border. Fixed point theorems with applications to economics and game theory. Cambridge\nUniversity Press, 1985. 24\n[16] K. C. Border. Implementation of reduced form auctions: A geometric approach. Econometrica, 59\n(4):1175–1187, 1991. URL http://www.jstor.org/stable/2938181. 87, 90, 91, 93\n[17] K. C. Border. Reduced form auctions revisited. Economic Theory, 31:167–181, 2007. 93\n[18] M. Braverman, Y. Kun Ko, and O. Weinstein. Approximating the best Nash equilibrium in no(log n)-\ntime breaks the exponential time hypothesis. In Proceedings of the 26th Annual ACM-SIAM Symposium\non Discrete Algorithms (SODA), pages 970–982. SIAM, 2015. doi: 10.1137/1.9781611973730.66.\n54\n[19] M. Braverman, Y. Kun Ko, A. Rubinstein, and O. Weinstein. ETH hardness for densest-k-subgraph\nwith perfect completeness. In Proceedings of the 28th Annual ACM-SIAM Symposium on Discrete\nAlgorithms (SODA), pages 1326–1341, 2017. 54\n[20] G. W. Brown. Iterative solutions of games by ﬁctitious play. In T. C. Koopmans, editor, Activity\nAnalysis of Production and Allocation, Cowles Commission Monograph No. 13, chapter XXIV, pages\n374–376. Wiley, 1951. 14\n[21] Y. Cai, C. Daskalakis, and S. M. Weinberg. An algorithmic characterization of multi-dimensional\nmechanisms. In Proceedings of the 44th Symposium on Theory of Computing (STOC), pages 459–478,\n2012. 90, 94, 95\n[22] Y. Cai, C. Daskalakis, and S. M. Weinberg. Optimal multi-dimensional mechanism design: Reducing\nrevenue to welfare maximization. In Proceedings of the 53rd Annual Symposium on Foundations of\nComputer Science (FOCS), pages 130–139, 2012. 94\n[23] Y. Cai, O. Candogan, C. Daskalakis, and C. H. Papadimitriou. Zero-sum polymatrix games: A\ngeneralization of minmax. Mathematics of Operations Research, 41(2):648–655, 2016. 99\n[24] O. Candogan, A. Ozdaglar, and P. Parrilo. Iterative auction design for tree valuations. Operations\nResearch, 63(4):751–771, 2015. 81\n[25] O. Candogan, A. Ozdaglar, and P. Parrilo. Pricing equilibria and graphical valuations. ACM Transac-\ntions on Economics and Computation, 2017. To appear. 81\n[26] N. Cesa-Bianchi and G. Lugosi. Prediction, Learning, and Games. Cambridge University Press,\n2006. 17\n[27] N. Cesa-Bianchi, Y. Mansour, and G. Stolz. Improved second-order bounds for prediction with expert\nadvice. Machine Learning, 66(2–3):321–352, 2007. 16\n[28] Y.-K. Che, J. Kim, and K. Mierendorﬀ. Generalized reduced form auctions: A network ﬂow approach.\nEconometrica, 81:2487–2520, 2013. 93, 94, 95\n108\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 169
  },
  {
    "chunk_full": "[29] X. Chen and X. Deng. 3-Nash is PPAD-complete. Technical Report TR05-134, ECCC, 2005. 49, 109\n[30] X. Chen and X. Deng. Settling the complexity of two-player Nash equilibrium. In Proceedings of the\n47th Annual Symposium on Foundations of Computer Science (FOCS), pages 261–270, 2006. 49, 109\n[31] X. Chen and X. Deng. On the complexity of 2D discrete ﬁxed point problem. Theoretical Computer\nScience, 410(44):4448–4456, Oct. 2009. doi: 10.1016/j.tcs.2009.07.052. 48\n[32] X. Chen, X. Deng, and S.-H. Teng. Computing Nash equilibria: Approximation and smoothed\ncomplexity. In Proceedings of the 47th Annual Symposium on Foundations of Computer Science\n(FOCS), pages 603–612, 2006. 49, 109\n[33] X. Chen, X. Deng, and S.-H. Teng. Sparse games are hard. In Proceedings of the Second Annual\nInternational Workshop on Internet and Network Economics (WINE), volume 4286 of Lecture Notes\nin Computer Science, pages 262–273, 2006. 109\n[34] X. Chen, X. Deng, and S.-H. Teng. Settling the complexity of computing two-player Nash equilibria.\nJournal of the ACM, 56(3):14, 2009. doi: 10.1145/1516512.1516516. Journal version of [29], [30],\n[32], and [33]. 26, 49, 53, 56\n[35] G. Christodoulou and E. Koutsoupias. On the price of anarchy and stability of correlated equilibria\nof linear congestion games. In Proceedings of the 13th Annual European Symposium on Algorithms\n(ESA), pages 59–70, 2005. 106\n[36] G. Christodoulou, A. Kovács, and M. Schapira. Bayesian combinatorial auctions. Journal of the\nACM, 63(2):11, 2016. 74\n[37] G. Christodoulou, A. Kovács, A. Sgouritsa, and B. Tang. Tight bounds for the price of anarchy of\nsimultaneous ﬁrst price auctions. ACM Transactions on Economics and Computation, 4(2):9, 2016.\n67, 74, 77\n[38] V. Chvátal. Linear Programming. Freeman, 1983. 10, 85, 104\n[39] G. B. Dantzig. A proof of the equivalence of the programming problem and the game problem. In T. C.\nKoopmans, editor, Activity Analysis of Production and Allocation, Cowles Commission Monograph\nNo. 13, chapter XX, pages 330–335. Wiley, 1951. 9\n[40] G. B. Dantzig. Reminiscences about the origins of linear programming. Technical Report SOL 81-5,\nSystems Optimization Laboratory, Department of Operations Research, Stanford University, 1981. 9\n[41] C. Daskalakis and Q. Pan. A counter-example to Karlin’s strong conjecture for ﬁctitious play. In\nProceedings of the 55th Annual Symposium on Foundations of Computer Science (FOCS), pages\n11–20. IEEE, IEEE Computer Society, 2014. 14\n[42] C. Daskalakis and C. H. Papadimitriou. Three-player games are hard. Technical Report TR05-139,\nECCC, 2005. 49, 110\n[43] C. Daskalakis, P. W. Goldberg, and C. H. Papadimitriou. The complexity of computing a Nash\nequilibrium. In Proceedings of the 38th Annual ACM Symposium on Theory of Computing (STOC),\npages 71–78, 2006. 49, 110\n109\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 170
  },
  {
    "chunk_full": "[44] C. Daskalakis, P. W. Goldberg, and C. H. Papadimitriou. The complexity of computing a Nash\nequilibrium. SIAM Journal on Computing, 39(1):195–259, 2009. doi: 10.1137/070699652. Journal\nversion of [42], [43], and [63]. 26, 49, 53, 56\n[45] C. Daskalakis, P. W. Goldberg, and C. H. Papadimitriou. The complexity of computing a Nash\nequilibrium. Communications of the ACM, 52(2):89–97, 2009. 49\n[46] S. Dobzinski and J. Vondrak. Communication complexity of combinatorial auctions with submodular\nvaluations. In Proceedings of the 24th Annual ACM-SIAM Symposium on Discrete Algorithms (SODA),\npages 1205–1215, 2013. 77\n[47] S. Dobzinski, N. Nisan, and M. Schapira. Approximation algorithms for combinatorial auctions with\ncomplement-free bidders. Mathematics of Operations Research, 35(1):1–13, 2010. 72\n[48] P. Dütting, V. Gkatzelis, and T. Roughgarden. The performance of deferred-acceptance auctions.\nMathematics of Operations Research, 42(4):897–914, 2017. 65\n[49] K. Etessami and M. Yannakakis. On the complexity of Nash equilibria and other ﬁxed points. SIAM\nJournal on Computing, 39(6):2531–2597, 2010. 47\n[50] U. Feige. On maximizing welfare where the utility functions are subadditive. SIAM Journal on\nComputing, 39(1):122–142, 2009. 73, 74\n[51] U. Feige and J. Vondrák. The submodular welfare problem with demand queries. Theory of Computing,\n6(1):247–290, 2010. 77\n[52] M. Feldman, H. Fu, N. Gravin, and B. Lucier. Simultaneous auctions are (almost) eﬃcient. In\nProceedings of the Forty-ﬁfth Annual ACM Symposium on Theory of Computing, STOC ’13, pages\n201–210, New York, NY, USA, 2013. ACM. ISBN 978-1-4503-2029-0. doi: 10.1145/2488608.\n2488634. URL http://doi.acm.org/10.1145/2488608.2488634. 67, 74\n[53] D. P. Foster and R. Vohra. Calibrated learning and correlated equilibrium. Games and Economic\nBehavior, 21(1–2):40–55, 1997. 102, 103\n[54] A. Fréchette, N. Newman, and K. Leyton-Brown. Solving the station repacking problem. In Handbook\nof Spectrum Auction Design, chapter 38, pages 813–827. Cambridge University Press, 2017. 63\n[55] Y. Freund and R. E. Schapire. A decision-theoretic generalization of on-line learning and an application\nto boosting. Journal of Computer and System Sciences, 55(1):119–139, 1997. 16\n[56] Y. Freund and R. E. Schapire. Adaptive game playing using multiplicative weights. Games and\nEconomic Behavior, 29(1–2):79–103, 1999. 15\n[57] D. Fudenberg and D. K. Levine. Consistency and cautious ﬁctitious play. Journal of Economic\nDynamics and Control, 19(5):1065–1089, 1995. 15\n[58] D. Gale, H. W. Kuhn, and A. W. Tucker. Linear programming and the theory of games. In T. C.\nKoopmans, editor, Activity Analysis of Production and Allocation, Cowles Commission Monograph\nNo. 13, chapter XIX, pages 317–329. Wiley, 1951. 9\n110\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 171
  },
  {
    "chunk_full": "[59] S. Garg, O. Pandey, and A. Srinivasan. Revisiting the cryptographic hardness of ﬁnding a Nash\nequilibrium. In Proceedings of the 36th Annual International Cryptology Conference on Advances in\nCryptology (CRYPTO), pages 579–604, 2016. 50\n[60] J. Geanakoplos. Nash and Walras equilibrium via Brouwer. Economic Theory, 21(2/3):585–603,\n2003. 25\n[61] I. Gilboa and E. Zemel. Nash and correlated equilibria: Some complexity considerations. Games and\nEconomic Behavior, 1(1):80–93, 1989. 103\n[62] V. Gkatzelis, E. Markakis, and T. Roughgarden. Deferred-acceptance auctions for multiple levels of\nservice. In Proceedings of the 18th Annual ACM Conference on Economics and Computation (EC),\npages 21–38, 2017. 65\n[63] P. W. Goldberg and C. H. Papadimitriou. Reducibility among equilibrium problems. In Proceedings\nof the 38th Annual ACM Symposium on Theory of Computing (STOC), pages 61–70, 2006. 49, 110\n[64] M. Göös. Lower bounds for clique vs. independent set. In Proceedings of the 56th Annual Symposium\non Foundations of Computer Science (FOCS), pages 1066–1076, 2015. 30\n[65] M. Göös, S. Lovett, R. Meka, T. Watson, and D. Zuckerman. Rectangles are nonnegative juntas.\nIn Proceedings of 47th Annual ACM Symposium on Theory of Computing (STOC), pages 257–266,\n2015. 23\n[66] M. Göös, T. Pitassi, and T. Watson. Deterministic communication vs. partition number. In Proceedings\nof the 56th Annual Symposium on Foundations of Computer Science (FOCS), pages 1077–1088, 2015.\ndoi: 10.1109/FOCS.2015.70. URL http://dx.doi.org/10.1109/FOCS.2015.70. 31, 32\n[67] M. Göös, T. Pitassi, and T. Watson. Query-to-communication lifting for BPP. In Proceedings of the\n58th Annual IEEE Symposium on Foundations of Computer Science, pages 132–143, 2017. 23, 31,\n32\n[68] P. Gopalan, N. Nisan, and T. Roughgarden. Public projects, Boolean functions, and the borders of\nBorder’s theorem. In Proceedings of the 16th ACM Conference on Economics and Computation (EC),\npage 395. ACM, 2015. doi: 10.1145/2764468.2764538. 7, 87, 94, 96\n[69] F. Gul and E. Stacchetti. Walrasian equilibrium with gross substitutes. Journal of Economic Theory,\n87:95–124, 1999. 81\n[70] J. Hannan. Approximation to Bayes risk in repeated play. In M. Dresher, A. W. Tucker, and P. Wolfe,\neditors, Contributions to the Theory of Games, volume 3, pages 97–139. Princeton University Press,\n1957. 14\n[71] S. Hart and A. Mas-Colell. A simple adaptive procedure leading to correlated equilibrium. Econo-\nmetrica, 68(5):1127–1150, 2000. 102, 103\n[72] J. D. Hartline. Mechanism design and approximation. Book draft, July 2017. 89\n[73] A. Hassidim, H. Kaplan, Y. Mansour, and N. Nisan. Non-price equilibria in markets of discrete goods.\nIn Proceedings of the 12th Annual ACM Conference on Economics and Computation (EC), pages\n295–296, 2011. 67\n111\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 172
  },
  {
    "chunk_full": "[74] M. D. Hirsch, C. H. Papadimitriou, and S. A. Vavasis. Exponential lower bounds for ﬁnding Brouwer\nﬁx points. Journal of Complexity, 5(4):379–416, 1989. 24, 29, 34, 35, 37, 38, 50, 53\n[75] P. Hubáček and E. Yogev. Hardness of continuous local search: Query complexity and cryptographic\nlower bounds. In Proceedings of the 28th Annual ACM-SIAM Symposium on Discrete Algorithms\n(SODA), pages 1352–1371, 2017. 50\n[76] P. Hubáček, M. Naor, and E. Yogev. The journey from NP to TFNP hardness. In Proceedings of the\n8th Conference on Innovations in Theoretical Computer Science (ITCS), 2017. Article 60. 50, 52\n[77] R. Impagliazzo and A. Wigderson. P = BPP if E requires exponential circuits: derandomizing the\nXOR lemma. In Proceedings of the 29th Annual ACM Symposium on Theory of Computing (STOC),\npages 220–229, 1997. 52\n[78] R. Impagliazzo, R. Paturi, and F. Zane. Which problems have strongly exponential complexity?\nJournal of Computer and System Sciences, 63(4):512–530, 2001. 53\n[79] A. X. Jiang and K. Leyton-Brown. Polynomial-time computation of exact correlated equilibrium in\ncompact games. Games and Economic Behavior, 91:347–359, 2015. 104\n[80] D. S. Johnson. The NP-completeness column: Finding needles in haystacks. ACM Transactions on\nAlgorithms, 3(2):24, 2007. 49\n[81] D. S. Johnson, C. H. Papadimitriou, and M. Yannakakis. How easy is local search?\nJournal of\nComputer and System Sciences, 37(1):79–100, 1988. 46\n[82] S. Kakade, M. Kearns, J. Langford, and L. Ortiz. Correlated equilibria in graphical games. In\nProceedings of the 4th ACM Conference on Electronic Commerce, pages 42–47, 2003. 104\n[83] B. Kalyanasundaram and G. Schnitger. The probabilistic communication complexity of set intersec-\ntion. SIAM Journal on Discrete Mathematics, 5(4):545–557, 1992. 23\n[84] S. Karlin. Mathematical Methods and Theory in Games, Programming, and Economics. Addison-\nWesley, 1959. 14\n[85] M. Kearns. Graphical games. In N. Nisan, T. Roughgarden, É. Tardos, and V. Vazirani, editors,\nAlgorithmic Game Theory, chapter 7, pages 159–180. Cambridge University Press, 2007. 99\n[86] M. Kearns, M. L. Littman, and S. Singh. Graphical models for game theory. In Proceedings of the\nConference on Uncertainty in Artiﬁcial Intelligence (UAI), pages 253–260, 2001. 103\n[87] A. S. Kelso and V. P. Crawford. Job matching, coalition formation, and gross substitutes. Econometrica,\n50(6):1483–1504, 1982. 81\n[88] L. G. Khachiyan. A polynomial algorithm in linear programming. Soviet Mathematics Doklady, 20\n(1):191–194, 1979. 84, 96, 104\n[89] T. H. Kjeldsen. John von Neumann’s conception of the Minimax theorem: A journey through diﬀerent\nmathematical contexts. Archive for History of Exact Sciences, 56:39–68, 2001. 25\n[90] D. Koller and B. Milch. Multi-agent inﬂuence diagrams for representing and solving games. Games\nand Economic Behavior, 45:181–221, 2003. 103\n112\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 173
  },
  {
    "chunk_full": "[91] S. Kopparty, O. Meir, N. Ron-Zewi, and S. Saraf. High-rate locally correctable and locally testable\ncodes with sub-polynomial query complexity. Journal of the ACM, 64(2):11, 2017. 59\n[92] E. Koutsoupias and C. H. Papadimitriou. Worst-case equilibria. In Proceedings of the 16th Annual\nConference on Theoretical Aspects of Computer Science (STACS), pages 404–413, Berlin, Heidelberg,\n1999. Springer-Verlag. URL http://dl.acm.org/citation.cfm?id=1764891.1764944. 67, 73\n[93] E. Kushilevitz and N. Nisan. Communication Complexity. Cambridge University Press, 1996. 23, 70,\n78\n[94] C. Lautemann. BPP and the polynomial hierarchy. Information Processing Letters, 17(4):215–217,\n1983. 50\n[95] B. Lehmann, D. Lehmann, and N. Nisan. Combinatorial auctions with decreasing marginal utilities.\nGames and Economic Behavior, 55:270–296, 2006. 83\n[96] C. E. Lemke and J. T. Howson, Jr. Equilibrium points of bimatrix games. SIAM Journal, 12(2):\n413–423, 1964. 19, 47\n[97] K. Leyton-Brown, P. Milgrom, and I. Segal. Economics and computer science of a radio spectrum\nreallocation. Proceedings of the National Academy of Sciences (PNAS), 114(28):7202–7209, 2017.\n63\n[98] R. J. Lipton and N. E. Young. Simple strategies for large zero-sum games with applications to\ncomplexity theory. In Proceedings of 26th Annual ACM Symposium on Theory of Computing (STOC),\npages 734–740, 1994. 19\n[99] R. J. Lipton, E. Markakis, and A. Mehta. Playing large games using simple strategies. In Proceedings\nof the 4th ACM Conference on Electronic Commerce (EC), pages 36–41. ACM, 2003. doi: 10.1145/\n779928.779933. 20, 76\n[100] N. Littlestone and M. K. Warmuth. The weighted majority algorithm. Information and Computation,\n108(2):212–261, 1994. 16\n[101] E. Maskin and J. Riley. Optimal auctions with risk-adverse buyers. Econometrica, 52:1473–1518,\n1984. 90\n[102] S. A. Matthews. On the implementability of reduced form auctions. Econometrica, 52:1519–1522,\n1984. 90\n[103] A. McLennan. Advanced ﬁxed point theory for economics. Book in preparation, 2015. 24\n[104] A. McLennan and R. Tourky. From imitation games to Kakutani. Unpublished manuscript, 2006. 38\n[105] N. Megiddo and C. H. Papadimitriou. On total functions, existence theorems and computational\ncomplexity. Theoretical Computer Science, 81(2):317–324, 1991. 44\n[106] P. Milgrom. Putting auction theory to work: The simultaneous ascending auction. Journal of Political\nEconomy, 108(2):245–272, 2000. 81\n[107] P. Milgrom. Putting Auction Theory to Work. Churchill Lectures in Economics. Cambridge University\nPress, 2004. 65\n113\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 174
  },
  {
    "chunk_full": "[108] P. Milgrom and I. Segal. Deferred-acceptance auctions and radio spectrum reallocation. In Proceedings\nof the 15th ACM Conference on Economics and Computation (EC), pages 185–186, New York, NY,\nUSA, 2014. ACM. doi: 10.1145/2600057.2602834. 62, 64\n[109] W. D. Morris, Jr. Lemke paths on simple polytopes. Mathematics of Operations Research, 19:\n780–789, 1994. 19\n[110] H. Moulin and J. P. Vial. Strategically zero-sum games: The class of games whose completely mixed\nequilibria cannot be improved upon. International Journal of Game Theory, 7(3–4):201–221, 1978.\n101\n[111] R. Myerson. Optimal auction design. Mathematics of Operations Research, 6(1):58–73, 1981. 89\n[112] S. Nasar. A Beautiful Mind: a Biography of John Forbes Nash, Jr., Winner of the Nobel Prize in\nEconomics, 1994. Simon & Schuster, 1998. 19\n[113] J. F. Nash, Jr. Equilibrium points in N-person games. Proceedings of the National Academy of\nSciences, 36(1):48–49, 1950. 19\n[114] J. F. Nash, Jr. Non-cooperative games. Annals of Mathematics, 54(2):286–295, 1951. 19\n[115] N. Nisan. The communication complexity of approximate set packing and covering. In Proceedings of\nthe 29th International Colloquium on Automata, Languages and Programming (ICALP), pages 868–\n875. Springer-Verlag, 2002. URL http://dl.acm.org/citation.cfm?id=646255.684594. 70,\n71\n[116] N. Nisan and I. Segal. The communication requirements of eﬃcient allocations and supporting prices.\nJournal of Economic Theory, 129:192–224, 2006. 84\n[117] C. H. Papadimitriou. On the complexity of the parity argument and other ineﬃcient proofs of existence.\nJournal of Computer and System Sciences, 48(3):498–532, 1994. 45, 48, 49\n[118] C. H. Papadimitriou. The complexity of ﬁnding Nash equilibria. In N. Nisan, T. Roughgarden,\nÉ. Tardos, and V. V. Vazirani, editors, Algorithmic Game Theory, chapter 2, pages 29–51. Cambridge,\n2007. 49\n[119] C. H. Papadimitriou and T. Roughgarden. Computing correlated equilibria in multi-player games.\nJournal of the ACM, 55(3):14, 2008. 104\n[120] R. Raz and P. McKenzie. Separation of the monotone NC hierarchy. Combinatorica, 19(3):403–435,\n1999. doi: 10.1007/s004930050062. URL http://dx.doi.org/10.1007/s004930050062. 6,\n31, 32\n[121] A. A. Razborov. On the distributional complexity of disjointness. Theoretical Computer Science, 106\n(2):385–390, 1992. 23\n[122] J. Robinson. An iterative method of solving a game. Annals of Mathematics, pages 296–301, 1951.\n14\n[123] A. Rosen, G. Segev, and I. Shahaf. Can PPAD hardness be based on standard cryptographic assump-\ntions? In Proceedings of the 15th International Conference on Theory of Cryptography (TCC), pages\n173–205, 2017. 50\n114\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 175
  },
  {
    "chunk_full": "[124] T. Roughgarden. Selﬁsh Routing and the Price of Anarchy. MIT Press, 2005. 67\n[125] T. Roughgarden. Computing equilibria: A computational complexity perspective. Economic Theory,\n42(1):193–236, 2010. 49\n[126] T. Roughgarden. Barriers to near-optimal equilibria. In Proceedings of the 55th Annual Symposium\non Foundations of Computer Science (FOCS), pages 71–80. IEEE Computer Society, 2014. doi:\n10.1109/FOCS.2014.16. 7, 68, 75\n[127] T. Roughgarden. CS364B lecture notes. Stanford University, 2014. 74\n[128] T. Roughgarden. Intrinsic robustness of the price of anarchy. Journal of the ACM, 62(5):32, 2015.\n106\n[129] T. Roughgarden. Twenty Lectures on Algorithmic Game Theory. Cambridge University Press, 2016.\n25, 43, 65, 89, 101\n[130] T. Roughgarden. Communication complexity (for algorithm designers). Foundations and Trends in\nTheoretical Computer Science, 11(3-4):217–404, 2016. 23, 69, 70\n[131] T. Roughgarden and I. Talgam-Cohen. Why prices need algorithms. In Proceedings of the 16th Annual\nACM Conference on Economics and Computation (EC), pages 19–36, 2015. 7, 79, 82, 86\n[132] T. Roughgarden and É. Tardos. How bad is selﬁsh routing?\nJournal of the ACM, 49(2):236–259,\n2002. 67\n[133] T. Roughgarden and O. Weinstein. On the communication complexity of approximate ﬁxed points.\nIn Proceedings of the 57th Annual Symposium on Foundations of Computer Science (FOCS), pages\n229–238, 2016. 29, 32\n[134] T. Roughgarden, V. Syrgkanis, and É.. Tardos. The price of anarchy in auctions. Journal of Artiﬁcial\nIntelligence Research, 59:59–101, 2017. 67, 106\n[135] A. Rubinstein. Settling the complexity of computing approximate two-player Nash equilibria. In\nProceedings of the 57th Annual IEEE Symposium on Foundations of Computer Science, pages 258–\n265, 2016. 7, 24, 34, 38, 43, 48, 49, 53, 54, 57, 59, 60\n[136] R. Savani and B. von Stengel. Hard-to-solve bimatrix games. Econometrica, 74(2):397–429, 2006.\n19\n[137] A. Schrijver. Theory of Linear and Integer Programming. Wiley, 1986. 96\n[138] L. S. Shapley. Some topics in two-person games. In M. Dresher, L. S. Shapley, and A. W. Tucker,\neditors, Advances in Game Theory, pages 1–28. Princeton University Press, 1964. 14, 18\n[139] E. Solan and R. Vohra. Correlated equilibrium payoﬀs and public signalling in absorbing games.\nInternational Journal of Game Theory, 31:91–121, 2002. 105\n[140] D. A. Spielman. The complexity of error-correcting codes. In Proceedings of the 11th International\nSymposium on Fundamentals of Computation Theory, pages 67–84, 1997. 55\n115\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 176
  },
  {
    "chunk_full": "[141] D. A. Spielman and S.-H. Teng.\nSmoothed analysis: Why the simplex algorithm usually takes\npolynomial time. Journal of the ACM, 51(3):385–463, 2004. 49\n[142] N. Sun and Z. Yang. Equilibria and indivisibilities: Gross substitutes and complements. Econometrica,\n74(5):1385–1402, 2006. 81\n[143] V. Syrgkanis and É. Tardos. Composable and eﬃcient mechanisms. In Proceedings of the 45th ACM\nSymposium on Theory of Computing (STOC), pages 211–220, 2013. 77, 106\n[144] S. Toda. PP is as hard as the polynomial-time hierarchy. SIAM Journal on Computing, 20(5):865–877,\n1991. 96\n[145] A. Vetta. Nash equilibria in competitive societies, with applications to facility location, traﬃc routing\nand auctions. In Proceedings of the 43rd Annual Symposium on Foundations of Computer Science\n(FOCS), pages 416–425, 2002. 106\n[146] W. Vickrey. Counterspeculation, auctions, and competitive sealed tenders. Journal of Finance, 16(1):\n8–37, 1961. 87\n[147] J. Ville. Sur la theorie générale des jeux ou intervient l’habileté des joueurs. Fascicule 2 in Volume 4\nof É. Borel, Traité du Calcul des probabilités et de ses applications, pages 105–113. Gauthier-Villars,\n1938. 9\n[148] J. von Neumann. Zur Theorie der Gesellschaftsspiele. Mathematische Annalen, 100:295–320, 1928.\n9\n[149] J. von Neumann and O. Morgenstern. Theory of Games and Economic Behavior. Princeton University\nPress, 1944. 9\n[150] B. von Stengel. Equilibrium computation for two-player games in strategic and extensive form. In\nN. Nisan, T. Roughgarden, É. Tardos, and V. Vazirani, editors, Algorithmic Game Theory, chapter 3,\npages 53–78. Cambridge University Press, 2007. 19\n116\nECCC \n  ISSN 1433-8092 \nhttps://eccc.weizmann.ac.il\n",
    "book_id": "complexity_theory_game_theory_and_economics",
    "book_title": "Complexity Theory, Game Theory, and Economics",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 177
  },
  {
    "chunk_full": "",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 178
  },
  {
    "chunk_full": "",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 179
  },
  {
    "chunk_full": "FINITE AND \nINFINITE \nGAMES \nJAMES P. CARSE \nIffil \nTHE FREE PRESS \nA Division of Macmillan, Inc. \nNew York \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 180
  },
  {
    "chunk_full": "Copyright © 1986 by James P. Carse \nAll rights reserved. No part of this book may be reproduced or transmitted in any form or by \nany means, electronic or mechanical, including photocopying, recording, or by any \ninformation storage and retrieval system, without permission in writing from the Publisher. \nThe Free Press \nA Division of Macmillan, Inc. \n866 Third Avenue, New York, NY 10022 \nCollier Macmillan Canada, Inc. \nLibrary of Congress Catalog Card Number: 86-14304 \nPrinted in the United States of America \nLibrary or Congress Cataloglng-In-Publlcatlon Data \nCarse, James P. \nFinite and infinite games. \nIncludes index. \n1. Life. 2. Games-Symbolic aspects. 3. Religion. \n4. Philosophy. I. Title. \nBD431.C297 \n1986 \n110 \n86-14304 \nISBN 0-02-905980-1 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 181
  },
  {
    "chunk_full": "This book is dedicated to \nAlisa, Keene, and lamie, of course. \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 182
  },
  {
    "chunk_full": "",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 183
  },
  {
    "chunk_full": "CONTENTS \nONE: \nThere Are at Least Two Kinds of Games \nTWO: \nNo One Can Playa Game Alone \n35 \nTHREE: \nI Am the Genius of Myself \n65 \nFOUR: \nA Finite Game Occurs Within a World \n87 \nFIVE: \nNature Is the Realm of the Unspeakable \n97 \nSIX: \nWe Control Nature for Societal Reasons \n115 \nSEVEN: \nMyth Provokes Explanation \n137 \nbut Accepts None of It \nIndex \n151 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 184
  },
  {
    "chunk_full": "",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 185
  },
  {
    "chunk_full": "ONE \nTHERE ARE AT \nLEAST Two \nKINDS Of \nGAMES \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 186
  },
  {
    "chunk_full": "",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 187
  },
  {
    "chunk_full": "1 \nTHERE ARE at least two kinds of games. One could be called \nfinite, the other infinite. \nA finite game is played for the purpose of winning, an \ninfinite game for the purpose of continuing the play. \n2 \nIf a finite game is to be won by someone it must come \nto a definitive end. It will come to an end when someone \nhas won. \nWe know that someone has won the game when all the \nplayers have agreed who among them is the winner. No other \ncondition than the agreement of the players is absolutely re-\nquired in determining who has won the game. \nIt may appear that the approval of the spectators, or the \nreferees, is also required in the determination of the winner. \nHowever, it is simply the case that if the players do not agree \non a winner, the game has not come to a decisive conclusion-\nand the players have not satisfied the original purpose of play-\ning. Even if they are carried from the field and forcibly blocked \nfrom further play, they will not consider the game ended. \nFINITE AND INFINITE GAMES \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 188
  },
  {
    "chunk_full": "Suppose the players all agree, but the spectators and the \nreferees do not. Unless the players can be persuaded that \ntheir agreement was mistaken, they will not resume the play-\nindeed, they cannot resume the play. We cannot imagine \nplayers returning to the field and truly playing if they are \nconvinced the game is over. \nThere is no finite game unless the players freely choose \nto play it. No one can play who is forced to play. \nIt is an invariable principle of all play, finite and infinite, \nthat whoever plays, plays freely. Whoever must play, cannot \nplay. \n3 \nJust as it is essential for a finite game to have a definitive \nending, it must also have a precise beginning. Therefore, we \ncan speak of finite games as having temporal boundaries-\nto which, of course, all players must agree. But players must \nagree to the establishment of spatial and numerical boundaries \nas well. That is, the game must be played within a marked \narea, and with specified players. \nSpatial boundaries are evident in every finite conOict, from \nthe simplest board and court games to world wars. The oppo-\nnents in World War II agreed not to bomb Heidelberg and \nParis and declared Switzerland outside the boundaries of con-\nOict. When unnecessary and excessive damage is inOicted by \none of the sides in warfare, a question arises as to the legitimacy \nof the victory that side may claim, even whether it has been \na war at all and not simply gratuitous unwarranted violence. \nWhen Sherman burned his way from Atlanta to the sea, he \nso ignored the sense of spatial limitation that for many persons \n4 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 189
  },
  {
    "chunk_full": "the war was not legitimately won by the Union Army, and \nhas in fact never been concluded. \nNumerical boundaries take many forms but are always ap-\nplied in finite games. Persons are selected for finite play. It \nis the case that we cannot play if we must play, but it is \nalso the case that we cannot play alone. Thus, in every case, \nwe must find an opponent, and in most cases teammates, \nwho are willing to join in play with us. Not everyone who \nwishes to do so may play for, or against, the New York Yankees. \nNeither may they be electricians or agronomists by individual \nchoice, without the approval of their potential colleagues and \ncompetitors. \nBecause finite players cannot select themselves for play, \nthere is never a time when they cannot be removed from \nthe game, or when the other contestants cannot refuse to \nplay with them. The license never belongs to the licensed, \nnor the commission to the officer. \nWhat is preserved by the constancy of numerical bound-\naries, of course, is the possibility that all contestants can agree \non an eventual winner. Whenever persons may walk on or \noff the field of playas they wish, there is such a confusion \nof participants that none can emerge as aclear victor. Who, \nfor example, won the French Revolution? \n4 \nTo have such boundaries means that the date, place, and \nmembership of each finite game are externally defined. When \nwe say of a particular contest that it began on September 1, \n1939, we are speaking from the perspective of world time; \nthat is, from the perspective of what happened before the \nFINITE AND INFINITE GAMES \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 190
  },
  {
    "chunk_full": "beginning of the conflict and what would happen after its \nconclusion. So also with place and membership. A game is \nplayed in that place, with those persons. \nThe world is elaborately marked by boundaries of contest, \nits people finely classified as to their eligibilities. \n5 \nOnly one person or team can win a finite game, but the \nother contestants may well be ranked at the conclusion of \nplay. \nNot everyone can be a corporation president, although some \nwho have competed for that prize may be vice presidents or \ndistrict managers. \nThere are many games we enter not expecting to win, but \nin which we nonetheless compete for the highest possible \nranking. \n6 \nIn one respect, but only one, an infinite game is identical \nto a finite game: Of infinite players we can also say that if \nthey play they play freely; if they must play, they cannot \nplay. \nOtherwise, infinite and finite play stand in the sharpest \npossible contrast. \nInfinite players cannot say when their game began, nor \ndo they care. They do not care for the reason that their game \nis not bounded by time. Indeed, the only purpose of the game \n6 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 191
  },
  {
    "chunk_full": "is to prevent it from coming to an end, to keep everyone in \nplay. \nThere are no spatial or numerical boundaries to an infinite \ngame. No world is marked with the barriers of infinite play, \nand there is no question of eligibility since anyone who wishes \nmay play an infinite game. \nWhile finite games are externally defined, infinite games \nare internally defined. The time of an infinite game is not \nworld time, but time created within the play itself. Since \neach play of an infinite game eliminates boundaries, it opens \nto players a new horizon of time. \nFor this reason it is impossible to say how long an infinite \ngame has been played, or even can be played, since duration \ncan be measured only externally to that which endures. It is \nalso impossible to say in which world an infinite game is played, \nthough there can be any number of worlds within an infinite \ngame. \n7 \nFinite games can be played within an infinite game, but \nan infinite game cannot be played within a finite game. \nInfinite players regard their wins and losses in whatever \nfinite games they playas but moments in continuing play. \n8 \nIf finite games must be externally bounded by time, space, \nand number, they must also have internal limitations on what \nFINITE AND INFINITE GAMES \n7 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 192
  },
  {
    "chunk_full": "the players can do to and with each other. To agree on internal \nlimitations is to establish rules of play. \nThe rules will be different for each finite game. It is, in \nfact, by knowing what the rules are that we know what the \ngame is. \nWhat the rules establish is a range of limitations on the \nplayers: each player must, for example, start behind the white \nline, or have all debts paid by the end of the month, charge \npatients no more than they can reasonably afford, or drive \nin the right lane. \nIn the narrowest sense rules are not laws; they do not man-\ndate specific behavior, but only restrain the freedom of the \nplayers, allowing considerable room for choice within those \nrestraints. \nIf these restraints are not observed, the outcome of the \ngame is directly threatened. The rules of a finite game are \nthe contractual terms by which the players can agree who \nhas won. \n9 \nThe rules must be published prior to play, and the players \nmust agree to them before play begins. \nA point of great consequence to all finite play follows from \nthis: The agreement of the players to the applicable rules consti-\ntutes the ultimate validation of those rules. \nRules are not valid because the Senate passed them, or \nbecause heroes once played by them, or because God pro-\nnounced them through Moses or Muhammad. They are valid \nonly if and when players freely play by them. \n8 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 193
  },
  {
    "chunk_full": "There are no rules that require us to obey rules. If there \nwere, there would have to be a rule for those rules, and so \non. \n10 \nIf the rules of a finite game are unique to that game it is \nevident that the rules may not change in the course of play-\nelse a different game is being played. \nIt is on this point that we find the most critical distinction \nbetween finite and infinite play: The rules of an infinite game \nmust change in the course of play. The rules are changed \nwhen the players of an infinite game agree that the play is \nimperiled by a finite outcome-that is, by the victory of some \nplayers and the defeat of others. \nThe rules of an infinite game are changed to prevent anyone \nfrom winning the game and to bring as many persons as possi-\nble into the play. \nIf the rules of a finite game are the contractual terms by \nwhich the players can agree who has won, the rules of an \ninfinite game are the contractual terms by which the players \nagree to continue playing. \nFor this reason the rules of an infinite game have a different \nstatus from those of a finite game. They are like the grammar \nof a living language, where those of a finite game are like \nthe rules of debate. In the former case we observe rules as \na way of continuing discourse with each other; in the latter \nwe observe rules as a way of bringing the speech of another \nperson to an end. \nThe rules, or grammar, of a living language are always evolv-\nFINITE AND INFINITE GAMES \n9 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 194
  },
  {
    "chunk_full": "ing to guarantee the meaningfulness of discourse, while the \nrules of debate must remain constant. \n11 \nAlthough the rules of an infinite game may change by agree-\nment at any point in the course of play, it does not follow \nthat any rule will do. I t is not in this sense that the game \nis infinite. \nThe rules are always designed to deal with specific threats \nto the continuation of play. Infinite players use the rules to \nregulate the way they will take the boundaries or limits being \nforced against their play into the game itself. \nThe rule-making capacity of infinite players is often chal-\nlenged by the impingement of powerful boundaries against \ntheir play-such as physical exhaustion, or the loss of material \nresources, or the hostility of nonplayers, or death. \nThe task is to design rules that will allow the players to \ncontinue the game by taking these limits into play-even \nwhen death is one of the limits. It is in this sense that the \ngame is infinite. \nThis is equivalent to saying that no limitation may be im-\nposed against infinite play. Since limits are taken into play, \nthe play itself cannot be limited. \nFinite players play within boundaries; infinite players play \nwith boundaries. \n12 \nAlthough it may be evident enough in theory that whoever \nplays a finite game plays freely, it is often the case that finite \n10 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 195
  },
  {
    "chunk_full": "players will be unaware of this absolute freedom and will come \nto think that whatever they do they must do. There are several \npossible reasons for this: \n-We saw that finite players must be selected. While \nno one is forced to remain a lawyer or a rodeo performer or \na kundalini yogi after being selected for these roles, each role \nis nonetheless surrounded both by ruled restraints and expecta-\ntions on the part of others. One senses a compulsion to main-\ntain a certain level of performance, because permission to \nplay in these games can be canceled. We cannot do whatever \nwe please and remain lawyers or yogis-and yet we could \nnot be either unless we pleased. \n-Since finite games are played to be won, players make \nevery move in a game in order to win it. Whatever is not \ndone in the interest of winning is not part of the game. The \nconstant attentiveness of finite players to the progress of the \ncompetition can lead them to believe that every move they \nmake they must make. \n-I t may appear that the prizes for winning are indispensa-\nble, that without them life is meaningless, perhaps even impos-\nsible. There are, to be sure, games in which the stakes seem \nto be life and death. In slavery, for example, or severe political \noppression, the refusal to play the demanded role may be \npaid for with terrible suffering or death. \nEven in this last, extreme case we must still concede that \nwhoever takes up the commanded role does so by choice. \nCertainly the price for refusing it is high, but that there is \na price at all points to the fact that oppressors themselves \nacknowledge that even the weakest of their subjects must \nagree to be oppressed. If the subjects were unresisting puppets \nor automatons, no threat would be necessary, and no price \nwould be paid-thus the satire of the putative ideal of oppres-\nFINITE AND INFINITE GAMES \n11 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 196
  },
  {
    "chunk_full": "sors in Huxley's Gammas, Orwell's Proles, and Rossum's Uni-\nversal Robots (Capek). \nUnlike infinite play, finite play is limited from without; \nlike infinite play, those limitations must be chosen by the \nplayer since no one is under any necessity to play a finite \ngame. Fields of play simply do not impose themselves on \nus. Therefore, all the limitations of finite play are self-limita-\ntions. \n13 \nTo account for the large gap between the actual freedom \nof finite players to step off the field of play at any time and \nthe experienced necessity to stay at the struggle, we can say \nthat as finite players we somehow veil this freedom from our-\nselves. \nSome self-veiling is present in all finite games. Players must \nintentionally forget the inherently voluntary nature of their \nplay, else all competitive effort will desert them. \nFrom the outset of finite play each part or position must \nbe taken up with a certain seriousness; players must see them-\nselves as teacher, as light-heavyweight, as mother. In the \nproper exercise of such roles we positively believe we are the \npersons those roles portray. Even more: we make those roles \nbelievable to others. I t is in the nature of acting, Shaw said, \nthat we are not to see this woman as Ophelia, but Ophelia \nas this woman. \nIf the actress is so skillful that we do see Ophelia as this \nwoman, it follows that we do not see performed emotions \nand hear recited words, but a person's true feelings and speech. \nTo some extent the actress does not see herself performing \nbut feels her performed emotion and actually says her memo-\n12 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 197
  },
  {
    "chunk_full": "rized lines-and yet the very fact that they are performed \nmeans that the words and feelings belong to the role and \nnot to the actress. In fact, it is one of the requirements of \nher craft that she keep her own person distinct from the \nrole. What she feels as the person she is has nothing to do \nwith Ophelia and must not enter into her playing of the \npart. \nOf course, not for a second will this woman in her acting \nbe unaware that she is acting. She never forgets that she \nhas veiled herself sufficiently to play this role, that she has \nchosen to forget for the moment that she is this woman and \nnot Ophelia. But then, neither do we as audience forget we \nare audience. Even though we see this woman as Ophelia, \nwe are never in doubt that she is not. We are in complicity \nwith her veil. We allow her performed emotions to ~ffect \nus, perhaps powerfully. But we never forget that we allow \nthem to do so. \nSo it is with all roles. Only freely can one step into the \nrole of mother. Persons who assume this role, however, must \nsuspend their freedom with a proper seriousness in order to \nact as the role requires. A mother's words, actions, and feelings \nbelong to the role and not to the person-although some \npersons may veil themselves so assiduously that they make \ntheir performance believable even to themselves, overlooking \nany distinction between a mother's feelings and their own. \nThe issue here is not whether self-veiling can be avoided, \nor even should be avoided. Indeed, no finite play is possible \nwithout it. The issue is whether we are ever willing to .drop \nthe veil and openly acknowledge, if only to ourselves, that \nwe have freely chosen to face the world through a mask. \nConsider the actress whose skill at making Ophelia appear \nas this woman demonstrates the clarity with which she can \ndistinguish the role from herself. Is it not possible that when \nFINITE AND INFINITE GAMES \n13 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 198
  },
  {
    "chunk_full": "she leaves the stage she does not give up acting, but simply \nleaves off one role for another, say the role of \"actress,\" an \nabstracted personage whose public behavior is carefully \nscripted and produced? At which point do we confront the \nfact that we live one life and perform another, or others, \nattempting to make our momentary forgetting true and lasting \nforgetting? \nWhat makes this an issue is not the morality of masking \nourselves. It is rather that self-veiling is a contradictory act-\na free suspension of our freedom. I cannot forget that I have \nforgotten. I may have used the veil so successfully that I have \nmade my performance believable to myself. I may have con-\nvinced myself I am Ophelia. But credibility will never suffice \nto undo the contradictoriness of self-veiling. \"To believe is \nto know you believe, and to know you believe is not to believe\" \n(Sartre). \nIf no amount of veiling can conceal the veiling itself, the \nissue is how far we will go in our seriousness at self-veiling, \nand how far we will go to have others act in complicity with \nus. \n14 \nSince finite games can be played within an infinite game, \ninfinite players do not eschew the performed roles of finite \nplay. On the contrary, they enter into finite games with all \nthe appropriate energy and self-veiling, but they do so without \nthe seriousness of finite players. They embrace the abstractness \nof finite games as abstractness, and therefore take them up \nnot seriously, but playfully. (The term \"abstract\" is used here \naccording to Hegel's familiar definition of i.t as the substitution \nof a part of the whole for the whole, the whole being \"con-\n14 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 199
  },
  {
    "chunk_full": "crete.\") They freely use masks in their social engagements, \nbut not without acknowledging to themselves and others that \nthey are masked. For that reason they regard each participant \nin finite play as that person playing and not as a role played \nby someone. \nSeriousness is always related to roles, or abstractions. We \nare likely to be more serious with police officers when we \nfind them uniformed and performing their mandated roles \nthan when we find them in the process of changing into \ntheir uniforms. Seriousness always has to do with an established \nscript, an ordering of affairs completed somewhere outside \nthe range of our influence. We are playful when we engage \nothers at the level of choice, when there is no telling in advance \nwhere our relationship with them will come out-when, in \nfact, no one has an outcome to be imposed on the relationship, \napart from the decision to continue it. \nTo be playful is not to be trivial or frivolous, or to act as \nthough nothing of consequence will happen. On the contrary, \nwhen we are playful with each other we relate as free persons, \nand the relationship is open to surprise; everything that hap-\npens is of consequence. It is, in fact, seriousness that closes \nitself to consequence, for seriousness is a dread of the unpre-\ndictable outcome of open possibility. To be serious is to press \nfor a specified conclusion. To be playful is to allow for possibil-\nity whatever the cost to oneself. \nThere is, however, a familiar form of playfulness often asso-\nciated with situations protected from consequence-where no \nmatter what we do (within certain limits), nothing will come \nof it. This is not playing so much as it is playing at, a harmless \ndisregard for social constraints. While this is by no means \nexcluded from infinite play, it is not the same as infinite play. \nBy relating to others as they move out of their own freedom \nand not out of the abstract requirements of a role, infinite \nFINITE AND INFINITE GAMES \n15 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 200
  },
  {
    "chunk_full": "players are concrete persons engaged with concrete persons. \nFor that reason an infinite game cannot be abstracted, for \nit is not a part of the whole presenting itself as the whole, \nbut the whole that knows it is the whole. We cannot say a \nperson played this infinite game or that, as though the rules \nare independent of the concrete circumstances of play. It \ncan be said only that these persons played with each other \nand in such a way that what they began cannot be finished. \n15 \nInasmuch as a finite game is intended for conclusion, inas-\nmuch as its roles are scripted and performed for an audience, \nwe shall refer to finite playas theatrical. Although script and \nplot do not seem to be written in advance, we are always \nable to look back at the path followed to victory and say of \nthe winners that they certainly knew how to act and what \nto say. \nInasmuch as infinite players avoid any outcome whatsoever, \nkeeping the future open, making all scripts useless, we shall \nrefer to infinite playas dramatic. \nDramatically, one chooses to be a mother; theatrically, one \ntakes on the role of mother. \n16 \nOne obeys the rules in a finite game in order to play, but \nplaying does not consist only in obeying rules. \nThe rules of a finite game do not constitute a scr~pt. A \nscript is composed according to the rules but is not identical \nto the rules. The script is the record of the actual exchanges \n16 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 201
  },
  {
    "chunk_full": "between players-whether acts or words-and therefore can-\nnot be written down beforehand. In all true finite play the \nscripts are composed in the course of play. \nThis means that during the game all finite play is dramatic, \nsince the outcome is yet unknown. That the outcome is not \nknown is what makes it a true game. The theatricality of \nfinite play has to do with the fact that there is an outcome. \nFinite play is dramatic, but only provisionally dramatic. \nAs soon as it is concluded we are able to look backward and \nsee how the sequence of moves, though made freely by the \ncompetitors, could have resulted only in this outcome. We \ncan see how every move fit into a sequence that made it \ninevitable that this player would win. \nThe fact that a finite game is provisionally dramatic means \nthat it is the intention of each player to eliminate its drama \nby making a preferred end inevitable. It is the desire of all \nfinite players to be Master Players, to be so perfectly skilled \nin their play that nothing can surprise them, so perfectly \ntrained that every move in the game is foreseen at the begin-\nning. A true Master Player plays as though the game is already \nin the past, according to a script whose every detail is known \nprior to the play itself. \n17 \nSurprise is a crucial element in most finite games. If we \nare not prepared to meet each of the possible moves of an \nopponent, our chances of losing are most certainly increased. \nIt is therefore by surprising our opponent that we are most \nlikely to win. Surprise in finite play is the triumph of the \npast over the future. The Master Player who already knows \nwhat moves are to be made has a decisive advantage over \nFINITE AND INFINITE GAMES \n17 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 202
  },
  {
    "chunk_full": "the unprepared player who does not yet know what moves \nwill be made. \nA finite player is trained not only to anticipate every future \npossibility, but to control the future, to prevent it from altering \nthe past. This is the finite player in the mode of seriousness \nwith its dread of unpredictable consequence. \nInfinite players, on the other hand, continue their play in \nthe expectation of being surprised. If surprise is no longer \npossible, all play ceases. \nSurprise causes finite play to end; it is the reason for infinite \nplay to continue. \nSurprise in infinite play is the triumph of the future over \nthe past. Since infinite players do not regard the past as having \nan outcome, they have no way of knowing what has been \nbegun there. With each surprise, the past reveals a new begin-\nning in itself. Inasmuch as the future is always surprising, \nthe past is always changing. \nBecause finite players are trained to prevent the future from \naltering the past, they must hide their future moves. The \nunprepared opponent must be kept unprepared. Finite players \nmust appear to be something other than what they are. Every-\nthing about their appearance must be concealing. To appear \nis not to appear. All the moves of a finite player must be \ndeceptive: feints, distractions, falsifications, misdirections, \nmystifications. \nBecause infinite players prepare themselves to be surprised \nby the future, they play in complete openness. It is not an \nopenness as in candor, but an openness as in vulnerability. \nIt is not a matter of exposing one's unchanging identity, the \ntrue self that has always been, but a way of exposing one's \nceaseless growth, the dynamic self that has yet to be. The \ninfinite player does not expect only to be amused by surprise, \n18 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 203
  },
  {
    "chunk_full": "but to be transformed by it, for surprise does not alter some \nabstract past, but one's own personal past. \nTo be prepared against surprise is to be trained. To be \nprepared for surprise is to be educated. \nEducation discovers an increasing richness in the past, be-\ncause it sees what is unfinished there. Training regards the \npast as finished and the future as to be finished. Education \nleads toward a continuing self-discovery; training leads toward \na final self-definition. \nTraining repeats a completed past in the future. Education \ncontinues an unfinished past into the future. \n18 \nWhat one wins in a finite game is a title. \nA title is the acknowledgment of others that one has been \nthe winner of a particular game. Titles are public. They are \nfor others to notice. I expect others to address me according \nto my titles, but I do not address myself with them-unless, \nof course, I address myself as an other. The effectiveness of \na title depends on its visibility, its noticeabilit~, to others. \n19 \nAny given finite game can be played many times, although \neach occasion of its occurrence is unique. The game that \nwas played at that time by those players can never be played \nagam. \nSince titles are ~imeless , but exist only so far as they are \nacknowledged, we must find means to guarantee the memory \nFINITE AND INFINITE GAMES \n19 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 204
  },
  {
    "chunk_full": "of them. The birettas of dead cardinals are suspended from \nthe ceilings of cathedrals, as it were forever; the numbers of \ngreat athletes are \"retired\" or withdrawn from all further play; \ngreat achievements are carved in imperishable stone or memo-\nrialized by perpetual flames. \nSome titles are inherited, though only when the bloodline \nor some other tangible connection with the original winner \nhas been established, suggesting that the winners have contin-\nued to exist in their descendants. The heirs to titles are there-\nfore obliged to display the appropriate emblems: a coat of \narms or identifiable styles of speech, clothing, or behavior. \nI t is a principal function of society to validate titles and \nto assure their perpetual recognition. \n20 \nIt is in connection with the timelessness of titles that we \ncan first discern the importance of death to both finite and \ninfinite game!) and the great difference between the ways death \nis understo.cd in each. \nA finite game must always be won with a terminal move, \na final act within the boundaries of the game that establishes \nthe winner beyond any possibility of challenge. A terminal \nmove results, in other words, in the death of the opposing \nplayer as player. The winner kills the opponent. The loser \nis dead in the sense of being incapable of further play. \nProperly speaking, life and death as such are rarely the \nstakes of a finite game. What one wins is a title; and when \nthe loser of a finite game is declared dead to further play, it \nis equivalent to declaring that person utterly without title-\n20 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 205
  },
  {
    "chunk_full": "a person to whom no attention whatsoever need be given. \nDeath, in finite play, is the triumph of the past over the \nfuture, a condition in which no surprise is possible. \nFor this reason, death for a finite player need have nothing \nto do with the physical demise of the body; it is not a reference \nto a corporeal state. There are two ways in which death is \ncommonly associated with the fate of the body: One can be \ndead in life, or one can be alive in death. \nDeath in life is a mode of existence in which one has ceased \nall play; there is no further striving for titles. All competitive \nengagement with others has been abandoned. For some, \nthough not for all, death in life is a misfortune, the resigned \nacceptance of a loser's status, a refusal to hold any title up \nfor recognition. For others, however, death in life can be \nregarded as an achievement, the result of a spiritual discipline, \nsay, intended to extinguish all traces of struggle with the world, \na liberation from the need for any title whatsoever. \"Die before \nye die,\" declare the Sufi mystics. \nLife in death concerns those who are titled and whose \ntitles, since they are timeless, may not be extinguished by \ndeath. Immortality, in this case, is not a reward but the condi-\ntion necessary to the possession of rewards. Victors live forever \nnot because their souls are unaffected by death but because \ntheir titles must not be forgotten. \nIt was not merely the souls of the Egyptian pharaohs that \npassed on into the afterlife, but their complete offices and \nroles, along with all the tangible reminders of their earthly \ntriumphs-including servants put to death that they might \naccompany their titled masters into eternity. For Christian \nsaints \"death has lost its sting\" not because there is something \ninherently imperishable in the human soul, but because they \nFINITE AND INFINITE GAMES \n21 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 206
  },
  {
    "chunk_full": "have fought the good fight, and they have successfully pressed \non \"toward the goal for the prize of the upward caiI of God \nin Christ Jesus\" (Paul). \nSoldiers commonly achieve a life in death. Soldiers fight \nnot to stay alive but to save the nation. Those who do fight \nonly to protect themselves are, in fact, considered guilty of \nthe highest military crimes. Soldiers who die fighting the en-\nemy, however, receive the nation's highest reward: They are \ndeclared unforgettable. Even unknown soldiers are memorial-\nized-though their names have been lost, their titles will not \nbe. \nWhat the winners of finite games achieve is not properly \nan afterlife but an afterworld, not continuing existence but \ncontinuing recognition of their titles. \n21 \nThere are games in which the stakes do seem to be life \nand death. \nExtreme forms of bondage sometimes ofter persons the priv-\nilege of staying alive in exchange for their play-and death \nfor refusing to play. There is, however, something odd in \nthis exchange. A slave does not so much receive a life as \ngive a life-a life whose only function is to reflect the master's \nsuperiority. The slave's life is the property of the master; the \nslave exists only as an emblem of the master's prior victories. \nA slave can have life only by giving it away. \"He who \nloves his life loses it, and he who hates his life in this world \nwill keep it for eternal life\" (Jesus). \nPerhaps a more common example of such life-or-death forms \nof bondage is found in those persons who resort to expensive \nmedical strategies to be cured of life-threatening illness. They, \n22 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 207
  },
  {
    "chunk_full": "too, seem to be giving life away in order to win it back. So \nalso are those who observe special diets or patterns of life \ndesigned to prolong their youth and to postpone aging and \ndeath indefinitely; they hate their life in this world now in \norder that they may have it later. And just as with slaves, \nthe life they receive is given to them by others: doctors, yogis, \nor their anonymous admirers. \nWhen life is viewed by a finite player as the award to be \nwon, then death is a token of defeat. Death is not, therefore, \nchosen, but inflicted. It happens to one when the struggle \nagainst it fails. Death comes as a judgment, a dishonor, a \nsign of certain weakness. Death for the finite player is deserved, \nearned. \"The wages of sin is death\" (Paul). \nIf the losers are dead, the dead are also losers. \nThere is a contradiction here: If the prize for winning finite \nplay is life, then the players are not properly alive. They are \ncompeting for life. Life, then, is not play, but the outcome \nof play. Finite players play to live; they do not live their \nplaying. Life is therefore deserved, bestowed, possessed, won. \nI t is not lived. \"Life itself appears only as a means to life\" \n(Marx). \nThis is a contradiction common to all finite play. Because \nthe purpose of a finite game is to bring play to an end with \nthe victory of one of the players, each finite game is played \nto end itself. The contradiction is precisely that all finite play \nis play against itself. \n22 \nDeath, for finite players, is abstract, not concrete. It is \nnot the whole person, but only an abstracted fragment of \nthe whole, that dies in life or lives in death. \nFINITE AND INFINITE GAMES \n23 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 208
  },
  {
    "chunk_full": "So aL is life abstract for finite players. It is not the whole \nperson who lives. If life is a means to life, we must abstract \nourselves, but only for the sake of winning an abstraction. \nImmortality, therefore, is the triumph of such abstraction. \nIt is a state of unrelieved theatricality. An immortal soul is \na person who cannot help but continue living out a role already \nscripted. An immortal person could not choose to die nor, \nfor the same reason, choose to live. Immortality is serious \nand in no way playful. One's actions can have no consequence \nbeyond themselves. There are no surprises in the afterworld. \nOf course, immortality of the soul-the bare soul, cleansed \nof any personality traces-is rarely what is desired in the yearn-\ning for immortality. \"The information that my soul is to last \nforever could then be of no more personal concern to me \nthan the news that my appendix is to be preserved eternally \nin a bottle\" (Flew). More often what one intends to preserve \nis a public personage, a permanently veiled selfhood. Immortal-\nity is the state of forgetting that we have forgotten-that \nis, overlooking the fact that we freely decided to enter into \nfinite play, a decision in itself playful and not serious. \nImmortality is therefore the supreme example of the contra-\ndictoriness of finite play: It is a life one cannot live. \n23 \nInfinite players die. Since the boundaries of death are always \npart of the play, the infinite player does not die at the end \nof play, but in the course of play. \nThe death of an infinite player is dramatic. It does not \nmean that the game comes to an end with death; on the \ncontrary, infinite players offer their death as a way of continu-\ning the play. For that reason they do not play for their own \n24 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 209
  },
  {
    "chunk_full": "life; they live for their own play. But since that play is always \nwith others, it is evident that infinite players both live and \ndie for the continuing life of others. \nWhere the finite player plays for immortality, the infinite \nplayer plays as a mortal. In infinite play one chooses to be \nmortal inasmuch as one always plays dramatically, that is, \ntoward the open, toward the horizon, toward surprise, where \nnothing can be scripted. It is a kind of play that requires \ncomplete vulnerability. To the degree that one is protected \nagainst the future, one has established a boundary and no \nlonger plays with but against others. \nDeath is a defeat in finite play. It is inflicted when one's \nboundaries give way and one falls to an opponent. The finite \nplayer dies under the terminal move of another. \nAlthough infinite players choose mortality, they may not \nknow when death comes, but we can always say of them \nthat \"they die at the right time\" (Nietzsche). \nThe finite play for life is serious; the infinite play of life \nis joyous. Infinite play resounds throughout with a kind of \nlaughter. It is not a laughter at others who have come to an \nunexpected end, having thought they were going somewhere \nelse. I t is laughter with others with whom we have discovered \nthat the end we thought we were coming to has unexpectedly \nopened. We laugh not at what has surprisingly come to be \nimpossible for others, but over what has surprisingly come \nto be possible with others. \n24 \nInfinite play is inherently paradoxical, just as finite play is \ninherently contradictory. Because it is the purpose of infinite \nplayers to continue the play, they do not play for themselves. \nFINITE AND INFINITE GAMES \n25 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 210
  },
  {
    "chunk_full": "The contradiction of finite play is that the players desire to \nbring play to an end for themselves. The paradox of infinite \nplay is that the players desire to continue the play in others. \nThe paradox is precisely that they play only when others go \non with the game. \nInfinite players play best when they become least necessary \nto the continuation of play. It is for this reason they playas \nmortals. \nThe joyfulness of infinite play, its laughter, lies in learning \nto start something we cannot finish. \n25 \nIf finite players acquire titles from winning their games, \nwe must say of infinite players that they have nothing but \ntheir names. \nNames, like titles, are given. Persons cannot name them-\nselves any more than they can entitle themselves. However, \nunlike titles, which are given for what a person has done, a \nname is given at birth-at a time when a person cannot yet \nhave done anything. Titles are given at the end of play, names \nat the beginning. \nWhen a person is known by title, the attention is on a \ncompleted past, on a game already concluded, and not there-\nfore to be played again. A title effectively takes a person out \nof play. \nWhen a person is known only by name, the attention of \nothers is on an open future. We simply cannot know what \nto expect. Whenever we address each other by name we ignore \nall scripts, and open the possibility that our relationship will \nbecome deeply reciprocal. That I cannot now predict your \nfuture is exactly what makes mine unpredictable. Our futures \n26 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 211
  },
  {
    "chunk_full": "enter into each other. What is your future, and mine, becomes \nours. We prepare each other for surprise. \nTitles are abstractions; names are always concrete. \nIt can happen that when persons are distinctly identified \nas winners their names can have the force of titles. We some-\ntimes act \"to clear our name\" of aspersions, or to defend \nthe \"good name of our family.\" Names can even become \ntitles in the formal sense, such as \"Caesar,\" or \"Napoleon,\" \nor \"the name of Jesus which is above every name\" (Paul). \nWhen Jesus is regarded by way of a title instead of a name, \nhe becomes an abstracted, theatrical role, a person with whom \nwe can share no future, rather a Master Player in whose future \nwe live in a manner that has already been scripted, or decided, \nfor us. \"Before Abraham was, I am,\" Jesus said of himself \nin the Gospel of John. \n26 \nTitles, then, point backward in time. They have their origin \nin an unrepeatable past. \nTitles are theatrical. Each title has a specified ceremonial \nform of address and behavior. Titles such as Captain, Mrs., \nLord, Esquire, Professor, Comrade, Father, Under Secretary, \nsignal not only a mode of address with its appropriate defer-\nence or respect, but also a content of address (only certain \nsubjects are suitable for discussion with the Admiral of the \nFleet or the District Attorney or the Holy Mother), and a \nmanner of address (shaking hands, kneeling, prostrating or \ncrossing oneself, saluting, bowing, averting the eyes, or stand-\ning in silence). \nThe mode and content of address and the manner of behav-\nior are recognitions of the areas in which titled persons are \nFINITE AND INFINITE GAMES \n27 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 212
  },
  {
    "chunk_full": "no longer in competition. There are precise ways in. which \none may no longer compete with the Dalai Lama or the Heavy-\nweight Champion of the World. There is no possible action \nby which one may deprive them of their titles to contests \nnow in the past. Therefore, insofar as we recognize their titles \nwe withdraw from any contest with them in those areas. \n27 \nThe titled are powerful. Those around them are expected \nto yield, to withdraw their opposition, and to conform to \ntheir will-in the arena in which the title was won. \nThe exercise of power always presupposes resistance. Power \nis never evident until two or more elements are in opposition. \nWhichever element can move another is the more powerful. \nIf no one else ever strove to be a Boddhisattva or the Baton \nTwirling Champion of the State of Indiana, those titles would \nbe powerless-no one would defer to them. \nThe exercise of power also presupposes a closed field and \nfinite units of time. My power is determined by the amount \nof resistance I can displace within given spatial and temporal \nlimits. The question is not whether I can lift ten pounds, \nbut whether I can lift ten pounds five feet off the ground \nin one second--{)r within some other precise limitation of \ntime and space. The establishment of the limits makes it \npossible to know how powerful I am in relation to others. \nPower is always measured in units of comparison. In fact, \nit is a term of competition: How much resistance can I over-\ncome relative to others? \nPower is a concept that belongs only in finite play. But \npower is not properly measurable until the game is com-\npleted-until the designated period of time has run out. Dur-\n28 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 213
  },
  {
    "chunk_full": "ing the course of play we cannot yet determine the power \nof the players, because to the degree that it is genuine play \nthe outcome is unknown. A player who is being pushed all \nover the field by an apparently superior opponent may display \nan unsuspected burst of activity at the end and take the victory. \nUntil the final hours of the count in the presidential election \nof 1948 many Americans thought that Harry Truman was a \nfar weaker candidate than Thomas Dewey. \nTo speak meaningfully of a person's power is to speak of \nwhat that person has already completed in one or another \nclosed field. To see power is to look backward in time. \nInasmuch as power is determined by the outcome of a \ngame, one does not win by being powerful; one wins to be \npowerful. If one has sufficient power to win before the game \nhas begun, what follows is not a game at all. \nOne can be powerful only through the possession of an \nacknowledged title-that is, only by the ceremonial deference \nof others. Power is never one's own, and in that respect it \nshows the contradiction inherent in all finite play. I can be \npowerful only by not playing, by showing that the game is \nover. I can therefore have only what powers others give me. \nPower is bestowed by an audience after the play is complete. \nPower is contradictory, and theatrical. \n28 \nIt may seem implausible to claim that power is a matter \nof deference to titles. If anything appears to be a permanent \nfeature of reality it is power-the constant impingement on \nus of superior forces both without and within. Everything \nfrom changes in the weather and acts of national governments \nto the irresistible push of instinct and the process of aging \nFINITE AND INFINITE GAMES \n29 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 214
  },
  {
    "chunk_full": "seems to confirm us as helpless creatures of circumstance-\nand to that degree powerless. It seems plainly false to say \nthat power is theatrical. \nAnd yet, the theatrical nature of power seems to be consis-\ntent with the principle arrived at earlier: Whoever must play \ncannot play. The intuitive idea in that principle is that no \none can engage us competitively unless we fully cooperate, \nunless we join the game and join it to win. Because power \nis measurable only in comparative-that is, competitive-\nterms, it presupposes some kind of cooperation. If we defer \nto titled winners, it is only because we regard ourselves as \nlosers. To do so is freely to take part in the theater of power. \nThere certainly are acts of government, or acts of nature, \nor acts of god that far exceed any contravening ability of \nour own, but it is unlikely that we would consider ourselves \nlosers in relation to them. We are not defeated by floods or \ngenetic disease or the rate of inflation. It is true that these \nare real, but we do not play against reality; we play according \nto reality. We do not eliminate weather or genetic influence \nbut accept them as the realities that establish the context \nof play, the limits within which we are to play. \nIf I accept death as inevitable, I do not struggle against \nmortality. I struggle as a mortal. \nAll the limitations of finite play are self-limitations. \n29 \nPower is a feature only of finite games. It is not dramatic \nbut theatrical. How then do infinite players contend with \npower? Infinite play is always dramatic; its outcome is endlessly \nopen. There is no way of looking back to make a definitive \nassessment of the power or weakness of earlier play. Infinite \n30 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 215
  },
  {
    "chunk_full": "players look forward, not to a victory in which the past will \nachieve a timeless meaning, but toward ongoing play in which \nthe past will require constant reinterpretation. Infinite players \ndo not oppose the actions of others, but initiate actions of \ntheir own in such a way that others will respond by initiating \ntheir own. \nWe need a term that will stand in contrast to \"power\" \nas it acquires its meaning in finite play. Let us say that where \nthe finite player plays to be powerful the infinite player plays \nwith strength. \nA powerful person is one who brings the past to an outcome, \nsettling all its unresolved issues. A strong person is one who \ncarries the past into the future, showing that none of its issues \nis capable of resolution. Power is concerned with what has \nalready happened; strength with what has yet to happen. \nPower is finite in amount. Strength cannot be measured, be-\ncause it is an opening and not a closing act. Power refers to \nthe freedom persons have within limits, strength to the free-\ndom persons have with limits. \n_ \nPower will always be restricted to a relatively small number \nof selected persons. Anyone can be strong. \nStrength is paradoxical. I am not strong because I can force \nothers to do what I wish as a result of my play with them, \nbut because I can allow them to do what they wish in the \ncourse of my play with them. \n30 \nAlthough anyone who wishes can be an infinite player, and \nalthough anyone can be strong, we are not to suppose that \npower cannot work irremediable damage on infinite play. Infi-\nnite play cannot prevent or eliminate evil. Though infinite \nFINITE AND INFINITE GAMES \n31 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 216
  },
  {
    "chunk_full": "players are strong, they are not powerful and do not attempt \nto become powerful. \nEvil is the termination of infinite play. It is infinite play \ncoming to an end in unheard silence. \nUnheard silence does not necessarily mean the death of \nthe player. Unheard silence is not the loss of the player's \nvoice, but the loss of listeners for that voice. It is an evil \nwhen the drama of a life does not continue in others for \nreason of their deafness or ignorance. \nThere are silences that can be heard, even from the dead \nand from the severely oppressed. Much is recoverable from \nan apparently forgotten past. Sensitive and faithful historians \ncan learn much of what has been lost, and much therefore \nthat can be continued. \nThere are silences, however, that will never and can never \nbe heard. There is much evil that remains beyond redemption. \nWhen Europeans first landed on the North American conti-\nnent the native population spoke as many as ten thousand \ndistinct languages, each with its own poetry and treasury of \nhistories and myths, its own ways of living in harmony with \nthe spontaneities of the natural environment. All but a very \nfew of those tongues have been silenced, their cultures forever \nlost to those of us who stand ignorantly in their place. \nEvil is not the termination of a finite game. Finite players, \neven those who play for their own lives, know the stakes of \nthe games they freely choose to play. \nEvil is not the attempt to eliminate the play of another \naccording to published and accepted rules, but to eliminate \nthe play of another regardless of the rules. Evil is not the \nacquisition of power, but the expression of power. It is the \nforced recognition of a title-and therein lies the contradiction \nof evil, for recognition cannot be forced. The Nazis did not \ncompete with the Jews for a title, but demanded recognition \n32 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 217
  },
  {
    "chunk_full": "of a title without competition. This could be achieved, how-\never, only by silencing the Jews, only by hearing nothing from \nthem. They were to die in silence, along with their culture, \nwithout anyone noticing, not even those who managed the \ninstitutions and instruments of death. \n31 \nEvil is never intended as evil. Indeed, the contradiction \ninherent in all evil is that it originates in the desire to eliminate \nevil. \"The only good Indian is a dead Indian.\" \nEvil arises in the honored belief that history can be tidied \nup, brought to a sensible conclusion. I t is evil to act as though \nthe past is bringing us to a specifiable end. It is evil to assume \nthat the past will make sense only if we bring it to an issue \nwe have clearly in view. It is evil for a nation to believe it \nis \"the last, best hope on earth.\" It is evil to think history \nis to end with a return to Zion, or with the classless society, \nor with the Islamicization of all living infidels. \nYour history does not belong to me. We live with each \nother in a common history. \nInfinite players understand the inescapable likelihood of \nevil. They therefore do not attempt to eliminate evil in others, \nfor to do so is the very impulse of evil itself, and therefore \na contradiction. They only attempt paradoxically to recognize \nin themselves the evil that takes the form of attempting to \neliminate evil elsewhere. \nEvil is not the inclusion of finite games in an infinite game, \nbut the restriction of all play to one or another finite game. \nFINITE AND INFINITE GAMES \n33 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 218
  },
  {
    "chunk_full": "",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 219
  },
  {
    "chunk_full": "TWO \nNo ONE CAN \nPLAY A GAME \nALONE \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 220
  },
  {
    "chunk_full": "",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 221
  },
  {
    "chunk_full": "32 \nNo ONE CAN PLAya game alone. One cannot be human by \noneself. There is no selfhood where there is no community. \nWe do not relate to others as the persons we are; we are \nwho we are in relating to others. \nSimultaneously the others with whom we are in relation \nare themselves in relation. We cannot relate to anyone who \nis not also relating to us. Our social existence has, therefore, \nan inescapably fluid character. This is not to say that we \nlive in a fluid context, but that our lives are themselves fluid. \nAs in the Zen image we are not the stones over which the \nstream of the world flows; we are the stream itself. As we \nshall see, this ceaseless change does not mean discontinuity; \nrather change is itself the very basis of our continuity as per-\nsons. Only that which can change can continue: this is the \nprinciple by which infinite players live. \nThe fluidity of our social and therefore personal existence \nis a function of our essential freedom-the kind of freedom \nindicated in the formula \"Who must play, cannot play.\" Of \ncourse, as we have seen, finite games cannot have fluid bound-\naries, for if they do it will be impossible to agree on winners. \nBut finite games float, as it were, in the unconstrained choice \neach player makes in entering and continuing the play. Finite \nFINITE AND INFINITE GAMES \n37 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 222
  },
  {
    "chunk_full": "games sometimes appear, therefore, to have fixed points of \nsocial reference. Not only are there true and false ways of \nloving your country, for example; there is a positive require-\nment that you do so. \nIt is this essential fluidity of our humanness that is irreconcil-\nable with the seriousness of finite play. It is, therefore, this \nfluidity that presents us with an unavoidable challenge: how \nto contain the serious within the truly playful; that is, how \nto keep all our finite games in infinite play. \nThis challenge is commonly misunderstood as the need to \nfind room for playfulness within finite games. This is what \nwas referred to above as playing at, or perhaps playing around, \na kind of play that has no consequence. This is the sort of \nplayfulness implied in the ordinary sense of such terms as \nentertainment, amusement, diversion, comic relief, recreation, \nrelaxation. Inevitably, however, seriousness will creep back into \nthis kind of play. The executive's vacation, like the football \nteam's time out, comes to be a device for refreshing the contes-\ntant for a higher level of competition. Even the open playful-\nness of children is exploited through organized athletic, \nartistic, and educational regimens as a means of preparing \nthe young for serious adult competition. \n33 \nWhen Bismarck described politics as the art of the possible, \nhe meant, of course, that the possible is to be found somewhere \nwithin fixed limits, within social realities. He plainly did not \nmean that the possible extended to those limits themselves. \nSuch a politics is therefore seriousness itself, especially since \npoliticians of nearly every ideology represent themselves as \nchampions of freedom, doing what is necessary and even dis-\n38 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 223
  },
  {
    "chunk_full": "tasteful toward the end of enlarging the range of the possible. \n\"We must learn the fine arts of war and independence so \nthat our children can learn architecture and engineering so \nthat their children may learn the fine arts and painting\" (John \nQuincy Adams). \nThe interest of infinite players has little in common with \nsuch politics, since they are not concerned to find how much \nfreedom is available within the given realities-for this is free-\ndom only in the trivial sense of playing at-but are concerned \nto show how freely we have decided to place these particular \nboundaries around our finite play. They remind us that political \nrealities do not precede, but follow from, the essential fluidity \nof our humanness. \nThis does not mean that infinite players are politically disen-\ngaged; it means rather that they are political without having \na politics, a paradoxical position easily misinterpreted. To have \na politics is to have a set of rules by which one attempts to \nreach a desired end; to be political-in the sense meant here-\nis to recast rules in the attempt to eliminate all societal ends, \nthat is, to maintain the essential fluidity of human association. \nTo be political in the mode of infinite play is by no means \nto disregard the appalling conditions under which many hu-\nman beings live, the elimination of which is the professed \nend of much politics. We can imagine infinite players nodding \nthoughtfully at Rousseau's famous declaration: \"Man is born \nfree, and everywhere he is in chains.\" They can see that the \ndream of freedom is universal, that wars are fought to win \nit, heroes die to protect it, and songs are written to commemo-\nrate its attainment. But in the infinite player's vision of politi-\ncal affairs the element of intentionality and willfulness, so \neasily obscured in the exigencies of public crisis, stands out \nin clear relief. Therefore, even warfare and heroism are seen \nwith their self-contradictions in full display. No nation can \n, \nFINITE AND INFINITE GAMES \n39 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 224
  },
  {
    "chunk_full": "go to war until it has found another that can agree to the \nterms of the conflict. Each side must therefore be in complicity \nwith the other: Before I can have an enemy, I must persuade \nanother to recognize me as an enemy. I cannot be a hero \nunless I can first find someone who will threaten my life-\nor, better, take my life. Once under way, warfare and acts \nof heroism have all the appearance of necessity, but that ap-\npearance is but a veil over the often complicated maneuvers \nby which the antagonists have arranged their conflict with \neach other. \nTherefore, for infinite players, politics is a form of theatrical-\nity. It is the performance of roles before an audience, according \nto a script whose last scene is known in advance by the perform-\ners. The United States did not, for example, lose its war in \nSoutheast Asia so much as lose its audience for a war. No \ndoubt much of the disillusion and bitterness of its warriors \ncomes from the missing final scene-the hero's homecoming \nto parades or ceremonial burial-an anticipated scene that \ncarries many into battle. \nIt is because of the essential theatricality of politics that \ninfinite players do not take sides in political issues-at least \nnot seriously. Instead they enter into social conflict dramati-\ncally, attempting to offer a vision of continuity and open-\nendedness in place of the heroic final scene. In doing so they \nmust at the very least draw the attention of other political \nparticipants not to what they feel they must do, but to why \nthey feel they must do it. \nIn their own political engagements infinite players make \na distinction between society and culture. Society they under-\nstand as the sum of those relations that are under some form \nof public constraint, culture as whatever we do with each \nother by undirected choice. If society is all that a people \nfeels it must do, culture \"is the realm of the variable, free, \n40 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 225
  },
  {
    "chunk_full": "not necessarily universal, of all that cannot lay claim to compul-\nsive authority\" (Burckhardt). \nThe infinite player's understanding of society is not to be \nconfused with, say, natural instinct, or any other form of invol-\nuntary activity. Society remains entirely within our free choice \nin quite the same way that finite competition, however strenu-\nous or costly to the player, never prevents the player from \nwalking off the field of play. Society applies only to those \nareas of action which are believed to be necessary. \nJust as infinite play cannot be contained within finite play, \nculture cannot be authentic if held within the boundaries \nof a society. Of course, it is often the strategy of a society \nto initiate and embrace a culture as exclusively its own. Culture \nso bounded may even be so lavishly subsidized and encouraged \nby society that it has the appearance of open-ended activity, \nbut in fact it is designed to serve societal interests in every \ncase-like the socialist realism of Soviet art. \nSociety and culture are therefore not true opponents of \neach other. Rather society is a species of culture that persists \nin contradicting itself, a freely organized attempt to conceal \nthe freedom of the organizers and the organized, an attempt \nto forget that we have willfully forgotten our decision to enter \nthis or that contest and to continue in it. \n34 \nIf we think of society as all that a people does under the \nveil of necessity, we must also think of it as a single finite \ngame that includes any number of smaller games within its \nboundaries. \nA large society will consist of a wide variety of games-\nthough all somehow connected, inasmuch as they have a bear-\nFINITE AND INFINITE GAMES \n41 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 226
  },
  {
    "chunk_full": "ing on a final societal ranking. Schools are a species of finite \nplay to the degree that they bestow ranked awards on those \nwho win degrees from them. Those awards in turn qualify \ngraduates for competition in still higher games-certain presti-\ngious colleges, for example, and then certain professional \nschools beyond that, with a continuing sequence of higher \ngames in each of the professions, and so forth. It is not uncom-\nmon for families to think of themselves as a competitive unit \nin a broader finite game for which they are training their \nmembers in the struggle for societally visible titles. \nLike a finite game, a society is numerically, spatially, and \ntemporally limited. Its citizenship is precisely defined, its \nboundaries are inviolable, and its past is enshrined. \nThe power of citizens in a society is determined by their \nranking in games that have been played. A society preserves \nits memory of past winners. Its record-keeping functions are \ncrucial to societal order. Large bureaucracies grow out of the \nneed to verify the numerous entitlements of the citizens of \nthat society. \nThe power of a society is determined by its victory over \nother societies in still larger finite games. Its most treasured \nmemories are those of the heroes fallen in victorious battles \nwith other societies. Heroes of lost battles are almost never \nmemorialized. Foch has his monument, but not Petain; Lin-\ncoln, but not Jefferson Davis; Lenin, but not Trotsky. \nThe power in a society is guaranteed and enhanced by \nthe power of a society. \nThe prizes won by its citizens can be protected only if \nthe society as a whole remains powerful in relation to other \nsocieties. Those who desire the permanence of their prizes \nwill work to sustain the permanence of the whole. Patriotism \nin one or several of its many forms (chauvinism, racism, sexism, \nnationalism, regionalism) is an ingredient in all societal play. \n42 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 227
  },
  {
    "chunk_full": "Because power is inherently patriotic, it is characteristic \nof finite players to seek a growth of power in a society as a \nway of increasing the power of a society. It is in the interest \nof a society therefore to encourage competition within itself, \nto establish the largest possible number of prizes, for the hold-\ners of prizes will be those most likely to defend the society \nas a whole against its competitors. \n35 \nCulture, on the other hand, is an infinite game. Culture \nhas no boundaries. Anyone can be a participant in a culture-\nanywhere and at any time. \nBecause a society maintains careful temporal limits, it under-\nstands its past as destiny; that is, its course of history lies \nbetween a definitive beginning (the founders of a society are \nalways especially memorialized) and a definitive ending. (The \nnature of its victory is repeatedly anticipated in official declara-\ntions; \"to each according to their need, from each according \nto their ability,\" for example.) \nBecause culture as such can have no temporal limits, a \nculture understands its past not as destiny, but as history, \nthat is, as a narrative that has begun but points always toward \nthe endlessly open. Culture is an enterprise of mortals, disdain-\ning to protect themselves against surprise. Living in the \nstrength of their vision, they eschew power and make joyous \nplay of boundaries. \nSociety is a manifestation of power. It is theatrical, having \nan established script. Deviations from the script are evident \nat once. Deviation is antisocietal and therefore forbidden by \nsociety under a variety of sanctions. I t is easy to see why \ndeviancy is to be resisted. If persons did not adhere to the \nFINITE AND INFINITE GAMES \n43 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 228
  },
  {
    "chunk_full": "standing rules of the society, any number of rules would \nchange, and some would be dropped altogether. This would \nmean that past winners no longer warrant ceremonial recogni-\ntion of their titles and are therefore without power-like Rus-\nsian princes after the Revolution. \nI t is a highly valued function of society to prevent changes \nin the rules of the many games it embraces. Such procedures \nas academic accreditation, licensure of trades and professions, \nsynodical ordination, parliamentary confirmation of official ap-\npointments, and the inauguration of political leaders are acts \nof the larger society allowing persons to compete in the finite \ngames within it. \nDeviancy, however, is the very essence of culture. Whoever \nmerely follows the script, merely repeating the past, is cultur-\nally impoverished. \n. \nThere are variations in the quality of deviation; not all diver-\ngence from the past is culturally significant. Any attempt to \nvary from the past in such a way as to cut the past off, causing \nit to be forgotten, has little cultural importance. Greater signif-\nicance attaches to those variations that bring the tradition \ninto view in a new way, allowing the familiar to be seen as \nunfamiliar, as requiring a new appraisal of all that we have \nbeen-and therefore of all that we are. \nCultural deviation does not return us to the past, but contin-\nues what was begun and not finished in the past. Societal \nconvention, on the other hand, requires that a completed \npast be repeated in the future. Society has all the seriousness \nof immortal necessity; culture resounds with the laughter of \nunexpected possibility. Society is abstract, culture concrete. \nFinite games can be played again; they can be played an \nindefinite number of times. It is true that the winners of a \ngame are always the winners of a game played at that particular \ntime, but the validity of their titles depends on the repeatabil-\n44 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 229
  },
  {
    "chunk_full": "ity of that game. We memorialize early football greats but \nwould not do so if football had vanished after its first decade. \nAs we have seen, because an infinite game cannot be brought \nto an end, it cannot be repeated. Unrepeatability is a character-\nistic of culture everywhere. Mozart's Jupiter Symphony cannot \nbe composed again, nor could Rembrandt's self-portraits be \npainted twice. Society preserves these works as the prizes of \nthose who have triumphed in their respective games. Culture, \nhowever, does not consider the works as the outcome of a \nstruggle, but as moments in an ongoing struggle-the very \nstruggle that culture is. Culture continues what Mozart and \nRembrandt had themselves continued by way of their work: \nan original, or deviant, shaping of the tradition they received, \noriginal enough that it does not invite duplication of itself \nby others, but invites the originality of others in response. \nJust as an infinite game has rules, a culture has a tradition. \nSince the rules of play in an infinite game are freely agreed \nto and freely altered, a cultural tradition is both adopted and \ntransformed in its adoption. \nProperly speaking, a culture does not have a tradition; it \nis a tradition. \n36 \nIt is essential to the identity of a society to forget that it \nhas forgotten that society is always a species of culture. Its \ncitizens must find ways of persuading themselves that their \nown particular boundaries have been imposed on them, and \nwere not freely chosen by them. For example, it is one thing \nfor persons to choose to be Americans, quite another for per-\nsons to choose to be America. Societal thinking easily permits \nthe former, never the latter. \nFINITE AND INFINITE GAMES \n45 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 230
  },
  {
    "chunk_full": "One of the most effective means of self-persuasion available \nto a citizenry is the bestowal of property. Who actually owns \na society's property, and how it is distributed, are far less \nimportant than the fact that property exists at all. T::> under-\nstand the peculiar dynamic of property we must return to \none of the features of finite play. \nWhat the winner of a finite game wins is a title. A title \nis the acknowledgment of others that one has been the winner \nof a particular game. I cannot entitle myself. Titles are theatri-\ncal, requiring an audience to bestow and respect them. Power \nattaches to titles inasmuch as those who acknowledge them \naccept the fact that the struggle in which the titles were \nwon cannot be taken up again. Possession of the title signifies \nan agreement that competition is forever closed in that particu-\nlar game. \nIt is therefore essential to the effectiveness of every title \nthat it be visible and that in its visibility it point back at \nthe contest in which it was won. The purpose of property is \nto make our titles visible. Property is emblematic. It recalls \nto others those areas in which our victories are beyond chal-\nlenge. \nProperty may be stolen, but the thief does not therefore \nown it. Ownership can never be stolen. Titles are timeless, \nand so is the ownership of property. Nations will sometimes \ngo to war over claims to the ownership of land that go back \nmany centuries. Titles can be inherited, and when they are \nthere is an appropriate transfer of property to the heir-who \nmust, of course, possess the very worthiness by which the \ninheritor originally secured the title. (An inheritance can often \nbe legally challenged by demonstrating the heir's incompe-\ntence or immorality.) \nA thief, however, does not mean to steal the title. A thief \ndoes not want to take what belongs to someone else. The \n46 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 231
  },
  {
    "chunk_full": "thief does not compete with me for the articles I have title \nto, but for the title to those articles. The thief means to \nwin the title, believing that those things to which I claim \ntitle belong to no one and are there for the taking. \"If you \ndon't take pocket-handkechers and watches,\" explains the Art-\nful Dodger to Oliver, \"some other cove will; so that the coves \nthat lost' em will be all the worse, and you'll be all the worse \ntoo and nobody half a ha'p'orth the better, except the chaps \nwot gets them-and you've just as good a right to them as \nthey have.\" \n37 \nOne reason for the necessity of a society is its role in ascrib-\ning and validating the titles to property. \"The great and chief \nend therefore, of Mens uniting into Commonwealths, and \nputting themselves under Government, is the preservation \nof their Property; to which in the state of nature there are \nmany things wanting\" (Locke). \nWhen we ask precisely how a society will go about preserv-\ning its citizens' property, we can expect the reply that it will \ndo so by the use of force. This reply introduces a dilemma. \nWhile it is true that there are ways of forcibly restraining a \nthief, it is also true that no amount of force can lead the \nArtful Dodger truly to acknowledge a gentleman's title to \nthe handkerchief in his pocket. Until the young ruffian is \npersuaded freely to respect that title, he will remain a thief. \nBy extension, this observation applies to the society as a whole. \nThere is no effective pattern of entitlement in a society short \nof the free agreement of all opponents that the titles to prop-\nerty are in the hands of the actual winners. \nNo force will establish this agreement. Indeed, the opposite \nFINITE AND INFINITE GAMES \n47 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 232
  },
  {
    "chunk_full": "is the case: It is agreement that establishes force. Only those \nwho consent to a society's constraints see them as constraints-\nthat is, as guides to action and not as actions to be opposed. \nThose who challenge the existing pattern of entitlements \nin a society do not consider the designated officers of enforce-\nment powerful; they consider them opponents in a struggle \nthat will determine by its outcome who is powerful. One \ndoes not win by power; one wins to be powerful. \nOnly by free self-concealment can persons believe they obey \nthe law because the law is powerful; in fact, the law is powerful \nfor persons only because they obey it. We do not proceed \nthrough a traffic intersection because the signal changes, but \nwhen the signal changes. \nThis means that a peculiar burden falls on property owners. \nSince the laws protecting their property will be effective only \nwhen they are able to persuade others to obey those laws, \nthey must introduce a theatricality into their ownership suffi-\nciently engaging that their opponents will live by its script. \n38 \nThe theatricality of property has, in fact, an elaborate struc-\nture that property owners must be at considerable labor to \nsustain. If property is to be persuasively emblematic, that is, \nif it is to draw attention to the owner's titles in past victories, \na double burden falls on its owners: \nFirst, they must show that the amount of their property \ncorresponds to the difficulty they were under in winning title \nto it. Property must be seen as compensation. \nSecond, they must show that the type of their property \ncorresponds to the nature of the competition by which title \nto it was won. Property must be seen to be consumed. \n48 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 233
  },
  {
    "chunk_full": "39 \nProperty is appropriately compensatory whenever owners \ncan show that what is gained is no more than what was ex-\npended in the effort to acquire it. There must be an equiva-\nlency between what the owners have given of themselves and \nwhat they have received from others by way of their titles. \nWhoever is unable to show a correspondence between \nwealth and the risks undergone to acquire it, or the talents \nspent in its acquisition, will soon face a challenge over entitle-\nment. The rich are regularly subject to theft, to taxation, to \nthe expectation that their wealth be shared, as though what \nthey have is not true compensation and therefore not com-\npletely theirs. \nTo be fully compensated for what one gave of oneself in \nthe struggle for a title is to be restored to the condition one \nwas in prior to competition. \nProperty is an attempt to recover the past. It returns one \nto precompetitive status. One is compensated for the amount \nof time spent (and thus lost) in competition. \nThis attempt to recover the past is, however, a theatrical \nattempt which can succeed only to the degree that it is conspic-\nuous to its audience. Property must take up space. I t must \nbe somewhere-and somewhere obvious. That is, it must exist \nin such a form that others will come upon it and take notice \nof it. Our property must intrude on another, stand in another's \nway, causing one to contend with it. Propertied persons typi-\ncally have large estates and freedom of movement through \nthe society. At the same time, the property of the rich has \nthe effect of crowding and confining the less propertied. The \nvery poor are typically restricted to narrow geographical limits \nand are regarded as aliens outside them. \nWhat is at stake here for owners is not the amount of \nFINITE AND INFINITE GAMES \n49 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 234
  },
  {
    "chunk_full": "property as such, but its ability to draw an audience for whom \nit will be appropriately emblematc; that is, an audience who \nwill see it as just compensation for the effort and skill used \nin acquiring it. \n40 \nThere is a second theatrical requirement that falls on the \nowners of property. Once they have drawn attention to what \nthey have lost in acquiring what they own, they must then \nconsume what they have gained in a way that recovers the \nloss. The intuitive principle here is that we cannot be justified \nin owning what we do not need to use or plan to use. One \ndoes not earn money merely to store it away where it will \nbe protected from all possible future use. \nConsumption is to be understood as an intentional activity. \nOne does not consume property simply by destroying it-\nelse burning our earned money would suffice-but by using \nit up in a certain way. \nConsumption is a kind of activity that is directly opposite \nto the very form of engagement by which the title was won. \nIt must be the kind of activity that can convince all observers \nthat the possesser's title to it is no longer in question. \nThe more powerful we consider persons to be, the less \nwe expect them to do, for their power can come only from \nthat which they have done. After athletic contests in which \nmajor titles have been at stake, it is common for the audience \nto lift the winners to their shoulders, marching them about \nas if they were helpless-in the sharpest possible contrast to \nthe physical skill and energy they have just displayed. Mon-\n50 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 235
  },
  {
    "chunk_full": "archs and divinities are often borne on ceremonial transports; \nthe very wealthy are driven in carriages or limousines. \nConsumption is an activity so different from gainful labor \nthat it shows itself in the mode of leisure, even indolence. \nWe display the success of what we have done by not having \nto do anything. The more we use up, therefore, the more \nwe show ourselves to be winners of past contests. \"Conspicuous \nabstention from labour therefore becomes the conventional \nmark of superior pecuniary achievement and the conventional \nindex of reputability; and conversely, since application to pro-\nductive labour is a mark of poverty and subjection, it becomes \ninconsistent with a reputable standing in the community\" \n(Veblen). \nJust as compensation makes itself conspicuous by taking \nup space, consumption draws attention to itself by the length \nof time it continues. Property must not only intrude on others, \nit must continue to intrude on others. The amount of property \nwe have is measurable according to the length of time we \nremain conspicuous, requiring others to adjust their freedom \nof movement to our spatial dimensions. It is the common \ngoal of the ;'ich to establish a mode of visibility that will \nextend itself over generations by executing wills that prevent \nthe rapid exhaustion of their fortune, by endowing societally \nimportant institutions, by erecting great buildings in their \nname. Persons of small victories, of lower rank, do not have \nproperty of great temporal value; what they have will be ex-\nhausted quickly. Those persons whose victories the society \nwishes never to forget are given prominent and eternal monu-\nments at the heart of its capital cities, often taking up consider-\nable space, diverting traffic, and standing in the path of casual \nstrollers. \nFINITE AND INFINITE GAMES \n51 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 236
  },
  {
    "chunk_full": "It is apparent to infinite players that wealth is not so much \npossessed as it is performed. \n41 \nIf one of the reasons for uniting into commonwealths is \nthe protection of property, and if property is to be protected \nless by power as such than by theater, then societies become \nacutely dependent on their artists-what Plato called poietai: \nthe storytellers, the inventors, sculptors, poets, any original \nthinkers whatsoever. \nI t is certainly the case that no gentleman will find the \nArtful Dodger's hand in his pocket so long as it is in the \nforceful grip of an officer of the law. But any policy of forceful \nrestraint so extreme that it requires an officer for each potential \ncriminal is a formula for quick descent into social chaos. \nSome societies develop the belief that they can eliminate \nthievery by guaranteeing all their members, including thieves, \na certain amount of property-the impulse behind much social \nwelfare legislation. But putting a coin into the pocket of the \nArtful Dodger will hardly convince him that he is no longer \na legitimate contender for the coin in mine. \nThe more effective policy for a society is to find ways of \npersuading its thieves to abandon their role as competitors \nfor property for the sake of becoming audience to the theater \nof wealth. It is for this reason that societies fall back on the \nskill of those poietai who can theatricalize the property rela-\ntions, and indeed, all the inner structures of each society. \nSocietal theorists of any subtlety whatever know that such \ntheatricalization must be taken with great seriousness. With-\nout it there is no culture at all, and a society without culture \nwould be too drab and lifeless to be endured. What would \n52 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 237
  },
  {
    "chunk_full": "Nazism have been without its musicians, graphic artists, and \nset designers, without its Albert Speer and Leni Riefenstahl? \nEven the rigid authoritarian shell of Plato's Republic will be \n\"filled with a multitude of things which are no longer necessi-\nties, as for example all kinds of hunters and artists, many of \nthem concerned with shapes and colors, many with music; \npoets and their auxiliaries, actors, choral dancers, and contrac-\ntors; and makers of all kinds of instruments, including those \nneeded for the beautification of women\" (Plato). \nIf wealth and might are to be performed, great wealth and \ngreat might must be performed brilliantly. \n42 \nWhile societal thinkers may not overlook the importance \nof poiesis, or creative activity, neither may they underestimate \nits danger, for the poietai are the ones most likely to remember \nwhat has been forgotten-that society is a species of culture. \nSocieties commonly treat their poietai with considerable \nambivalence. The governing bodies of the Soviet Union do \nnot believe that all genuine art must conform to the standards \nof socialist realism, but they do believe it is always possible \nto find true art that is compatibl~ with socialist realism; there-\nfore, those artists whose works do not conform to that line \nmay be punished without affecting the integrity of art as such. \nPlato did not expect his artists to compromise their art, but \nhe did say that there must be \"general lines which the poietai \nmust follow in their stories. These lines they will not be able \nto cross.\" \nThe deepest and most consequent struggle of each society \nis therefore not with other societies, but with the culture \nthat exists within itself-the culture that is itself. Conflict \nFINITE AND INFINITE GAMES \n53 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 238
  },
  {
    "chunk_full": "with other societies is, in fact, an effective way for .a society \nto restrain its own culture. Powerful societies do not silence \ntheir poietai in order that they may go to war; they go to \nwar as a way of silencing their poietai. Original thinkers can \nbe suppressed through execution and exile, or they can be \nencouraged through subsidy and flattery to praise the society's \nheroes. Alexander and Napoleon took their poets and their \nscholars into battle with them, saving themselves the nuisance \nof repression and along the way drawing ever larger audiences \nto their triumph. \nAnother successful defense of society against the culture \nwithin itself is to give artists a place by regarding them as \nthe producers of property, thus elevating the value of consum-\ning art, or owning it. It is notable that very large collections \nof art, and all the world's major museums, are the work of \nthe very rich or of societies during strongly nationalistic peri-\nods. All the principal museums in New York, for example, \nare associated with the names of the famously rich: Carnegie, \nFrick, Rockefeller, Guggenheim, Whitney, Morgan, Lehman. \nSuch museums are not designed to protect the art from \npeople, but to protect the people from art. \n43 \nCulture is likely to break out in a society not when its \npoietai begin to voice a line contrary to that of the society, \nbut when they begin to ignore all lines whatsoever and concern \nthemselves with bringing the audience back into play-not \ncompetitive play, but play that affirms itself as play. \nWhat confounds a society is not serious opposition, but \nthe lack of seriousness altogether. Generals can more easily \n54 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 239
  },
  {
    "chunk_full": "suffer attempts to oppose their warfare with poiesis than at-\ntempts to show warfare as poiesis. \nArt that is used against a society or its policies gives up \nits character as infinite play, and aims for an end. Such art \nis no less propaganda than that which praises its heroes with \nhigh seriousness. Once warfare, or any other societal activity, \nhas been taken into the infinite play of poiesis so that it \nappears to be either comical or pointless (in the way that, \nsay, beauty is pointless), there is an acute danger that the \nsoldiers will find no audience for their prizes, and therefore \nno reason to fight for them. \n44 \nSince culture is itself a poiesis, all of its participants are \npoietai-inventors, makers, artists, storytellers, mythologists. \nThey are not, however, makers of actualities, but makers of \npossibilities. The creativity of culture has no outcome, no \nconclusion. It does not result in art works, artifacts, products. \nCreativity is a continuity that engenders itself in others. \"Art-\nists do not create objects, but create by way of objects\" (Rank). \nArt is not art, therefore, except as it leads to an engendering \ncreativity in its beholders. Whoever takes possession of the \nobjects of art has not taken possession of the art. \nSince art is never possession, and always possibility, nothing \npossessed can have the status of art. If art cannot become \nproperty, property is never art-as property. Property draws \nattention to titles, points backward toward a finished time. \nArt is dramatic, opening always forward, beginning something \nthat cannot be finished. \nBecause it is not conclusive, but engendering, culture has \nFINITE AND INFINITE GAMES \n55 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 240
  },
  {
    "chunk_full": "no estal ~!shed catalogue of acceptable activities. We are not \nartists by reason of having mastered certain skills or exercising \nspecified techniques. Art has no scripted roles for its perform-\ners. It is precisely because it has none that it is art. Artistry \ncan be found anywhere; indeed, it can only be found anywhere. \nOne must be surprised by it. It cannot be looked for. We \ndo not watch artists to see what they do, but watch what \npersons do and discover the artistry in it. \nArtists cannot be trained. One does not become an artist \nby acquiring certain skills or techniques, though one can use \nany number of skills and techniques in artistic activity. The \ncreative is found in anyone who is prepared for surprise. Such \na person cannot go to school to be an artist, but can only \ngo to school as an artist. \nTherefore, poets do not \"fit\" into society, not because a \nplace is denied them but because they do not take their \n\"places\" seriously. They openly see its roles as theatrical, its \nstyles as poses, its clothing costumes, its rules conventional, \nits crises arranged, its conflicts performed, and its metaphysics \nideological. \n45 \nTo regard society as a species of culture is not to overthrow \nor even alter society, but only to eliminate its perceived neces-\nsity. Infinite players have rules; they just do not forget that \nrules are an expression of agreement and not a requirement \nfor agreement. \nCulture is not therefore mere disorder. Infinite players never \nunderstand their culture as the composite of all that they \nchoose individually to do, but as the congruence of all that \n56 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 241
  },
  {
    "chunk_full": "they choose to do with each other. Because there is no congru-\nence without the decision to have one, all cultural congruence \nis under constant revision. No sooner did the Renaissance \nbegin than it began to change. Indeed, the Renaissance was \nnot something apart from its change; it was itself a certain \npersistent and congruent evolution. \nFor this reason it can be said that where a society is defined \nby its boundaries, a culture is defined by its horizon. \nA boundary is a phenomenon of opposition. It is the meeting \nplace of hostile forces. Where nothing opposes there can be \nno boundary. One cannot move beyond a boundary without \nbeing resisted. \nThis is why patriotism-that is, the desire to protect the \npower in a society by way of increasing the power of a society-\nis inherently belligerent. Since there can be no prizes without \na society, no society without opponents, patriots must create \nenemies before we can require protection from them. Patriots \ncan flourish only where boundaries are well-defined, hostile, \nand dangerous. The spirit of patriotism is therefore characteris-\ntically associated with the military or other modes of interna-\ntional conflict. \nBecause patriotism is the desire to contain all other finite \ngames within itself-that is, to embrace all horizons within \na single boundary-it is inherently evil. \nA horizon is a phenomenon of vision. One cannot look \nat the horizon; it is simply the point beyond which we cannot \nsee. There is nothing in the horizon itself, however, that limits \nvision, for the horizon opens onto all that lies beyond itself. \nWhat limits vision is rather the incompleteness of that vision. \nOne never reaches a horizon. It is not a line; it has no \nplace; it encloses no field; its location is always relative to \nthe view. To move toward a horizon is simply to have a new \nFINITE AND INFINITE GAMES \n57 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 242
  },
  {
    "chunk_full": "horizon. One can therefore never be close to one's horizon, \nthough one may certainly have a short range of vision, a narrow \nhorizon. \nWe are never somewhere in relation to the horizon since \nthe horizon moves with our vision. We can only be somewhere \nby turning away from the horizon, by replacing vision with \nopposition, by declaring the place on which we stand to be \ntimeless-a sacred region, a holy land, a body of truth, a \ncode of inviolable commandments. To be somewhere is to \nabsolutize time, space, and number. \nEvery move an infinite player makes is toward the horizon. \nEvery move made by a finite player is within a bound-\nary. Every moment of an infinite game therefore presents a \nnew vision, a new range of possibilities. The Renaissance, \nlike all genuine cultural phenomena, was not an effort to pro-\nmote one or another vision. It was an effort to find visions \nthat promised still more vision. \nWho lives horizon ally is never somewhere, but always in \npassage. \n46 \nSince culture is horizonal it is not restricted by time or \nspace. \nTo the degree that the Renaissance was true culture it \nhas not ended. Anyone may enter into its mode of renewing \nvision. This does not mean that we repeat what was done. \nTo enter a culture is not to do what the others do, but to \ndo whatever one does with the others. \nThis is why every new participant in a culture both enters \ninto an existing context and simultaneously changes that con-\ntext. Each new speaker of its language both learns the language \n58 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 243
  },
  {
    "chunk_full": "and alters it. Each new adoption of a tradition makes it a \nnew tradition-just as the family into which a child is born \nexisted prior to that birth, but is nonetheless a new family \nafter the birth. \nThe reciprocity of this transformation has no respect to \ntime. The fact that the Renaissance began in the fourteenth \nor fifteenth century has nothing to do with its capacity for \nchanging our horizon. This reciprocity works backward as well \nas forward. Each person whose horizon is affected by the \nRenaissance affects the horizon of the Renaissance in turn. \nAny culture that continues to influence our vision continues \nto grow in the very exercise of that influence. \n47 \nSince a culture is not anything persons do, but anything \nthey do with each other, we may say that a culture comes \ninto being whenever persons choose to be a people. It is as \na people that they arrange their rules with each other, their \nmoralities, their modes of communication. \nProperly speaking, the Renaissance is not a period but a \npeople, moreover, a people without a boundary, and therefore \nwithout an enemy. The Renaissance is not against anyone. \nWhoever is not of the Renaissance cannot go out to oppose \nit, for they will find orily an invitation to join the people it \nIS. \nA culture is sometimes opposed by suppressing its ideas, \nits works, even its language. This is a common strategy of a \nsociety afraid of the culture growing within its boundaries. \nBut it is a strategy certain to fail, because it confuses the \ncreative activity (poiesis) with the product (poiema) of that \nactivity. \nFINITE AND INFINITE GAMES \n59 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 244
  },
  {
    "chunk_full": "Societies characteristically separate the ideas from their \nthinkers, the poiema from its poietes. A society abstracts its \nthought and grants power to certain ideas as though they \nhad an existence of their own independent from those who \nthink them, even those who first produced them. In fact, a \nsociety is likely to have an idea of itself that no thinker may \nchallenge or revise. Abstracted thought-thought without a \nthinker-is metaphysics. A society's metaphysics is its ideol-\nogy: theories that present themselves as the product of these \npeople or those. The Renaissance had no ideology. \nInasmuch as it has no metaphysics, a people is not threat-\nened when its apparent society is threatened, or altered, or \neven destroyed. The manipulation of the government, the \nlaws, the enforcement functions of a state either by persons \nwithin the society (through usurpation or abuse of power) \nor by persons without (in other states) cannot in itself affect \nthe decision of a people to be a people. \nA people, as a people, has nothing to defend. In the same \nway a people has nothing and no one to attack. One cannot \nbe free by opposing another. My freedom does not depend \non your loss of freedom. On the contrary, since freedom is \nnever freedom from society, but freedom for it, my freedom \ninherently affirms yours. \nA people has no enemies. \n48 \nFor a bounded, metaphysically veiled, and destined society, \nenemies are necessary, conflict inevitable, and war likely. \nWar is not an act of unchecked ruthlessness but a declared \ncontest between bounded societies, or states. If a state has \nno enemies it has no boundaries. To keep its definitions clear \n60 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 245
  },
  {
    "chunk_full": "a state must stimulate danger to itself. Under the constant \ndanger of war the people of a state are far more attentive \nand obedient to the finite structures of their society: \"just \nas the blowing of the winds preserves the sea from the foulness \nwhich would be the result of a prolonged calm, so also corrup-\ntion in nations would be the product of prolonged, let alone \n'perpetual' peace\" (Hegel). \nWar presents itself as necessary for self-protection, when \nin fact it is necessary for self-identification. \nIf it is the impulse of a finite player to go against another \nnation in war, it is the design of an infinite player to oppose \nwar within a nation. \nIf as a people infinite players cannot go to war against a \npeople, they can act against war itself within whatever state \nthey happen to reside. In one wa.y their opposition to war \nresembles that of finite players: Each is opposed to the exis-\ntence of a state. But their reasons and the strategies for at-\ntempting to eliminate states are radically different. Finite \nplayers go to war against states because they endanger bound-\naries; infinite players oppose states because they engender \nboundaries. \nThe strategy of finite players is to kill a state by killing \nthe people who invented it. Infinite players, however, under-\nstanding war to be a conflict between states, conclude that \nstates can have only states as enemies; they cannot have per-\nsons as enemies. \"Sometimes it is possible to kill a state without \nkilling a single one of its members; and war gives no right \nwhich is not necessary to the gaining of its object\" (Rousseau). \nFor infinite players, if it is possible to wage a war without \nkilling a single person, then it is possible to wage war only \nwithout killing a single person. \nFor infinite players the chief difficulty with finite players' \ncommitment to war is not, however, that persons are killed. \nFINITE AND INFINITE GAMES \n61 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 246
  },
  {
    "chunk_full": "Indeed, finite players themselves often genuinely regret this \nand do as little killing as possible. The difficulty is that such \nwarfare has in it the contradiction of all finite play. Winning \na war can be as destructive as losing one, for if boundaries \nlose their clarity, as they do in a decisive victory, the state \nloses its identity. Just as Alexander wept upon learning he \nhad no more enemies to conquer, finite players come to rue \ntheir victories unless they see them quickly challenged by new \ndanger. A war fought to end all wars, in the strategy of finite \nplay, only breeds universal warfare. \nThe strategy of infinite players is horizonal. They do not \ngo to meet putative enemies with power and violence, but \nwith poiesis and vision. They invite them to become a people \nin passage. Infinite players do not rise to meet arms with \narms; instead, they make use of laughter, vision, and surprise \nto engage the state and put its boundaries back into play. \nWhat will undo any boundary is the awareness that it is \nour vision, and not what we are viewing, that is limited. \n49 \nPlato suggested that some of the poets be driven out of \nthe Republic because they had the power to weaken the guard-\nians. Poets can make it impossible to have a war-unless they \ntell stories that agree with the \"general line\" established by \nthe state. Poets who have no metaphysics, and therefore no \npolitical line, make war impossible because they have the irre-\nsistible ability to show the guardians that what seems necessary \nis only possible. \nThe danger of the poets, for Plato, is that they can imitate \nso well that it is difficult to see what is true and what is \n6Z \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 247
  },
  {
    "chunk_full": "merely invented. Since reality cannot be invented, but only \ndiscovered through the exercise of reason-according to \nPlato-all poets must be put into the service of reason. The \npoets are to surround the citizens of the Republic with such \nart as will \"lead them unawares from childhood to love of, \nresemblance to, and harmony with, the beauty of reason.\" \nThe use of the word \"unawares\" shows Plato's intention \nto keep the metaphysical veil intact. Those who are being \nled to reason cannot be aware of it. They must be led to it \nwithout choosing it. Plato asks his poets not to create, but \nto deceive. \nTrue poets lead no one unawares. It is nothing other than \nawareness that poets-that is, creators of all sorts-seek. They \ndo not display their art so as to make it appear real; they \ndisplay the real in a way that reveals it to be art. \nWe must remind ourselves, to be sure, that Plato was him-\nself an artist, a poietes. His Republic was an invention. So \nwere the theory of forms and the idea of the Good. Since \nall veiling is self-veiling, we cannot help but think that behind \nthe rational metaphysician, philosophy's great Master Player, \nstood Plato the poet, fully aware that the entire opus was \nan act of play, an invitation to readers not to reproduce the \ntruth but to take his inventions into their own play, establish-\ning the continuity of his art by changing it. \n50 \nWe can find metaphysicians thinking, but we cannot find \nmetaphysicians in their thinking. When we separate the meta-\nphysics from the thinker we have an abstraction, the deathless \nshadow of a once living act. It is no longer what someone \nFINITE AND INFINITE GAMES \n63 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 248
  },
  {
    "chunk_full": "is saying but what someone has said. When metaphysics is \nmost successful on its own terms, it leaves its listeners in \nsilence, certainly not in laughter. \nMetaphysics is about the real but is abstract. Poetry is the \nmaking (poiesis) of the real and is concrete. Whenever what \nis made (poiema) is separated from the maker (poietes), it \nbecomes metaphysical. As it stands there, and as the voice \nof the poietes is no longer listened to, the poiema is an object \nto be studied, not an act to be learned. One cannot learn' \nan object, but only the poiesis, or the act of creating objects. \nTo separate the poiema from poiesis, the created object from \nthe creative act, is the essence of the theatrical. \nPoets cannot kill; they die. Metaphysics cannot die; it kills. \n64 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 249
  },
  {
    "chunk_full": "THREE \nI AM THE GENIUS \nOF MYSELF \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 250
  },
  {
    "chunk_full": "",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 251
  },
  {
    "chunk_full": "51 \nI AM THE GENIUS of myself, the poietes who composes the \nsentences I speak and the actions I take. It is I, not the \nmind, that thinks. It is I, not the will, that acts. It is I, not \nthe nervous system, that feels. \nWhen I speak as the genius I am, I speak these words \nfor the first time. To repeat words is to speak them as though \nanother were saying them, in which case I am not saying \nthem. To be the genius of my speech is to be the origin of \nmy words, to say them for the first, and last, time. Even to \nrepeat my own words is to say them as though I were another \nperson in another time and place. \nWhen I forsake my genius and speak to you as though I \nwere another, I also speak to you as someone you are not \nand somewhere you are not. I address you as audience, and \ndo not expect you to respond as the genius you are. \nHamlet was not reading when he said he was reading words; \nneither do we act when we perform actions, nor think when \nwe entertain thoughts. A dog taught the action of shaking \nhands does not shake your hand. A robot can say words but \ncannot say them to you. \nSince being your own genius is dramatic, it has all the \nparadox of infinite play: You can have what you have only \nFINITE AND INFINITE GAMES \n67 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 252
  },
  {
    "chunk_full": "by releasing it to others. The sounds of the words you speak \nmay lie on your own lips, but if you do not relinquish them \nentirely to a listener they never become words, and you say \nnothing at all. The words die with the sound. Spoken to me, \nyour words become mine to do with as I please. As the genius \nof your words, you lose all authority over them. So too with \nthoughts. However you consider them your own, you cannot \nthink the thoughts themselves, but only what they are about. \nYou cannot think thoughts any more than you can act actions. \nIf you do not truly speak the words that reside entirely in \ntheir own sound, neither can you think that which remains \nthought or can be translated back into thought. In thinking \nyou cast thoughts beyond themselves, surrendering them to \nthat which they cannot be. \nThe paradox of genius exposes us directly to the dynamic \nof open reciprocity, for if you are the genius of what you \nsay to me, I am the genius of what I hear you say. What \nyou say originally I can hear only originally. As you surrender \nthe sound on your lips, I surrender the sound in my ear. \nEach of us has relinquished to the other what has been relin-\nquished to the other. \nThis does not mean that speech has come to nothing. On \nthe contrary, it has become speech that invites speech. When \nthe genius of speech is abandoned, words are said not originally \nbut repetitively. To repeat words, even our own, is to contain \nthem in their own sound. Veiled speech is that spoken as \nthough we have forgotten we are its originators. \nTo speak, or act, or think originally is to erase the boundary \nof the self. It is to leave behind the territorial personality. \nA genius does not have a mind full of thoughts but is the \nthinker of thoughts, and is the center of a field of vision. It \nis a field of vision, however, that is recognized as a field of \n68 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 253
  },
  {
    "chunk_full": "vIsion only when we see that it includes within itself the \noriginal centers of other fields of vision. \nThis does not mean that I can see what you see. On the \ncontrary, it is because I cannot see what you see that I can \nsee at all. The discovery that you are the unrepeatable center \nof your own vision is simultaneous with the discovery that I \nam the center of my own. \n52 \nAs the geniuses we are, we do not look but see. \nTo look at something is to look at it within its limitations. \nI look at what is marked off, at what stands apart from other \nthings. But things do not have their own limitations. Nothing \nlimits itself. The sea gulls circling on the invisible currents, \nthe cat on my desk, the siren of a distant ambulance are \nnot somehow distinct from the environment; they are the \nenvironment. To look at them I must look for what I take \nthem to be. I was not looking at the sea gulls as though it \nwas the sea gulls who happened to be there-I was looking \nfor something to make this example. I might have seen them \nas a sign that land is not far, or that the sea is not far; I \ncould have been looking for a form to reproduce on a canvas \nor in a poem. To look at is to look for. It is to bring the \nlimitations with us. \"Nature has no outline. Imagination has\" \n(Blake). \nIf to look is to look at what is contained within its limita-\ntions, to see is to see the limitations themselves. Each new \nschool of painting is new not because it now contains subject \nmatter ignored in earlier work, but because it sees the limita-\ntions previous artists imposed on their subject matter but could \nFINITE AND INFINITE GAMES \n69 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 254
  },
  {
    "chunk_full": "not see themselves. The earlier artists worked within the out-\nlines they imagined; the later reworked their imaginations. \nTo look is a territorial activity. It is to observe one thing \nafter another within a bounded space-as though in time it \ncan all be seen. Academic fields are such territories. Sometimes \neverything in a field finally does get looked at and defined-\nthat is, placed in its proper location. Mechanics and rhetoric \nare such fields. Physics may prove to be. Biological mysteries \nfall away at an astonishing rate. It becomes increasingly diffi-\ncult to find something new to look at. \nWhen we pass from looking to seeing, we do not therefore \nlose our sight of the objects observed. Seeing, in fact, does \nnot disturb our looking at all. It rather places us in that territory \nas its genius, aware that our imagination does not create within \nits outlines but creates the outlines themselves. The physicist \nwho sees speaks physics with us, inviting us to see that the \nthings we thought were there are not things at all. By learning \nnew limitations from such a person, we learn not only what \nto look for with them but also how to see the way we use \nlimitations. A physics so taught becomes poiesis. \n53 \nTo be the genius of myself is not to bring myself into \nbeing. As the origin of myself I am not also the cause of \nmyself, as though I were the product of my own action. But \nthen neither am I the product of any other action. My parents \nmay have wanted a child, but they could not have wanted \nme. \nI am both the outcome of my past and the transformation \nof my past. To be related to the past as its outcome is to \nstand in causal continuity with it. Such a relation can be \n70 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 255
  },
  {
    "chunk_full": "accounted for in scientific explanation. I can be said to be \nthe result of precise genetic influence. The date and place \nof my birth are matters of causal necessity; I had no part in \ndeciding either. Neither could anyone else have chosen them. \nMy birth, when understood in terms of causal continuity, \nmarks no absolute beginning. It marks nothing at all except \nan arbitrary point in an unbroken process. Causally speaking, \nthere is nothing new here, only the kinds of change that \nconform to the known laws of nature. \nSpeaking in purely causal terms, I cannot say I was born; \nI should say rather that I have emerged as a phase in the \nprocess of reproduction. A reproduction is a repetition, a recur-\nrence of that which has been. Birth, on the other hand, in \ncausal terms, is all discontinuity. It has its beginning in itself, \nand can be caused by nothing. It makes no sense to say, \"I \nwas reproduced on this date and in this place.\" To say \"I \nwas born\" is to speak of myself as having an uncaused point \nof departure within the realm of the continuous, an absolute \nbeginning not comprehensible to the explanatory intelligence. \nAs such a phenomenon birth repeats nothing; it is not the \noutcome of the past but the recasting of a drama already \nunder way. A birth is an event in the ongoing history of a \nfamily, even the history of a culture. The radical originality \nof a birth announces itself in the way it brings the dramatic \ninto conflict with the theatrical in cultural or family history. \nTheatrically, my birth is an e~ent of plotted repetition. I \nam born as another member of my family and my culture. \nWho I am is a question already answered by the content \nand character of a tradition. Dramatically, my birth is the \nrupture of that repetitive sequence, an event certain to change \nwhat the past has meant. In this case the character of a tradi-\ntion is determined by who I am. Dramatically speaking, every \nbirth is the birth of genius. \nFINITE AND INFINITE GAMES \n71 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 256
  },
  {
    "chunk_full": "The drama under way at the time of my birth is moved \nforward to new possibilities by the appearance of a new genius \nwithin it. It is a drama, however, already peopled by finite \nplayers attempting to forget, playing for keeps. If I am born \ninto, and add to, the culture of a family, I am also a product \nand a citizen of its politics. I first experience the conflict \nbetween the theatrical and the dramatic in the felt pressure \nto take up one of the roles prepared for me: eldest son, favorite \ndaughter, heir to the family's honor, avenger of its losses. \nEach of these roles comes, of course, with a script, one \nwhose lines a person might easily spend a lifetime repeating, \nwhile intentionally forgetting, or repressing, the fact that it \nis but a learned script. Such a person \"is obliged to repeat \nthe repressed material as a contemporary experience instead \nof, as the physician would prefer to see, remembering it as \nsomething belonging to the past\" (Freud). It is the genius \nin us who knows that the past is most definitely past, and \ntherefore not forever sealed but forever open to creative rein-\nterpretation. \n54 \nNot allowing the past to be past may be the primary source \nfor the seriousness of finite players. Inasmuch as finite play \nalways has its audience, it is the audience to whom the finite \nplayer intends to be known as winner. The finite player, in \nother words, must not only have an audience but must have \nan audience to convince. \nJust as the titles of winners are worthless unless they are \nvisible to others, there is a kind of antititle that attaches to \ninvisibility. To the degree that we are invisible we have a \npast that has condemned us to oblivion. It is as though we \n72 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 257
  },
  {
    "chunk_full": "have somehow been overlooked, even forgotten, by our chosen \naudience. If it is the winners who are presently visible, it is \nthe losers who are invisibly past. \nAs we enter into finite play-not playfully, but seriously-\nwe come before an audience conscious that we bear the antiti-\ntles of invisibility. We feel the need, therefore, to prove to \nthem that we are not what we think they think we are or, \nmore precisely, that we were not who we think the audience \nthinks we were. \nAs with all finite play, an acute contradiction quickly devel-\nops at the heart of this attempt. As finite players we will \nnot enter the game with sufficient desire to win unless we \nare ourselves convinced by the very audience we intend to \nconvince. That is, unless we believe we actually are the losers \nthe audience sees us to be, we will not have the necessary \ndesire to win. The more negatively we assess ourselves, the \nmore we strive to reverse the negative judgment of others. \nThe outcome brings the contradiction to perfection: by prov-\ning to the audience they were wrong, we prove to ourselves \nthe audience was right. \nThe more we are recognized as winners, the more we know \nourselves to be losers. That is why it is rare for the winners \nof highly coveted and publicized prizes to settle for their titles \nand retire. Winners, especially celebrated winners, must prove \nrepeatedly they are winners. The script must be played over \nand over again. Titles must be defended by new contests. \nNo one is ever wealthy enough, honored enough, applauded \nenough. On the contrary, the visibility of our victories only \ntightens the grip of the failures in our invisible past. \nSo crucial is this power of the past to finite play that we \nmust find ways of remembering that we have been forgotten \nto sustain our interest in the struggle. There is a humiliating \nmemory at the bottom of all serious conflicts. \"Remember \nFINITE AND INFINITE GAMES \n73 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 258
  },
  {
    "chunk_full": "the Alamo!\" \"Remember the Maine!\" \"Remember Pearl Har-\nbor!\" These are the cries that carried Americans into several \nwars. Having once been insulted by Athens, the great Persian \nEmperor Darius renewed his appetite for war by having a \npage follow him about to whisper in his ear, \"Sire, remember \nthe Athenians.\" \nIndeed, it is only by remembering what we have forgotten \nthat we can enter into competition with sufficient intensity \nto be able to forget we have forgotten the character of all \nplay: Whoever must play cannot play. \nWhenever we act as the genius of ourselves, it will be in \nthe spirit of allowing the past to be past. I t is the genius in \nus who is capable of ridding us of resentment by exercising \nwhat Nietzsche called the \"faculty of oblivion,\" not as a way \nof denying the past but as a way of reshaping it through \nour own originality. Then we forget that we have been forgot-\nten by an audience, and remember that we have forgotten \nour freedom to play. \n55 \nIf in the culture into which we are born there are always \npersons who will urge us to theatricalize our lives by supplying \nus with a repeatable past, there will also be persons (possibly \nthe same ones) in whose presence we learn to prepare ourselves \nfor surprise. It is in the presence of such persons that we \nfirst recognize ourselves as the geniuses we are. \nThese persons do not give us our genius or produce it in \nus. In no way is the source of genius external to itself; never \nis a child moved to genius. Genius arises with touch. Touch \n74 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 259
  },
  {
    "chunk_full": "is a characteristically paradoxical phenomenon of infinite play. \nI am not touched by an other when the distance between \nus is reduced to zero. I am touched only if I respond from \nmy own center-that is, spontaneously, originally. But you \ndo not touch me except from your own center, out of your \nown genius. Touching is always reciprocal. You cannot touch \nme unless I touch you in response. \nThe opposite of touching is moving. You move me by press-\ning me from without toward a place you have already foreseen \nand perhaps prepared. It is a staged action that succeeds only \nif in moving me you remain unmoved yourself. I can be moved \nto tears by skilled performances and heart-rending newspaper \naccounts, or moved to passion by political manifestos and \nnarratives of heroic achievement-but in each case I am \nmoved according to a formula or design to which the actor \nor agent is immune. When actors bring themselves to tears \nby their performance, and not as their performance, they \nhave failed their craft; they have become theatrically inept. \nThis means that we can be moved only by persons who \nare not what they are; we can be moved only when we are \nnot who we are, but are what we cannot be. \nWhen I am touched, I am touched only as the person I \nam behind all the theatrical masks, but at the same time I \nam changed from within-and whoever touches me is touched \nas well. We do not touch by design. Indeed, all designs are \nshattered by touching. Whoever touches and whoever is \ntouched cannot but be surprised. (The unpredictability of this \nphenomenon is reflected in our reference to the insane as \n\"touched. \") \nWe can be moved only by way of our veils. We are touched \nthrough our veils. \nFINITE AND INFINITE GAMES \n75 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 260
  },
  {
    "chunk_full": "56 \nThe character of touching can be seen quite clearly in the \nway infinite players understand both healing and sexuality. \nIf to be touched is to respond from one's center, it is also \nto respond as a whole person. To be whole is to be hale, or \nhealthy. In sum, whoever is touched is healed. \nThe finite player's interest is not in being healed, or made \nwhole, but in being cured, or made functional. Healing restores \nme to play, curing restores me to competition in one or another \ngame. \nPhysicians who cure must abstract persons into functions. \nThey-treat the illness, not the person. And persons willfully \npresent themselves as functions. Indeed, what sustains the \nenormous size and cost of the curing professions is the wide-\nspread desire to see oneself as a function, or a collection of \nfunctions. To be ill is to be dysfunctional; to be dysfunctional \nis to be unable to cbmpete in one's preferred contests. It is \na kind of death, an inability to acquire titles. The ill become \ninvisible. Illness always has the smell of death about it: Either \nit may lead to death, or it leads to the death of a person as \ncompetitor. The dread of illness is the dread of losing. \nOne is never ill in general. One is always ill with relation \nto some bounded activity. It is not cancer that makes me \nill. I t is because I cannot work, or run, or swallow that I \nam ill with cancer. The loss of function, the obstruction of \nan activity, cannot in itself destroy my health. I am too heavy \nto fly by flapping my arms, but I do not for that reason com-\nplain of being sick with weight. However, if I desired to be \na fashion model, a dancer, or a jockey, I would consider exces-\nsive weight to be a kind of disease and would be likely to \nconsult a doctor, a nutritionist, or another specialist to be \ncured of it. \n76 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 261
  },
  {
    "chunk_full": "When I am healed I am restored to my center in -a way \nthat my freedom as a person is not compromised by my loss \nof functions. This means that the illness need not be elimi-\nnated before I can be healed. I am not free to the degree \nthat I can overcome my infirmities, but only to the degree \nthat I can put my infirmities into play. I am cured of my \nillness; I am healed with my illness. \nHealing, of course, has all the reciprocity of touching. Just \nas I cannot touch myself, I cannot heal myself. But healing \nrequires no specialists, only those who can come to us out \nof their own center, and who are prepared to be healed them-\nselves. \n57 \nSexuality for the infinite player is entirely a matter of touch. \nOne cannot touch without touching sexually. \nBecause sexuality is a drama of origins, it gives full expression \nto the genius you are and to the genius of others who partici-\npate in that drama. This throws a high challenge before the \npolitical ideologue. Aware that genuine sexual expression is \nat least as dangerous to society as genuine artistic expression, \nthe sexual metaphysician can appeal to at least two powerful \nsolutions. One is to treat sexuality as a process of reproduction; \nanother is to place it in the area of feeling and behavior. \nAlthough reproduction is a process that operates by way \nof our bodies, it nonetheless operates autonomously. Like every \nother natural process it is a phenomenon of causal continuity, \nhaving no inherent beginning or end. Therefore we cannot \nbe said to initiate the process by any act of our own. We \ncan only be carried along by it, inasmuch as conception occurs \nonly when all the necessary conditions have been met by the \nFINITE AND INFINITE GAMES \n77 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 262
  },
  {
    "chunk_full": "parenting couple. No one conceives a child; a child is conceived \nin the conjunction of sperm and ovum. The mother does \nnot give birth to a child; the mother is where the birth occurs. \nThe metaphysics of sexuality, applying to this solution, can \ntherefore draw a boundary line around sexual activity that \nleaves the genius of parenting altogether outside it. Thus the \nfamiliar view of some Christian theologians who say that the \nonly end of the sexual act is procreation. But this metaphysics, \ncommitted as it is to the continuity of the process, also leaves \nthe genius of the child entirely outside it. Thus the familiar \nview of theologians who say that the end of childbirth is to \nprovide citizens for the kingdom of God. Metaphysically un-\nderstood, sexuality has nothing to do with our existence as \npersons, for it views persons as expressions of sexuality, and \nnot sexuality as the expression of persons. \nThe second way of veiling genuine sexuality is to regard \nit as a feeling or as a kind of behavior. In either case it has \nthe character of something under observation. Even if it is \nour own sexuality we are concerned with, we can still look \non it from without, making an assessment of it as though it \nwere of another person. We ask ourselves and each other \nwhether certain behavior is acceptable or desirable; we are \npuzzled over the proper response to sexual feelings--ours or \nanother's. Sexuality can in this way be dealt with as a societal \nphenomenon, regulated and managed according to the prevail-\ning ideology. Sexual rebels, violators of the sexual taboos, do \nnot weaken this ideology but affirm it as the rules of finite \nplay. \nIt is convenient to think that sexual misfits violate rules. \nThe matter is subtler by far. They are not concerned to oppose \nthe rules themselves but to engage in competitive struggle \nby way of those rules. Sexual attractiveness, or sexiness, is \neffective only to the degree that someone is offended by it. \n78 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 263
  },
  {
    "chunk_full": "Pornography is exciting only so far as it reveals something \nforbidden, something otherwise unseeable. Thus the manda-\ntory hostility in it, the quality of shock and violence. \nBecause sexuality is so rich in the mystery of origin, it \nbecomes a region of human action deeply shaped by resent-\nment, where participants play out a manifold strategy of hostile \nencounters. The players in finite sexuality not only require \nthe offended resistance of those who refuse to join them in \ntheir play, they require the resistance of those who do join \nthem. \nSexual plotting on the part of one player is in fact stimulated \nby disinterest or fear or loathing on the part of the other. \nA Master Player of finite sexuality chooses not to take these \nattitudes as a way of refusing the sexual game, but takes them \nto be part of the game. Thus my indifference or revulsion \nto your sexuality becomes in your masterful playa sexual indif-\nference, a sexual revulsion. Suddenly I am no longer indifferent \nto your game, but indifferent to you within your game, and \nhave ipso facto made myself your opponent. This is the plot \nof the classical pulp novel and of Hollywood romance: indiffer-\nent girl won by ardent boy. \nThe profound seriousness of such sexual play is seen in \nthe unique nature of the prize that goes to the winner. What \none wants in the sexual contest is not just to have defeated \nthe other, but to have the defeated other. Sexuality is the \nonly finite game in which the winner's prize is the defeated \nopponent. \nSexual titles, like all other titles, have appropriately conspicu-\nous emblems. However, only in sexuality do persons themselves \nbecome property. In slavery or wage labor what we possess \nis not the persons of the slaves or the workers, but the products \nof their labors. In this case, to use Marx's phrase, persons \nare abstracted from their labor. But in sexuality persons are \nFINITE AND INFINITE GAMES \n79 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 264
  },
  {
    "chunk_full": "abstracted from themselves. The seduced opponent is so dis-\nplayed as to draw public attention to the seducer's triumph. \nIn the complex plotting of sexual encounter it is by no means \nuncommon for the partners to have played a double game \nin which each is winner and loser, and each is an emblem \nfor the other's seductive power. \nA society shows its mastery in the management of sexuality \nnot when it sets out unambiguous standards for sexual behavior \nor prescribed attitudes toward sexual feelings, but when it \ninstitutionalizes the emblematic display of sexual conquest. \nThese institutions can be as varied as burning widows alive \non the funeral pyres of their husbands or requiring the high \nvisibility of a spouse at an elected official's inauguration. \nFinite sexuality is a form of theater in which the distance \nbetween persons is regularly reduced to zero but in which \nneither touches the other. \n58 \nInsofar as sexuality is a drama of origin it is original to \nsociety and not derivative of it. It is therefore somewhat mis-\nleading to describe society as a regulator of finite sexual play. \nIt is more the case that finite sexuality shapes society than \nis shaped by it. Only to a limited extent do we take on the \nsexual roles assigned us by society. Much more frequently \nwe enter into societal arrangements by way of sexual roles. \n(For example, we are more likely to refer to the king as the \nfather of the country than we are to refer to the father as \nking of the family.) While society does serve a regulatory \nfunction, it is probably more correctly understood as sexuality \nmaking use of society to regulate itself. \nThis means that society plays little or no role in either \n80 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 265
  },
  {
    "chunk_full": "causing or preventing sexual tensions. On the contrary, society \nabsorbs sexual tensions into all of its structures. It becomes \nthe larger theater for playing out the patterns of resentment \nlearned in the family. Society is where we prove to parents \nqua audience that we are not what we thought they thought \nwe were. Since the emphasis in this relationship is not on \nwhat our parents thought of us but on what we thought they \nthought, they become an audience that easily survives their \nphysical absence or death. Moreover, for the same reason \nthey become an audience whose definitive approval we can \nnever win. \nTo use Freud's famous phrase, the civilized are, therefore, \nthe discontent. We do not become losers in civilization but \nbecome civilized as losers. The collective result of this ineradi-\ncable sense of failure is that civilizations take on the spirit \nof resentment. Acutely sensitive to an imagined audience, \nthey are easily offended by other civilizations. Indeed, even \nthe most powerful societies can be embarrassed by the weak-\nest: the Soviet Union by Afghanistan, Great Britain by Argen-\ntina, the United States by Grenada. \nThis is also why the only true revolutionary act is not the \noverthrow of the father by the son-which only reinforces \nthe existing patterns of resentment-but the restoration of \ngenius to sexuality. It is by no means an accident that the \nonly successful attempt of the American citizenry to force \nthe ending of a foreign war occurred simultaneously with a \nwide revision in sexual attitudes. The civilization quickly recov-\nered from this threat, however, by tempting these revolutionar-\nies into a new sexual politics, one of societal standoff, where \nsexual genius is confused with such struggles as the passage \nof the Equal Rights Amendment and the election of women \nto national office. \nThere is one other way in which society is shaped by the \nFINITE AND INFINITE GAMES \n81 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 266
  },
  {
    "chunk_full": "tensions of finite sexuality: in its orientation toward property. \nSince sexuality is the only finite game in which the winner's \nprize is the loser, the most desirable form of property is the \npublicly acknowledged possession of another's person, a rela-\ntionship to which the possessed must of course freely consent. \nAll other forms of property are considerably less desirable, \neven when they are vast in quantity. The true value of my \nproperty, in fact, varies not with its monetary worth but with \nits effectiveness in winning for me the declaration that I am \nthe Master Player in our game with each other. \nThe most serious struggles are those for sexual property. \nFor this wars are fought, lives are generously risked, great \nschemes are initiated. However, who wins empire, fortune, \nand fame but loses in love has lost in everything. \n59 \nBecause finite, or veiled, sexuality is one or another struggle \nwhich its participants mean to win, it is oriented toward mo-\nments, outcomes, final scenes. Like all finite play it proceeds \nlargely by deception. Sexual desires are usually not directly \nannounced but concealed under a series of feints, gestures, \nstyles of dress, and showy behavior. Seductions are staged, \nscripted, costumed. Certain responses are sought, plots are \ndeveloped. In skillful seductions delays are employed, special \ncircumstances and settings are arranged. \nSeductions are designed to come to an end. Time runs \nout. The play is finished. All that remains is recollection, the \nmemory of a moment, and perhaps a longing for its repetition. \nSeductions cannot be repeated. Once one has won or lost \nin a particular finite game, the game cannot be played over. \n82 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 267
  },
  {
    "chunk_full": "Moments once reached cannot be reached again. Lovers often \nsustain vivid reminders of extraordinary moments, but they \nare reminded at the same time of their impotence in recreating \nthem. The appetite for novelty in lovemaking-new positions, \nthe use of drugs, exotic surroundings, additional partners-\nis only a search for new moments that can live on only in \nrecollection. \nAs with all finite play, the goal of veiled sexuality is to \nbring itself to an end. \n60 \nBy contrast, infinite players have no interest in seduction \nor in restricting the freedom of another to one's own bound-\naries of play. Infinite players recognize choice in all aspects \nof sexuality. They may see in themselves and in others, for \nexample, the infant's desire to compete for the mother, but \nthey also see that there is neither physiological nor societal \ndestiny in sexual !,atterns. Who chooses. to compete with an-\nother can also choose to play with another. \nSexuality is not a bounded phenomenon but a horizonal \nphenomenon for infinite players. One can never say, therefore, \nthat an infinite player is homosexual, or heterosexual, or celi-\nbate, or adulterous, or faithful-because each of these defini-\ntions has to do with boundaries, with circumscribed areas \nand styles of play. Infinite players do not play within sexual \nboundaries, but with sexual boundaries. They are concerned \nnot with power but with vision. \nIn their sexual play they suffer others, allow them to be \nas they are. Suffering others, they open themselves. Open, \nthey learn both about others and about themselves. Learning, \nFINITE AND INFINITE GAMES \n83 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 268
  },
  {
    "chunk_full": "they grow. What they learn is not about sexuality, but how \nto be more concretely and originally themselves, to be the \ngenius of their own actions, to be whole. \nMoving therefore from an original center, the sexual engage-\nments of infinite players have no standards, no ideals, no marks \nof success or failure. Neither orgasm nor conception is a goal \nin their play, although either may be part of the play. \n61 \nThere is nothing hidden in infinite sexuality. Sexual desire \nis exposed as sexual desire and is never therefore serious. Its \nsatisfaction is never an achievement, but an act in a continuing \nrelationship, and therefore joyous. Its lack of satisfaction is \nnever a failure, but only a matter to be taken on into further \nplay. \nInfinite lovers mayor may not have a family. Rousseau \nsaid the only human institution that is not conventional is \nthe family, which for a brief time is required by nature. Rous-\nseau erred. No family is united by natural or any other kind \nof necessity. Families can convene only out of choice. The \nfamily of infinite lovers has this difference, that it is self-evi-\ndently chosen. It is a progressive work of unveiling. Fathering \nand mothering are roles freely assumed but always with the \ndesign of showing them to be theatrical. It is the intention \nof parents in such families to make it plain to their children \nthat they all play cultural and not societal roles, that they \nare only roles, and that they are all truly concrete persons \nbehind them. Therefore, children also learn that they have \na family only by choosing to have it, by a collective act to \nbe a family with each other. \n84 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 269
  },
  {
    "chunk_full": "62 \nInfinite sexuality does not focus its attention on certain \nparts or regions of the body. Infinite lovers have no \"private \nparts.\" They do not regard their bodies as having secret zones \nthat can be exposed or made accessible to others for special \nfavors. It is not their bodies but their persons they make \naccessible to others. \nThe paradox of infinite sexuality is that by regarding sexual-\nity as an expression of the person and not the body, it becomes \nfully embodied play. It becomes a drama of touching. \nThe triumph of finite sexuality is to be liberated from play \ninto the body. The essence of infinite sexuality is to be liberated \ninto play with the body. In finite sexuality I expect to relate \nto you as a body; in infinite sexuality I expect to relate to \nyou in your body. \nInfinite lovers conform to the sexual expectations of others \nin a way that does not expose something hidden, but unveils \nsomething in plain sight: that sexual engagement is a poiesis \nof free persons. In this exposure they emerge as the persons \nthey are. They meet others with their limitations, and not \nwithin their limitations. In doing so they expect to be trans-\nformed-and are transformed. \nFINITE AND INFINITE GAMES \n85 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 270
  },
  {
    "chunk_full": "",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 271
  },
  {
    "chunk_full": "FOUR \nA FINITE GAME \nOCCURS WITHIN \nA WORLD \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 272
  },
  {
    "chunk_full": "",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 273
  },
  {
    "chunk_full": "63 \nA FINITE GAME occurs within a world. The fact that it must \nbe limited temporally, numerically, and spatially means that \nthere is something against which the limits stand. There is \nan outside to every finite game. Its limits are meaningless \nunless there is something to be limited, unless there is a larger \nspace, a longer time, a greater number of possible competitors. \nThere is nothing about a finite game, in itself, that deter-\nmines at what time it is to be played, or by whom, or where. \nThe rules of a finite game will indicate the temporal, spatial, \nand numerical nature of the game itself; that, for example, \nit will last sixty minutes, will be played on a field 100 yards \nin length, and by two teams of eleven players each. But the \nrules do not, and cannot, determine the date, the location, \nand the specific participants. There is nothing in the rules \nthat requires professional teams composed of certain persons, \nearning salaries of specified amounts, joining at the end of \neach season in a national championship. The rules for the \npractice of medicine or for the exercise of the office of the \nBishop of Rome do not indicate which persons are to enter \nthese games; which kinds of persons, yes, but never the names \nof anyone. \nFINITE AND INFINITE GAMES \n89 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 274
  },
  {
    "chunk_full": "A world provides an absolute reference without which the \ntime, place, and participants make no sense. \nWhatever occurs within a game is relatively intelligible with \nreference to whatever else has happened inside its boundaries, \nbut it is absolutely intelligible with reference to that world \nfor the sake of which its boundaries exist. \nIt is relatively intelligible to have won an election for the \npresidency by a few thousand votes after a campaign of about \nten months; it is absolutely intelligible to be the sixteenth \nPresident of the United States, a society unambiguously \nmarked off from all the rest of the world by its declared bound-\naries, in the 1,860th year of that world's history. \nWe cannot have a precise understanding of what it means \nto be the winner of a contest until we can place the game \nin the absolute dimensions of a world. \n64 \nWorld exists in the form of audience. A world is not all that \nis the case, but that which determines all that is the case. \nAn audience consists of persons observing a contest without \nparticipating in it. \nNo one determines who an audience will be. No exercise \nof power can make a world. A world must be its own spontane-\nous source. \"A world worlds\" (Heidegger). Who must be a \nworld cannot be a world. \nThe number of persons who join an audience is irrelevant. \nSo is the time and space in which an audience occurs. The \ntemporal and spatial boundaries of a finite game must be \nabsolute-in relation to an audience or a world. But when \nand where a world occurs, and whom it includes, is of no \nimportance. One does not say, \"I was in the world, or audience, \n90 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 275
  },
  {
    "chunk_full": "on November 22, 1963,\" but rather, \"I was just getting out \nof the car thinking about what to cook for dinner when I \nheard that the President had been shot.\" An audience does \nnot receive its identity according to the persons within it, \nbut according to the events it observes. Those who remember \nthat day remember precisely what they were doing in the \nearly afternoon of that day, not because it was the 22d of \nNovember, but because it was at that moment that they be-\ncame audience to the events of that day. \nIf the boundaries of an audience are irrelevant, what is \nrelevant is the unity of the audience. They must be a singular \nentity, bound in their desire to see who will win the contest \nbefore them. Anyone for whom this desire is not primary is \nnot in the audience for that contest, and is not a person in \nthat world. \nThe fact that a finite game needs an audience before which \nit can be played, and the fact that an audience needs to be \nsingularly absorbed in the events before it, show the crucial \nreciprocity of finite play and the world. Finite players need \nthe world to provide an absolute reference for understanding \nthemselves; simultaneously, the world needs the theater of \nfinite play to remain a world. George Eliot's villainous charac-\nter, Grandcourt, \"did not care a languid curse for anyone's \nadmiration; but this state of non-caring, just as much as desire, \nrequired its related object-namely, a world of admiring and \nenvying spectators: for if you are fond of looking stonily at \nsmiling persons, the persons must be there and they must \nsmile.\" \nWeare players in search of a world as often as we are \nworld in search of players, and sometimes we are both at \nonce. Some worlds pass quickly into existence, and quickly \nout of it. Some sustain themselves for longer periods, but \nno world lasts forever. \nFINITE AND INFINITE GAMES \n91 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 276
  },
  {
    "chunk_full": "65 \nThere is an indefinite number of worlds. \n66 \nThe reciprocity of game and world has another, deeper \neffect on the persons involved. Because the seriousness of \nfinite play derives from the players' need to correct another's \nputative assessment of themselves, there is no requirement \nthat the audience be physically present, since players are al-\nready their own audience. Just as in finite sexuality where \nthe absence or death of parents has no effect on the child's \ndetermination to prove them wrong, finite players become \ntheir own hostile observers in the very act of competing. \nI cannot be a finite player without being divided against \nmyself. \nA similar dynamic is found in the audience. When suffi-\nciently oblivious to their status as audience, the observers of \na finite game become so absorbed in its conduct that they \nlose the sense of distance between themselves and the players. \nIt is they, quite as much as the players, who win or lose. \nFor this reason the audience absorbs in itself the same politics \nof resentment that moves players to show they are not what \nthey think others think they are. The audience is under the \nsame constraint to disprove this judgment. \nWhen we ask where an audience will find its own audience, \nwe discover the division inherent in all audiences. Each side \nof a conflict comes with its own partisan observers. Inasmuch \nas the conflict is expressed within the bounded playing of a \n92 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 277
  },
  {
    "chunk_full": "game, the audience is unified-but its unity consists in its \nopposition to itself. \nWe cannot become a world without being divided against \nourselves. \n67 \nOccurring before a world, theatrically, a finite game occurs \nwithin time. Because it has its boundaries, its beginning and \nend, within the absolute temporal limits established by a world, \ntime for a finite player runs out; it is used up. It is a diminishing \nquantity. \nA finite game does not have its own time. It exists in a \nworld's time. An audience allows players only so much time \nto win their titles. \nEarly in a game time seems abundant, and there appears \na greater freedom to develop future strategies. Late in a game, \ntime is rapidly being consumed. As choices become more lim-\nited they become more important. Errors are more disastrous. \nWe look on childhood and youth as those \"times of life\" \nrich with possibility only because there still seem to remain \nso many paths open to a successful outcome. Each year that \npasses, however, increases the competitive value of making \nstrategically correct decisions. The errors of childhood can \nbe more easily amended than those of adulthood. \nFor the finite player in us freedom is a function of time. \nWe must have time to be free. \nThe passage of time is always relative to that which does \nnot pass, to the timeless. Victories occur in time, but the \ntitles won in them are timeless. Titles neither age nor die. \nFINITE AND INFINITE GAMES \n93 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 278
  },
  {
    "chunk_full": "The points of reference for all finite history are signal triumphs \nmeant never to be forgotten: establishment of the th~one of \nDavid, the birth of the Savior, the journey to Medina, the \nbattle of Hastings, the American, French, Russian, Chinese, \nand Cuban revolutions. \nTime divided into periods is theatrical time. The lapse of \ntime between the opening and closing of an era is a scene \nbetween curtains. It is not a time lived, but a time viewed-\nby both players and audience. The periodization of time pre-\nsupposes a viewer existing outside the boundaries of play, able \nto see the beginning and the end simultaneously. \nThe outcome of a finite game is the past waiting to happen. \nWhoever plays toward a certain outcome desires a particular \npast. By competing for a future prize, finite players compete \nfor a prized past. \n68 \nThe infinite player in us does not consume time but gener-\nates it. Because infinite play is dramatic and has no scripted \nconclusion, its time is time lived and not time viewed. \nAs an infinite player one is neither young nor old, for one \ndoes not live in the time of another. There is therefore no \nexternal measure of an infinite player's temporality. Time does \nnot pass for an infinite player. Each moment of time is a \nbeginning. \nEach moment is not the beginning of a period of time. \nIt is the beginning of an event that gives the time within it \nits specific quality. For an infinite player there is no such \nthing as an hour of time. There can be an hour of love, or \na day of grieving, or a season of learning, or a period of labor. \nAn infinite player does not begin working for the purpose \n94 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 279
  },
  {
    "chunk_full": "of filling up a period of time with work, but for the purpose \nof filling work with time. Work is not an infinite player's \nway of passing time, but of engendering possibility. Work is \nnot a way of arriving at a desired present and securing it \nagainst an unpredictable future, but of moving toward a future \nwhich itself has a future. \nInfinite players cannot say how much they have completed \nin their work or love or quarreling, but only that much remains \nincomplete in it. They are not concerned to determine when \nit is over, but only what comes of it. \nFor the finite player in us freedom is a function of time. \nWe must have the time to be free. For the infinite player \nin us time is a function of freedom. We are free to have \ntime. A finite player puts play into time. An infinite player \nputs time into play. \n69 \nJust as infinite players can play any number of finite games, \nso too can they join the audience of any game. They do so, \nhowever, for the play that is in observing, quite aware that \nthey are audience. They look, but they see that they are look-\nmg. \nInfinite play remains invisible to the finite observer. Such \nviewers are looking for closure, for the ways in which players \ncan bring matters to a conclusion and finish whatever remains \nunfinished. They are looking for the way time has exhausted \nitself, or will soon do so. Finite players stand before infinite \nplayas they stand before art, looking at it, making a poiema \nof it. \nIf, however, the observers see the poiesis in the work they \ncease at once being observers. They find themselves in its \nFINITE AND INFINITE GAMES \n95 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 280
  },
  {
    "chunk_full": "time, aware that it remains unfinished, aware that their reading \nof the poetry is itself poetry. Infected then by the genius of \nthe artist they recover their own genius, becoming beginners \nwith nothing but possibility ahead of them. \nIf the goal of finite play is to win titles for their timelessness, \nand thus eternal life for oneself, the essence of infinite play \nis the paradoxical engagement with temporality that Meister \nEckhart called \"eternal birth.\" \n96 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 281
  },
  {
    "chunk_full": "FIVE \nNATURE Is THE \nREALM OF THE \nUNSPEAKABLE \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 282
  },
  {
    "chunk_full": "",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 283
  },
  {
    "chunk_full": "70 \nNATURE IS the realm of the unspeakable. It has no voice of \nits own, and nothing to say. We experien~e the unspeakability \nof nature as its utter indifference to human culture. \nThe Master Player in us tolerates this indifference scarcely \nat all. Indeed, we respond to it as a challenge, an invitation \nto confrontation and struggle. If nature will offer us no home, \noffer us nothing at all, we will then clear and arrange a space \nfor ourselves. We take nature on as an opponent to be subdued \nfor the sake of civilization. We count among the highest \nachievements of modern society the development of a technol-\nogy that allows us to master nature's vagaries. \nThe effort has largely taken the form of theatricalizing our \nrelation to nature. Like any Master Player we have been pa-\ntiently attentive to the slightest clues in our opponent's behav-\nior-as a way of preparing ourselves against surprise. Like \nhunters stalking their prey, we have learned to mimic the \nmovements of nature, waiting for the chance to take hold \nof them before they get away from us. \"Nature, to be com-\nmanded, must be obeyed\" (Bacon). It is as though, by learning \nits secret script, we have learned to direct its playas well. \nThere is little left to surprise us. \nThe assumption guiding our struggle against nature is that \nFINITE AND INFINITE GAMES \n99 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 284
  },
  {
    "chunk_full": "deep within itself nature contains a structure, an order, that \nis ultimately intelligible to the human understanding. Since \nthis inherent structure determines the way things change, and \nis not itself subject to change, we speak of nature being lawful, \nof repeating itself according to quite predictable patterns. \nWhat we have done by showing that certain events repeat \nthemselves according to known laws is to explain them. Expla-\nnation is the mode of discourse in which we show why matters \nmust be as they are. All laws made use of in explanation \nlook backward in time from the, conclusion or the completion \nof a sequence. It is implicit in all explanatory discourse that \njust as there is a discoverable necessity in the outcome of \npast events, there is a discoverable necessity in future events. \nWhat can be explained can also be predicted, if one knows \nthe initial events and the laws covering their succession. A \nprediction is but an explanation in advance. \nBecause of its thorough lawfulness nature has no genius \nof its own. On the contrary, it is sometimes thought that \nthe grandest discovery of the human genius is the perfect \ncompatibility between the structure of the natural order and \nthe structure of the mind, thereby making a complete under-\nstanding of nature possible. \"One may say 'the eternal mystery \nof the world is its comprehensibility' \" (Einstein). \nThis is as much as to say that nature does have a voice, \nand its voice is no different from our own. We can then \npresume to speak for the unspeakable. \nThis achievement is often raised as a sign of the great \nsuperiority of modern civilization over the many faded and \nlost civilizations of the ancients. While our great skill lies in \nfinding patterns of repetition under the apparent play of acci-\ndent and chance, less successful civilizations dealt with the \nthreats of natural accident by appealing to supernatural powers \n100 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 285
  },
  {
    "chunk_full": "for protection. But the voices of the gods proved to be ignorant \nand false; they have been silenced by the truth. \n71 \nThere is an irony in our silencing of the gods. By presuming \nto speak for the unspeakable, by hearing our own voice as \nthe voice of nature, we have had to step outside the circle \nof nature. I t is one thing for physics and chemistry to be \nspeaking about nature; it is quite another for physics and \nchemistry to be the speaking of nature. No chemist would \nwant to say that chemistry is itself chemical, for our speaking \ncannot be both chemical and about chemistry. If speaking \nabout a process is itself part of the process, there is something \nthat must remain permanently hidden from the speaker. To \nbe intelligible at all, we must claim that we can step aside \nfrom the process and comment on it \"objectively\" and \"dispas-\nsionately,\" without anything obstructing our view of these \nmatters. Here lies the irony: By way of this perfectly reasonable \nclaim the gods have stolen back into our struggle with nature. \nBy depriving the gods of their own voices, the gods have \ntaken ours. It is we who speak as supernatural intelligences \nand powers, masters of the forces of nature. \nThis irony passes unnoticed only so long as we continue \nto veil ourselves against what we can otherwise plainly see: \nnature allows no master over itself. Bacon's principle works \nboth ways. If we must obey to command, then our command-\ning is only obeying and not commanding at all. There is no \nsuch thing as an unnatural act. Nothing can be done to or \nagainst nature, much less outside it. Therefore, the ignorance \nwe thought we could avoid by an unclouded observation of \nFINITE AND INFINITE GAMES \n101 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 286
  },
  {
    "chunk_full": "nature has swept us back into itself. What we thought we \nread in nature we discover we have read into nature. \"We \nhave to remember that what we observe is not nature in itself \nbut nature exposed to our method of questioning\" (Heisen-\nberg). \n72 \nWeare speaking now of no ordinary ignorance. I t is not \nwhat we could have known but do not; it is unintelligibility \nitself: that which no mind can ever comprehend. \nUnveiled, aware of the insuperable limitation placed against \nall our looking, we come back to nature's perfect silence. Now \nwe can see that it is a silence so complete there is no way \nof knowing what it is silent about-if anything. What we \nlearn from this silence is the unlikeness between nature and \nwhatever we could think or say about it. But this silence \nhas an irony of its own: Far from stupefying us, it provides \nan indispensable condition to the mind's own originality. By \nconfronting us with radical unlikeness, nature becomes the \nsource of metaphor. \nMetaphor is the joining of like to unlike such that one \ncan never become the other. Metaphor requires an irreducibil-\nity, an imperturbable indifference of its terms for one another. \nThe falcon can be the \"kingdom of daylight's dauphin\" only \nif the daylight could have no dauphin, could indeed have \nnothing to do with dauphins. \nAt its root all language has the character of metaphor, be-\ncause no matter what it intends to be about it remains lan-\nguage, and remains absolutely unlike whatever it is about. \nThis means that we can never have the falcon, only the word \n\"falcon.\" To say that we have the falcon, and not the \"falcon,\" \n102 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 287
  },
  {
    "chunk_full": "is to presume again that we know precisely what it is we \nhave, that we can see it in its entirety, and that we can speak \nas nature itself. \nThe unspeakability of nature is the very possibility of lan-\nguage. \nOur attempt to take control of nature, to be Master Player \nin our opposition to it, is an attempt to rid ourselves of lan-\nguage. It is the refusal to accept nature as \"nature.\" It is to \ndeafen ourselves to metaphor, and to make nature into some-\nthing so familiar it is essentially an extension of our willing \nand speaking. What the hunter kills is not the deer, but the \nmetaphor of the deer-the \"deer.\" Killing the deer is not \nan act against nature; it is an act against language. To kill \nis to impose a silence that remains a silence. It is the reduction \nof an unpredictable vitality to a predictable mass, the transfor-\nmation of the remote into the familiar. It is to rid oneself \nof the need to attend to its otherness. \nThe physicists who look at their objects within their limita-\ntions teach physics; those who see the limitations they place \naround their objects teach \"physics.\" For them physics is a \npOleSlS. \n73 \nIf nature is the realm of the unspeakable, history is the \nrealm of the speakable. Indeed, no speaking is possible that \nis not itself historical. Students of history, like students of \nnature, often believe they can find unbiased, direct views of \nevents. They look in on the lives of others, noting the multi-\ntude of ways those lives have been limited by the age in \nwhich they were lived. But no one can look in on an age, \neven if it is one's own age, without looking out of an age as \nFINITE AND INFINITE GAMES \n103 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 288
  },
  {
    "chunk_full": "well. There is no refuge outside history for such viewers, any \nmore than there is a vantage outside nature. \nSince history is the drama of genius, its relentless surprise \ntempts us into designing boundaries for it, searching through \nit for patterns of repetition. Historians sometimes speak of \ntrends, of cycles, of currents, of forces, as though they were \ndescribing natural events. In doing so they must dehistoricize \nthemselves, taking a perspective from the timeless, believing \nthat each observed history is always of others and never of \nthemselves, that each observation is of history but not itself \nhistorical. \nGenuine historians therefore reverse the assumption of the \nobservers of nature that the observation itself cannot be an \nact of nature. Historians who understand themselves to be \nhistorical abandon explanation altogether. The mode of dis-\ncourse appropriate to such self-aware history is narrative. \nLike explanation, narrative is concerned with a sequence \nof events and brings its tale to a conclusion. However, there \nis no general law that makes this outcome necessary. In a \ngenuine story there is no law that makes any act necessary. \nExplanations place all apparent possibilities into the context \nof the necessary; stories set all necessities into the context \nof the possible. \nExplanation can tolerate a degree of chance, but it cannot \ncomprehend freedom at all. We explain nothing when we \nsay that persons do whatever they do because they choose \nto do it. On the other hand, causation cannot find a place \nin narrative. We have not told a story when we show that \npersons do whatever they do because they were caused to \ndo it-by their genes, their social circumstances, or the influ-\nence of the gods. \nExplanations settle issues, showing that matters must end \nas they have. Narratives raise issues, showing that matters \n104 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 289
  },
  {
    "chunk_full": "do not end as they must but as they do. Explanation sets \nthe need for further inquiry aside; narrative invites us to \nrethink what we thought we knew. \nIf the silence of nature is the possibility of language, lan-\nguage is the possibility of history. \n74 \nSuccessful explanations do not draw attention to themselves \nas modes of speaking, because what is explained is not itself \nsubject to history. If I explain to you why cold water sinks \nto the bottom of the pond and ice rises to the surface, I \ncertainly do not intend my explanation to be true now and \nnot later. The explanation is true anywhere and any time. \nThat I choose to explain this to you in this time and place, \nhowever, is historical; it is an event-the narrative of our \nrelation with each other. There must therefore be a reason \nfor the speaking of this verity. Explanations are not offered \ngratuitiously, just because, say, ice happens to float. I can \nexplain nothing to you unless I first draw your attention to \npatent inadequacies in your knowledge: discontinuities in the \nrelations between objects, or the presence of anomalies you \ncannot account for by any of the laws known to you. You \nwill remain deaf to my explanations until you suspect yourself \nof falsehood. \nMany of these suspicions are, of course, minor, requiring \nmerely small adjustments in one's views, incurring no doubt \nwhatsoever concerning those views. Major challenges, how-\never, are too serious to be met with argument, or with sharp-\nened explanation. They call either for outright and wholesale \nrejection, or for conversion. One does not cross over from \nManichaeism to Christianity, or from Lamarckianism to Dar-\nFINITE AND INFINITE GAMES \n\\05 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 290
  },
  {
    "chunk_full": "winism, by a mere adjustment of views. True conversions con-\nsist in the choice of a new audience, that is, of a new world. \nAll that was once familiar is now seen in startlingly new ways. \nAs theatrical as conversions are, they remain oblivious to \nthe degree to which choice is involved in the passage from \none world to another. Radical conversions, especially, veil \nthemselves against their own arbitrariness. Augustine, the most \nfamous convert of antiquity, was puzzled that he could have \nheld so firmly to so many different falsehoods; he was not \nastounded that there are so many different truths. His conver-\nsion was not from explanation to narrative, but from one \nexplanation to another. When he crossed the line from pagan-\nism to Christianity, he arrived in the territory of a truth beyond \nfurther challenge. \nExplanations succeed only by convincing resistant hearers \nof their error. If you will not hear my explanations until you \nare suspicious of your own truths, you will not accept my \nexplanations until you are convinced of your error. Explanation \nis an antagonistic encounter that succeeds by defeating an \nopponent. It possesses the same dynamic of resentment found \nin other finite play. I will press my explanations on you because \nI need to show that I do not live in the error that I think \nothers think I do. \nWhoever wins this struggle is privileged with the claim \nto true knowledge. Knowledge has been arrived at, it is the \noutcome of this engagement. I ts winners have the uncontested \npower to make certain statements of fact. They are to be \nlistened to. In those areas appropriate to the contests now \nconcluded, winners possess a knowledge that no longer can \nbe challenged. \nKnowledge, therefore, is like property. It must be published, \ndeclared, or in some other way so displayed that others cannot \n106 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 291
  },
  {
    "chunk_full": "but take account of it. It must stand in their way. It must \nbe emblematic, pointing backward at its possessor's competi-\ntive skill. \nSo close are knowledge and property that they are often \nthought to be continuous. Those who are entitled to knowl-\nedge feel they should be granted property as well, and those \nwho are entitled to property believe a certain knowledge goes \nwith it. Scholars demand higher salaries for their publishable \nsuccesses; industrialists sit on university boards. \n75 \nIf explanation, to be successful, must be oblivious to the \nsilence of nature, it must also in its success impose silence \non its listeners. Imposed silence is the first consequence of \nthe Master Player's triumph. \nWhat one wins in a title is the privilege of magisterial \nspeech. The privilege of magisterial speech is the highest honor \nattaching to any title. We expect the first act of a winner \nto be a speech. The first act of the loser may also be a speech, \nbut it will be a speech to concede victory, to declare there \nwill be no further challenge to the winner. It is a speech \nthat promises to silence the loser's voice. \nThe silence to which the losers pledge themselves is the \nsilence of obedience. Losers have nothing to say; nor have \nthey an audience who would listen. The vanquished are effec-\ntively of one will with the victors, and of one mind; they \nare completely incapable of opposition, and therefore without \nany otherness whatsoever. \nThe victorious do not speak with the defeated; they speak \nfor the defeated. Husbands speak for wives in the finite family, \nFINITE AND INFINITE GAMES \n107 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 292
  },
  {
    "chunk_full": "and parents for their children. Kings speak for the realm, \ngovernors for the state, popes for the church. Indeed, the \ntitled, as titled, cannot speak with anyone. \nIt is chiefly in magisterial speech that the power of winners \nresides. To be powerful is to have one's words obeyed. It is \nonly by magisterial speech that the emblematic property of \nwinners can be safeguarded. Those entitled to their possessions \nhave the privilege of calling the police, calling up an army, \nto force the recognition of their emblems. \nThe power of gods is known principally through their utter-\nances. The sicut dixit dominus (thus says the lord) is always \na signal for ritual silence. The speech of a god can be so \nperfectly expressive of that god's power that the god and its \nspeech become identical: \"In the beginning was the word. \nThe word was with God, and the word was God.\" \nOne is speechless before a god, or silent before a winner, \nbecause it no longer matters to others what one has to say. \nTo lose a contest is to become obedient; to become obedient \nis to lose one's listeners. The silence of obedience is an unheard \nsilence. It is the silence of death. For this reason the demand \nfor obedience is inherently evil. \nThe silence of nature is the possibility of language. By subdu-\ning nature the gods give it their own voice, but in making \nnature an opponent they make all their listeners opponents. \nBy refusing the silence of nature they demand the silence \nof obedience. The unspeakability of nature is therefore trans-\nformed into the unspeakability of language itself. \n76 \nInfinite speech is that mode of discourse that consistently \nreminds us of the unspeakability of nature. It bears no claim \n108 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 293
  },
  {
    "chunk_full": "to truth, originating from nothing but the genius of the \nspeaker. Infinite speech is therefore not about anything; it \nis always to someone. I t is not command, but address. 1 t \nbelongs entirely to the speakable. \nThat language is not about anything gives it its status as \nmetaphor. Metaphor does not point at something there. Never \nshall we find the kingdom of daylight's dauphin in one place \nor another. It is not the role of metaphor to draw our sight \nto what is there, but to draw our vision toward what is not \nthere and, indeed, cannot be anywhere. Metaphor is horizonal, \nreminding us that it is one's vision that is limited, and not \nwhat one is viewing. \nThe meaning of a finite speaker's discourse lies in what \nprecedes its utterance, what is already the case and therefore \nis the case whether or not it is spoken. \nThe meaning of an infinite speaker's discourse lies in what \ncomes of its utterance-that is, whatever is the case because \nit is spoken. \nFinite language exists complete before it is spoken. There \nis first a language-then we learn to speak it. Infinite language \nexists only as it is spoken. There is first a language-when \nwe learn to speak it. It is in this sense that infinite discourse \nalways arises from a perfect silence. \nFinite speakers come to speech with their voices already \ntrained and rehearsed. They must know what they are doing \nwith the language before they can speak it. Infinite speakers \nmust wait to see what is done with their language by the \nlisteners before they can know what they have said. Infinite \nspeech does not expect the hearer to see what is already known \nto the speaker, but to share a vision the speaker could not \nhave had without the response of the listener. \nSpeaker and listener understand each other not because \nthey have the same knowledge about something, and not be-\nFINITE AND INFINITE GAMES \n109 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 294
  },
  {
    "chunk_full": "cause they have established a likeness of mind, but because \nthey know \"how to go on\" with each other (Wittgenstein). \n77 \nBecause it is address, attending always on the response of \nthe addressed, infinite speech has the form of listening. Infinite \nspeech does not end in the obedient silence of the hearer, \nbut continues by way of the attentive silence of the speaker. \nIt is not a silence into which speech has died, but a silence \nfrom which speech is born. \nInfinite speakers do not give voice to another, but receive \nit from another. Infinite speakers do not therefore appeal to \na world as audience, do not speak before a world, but present \nthemselves as an audience by way of talking with others. Finite \nspeech informs another about the world-for the sake of being \nheard. Infinite speech forms a world about the other-for \nthe sake of listening. \nI t is for this reason that the gods, insofar as they speak as \nthe lords of this world, magisterially, speak before this world \nand are therefore unable to change it. Such gods cannot create \na world but can only be creations of a world-can only be \nidols. A god cannot create a world and be magisterial within \nit. \"The religions which represent divinity as commanding \nwhenever it has the power to do so seem false. Even though \nthey are monotheistic they are idolatrous\" (Weil). \nA god can create a world only by listening. \nWere the gods to address us it would not be to bring us \nto silence through their speech, but to bring us to speech \nthrough their silence. \nThe contradiction of finite speech is that it must end by \nbeing heard. The paradox of infinite speech is that it continues \n110 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 295
  },
  {
    "chunk_full": "only because it is a way of listening. Finite speech ends with \na silence of closure. Infinite speech begins with a disclosure \nof silence. \n78 \nStorytellers do not convert their listeners; they do not move \nthem into the territory of a superior truth. Ignoring the issue \nof truth and falsehood altogether, they offer only vision. Story-\ntelling is therefore not combative; it does not succeed or fail. \nA story cannot be obeyed. Instead of placing one body of \nknowledge against another, storytellers invite us to return from \nknowledge to thinking, from a bounded way of looking to \nan horizonal way of seeing. \nInfinite speakers are Plato's poietai taking their place in \nthe historical. Storytellers enter the historical not when their \nspeaking is full of anecdotes about actual persons, or when \nthey appear as characters in their own tales, but when in \ntheir speaking we begin to see the narrative character of OUT \nlives. The stories they tell touch us. What we thought was \nan accidental sequence of experiences suddenly takes the dra-\nmatic shape of unresolved narrative. \nThere is no narrative without structure, or plot. In a great \nstory this structure seems like fate, like an inescapable judg-\nment descending on its still unaware heroes, a great metaphys-\nical causality that crowds out all room for choice. Fate arises \nnot as a limitation on our freedom, but as a manifestation \nof our freedom, testimony that choice is consequent. The \nexercise of your freedom cannot prevent the exercise of my \nown freedom, but it can determine the context in which I \nam to act freely. You cannot make choices for me, but you \ncan largely determine what my choices will be about. Great \nFINITE AND INFINITE GAMES \nIII \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 296
  },
  {
    "chunk_full": "stories explore the drama of this deeper touching of one free \nperson by another. They are therefore genuinely sexual dramas \nastounding us once more with the magic of origins. \nThe myth of Oedipus is one of many great sexual narratives \nin the cultural treasury of the West that plays on the dramatic \nrelation of fate and origin. Once Oedipus had impulsively \nkilled Laius, not knowing he was his own father, he was carried \nahead by ambition and lust into marriage with the dead man's \nwife, unaware of her true identity. We can read this as fate \nor we can read it as one act of willfulness that leads to another. \nOedipus has taken the posture of the Master Player executing \nterminal moves-but the moves are not terminal. Oedipus \nis able to bring nothing to an end. Even the act of blinding \nhimself, meant as a kind of concluding gesture, only brings \nhim to a higher vision. What Oedipus sees is not what the \ngods have done to him, but what he has done. He learns \nthat what had been limited was his vision, and not what he \nwas viewing. His blinding is an unveiling, and like all unveiling \nit is self-unveiling. Confronted in the end with nothing but \nhis own genius, Oedipus is finally able to touch. The end of \nhis story is a beginning. \nWhat raises this story into the historical is not just that \nOedipus sees; it is that we see that he sees. We become \nlisteners who see that we are listening and therefore participat-\ning in a now enlarged drama of origins. Nothing is explained \nhere. On the contrary, what we see is that everything remains \nstill to be said. \n79 \nThere is a risk here of supposing that because we know \nour lives to have the character of narrative, we also know \n112 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 297
  },
  {
    "chunk_full": "what that narrative is. If I were to know the full story of \nmy life I would then have translated it back into explanation. \nIt is as though I could stand as audience to myself, seeing \nthe opening scene and the final scene at the same time, as \nthough I could see my life in its entirety. In doing so I would \nbe performing it, not living it. \nSocietal theorists are tempted into the belief that they know \nthe story of a civilization. They can script its final scene of \ntriumph or defeat. It is by way of such end-of-history thinking \nthat the discovered laws of behavior to which persons conform \nbecome the scripted laws of behavior to which they must \nconform. \nTrue storytellers do not know their own story. What they \nlisten to in their poiesis is the disclosure that wherever there \nis closure there is the possibility of a new opening, that they \ndo not die at the end, but in the course of play. Neither do \nthey know anyone else's story in its entirety. The primary \nwork of historians is to open all cultural termini, to reveal \ncontinuity where we have assumed something has ended, to \nremind us that no one's life, and no culture, can be known, \nas one would know a poiema, but only learned, as one would \nlearn a poiesis. \nHistorians become infinite speakers when they see that \nwhatever begins in freedom cannot end in necessity. \nFINITE AND INFINITE GAMES \n11 3 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 298
  },
  {
    "chunk_full": "",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 299
  },
  {
    "chunk_full": "SIX \nWE CONTROL \nNATURE FOR \nSOCIETAL \nREASONS \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 300
  },
  {
    "chunk_full": "",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 301
  },
  {
    "chunk_full": "80 \nWE CONTROL NATURE for societal reasons. The control of \nnature advances with our ability to predict the outcome of \nnatural processes. Inasmuch as predictions are but explanations \nin reverse, it is possible that they will be quite as combative \nas explanations. Indeed, prediction is the most highly devel-\noped skill of the Master Player, for without it control of an \nopponent is all the more difficult. I t follows that our domina-\ntion of nature is meant to achieve not certain natural outcomes, \nbut certain societal outcomes. \nA small group of physicists, using calcuiations of the highest \nknown abstraction, uncovered a predictable sequence of sub-\natomic reactions that led directly to the construction of a \nthermonuclear bomb. It is true that the successful detonation \nof the bomb proved the predictions of the physicists, but it \nis also true that we did not explode the bomb to prove them \ncorrect; we exploded it to control the behavior of millions \nof persons and to bring our relations with them to a certain \nclosure. \nWhat this example shows is not that we can exercise power \nover nature, but that our attempt to do so masks our desire \nfor power over each other. This raises a question as to the \nFINITE AND INFINITE GAMES \n117 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 302
  },
  {
    "chunk_full": "cultural consequences of abandoning the strategy of power \nin our attitude toward nature. \nThe alternative attitudes toward nature can be characterized \nin a rough way by saying that the result of approaching nature \nas a hostile Other whose designs are basically inimical to our \ninterests is the machine, while the result of learning to disci-\npline ourselves to consist with the deepest discernable patterns \nof natural order is the garden. \n\"Machine\" is used here as inclusive of technology and not \nas an example of it-as a way of drawing attention to the \nmechanical rationality of technology. We might be surprised \nby the technological devices that spring from the imagination \nof gifted inventors and engineers, but there is nothing surpris-\ning in the technology itself. The physicists' bomb is as thor-\noughly mechanical as the Neanderthal's lever-each the \nexercise of calculable cause-and-effect sequences. \n\"Garden\" does not refer to the bounded plot at the edge \nof the house or the margin of the city. This is not a garden \none lives beside, but a garden one lives within. It is a place \nof growth, of maximized spontaneity. To garden is not to \nengage in a hobby or an amusement; it is to design a culture \ncapable of adjusting to the widest possible range of surprise \nin nature. Gardeners are acutely attentive to the deep patterns \nof natural order, but are also aware that there will always be \nmuch lying beyond their vision. Gardening is a horizonal activ-\nity. \nMachine and garden are not absolutely opposed to each \nother. Machinery can exist in the garden quite as finite games \ncan be played within an infinite game. The question is not \none of restricting machines from the garden but asking \nwhether a machine serves the interest of the garden, or the \nliB \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 303
  },
  {
    "chunk_full": "garden the interest of the machine. We are familiar with a \nkind of mechanized gardening that has the appearance of \nhigh productivity, but looking closely we can see that what \nis intended is not the encouragement of natural spontaneity \nbut its harnessing. \n81 \nThe most elemental difference between the machine and \nthe garden is that one is driven by a force which must be \nintroduced from without, the other grown by an energy which \noriginates from within itself. \nCertainly machines of extraordinary complexity have been \nbuilt: spacecraft, for example, that sustain themselves for \nmonths in the void while performing complicated functions \nwith great accuracy. But no machine has been made, nor \ncan one be made, that has the source of its spontaneity within \nitself. A machine must be designed, constructed, and fueled. \nCertainly gardens can be treated with such a range of chemi-\ncal and technological strategies that we can speak of \"raising\" \nfood, and of the food we have raised as \"produce.\" But no \nway has been found, or can be found, by which organic growth \ncan be forced from without. The application of fertilizers, \nherbicides, and any number of other substances does not alter \ngrowth but allows growth; it is meant to consist with natural \ngrowth. A plant cannot be designed or constructed. Though \nwe seem to give it \"fuel\" in the form of rich earth and appropri-\nate nutrients, we depend on the plant to make use of the \nfuel by way of its own vitality. A machine depends on its \ndesigner and its operator both for the supply of fuel and its \nFINITE AND INFINITE GAMES \n119 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 304
  },
  {
    "chunk_full": "consumption. A machine has not the merest trace of its own \nspontaneity or vitality. Vitality cannot be given, only found. \n82 \nJust as nature has no outside, it has no inside. It is not \ndivided within itself and cannot therefore be used for or against \nitself. There is no inherent opposition of the living and the \nnonliving within nature; neither is more or less natural than \nthe other. The use of agricultural poisons, for example, will \nsurely kill selected organisms; it will arrest the spontaneity \nof living entities-but it is not an unnatural act. Nature has \nnot been changed. All that changes is the way we discipline \nourselves to consist with natural order. \nOur freedom in relation to nature is not the freedom to \nchange nature; it is not the possession of power over natural \nphenomena. It is the freedom to change ourselves. We are \nperfectly free to design a culture that will turn on the awareness \nthat vitality cannot be given but only found, that the given \npatterns of spontaneity in nature are not only to be respected, \nbut to be celebrated. \nAlthough \"natural order\" is the common expression, it has \nsomething of a veiling quality about it. More properly speaking, \nit is not the order of nature but its irreducible spontaneity \nwith which we find ourselves contending. That nature has \nno outside, and no inside, that it suffers no opposition to \nitself, that it is not moved by unnatural influence, is not the \nexpression of an order so much as it is the display of a perfect \nindiHerence on nature's part to all matters cultural. \nNature's source of movement is always from within itself; \nindeed it is itself. And it is radically distinct from our own \nsource of movement. This is not to say that, possessing no \n120 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 305
  },
  {
    "chunk_full": "order, nature is chaotic. It is neither chaotic nor ordered. \nChaos and order describe the cultural experience of nature-\nthe degree to which nature's indifferent spontaneity seems \nto agree with our current manner of cultural self-control. A \nhurricane, or a plague, or the overpopulation of the earth \nwill seem chaotic to those whose cultural expectations are \ndamaged by them and orderly to those whose expectations \nhave been confirmed by them. \n83 \nThe paradox in our relation to nature is that the more \ndeeply a culture respects the indifference of nature, the more \ncreatively it will call upon its own spontaneity in response. \nThe more clearly we remind ourselves that we can have \nno unnatural influence on nature, the more our culture will \nembody a freedom to embrace surprise and unpredictabil-\nity. \nHuman freedom is not a freedom over nature; it is the \nfreedom to be natural, that is, to answer to the spontaneity \nof nature with our own spontaneity. Though we are free to \nbe natural, we are not free by nature; we are free by culture, \nby history. \nThe contradiction in our relation to nature is that the more \nvigorously we attempt to force its agreement with our own \ndesigns the more subject we are to its indifference, the more \nvulnerable to its unseeing forces. The more power we exercise \nover natural process the more powerless we become before \nit. In a matter of months we can cut down a rain forest \nthat took tens of thousands of years to grow, but we are helpless \nin repulsing the desert that takes its place. And the desert, \nof course, is no less natural than the forest. \nFINITE AND INFINITE GAMES \n121 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 306
  },
  {
    "chunk_full": "84 \nSuch contradiction is most obvious in the matter of machin-\nery. We make use of machines to increase our power, and \ntherefore our control, over natural phenomena. By exerting \nthemselves no more than is necessary to operate fingertip con-\ntrols, a team of workers can cut six-lane highways through \nmountains and dense forest, or fill in wetlands to build shop-\nping malls. \nWhile a machine greatly aids the operator in such tasks, \nit also disciplines its operator. As the machine might be consid-\nered the extended arms and legs of the worker, the worker \nmight be considered an extension of the machine. All ma-\nchines, and especially very complicated machines, require oper-\nators to place themselves in a provided location and to perform \nfunctions mechanically adapted to the functions of the ma-\nchine. To use the machine for control is to be controlled \nby the machine. \nTo operate a machine one must operate like a machine. \nUsing a machine to do what we cannot do, we find we must \ndo what the machine does. \nMachines do not, of course, make us into machines when \nwe operate them; we make ourselves into machinery in order \nto op~rate them. Machinery does not steal our spontaneity \nfrom us; we set it aside ourselves, we deny our originality. \nThere is no style in operating a machine. The more efficient \nthe machine, the more it either limits or absorbs our unique-\nness into its operation. \nIndeed, we come to think that the style of operation does \nnot belong to the operator at all, but is inherent in the ma-\nchine. Advertisers and manufacturers speak of their products \nas though they have designed style into them. Most consumer \nproducts are \"styled\" inasmuch as they actually standardize \n122 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 307
  },
  {
    "chunk_full": "the activity or the taste of the consumer. In a perfect contradic-\ntion we are urged to buy a \"styled\" artifact because others \nare also buying it-that is, we are asked to express our genius \nby giving up our genius. \nBecause we make use of machinery in the belief we can \nincrease the range of our freedom, and instead only decrease \nit, we use machines against ourselves. \n85 \nMachinery is contradictory in another way. Just as we use \nmachinery against ourselves, we also use machinery against \nitself. A machine is not a way of doing something; it stands \nin the way of doing something. \nWhen we use machines to achieve whatever it is we desire, \nwe cannot have what we desire until we have finished with \nthe machine, until we can rid ourselves of the mechanical \nmeans of reaching our intended outcome. The goal of technol-\nogy is therefore to eliminate itself, to become silent, invisible, \ncarefree. \nWe do not purchase an automobile, for example, merely \nto own some machinery. Indeed, it is not machinery we are \nbuying at all, but what we can have by way of it: a means \nof rapidly carrying us from one location to another, an object \nof envy for others, protection from the weather. Similarly, a \nradio must cease to exist as equipment and become sound. \nA perfect radio will draw no attention to itself, will make it \nseem we are in the very presence of the source of its sound. \nNeither do we watch a movie screen, nor look at television. \nWe look at what is on television, or in the movie, and become \nannoyed when the equipment intrudes-when the film is unfo-\ncused or the picture tube malfunctions. \nFINITE AND INFINITE GAMES \n123 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 308
  },
  {
    "chunk_full": "When machinery functions perfectly it ceases to be there-\nbut so do we. Radios and films allow us to be where we are \nnot and not be where we are. Morever, machinery is veiling. \nIt is a way of hiding our inaction from ourselves under what \nappear to be actions of great effectiveness. We persuade our-\nselves that, comfortably seated behind the wheels of our autos, \nshielded from every unpleasant change of weather, and raising \nor lowering our foot an inch or two, we have actually traveled \nsomewhere. \nSuch travel is not through space foreign to us, but in a \nspace that belongs to us. We do not move from our point \nof departure, but with our point of departure. To be moved \nfrom our living room by an automobile whose upholstered \nseats differ scarcely at all from those in our living rooms, to \nan airport waiting room and then to the airplane where we \nare provided the same sort of furniture, is to have taken our \norigin with us; it is to have left home without leaving home. \nTo be at home everywhere is to neutralize space. \nTherefore, the importance of reducing time in travel: by \narriving as quickly as possible we need not feel as though \nwe had left at all, that neither space nor time can affect \nus-as though they belong to us, and not we to them. \nWe do not go somewhere in a car, but arrive somewhere \nin a car. Automobiles do not make travel possible, but make \nit possible for us to move locations without traveling. \nThus, the theatricality of machinery: Such movement is \nbut a change of scenes. If effective, the machinery will see \nto it that we remain untouched by the elements, by other \ntravelers, by those whose towns or lives we are traveling \nthrough. We can see without being seen, move without being \ntouched. \nWhen most effective, the technology of communication \nallows us to bring the histories and the experiences of others \n124 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 309
  },
  {
    "chunk_full": "into our home, but without changing our home. When most \neffective, the technology of travel allows us to pass through \nthe histories of other persons with the \"comforts of home,\" \nbut without changing those histories. \nWhen it is most effective, machinery will have no effect \nat all. \n86 \nIn still another way is machinery contradictory. Using it \nagainst itself and against ourselves, we also use machinery \nagainst each other. \nI cannot use machinery without using it with another. I \ndo not talk on the telephone; I talk with someone on the \ntelephone. I listen to someone on the radio, drive to visit a \nfriend, compute business transactions. To the degree that my \nassociation with you depends on such machinery, the connect-\ning medium makes each of us an extension of itself. If your \nbusiness activities cannot translate into data recognizable by \nmy computer, I can have no business with you. If you do \nnot live where I can drive to see you, I will find another \nfriend. In each case your relationship to me does not depend \non my needs but on the needs of my machinery. \nIf to operate a machine is to operate like a machine, then \nwe not only operate with each other like machines, we operate \neach other like machines. And if a machine is most effective \nwhen it has no effect, then we operate each other in such a \nway that we reach the outcome desired-in such a way that \nnothing happens. \nThe inherent hostility of machine-mediated relatedness is \nnowhere more evident than in the use of the most theatrical \nmachines of all: instruments of war. All weapons are designed \nFINITE AND INFINITE GAMES \n125 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 310
  },
  {
    "chunk_full": "to affect others without affecting ourselves, to make others \nanswerable to the technology in our control. Weapons are \nthe equipment of finite games designed in such a way that \nthey do not maximize the play but eliminate it. Weapons \nare meant not to win contests but to end them. Killers are \nnot victors; they are unopposed competitors, players without \na game, living contradictions. \nThis is particularly the case with the airborne electronic \nweaponry of the present century, where the operator deals \nonly with the technology-buttons, blips, lights, dials, levers, \ncomputer data-and never with the unseen opponent. Indeed, \nso empty of drama is the modern machinery of slaughter \nthat it is intended to assault enemies only while they are \nstill unseen. This reaches an extreme form in the belief that \nour enemies are not unseen because they are enemies, but \nare enemies because they are unseen. \nThere is a logic in the instrumentality of death that leads \nus to killing the unseen because they are unseen. The crudest \nspear or sword is raised by an attacker because the independent \nexistence of another cannot be countenanced-because the \nother cannot be seen as an other. Just as I insist that the \ncondition of our friendship is your unresisting use of the tele-\nphone, I will expect the weapon in my hand to function with-\nout finding an other that can resist it. Killers can suffer no \nsuggestion that they are living into the open, that their histo-\nries are not finished, that their freedom is always a freedom \nwith others, and not over others, that it is not their vision \nthat is limited but what they are viewing. \nThe fact that the technology of slaughter at vast distances \nhas become extremely sophisticated does not culturally ad-\nvance its highly trained operators over club-swinging primi-\n126 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 311
  },
  {
    "chunk_full": "tives; it makes complete the blindness that was but \nrudimentary in the primitive. It is the supreme triumph of \nresentment over vision. We are the unseeing killing the un-\nseen. \nNot everyone who uses machinery is a killer. But when \nthe use of machinery springs from our attempt to respond \nto the indifference of nature with an indifference of our own \nto nature, we have begun to acquire the very indifference to \npersons that has led to the century's grandest crimes by its \nmost civilized nations. \n87 \nIf indifference to nature leads to the machine, the indiffer-\nence of nature leads to the garden. All culture has the form \nof gardening: the encouragement of spontaneity in others by \nway of one's own, the respect for source, and the refusal to \nconvert source into resource. \nGardeners slaughter no animals. They kill nothing. Fruits, \nseeds, vegetables, nuts, grains, grasses, roots, Rowers, herbs, \nberries-all are collected when they have ripened, and when \ntheir collection is in the interest of the garden's heightened \nand continued vitality. Harvesting respects a source, leaves \nit unexploited, suffers it to be as it is. \nAnimals cannot be harvested. They mature, but they do \nnot \"ripen.\" They are killed not when they have completed \nthe cycle of their vitality but when they are at the peak of \ntheir vitality. Finite gardeners, converting agriculture into \ncommerce, \"raise\" or \"produce\" animals--or meat products-\nas though by machine. Animal husbandry is a science, a \nFINITE AND INFINITE GAMES \n127 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 312
  },
  {
    "chunk_full": "method of controlling growth. It assumes that animals belong \nto us. What is source in them is to be resource for us. Cattle \nare confined to pens to prevent such movement as would \n\"toughen\" their flesh. Geese, their feet nailed to the floor, \nare force fed like machines until they can be butchered for \ntheir fattened livers. \nWhile machinery is meant to work changes without chang-\ning its operators, gardening transforms its workers. One learns \nhow to drive a car, one learns to drive as a car; but one \nbecomes a gardener. \nGardening is not outcome-oriented. A successful harvest \nis not the end of a garden's existence, but only a phase of \nit. As any gardener knows, the vitality of a garden does not \nend with a harvest. It simply takes another form. Gardens \ndo not \"die\" in the winter but quietly prepare for another \nseason. \nGardeners celebrate variety, unlikeness, spontaneity. They \nunderstand that an abundance of styles is in the interest of \nvitality. The more complex the organic content of the soil, \nfor example-that is, the more numerous its sources of \nchange-the more vigorous its liveliness. Growth promotes \ngrowth. \nSo also in culture. Infinite players understand that the vigor \nof a culture has to do with the variety of its sources, the \ndifferences within itself. The unique and the surprising are \nnot suppressed in some persons for the strength of others. \nThe genius in you stimulates the genius in me. \nOne operates a machine effectively, so that it disappears, \ngiving way to results in which the machine has no part. One \ngardens creatively, so that all the sources of the garden's vitality \nappear in its harvest, giving rise to a continuity in which \nwe take an active part. \n128 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 313
  },
  {
    "chunk_full": "88 \nInasmuch as gardens do not conclude with a harvest and \nare not played for a certain outcome, one never arrives any-\nwhere with a garden. \nA garden is a place where growth is found. It has its own \nsource of change. One does not bring change to a garden, \nbut comes to a garden prepared for change, and therefore \nprepared to change. It is possible to deal with growth only \nout of growth. True parents do not see to it that their children \ngrow in a particular way, according to a preferred pattern or \nscripted stages, but they see to it that they grow with their \nchildren. The character of one's parenting, if it is genuinely \ndramatic, must be constantly altered from within as the chil-\ndren change from within. So, too, with teaching, or working \nwith, or loving each other. \nIt is in the garden that we discover what travel truly is. \nWe do not journey to a garden but by way of it. \nGenuine travel has no destination. Travelers do not go some-\nwhere, but constantly discover they are somewhere else. Since \ngardening is a way not of subduing the indifference of nature \nbut of raising one's own spontaneity to respond to the disre-\ngarding vagaries and unpredictabilities of nature, we do not \nlook on nature as a sequence of changing scenes but look \non ourselves as persons in passage. \nNature does not change; it has no inside or outside. It is \ntherefore not possible to travel through it. All travel is there-\nfore change within the traveler, and it is for that reason that \ntravelers are always somewhere else. To travel is to grow. \nGenuine travelers travel not to overcome distance but to \ndiscover distance. It is not distance that makes travel necessary, \nbut travel that makes distance possible. Distance is not deter-\nFINITE AND INFINITE GAMES \n) 29 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 314
  },
  {
    "chunk_full": "mined by the measurable length between objects, but by the \nactual differences between them. The motels around the air-\nports in Chicago and Atlanta are so little different from the \nmotels around the airports of Tokyo and Frankfurt that all \nessential distances dissolve in likeness. What is truly separated \nis distinct; it is unlike. \"The only true voyage would be not \nto travel through a hundred different lands with the same \npair of eyes, but to see the same land through a hundred \ndifferent pairs of eyes\" {Proust}. \nA gardener, whose attention is ever on the spontaneities \nof nilture, acquires the gift of seeing differences, looks always \nfor the merest changes in plant growth, or in the composition \nof the soil, the emerging populations of insects and earth-\nworms. So will gardeners, as parents, see changes of the small-\nest subtlety in their children, or as teachers see the signs of \nan increasing skill, and possibly wisdom, in their students. A \ngarden, a family, a classroom-any place of human gathering \nwhatsoever-will offer no end of variations to be observed, \neach an arrow pointing toward yet more changes. But these \nobserved changes are not theatrically amusing to genuine \ngardeners; they dramatically open themselves to a renewed \nfuture. \nSo, too, with those who look everywhere for difference, \nwho see the earth as source, who celebrate the genius in others, \nwho are not prepared against but for surprise. \"I have traveled \nfar in Concord\" {Thoreau}. \n89 \nSince machinery requires force from without, its use always \nrequires a search for consumable power. When we think of \n130 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 315
  },
  {
    "chunk_full": "nature as resource, it is as a resource for power. As we preoc-\ncupy ourselves with machinery, nature is increasingly thought \nof as a reservoir of needed substances. It is a quantity of \nmaterials that exist to be consumed, chiefly in our machines. \nBeing undivided, nature cannot be used against itself. We \ndo not therefore consume it, or exhaust it. We simply rear-\nrange our societal patterns in a way that reduces our ability \nto respond creatively to the existing patterns of spontaneity. \nThat is, to use the societal expression, we create waste. Waste, \nof course, is by no means unnatural. The trash and garbage \nof a civilization do not befoul nature; they are nature-but \nin a form society no longer is able to exploit for its own \nends. \nSociety regards its waste as an unfortunate, but necessary, \nconsequence of its activities-what is left when we have made \nessential societal goods available. But waste is not the result \nof what we have made. It is what we have made. Waste \nplutonium is not an indirect consequence of the nuclear indus-\ntry; it is a product of that industry. \n90 \nWaste is unveiling. As we find ourselves standing in garbage \nthat we know is our own, we find also that it is garbage we \nhave chosen to make, and having chosen to make it could \nchoose not to make it. Because waste is unveiling, we remove \nit. We place it where it is out of sight. We either find unin-\nhabited areas where waste can be disposed of, or fill them \nwith our refuse until they become uninhabitable. Since a flour-\nishing society will vigorously exploit its natural resources, it \nwill produce correspondingly great quantities of trash, and \nFINITE AND INFINITE GAMES \n131 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 316
  },
  {
    "chunk_full": "quickly its uninhabited lands will overflow with waste, threat-\nening to make the society's own habitation into a waste-\nland. \nBecause waste is unveiling, it is not only placed out of \nsight, it is declared a kind of anti property. No one owns it. \nPart of the contradiction in the phenomenon of waste is that \ntreating nature as though it belongs to us we must soon treat \nnature as though it belongs to no one. Not only does no \none own waste, no one wants it. Instead of competing to \npossess these particular products, we compete to dispossess \nthem. We force it on others less able to rid themselves of \nit. Trash accumulates in slums, sewage runs downstream, air-\nborne acid drifts hundreds of miles settling on the lands of \nthose powerless to halt its \"disposal\" into the atmosphere. \nThousands of square miles of farm lands have been laid waste \nby the construction of multilane highways, or submerged \nby dams whose water is used to flush waste from distant \ncities. \nWaste is the antiproperty that becomes the possession of \nlosers. It is the emblem of the untitled. \nWaste is unveiling, because it persists in showing itself as \nwaste, and as our waste. If waste is the result of our indifference \nto nature, it is also the way we experience the indifference \nof nature. Waste is therefore a reminder that society is a \nspecies of culture. Looking about at the wasteland into which \nwe have converted our habitation, we can plainly see that \nnature is not whatever we want it to be; but we can also \nplainly see that society is only what we want it to be. \nI t is a consequence of this contradiction that the more \nwaste a society produces, the more unveiling that waste is, \nand thus the more vigorously must a society deny that it \nproduces any waste at all; the more it must dispose, or hide, \nor ignore, its detritus. \n132 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 317
  },
  {
    "chunk_full": "91 \nSince the attempt to control nature is at its heart the at-\ntempt to control other persons, we can expect societies to \nbe less patient with those cultures which express some degree \nof indifference to societal goals and values. I t is this repeated \nparallel that brings us to see that the society that creates \nnatural waste creates human waste. \nWaste persons are those no longer useful as resources to \na society for whatever reason, and have become apatrides, \nor noncitizens. Waste persons must be placed out of view-\nin ghettos, slums, reservations, camps, retirement villages, mass \ngraves, remote territories, strategic hamlets-all places of deso-\nlation, and uninhabitable. We live in a century whose Master \nPlayers have created many millions of such \"superfluous per-\nsons\" (Rubenstein). \nA people does not become superfluous by itself, any more \nthan natural waste creates itself. It is society that declares \nsome persons to be waste. Human trash is not an unfortunate \nburden on a society, an indirect result of its proper conduct; \nit is its direct product. European settlers in the Ameri-\ncan, African, and Asian continents did not happen to come \nupon populations of unwanted persons nature had thrust in \ntheir way; they made them superfluous by way of some of \nthe most important and irreversible principles of their societ-\nIes. \nStrictly speaking, waste persons do not exist outside the \nboundaries of a society. They are not society's enemies. One \ndoes not go to war against them, as one goes to war against \nanother society. Waste persons do not constitute an alterna-\ntive or threatening society; they constitute an unveiling cul-\nture. They are therefore \"purged.\" A society cleanses itself of \nthem. \nFINITE AND INFINITE GAMES \n\\33 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 318
  },
  {
    "chunk_full": "92 \nWhen society is unveiled, when we see that it is whatever \nwe want it to be, that it is a species of culture with nothing \nnecessary in it, by no means a phenomenon of nature or a \nmanifestation of instinct, nature is no longer shaped and fitted \ninto one or another set of societal goals. Unveiled, we stand \nbefore a nature whose only face is its hidden self-origination: \nits genius. \nWe see nature as genius when we see as genius. \nWe understand nature as source when we understand our-\nselves as source. We abandon all attempts at an explanation \nof nature when we see that we cannot be explained, when \nour own self-origination cannot be stated as fact. We behold \nthe irreducible otherness of nature when we behold ourselves \nas its other. \n93 \nFor the infinite player, seeing as genius, nature is the abso-\nlutely unlike. The infinite player recognizes nothing on the \nface of nature. Nature displays not only its indifference to \nhuman existence but its difference as well. \nNature offers no home. Although we become gardeners \nin response to its indifference, nature does nothing of itself \nto feed us. In Jewish and Islamic mythology God provided \nus with a garden but did not, indeed could not, do the garden-\ning for us. It was only a garden because we could respond \nto it, because we could be responsible for it. Our responsibility \nlay in noting its variabilities and discrete features. We were \nto name the animals, separating one from the other. This \ngarden was not a machine-like device automatically providing \n134 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 319
  },
  {
    "chunk_full": "food for us. Neither were we machine-like, driven from without \nand destined from within. According to this myth, God did \nbreathe life into us, but in order to continue living we had \nto do our own breathing. \nBut responsibility for the garden does not mean that we \ncan make a garden of nature, as though it were a poiema \nof which we could take possession. A garden is not something \nwe have, over which we stand as gods. A garden is a poiesis, \na receptivity to variety, a vision of differences that leads always \nto a making of differences. The poet joyously suffers the unlike, \nreduces nothing, explains nothing, possesses nothing. \nWe stand before genius in silence. We cannot speak it, \nwe can only speak as it. Yet, though I speak as genius, I \ncannot speak for genius. I cannot give nature a voice in my \nscript. I can not give others a voice in my script-without \ndenying their own source, their originality. To do so is to \ncease responding to the other, to cease being responsible. No \none and nothing belong in my script. \nThe homelessness of nature, its utter indifference to human \nexistence, disclose to the infinite player that nature is the \ngenius of the dramatic. \nFINITE AND INFINITE GAMES \n135 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 320
  },
  {
    "chunk_full": "",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 321
  },
  {
    "chunk_full": "SEVEN \nMYTH \nPROVOKES \nEXPLANATION \nBUT ACCEPTS \nNONE Of IT \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 322
  },
  {
    "chunk_full": "",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 323
  },
  {
    "chunk_full": "94 \nMYTH PROVOKES explanation but accepts none of it. Where \nexplanation absorbs the unspeakable into the speakable, myth \nreintroduces the silence that makes original discourse possible. \nExplanations establish islands, even continents, of order and \npredictability. But these regions were first charted by adventur-\ners whose lives are narratives of exploration and risk. They \nfound them only by mythic journeys into the wayless open. \nWhen the less adventuresome settlers arrive later to work \nout the details and domesticate these spaces, they easily lose \nthe sense that all this firm knowledge does not expunge myth, \nbut floats in it. \nFew discoveries were greater than Copernicus', for they \nprojected an order into the heavens that no one has successfully \nchallenged. Many thought then, and some still think, that \nthis great statement of truth dispelled clouds of myth that \nhad kept humankind in retarding darkness. What Copernicus \ndispelled, however, were not myths but other explanations. \nMyths lie elsewhere. To see where, we do not look at the \nfacts in Copernicus' works; we look for the story in his stating \nthem. Knowledge is what successful explanation has led to; \nthe thinking that sent us forth, however, is pure story. \nCopernicus was a traveler who went with a hundred pairs \nFINITE AND INFINITE GAMES \n139 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 324
  },
  {
    "chunk_full": "of eyes, daring to look again at all that is familiar in the \nhope of vision. What we hear in this account is the ancient \nsaga of the solitary wanderer, the peregrinus, who risks any-\nthing for the sake of surprise. True, at a certain point he \nstopped to look and may have ended his journey as a Master \nPlayer setting down bounded fact. But what resounds most \ndeeply in the life of Copernicus is the journey that made \nknowledge possible and not the knowledge that made the \njourney successful. \nThat myth does not accept the explanations it provokes \nwe can see in the boldness with which thinkers in any territorial \nendeavor reexamine the familiar for a higher seeing. Indeed, \nthe very liveliness of a culture is determined not by how fre-\nquently these thinkers discover new continents of knowledge \nbut by how frequently they depart to seek them. \nA culture can be no stronger than its strongest myths. \n95 \nA story attains the status of myth when it is retold, and \npersistently retold, solely for its own sake. \nIf I tell a story as a way of bracing up an argument or \namusing an audience, I am not telling it for its own sake. \nTo tell a story for its own sake is to tell it for no other reason \nthan that it is a story. Great stories have this feature: To \nlisten to them and learn them is to become their narrators. \nOur first response to hearing a story is the desire to tell \nit ourselves-the greater the story the greater the desire. We \nwill go to considerable time and inconvenience to arrange a \nsituation for its retelling. It is as though the story is itself \nseeking the occasion for its recurrence, making use of us as \n140 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 325
  },
  {
    "chunk_full": "its agents. We do not go out searching for stories for ourselves; \nit is rather the stories that have found us for themselves. \nGreat stories cannot be observed, any more than an infinite \ngame can have an audience. Once I hear the story I enter \ninto its own dimensionality. I inhabit its space at its time. I \ndo not therefore understand the story in terms of my experi-\nence, but my experience in terms of the story. Stories that \nhave the enduring strength of myths reach through experience \nto touch the genius in each of us. But experience is the result \nof this generative touch, not its cause. So far is this the case \nthat we can even say that if we cannot tell a story about \nwhat happened to us, nothing has happened to us. \nIt was not Freud's theory of the unconscious that led hiJl1 \nto Oedipus, but the myth of Oedipus that shaped the way \nhe listened to his patients. \"The theory of instincts,\" he wrote, \n\"is so to say our mythology.\" So too, then, the theory of \nthe unconscious that follows from it, and the superego, and \nthe ego. This is a mythology of such poetic strength that it \nhas altered not only the way we understand our experience, \nbut our experience itself. Who of us has not known a crisis \nof ego, the disturbing presence of unwanted feelings, or the \nanxious recoil from a more polymorphously embodied sexual-\nity? These experiences are not described by Freud the dispas-\nsionate scientist; they are made possible by Freud the mythic \ndreamer. \nAs myths make individual experience possible, they also \nmake collective experience possible. Whole civilizations rise \nfrom stories-and can rise from nothing else. It is not the \nhistorical experience of Jews that makes the Torah meaningful. \nThe Torah is no more a description of the creation of the \nearth and early Jewish life than the theory of instincts is a \ndescription of the psyches of a handful of bourgeois Viennese \nFINITE AND INFINITE GAMES \n141 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 326
  },
  {
    "chunk_full": "of the early twentieth century. The Torah is not the story \nof the Jews; it is what makes Judaism a story. \nWe tell myths for their own sake, because they are stories \nthat insist on being stories-and insist on being told. We \ncome to life at their touch. \nHowever seriously we might regard them as so much inert \npoiema, and attach metaphysical meanings to them, they \nspring back out of their own vitality. When we look into a \nstory to find its meaning, it is always a meaning we have \nbrought with us to look at. \nMyths are like magic trees in the garden of culture. They \ndo not grow on but out of the silent earth of nature. The \nmore we strip these trees of their fruit or prune them back \nto our favored design, the more imposing and fecund they \nbecome. \nMyths, told for their own sake, are not stories that have \nmeanings, but stories that give meanings. \n96 \nStorytellers become metaphysicians, or ideologists, when \nthey come to believe they know the entire story of a people. \nThis is history theatricalized, with the beginning and end in \nplain sight. A psychoanalyst who looks for the Freudian myth \nin patients imposes a filter that lets through nothing the psy-\nchoanalyst was not prepared to find. \nThe psychotherapeutic relationship will become horizonal \nonly when both patient and therapist realize that the Freudian \nmyth does not determine the meaning of what happens be-\ntween them, but offers the possibility that their relationship \nwill have a story of its own. \nThe Freudian myth does not therefore repeat itself in their \n142 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 327
  },
  {
    "chunk_full": "relationship, but resonates in it. Those Jews who claim the \nright to certain territories on the basis of a biblical promise, \nthose Christians who believe the Russians are the great evil \narmies foreseen in biblical prophecies of the end of the world, \nrepeat the bible but do not resonate with it. \nWe resonate with myth when it resounds in us. A myth \nresounds in me when its voice is heard in mine but not heard \nas mine. I do not resonate when I quote Jeremiah or when \nI speak as Jeremiah, but only when Jeremiah speaks in a way \nthat touches an original voice in me. The speech of New \nYorkers resonates not because they talk like New Yorkers, \nbut because when they talk we hear New York in their voice. \nThe resonance of myth collapses the apparent distinction \nbetween the story told by one person to another and the \nstory of their telling and listening. I t is one thing for you to \ntell me the story of Muhammad; it is quite another for me \nto tell the story of your telling me about Muhammad. Ordi-\nnarily we confine the story to the words of the speaker. But \nin doing so we treat it as a story quoted, not a story told. \nIn your relating, and not repeating, the story of Muhammad, \nI am touched, and I respond from my genius. Something \nhas begun. But in touching, you are also touched. Something \nhas begun between us. Our relationship has opened forward \ndramatically. Since this drama emerged from the telling of \nthe story of Muhammad, our story resonates with Muham-\nmad's, and Muhammad's with ours. \nAs myths are told, and continue to resound in the telling, \nthey come to us already richly resonant. The stories they are \nsound deeply with the stories of their telling. Their strength \nas stories lies in their ability to invite us into their drama. \nIt is a drama that contains an entire history of voices, sounding \nand resounding from a thousand sources in our culture. For \nthis reason myths are significantly unresolved-but unresolved \nFINITE AND INFINITE GAMES \n143 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 328
  },
  {
    "chunk_full": "in the way of an infinite game, having rules, or narrative struc-\nture, that allow any number of participants at any time to \nenter the drama without fixing its plot or bringing it to closure \nin a final scene. In such stories much will be said about closure, \nor death, but their telling will always disclose the way death \ncomes in the course of play and not at its end. \n97 \nMyths of irrepressible resonance have lost all trace of an \nauthor. Even when sacred texts are written down by an identifi-\nable prophet or evangelist, it is invariably thought that these \nwords were first spoken to their recorders and not spoken \nby them. Moses received the law and did not compose it. \nMuhammad heard the Quran and did not dictate it. Christians \ndo not read Mark but the gospel according to Mark. Hindus \nunderstand their most authoritative texts, the Vedas, to be \nheard (sruti), and the literature that derives from the Vedas \nto be composed (smriti ). \nThe gospel can be heard nowhere except from those who \nthemselves have heard it. Although I might hear New York \nin your voice, there is no possibility I could hear New York \nby itself. No myth, therefore, exists by itself; neither does it \nhave a discoverable origin. Whom could we name as the first \nNew Yorker? Even when it is God who is heard by the prophet, \nit is a god who speaks in the language and idiom of the prophet, \nand not in locutions restricted to divine utterance-as though \nthat god's speaking were itself a form of listening. \nIndeed, myth is the highest form of our listening to each \nother, of offering a silence that makes the speech of the other \npossible. This is why listening is far more valued by religion \n144 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 329
  },
  {
    "chunk_full": "than speaking. Fides ex auditu. Faith comes by listening, Paul \nsaid. \n98 \nThe opposite of resonance is amplification. A choir is the \nunified expression of voices resonating with each other; a loud-\nspeaker is the amplification of a single voice, excluding all \nothers. A bell resonates, a cannon amplifies. We listen to \nthe bell, we are silenced by the cannon. \nWhen a single voice is sufficiently amplified, it becomes \na speaking that makes it impossible for any other voices to \nbe heard. We do not listen to a loudspeaker for what is being \nsaid, but only because it is all that is being said. Magisterial \nspeech is amplified speech; it is speech that silences. Loud-\nspeaking is a mode of command, and therefore a speech de-\nsigned to bring itself to an end as completely and swiftly as \npossible. The amplified voice seeks obedient action on the \npart of its hearers and an immediate end to their speech. \nThere is no possibility of conversation with a loudspeaker. \nIdeology is the amplification of myth. It is the assumption \nthat since the beginning and end of history are known there \nis nothing more to say. History is therefore to be obediently \nlived out according to the ideology. Just as the warm akers \nof Europe regularly melted down the bells to recast them \ninto cannon, the metaphysicians have found the meaning of \ntheir myths and announced those meanings without their nar-\nrative resonance. The myths themselves are now regarded as \nfalsehoods or curiosities, and are therefore to be disregarded, \nif not forbidden. \nWhat ideologists are concerned to hide is the choral nature \nFINITE AND INFINITE GAMES \n145 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 330
  },
  {
    "chunk_full": "of history, the sense that it is a symphony of very different, \neven opposed, voices, each nonetheless making the other \npossible. \n99 \nIf it is true that myth provokes explanation, then it is also \ntrue that explanation's ultimate design is to eliminate myth. \nIt is not just that the availability of bells in churches and \ntown halls of Europe makes it possible to forge new cannon; \nit is that the cannon are forged in order to silence the bells. \nThis is the contradiction of finite play in its highest form: \nto play in such a way that all need for play is erased. \nThe loudspeaker, successfully muting all other voices and \ntherefore all possibility of conversation, is not listened to at \nall, and for that reason loses its own voice and becomes mere \nnoise. Whenever we succeed in being the only speaker, there \nis no speaker at all. Julius Caesar originally sought power in \nRome because he loved to play the very dangerous style of \npolitics common to the Republic; but he played the game \nso well that he destroyed all his opponents, making it impossi-\nble for him to find genuinely dangerous combat. He was unable \nto do the very thing for which he sought power. His word \nwas now irresistible, and for that reason he could speak with \nno one, and his isolation was complete. \"We might almost \nsay this man was looking for an assassination\" (Syme). \nIf we are to say that all explanation is meant to silence \nmyth itself, then it will follow that whenever we find people \ndeeply committed to explanation and ideology, whenever play \ntakes on the seriousness of warfare, we will find persons trou-\nbled by myths they cannot forget they have forgotten. The \n146 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 331
  },
  {
    "chunk_full": "myths that cannot be forgotten are those so resonant with \nthe paradox of silence they become the source of our thinking, \neven our culture, and our civilization. \nThese are the myths we can easily discover and name, but \nwhose meanings continually elude us, myths whose conversion \nto truth never quite fills the bells of their resonance with \nthe sand of metaphysical interpretation. These are often ex-\nceedingly simple stories. Abraham is an example. Although \nonly two children were born to Abraham in his long life, \nand one of those was illegitimate, he was promised that his \ndescendents would be as numberless as the stars of the heavens. \nAll three of the West's major religions consider themselves \nchildren of Abraham, though each has often understood to \nbe itself the only and final family of the patriarch, an under-\nstanding always threatened by the resounding phrase: num-\nbered as the stars of the heavens. This is the myth of a future \nthat always has a future; there is no closure in it. It is a \nmyth of horizon. \nThe myth of the Buddha's enlightenment has the same \nparadox in it, the same provocation to explanation but with \nas little possibility of settling the matter. It is the story of a \nmere mortal, completely without divine aid, undertaking suc-\ncessfully a spiritual quest for release from all forms of bondage, \nincluding the need to report this release to others. The perfect \nunspeakability of this event has given rise to an immense \nflow of literature in scores of languages that shows no signs \nof abating. \nPerhaps the Christian myth has been the narrative most \ndisturbing to the ideological mind. It is, like those of Abraham \nand the Buddha, a very simple tale: that of a god who listens \nby becoming one of us. It is a god \"emptied\" of divinity, \nwho gave up all privilege of commanding speech and \"dwelt \nFINITE AND INFINITE GAMES \n147 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 332
  },
  {
    "chunk_full": "among us,\" coming \"not to be served, but to serve,\" \"being \nall things to all persons.\" But the worlds to which he came \nreceived him not. They no doubt preferred a god of magisterial \nutterance, a commanding idol, a theatrical likeness of their \nown finite designs. They did not expect an infinite listener \nwho joyously took their unlikeness on himself, giving them \ntheir own voice through the silence of wonder, a healing and \nholy metaphor that leaves everything still to be said. \nThose Christians who deafened themselves to the resonance \nof their own myth have driven their killing machines through \nthe garden of history, but they did not kill the myth. The \nemptied divinity whom they have made into an Instrument \nof Vengeance continues to return as the Man of Sorrows \nbringing with him his unfinished story, and restoring the voices \nof the silenced. \n100 \nThe myth of Jesus is exemplary, but not necessary. No \nmyth is necessary. There is no story that must be told. Stories \ndo not have a truth that someone needs to reveal, or someone \nneeds to hear. It is part of the myth of Jesus that it makes \nitself unnecessary; it is a narrative of the word becoming flesh, \nof language entering history; a narrative of the word becoming \nflesh and dying, of history entering language. Who listens \nto his myth cannot rise above history to utter timeless truths \nabout it. \nI t is not necessary for infinite players to be Christians; in-\ndeed it is not possible for them to be Christians-seriously. \nNeither is it possible for them to be Buddhists, or Muslims, \nor atheists, or New Yorkers-seriously. All such titles can only \n148 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 333
  },
  {
    "chunk_full": "be playful abstractions, mere performances for the sake of \nlaughter. \nInfinite players are not serious actors in any story, but the \njoyful poets of a story that continues to originate what they \ncannot finish. \n101 \nThere is but one infinite game. \nFINITE AND INFINITE GAMES \n149 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 334
  },
  {
    "chunk_full": "",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 335
  },
  {
    "chunk_full": "INDEX \nNumbers following entries refer to sections. \nAdams, John Quincy, 33 \nArt, 42, 43, 44; see also Poiema, Poiesis, \nPoietes \nAudience, 13, 54, 64,66,69,77; see also \nWorld \nAugustine, 74 \nBacon, Francis, 70, 71 \nBirth, 53 \nBismarck, von, Otto, 33 \nBlake, William, 52 \nBoundaries, 3, 4, 6, II, 45, 48, 60, 63, \n64; see also Limitations \nBurckhardt, Jacob, 33 \nContradiction, 13,21 , 22, 24, 54,83 \nCopernicus, 94 \nCulture, 33, 35, 36, 42--47, 80, 83, 87, \n91,92 \nDeath, II, 20-23 \nDickens, Charles, 36 (quoted) \nDramatic, the, 15, 16, 23, 54 \nEinstein, Albert, 70 \nEliot, George, 64 \nEvil, 30, 31, 75 \nExplanation, 70, 73-75, 78--80, 94, 99 \nFlew, Antony, 22 \nFreedom, 12, 13,47,68,73,78,79, 82, \n83 \nFreud, Sigmund, 53, 58, 95 \nGarden, 80, 81 , 87, 88, 93 \nGenius, 51-55, 57, 58,60,69, 70, 73, \n76, 78, 84, 87, 88, 92, 93, 95, 96 \nHealing, 56 \nHegel, G. W . F., 48 \nHeidegger, Martin, 64 \nHeisenberg, Werner, 71 \nHistory, 73, 74, 78, 79, 98, 100 \nHopkins, Gerard Manley, 72 (quoted) \nHorizon, 45, 46, 48 \nIdeology, 47, 98; see also Metaphysics \nJesus, 21, 25 \nLanguage, 72, 73, 75-78, 100 \nLimitations, 12, 52; see also Boundaries \nListening, 77, 97 \nLocke, John, 37 \nLooking, 52 \nMachine, 80, 81, 84--87, 89; see also \nTechnology \nMarx, Karl, 21, 35 (quoted), 57 \nMaster Player, 16, 17,25,49, 57, 58, \n70, 72, 75, 78, 80, 91 \nMeister Eckhart, 69 \nMetaphor, 72, 76 \nMetaphysics, 47, 50; see also Ideology \nMoving, 55; see also Touching \nMyth, 94-100 \nINDEX \n151 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 336
  },
  {
    "chunk_full": "Names, 25 \nNarrative, 73, 78, 79 \nNature, 70-73, 75, 76, 80, 82, 83, 86-\n90,92,93 \nNazism, 30, 41 \nNietzsche, Friedrich, 23, 54 \nOedipus, 78 \nParadox, 24, 51, 83 \nPaul, 20, 21, 25 \nPlato, 41 , 42, 49 \nPoets, 49; see also Poietes \nPoiema, 47, 50, 69 \nPoiesis, 42, 44, 47, 50, 62, 69, 79 \nPoietes (plural: Poietai), 41-44, 50, 78 \nPower, 27-29, 34, 80 \nPrize, 21,57,67 \nProperty, 36-41, 44, 58, 74, 90 \nProust, Marcel, 88 \nRank, Otto, 44 \nRenaissance, 45-47 \nRoles, 13-15 \nRousseau, Jean-Jacques, 33, 48, 61 \nRubenstein, Richard L., 91 \nRules, 8-11, 16,63 \n15Z \nSartre, Jean-Paul, 13 \nSeeing, 52 \nSexuality, 57--62 \nShaw, George Bernard, 13 \nSilence, 72, 73, 75, 77 \nSociety, 33-36,41,42,45,48, 58, 80, \n90-92 \nStory: see Myth, Narrative \nStrength, 29 \nSyme, Ronald, Sir, 99 \nTechnology, 80, 85; see also Machine \nTheatrical, the, 15, 16, 22, 33, 37-41 , \n53-55, 57, 67, 85 \nThoreau, Henry David, 88 \nTime, 6,17, 19,27,64,67--69 \nTitle, 18-20, 25-28, 36, 37, 57, 75 \nTouching, 55-57 \nTrash, 89-91 \nVeblen, Thorstein, 40 \nVeiling, 13,49, 55 \nWaste, 89-91 \nWeil, Simone, 77 \nWittgenstein, Ludwig, 76 \nWorld, 63--67, 77; see also Audience \nZen Buddhism, 32 \n",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 337
  },
  {
    "chunk_full": "",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 338
  },
  {
    "chunk_full": "",
    "book_id": "finite_and_infinite_games",
    "book_title": "Finite and Infinite Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 339
  },
  {
    "chunk_full": "Game Theory-Based Opponent Modeling in Large\nImperfect-Information Games\n∗\nSam Ganzfried and Tuomas Sandholm\nComputer Science Department\nCarnegie Mellon University\n{sganzfri, sandholm}@cs.cmu.edu\nABSTRACT\nWe develop an algorithm for opponent modeling in large\nextensive-form games of imperfect information. It works by\nobserving the opponent’s action frequencies and building an\nopponent model by combining information from a precom-\nputed equilibrium strategy with the observations. It then\ncomputes and plays a best response to this opponent model;\nthe opponent model and best response are both updated\ncontinually in real time.\nThe approach combines game-\ntheoretic reasoning and pure opponent modeling, yielding\na hybrid that can eﬀectively exploit opponents after only a\nsmall number of interactions. Unlike prior opponent mod-\neling approaches, ours is fundamentally game theoretic and\ntakes advantage of recent algorithms for automated abstrac-\ntion and equilibrium computation rather than relying on\ndomain-speciﬁc prior distributions, historical data, or a hand-\ncrafted set of features. Experiments show that our algorithm\nleads to signiﬁcantly higher win rates (than an approximate-\nequilibrium strategy) against several opponents in limit Texas\nHold’em — the most studied imperfect-information game\nin computer science — including competitors from recent\nAAAI computer poker competitions.\nCategories and Subject Descriptors\nI.2.m [Computing Methodologies]: Artiﬁcial Intelligence\nGeneral Terms\nAlgorithms, Economics\nKeywords\nGame theory, multiagent learning\n1.\nINTRODUCTION\nWhile much work has been done in recent years on ab-\nstracting and computing equilibria in large extensive-form\n∗This material is based upon work supported by the Na-\ntional Science Foundation under IIS grants 0905390 and\n0964579. We also acknowledge Intel Corporation and IBM\nfor their machine gifts.\nCite as: Game Theory-Based Opponent Modeling in Large Imperfect-\nInformation Games, Sam Ganzfried and Tuomas Sandholm, Proc. of\n10th Int. Conf. on Autonomous Agents and Multiagent Sys-\ntems (AAMAS 2011), Tumer, Yolum, Sonenberg and Stone (eds.),\nMay, 2–6, 2011, Taipei, Taiwan, pp. XXX-XXX.\nCopyright c⃝2011, International Foundation for Autonomous Agents and\nMultiagent Systems (www.ifaamas.org). All rights reserved.\ngames, relatively little work has been done on exploiting sub-\noptimal opponents (aka opponent modeling). While playing\nan equilibrium guarantees at least the value of the game in\na two-player zero-sum game, often much higher payoﬀs can\nbe obtained by deviating from equilibrium to exploit oppo-\nnents who make signiﬁcant mistakes. For example, against\na poker opponent who always folds, the strategy of always\nraising will perform far better than any equilibrium strategy\n(which will sometimes fold with bad hands).\nTexas Hold’em poker has emerged as the main testbed\nfor evaluating algorithms in extensive-form games. In ad-\ndition to its tremendous popularity, it also contains enor-\nmous strategy spaces, imperfect information, and stochastic\nevents; such elements also characterize most of the chal-\nlenging problems in computational game theory and multia-\ngent systems. In light of these factors and the AAAI annual\ncomputer poker competition, poker has emerged as an im-\nportant, visible challenge problem for AI as a whole, and\nmultiagent systems in particular.\nIt is worth noting, however, that a fair amount of prior\nwork has been done on opponent exploitation in signiﬁcantly\nsmaller games. For example, Hoehn et al. [7] run experi-\nments on Kuhn poker, a small two-player poker variant with\nabout 20 states in its game tree. Recent work has also been\ndone on opponent exploitation in rock-paper-scissors [12]\nand the repeated prisoners’ dilemma [2].\nHowever, these\nalgorithms do not scale to large games.\nIn contrast, the\ngame tree of limit Texas hold’em has about 1018 states.\nA potential drawback of evaluating algorithms on one spe-\nciﬁc problem is that we run the risk of developing algorithms\nthat are so game speciﬁc that they will not generalize to\nother settings. Heeding this risk, in this work we abandon\nmany of the game-speciﬁc assumptions taken by prior ap-\nproaches. Rather than relying on massive databases of hu-\nman poker play [3, 14] and expert-generated features or prior\ndistributions [7, 16], we will instead rely on game-theoretic\nconcepts such as Nash equilibrium and best response, which\napply to all games.\nIn addition, we require our algorithms to operate eﬃ-\nciently in real time (online), as opposed to algorithms that\nperform oﬄine computations assuming they have access to\na large number of samples of the opponent’s strategy in ad-\nvance [9, 13]. That prior work also assumed access to his-\ntorical data which included the private information of the\nopponents (i.e., their hole cards) even when such informa-\ntion was only observed by the opponent. In many multiagent\nsettings, an agent must play against opponents about whom\nhe has little to no information in advance, and must learn to\n",
    "book_id": "game_theory-based_opponent_modeling_in_large_imperfect-information_games",
    "book_title": "Game Theory-Based Opponent Modeling in Large Imperfect-Information Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 340
  },
  {
    "chunk_full": "exploit weaknesses in a small number of interactions. Thus,\nwe assume we have no prior information on our opponent’s\nstrategy in advance, and our algorithms will operate online.\nOur main algorithm, called Deviation-Based Best Response\n(DBBR), works by noting deviations between the opponent’s\nstrategy and that of a precomputed approximate equilibrium\nstrategy, and constructing a model of the opponent based\non these deviations. Then it computes and plays a best re-\nsponse to this opponent model (in real time). Both the con-\nstruction of the opponent model and the computation of a\nbest response take time linear in the size of the game tree and\ncan be performed quickly in practice. As discussed above, we\nevaluate our algorithm empirically on limit Texas Hold’em;\nit achieves signiﬁcantly higher win rates against several op-\nponents — including competitors from recent AAAI com-\nputer poker competitions — than an approximate equilib-\nrium strategy does.\n2.\nGAME THEORY BACKGROUND\nIn this section, we review relevant deﬁnitions and results\nfrom game theory.\n2.1\nExtensive-form games\nAn extensive-form game is a general model of multiagent\nsequential decision-making with imperfect information1. As\nwith perfect-information games, extensive-form games con-\nsist primarily of a game tree; each non-terminal node has\nan associated player (possibly chance) that makes the de-\ncision at that node, and each terminal node has associated\nutilities for the players. Additionally, game states are parti-\ntioned into information sets, Ii ∈Ii, where a player cannot\ndistinguish among the states in the same information set.\nTherefore, the player whose turn it is to move must choose\nactions with the same distribution at each state in the in-\nformation set.\nIn this paper, we will only concern ourselves with two-\nplayer, zero-sum2, extensive-form games (though our algo-\nrithm extends naturally to multiplayer and non-zero-sum\ngames as well).\nFurthermore, we will make the standard\nassumption of perfect recall: no player forgets information\nthat he previously knew.\nA history, h ∈H, is a sequence of actions. A (mixed) strat-\negy for player i, σi, is a function that assigns a probability\ndistribution over all actions at each information set belong-\ning to i; by convention the opponent’s strategy is denoted\nσ−i. Let Σi denote the (mixed) strategy space of player i.\nA strategy proﬁle σ is a vector of strategies, one for each\nplayer.\nIn this paper we will assume that the moves of all players\nother than chance are observed by all players; for example,\nin poker all moves other than the initial dealing of the cards\nare publicly observed. In this setting, we can partition all\ngame states into public history sets, PHi, where states in\nthe same public history set correspond to the same history\nof publicly observed actions. Note that each public history\nset must consist of a set of information sets of player i. For\npublic history set n ∈PHi, let An denote the set of actions\nof player i at n. In general when we omit subscripts, player\n1Much of our description of extensive-form games is adapted\nfrom [11].\n2An extensive-form game is zero-sum if the sum of the pay-\noﬀs at each terminal node equals zero.\ni will be implied.\n2.2\nBest responses and Nash equilibria\nPlayer i’s best response to σ−i is any strategy in\narg max\nσ′\ni∈Σi\nui(σ′\ni, σ−i).\nA Nash equilibrium is a strategy proﬁle σ such that σi is a\nbest response to σ−i for all i. An ϵ-equilibrium is a strategy\nproﬁle in which each player achieves a payoﬀof within ϵ of\nhis best response. Formally, an ϵ-equilibrium is a strategy\nproﬁle σ∗such that, for all i, we have\nui(σ∗\ni , σ∗\n−i) ≥max\nσi∈Σi ui(σi, σ∗\n−i) −ϵ.\nAll ﬁnite games have at least one Nash equilibrium. In the\ncase of zero-sum extensive-form games with perfect recall,\nthere are eﬃcient techniques for ﬁnding an ϵ-equilibrium,\nsuch as linear programming (LP) [10], the excessive gap\ntechnique (EGT) [6], and counterfactual regret minimiza-\ntion (CFR) [17].\nHowever, the latter two scale to much\nlarger games; they scale to 1012 states in the game tree,\nwhile the best current LP techniques do not scale beyond\n108 states.\nBest responses can be computed much more eﬃciently\nthan Nash equilibria. Computing a best response involves\na single matrix-vector multiplication followed by a traversal\nup the game tree, both of which take linear time in the size\nof the game tree.\n2.3\nAbstraction\nDespite the tremendous progress in equilibrium-ﬁnding in\nrecent years, many interesting real-world games (such as\npoker) are so large that even the best algorithms have no\nhope of computing an equilibrium directly. The standard\napproach of dealing with this is to apply an abstraction al-\ngorithm, which constructs a smaller game that is similar to\nthe original game; then the smaller game is solved, and its\nsolution is mapped to a strategy proﬁle in the original game.\nThe approach has been applied to two-player Texas Hold’em\npoker, ﬁrst with a manually generated abstraction [1], and\ncurrently with abstraction algorithms [4]. Many abstraction\nalgorithms work by coarsening the moves of chance, collaps-\ning several information sets of the original game into single\ninformation sets of the abstracted game. We will sometimes\nrefer to information sets in abstracted games as buckets.\nThe game tree of limit Texas hold’em has about 1018\nstates, and recent solution techniques can compute approx-\nimate equilibria for abstractions with up to 1012 states [5,\n17]. Such algorithms typically take several weeks to compute\nan ϵ-equilibrium for reasonably small ϵ. On the other hand,\nbest responses in such an abstraction can be computed in\nabout an hour.\nIf coarser abstractions are used, best re-\nsponses can be computed in minutes or even seconds, and\ncan potentially be used as a subroutine in adaptive real-time\nalgorithms.\n3.\nIMPOSSIBILITY OF SAFE\nEXPLOITATION\nWhile deviating from equilibrium to exploit an opponent\ncan often lead to a signiﬁcantly higher payoﬀ, it also runs\nthe risk that the exploitative strategy can itself become ex-\nploitable. For example, the opponent could play a certain\n",
    "book_id": "game_theory-based_opponent_modeling_in_large_imperfect-information_games",
    "book_title": "Game Theory-Based Opponent Modeling in Large Imperfect-Information Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 341
  },
  {
    "chunk_full": "strategy for several iterations to trick the exploiter, then\nexploit him in turn; this is referred to as the get-taught-and-\nexploited problem [15].\nOne might think that this problem can be avoided by only\nrisking the amount won so far. For example, suppose we are\nrepeating a two-player zero-sum game (with value zero) 100\ntimes, and have won $50 so far through 50 iterations. Then\nif we attempt to exploit the opponent for the next 50 iter-\nations by playing a strategy with exploitability at most $1\nper iteration, it appears that we may be able to safely ex-\nploit the opponent by deviating from equilibrium while still\nguaranteeing the value of the game. Unfortunately, this in-\ntuition is not correct; it is possible that the opponent was\nin fact playing an equilibrium all along and that we were\njust lucky for the ﬁrst 50 iterations. If we then deviate from\nequilibrium, our overall strategy could actually have a nega-\ntive payoﬀin expectation against an equilibrium opponent.\nFormally:\nProposition 1. It is not possible to exploit an opponent\nby deviating from equilibrium while simultaneously guaran-\nteeing obtaining the value of the game in expectation.\nThus, we must turn to algorithms that are exploitable to\nsome extent in the worst case if we hope to exploit the op-\nponent more than any equilibrium strategy does.\n4.\nDBBR: AN EFFICIENT REAL-TIME\nOPPONENT MODELING ALGORITHM\nIn this section we present our algorithm, Deviation-Based\nBest Response (DBBR). It works by observing the oppo-\nnent’s action frequencies over the course of game, then us-\ning these observations to construct a model of the opponent’s\nstrategy. Essentially, we would like to conservatively assume\nthat the opponent is playing the best (i.e., least exploitable)\nstrategy that is consistent with our observations of his play.\nThe obvious way to accomplish this would be to add linear\nconstraints to the LP for ﬁnding an equilibrium [10] that\nforce the opponent model to conform with our observations.\nHowever, as discussed in Section 2.3, such a computation\ncould take several weeks, and would not be practical for\nreal-time play in large games.\nTo obtain a more practical algorithm, we must ﬁnd a faster\nway of constructing an opponent model from our observa-\ntions. DBBR constructs the model by noting deviations of\nour opponent’s observed action frequencies from equilibrium\nfrequencies. For example, in poker suppose an equilibrium\nstrategy raises 50% of the time when ﬁrst to act, while the\nopponent raises only 30% of the time. While the opponent\nmight be raising any 30% of hands, a safe guess might be\nto assume that he is raising his ‘best’ 30% of hands; we can\nconstruct such a strategy by starting with the equilibrium\nstrategy, then removing the ‘worst’ 20% of hands from the\nraising range. Our algorithm is based on this intuition.\n4.1\nOverview of the algorithm\nPseudocode for a high-level overview of DBBR is given in\nAlgorithm 1. In the ﬁrst step, an approximate equilibrium\nσ∗of the game is precomputed oﬄine. Next, when the game\nbegins, the frequencies of the opponent’s actions at diﬀerent\npublic history sets are recorded. These are used to compute\nthe opponent’s posterior action probabilities: the probabil-\nities with which he chooses each action at each public his-\ntory set n ∈PH−i. (We say that the elements of PH−i are\nnumbered according to breadth-ﬁrst-search (BFS) traversal\norder.) Next, we compute the probability the opponent is in\neach bucket at n given our model of his play so far; we refer\nto these probabilities as the posterior bucket probabilities.\nWe then compute a full model of the opponent’s strategy by\nconsidering the deviations between the opponent’s posterior\naction probabilities and those of σ∗at n. Based on these\ndeviations, we iterate over all buckets and shift weight away\nfrom the action probabilities in σ∗until we obtain a strategy\nconsistent with our model of the opponent’s action probabil-\nities. Finally, after we have iterated over all public history\nsets, we compute a best response to the opponent model.\nThe next subsections will discuss the diﬀerent components\nof the algorithm in detail.\nAlgorithm 1 High-level overview of DBBR\nCompute an approximate equilibrium of the game.\nMaintain\ncounters\nfrom\nobserving\nopponent’s\nplay\nthroughout the match.\nfor n = 1 to |PH−i| do\nCompute posterior action probabilities at n.\nCompute posterior bucket probabilities at n.\nCompute full model of opponent’s strategy at n.\nend for\nreturn Best response to the opponent model.\n4.2\nComputing posterior action probabilities\nIn the course of our play against the opponent, we observe\nhow often he chooses each action a at each public history\nset n; we denote this quantity by cn,a. One idea would be\nto assume the opponent will play action a with probability\ncn,a\nP\na′ cn,a′ .\nHowever, doing this could be problematic for a few reasons.\nFirst, we might not have any observations at a given set\nn, in which case this quantity would not even be deﬁned.\nMore generally, the quality of our observations might vary\ndramatically between public history sets; for example, we\nhave a lot more conﬁdence in sets for which we have 1000\nobservations than sets for which we have just 1 or 2, and we\nwould like our algorithm to reﬂect this. A similar observa-\ntion was the motivation behind a recent paper [8], though\nthat work assumed that the opponent’s private information\nwas observable.\nOur algorithm works by choosing a combination of the ob-\nserved probability and the probability under the equilibrium\nstrategy σ∗, where the weight on the observed frequencies is\nhigher at public history sets for which we have more obser-\nvations. Speciﬁcally, we use a Dirichlet prior distribution,\nwhere we assume we have seen Nprior ﬁctitious hands at the\ngiven public history set for which the opponent played ac-\ncording to σ∗. Let p∗\nn,a denote the probability that σ∗plays\naction a at public history set n. We compute the posterior\naction probabilities, αn,a, as follows:\nαn,a = p∗\nn,a · Nprior + cn,a\nNprior + P\na′ cn,a′ .\n(1)\n4.3\nComputing posterior bucket probabilities\nSince we are constructing the model of the opponent’s\nstrategy using a BFS ordering of the public history sets,\n",
    "book_id": "game_theory-based_opponent_modeling_in_large_imperfect-information_games",
    "book_title": "Game Theory-Based Opponent Modeling in Large Imperfect-Information Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 342
  },
  {
    "chunk_full": "we assume that we have already set his strategy for all an-\ncestors of the current set n (including the parent n′). Let\nsn′,b,a denote our model of the probability that the oppo-\nnent plays his portion of the strategy sequence leading to n′,\nthen chooses action a in bucket b at state n′; this quantity\nhas already been computed by the time we get to n in the\nalgorithm. We can use these probabilities to construct the\nposterior probability, βn,b, that the opponent is in bucket b\n(i.e., in poker, the opponent has those private cards) at pub-\nlic history set n. Pseudocode for this procedure is given in\nAlgorithm 2, where hb denotes the probability that chance\nmakes the moves needed to put the opponent in bucket b.\nAlgorithm 2 ComputeBucketProbs(n)\nfor b = 1 to |Bn| do\nn′ ←parent(n)\na ←action taken to get from n′ to n.\nβn,b ←hb · sn′,b,a\nend for\nNormalize the values βn so they sum up to 1.\n4.4\nComputing the opponent model\nIn this section we will present three diﬀerent techniques for\ncomputing the opponent model. Recall that our high-level\ngoal is to compute the ‘best’ (i.e., least exploitable) strategy\nfor the opponent that is consistent with our observations of\nhis behavior. We could accomplish this by performing an\nequilibrium-like computation; however, such a computation\nis too challenging to be performed in real time.\nRather than ﬁnd the strategy consistent with our observa-\ntions that is least exploitable, we will instead ﬁnd the strat-\negy that is ‘closest’ to the precomputed equilibrium. It turns\nout that this can be accomplished eﬃciently in practice, and\nintuitively we would expect strategies closer to equilibrium\nto be less exploitable.\n4.4.1\nWeighted L1-distance minimization\nRecall that the L1 distance between two vectors x and y\nis deﬁned as\n||x −y||1 =\nk\nX\ni=1\n|xi −yi|.\n(2)\nWhile this function treats all indices of the vector equally,\nin some cases we might want to put more weight on some\ncomponents than on others. If p is a probability distribution\nover the integers from 1 to k, we deﬁne the weighted L1\ndistance between x and y as\nk\nX\ni=1\npi · |xi −yi|.\n(3)\nNow, suppose we are at public history set n, where βn,b\ndenotes the posterior probability that we are in bucket b, as\ncomputed by Algorithm 2. If we let the yi’s in Equation 3\ncorrespond to the equilibrium probabilities of taking each\naction, and let the pi’s correspond to the βn,b’s, then we\ncan formulate the problem of ﬁnding the strategy closest to\nthe precomputed equilibrium, subject to the posterior action\nprobabilities αn,a, as an L1-distance minimization problem.\nFormally, we can formulate the optimization problem as\nfollows, for a given public history set n:\nminimize\nX\nb∈Bn\nX\na∈An\n\u0002\nβn,b · |xn,b,a −σ∗\nn,b,a|\n\u0003\n(4)\nsubject to\nX\nb∈Bn\n[βn,b · xn,b,a] = αn,a for all a ∈An\nX\na∈An\nxn,b,a = 1 for all b ∈Bn\n0 ≤xn,b,a ≤1 for all a ∈An, b ∈Bn\nRecall that Bn denotes the set of all buckets we could\nbe in at public history set n, while An denotes the set of\nactions at n. The variables xn,b,a correspond to the model\nof the opponent’s strategy that we are trying to compute.\nNote that we can do this optimization separately for each\npublic history set n; it makes more sense to do many smaller\noptimizations than to do a huge one for all public history\nsets at once, since the computations of the actions taken at\ndiﬀerent states do not depend on each other.\nSo as discussed above, we will perform a separate opti-\nmization at each n according to the program of Equation 4.\nIt turns out that this can be cast as a linear program (LP)\nand solved eﬃciently using CPLEX’s dual simplex algorithm\nfor solving LPs.\nDoing this for each public history set n\nyields the opponent model x. Note that the program could\nhave many solutions, and that CPLEX will just output the\nﬁrst solution it encounters (and not necessarily the solu-\ntion that performs best in practice). This means that there\nmight actually exist a strategy that minimizes L1 distance\nfrom equilibrium that performs better in practice than the\nstrategy output by CPLEX.\n4.4.2\nWeighted L2-distance minimization\nWhile Section 4.4.1 uses the weighted L1 distance to mea-\nsure the proximity of two strategies, we could also use other\ndistance metrics. In this section we will consider another\ncommon distance function: the weighted L2 distance.\nSimilarly to Equation 2, the L2 distance between x and y\nis deﬁned as\n||x −y||2 =\nv\nu\nu\nt\nk\nX\ni=1\n(xi −yi)2.\n(5)\nAnalogously to the L1 case, we deﬁne the weighted L2\ndistance between x and y as\nv\nu\nu\nt\nk\nX\ni=1\npi · (xi −yi)2.\n(6)\nThe new program for computing the opponent model at\nn is the following:\nminimize\nX\nb∈Bn\nX\na∈An\n\u0002\nβn,b · (xn,b,a −σ∗\nn,b,a)2\u0003\n(7)\nsubject to\nX\nb∈Bn\n[βn,b · xn,b,a] = αn,a for all a ∈An\nX\na∈An\nxn,b,a = 1 for all b ∈Bn\n0 ≤xn,b,a ≤1 for all a ∈An, b ∈Bn\nNote that we can omit the square root, since it is a mono-\ntonic operator. The resulting formulation in Equation 7 is a\n",
    "book_id": "game_theory-based_opponent_modeling_in_large_imperfect-information_games",
    "book_title": "Game Theory-Based Opponent Modeling in Large Imperfect-Information Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 343
  },
  {
    "chunk_full": "quadratic program (QP), which can also be solved eﬃciently\nin practice using CPLEX. As in the L1 case, we can for-\nmulate and solve a separate optimization problem for each\npublic history set n to compute the opponent model x.\n4.4.3\nOur custom weight-shifting algorithm\nWhile the previous two sections described how to compute\nan opponent model using two popular distance functions,\nperhaps we can do even better by designing our own custom\nalgorithm that takes into account the conservative reasoning\nabout the opponent that we discussed earlier. In this section\nwe will describe such an algorithm. In particular, it takes\ninto account the fact that we already know an approximate\nranking of the buckets at each public history set from the\napproximate equilibrium σ∗.\nFor example, suppose the opponent is only raising 30% of\nthe time when ﬁrst to act, while σ∗raises 50% of the time in\nthat situation (as given in the example at the beginning of\nthis section). Instead of doing a full L1 or L2-minimization\nexplicitly, we could use the following heuristic algorithm:\nsort all buckets by how often the opponent raises with them\nunder σ∗, then greedily keep removing buckets from his rais-\ning range until the weighted sum (using the βn,b’s as weights)\nequals 30%. This is a simple greedy algorithm, which can\nbe run signiﬁcantly more eﬃciently in practice than the L1\nand L2-minimization procedures described in the last two\nsubsections, which must repeatedly use CPLEX at runtime.\nFor simplicity, we present our algorithm for the case of\nthree actions, although it extends naturally to any number\nof actions.\nFirst we initialize the opponent’s strategy at\nn, σn, to the equilibrium σ∗. We also initialize our current\nmodel of his action probabilities γn to p∗\nn,a, the equilibrium\naction probabilities.\nNext, we check whether the opponent is taking action 3\nmore often than he should at n by comparing αn,3 to γn,3.\nIf he is, we are going to want to increase the probabilities he\nplays action 3 in various buckets; otherwise, we will decrease\nthese probabilities. For now, we will assume that αn,3 > γn,3\n(the other case is handled analogously).\nWe start by adding weight to the bucket that plays action\n3 with the highest probability at n; denote this bucket by ˆb.\nIf\nγn,3 + βn,ˆb · (1 −σn,ˆb,3) < αn,3,\n(8)\nwe set σn,ˆb,3 = 1, since that will not cause γn,3 to exceed\nαn,3 once it is adjusted. Otherwise, we increase σn,ˆb,3 by\n(αn,3−γn,3)\nβn,ˆb\n. (Recall that βn,ˆb denotes the posterior proba-\nbility that the opponent holds bucket ˆb at n, as computed\nin Algorithm 2.)\nLet ∆denote the amount by which we\nincrease σn,ˆb,3. We will also increase the action probability\nγn,3 by βˆb · ∆.\nNext we must compensate for this increase of the prob-\nability of playing action 3 in bucket ˆb by decreasing the\nprobabilities of playing actions 1 and/or 2. Let a denote the\naction (1 or 2) played with lower probability in σn in bucket\nˆb, and let a denote the other action. If σn,ˆb,a ≥∆, then we\nset σn,ˆb,a = σn,ˆb,a −∆and update γn,a accordingly. Other-\nwise, we set σn,ˆb,a = 0 and remove the remaining probability\n∆−σn,ˆb,a from σn,ˆb,a.\nIf the inequality of Equation 8 held above, then our op-\nponent model probabilities still do not agree with the poste-\nrior action probabilities, and thus we must continue shifting\nprobability mass; we continue by setting ˆb to the bucket that\nplays action 3 with the second highest probability at n, and\nrepeating the above procedure. Otherwise, we are done set-\nting the probabilities for action 3, and we perform a similar\nprocedure to shift weight between the probabilities that he\nplays actions 1 and 2 until they agree with αn.\nWe have now constructed an opponent model that agrees\nwith our posterior action probabilities. Note that we had to\niterate over possibly all of the buckets at public history set\nn. Since each bucket is contained in only one public history\nset, the algorithm’s run time is linear in the size of the game\ntree.\nAdditionally, although we presented this algorithm for the\ncase of three actions at n, it easily generalizes to more ac-\ntions. Rather than just designating a and a, we will sort all\nactions in the order of how often they are played in bucket\nˆb, and proceed through this list adjusting probabilities as in\nthe three-action case.\n4.5\nFull algorithm\nIn practice, constructing an opponent model and comput-\ning a best response at each repetition of the game (e.g., hand\nin poker) might be too slow. This can be mitigated by do-\ning so only every k repetitions. In addition, we may want\nto start oﬀplaying the equilibrium σ∗for several repeti-\ntions so that we can obtain a reasonable number of samples\nof the opponent’s play, rather than trying to exploit him\nimmediately. Overall, our full algorithm will have three pa-\nrameters: T denotes how many repetitions to ﬁrst play the\nequilibrium σ∗before starting to exploit, k denotes how of-\nten to recompute an opponent model and best response, and\nNprior from Equation 1 is the parameter of the action prob-\nability prior distributions. Pseudocode for the algorithm is\ngiven in Algorithm 3, where M is the number of repetitions\nin the match.\nAlgorithm 3 DBBR(T,k,Nprior)\nfor iter = 1 to T do\nPlay according to the precomputed equilibrium strategy\nσ∗\nend for\nopponent model = ComputeOppModel(Nprior)\nσBR = ComputeBestResponse(opponent model)\nfor iter = T + 1 to M do\nif iter is a multiple of k then\nopponent model = ComputeOppModel(Nprior)\nσBR = ComputeBestResponse(opponent model)\nend if\nPlay according to σBR\nend for\n5.\nEXPERIMENTS AND DISCUSSION\nWe used two-player Limit Texas Hold’em as our experi-\nmental domain. It is a large-scale game with 1018 states in\nthe game tree. It is the most-studied full-scale poker game in\ncomputer science, and is also played by human professionals.\n5.1\nLimit Texas Hold’em\nThe rules of the game are as follows. Each player at the\ntable is dealt two private hole cards, and the players initially\nhave 1 and 2 chips invested in the pot respectively. Then\n",
    "book_id": "game_theory-based_opponent_modeling_in_large_imperfect-information_games",
    "book_title": "Game Theory-Based Opponent Modeling in Large Imperfect-Information Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 344
  },
  {
    "chunk_full": "there is a round of betting, after which three cards (called\nthe ﬂop) are dealt face up in the middle of the table. Then\nthere is another round of betting, followed by another card\ndealt face up (the turn); then one more round of betting,\nfollowed by a ﬁfth card face up (the river), followed by a\nﬁnal round of betting.\nDuring each betting round, each player has three possible\noptions. (1) fold: pass and forfeit his chance of winning the\npot. (2) call: put a number of chips equal to the size of the\ncurrent bet into the pot. (3) raise: put a ﬁxed number of\nadditional chips in the pot beyond what was needed to call.\nIf one player folds during the course of betting, then the\nother player wins the entire pot. If neither player has folded,\nthe player with the best ﬁve-card hand (constructed from his\ntwo hole cards and the ﬁve community cards) wins the pot.\nIn case of a tie, the players split the pot evenly.\nAs in the AAAI computer poker competitions, in our\nexperiments, each match consists of 3000 duplicate hands:\n3000 hands are played normally, then the players switch po-\nsitions and play the same 3000 hands (with no memory of\nthe previous hands). This is a well-known technique for re-\nducing the variance so that fewer hands are needed to obtain\nstatistical signiﬁcance. Whenever we match two players, we\nhave them play several duplicate matches and report the\nstandard error.\n5.2\nExperimental results\nWe ran our algorithm against several opponents; the re-\nsults are shown in Table 1.\nThe ﬁrst four opponents —\nRandom, AlwaysFold, AlwaysCall, and AlwaysRaise — play\nna¨ıvely as their names suggest. GUS2 and Dr. Sahbak were\nentrants in the 2008 AAAI computer poker competition, and\nTommybot was an entrant in the 2009 competition; we se-\nlected these bots to experiment against because they had the\nworst performances in the competitions, and we expect op-\nponent modeling to provide the biggest improvement against\nweak opponents. Against stronger opponents one might pre-\nfer to always play the precomputed equilibrium rather than\nturning on the exploitation. This can be accomplished by\nperiodically looking at the win rate, and only attempting to\nexploit the opponent if a win rate above some threshold is\nattained.\nGS5 is a bot we entered in the 2009 AAAI computer poker\ncompetition that plays an approximate-equilibrium strategy.\nIt was computed using an abstraction which had branching\nfactors of 15, 40, 6, and 6 respectively in the four betting\nrounds.\nThe parameter values we used in DBBR (as de-\nscribed in Section 4.5) were T = 1000, k = 50, Nprior =\n5, with GS5 playing the role of the initial approximate-\nequilibrium strategy (i.e., we ran GS5 for the ﬁrst 1000\nhands of each match and recomputed an opponent model\nand best response every 50 hands subsequently). Since each\nmatch consists of 3000 duplicate hands, this means that GS5\nand DBBR play the same strategy for the ﬁrst third of each\nmatch.\nWe set T = 1000 since it is essential that our algorithm\nobtains a reasonable number of samples of the opponent’s\nplay (in diﬀerent parts of the game tree) before attempting\nto exploit. As discussed in the next paragraph, our main mo-\ntivation in setting k was to allow us to update the opponent\nmodel as frequently as we could while remaining under the\ncompetition time limit. For Nprior, we wanted to choose a\nsmall number so that our observations would quickly trump\nthe prior for common public history sets, but so that the\nprior would have more weight if we had just one or two ob-\nservations.\nNote that setting Nprior = 5 means that our\nprior and our observations will have equal weight in our\nmodel when we have observed the opponent’s action 5 times\nat the given public history set.\nChanging the parameter\nvalues could certainly have a large eﬀect on the results, and\nshould be studied further.\nUnfortunately GS5 was too large to use as the approximate-\nequilibrium strategy in our real-time opponent modeling up-\ndates.\nTherefore, we also precomputed an approximate-\nequilibrium σ∗that used a much smaller abstraction than\nGS5: the branching factors of its abstraction were 8, 12, 4,\nand 4. While σ∗is clearly an inferior strategy to GS5, it\nwas small enough to allow us to construct opponent models\nand compute best responses in just a few seconds, keeping\nus within the time limit of the AAAI competition.\nWe experimented with all three of the approaches for\ncomputing the opponent model described in Section 4.4:\nthe three algorithms DBBR-L1, DBBR-L2, and DBBR-WS\n(i.e., ‘Weight-Shifting’) correspond to the three diﬀerent al-\ngorithms in that section.\nWe ran all three of these algo-\nrithms against each of the opponents described above (with\nthe exception of Tommybot, which we were not able to play\nagainst DBBR-L1 and DBBR-L2 due to technical issues).\nAs shown in Table 1, our main algorithm DBBR-WS per-\nformed signiﬁcantly better against all of the opponents than\nGS5 did (in one case, the win rate was over twice as high).\nFurthermore, DBBR-WS beat GUS2 by more than any other\nbot in the 2008 competition did, and its win rates against\nDr. Sahbak and Tommybot were surpassed by the win rate\nof just a single bot.\n5.3\nComparing the opponent modeling\nalgorithms\nIt is not totally clear from the results in Figure 1 which of\nthe three algorithms for constructing the opponent model —\nL1, L2, or our weight-shifting algorithm — is best. For ex-\nample, DBBR-WS obtains a win rate of 1.391 sb/h against\nAlwaysRaise while DBBR-L1 obtains a win rate of 0.878\nsb/h, but DBBR-L1 obtains a win rate of 2.164 sb/h against\nRandom while DBBR-WS obtains only 1.769 sb/h. Simi-\nlarly, for all other pairings there exist opponents such that\none bot achieves a higher win rate against one opponent, but\nnot against the other opponent. So there is no clear total\nordering of the three algorithms.\nThat being said, DBBR-L2 does at least as well (or essen-\ntially the same) against all of the opponents as DBBR-L1,\nexcept for Dr.\nSahbak; this suggests that DBBR-L2 is a\nstronger program. As between DBBR-L2 and DBBR-WS,\nit really seems to depend on the opponent. DBBR-WS per-\nforms signiﬁcantly better against AlwaysRaise, GUS2, and\nDr.\nSahbak and slightly better against AlwaysFold than\nDBBR-L2; however, DBBR-L2 performs signiﬁcantly bet-\nter against Random and slightly better against AlwaysCall\nthan DBBR-WS. So DBBR-WS performs signiﬁcantly bet-\nter against three of the six opponents than DBBR-L2 (and\nessentially the same against two opponents), suggesting that\nit is a better algorithm.\nIn addition, DBBR-WS performs signiﬁcantly better against\nboth of the actual opponents from the AAAI competition\n(GUS2 and Dr.\nSahbak) than DBBR-L2, which suggests\nthat it might perform better in practice against realistic op-\n",
    "book_id": "game_theory-based_opponent_modeling_in_large_imperfect-information_games",
    "book_title": "Game Theory-Based Opponent Modeling in Large Imperfect-Information Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 345
  },
  {
    "chunk_full": "Random\nAlwaysFold\nAlwaysCall\nAlwaysRaise\nGUS2\nDr. Sahbak\nTommybot\nGS5\n0.854 ± 0.008\n0.646 ± 0.0009\n0.582 ± 0.005\n0.791 ± 0.009\n0.636 ± 0.004\n0.665 ± 0.027\n0.552 ± 0.008\nDBBR-WS\n1.769 ± 0.025\n0.719 ± 0.002\n0.930 ± 0.014\n1.391 ± 0.034\n0.807 ± 0.011\n1.156 ± 0.043\n1.054 ± 0.044\nDBBR-L1\n2.164 ± 0.036\n0.717 ± 0.002\n0.935 ± 0.017\n0.878 ± 0.032\n0.609 ± 0.054\n1.153 ± 0.074\nDBBR-L2\n2.287 ± 0.046\n0.716 ± 0.002\n0.931 ± 0.026\n1.143 ± 0.084\n0.721 ± 0.050\n1.027 ± 0.072\nTable 1: Win rate in small bets/hand of the bot listed in the row. The ± given is the standard error (standard\ndeviation divided by the square root of the number of hands).\nponents. This fact, combined with the fact that DBBR-WS\nis more eﬃcient than the other algorithms, which have to\nperform many optimizations using CPLEX at runtime, sug-\ngest that DBBR-WS is a better algorithm to use in practice.\nNote that this does not imply that the weighted L1 and L2\ndistance functions are poor distance metrics; it just means\nthat the particular solution output by CPLEX does not do as\nwell as the solution output by DBBR-WS. It is very possible\nthat if CPLEX used diﬀerent LP/QP algorithms, it might\nﬁnd a solution that does signiﬁcantly better.\nThis would\ncertainly be a worthwhile avenue for future work.\n5.4\nWin rates over time\nOne might expect that DBBR3 would immediately begin\nexploiting the opponents at hand 1001 — when it switches\nfrom playing an approximate equilibrium to opponent mod-\neling — and that the win rate would increase steadily. In\nfact, this happened in the matches against most of the bots.\nFor example, Figure 1(a) shows that DBBR’s proﬁts against\nAlwaysFold increase linearly over time, and Figure 1(d) shows\nthat DBBR’s win rate increases in a concave fashion.\nSurprisingly, we observed a diﬀerent behavior in the matches\nagainst AlwaysRaise and GUS2. In both of these matches,\nthe win rate decreases signiﬁcantly for the ﬁrst several hun-\ndred hands before it starts to increase, as shown in Figure 1.\nThis happens because the approximate-equilibrium strategy\nplays some action sequences with very low probability, lead-\ning it to not explore the opponent’s full strategy space in the\n1000 hands. This will lead to a signiﬁcant disparity between\nthe prior and actual strategies of the opponent at hand 1001\nif the opponent’s strategy diﬀers signiﬁcantly from the ap-\nproximate equilibrium in those unexplored regions. This in\nturn may cause DBBR to think it can immediately exploit\nthe opponent in certain ways, which turn out to be unsuc-\ncessful; but eventually as DBBR explores these sequences\nfurther and gathers more observations, it ﬁgures out suc-\ncessful exploitations.\nThe following hand from our experiments between DBBR\nand AlwaysRaise exempliﬁes this phenomenon. The hand\nwas the 1006’th hand of the match. There were many raises\nand re-raises during the preﬂop, ﬂop, and turn betting rounds.\nWhen the river card came, DBBR had only a ten high (a\nvery weak hand in this situation). However, based on its\nobservations during the ﬁrst 1005 hands, it knew that Al-\nwaysRaise had a very wide range of hands given this bet-\nting sequence, many of which were also weak hands (though\nprobably still stronger than ten high). On the other hand,\nDBBR had very few observations of how AlwaysRaise re-\nsponds to a series of raises on the river, since GS5 made\nthose plays very rarely during the ﬁrst 1000 hands; hence,\nDBBR resorted to the prior to model the opponent, which\nhad the opponent folding all of his weak hands to a raise\n3The results in this section refer to our main algorithm,\nDBBR-WS.\n(since GS5 would do this). So DBBR thought that raising\nwould get the opponent to fold most of his hands, while in\nreality AlwaysRaise continues to raise with all of his hands.\nIn this particular hand, DBBR lost a signiﬁcant amount of\nmoney due to the additional raises he made on the river with\na very weak hand.\n6.\nCONCLUSION\nWe presented DBBR, an eﬃcient real-time algorithm for\nopponent modeling and exploitation in large extensive-form\ngames.\nIt works by observing the opponent’s action fre-\nquencies and building an opponent model by combining in-\nformation from a precomputed equilibrium strategy with the\nobservations. This enables the algorithm to combine game-\ntheoretic reasoning and pure opponent modeling, yielding a\nhybrid that can eﬀectively exploit opponents after a small\nnumber of interactions.\nOur experiments in full-scale two-player limit Texas Hold-\n’em poker show that DBBR is eﬀective in practice against a\nvariety of opponents, including several entrants from recent\nAAAI computer poker competitions. DBBR achieved a sig-\nniﬁcantly higher win rate than an approximate-equilibrium\nstrategy against all of the opponents in our experiments.\nFurthermore, it achieved a higher win rate against the op-\nponents from previous competitions than all of the entrants\nfrom that year’s competition achieved (except for at most\none). We compared three diﬀerent algorithms for construct-\ning the opponent model, and conclude that our custom weight-\nshifting algorithm outperforms algorithms that employ weight-\ned L1 and L2-distance minimization.\nWhile DBBR is able to eﬀectively exploit weak opponents,\nit might actually become signiﬁcantly exploitable to strong\nopponents (e.g., opponents who operate in a ﬁner-grained\nabstraction). Thus, we would like to only attempt to ex-\nploit weak opponents, while playing the equilibrium against\nstrong opponents. This can be accomplished by periodically\nlooking at the win rate, and only attempting to exploit the\nopponent if a win rate above some threshold is attained. Our\ncurrent work involves developing automated schemes that al-\nternate between DBBR and equilibrium play based on the\nspeciﬁc opponent at hand. In addition, DBBR could be ex-\ntended to the setting where the opponent’s private informa-\ntion from the previous game iteration is sometimes observed.\nFinally, future work could look at more robust versions of\nDBBR, where the opponent model allows the opponent to\nsometimes deviate from his observed action probabilities, or\na safer strategy than the actual best response is used.\n7.\nREFERENCES\n[1] Darse Billings, Neil Burch, Aaron Davidson, Robert\nHolte, Jonathan Schaeﬀer, Terence Schauenberg, and\nDuane Szafron. Approximating game-theoretic\noptimal strategies for full-scale poker. IJCAI, 2003.\n",
    "book_id": "game_theory-based_opponent_modeling_in_large_imperfect-information_games",
    "book_title": "Game Theory-Based Opponent Modeling in Large Imperfect-Information Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 346
  },
  {
    "chunk_full": "(a)\n(b)\n(c)\n(d)\n(e)\n(f)\nFigure 1: Proﬁts and win rates over time of DBBR-WS against several opponents. Results against AlwaysFold\nare shown in Figures 1(a) and 1(d), results against AlwaysRaise are shown in Figures 1(b) and 1(e), and results\nagainst GUS2 are shown in Figures 1(c) and 1(f). The top three graphs show proﬁt over time, and the bottom\nthree show win rates over time.\n[2] Doran Chakraborty and Peter Stone. Convergence,\ntargeted optimality, and safety in multiagent learning.\nICML, 2010.\n[3] Aaron Davidson, Darse Billings, Jonathan Schaeﬀer,\nand Duane Szafron. Improved opponent modeling in\npoker. IJCAI, 2000.\n[4] Andrew Gilpin and Tuomas Sandholm. A competitive\nTexas Hold’em poker player via automated abstraction\nand real-time equilibrium computation. AAAI, 2006.\n[5] Andrew Gilpin, Tuomas Sandholm, and Troels Bjerre\nSørensen. Potential-aware automated abstraction of\nsequential games, and holistic equilibrium analysis of\nTexas Hold’em poker. AAAI, 2007.\n[6] Andrew Gilpin, Samid Hoda, Javier Pe˜na, and\nTuomas Sandholm. Gradient-based algorithms for\nﬁnding Nash equilibria in extensive form games.\nWINE, 2007. Extended version in Math. of OR, 2010.\n[7] Bret Hoehn, Finnegan Southey, Robert C. Holte, and\nValeriy Bulitko. Eﬀective short-term opponent\nexploitation in simpliﬁed poker. AAAI, 2005.\n[8] Michael Johanson and Michael Bowling. Data biased\nrobust counter strategies. AISTATS, 2009.\n[9] Michael Johanson, Martin Zinkevich, and Michael\nBowling. Computing robust counter-strategies. NIPS,\n2007.\n[10] Daphne Koller, Nimrod Megiddo, and Bernhard von\nStengel. Eﬃcient computation of equilibria for\nextensive two-person games. GEB, 1996.\n[11] Marc Lanctot, Kevin Waugh, Martin Zinkevich, and\nMichael Bowling. Monte Carlo sampling for regret\nminimization in extensive games. COLT workshop on\nOnline Learning with Limited Feedback, 2009.\n[12] Peter McCracken and Michael Bowling. Safe strategies\nfor agent modelling in games. AAAI Fall Symposium\non Artiﬁcial Multi-agent Learning, 2004.\n[13] Marc Ponsen, Marc Lanctot, and Steven de Jong.\nMCRNR: Fast computing of restricted Nash responses\nby means of sampling. AAAI workshop on Interactive\nDecision Theory and Game Theory Workshop, 2010.\n[14] Marc Ponsen, Jan Ramon, Tom Croonenborghs, Kurt\nDriessens, and Karl Tuyls. Bayes-relational learning of\nopponent models from incomplete information in\nno-limit poker. AAAI, 2008.\n[15] Tuomas Sandholm. Perspectives on multiagent\nlearning. Artiﬁcial Intelligence, 2007.\n[16] Finnegan Southey, Michael Bowling, Bryce Larson,\nCarmelo Piccione, Neil Burch, Darse Billings, and\nChris Rayner. Bayes’ bluﬀ: Opponent modelling in\npoker. UAI, 2005.\n[17] Martin Zinkevich, Michael Bowling, Michael\nJohanson, and Carmelo Piccione. Regret minimization\nin games with incomplete information. NIPS, 2007.\n",
    "book_id": "game_theory-based_opponent_modeling_in_large_imperfect-information_games",
    "book_title": "Game Theory-Based Opponent Modeling in Large Imperfect-Information Games",
    "book_author": "Unknown",
    "topic_id": "theory_game",
    "topic_label": "game",
    "chunk_index": 347
  }
]