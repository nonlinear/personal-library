[
  {
    "chunk_full": "![](../images/00005.jpeg)\n\n\nCopyright © 2014 by Kim Zetter\n\nAll rights reserved.\n\nPublished in the United States by Crown Publishers, an imprint of the Crown\nPublishing Group, a division of Random House LLC, a Penguin Random House\nCompany, New York.\n\n[www.crownpublishing.com](http://www.crownpublishing.com)\n\nCROWN and the Crown colophon are registered trademarks of Random House LLC.\n\nPortions of this work were originally published in different form in “How\nDigital Detectives Deciphered Stuxnet, the Most Menacing Malware in History”\ncopyright © [Wired.com](http://www.Wired.com). Used with permission. First\npublished July 2011.\n\nCataloging-in-Publication data is on file with the Library of Congress.\n\nISBN 978-0-7704-3617-9\n\neBook ISBN 978-0-7704-3618-6\n\nPRINTED IN THE UNITED STATES OF AMERICA\n\n_Jacket design by Oliver Munday_\n\n_Jacket photograph: DigitalGlobe/Getty Images_\n\nv3.1\n\n\nFor SC and for my parents—with love and great gratitude, though gratitude is\ninsufficient for all that you’ve done.\n\n\n# **CONTENTS**\n\n[_Cover_](kindle:embed:0006?mime=image/jpg)\n\n[_Title Page_](part0000.html)\n\n[_Copyright_](part0001.html)\n\n[_Dedication_](part0002.html)\n\n[**Prologue: The Case of the Centrifuges**](part0004.html)\n\n[1\\. **Early Warning**](part0005.html)\n\n[2\\. **500 Kilobytes of Mystery**](part0006.html)\n\n[3\\. **Natanz**](part0007.html)\n\n[4\\. **Stuxnet Deconstructed**](part0008.html)\n\n[5\\. **Springtime for Ahmadinejad**](part0009.html)\n\n[6\\. **Digging for Zero Days**](part0010.html)\n\n[7\\. **Zero-Day Paydays**](part0011.html)\n\n[8\\. **The Payload**](part0012.html)\n\n[9\\. **Industrial Controls Out of Control**](part0013.html)\n\n[10\\. **Precision Weapon**](part0014.html)\n\n[11\\. **A Digital Plot Is Hatched**](part0015.html)\n\n[12\\. **A New Fighting Domain**](part0016.html)\n\n[13\\. **Digital Warheads**](part0017.html)\n\n[14\\. **Son of Stuxnet**](part0018.html)\n\n[15\\. **Flame**](part0019.html)\n\n[16\\. **Olympic Games**](part0020.html)\n\n[17\\. **The Mystery of the Centrifuges**](part0021.html)\n\n[18\\. **Qualified Success**](part0022.html)\n\n[19\\. **Digital Pandora**](part0023.html)\n\n[**Acknowledgments**](part0024.html)\n\n\n# PROLOGUE\n\n# **THE CASE OF THE CENTRIFUGES**\n\nIt was January 2010 when officials with the International Atomic Energy Agency\n(IAEA), the United Nations body charged with monitoring Iran’s nuclear\nprogram, first began to notice something unusual happening at the uranium\nenrichment plant outside Natanz in central Iran.\n\nInside the facility’s large centrifuge hall, buried like a bunker more than\nfifty feet beneath the desert surface, thousands of gleaming aluminum\ncentrifuges were spinning at supersonic speed, enriching uranium hexafluoride\ngas as they had been for nearly two years. But over the last weeks, workers at\nthe plant had been removing batches of centrifuges and replacing them with new\nones. And they were doing so at a startling rate.\n\nAt Natanz each centrifuge, known as an IR-1, has a life expectancy of about\nten years. But the devices are fragile and prone to break easily. Even under\nnormal conditions, Iran has to replace up to 10 percent of the centrifuges\neach year due to material defects, maintenance issues, and worker accidents.\n\nIn November 2009, Iran had about 8,700 centrifuges installed at Natanz, so it\nwould have been perfectly normal to see technicians decommission about 800 of\nthem over the course of the year as the devices failed for one reason or\nanother. But as IAEA officials added up the centrifuges removed over several\nweeks in December 2009 and early January, they realized that Iran was plowing\nthrough them at an unusual rate.\n\nInspectors with the IAEA’s Department of Safeguards visited Natanz an average\nof twice a month—sometimes by appointment, sometimes unannounced—to track\nIran’s enrichment activity and progress.[1](part0004.html#prl-ftn1) Anytime\nworkers at the plant decommissioned damaged or otherwise unusable centrifuges,\nthey were required to line them up in a control area just inside the door of\nthe centrifuge rooms until IAEA inspectors arrived at their next visit to\nexamine them. The inspectors would run a handheld gamma spectrometer around\neach centrifuge to ensure that no nuclear material was being smuggled out in\nthem, then approve the centrifuges for removal, making note in reports sent\nback to IAEA headquarters in Vienna of the number that were decommissioned\neach time.\n\nIAEA digital surveillance cameras, installed outside the door of each\ncentrifuge room to monitor Iran’s enrichment activity, captured the\ntechnicians scurrying about in their white lab coats, blue plastic booties on\ntheir feet, as they trotted out the shiny cylinders one by one, each about six\nfeet long and about half a foot in diameter. The workers, by agreement with\nthe IAEA, had to cradle the delicate devices in their arms, wrapped in plastic\nsleeves or in open boxes, so the cameras could register each item as it was\nremoved from the room.\n\nThe surveillance cameras, which weren’t allowed inside the centrifuge rooms,\nstored the images for later perusal. Each time inspectors visited Natanz, they\nexamined the recorded images to ensure that Iran hadn’t removed additional\ncentrifuges or done anything else prohibited during their\nabsence.[2](part0004.html#prl-ftn2) But as weeks passed and the inspectors\nsent their reports back to Vienna, officials there realized that the number of\ncentrifuges being removed far exceeded what was normal.[3](part0004.html#prl-\nftn3)\n\nOfficially, the IAEA won’t say how many centrifuges Iran replaced during this\nperiod. But news reports quoting European “diplomats” put the number at 900 to\n1,000. A former top IAEA official, however, thinks the actual number was much\nhigher. “My educated guess is that 2,000 were damaged,” says Olli Heinonen,\nwho was deputy director of the Safeguards Division until he resigned in\nOctober 2010.\n\nWhatever the number, it was clear that something was wrong with the devices.\nUnfortunately, Iran wasn’t required to tell inspectors why they had replaced\nthem, and, officially, the IAEA inspectors had no right to ask. The agency’s\nmandate was to monitor what happened to uranium at the enrichment plant, not\nkeep track of failed equipment.\n\nWhat the inspectors didn’t know was that the answer to their question was\nright beneath their noses, buried in the bits and memory of the computers in\nNatanz’s industrial control room. Months earlier, in June 2009, someone had\nquietly unleashed a destructive digital warhead on computers in Iran, where it\nhad silently slithered its way into critical systems at Natanz, all with a\nsingle goal in mind—to sabotage Iran’s uranium enrichment program and prevent\nPresident Mahmoud Ahmadinejad from building a nuclear bomb.\n\nThe answer was there at Natanz, but it would be nearly a year before the\ninspectors would obtain it, and even then it would come only after more than a\ndozen computer security experts around the world spent months deconstructing\nwhat would ultimately become known as one of the most sophisticated viruses\never discovered—a piece of software so unique it would make history as the\nworld’s first digital weapon and the first shot across the bow announcing the\nage of digital warfare.\n\n* * *\n\n[1](part0004.html#prl-ftn1a) The number of inspection visits to Natanz has\nincreased since this period. Beginning in 2010, inspections increased to once\na week, and after a new agreement with Iran in late 2013, inspectors are now\non-site at Natanz every day.\n\n[2](part0004.html#prl-ftn2a) IAEA inspectors are not allowed to remove the\nrecorded images from Natanz and can only view them on-site, where they are\nstored.\n\n[3](part0004.html#prl-ftn3a) Inspectors visiting Natanz and other nuclear\nfacilities around the world rotate on a regular basis, so the same IAEA\ninspectors don’t visit every time. This is why the large number of\ndecommissioned centrifuges didn’t get noticed until after several reports of\nchanging numbers arrived in Vienna and got viewed in the aggregate by analysts\nand officials there.\n\n\n# CHAPTER 1\n\n# **EARLY WARNING**\n\nSergey Ulasen is not the sort of person you’d expect to find at the center of\nan international incident. The thirty-one-year-old Belarusian has close-\ncropped blond hair, a lean boyish frame, and the open face and affable\ndemeanor of someone who goes through life attracting few enemies and even\nfewer controversies. One of his favorite pastimes is spending the weekend at\nhis grandmother’s country house outside Minsk, where he decompresses from\nweekday stresses, far from the reach of cell phones and the internet. But in\nJune 2010, Ulasen encountered something unusual that soon propelled him into\nthe international spotlight and into a world of new\nstress.[1](part0005.html#c01-ftn1)\n\nIt was a warm Thursday afternoon, and Ulasen, who headed the antivirus\ndivision of a small computer security firm in Belarus called Virus-BlokAda,\nwas seated with his colleague Oleg Kupreev in their lab in downtown Minsk\ninside a drab, Soviet-era building about a block from the Svisloch River. They\nwere sifting methodically through suspicious computer files they had recently\nfound on a machine in Iran when something striking leapt out at Kupreev. He\nsat back in his chair and called Ulasen over to take a look. Ulasen scrolled\nthrough the code once, then again, to make sure he was seeing what he thought\nhe saw. A tiny gasp escaped his throat. The code they had been inspecting the\npast few days, something they had until now considered a mildly interesting\nbut nonetheless run-of-the-mill virus, had just revealed itself to be a work\nof quiet and diabolical genius.\n\nNot only was it using a skillful rootkit to cloak itself and make it invisible\nto antivirus engines, it was using a shrewd zero-day exploit to propagate from\nmachine to machine—an exploit that attacked a function so fundamental to the\nWindows operating system, it put millions of computers at risk of infection.\n\nExploits are attack code that hackers use to install viruses and other\nmalicious tools onto machines. They take advantage of security vulnerabilities\nin browser software like Internet Explorer or applications like Adobe PDF\nReader to slip a virus or Trojan horse onto a system, like a burglar using a\ncrowbar to pry open a window and break into a house. If a victim visits a\nmalicious website where the exploit lurks or clicks on a malicious e-mail\nattachment containing an exploit, the exploit uses the security hole in the\nsoftware to drop a malicious file onto their system. When software makers\nlearn about such holes in their products, they generally produce “patches” to\nclose them up and seal the intruders out, while antivirus firms like Ulasen’s\nadd signatures to their scanners to detect any exploits that try to attack the\nvulnerabilities.\n\nZero-day exploits, however, aren’t ordinary exploits but are the hacking\nworld’s most prized possession because they attack holes that are still\nunknown to the software maker and to the antivirus vendors—which means there\nare no antivirus signatures yet to detect the exploits and no patches\navailable to fix the holes they attack.\n\nBut zero-day exploits are rarely found in the wild. It takes time and skill\nfor hackers to discover new holes and write workable exploits to attack them,\nso the vast majority of hackers simply rely on old vulnerabilities and\nexploits to spread their malware, counting on the fact that most computer\nusers don’t often patch their machines or have up-to-date antivirus software\ninstalled, and that it can take vendors weeks or months to produce a patch for\na known hole. Although more than 12 million viruses and other malicious files\nare captured each year, only about a dozen or so zero-days are found among\nthem. Yet here the attackers were using an extremely valuable zero-day\nexploit, and a skillful rootkit, for a virus that, as far as Ulasen and\nKupreev could tell, had been found only on machines in Iran so far. Something\ndidn’t add up.\n\nTHE MYSTERY FILES had come to their attention a week earlier when a reseller\nof VirusBlokAda’s security software in Iran reported a persistent problem with\na customer’s machine in that country. The computer was caught in a reboot\nloop, crashing and rebooting repeatedly while defying the efforts of\ntechnicians to control it.[2](part0005.html#c01-ftn2) VirusBlokAda’s tech-\nsupport team had scanned the system remotely from Minsk to look for any\nmalware their antivirus software might have missed, but came up with nothing.\nThat’s when they called in Ulasen.\n\nUlasen had been hired by the antivirus firm while still in college. He was\nhired to be a programmer, but the staff at VirusBlokAda was so small, and\nUlasen’s skills so keen, that within three years, at the age of twenty-six, he\nfound himself leading the team that developed and maintained its antivirus\nengine. He also occasionally worked with the research team that deconstructed\nmalicious threats. This was his favorite part of the job, though it was\nsomething he rarely got to do. So when the tech-support team asked him to\nweigh in on their mystery from Iran, he was happy to\nhelp.[3](part0005.html#c01-ftn3)\n\nUlasen assumed the problem must be a misconfiguration of software or an\nincompatibility between an application installed on the machine and the\noperating system. But then he learned it wasn’t just one machine in Iran that\nwas crashing but multiple machines, including ones that administrators had\nwiped clean and rebuilt with a fresh installation of the operating system. So\nhe suspected the culprit might be a worm lurking on the victim’s network,\nreinfecting scrubbed machines each time they were cleaned. He also suspected a\nrootkit was hiding the intruder from their antivirus engine. Ulasen had\nwritten anti-rootkit tools for his company in the past, so he was confident\nhe’d be able to hunt this one down if it was there.\n\nAfter getting permission to connect to one of the machines in Iran and\nremotely examine it, Ulasen and Kupreev zeroed in on six suspicious files—two\nmodules and four other files—they thought were the source of the\nproblem.[4](part0005.html#c01-ftn4) Then with help from several colleagues in\ntheir lab, they spent the next several days picking at the files in fits and\nstarts, hurling curses at times as they struggled to decipher what turned out\nto be surprisingly sophisticated code. As employees of a small firm that\nmostly developed antivirus products for government customers, they weren’t\naccustomed to taking on such complex challenges: they spent most of their days\nproviding routine tech support to customers, not analyzing malicious threats.\nBut they pressed forward nonetheless and eventually determined that one of the\nmodules, a driver, was actually a “kernel-level” rootkit, as Ulasen had\nsuspected.[5](part0005.html#c01-ftn5)\n\nRootkits come in several varieties, but the most difficult to detect are\nkernel-level rootkits, which burrow deep into the core of a machine to set up\nshop at the same privileged level where antivirus scanners work. If you think\nof a computer’s structure like the concentric circles of an archer’s target,\nthe kernel is the bull’s eye, the part of the operating system that makes\neverything work. Most hackers write rootkits that operate at a machine’s outer\nlayers—the user level, where applications run—because this is easier to do.\nBut virus scanners can detect these—so a truly skilled hacker places his\nrootkit at the kernel level of the machine, where it can subvert the scanner.\nThere, it serves as a kind of wingman for malicious files, running\ninterference against scanners so the malware can do its dirty work unhindered\nand undetected. Kernel-level rootkits aren’t uncommon, but it takes\nsophisticated knowledge and a deft touch to build one that works well. And\nthis one worked very well.[6](part0005.html#c01-ftn6)\n\nKupreev determined that the rootkit was designed to hide four malicious .LNK\nfiles—the four other suspicious files they’d found on the system in Iran. The\nmalware appeared to be using an exploit composed of these malicious files to\nspread itself via infected USB flash drives, and the rootkit prevented the\n.LNK files from being seen on the flash drive. That’s when Kupreev called\nUlasen over to have a look.\n\nExploits that spread malware via USB flash drives aren’t as common as those\nthat spread them over the internet through websites and e-mail attachments,\nbut they aren’t unheard of, either. All of the USB exploits the two\nresearchers had seen before, however, used the Autorun feature of the Windows\noperating system, which allowed malicious programs on a USB flash drive to\nexecute as soon as the drive was inserted in a machine. But this exploit was\nmore clever.[7](part0005.html#c01-ftn7)\n\nWindows .LNK files are responsible for rendering the icons for the contents of\na USB flash drive or other portable media device when it’s plugged into a PC.\nInsert a USB flash drive into a PC, and Windows Explorer or a similar tool\nautomatically scans it for .LNK files to display the icon for a music file,\nWord document, or program stored on the flash\ndrive.[8](part0005.html#c01-ftn8) But in this case, the attackers embedded an\nexploit in a specially crafted .LNK file so that as soon as Windows Explorer\nscanned the file, it triggered the exploit to spring into action to\nsurreptitiously deposit the USB’s malicious cargo onto the machine, like a\nmilitary transport plane dropping camouflaged paratroopers onto enemy\nterritory.\n\nThe .LNK exploit attacked such a fundamental feature of the Windows system\nthat Ulasen wondered why no one had thought of it before. It was much worse\nthan Autorun exploits, because those could be easily thwarted by disabling the\nAutorun feature on machines—a step many network administrators take as a\nmatter of course because of Autorun’s known security risk. But there is no way\nto easily disable the .LNK function without causing other problems for users.\n\nUlasen searched a registry of exploits for any others that had used .LNK files\nin the past, but came up with nothing. That was when he suspected he was\nlooking at a zero-day.\n\nHe took a USB flash drive infected with the malicious files and plugged it\ninto a test machine running Windows 7, the newest version of the Microsoft\noperating system. The machine was fully patched with all the latest security\nupdates. If the .LNK exploit was already known to Microsoft, patches on the\nsystem would prevent it from dropping the malicious files onto the machine.\nBut if the .LNK exploit was a zero-day, nothing would stop it. He waited a few\nminutes to examine the computer and, sure enough, the malicious files were\nthere.\n\nHe couldn’t believe it. VirusBlokAda, a tiny security firm that few in the\nworld had ever heard of, had just discovered that rarest of trophies for a\nvirus hunter. But this wasn’t just any zero-day exploit; it was one that\nworked against every version of the Windows operating system released since\nWindows 2000: the attackers had bundled four versions of their exploit\ntogether—in four different .LNK files—to make sure their attack worked against\nevery version of Windows it was likely to\nencounter.[9](part0005.html#c01-ftn9)\n\nUlasen tried to wrap his head around the number of machines that were at risk\nof infection from this. But then something equally troubling struck him. The\nmalicious driver module, and another driver module that got dropped onto\ntargeted machines as part of the malicious cargo, had installed themselves\nseamlessly on their test machine, without any warning notice popping up on-\nscreen to indicate they were doing so. Windows 7 had a security feature that\nwas supposed to tell users if an unsigned driver, or one signed with an\nuntrusted certificate, was trying to install itself on their machine. But\nthese two drivers had loaded with no problem. That was because, Ulasen\nrealized with alarm, they were signed with what appeared to be a legitimate\ndigital certificate from a company called RealTek\nSemiconductor.[10](part0005.html#c01-ftn10)\n\nDigital certificates are trusted security documents, like digital passports,\nthat software makers use to sign their programs to authenticate them as\nlegitimate products of their company. Microsoft digitally signs its programs\nand software updates, as do antivirus firms. Computers assume that a file\nsigned with a legitimate digital certificate is trustworthy. But if attackers\nsteal a Microsoft certificate and the private cryptographic “key” that\nMicrosoft uses with the certificate to sign its files, they can fool a\ncomputer into thinking their malicious code is Microsoft code.\n\nAttackers had used digital certificates to sign malicious files before. But\nthey had used fake, self-signed certificates masquerading as legitimate ones,\nor had obtained real certificates through fraudulent means, such as creating a\nshell company to trick a certificate authority into issuing them a certificate\nunder the shell company’s name.[11](part0005.html#c01-ftn11) In both\nscenarios, attackers ran the risk that machines would view their certificate\nas suspicious and reject their file. In this case, the attackers had used a\nvalid certificate from RealTek—a trusted hardware maker in Taiwan—to fool\ncomputers into thinking the drivers were legitimate RealTek drivers.\n\nIt was a tactic Ulasen had never seen before and it raised a lot of questions\nabout how the attackers had pulled it off. One possibility was that they had\nhijacked the computer of a RealTek software developer and used his machine and\ncredentials to get their code secretly signed.[12](part0005.html#c01-ftn12)\n\nBut it was also possible the attackers had simply stolen the signing key and\ncertificate, or cert. For security reasons, smart companies store their certs\nand keys on offline servers or in hardware security modules that offered extra\nprotection. But not everyone did this, and there were possible clues to\nsuggest that RealTek’s cert had indeed been nabbed. A timestamp on the\ncertificates showed that both of the drivers had been signed on January 25,\n2010. Although one of the drivers had been compiled a year earlier on January\n1, 2009, the other one was compiled just six minutes before it was signed. The\nrapid signing suggested the attackers might have had the RealTek key and cert\nin their possession.\n\nThe implications were disturbing. The use of a legitimate digital certificate\nto authenticate malicious files undermined the trustworthiness of the computer\nworld’s signing architecture and called into question the legitimacy of any\nfile signed with digital certificates thereafter. It was only a matter of time\nbefore other attackers copied the tactic and began stealing certificates as\nwell.[13](part0005.html#c01-ftn13) Ulasen needed to get the word out.\n\nResponsible disclosure dictated that researchers who find vulnerabilities in\nsoftware notify the relevant vendors before going public with the news to give\nthe vendors time to patch the holes, so Ulasen dashed off e-mails to both\nRealTek and Microsoft, notifying them of what his team had found.\n\nBut after two weeks passed with no response from either company, Ulasen and\nKupreev decided they couldn’t keep quiet.[14](part0005.html#c01-ftn14) The\nrest of the security community needed to know about the .LNK exploit. They had\nalready added signatures to VirusBlokAda’s antivirus engine to detect the\nmalicious files and were seeing infections pop up on machines all over the\nMiddle East and beyond. The worm/virus was on the run and spreading quickly.\nThey had to go public with the news.[15](part0005.html#c01-ftn15)\n\nSo on July 12, Ulasen posted a brief announcement about the zero-day to his\ncompany’s website and to an online English-language security forum, warning\nthat an epidemic of infections was about to break\nout.[16](part0005.html#c01-ftn16) He divulged few details about the hole it\nwas attacking, to avoid giving copycat hackers information that would help\nthem exploit it. But members of the forum grasped the implications quickly,\nnoting that it had the potential to be “deadly to many.”\n\nThree days later, tech journalist Brian Krebs picked up the announcement and\nwrote a blog post about it, summarizing what little was known about the\nvulnerability and exploit at the time.[17](part0005.html#c01-ftn17) The news\nraced through the security community, causing everyone to brace for a wave of\nassaults expected to come from the worm and copycat attacks using the same\nexploit.[18](part0005.html#c01-ftn18) In the meantime, the head of an\ninstitute in Germany that researched and tested antivirus products brokered an\nintroduction between Ulasen and his contacts at Microsoft, prompting the\nsoftware company to begin work on a patch.[19](part0005.html#c01-ftn19) But\nwith news of the vulnerability already leaked, Microsoft decided to release an\nimmediate advisory about the critical flaw to customers, along with a few tips\nadvising them how to mitigate their risk of infection in the meantime. In the\nabsence of a patch, however, which wouldn’t be released for another two weeks,\nit was far from a cure.[20](part0005.html#c01-ftn20)\n\nThe computer security industry also rumbled into action to address the worm\nthat now had a name—“Stuxnet,” an alias Microsoft conjured from letters in the\nname of one of the driver files (mrxnet.sys) and another part of the code. As\nsecurity companies added signatures to their engines to detect the worm and\nits exploit, thousands of malicious files started showing up on the machines\nof infected customers.[21](part0005.html#c01-ftn21)\n\nAlmost immediately, another surprise emerged. On July 17, an antivirus firm in\nSlovakia named ESET spotted another malicious driver that appeared to be\nrelated to Stuxnet. This one was also signed with a digital certificate from a\ncompany in Taiwan, though not from RealTek. Instead, it came from a company\ncalled JMicron Technology, a maker of circuits.\n\nThe driver was discovered on a computer by itself, without any of Stuxnet’s\nother files, but everyone assumed it must be related to Stuxnet since it\nshared similarities with the other drivers that VirusBlokAda had\nfound.[22](part0005.html#c01-ftn22) There was something notable about the\ncompilation date of this driver, however. When hackers ran their source code\nthrough a compiler to translate it into the binary code that a machine could\nread, the compiler often placed a timestamp in the binary file. Though\nattackers could manipulate the timestamp to throw researchers off, this one\nappeared to be legitimate. It indicated that the driver had been compiled on\nJuly 14, two days _after_ VirusBlokAda had gone public with news of Stuxnet.\nHad the Stuxnet hackers unleashed the driver in a new attack, completely\noblivious to the fact that an obscure antivirus firm in Belarus had just blown\ntheir cover? Or had they known their stealth mission was about to be exposed\nand were racing to get Stuxnet onto more machines before it would be blocked?\nThere were clues that the attackers had missed a few steps while signing the\ndriver with the JMicron cert, which suggested they may indeed have been in a\nhurry to get their attack code out the door and onto\nmachines.[23](part0005.html#c01-ftn23) One thing was clear, though: the\nattackers had needed this new certificate to sign their driver because the\nRealTek certificate had expired a month earlier, on June 12. Digital\ncertificates have a limited life-span, and once RealTek’s expired, the\nattackers could no longer use it to sign new files. The certificate was also\nrevoked by certificate authorities once Stuxnet was exposed, which meant that\nWindows machines would now reject or flag any files that had already been\nsigned with it.[24](part0005.html#c01-ftn24)\n\nThe discovery of the second certificate led to more speculation about how the\nhackers had obtained these security documents. RealTek and JMicron were both\nheadquartered just two blocks away from each other in the Hsinchu Science and\nIndustrial Park in Hsinchu City, Taiwan. Given their geographic proximity,\nsome speculated that the attackers may have physically broken into the two\noffices to steal the digital signing keys and certs. Others speculated that\nthe People’s Republic of China was behind the Stuxnet attack and had hacked\nthe two Taiwanese companies to get their digital signing keys and\ncertificates.\n\nWhatever the scenario, it meant the attackers likely had other stolen digital\ncertificates in their arsenal. And if they had gone to this much trouble to\nmake sure their attack would work, it likely meant they had a serious goal and\nconsiderable means at their disposal. Many in the security community were left\nfeeling very uneasy and perplexed. “We rarely see such professional\noperations,” ESET researcher Pierre-Marc Bureau remarked\nonline.[25](part0005.html#c01-ftn25)\n\nAs antivirus firms examined the Stuxnet files pouring in from customers, they\ngot another surprise. Based on dates in some of the files, it appeared that\nStuxnet had been launched in the wild as early as June 2009, which meant it\nhad been lurking on machines for at least a year before VirusBlokAda\ndiscovered it. It also appeared that the attackers had unleashed their attack\nin three different waves—in June 2009, and in March and April 2010—changing\nthe code slightly in each of these waves.\n\nOne thing that was still a mystery, though, was Stuxnet’s intention.\nResearchers could find no sign in any of the files that Stuxnet was stealing\nbank account passwords or other credentials the way so much other malware was\ndesigned to do. Neither could they find signs of any other obvious motive in\nthe code. That is, until a researcher in Germany found one possible clue\nsuggesting Stuxnet’s aim.\n\n“Hi guys,” Frank Boldewin wrote to the online forum where Ulasen had first\npublished his notice about Stuxnet, “has anyone … taken a deeper look at the\nmalware?” Boldewin had unwrapped the first layer of covering on one of\nStuxnet’s files and found unusual references inside to software made by the\nGerman firm Siemens. The attackers appeared to be searching for computers that\nhad one of two Siemens proprietary software programs installed—either Siemens\nSIMATIC Step 7 software or its SIMATIC WinCC program. Both programs are part\nof an industrial control system (ICS) designed to work with Siemens\nprogrammable logic controllers (PLCs)—small computers, generally the size of a\ntoaster, that are used in factories around the world to control things like\nthe robot arms and conveyor belts on assembly lines.\n\nBoldewin had never seen malware targeting an industrial control system before.\nThere was no obvious financial gain to be made from hacking factory equipment\nlike PLCs, at least not the kind of quick cash that could be made from hacking\nbank accounts and credit card systems. It could mean only one thing to him.\n“Looks like this malware was made for espionage,” he\nwrote.[26](part0005.html#c01-ftn26) The attackers must have been looking to\nsteal a competitor’s factory design or their product blueprints.\n\nIt was an assessment that many in the tech community were all too happy to\nembrace. Stuxnet appeared to be targeting only systems with the Siemens\nsoftware installed, which meant that any computer not using the Siemens\nprograms was presumably safe, and their owners could relax. The systems in\nIran that were caught in the reboot loop didn’t have the Siemens software\ninstalled, Ulasen discovered, and aside from the system crashes they\nexperienced, it appeared that Stuxnet had caused them no lingering harm.\n\nSo within a week or so after the mysterious worm’s brief brush with fame, it\nappeared that Stuxnet was on its way out the door to lasting obscurity.\nMicrosoft was still working on a patch to fix the security hole the .LNK\nexploit breached, but as far as most security companies were concerned, once\nthey added signatures to their scanners to detect the worm’s malicious files,\nStuxnet held no further interest.\n\nThe story of the world’s first digital weapon might well have ended here,\nexcept that a few security researchers weren’t quite ready to let it go.\n\n* * *\n\n[1](part0005.html#c01-ftn1a) Ulasen and his team encountered the malware the\nweek of June 24, 2010.\n\n[2](part0005.html#c01-ftn2a) Ulasen has never disclosed the name of the\nreseller, but a link on VirusBlokAda’s website for its distributor in Iran\npoints to [vba32-ir.com](http://www.vba.com.by/dialer/iran/), a site owned by\nthe Deep Golden Recovery Corporation, a data-recovery firm in Iran.\n\n[3](part0005.html#c01-ftn3a) Information about VirusBlokAda’s encounter with\nthe malware comes from interviews with Sergey Ulasen and Oleg Kupreev, as well\nas from an account published by Kaspersky Lab in 2011, after the Russian\nantivirus firm hired Ulasen away from VirusBlokAda. That interview, “The Man\nWho Found Stuxnet—Sergey Ulasen in the Spotlight,” was published November 2,\n2011, at [eugene.kaspersky.com/2011/11/02/the-man-who-found-stuxnet-sergey-\nulasen-in-the-spotlight](http://www.eugene.kaspersky.com/2011/11/02/the-man-\nwho-found-stuxnet-sergey-ulasen-in-the-spotlight).\n\n[4](part0005.html#c01-ftn4a) A module is a stand-alone component. It is often\ninterchangeable and can be used with various programs.\n\n[5](part0005.html#c01-ftn5a) Drivers are software programs that are used as\ninterfaces between a device and a computer to make the device work with the\nmachine. For example, a driver is required to allow a computer to communicate\nwith a printer or digital camera that is connected to it—different drivers are\navailable for different operating systems so that the same device will work\nwith any computer. In this case the drivers were actually rootkits designed to\ninstall and conceal malicious files on the machine.\n\n[6](part0005.html#c01-ftn6a) The reboot problem didn’t occur on other machines\nlater found to be infected by the malware. So some researchers suspect the\nproblem may have been an incompatibility between one of the malware’s drivers\nand VirusBlokAda’s antivirus software. The malware used the driver to install\nitself, and researchers at Kaspersky Lab in Russia suspected that when the\ndriver injected the malware’s main file into the memory of the machines in\nIran, this caused some machines to crash. Researchers at Kaspersky Lab later\ntried to reproduce the problem but got inconsistent results—sometimes a\nmachine crashed, sometimes it didn’t. The irony is that the attackers had put\na lot of effort into testing their malware against antivirus scanners from\nKaspersky, Symantec, McAfee, and others, precisely to make sure their code\nwouldn’t be detected by the scanners or crash machines. But they apparently\nhadn’t tested it against VirusBlokAda’s scanning software. So if VBA’s scanner\n_was_ the problem, it meant this tiny Belarusian firm had been their undoing\nin more ways than one.\n\n[7](part0005.html#c01-ftn7a) Autorun is a convenience feature in Windows that\nallows programs on a USB flash drive, CD-ROM, or DVD, to automatically launch\nwhen the devices are inserted into a computer. It’s a known security risk,\nhowever, because any malicious program on the device will automatically launch\nas well.\n\n[8](part0005.html#c01-ftn8a) If Autorun is disabled for security reasons, then\nthe malicious code on the flash drive that exploits this feature will not be\nable to launch automatically but will launch only if users specifically click\non the file to open it.\n\n[9](part0005.html#c01-ftn9a) The exploit worked against seven versions of\nWindows: Windows 2000, WinXP, Windows 2003, Vista, Windows Server 2008,\nWindows 7, and Windows Server 2008 R2.\n\n[10](part0005.html#c01-ftn10a) With Windows Vista and Windows 7, a driver that\nisn’t signed with a trusted digital certificate that Microsoft recognizes will\nhave trouble installing on the machine. On 32-bit Windows machines that have\nVista or Windows 7 installed, a warning will display, telling the user the\nfile is not signed or is not signed with a trusted certificate, forcing the\nuser to make a decision about whether to let it install. On 64-bit Windows\nmachines using either operating system, a file not signed with a trusted\ncertificate simply won’t install at all. The malware VirusBlokAda found only\nworked on 32-bit Windows machines.\n\n[11](part0005.html#c01-ftn11a) Certificate authorities dole out the signing\ncertificates that companies use to sign their code and websites. The CAs are\nsupposed to verify that an entity requesting a certificate has the authority\nto do so—to prevent someone other than Microsoft from obtaining a code-signing\ncertificate in Microsoft’s name, for example—and to ensure that if someone\napplies for a signing certificate for a company they claim is theirs, it’s a\nreal company producing real code. Some certificate authorities don’t do due\ndiligence, however, and certificates are sometimes issued to malicious actors.\nThere are also companies that, for a fee, will use their key and certificate\nto sign code for others. Hackers have used these companies in the past to sign\ntheir malware.\n\n[12](part0005.html#c01-ftn12a) In September 2012, this is exactly what\nhappened to Adobe. The software giant, which distributes the popular Adobe\nReader and Flash Player programs, announced that attackers had breached its\ncode-signing server to sign two malicious files with an Adobe certificate.\nAdobe stored its private signing keys in a device called a hardware security\nmodule, which should have prevented the attackers from accessing the keys to\nsign their malicious files. But they compromised a build server—a server used\nfor developing software—which had the ability to interact with the code-\nsigning system and get it to sign their files.\n\n[13](part0005.html#c01-ftn13a) Ironically, on July 12, 2010, the day Ulasen\nwent public with news about the malware, a researcher with the Finnish\nsecurity firm F-Secure published a conference presentation about digital\ncertificates, stating that, as of then, malware using stolen certificates had\nyet to be discovered. He noted, however, that this would inevitably happen now\nthat new versions of Windows treated unsigned drivers with suspicion, pushing\nhackers to steal legitimate certificates to sign their malware. (See Jarno\nNiemela, “It’s Signed, Therefore It’s Clean, Right?” presented at the CARO\nconference in Helsinki, Finland; available at\n[f-secure.com/weblog/archives/Jarno_Niemela_its_signed.pdf](http://www.f-secure.com/weblog/archives/Jarno_Niemela_its_signed.pdf).)\nIndeed, not long after VirusBlokAda’s discovery of the RealTek certificate,\nother hackers were already attempting to use the same tactic. In September\n2010, antivirus firms discovered Infostealer. Nimkey, a Trojan horse\nspecifically designed to steal private key certificates from computers. This\nwas followed over the next two years by a number of malicious programs signed\nwith certificates apparently stolen from various trusted companies.\n\n[14](part0005.html#c01-ftn14a) Ulasen contacted Microsoft through a general\ne-mail address used for its security team. But Microsoft’s security response\nteam receives more than 100,000 e-mails a year, so it was understandable that\nan e-mail sent to its general mailbox from an obscure antivirus firm in\nBelarus got lost in the queue.\n\n[15](part0005.html#c01-ftn15a) The malware, researchers would later discover,\nwas a combination of a worm and virus. The worm portion allowed it to spread\nautonomously without user action, but once it was on a system, other\ncomponents infected files, like a virus would, and required user action to\nspread.\n\n[16](part0005.html#c01-ftn16a) Ulasen published his note on his company’s site\nat anti-virus.by/en/tempo/shtml and at the Wilders Security forum at\n[wilderssecurity.com/showthread.php?p=1712146](http://www.wilderssecurity.com/showthread.php?p=1712146).\n\n[17](part0005.html#c01-ftn17a) Krebs, a former _Washington Post_ reporter,\nruns the [KrebsonSecurity.com](http://www.KrebsonSecurity.com) blog, which\nfocuses on computer security and cybercrime. He published his post July 15,\n2010, at [krebsonsecurity.com/2010/07/experts-warn-of-new-windows-shortcut-\nflaw](http://www.krebsonsecurity.com/2010/07/experts-warn-of-new-windows-\nshortcut-flaw).\n\n[18](part0005.html#c01-ftn18a) Lenny Zeltser, “Preempting a Major Issue Due to\nthe .LNK Vulnerability—Raising Infocon to Yellow,” published July 19, 2010, at\n[isc.sans.edu/diary.html?storyid=9190](http://www.isc.sans.edu/diary.html?storyid=9190).\n\n[19](part0005.html#c01-ftn19a) Andreas Marx, head of [AV-\nTEST.org](http://www.AV-TEST.org) in Germany, brokered the introduction with\nhis direct contacts at Microsoft.\n\n[20](part0005.html#c01-ftn20a) Microsoft’s advisory appears at\n[technet.microsoft.com/en-\nus/security/advisory/2286198](http://www.technet.microsoft.com/en-\nus/security/advisory/2286198).\n\n[21](part0005.html#c01-ftn21a) Most antivirus companies have automated\nreporting systems that will notify them when a malicious file is detected on a\ncustomer’s machine if the customer has opted for this feature. In most cases\nall that gets sent to the company is a “hash” of the file—a cryptographic\nrepresentation of the contents of the file composed of a string of letters and\nnumbers produced by running the file through an algorithm—with no indication\nof who the victim is, other than the sender’s IP address. But in other cases\ncompanies can obtain the entire malicious file itself if the victim decides to\nsend it or the antivirus firm determines through the IP address who the victim\nis and requests a copy of the file.\n\n[22](part0005.html#c01-ftn22a) Researchers speculated that the driver might\nhave been used with a new version of Stuxnet the attackers unleashed after\ntweaking the code to prevent antivirus signatures from detecting it. No later\nversion of Stuxnet has ever been discovered, but see [footnote\n41](part0021.html#c17-ftn41), for further discussion about a later version of\nStuxnet.\n\n[23](part0005.html#c01-ftn23a) See Costin G. Raiu and Alex Gostev, “A Tale of\nStolen Certificates,” published in _SecureView_ , 2nd Quarter 2011, a\nquarterly newsletter from Kaspersky Lab. The mistakes appear in the digital\nsignature block on the certificate, where a company provides information about\nitself. In this case, the attackers mistyped the URL for JMicron so that it\nreturned a “server not found” error if someone tried to visit the website.\nThey also failed to fill in several fields for the company’s name, copyright\nownership, and other data. In eight of the fields, the words “change me”\nappeared instead of information.\n\n[24](part0005.html#c01-ftn24a) The RealTek certificate was valid from March\n15, 2007, to June 12, 2010. The JMicron certificate was valid until July 26,\n2012, but once it was revoked by certificate authorities, the attackers\ncouldn’t use it anymore.\n\n[25](part0005.html#c01-ftn25a) Pierre-Marc Bureau, “Win32/Stuxnet Signed\nBinaries,” published August 9, 2010, at\n[blog.eset.com/2010/07/19/win32stuxnet-signed-\nbinaries](http://www.blog.eset.com/2010/07/19/win32stuxnet-signed-binaries).\n\n[26](part0005.html#c01-ftn26a) Boldewin published his note at\n[wilderssecurity.com/showthread.php?p=1712146](http://www.wilderssecurity.com/showthread.php?p=1712146).\n\n\n# CHAPTER 2\n\n# **500 KILOBYTES OF MYSTERY**\n\nIn the six years Liam O’Murchu had been analyzing viruses and worms, he’d\nnever seen anything like the code he was looking at now. It was using\ntechniques that went way beyond anything he’d ever seen other malware do. This\nwasn’t at all what he’d expected when he sat down at his computer in\nSymantec’s Southern California office and pulled up the Stuxnet files that had\narrived overnight from his colleagues in Europe.\n\nIt was Friday, July 16, the day after the news of Stuxnet had broken in the\ntech community, and O’Murchu was in the midst of what he thought would be a\nroutine and perfunctory review of the code. The thirty-three-year-old Irishman\nwas manager of operations for the Security Response team in Symantec’s Culver\nCity office, and it was his job to review new malware that came in to\ndetermine if it merited closer scrutiny.\n\nAnalysts in the company’s office in Dublin, Ireland, had got hold of the\nStuxnet files late in their afternoon but only had a couple of hours with the\ncode before it was time to hand it off to O’Murchu’s team in California, who\nwere just waking up. Symantec’s threat-analysis team is spread across multiple\ncontinents so that anytime an important threat pops up, someone somewhere is\nawake to jump on it. Then as the sun sets on one office and rises on another,\nworkers in one time zone hand off their notes, like tag-team wrestlers, to\nthose in the next zone.\n\nNot all malware gets this follow-the-sun coverage. Of the more than 1 million\nmalicious files Symantec and other security firms find each month, most are\ncopycats of known tools that hackers simply tweak to alter their fingerprints\nand try to outrun antivirus scanners. These standard threats get piped through\nalgorithms that tear through the code looking for signatures or behavior that\nmatches known malware. Code gets kicked out of the queue for researchers to\nexamine manually only if the algorithms find something they can’t reconcile.\nMalware containing, or suspected of containing, a zero-day exploit always gets\nexamined by hand, which is the only reason Stuxnet landed on O’Murchu’s desk.\n\nO’Murchu is an avid snowboarder with a lyrical accent and closely cropped\nbrown hair sculpted vertically in front like the lip of a small half-pipe. A\nfairly recent transplant to the United States from Dublin, he’d only been in\nSymantec’s California office about two years before Stuxnet struck, but he’d\nworked for the company since 2004. He led a team of highly skilled malware\nanalysts and reverse engineers who were engaged in a constant battle against\nan onslaught of digital threats, each one often more advanced than the last.\nNone of them, however, prepared him for what he found in Stuxnet.\n\nO’Murchu expected their examination of the code would be merely routine, just\nto confirm the presence of the zero-day exploit that Ulasen and Kupreev had\nalready found. So he passed the code off to a junior engineer, thinking it\nwould be a good opportunity to train him on zero days, and only examined the\ncode himself to backstop his colleague and make sure he didn’t miss anything.\nBut as soon as he opened the files, it was immediately clear there was\nsomething strange going on with the code.\n\nThe main Stuxnet file was incredibly large—500 kilobytes, as opposed to the 10\nto 15 KB they usually saw. Even Conficker, the monster worm that infected more\nthan 6 million machines the previous two years, was only 35 kilobytes in size.\nAny malware larger than this usually just contained a space-hogging image file\nthat accounted for its bloat—such as a fake online banking page that popped up\nin the browser of infected machines to trick victims into relinquishing their\nbanking credentials. But there was no image file in Stuxnet, and no extraneous\nfat, either. And, as O’Murchu began to take the files apart, he realized the\ncode was also much more complex than he or anyone else had previously\nbelieved.\n\nWhen you’ve seen as much malware as O’Murchu has, you can glance at a virus or\nTrojan horse and know immediately what it does—this one is a keystroke logger\nthat records everything a victim types; that one is a banking Trojan that\nsteals login credentials to online banking accounts. It’s also easy to see\nwhether a piece of code was slapped together sloppily or crafted skillfully\nwith care. Stuxnet was obviously the latter. It appeared to be a dense and\nwell-orchestrated collection of data and commands that contained an enormous\namount of functionality. What those functions were was still a mystery, but\nO’Murchu’s interest was immediately piqued.\n\nO’MURCHU’S FIRST ENCOUNTER with malware occurred in 1996 when he was studying\ncomputer science at University College Dublin and a fellow student unleashed a\nhomemade virus that infected all the machines in the school’s computer labs.\nOn the Ides of March, the virus seized control of the terminals and locked\neveryone out. Users could only log in after answering a series of ten\nquestions that flashed on the screens. Most were annoyed by the interruption,\nbut O’Murchu just wanted to get his hands on a copy of the virus to take it\napart. It was part of his DNA to deconstruct things. Growing up in the country\noutside the small town of Athy in County Kildare, he was the kind of kid who\nwas less interested in playing with toy cars than in tearing them apart to see\nhow they worked.\n\nO’Murchu didn’t set out to become a virus wrangler. He began his college\ncareer dutifully taking physics and chemistry classes for the science degree\nhe planned to pursue, but then enrolled in a computer science course and\nbecame obsessed. He quickly abandoned the chemist’s lab for the computer lab.\nHacking was a growing problem at the university, but O’Murchu never considered\ncomputer security a possible career path until intruders began breaking into\nservers belonging to the school’s computer club, and a team of students was\ntasked with patching the servers to kick them out. O’Murchu was fascinated by\nthe cat-and-mouse game that ensued, as he watched the intruders repeatedly\noutmaneuver the defenders to get back in.\n\nThat lesson in breaking digital barriers came in handy when he and a group of\nfriends traveled to the United States after college and briefly got jobs\ntesting internet kiosks for a San Diego start-up. They were hired to see if\nthey could bypass the kiosk’s paywall in order to steal internet access. But\ninstead of getting the normal computer users the company thought it was\ngetting, it had inadvertently hired a team of skilled hackers. After half a\ndozen kiosks were set up in the warehouse where the systems were being\nassembled, O’Murchu and his friends were told to go at them. They were only\nsupposed to test the system for two weeks before the company planned to ship\nthe kiosks out to customers, but O’Murchu and his friends kept finding new\nways to break the paywall. After two months passed and they were still finding\nholes, the company canceled the testing and just shipped the kiosks out.\n\nO’Murchu spent the next couple of years traveling the world and snowboarding\nwith a vague desire to get into security but without any plan for doing it.\nThen in 2002, he got a job with the anti-spam company Brightmail in Dublin. He\nonly took it to earn money to support his traveling, but when Symantec bought\nthe firm in 2004, he saw it as a chance to leap into security. During a tour\nof Symantec’s Dublin office given to the Brightmail employees, O’Murchu could\nbarely contain his impatience at being shown around the various departments.\nAll he wanted to see was the virus research team that he hoped to join. But\nwhen he finally met Eric Chien, the American who managed the team, his dream\nof being hired was dashed. O’Murchu thought Symantec had hundreds of analysts\nstationed around the world and that it would therefore be easy to get a job.\nBut Chien told him only half a dozen people worked on the team, and all of\nthem had been on the job for years. “Nobody really leaves,” Chien said.\n“Everyone loves their work.”\n\nO’Murchu was undeterred. He taught himself the tools the analysts used to\ndecipher malicious code and write signatures, and when an explosion of spyware\nand adware burst onto the scene several months later, he was ready when\nSymantec needed to expand its team. He worked the next four years in\nSymantec’s Dublin office—where the company still maintains its largest\nresearch group—before transferring to Culver City in 2008.\n\nOver the years, O’Murchu and the Symantec team had worked on a number of high-\nprofile and complex threats. But none was as fascinating or as challenging as\nStuxnet would turn out to be.\n\nWHEN O’MURCHU EXAMINED Stuxnet’s main file, he immediately came up against\nseveral layers of encryption masking its many parts and inner core. Luckily\nthe first layer was a simple “packer” that was easily cracked.\n\nPackers are digital tools that compress and mangle code to make it slightly\nharder for antivirus engines to spot the signatures inside and for forensic\nexaminers to quickly determine what a code is doing. Malware run through a\npacker morphs a little differently on its surface each time it’s packed, so\nthe same code run through a packer a thousand times will create a thousand\ndifferent versions of the code, though beneath the packer layer they will all\nbe the same at their core. Antivirus engines can tell when a malicious file\nhas been run through a known packer and can then unpack it on the fly to hunt\nfor the signatures beneath. To thwart this, smart attackers design custom\npackers that aren’t easily recognized or removed. But Stuxnet’s creators\nhadn’t bothered to do this. Instead they used an off-the-shelf packer called\nUPX—short for “Ultimate Packer for eXecutables”—that was easily identified and\neliminated. Given the sophisticated nature of the rest of the threat—the zero-\nday exploit and the stolen digital certificates—it seemed an odd choice for\nStuxnet’s creators to make. So O’Murchu assumed their primary reason for using\nthe packer must have been to simply compress the files and reduce Stuxnet’s\nfootprint. Once unpacked and decompressed, the main module expanded to 1.18\nmegabytes in size.\n\nWith the packer now removed, O’Murchu was able to easily spot the Siemens\nstrings Frank Boldewin had seen. But more important, he also spotted an\nencrypted block of code that turned out to be Stuxnet’s mother lode—a large\n.DLL file (dynamic link library) that contained about three dozen other .DLLs\nand components inside, all wrapped together in layers of encryption like\nRussian nesting dolls. He also found a massive configuration file containing a\nmenu of more than four hundred settings the attackers could tweak to change\neverything from the URL for the command-and-control servers Stuxnet contacted\nto the number of machines Stuxnet would infect via a USB flash drive before\nthe USB exploit would shut down.[1](part0006.html#c02-ftn1) Curiously,\nO’Murchu also found an infection stop date in the file—June 24, 2012. Every\ntime Stuxnet encountered a new machine, it checked the computer’s calendar to\nsee if the June date had passed. If it had, Stuxnet would halt and not infect\nit. Any payload already installed on other machines would continue to work,\nbut Stuxnet wouldn’t infect any new machines. The stop date had been set for\nthree years after Stuxnet infected its first machines in Iran and was\npresumably the date by which the attackers expected to achieve their\ngoal.[2](part0006.html#c02-ftn2)\n\nWhat most stood out to O’Murchu, however, was the complex way that Stuxnet\nconcealed its files on infected machines and hijacked normal functions to\nperform its nefarious deeds. It took O’Murchu nearly a day to work out the\ndetails, and when he finally did, he was astounded.\n\nNormally, the code for performing common tasks on a Windows machine, such as\nopening and reading a file or saving its contents to disk, is stored in .DLLs\nin the operating system. When the operating system or another application\nneeds to perform one of these tasks, they call up the relevant code from the\n.DLL—like a library patron checking out a book—and run it in the machine’s\nmemory. Conventional hackers would try to store code for their malicious\nactivities in the Windows .DLLs too, but antivirus scanners can spot code in a\nlibrary that shouldn’t be there, so Stuxnet placed its malicious code in the\nmachine’s memory instead, where antivirus programs were less likely to detect\nit. That alone wasn’t remarkable, since a lot of smart hackers stored their\nmalicious code in memory. But the _way_ Stuxnet got its code to run was.\n\nUsually, malicious code that lurks in memory will still need to ask the system\nto load additional code from files that it stores on the computer’s disk. But\nantivirus engines will spot this behavior as well, so Stuxnet did it one\nbetter. Stuxnet kept all of the code it needed to operate inside itself,\nstored as virtual files with specially crafted names. Ordinarily this wouldn’t\nwork because when Stuxnet tried to call up this code, the operating system\nwouldn’t recognize the names or would look for the oddly named files on disk\nand not be able to find them. But Stuxnet “hooked” or reprogrammed part of the\nWindows API—the interface between the operating system and the programs that\nrun on top of it—so that anytime it called on these oddly named files, the\noperating system would simply go to Stuxnet, sitting in memory, to obtain the\ncode instead. If an antivirus engine grew suspicious of the files in memory\nand tried to examine them, Stuxnet was prepared for this as well. Because it\ncontrolled parts of the Windows API responsible for displaying the attributes\nof files, it simply tricked the scanner into thinking the files were empty,\nessentially telling it, “Nothing to see here, move\nalong.”[3](part0006.html#c02-ftn3)\n\nBut this wasn’t the end of it. Normal malware executes its code in a\nstraightforward manner by simply calling up the code and launching it. But\nthis was too easy for Stuxnet. Instead, Stuxnet was built like a Rube Goldberg\nmachine so that rather than calling and executing its code directly, it\nplanted the code inside another block of code that was already running in a\nprocess on the machine, then took the code that was running in that process\nand slipped it inside a block of code running in _another_ process to further\nobscure it.\n\nO’Murchu was astounded by the amount of work the attackers had invested in\ntheir heist. Even the most complex threats he’d seen in recent years didn’t go\nto such lengths. The average malware writer did just the minimum of what he\nneeded to do to make his attack work and avoid detection; there was little to\nbe gained from investing a lot of time in code that was just meant to do a\nquick smash-and-grab of passwords or other data. Even the advanced espionage\ntools that appeared to come from China didn’t bother with the kinds of tricks\nhe was seeing in Stuxnet. Red flags were popping up all over the code, and\nO’Murchu had only examined the first 5 KB of the 1 MB threat.\n\nIt was clear this wasn’t a standard attack, and needed to be examined more\nclosely. But the size and complexity of the code meant it was going to take a\nteam of people to reverse-engineer and decipher it. So the question running\nthrough O’Murchu’s mind was should they even bother doing it? No one would\nblame Symantec if the researchers dropped the code and moved on to other\nthings. After all, the primary task of any antivirus firm was to halt\ninfections before they began or to rid infected systems of malware that was\nalready on them. What malicious code did to computers once it was on them was\nsecondary.\n\nBut even though their primary work stopped at the point of detection, any\ncustomer infected with Stuxnet would still want to know what the malware had\ndone to their system, even if Symantec had already detected and deleted its\nmalicious files. Had it pilfered credentials or important documents? Altered\nor deleted crucial data? O’Murchu felt it was their duty to find out.\n\nBut this wasn’t the only reason he wanted to continue digging through the\ncode. The truth was, Stuxnet appealed to him because it was a huge adrenaline\nrush of a puzzle—a virus far too complex to be merely a tool for espionage,\nand far too sophisticated to be the work of mere cybercriminals. He just had\nto figure it out.\n\n![](../images/00007.jpeg)\n\nAS THE END of that first day drew near, O’Murchu typed up his notes describing\nwhat he had uncovered so far and sent them off to Symantec’s team in Tokyo,\nregretting that he didn’t have more time to spend with the code.\n\nThe Tokyo team worked part of that weekend, mapping Stuxnet’s components and\ndoing a high-level analysis of the code so that everyone could get a handle on\nwhat they were dealing with. Back in California, where O’Murchu lived with his\nBritish girlfriend near the beach in Marina del Rey, he tried to push the code\nout of his mind, but couldn’t. Memories of the complex way it hijacked a\nsystem invaded his mind until he started to question whether he was right\nabout what he had seen. To silence his doubts, he returned to the office to\nlook at the code again until he was satisfied that he was correct.\n\nBy the time Monday morning arrived, he was impatient to get to the office to\nmeet with his colleague Eric Chien and report what he had found. Like\nO’Murchu, Chien had transferred from Symantec’s Dublin office to Culver City\nand was now technical director of the company’s Security Response team. Chien\ndecided they should call Nicolas Falliere, a young senior software engineer\nand analyst in Symantec’s Paris office who was a whiz at deconstructing\ndifficult code. The three of them worked out a plan for tackling the project.\n\nStuxnet was so large, with so many different parts, but the obvious place to\nstart was the command-and-control servers. So while Falliere familiarized\nhimself with the parts of Stuxnet that O’Murchu had already seen, Chien and\nO’Murchu focused on the servers.\n\nEach time Stuxnet infected a system, it “phoned home” to one of two internet\ndomains masquerading as soccer fan sites—mypremierfutbol.com and\ntodaysfutbol.com. The domain names, registered by someone who used fake names\nand fraudulent credit cards, pointed to servers in Denmark and Malaysia that\nserved as command-and-control stations for the attack. Each time Stuxnet\ninfected a machine, it contacted the servers to announce its conquest and\ncommunicate intelligence about the latest victim. The communication was\nencrypted to prevent anyone from casually reading it, but the encryption the\nattackers had used was surprisingly weak and easily cracked. Once Chien and\nO’Murchu unlocked it, they were able to see that Stuxnet was reporting the\nmachine’s computer and domain names to the attackers, as well as the internal\nIP address, the version of Windows it was running, and whether or not it had\nthe targeted Siemens software installed on it.[4](part0006.html#c02-ftn4)\n\nEach piece of data presumably helped the attackers determine if Stuxnet was\nclosing in on its target. This was important because they were essentially\nflying blind in their attack. Once unleashed, a self-propagating worm like\nStuxnet has a life of its own, and the attackers would have had no real\ncontrol over where their malicious code traveled. The data coming back to the\nservers would have helped them track its path to some degree as it crawled\nthrough networks in search of its quarry.\n\nBut of all the information Stuxnet reported to its masters, the Siemens data\nwas the most important because, as the researchers would soon learn, if\nStuxnet found itself on a system that _didn’t_ have the Siemens software\ninstalled, it simply shut itself down. It still sought other machines to\ninfect, but it wouldn’t launch its payload on any machine that didn’t have the\nSiemens software installed. Any system without the software was just a means\nto Stuxnet’s end.[5](part0006.html#c02-ftn5)\n\nO’Murchu contacted the DNS (domain name system) service providers for the two\ncommand-and-control domains and asked them to stop the traffic going to the\nattackers and divert it to a sinkhole—a computer dedicated to receiving\nhostile traffic—that Symantec controlled instead. DNS providers are the\ntraffic cops of the internet, who make sure that e-mail and browsers reach\ntheir destinations, so that anytime someone types “nytimes.com” into their\nbrowser or clicks on a link for a website, they will arrive at the proper IP\naddress.[6](part0006.html#c02-ftn6) By diverting the traffic to their\nsinkhole, the researchers could now collect the real-time data that Stuxnet,\nlike a good soldier, was supposed to be reporting to the attackers. By Tuesday\nmorning, July 20, a flood of traffic was coming to their sinkhole.\n\nAs each infected machine called in, O’Murchu and Chien mapped the domains and\ncountries from which they reported and examined the data that Stuxnet sent in,\nlooking for common characteristics—including the number of victims carrying\nthe Siemens software. By the end of the week, more than 38,000 infected\nmachines from dozens of countries had contacted the sinkhole, and at a rate of\n9,000 new infections a day, the number was swiftly growing. They would\neventually track more than 100,000 infections in more than 100\ncountries.[7](part0006.html#c02-ftn7) Stuxnet was still spreading, despite\nsignatures distributed by antivirus firms to stop it, indicating that many\nvictims didn’t have the latest antivirus software installed. Among the\ninfected machines calling in to their sinkhole was an occasional hit from an\nantivirus firm—a sign that researchers at some competing firms were still\nrunning Stuxnet on their test-beds.\n\nAs O’Murchu and Chien mapped the geographical location of each infection, an\nunusual pattern began to emerge. Out of the initial 38,000 machines they\ntracked, more than 22,000 were based in Iran. Indonesia was a distant second,\nwith about 6,700 machines, followed by India with 3,700 infections. The United\nStates had fewer than 400 infections, and the numbers in other countries\ndropped steeply from there. Only a small number of all of the infected\nmachines had the Siemens software installed, and the majority of those were in\nIran as well—217, as opposed to a mere 16 machines in the United\nStates.[8](part0006.html#c02-ftn8)\n\nThe infection numbers were way out of sync with previous patterns of worldwide\noutbreaks, in which Iran never placed high, if at all, in the infection stats.\nEven in outbreaks that began in the Middle East or Central Asia, Iran never\ntracked high on the charts. It seemed clear that they were looking at a\ntargeted attack focused on the Islamic Republic. But if the attackers were\nprimarily interested in Siemens machines installed in Iran, then Stuxnet had\nspread far beyond its target. And why was it spreading farther in India and\nIndonesia than in the United States and Europe? What did the three nations\nhave in common that made the infections concentrate there? Given the time and\nmoney that had obviously gone into producing the code, they knew they weren’t\nlooking at someone who was out to steal pharmaceutical recipes or the\nproduction secrets of an automobile plant, as Boldewin had speculated. The\nattackers had to be aiming to steal intelligence about critical systems,\nperhaps with strategic political importance to the region. The Siemens\nsoftware that Stuxnet sought wasn’t just used in industrial plants, it was\nalso used in critical infrastructure systems. Chien did a quick Google search\non Iran and India to see what the two countries had in common and found recent\nstories about a natural gas pipeline that was being built to connect the two\nnations. The so-called Peace Pipeline involved a 1,700-mile pipeline running\nfrom Iran’s South Pars gas field in the south of the country through Pakistan\nand into India, a plan the United States strongly opposed. The project had\ngone through a number of ups and downs over the years due to shifting\ngeopolitical winds and funding issues, with India pulling out of it in 2009\nunder pressure from the United States. But in May 2010, just two months before\nStuxnet was discovered, India had rejoined the project. Also that month, Iran\nwas set to begin design and construction on the final portion of the pipeline\nto be built inside its borders.\n\nBut there was also something else dominating headlines about Iran—its rapidly\nexpanding nuclear program. Iran was about to open a nuclear reactor at\nBushehr, in the south of the country, which had been a source of great tension\nwith Israel and the West for a number of years. But even more controversial\nthan the reactor was a uranium enrichment plant in a place called Natanz that\nhad been built to supply the reactor with nuclear fuel. The UN had voted for\nsanctions against Iran over the plant, and there was also talk about a\npossible air strike against the plant.\n\nA disturbing geopolitical picture was beginning to emerge. The sophisticated\nnature of the malicious code, plus the stolen certificates and Iran’s place at\nthe center of the outbreak made it appear that Stuxnet might be the product of\na covert government spy mission—albeit one that had clearly run amok. Given\nthat something in Iran appeared to be the target, the list of likely suspects\nwas small—Israel, China, Russia, or the United States.\n\nChien paused to consider the implications. If Stuxnet _was_ the product of a\ngovernment spy mission, specifically a US spy mission, it made their sinkhole\npretty audacious. By intercepting data the attackers were expecting to receive\nfrom infected machines in Iran, they had possibly landed themselves smack in\nthe middle of an international incident and also may have helped sabotage a\nclassified operation. The potential ramifications were daunting.\n\nBut Chien couldn’t dwell upon this right now. Symantec’s job wasn’t to help\nprotect covert government operations, no matter which country might be behind\nthem. Their job was to protect the machines of customers. It didn’t matter who\nlaunched the code or what it was targeting; as long as it was affecting\nSymantec customers, the malicious code had to be stopped.\n\nAlthough machines in Iran, where Symantec didn’t have customers, appeared to\nbe the malware’s primary target, Stuxnet had infected thousands of computers\nin other countries as well and was still on the loose, continuing to spread.\nAnd the researchers still didn’t know what its malicious payload was designed\nto do or if it contained any bugs that might affect nontargeted machines.\n\nThey also couldn’t rule out the possibility that Iran was actually the source\nof the attack instead of its target. Perhaps Iranian engineers had been\nwriting Stuxnet to target machines in the United States and had lost control\nof it in a lab, which would have helped explain all of the infections in Iran.\nIf it now spread to critical systems in the United States—an electric plant or\nthe control system for a dam or railroad—what would happen then?\n\nChien and O’Murchu decided they had to press on.\n\nWhatever the political implications of their decision might be, these would\nhave to wait for consideration another day.\n\n* * *\n\n[1](part0006.html#c02-ftn1a) The .LNK exploit on USB flash drives was\nconfigured to spread Stuxnet to only three new machines before it would shut\ndown and delete the files from the USB flash drive.\n\n[2](part0006.html#c02-ftn2a) Forensic evidence found inside the versions of\nStuxnet Symantec examined indicated that the first infection in Iran occurred\nJune 23, 2009.\n\n[3](part0006.html#c02-ftn3a) Nicolas Falliere, Liam O’Murchu, and Eric Chien,\n“W32.Stuxnet Dossier” (report, February 2011), 13–15, available at\n[symantec.com/content/en/us/enterprise/media/security_response/whitepapers/w32_stuxnet_dossier.pdf](http://www.symantec.com/content/en/us/enterprise/media/security_response/whitepapers/w32_stuxnet_dossier.pdf).\nSymantec’s extensive dossier describes in detail Stuxnet’s technical specs and\nwhat each function in the code is designed to do.\n\n[4](part0006.html#c02-ftn4a) A machine’s domain name and external IP\naddress—the outer-facing address of machines connected to the internet—can\nreveal the name of the organization or company that owns the infected machine,\nbased on who owns the block of IP addresses in which the machine’s address\nfalls. This could help the attackers determine how fast and far Stuxnet\nspread. This information would also have told the attackers when Stuxnet\ntraveled way off track as it began to show up in geographical regions far from\nits target. Internal IP addresses, on the other hand, are addresses that\ncompanies assign internally to machines to map them and route traffic between\nthem. These IP addresses can be useful if the attackers possessed a map of the\ninfected company or organization’s internal network, perhaps stolen from a\nsystem administrator’s computer, which indicated the internal IP address\nassigned to each machine on the network. If this was the case, the attackers\ncould have tracked Stuxnet’s path as it slithered inside a network infecting\nmachine after machine, reporting back to the command-and-control servers each\ntime it infected one that was connected to the internet. As for the computer\nname, it could have helped the attackers identify which employee or work group\ninside an organization owned the machines that were infected. One machine, for\nexample, was named GORJI-259E4B69A, another was PEYMAN-PC. But many of the\ninfected systems shared the same generic name: “ADMIN-PC,” “USER-PC,” or “home\nlaptop,” making it difficult to distinguish between them.\n\n[5](part0006.html#c02-ftn5a) Alex Gostev, chief malware expert at Kaspersky\nLab in Russia, found that Stuxnet sent to the command servers a file—named\nOem6c.pnf—that identified not only which Siemens program was installed on the\ncomputer (the Siemens Step 7 programming software or the WinCC program, which\noperators use to monitor conditions on their PLCs) but also included a list of\nany Step 7 project files on the machine and the path string that showed where\non the computer the files were located. The Step 7 project files contain the\nprogramming commands for PLCs. Gostev suspects that anytime the attackers\nfound project files on a machine, they may have sent a separate tool to the\ncomputer to steal the files and examine them for configuration data to\ndetermine if Stuxnet had found the systems it was seeking.\n\n[6](part0006.html#c02-ftn6a) The DNS providers had already dead-lettered the\ntraffic to the two domains so that it was going nowhere when Symantec\napproached them. They had pointed the traffic to the IP address 127.0.01,\nwhich is commonly used to return traffic to the sender’s machine.\n\n[7](part0006.html#c02-ftn7a) The 100,000 figure is the number that Symantec\ntracked during the first six months after Stuxnet was discovered. But the\ntotal number of infections, based on figures that other antivirus companies\ncompiled as they added detection to their tools, eventually climbed to more\nthan 300,000, according to Kaspersky Lab.\n\n[8](part0006.html#c02-ftn8a) At a US Senate hearing in November 2010, Dean\nTurner, director of Symantec’s global intelligence network, testified that the\nnumber of unique infections in the United States had by then reached 1,600. Of\nthese, 50 machines had the Siemens WinCC software installed on them.\n\n\n# CHAPTER 3\n\n# **NATANZ**\n\nWhile Chien and O’Murchu contemplated their new role in international\npolitics, thousands of miles away in Iran, technicians at Natanz were still\nstruggling over problems with their centrifuges. Though about 1,000 of the\ndevices had been replaced months earlier, the cascades were only operating at\n45 to 66 percent capacity, being fed much less uranium gas than they were\ncapable of enriching. It was unclear to IAEA inspectors whether the problems\nwere due to the natural growing pains that come with raising a new plant to\nmaturity—Natanz began enriching uranium in 2007, but technicians were still\ninstalling new cascades and working out the kinks—or if something sinister was\nat play. The latter wouldn’t have been a surprise. Natanz was the focus of\nintense international scrutiny, and it was no secret that there were many who\nwould do anything to shut it down. In fact, they’d been trying to do so for\nnearly a decade.\n\nTHE ANCIENT TOWN of Natanz is located about two hundred miles south of Tehran\nand is home to the shrine of the thirteenth-century Sufi sheik Abd Al-Samad\nEsfahani, a model of early Persian architecture with elegant terracotta bricks\nand intricately patterned cobalt tiles. Although it sits on the edge of the\nDasht-e Kavir Desert in the shadow of the Karkas Mountains, the elevated\ngarden town has an invigorating mountain climate and is filled with natural\nsprings. It has long been known for its fertile orchards in general, and its\nsucculent pears in particular. But on August 14, 2002, it became known for\nsomething else. That’s the day the National Council of Resistance of Iran\n(NCRI), a coalition of Iranian opposition groups in exile, convened a press\nconference at the Willard InterContinental Hotel in Washington, DC, two blocks\nfrom the White House, to announce that Iran was building an illicit nuclear\nfacility near Natanz.\n\nAbout two dozen reporters and representatives from NGOs, think tanks, and Iran\nwatch groups filed into the Taft Room on the hotel’s second floor to hear what\nthe group had to say. Among them was a twenty-nine-year-old blond woman named\nCorey Hinderstein who worked for the Institute for Science and International\nSecurity (ISIS), a nonprofit nuclear nonproliferation group that tracked\nnuclear activities in Iran and elsewhere.\n\nAs guests sat down and a cameraman for C-SPAN took up position in the back of\nthe room, Alireza Jafarzadeh, spokesman for the group, wasted no time getting\nto his point. “Although on the surface, [Iran’s] main nuclear activity\nrevolves around [the] Bushehr nuclear plant …” he said into the bank of\nmicrophones, “in reality, many secret nuclear programs are at work without any\nknowledge of [the] International Atomic Energy Agency.… Today, I am going to\nreveal to you two top-secret sites of the Iranian regime that they have\nsucceeded to keep secret until today.”[1](part0007.html#c03-ftn1)\n\nHinderstein and others shifted to attention.\n\nIran’s nuclear power reactor at Bushehr, an ancient coastal city overlooking\nthe Persian Gulf, had been under construction on and off for thirty years. It\nwas one of three sites that Iran had identified as nuclear facilities under\nits safeguards agreement with the IAEA, the UN agency that tracks nuclear\nactivities around the world to make sure that countries like Iran don’t use\ncivilian nuclear facilities for covert nuclear weapons production.\n\nFor years Iran had insisted that its program at Bushehr, which was expected to\nbe operational in 2005, was entirely peaceful in\nnature.[2](part0007.html#c03-ftn2) But there had long been rumors of secret\nnuclear facilities in Iran, including a covert uranium enrichment plant that\nmight be used to create material for nuclear weapons. In 2001, US and foreign\ngovernment sources had told Hinderstein’s colleagues at ISIS that secret\nnuclear sites did exist in Iran, but provided no details that would help them\ninvestigate. Now it seemed that Jafarzadeh’s ragtag group of dissidents might\nfinally offer the proof that ISIS, and others, had been seeking.\n\nJafarzadeh, a thick dark mustache covering his upper lip, revealed the names\nof the two nuclear facilities, both of which were far north of Bushehr. One\nwas a heavy-water production plant being built on the banks of the Qara-Chai\nRiver near Arak. “Anybody who has any kind of nuclear plans for nuclear\nweapons, they would definitely want to have heavy-water projects,” he\nsaid.[3](part0007.html#c03-ftn3)\n\nThe other was a nuclear fuel manufacturing plant being built near an old\nhighway that linked the town of Natanz to the town of Kashan. It was a joint\noperation of Iran’s Atomic Energy Organization (AEOI) and its Supreme National\nSecurity Council. To hide the plant’s true purpose, however, front companies\nhad been established to secretly procure materials and technology for it. One\nof these was a company called Kala Electric (also known as Kalaye Electric\nCompany), which would later factor into Stuxnet as one of the companies\nbelieved to have been infected by the digital\nweapon.[4](part0007.html#c03-ftn4)\n\nConstruction on the Natanz complex, which Jafarzadeh said covered 100,000\nsquare meters of land and had cost $300 million already, began in 2000 and was\nexpected to be completed in three months, at which point workers would begin\nto install equipment. The cover story for the plant was that it was a desert-\neradication project. But if this was true, then it was an extremely important\ndesert-eradication project, because a former prime minister of Iran had toured\nthe site earlier that month as a representative of the Supreme National\nSecurity Council, and the head of the AEOI made monthly visits to nearby\nKashan just to keep tabs on the project. Workers at the plant also were not\nallowed to discuss the project with local officials. A major argument had in\nfact recently broken out between the AEOI and the Kashan Governor’s Office\nbecause the AEOI would not discuss information about the site with the office,\nJafarzadeh said. And when the deputy governor general of the province tried to\nvisit the construction site at Natanz, he was turned away.\n\nAs Jafarzadeh rattled off details about the site and pointed to poster boards\nat the front of the room showing the network of front companies and\nindividuals who were running the project, Hinderstein scribbled away in her\nnotebook. With the general location of facilities cited, as well as the names\nand addresses of front companies revealed, it was the first solid evidence\nISIS had received about Iran’s illicit nuclear program that might be\nindependently verified.\n\nThe timing of the revelations wasn’t lost on Hinderstein. Iran was a signatory\nto the Treaty on the Nonproliferation of Nuclear Weapons, and under its\nsafeguards agreement with the IAEA it was obligated to disclose the existence\nof any new nuclear facility 180 days before introducing nuclear material to\nthe site so that inspectors could begin monitoring it. If the Natanz plant was\nindeed ninety days away from completion, then Jafarzadeh’s group had exposed\nit just in time for IAEA inspectors to demand access to it before it opened.\n\nAll of this raised obvious questions about how the NCRI got their hands on\ntop-secret intelligence that had seemingly eluded the world’s top spy agencies\nfor years. Jafarzadeh insisted that his group obtained the information from\npeople inside Iran who were directly associated with the program, as well as\nthrough extensive research and investigation by his group. But more likely it\nhad come from US or Israeli intelligence agencies.[5](part0007.html#c03-ftn5)\nIsrael had a history of leaking intelligence by proxy in order to sway public\nopinion without tainting the intelligence with its own political agenda.\nIsrael was naturally the country with the most to fear from a nuclear-armed\nIran, but it had obvious integrity issues when it came to calling out the\nnuclear activities of other nations, since it had long maintained its own\ncovert nuclear weapons program, which it has never publicly\nacknowledged.[6](part0007.html#c03-ftn6) For this and other reasons, it\nconducted its political machinations behind the scenes by feeding intelligence\nto Western governments, the IAEA, and groups like Jafarzadeh’s.\n\nIf the information did come from the United States or Israel, Jafarzadeh’s\ngroup was an odd choice to leak it. The NCRI was the political arm of the\nMujahedin-e Khalq, or MEK, an Iranian opposition group once known for its\nanti-Israel and anti-US stance. It was accused of killing six Americans in\nIran in the 1970s as well as setting off bombs in Iran in 1981 that killed\nmore than 70 people, including the Iranian president and prime minister. The\ngroup had been on the US State Department’s list of terrorist organizations\nsince 1997 but had been trying to rehabilitate its image to get off the list\never since. Helping to expose secret nuclear facilities in Iran would no doubt\nearn it support in Congress to achieve that aim.[7](part0007.html#c03-ftn7)\n\nThe NCRI had made provocative claims about Iran’s nuclear program in the past,\nbut some of them had proved to be false. There were questions about the\naccuracy of this new information as well. Jafarzadeh had identified the Natanz\nfacility as a fuel-manufacturing plant, but this didn’t make sense to\nHinderstein and her colleagues at ISIS. Iran was already planning to build a\nfuel-manufacturing plant not far from Natanz, so it didn’t seem logical to\nbuild a second one so close. Nonetheless, they were willing for now to accept\nthe revelations as true. To help verify them, however, Hinderstein decided to\nseek out satellite images to see if she could spot evidence of construction\nthat matched Jafarzadeh’s description.\n\nHinderstein had been with ISIS for six years—she’d come to the job straight\nout of college—and over time had become its resident expert on satellite\nimagery, an emerging tool that only recently had become available to groups\nlike hers. For decades, satellite imagery, particularly high-resolution\nimages, had been the sole domain of governments and intelligence agencies. The\nonly time anyone else could see pictures from space was if a government agency\nor research institute decided to release them, which rarely occurred. Images\nonly became available for the public to buy in the mid-1990s, but these\nweren’t very sharp. It wasn’t until several years later that images at\n1.6-meter resolution—the resolution at which you could actually see details\nclearly—became available.\n\nISIS was one of the first nongovernmental organizations to invest in the\nexpensive software needed to analyze the images, recognizing early on the\nimportant role they could play in nonproliferation work. Hinderstein’s first\nexperience analyzing satellite images came in 1998, after Pakistan conducted\nsix underground nuclear tests in response to underground atomic detonations\nmade by India. Working with a satellite imagery expert, she learned how to\nidentify pixelated objects in the images and interpret shadows and gradations\nin order to decipher depth in the two-dimensional pictures.\n\nAbout two months after the press conference, armed with the details from\nJafarzadeh and extensive additional research, Hinderstein logged into their\naccount at Digital Globe, one of two commercial providers of satellite images\nin the United States, to scour the archive for available\nimages.[8](part0007.html#c03-ftn8) Today, satellites have imaged nearly every\npart of the Earth, with most pictures available to anyone via Google Earth.\nBut in 2002, the only way to find images in Digital Globe’s archive was if\nsomeone had already commissioned the company to photograph a site, or if\nDigital Globe had taken images of a location on its own initiative, such as\nNiagara Falls or the Grand Canyon—images the company knew would sell well. To\ncommission an image that wasn’t in the archive cost about $10,000, but once an\nimage existed, it became available for others to purchase at one-third the\nprice.\n\nThe Digital Globe interface that Hinderstein used looked like Google Maps,\nwith small gray boxes that popped up on-screen wherever satellite images were\navailable. But clicking on a gray box produced only a browsing image—a rough\nimage of 16-meter resolution, which meant that every pixel showed 16 meters of\nground. To see more detail, you had to buy the 1.6-meter version.\n\nHinderstein couldn’t believe her luck when she found images for both Arak and\nNatanz available in the archive. Jafarzadeh hadn’t provided exact coordinates\nfor either of the two sites, so Hinderstein had to first locate Arak on the\nDigital Globe map, then move slowly outward from the town, searching in\nconcentric circles until a gray box popped up. When she clicked on the image,\nit was clear this was a heavy-water production plant as Jafarzadeh described.\nISIS had identified such a plant in Pakistan a couple of years earlier, and\nthe site near Arak looked very similar.\n\nWhen she searched the region of Natanz, however, she found two possible\nlocations in the middle of the desert where images were available. At each of\nthe sites, three gray boxes stacked on top of each other popped up, indicating\nmultiple images were available for both sites. It was as if someone had left a\ngiant arrow directing her to them. The dates on the images indicated they had\nall been snapped September 16 and 26—weeks after Jafarzadeh’s press\nconference. It was clear that someone else had been seeking the same\ninformation that she was seeking. Hinderstein suspected it was the IAEA. The\nIAEA had established a satellite imagery analysis lab of its own the previous\nyear, and it would have made sense for the agency to commission images after\nJafarzadeh’s revelations.[9](part0007.html#c03-ftn9)\n\nHinderstein clicked on the gray boxes at one of the sites and quickly\neliminated it as the nuclear facility. It was nowhere near the 100,000 square\nmeters Jafarzadeh described and looked more like a water-purification or\nsewage plant than anything to do with nuclear fuel. The other site, however,\nwas more suspect. It was much larger than the first and showed obvious signs\nof massive, ongoing excavation. Despite the blurry 16-meter image, Hinderstein\ncould make out what looked to be a collection of buildings and large mounds of\nchurned earth inside two layers of security fences. She also noted a single\nroad leading out to the site, suggesting the area had restricted access.\n\nAfter she purchased and loaded the 1.6-meter image into their viewing tool,\nshe could see numerous pipes laid out on the ground as well as large piles of\ngravel for mixing concrete. There was also a traffic roundabout that had\nalready been partially paved. But as she studied the image more closely, she\nnoticed something odd. Jafarzadeh had said the site was a fuel-manufacturing\nplant, but fuel-manufacturing was a very industrial process and tended to\ninvolve aboveground facilities with large smokestacks. There were no\nsmokestacks at the Natanz site, however, and what’s more, there were three\nlarge buildings that were being built deep underground, with a tunnel\nconnecting them. The buildings were in the final stage of construction. She\ncould also make out what appeared to be a series of circles around the\nperimeter of the site, suggesting the future location of anti-aircraft guns.\n\nThe images had been captured at just the right time to catch Iranian workers\nstill in the process of covering the rooftops of the underground buildings\nwith several alternating layers of earth and cement. A few weeks later and\nthey would have been completely obscured from above, yielding no obvious sign\nof their existence. Someone had carefully planned the outing of Natanz at just\nthe right moment to capture the evidence.\n\nTwo of the underground buildings were each about the size of half a dozen\nfootball fields and were heavily reinforced with concrete walls about six to\neight feet thick. The Iranians were obviously fortifying them against a\npossible air strike. The tunnel leading down to the buildings was also built\nin the shape of a U instead of a straight line—a common tactic to prevent\nmissiles sent into the mouth of a tunnel from having direct aim at a target on\nthe other end.\n\nHinderstein showed the images to her boss, David Albright, a physicist and\nformer weapons inspector in Iraq who founded ISIS. The two were certain now\nthat this wasn’t a fuel-manufacturing plant. Iran would have no reason to\nbuild such a plant underground, since there would be little interest in\nbombing it. The only logical conclusion, they reasoned—one that would explain\nthe underground construction and the evidential plans for antiaircraft\nguns—was that this was the elusive uranium enrichment plant they had been\nseeking.\n\nIT WAS A quiet day in Vienna when news from Jafarzadeh’s press conference\nfiltered back to Olli Heinonen in the IAEA’s headquarters overlooking the\nDanube River. During August, most of Europe was on holiday, and Vienna was no\nexception. Heinonen’s boss, Dr. Mohamed ElBaradei, the IAEA’s director\ngeneral, was on vacation in Egypt, and much of the organization’s other staff\nmembers were out of town as well. So Heinonen, a Finn in his early fifties\nwith wire-framed glasses and a boyish mop of reddish-brown hair, was alone in\nhis office when he read the news. Heinonen was head of Division B of the\nIAEA’s Safeguards Department and had only three months before he was taken on\nthe IAEA’s Iran portfolio after having been the agency’s chief inspector of\nNorth Korea and other parts of Asia for several years. It was a return to\nfamiliar territory for him, since he’d managed the IAEA’s Iran portfolio\nbefore from 1992 to 1995. A Persian rug marking the period still decorated the\nfloor of his office.\n\nA veteran nuclear inspector, Heinonen had come to the IAEA in 1983 from a\nnuclear research center in Finland. With a PhD in radiochemistry from the\nUniversity of Helsinki, he had a higher level of subject expertise than early\ngenerations of IAEA inspectors, who tended to have little scientific training.\nHe also had a reputation for quiet confidence and steadfast determination that\nmade it clear to the nations he inspected that he had little patience for\nduplicity.\n\nAs he took in the news from Jafarzadeh, he was struck by the level of detail\nit revealed. Heinonen had been waiting for information like this for a while.\nLike his counterparts at ISIS, he immediately suspected the Natanz facility\nwasn’t a fuel-manufacturing plant at all but a uranium enrichment plant. Two\nyears earlier, government sources had told the IAEA that Iran tried to\nsecretly purchase parts from Europe in the 1980s to manufacture centrifuges\nfor uranium enrichment.[10](part0007.html#c03-ftn10) Based on this, Heinonen\nhad suspected that Iran had an illicit centrifuge plant hidden somewhere\nwithin its borders, but he never knew its location, and the IAEA couldn’t\nconfront the Iranians without exposing the source of the intelligence. The\nIAEA had also been wary of acting on information received from government\nsources, ever since an intelligence agency had told the IAEA in 1992 that Iran\nwas secretly procuring prohibited nuclear equipment but hadn’t provided any\ndetails. When the IAEA confronted Iran about the claims, officials denied the\naccusations and invited inspectors to visit their nuclear sites to see for\nthemselves. But the inspectors found nothing to support the claims and ended\nup leaving Iran embarrassed.[11](part0007.html#c03-ftn11)\n\nThe revelations this time, however, were different. They had been publicly\ndisclosed, so Heinonen didn’t have to hide the source of the information, and\nthey included precise and specific details, naming actual facilities and\nlocations. This meant the IAEA could independently verify their existence and\ndemand that Iran open them to inspection.[12](part0007.html#c03-ftn12)\n\nHeinonen picked up the phone and called his boss in Egypt, who agreed that he\nshould send a letter immediately to Ali Akhbar Salehi, the Iranian ambassador\nto the IAEA, demanding an explanation about what Iran was doing at Natanz.\nSalehi was outraged by the letter’s accusatory tone, saying the IAEA had no\nbusiness questioning Iran about unverified claims, especially ones that came\nfrom a known terrorist group. Gholam Reza Aghazadeh, Iran’s vice president and\nhead of its Atomic Energy Organization, told the IAEA that Iran had not been\nhiding Natanz, but had simply planned to disclose its existence to the IAEA at\na later date.[13](part0007.html#c03-ftn13) If the IAEA was patient, all would\nsoon be revealed, he said. For now he would only say that Iran planned to\nbuild several nuclear power plants over the next twenty years and needed\nnuclear fuel to operate them. He didn’t say if Natanz was a uranium enrichment\nplant being built to help produce such fuel, but this appeared to be the\nimplication.\n\nThe IAEA pressed Iran to open Natanz immediately to its inspectors, and after\na bit of back and forth Iranian officials reluctantly agreed to a date in\nOctober. But just as the IAEA was preparing for the trip, Iran canceled the\nvisit, saying the date would not work. A second visit was scheduled for\nDecember, but that too got canceled. Heinonen suspected Iran was trying to buy\ntime to move incriminating evidence out of Natanz.\n\nWhen ISIS founder David Albright learned that Iran was stalling, he decided to\ntake the satellite images to the media to pressure Iran into opening Natanz to\ninspectors. It was one thing for Iran to rebuff claims made by an opposition\ngroup with a political agenda. It was another to respond to stark images of\nsecret sites broadcast worldwide on CNN. So on December 12, CNN ran a story,\nalong with the satellite images provided by ISIS, saying that Iran was\nbelieved to be building a secret enrichment plant at Natanz that might be used\nto produce fissile material for nuclear weapons. Iran’s ambassador to the\nUnited Nations denied that Iran had a nuclear weapons program and told CNN\nthat “any satellite photographs of any facility that you may have” were for a\npeaceful nuclear energy program, not a weapons\nprogram.[14](part0007.html#c03-ftn14)\n\nThe images had the desired effect, however: after the CNN story ran, Iranian\nofficials committed to an inspection date in February.\n\nALTHOUGH THE NATANZ facility was new, Iran’s nuclear activities actually went\nback more than forty years. They had their roots in the regime of the former\nshah, Mohammad Reza Pahlavi, during a time when the United States and other\nWestern nations fully supported Iran’s nuclear aspirations.\n\nIran launched its public and approved nuclear program in 1957, more than a\ndecade after the United States detonated the first atomic bombs over Japan. It\nwas during a time when other nations were clamoring to join the exclusive\nnuclear club the United States had founded. In an effort to redirect the\nnuclear ambitions of these nations, the Eisenhower administration promoted\nwhat it called the Atoms for Peace program, whereby countries would receive\nhelp to develop nuclear technology as long as they used it for peaceful\npurposes only. As part of the program, Iran signed an agreement with the\nUnited States to receive help to build a light-water nuclear research reactor\nat Tehran University. The United States also agreed to supply enriched uranium\nto fuel it.[15](part0007.html#c03-ftn15)\n\nBut despite US efforts to limit the development of nuclear weapons, four other\nnations pushed their way into the elite nuclear club after the war—the Soviet\nUnion, Great Britain, France, and China. To curb the proliferation madness,\nthe Treaty on the Nonproliferation of Nuclear Weapons was developed in the\n1960s to prevent more countries from following suit and to work on reducing\nthe weapons that nuclear-armed nations already\npossessed.[16](part0007.html#c03-ftn16)\n\nUnder the treaty, which divided the world into nuclear haves and have-nots,\nthe nonweapons nations would be given aid to develop civilian nuclear programs\nas long as they agreed to foreswear building nuclear weapons and similarly\nagreed to regular inspections by the IAEA to ensure that materials and\nequipment intended for the civilian programs were not diverted for nuclear\nweapons development. The problem with this arrangement, however, was that many\nof the components and facilities for civilian nuclear programs were dual-use\nand could also be used for a nuclear weapons program, making it difficult to\npolice a country’s operations. As Hannes Alfvén, a Swedish Nobel laureate in\nphysics once said, “Atoms for peace and atoms for war are Siamese twins.”\n\nIran was one of the first countries to sign the treaty in 1968, and by 1974 it\nhad established its own Atomic Energy Organization and developed a grand\nscheme to build twenty nuclear reactors with support from Germany, the United\nStates, and France, who all stood to gain from the sale of equipment to the\nshah’s regime. The first two reactors were to be built at Bushehr. In 1975,\nGerman engineers with the Siemens subsidiary Kraftwerk Union broke ground on\nthe $4.3 billion construction project, which was slated to be completed in\n1981.[17](part0007.html#c03-ftn17)\n\nThere were concerns at the time that Iran’s endgame might be nuclear weapons.\nThe shah himself hinted at one point that his nuclear aims weren’t solely\npeaceful in nature, asserting in an interview that Iran would get nuclear\nweapons “without a doubt … sooner than one would think” if conditions in the\nMiddle East made it necessary.[18](part0007.html#c03-ftn18) But US leaders\nweren’t worried, because they considered the shah a friend and couldn’t seem\nto fathom a day when he or his regime wouldn’t be in\npower.[19](part0007.html#c03-ftn19)\n\nThat day came pretty quickly, however, when the Islamic Revolution erupted in\n1979 just as one of the reactor buildings at Bushehr was nearing completion.\nThe revolutionaries who ousted the shah and seized power with the Ayatollah\nRuhollah Khomeini took a narrow view of the behemoth reactors being erected at\nBushehr, considering them a symbol of the shah’s alliance with the West. The\nUnited States, alarmed by the unstable political situation, withdrew support\nfor the project, and the German government eventually forced Kraftwerk Union\nto pull out of its contract for Bushehr.[20](part0007.html#c03-ftn20)\n\nThe subsequent Iran–Iraq war wasn’t kind to the abandoned reactors. Throughout\nthe eight-year war, which ran from 1980 to 1988, Iraq bombed the two towers\nmore than half a dozen times, leaving them in\nruins.[21](part0007.html#c03-ftn21) During the war, the commander of Iran’s\nRevolutionary Guard urged the Ayatollah Khomeini to launch a nuclear weapons\nprogram to fend off Iraq and its Western allies. But Khomeini refused,\nbelieving that nuclear weapons were anathema to Islam and a violation of its\nbasic moral principles. He apparently changed his mind, however, after Saddam\nHussein unleashed chemical weapons on Iranian troops and civilians, killing\nabout 25,000 and injuring more than 100,000 others. Incensed by the UN’s\npassive reaction, and alarmed at rumors that Iraq was seeking to build nuclear\nweapons of its own, Khomeini decided to revive Iran’s nuclear program. This\nincluded developing a uranium enrichment program.[22](part0007.html#c03-ftn22)\n\nTo launch the program, Iran turned to a Pakistani metallurgist named Abdul\nQadeer Khan for help. Khan had been instrumental in helping Pakistan build its\nnuclear weapons program in the mid-1970s, using centrifuge technology he had\nstolen from Europe. Khan had worked for a Dutch company that conducted\ncentrifuge research and development for Urenco, a consortium formed by\nGermany, Great Britain, and the Netherlands to develop centrifuges for nuclear\npower plants in Europe. As part of his job, Khan had access to sensitive\ncentrifuge designs that he copied and took back to Pakistan. He also absconded\nwith lists of suppliers, many of whom were willing to secretly sell Pakistan\nparts and materials to make the centrifuges for its program.\n\nCentrifuges are metal cylinders with rotors inside that can spin at speeds in\nexcess of 100,000 revolutions per minute to enrich uranium hexafluoride gas,\nproduced from uranium ore found in earth and seawater. The hexafluoride gas is\npiped into “cascades” of centrifuges—groups of centrifuges connected by pipes\nand valves. And as the rotors inside them spin, the centrifugal force\nseparates the slightly lighter U-235 isotopes in the gas—the fissile isotopes\nneeded for atomic energy—from the heavier U-238 isotopes, in a process likened\nto panning for gold.[23](part0007.html#c03-ftn23) Gas containing the heavier\nisotopes gets pushed to the outer wall, while gas containing lighter isotopes\ngathers closer to the center. Coils wrapped around the outside of the\ncentrifuge that are filled with heated water create a varying temperature that\nsets the gas in vertical motion, in an oval pattern along the wall of the\ncentrifuge, to further separate the isotopes. Scoops divert the gas containing\nthe concentration of lighter isotopes into other centrifuges at a “higher”\nstage in the cascade, where further separation occurs, while the heavier gas,\nthe depleted uranium, is diverted into a second set of centrifuges in a lower\nstage of the cascade for further separation. When additional U-235 isotopes\nare separated from this gas, it gets fed back into the higher stages to be\nrecombined with the other U-235 isotopes while the depleted gas is sent to\n“waste”—that is, the tail end of the cascade, where it gets discarded. This\nprocess gets repeated until gas containing the desired concentration of U-235\nisotopes is achieved.[24](part0007.html#c03-ftn24)\n\nIn 1987, after Iran revived its nuclear program, officials there contacted a\nGerman engineer-turned-black-marketeer, who was a key supplier of equipment\nfor Pakistan’s illicit nuclear program. He helped arrange a secret meeting in\nDubai between Iranian officials and other members of the Khan supply network.\nIn exchange for $10 million, the Iranians walked away with two large suitcases\nand two briefcases filled with everything they needed to kick-start a uranium\nenrichment program—technical designs for making centrifuges, a couple of\ndisassembled centrifuge prototypes, and a drawing for the layout of a small\ncentrifuge plant containing six cascades.[25](part0007.html#c03-ftn25)\nApparently as a bonus, the marketeers threw in a fifteen-page document\ndescribing how to turn enriched uranium into uranium metal and cast it into\n“hemispheres,” the core component of nuclear\nbombs.[26](part0007.html#c03-ftn26) Khan later told Pakistani television that\nhe helped Iran develop its nuclear program because he thought if both Pakistan\nand Iran became nuclear powers, they would “neutralize Israel’s power” in the\nregion.[27](part0007.html#c03-ftn27)\n\nThe disassembled centrifuges the Iranians received were based on one of the\ndesigns Khan stole from Urenco. In Pakistan the centrifuge was known as a P-1,\nbut in Iran it became known as the IR-1. Initially, Iran lacked money to do\nmuch of anything with the designs, but in 1988, after the Iran–Iraq war ended\nand its resources were freed up, the country began pouring money into an\nenrichment program, buying high-strength aluminum and other materials to build\nits own centrifuges, and secretly importing nearly two tons of natural\nuranium—including uranium hexafluoride gas—from\nChina.[28](part0007.html#c03-ftn28)\n\nKhan later secretly gave Iran components for five hundred P-1 centrifuges, as\nwell as instructions for setting up a quality-assurance program for making and\ntesting the centrifuges. The latter was badly needed because Iran was having\ntrouble with the centrifuges it had created from Pakistan’s prototypes.\nSometimes they spun out of control and crashed; other times they didn’t work\nat all.[29](part0007.html#c03-ftn29) By 1994, Iran had succeeded in operating\nonly one centrifuge successfully at “nearly full\nspeed.”[30](part0007.html#c03-ftn30)\n\nAs a result, the Iranians accused Khan of selling them a bill of goods. So in\n1996, he handed over drawings for Pakistan’s P-2 centrifuge, a more advanced\ncentrifuge based on another design stolen from\nUrenco.[31](part0007.html#c03-ftn31) The P-2 was much more efficient than the\nIR-1 and could enrich about two and a half times the amount of uranium in the\nsame amount of time. It also used a rotor made from maraging steel—a more\nresilient material than the breakage-prone aluminum rotors in the IR-1.\n\nWhile Iran was busy developing its secret uranium enrichment program, its\npublic nuclear program continued in parallel. In 1995, the country signed an\n$800 million contract with Russia to resume construction of a reactor at\nBushehr. The two countries also discussed building a uranium enrichment plant\nto produce fuel for the reactor, but the Clinton administration intervened and\nconvinced Russia to drop it. So Iran simply built a secret enrichment plant on\nits own.[32](part0007.html#c03-ftn32)\n\nAround this time, Europe began tightening export controls on dual-use\nequipment and components. The controls didn’t deter Iran, however; they just\nforced its covert program further underground. To protect research and\nproduction facilities from being discovered, officials began spreading the\nwork out among various sites around the country, some of them on protected\nmilitary grounds, others hidden in plain sight in unassuming offices and\nwarehouses. As part of this effort, it moved its centrifuge-manufacturing\noperations out of the Tehran Nuclear Research Center, where it had been\nlaunched, and into factories that once belonged to the Kalaye Electric\nCompany, a former watch factory in an industrial part of Tehran that the\nAtomic Energy Organization had purchased as a front operation. It was the same\ncompany that Jafarzadeh would later mention at his press conference in 2002.\n\nSometime around 1999, Iran conducted its first successful enrichment tests at\nthe Kalaye factory using small cascades of centrifuges and some of the uranium\nhexafluoride gas purchased from China.[33](part0007.html#c03-ftn33) It was a\nmajor breakthrough, proving once and for all the viability of a program that\nhad taken a decade to develop. Officials with Iran’s Atomic Energy\nOrganization went full tilt at this point, ordering workers to begin large-\nscale production of 10,000 centrifuges for a sprawling enrichment plant they\nplanned to build at Natanz. At the same time, they began ramping up\nprocurement efforts to obtain parts and materials in Europe and\nelsewhere.[34](part0007.html#c03-ftn34) Sometime in 2000, workers broke ground\non the complex at Natanz, and Iran was on its way to becoming a nuclear\nnation.\n\n* * *\n\n[1](part0007.html#c03-ftn1a) Alireza Jafarzadeh’s speech is available in\nC-SPAN’s library at:\n[c-spanvideo.org/program/172005-1](http://www.c-spanvideo.org/program/172005-1).\nA nonofficial transcript of his comments is also available at:\n[iranwatch.org/privateviews/NCRI/perspex-ncri-\ntopsecretprojects-081402.htm](http://www.iranwatch.org/privateviews/NCRI/perspex-\nncri-topsecretprojects-081402.htm).\n\n[2](part0007.html#c03-ftn2a) Although nuclear nonproliferation specialists\nweren’t too concerned about plutonium from the light-water reactor at Bushehr\nbeing used to create nuclear weapons, because the material wasn’t ideal for\nthat purpose, there were other concerns related to the reactor. Deputy\nAssistant Secretary of Defense Marshall Billingslea told the Senate on July\n29, 2002, that there were concerns that Bushehr was “a pretext for the\ncreation of an infrastructure designed to help Tehran acquire atomic\nweapons”—meaning that materials acquired for Bushehr might be used for secret\nnuclear activites instead.\n\n[3](part0007.html#c03-ftn3a) Heavy water is water with a high amount of the\nhydrogen isotope deuterium. Heavy water has nonweapons applications as a\ncoolant and moderator in power plants and in research reactors for the\nproduction of medical isotopes. But spent fuel from such plants contains\nplutonium and other materials that, when reprocessed, can be used for nuclear\nweapons. Heavy-water reactors are a better source of plutonium than light-\nwater reactors like Bushehr.\n\n[4](part0007.html#c03-ftn4a) For more information, see [this\npage](part0010.html#page97).\n\n[5](part0007.html#c03-ftn5a) Jafarzadeh said the NCRI received the\nintelligence just days before the press conference and that it came from\nmembers of the resistance inside Iran. “These are people who were directly\nassociated or involved with this, [and] had access to information directly\nabout these kinds of activities,” he told reporters in the room. “Certainly,\nthese are people who have access to this information within the regime.” Asked\nif his group had shared the intelligence with US authorities, Jafarzadeh\nparsed his words carefully. The data “have been prov …,” he started to say,\n“have been available to the proper authorities in this country. I’m not aware\nof their reaction yet.” Two years later, CIA Director George Tenet said about\nthese and other revelations from the NCRI, “I want to assure you that recent\nIranian admissions about their nuclear programs validate our intelligence\nassessments. It is flat wrong to say that we were ‘surprised’ by reports from\nthe Iranian opposition last year.” He was speaking at Georgetown University on\nFebruary 5, 2004. A transcript of his talk is available at:\n<https://www.cia.gov/news-information/speeches-\ntestimony/2004/tenet_georgetownspeech_02052004.html>.\n\n[6](part0007.html#c03-ftn6a) Israel secretly joined the ranks of nuclear\npowers in 1967.\n\n[7](part0007.html#c03-ftn7a) The NCRI’s lobbying campaign worked. With the aid\nand support of a number of US lawmakers, as well as former leaders of the FBI\nand CIA, the group got its name removed from the terrorist list in 2012.\nSupporters called the group a loyal ally of the United States and cited its\nrole in helping expose Iran’s covert nuclear program as one of the reasons to\nremove it from the list.\n\n[8](part0007.html#c03-ftn8a) The other company was GeoEye.\n\n[9](part0007.html#c03-ftn9a) An IAEA source confirmed to me that the agency\ndid commission the images.\n\n[10](part0007.html#c03-ftn10a) David Albright, _Peddling Peril: How the Secret\nNuclear Trade Arms America’s Enemies_ (New York: Free Press, 2010), 187.\n\n[11](part0007.html#c03-ftn11a) Author interview with Heinonen in June 2011.\n\n[12](part0007.html#c03-ftn12a) There are differing reports about what the IAEA\nknew when. According to Mark Hibbs, a former leading journalist on nuclear\nissues who is now a policy analyst, about two months before the NCRI’s press\nconference, the United States gave the IAEA coordinates for the suspect sites\nin Iran, which the United States had been tracking since at least the\nbeginning of 2002 (Hibbs, “US Briefed Suppliers Group in October on Suspected\nIranian Enrichment Plant,” _Nuclear Fuel_ , December 23, 2001). David Albright\nof ISIS says, however, that although US sources gave the IAEA coordinates for\nsites, they didn’t say that the Natanz site was a uranium enrichment plant.\nMohamed ElBaradei, in his book _The Age of Deception_ , acknowledges that in\nmid-2002 the IAEA received information about the Natanz facility, but doesn’t\nsay if the IAEA knew it was a uranium enrichment plant.\n\n[13](part0007.html#c03-ftn13a) Iranian officials would later say that the only\nreason they had concealed their activities at Natanz was because the West had\ntried to thwart their efforts to build a civilian nuclear program.\n\n[14](part0007.html#c03-ftn14a) A transcript of the CNN piece is available at\n<http://transcripts.cnn.com/TRANSCRIPTS/0212/13/lol.07.html>.\n\n[15](part0007.html#c03-ftn15a) Digital National Security Archive, “US Supplied\nNuclear Material to Iran,” January 29, 1980, available at\n[nsarchive.chadwyck.com](http://www.nsarchive.chadwyck.com) (registration\nrequired). See also Dieter Bednarz and Erich Follath, “The Threat Next Door: A\nVisit to Ahmadinejad’s Nuclear Laboratory,” _Spiegel Online_ , June 24, 2011,\navailable at [spiegel.de/international/world/the-threat-next-door-a-visit-to-\nahmadinejad-s-nuclear-\nlaboratory-a-770272.html](http://www.spiegel.de/international/world/the-\nthreat-next-door-a-visit-to-ahmadinejad-s-nuclear-laboratory-a-770272.html).\n\n[16](part0007.html#c03-ftn16a) Anne Hessing Cahn, “Determinants of the Nuclear\nOption: The Case of Iran,” in _Nuclear Proliferation in the Near-Nuclear\nCountries_ , eds. Onkar Marway and Ann Shulz (Cambridge: Ballinger Publishing\nCo., 1975), 186.\n\n[17](part0007.html#c03-ftn17a) Ali Vaez, “Waiting for Bushehr,” _Foreign\nPolicy_ , September 11, 2011.\n\n[18](part0007.html#c03-ftn18a) John K. Cooley, “More Fingers on Nuclear\nTrigger?” _Christian Science Monitor_ , June 25, 1974. Iranian officials later\ndenied that he made the statement.\n\n[19](part0007.html#c03-ftn19a) In fact, Iran discussed plans with Israel to\nadapt surface-to-surface missiles to fit them with nuclear warheads. See Paul\nMichaud, “Iran Opted for N-bomb Under Shah: Ex-Official,” _Dawn_ , September\n23, 2003. Also, according to Akbar Etemad, head of Iran’s Atomic Energy\nOrganization under the shah, he had been tasked with creating a special team\nto track the latest nuclear research so that Iran would be ready to build a\nbomb if and when it was necessary. He disclosed the information during an\ninterview with _Le Figaro_ in 2003, according to Elaine Sciolino, “The World’s\nNuclear Ambitions Aren’t New for Iran,” _New York Times_ , June 22, 2003.\n\n[20](part0007.html#c03-ftn20a) John Geddes, “German Concern Ends a Contract,”\n_New York Times_ , August 3, 1979. See also Judith Perera, “Nuclear Plants\nTake Root in the Desert,” _New Scientist_ , August 23, 1979.\n\n[21](part0007.html#c03-ftn21a) Vaez, “Waiting for Bushehr.”\n\n[22](part0007.html#c03-ftn22a) Institute for Science and International\nSecurity, “Excerpts from Internal IAEA Document on Alleged Iranian Nuclear\nWeaponization,” October 2, 2009. The ISIS report is based on an IAEA internal\ndocument titled “Possible Military Dimensions of Iran’s Nuclear Program,”\navailable at\n[isisnucleariran.org/assets/pdf/IAEA_info_3October2009.pdf](http://www.isisnucleariran.org/assets/pdf/IAEA_info_3October2009.pdf).\n\n[23](part0007.html#c03-ftn23a) The U-235 isotope has three fewer neutrons than\nthe U-238, which makes it lighter.\n\n[24](part0007.html#c03-ftn24a) Charles D. Ferguson, _Nuclear Energy: What\nEveryone Needs to Know_ (New York: Oxford University Press, 2011).\n\n[25](part0007.html#c03-ftn25a) Dennis Frantz and Catherine Collins, _The\nNuclear Jihadist: The True Story of the Man Who Sold the World’s Most\nDangerous Secrets_ (New York: Free Press, 2007), 156. The items were listed on\na handwritten document the IAEA obtained that was described in IAEA Board of\nGovernors, “Director General, Implementation of the NPT Safeguards Agreement\nin the Islamic Republic of Iran, GOV/2005/67” (report, September 2, 2005), 5.\n\n[26](part0007.html#c03-ftn26a) In November 2007, according to the IAEA Board\nof Governors, Iran gave the IAEA a copy of the fifteen-page document,\n“Implementation of the NPT Safeguards Agreement and relevant provisions of\nSecurity Council resolutions 1737 (2006) and 1747 (2007) in the Islamic\nRepublic of Iran” (report, February 22, 2008), 4. Iran claimed it had not\nrequested the document but received it unsolicited from the black marketeers.\n\n[27](part0007.html#c03-ftn27a) Erich Follath and Holger Stark, “The Birth of a\nBomb: A History of Iran’s Nuclear Ambitions,” _Der Spiegel_ , June 17, 2010.\n\n[28](part0007.html#c03-ftn28a) IAEA Board of Governors, “Implementation of the\nNPT Safeguards Agreement in the Islamic Republic of Iran” (report, November\n10, 2003), 5.\n\n[29](part0007.html#c03-ftn29a) In 1992, the former head of Iran’s Atomic\nEnergy Organization, Masud Naraghi, left Iran and provided the CIA with some\ninformation about Iran’s program. Naraghi had helped negotiate the deal in\n1987 between Iran and A. Q. Khan to obtain the first centrifuges for Iran’s\nenrichment program. He told the CIA, for example, that Iranian researchers\nwere having trouble with the IR-1 centrifuges that they were trying to build\nfrom Khan’s design. See Frantz and Collins, _Nuclear Jihadist_ , 202. See also\nAlbright, _Peddling Peril_ , 76–81.\n\n[30](part0007.html#c03-ftn30a) _Nuclear Jihadist_ , 213.\n\n[31](part0007.html#c03-ftn31a) IAEA Board of Governors, “Director General,\nImplementation of the NPT Safeguards Agreement” (report September 2, 2005), 5.\n\n[32](part0007.html#c03-ftn32a) It’s believed that designs for a separate\nuranium conversion plant at Esfahan—for converting milled uranium ore into\ngas—may have come from China. In 1997, the Clinton administration announced\nthat it had halted a deal that China had made to sell Iran a conversion\nfacility, but Iran still obtained blueprints for the plant from the Chinese.\nSee John Pomfret, “U.S. May Certify China on Curbing Nuclear Exports,”\n_Washington Post_ , September 18, 1997.\n\n[33](part0007.html#c03-ftn33a) Iran released the details of its nuclear\nhistory piecemeal over a number of years, and they were relayed in IAEA\nreports as the agency received them, beginning in 2004. The details from Iran,\nhowever, did not always jibe with information the IAEA and reporters received\nfrom other sources.\n\n[34](part0007.html#c03-ftn34a) Albright, _Peddling Peril_ , 185.\n\n\n# CHAPTER 4\n\n# **STUXNET DECONSTRUCTED**\n\nIn the first days after the news of Stuxnet broke, nearly a dozen Symantec\nresearchers on three continents were involved in the company’s initial\nanalysis of the code. But very quickly that dropped down to just three—Chien,\nO’Murchu, and Falliere—as other analysts fell away to focus on new threats\nthat were coming in. Now, nearly a week after Stuxnet had been exposed, the\nthree analysts were still picking apart the “missile” portion of the attack\nand hadn’t even begun to examine the payload yet.\n\nLike conventional weapons, most digital weapons have two parts—the missile, or\ndelivery system, responsible for spreading the malicious payload and\ninstalling it onto machines, and the payload itself, which performs the actual\nattack, such as stealing data or doing other things to infected machines. In\nthis case, the payload was the malicious code that targeted the Siemens\nsoftware and PLCs.\n\nWith so much work on Stuxnet still to be done, Chien had the task of\nconvincing his managers that he and his team should continue digging through\nthe code, even though it was already becoming yesterday’s news. Every\nWednesday, he had a video conference call with the company’s threat managers\naround the world to review all of the major infections they were investigating\nat the time and to talk about strategy. The first Wednesday after Stuxnet was\nexposed, the puzzling attack was at the top of their agenda.\n\nSymantec’s offices in Culver City occupy a large and airy building on a nine-\nacre business campus dotted with palm trees and desert shrubs. The modern,\nfive-story structure is a stark contrast to VirusBlokAda’s cramped Communist-\nera office, with a spacious, high-ceilinged atrium and large cement-tile\nfloors that clink like hollow glass when visitors walk on them, due to tunnels\nbeneath that house the building’s power and ventilation systems. The Symantec\noffice complex is LEED–gold certified for its environment-friendly\narchitecture, with solar-reflecting roof to ward off the relentless Southern\nCalifornia sun and a glass façade designed to give every occupant a view, or\nat least what passes for one in this uninspired neighborhood of shopping malls\nand freeways near the Los Angeles airport.\n\nThe videoconference room was a small, windowless space tucked into a forgotten\nneighborhood of the building’s third floor that was reached via a circuitous\nroute from the malware lab. Inside the room, three large video screens,\nmounted at eye level on a wall in front of a row of tables, made it appear as\nif the virtual visitors were seated directly across from Chien.\n\nChien laid out a summary of O’Murchu’s early findings for his managers—the\ncode’s abnormally large size, its sophisticated method for loading and hiding\nits files, and the mysterious payload that seemed to target only Siemens PLCs.\nHe also revealed the bizarre geographic pattern of the infection data pouring\ninto their sinkhole. The possible political implications of the attack,\nhowever, remained unspoken.\n\n“We want to put Nico on this full-time,” Chien then told his managers,\nreferring to Falliere in France. “And I think Liam and I should continue\nworking on it as well.” There was one catch, however. He had no idea how long\nit would take them to finish analyzing the code.\n\nTypically, the company’s research teams analyzed about twenty malicious files\na day, so devoting three top analysts to a single threat indefinitely didn’t\nmake any business sense. They’d done this only once before, with the Conficker\nworm in 2008. But Conficker was a shape-shifting worm that infected millions\nof machines around the world and left a lot of still-unanswered questions in\nits wake, including why the worm had been created in the first\nplace.[1](part0008.html#c04-ftn1) Stuxnet, by contrast, infected only a\nfraction of Conficker’s numbers and had a targeted focus on an even smaller\nsubset—the Siemens PLCs. Yet something about the mysterious code cried out for\nfurther investigation, and Chien’s managers agreed they shouldn’t drop it just\nyet. “But keep us posted on what you find,” they said, with little idea that\ntheir weekly meetings would be dominated by talk of Stuxnet for months to\ncome.\n\nChien and his colleagues seized the opportunity to dive into the code, taking\nit on as a personal obsession. But no sooner had they begun the operation than\nthey realized they were headed into uncharted territory with little help to\nguide them.\n\nSYMANTEC IS A large, international corporation, but Chien and O’Murchu worked\nout of a small satellite office, going at it primarily alone with little\ninput. They worked in Symantec’s Threat Intelligence Lab in Culver City, the\ncyber equivalent of a biodefense lab, where researchers could unleash\nmalevolent code on a “red” network—a sandboxed system air-gapped from\nSymantec’s business network—to observe its hostile behavior in a controlled\nenvironment. To reach the ground-floor lab, workers passed through several\nsets of security doors, each with progressively more restrictive rules. The\nfinal gateway kept all but a handful of workers out and physically isolated\nthe red network from computers connected to the outside internet. Portable\nmedia were prohibited here—no DVDs, CD-ROMs, or USB flash drives were\nallowed—to prevent workers from mindlessly slipping one into an infested\nmachine and inadvertently carrying it out of the lab with a malicious specimen\nstowed away on it.\n\nThe term “threat intelligence lab” conjures a sterile workshop with scientists\nin white coats bent over microscopes and Petri dishes. But Symantec’s lab was\njust a nondescript office space filled with mostly empty cubicles and a\nhandful of workers who stared intently at their monitors all day, mostly in\nsilence, doing methodical and seemingly tedious work. There were no pictures\non the walls; no Nerf guns or other goofy office games that workers sometimes\nplay to blow off steam; no plants, fake or otherwise, to give the space a\nhomey feel. The only greenery came courtesy of a wall of windows overlooking a\ngrassy, tree-covered hill—the kind that business parks manufactured to\nsimulate nature for shut-in workers.\n\nO’Murchu’s cubicle was barren of any personal touch, aside from a lone\npanoramic shot of the Grand Canyon, bathed in pink and mauve sunset hues, that\ncommemorated a road trip he took with his father the previous year. He had two\nresearch computers on his desk that were attached to the red network and a\nthird, for reading e-mail and surfing the web, that consisted of just\nperipherals—a keyboard, monitor, and mouse—connected via snaking cables to a\nhard drive secreted outside the lab in a server closet, safely quarantined\nfrom the hostile network.\n\nChien’s cubicle, which shared a wall with O’Murchu’s, was only slightly more\npersonal, with an odd assortment of art postcards and pirate flags next to an\nenamel-coated door sign that read CHIEN LUNATIQUE—a pun on his name.\nTranslated loosely from the French it meant “Beware of Dog,” but Chien\npreferred the more literal translation, “Mad Dog.”\n\nChien was thirty-nine years old but looked a decade younger. Tall, with a\nlanky frame and wire-rimmed glasses, he had a wide, engaging grin with\ncavernous dimples that sank deep into his cheeks whenever he laughed, and he\ntalked in rapid-fire bursts whenever he got excited about a topic he was\ndiscussing. Chien had enjoyed a long and successful career in security, but in\na highly competitive field where professionals often hyped their skills and\nexperience to stand out among competitors, he was the opposite, modest and\nunderstated, preferring to focus on the forensics instead of the flash.\n\nOf the three of them, he had worked at Symantec the longest. It was his first\njob out of college, but he fell into it completely by chance. In the early\n’90s at UCLA, he studied a mix of genetics, molecular biology, and electrical\nengineering, and like O’Murchu was well on his way to a career in science. But\nafter graduating in 1996, he followed a few friends to Symantec, intending to\nstay just a couple of years to earn money for grad school. But he never left.\n\nCybersecurity was still a nascent field and it was easy to get a job without\ntraining or experience. Chien knew nothing about viruses at the time, but had\ntaught himself x86 assembly, the programming language most malware is written\nin, and that was enough. The best analysts weren’t trained computer engineers\nanyway. Engineers built things, but virus wranglers tore them apart. Even with\ncomputer security an established profession built on training courses and\ncertifications, Chien favored job candidates who had no experience but had an\nunquenchable curiosity and a nagging need to solve puzzles and tear things\napart. It was easy to teach someone how to code virus signatures, but you\ncouldn’t teach curiosity or instill in someone a passion for knowing how\nthings worked. The best researchers had an obsessive streak that made them dog\na piece of code until it relinquished its secrets.\n\nWhen Chien joined Symantec, antivirus researchers were like the Maytag\nrepairman in those iconic ads—they had a lot of downtime. Viruses were still\nrare and tended to spread slowly via floppy disks and the “sneaker\nnet”—carried from one computer to another by hand. Customers who thought they\nwere infected with a virus would mail the suspicious file on a floppy disk to\nSymantec, where it might sit in a desk tray for a week or more before Chien or\none of his colleagues wandered by and picked it up. Most of the time, the\nfiles turned out to be benign. But occasionally, they found a malicious\nspecimen. When that occurred, they dashed off some signatures to detect it,\nthen threw them onto another floppy disk and mailed it back to the customer\nalong with instructions for updating their virus scanner.\n\nIt wasn’t long, though, before malware evolved and the landscape changed. The\nintroduction of Microsoft Windows 98 and Office, along with the expanding\ninternet and proliferation of e-mail, spawned rapid-spreading viruses and\nnetwork worms that propagated to millions of machines in a matter of minutes.\nThe Melissa virus in 1999 was one of the most\nnotorious.[2](part0008.html#c04-ftn2) Launched by a thirty-one-year-old New\nJersey programmer named David Smith, it came embedded in a Word document that\nSmith posted to the alt.sex.usenet newsgroup. Smith knew his target audience\nwell—he enticed them to open the file by claiming it contained usernames and\npasswords to access porn sites. Once opened, Melissa exploited a vulnerability\nin the macro function of Microsoft Word and e-mailed itself to the first fifty\ncontacts in the victim’s Outlook address book. Within three days the world’s\nfirst mass-mailing virus had spread to more than 100,000 machines, a\nspectacular record at the time, but quaint by today’s standards. In addition\nto spreading via Outlook, it slipped a nerdy Scrabble reference into documents\non infected machines: “twenty-two, plus triple-word-score, plus fifty points\nfor using all my letters. Game’s over. I’m outta here.” Melissa was relatively\nbenign, but it opened the way to other fast-moving viruses and worms that\nwould dominate headlines for years.[3](part0008.html#c04-ftn3)\n\nAs the threat landscape expanded, Symantec realized it needed to halt\ninfections faster, before they began to spread. When the company first entered\nthe antivirus business, it was considered a good response time to turn a\nthreat around—from discovery to delivery of signatures—within a week. But\nSymantec aimed to reduce this to less than a day. To accomplish this, the\ncompany needed analysts in multiple time zones to spot viruses in the wild\nwhen they first appeared and get signatures out to US customers before they\nwoke up and began clicking on malicious e-mail attachments.\n\nChien had already surpassed his two-year plan with Symantec by then. He’d\nsaved enough money for grad school and planned to move to Colorado to\nsnowboard and cycle before applying to science programs. But Symantec dangled\nan enticing offer—a post in the Netherlands instead. The company had a tech\nsupport and sales office outside Amsterdam but wanted a team of malware\nanalysts too. Chien couldn’t say no. He landed in the Netherlands days before\nthe Love Letter worm crippled the internet in May 2000. The worm began as a\ncollege student’s mischievous class project in the Philippines but then spread\nrapidly to millions of machines worldwide. It was the perfect test for\nSymantec’s new European rapid-response team, even if that team consisted of\njust one. Within a record twenty minutes Chien had analyzed the code and\ncrafted signatures to detect it. (Sadly, the achievement was all for naught,\nsince Love Letter sucked up so much internet bandwidth that customers couldn’t\nreach Symantec’s servers to download the signatures.) As soon as the crisis\npassed, Chien hired four more researchers to complete his Amsterdam team, and\nthey were all in place when the next big threat—the Code Red worm—hit the\nfollowing year.\n\nHe moved to Tokyo for a brief period to open another research office. Then, in\n2004, Symantec moved its European headquarters from Amsterdam to Dublin, and\nChien went with it. Shortly after, he bulked up the research team with more\nthan a dozen new hires, including O’Murchu. In 2008 he returned to the United\nStates, along with his new wife, a Frenchwoman who had worked in Symantec’s\nNetherlands office. He was later joined in California by O’Murchu.\n\nNow in Culver City, the two of them and Falliere faced a daunting task in\ndeconstructing Stuxnet.\n\nTHE FIRST OBSTACLE the researchers encountered occurred when they tried to\ndecrypt all of Stuxnet’s code. As O’Murchu had already discovered, the core of\nStuxnet was a large .DLL file that got deposited onto machines. This came\npackaged with dozens of smaller .DLLs and components inside of it, all wrapped\ntogether in layers of encryption that had to be cracked and removed before\nthey could decipher the code. Luckily, the keys for unlocking them were in the\ncode itself; every time Stuxnet landed on a Windows machine, it used the keys\nto decrypt and extract each .DLL and component as needed, depending on the\nconditions it found on the machine. At least this was how it was supposed to\nwork. Some of the keys weren’t getting activated on their test machine—the\nfinal ones needed to unlock the payload.\n\nO’Murchu dug through the code, trying to find the reason, and that’s when he\ndiscovered references to specific brands of Siemens PLCs. Stuxnet wasn’t\n_just_ hunting for systems with Siemens Step 7 or WinCC software installed;\nthey also had to be using a specific line of Siemens PLCs—the company’s S7-315\nand S7-417 programmable logic controllers. Only this combination of software\nand hardware triggered Stuxnet’s keys to unlock and release the payload.\n\nThe only problem was, Chien and O’Murchu had neither—the Siemens software nor\nthe PLCs. Without them, they had to use a debugger to poke and prod the code\nto find the keys and manually unlock the payload.\n\nThe debugging program, a mainstay for reverse engineers, let them walk through\nthe code step-by-step—like a stop-motion camera—to isolate each function and\ndocument its activity. Using this, they singled out each section of code that\ncontained commands for decrypting the malware and followed the commands to\nfind the keys. But locating the keys was only half the trick. Once they had\nall the keys, they had to find the encryption algorithm that each key\nunlocked. It took several days of digging, but when they had all the parts\nunlocked, they could finally see every step that Stuxnet took during its\ninitial stages of infection.[4](part0008.html#c04-ftn4)\n\nOne of the first things Stuxnet did was determine if the computer was a 32-bit\nor 64-bit Windows machine; Stuxnet only worked with 32-bit Windows machines.\nIt also determined if the machine was already infected with Stuxnet. If it\nwas, Stuxnet made sure the resident malware was up to date and simply swapped\nout any old files for the latest ones. But if Stuxnet found itself on a new\nmachine, it began an elaborate infection dance, racing rapidly through a\nsuccession of steps to scope out the landscape of the machine and determine\nthe best way to proceed.\n\nDuring this process, one of its rootkits quickly took up position on the\nmachine to blind the system to Stuxnet’s files on the USB flash drive. It did\nthis by hooking the system so the file names couldn’t be seen by virus\nscanners—the equivalent of hiding them in a scanner’s shadow. If the scanner\ntried to read the contents of the flash drive, the rootkit intercepted the\ncommands and served back a modified list that didn’t include Stuxnet’s files.\nBut some scanners couldn’t be bypassed in this way. Stuxnet knew which\nscanners were trouble and modified its methods accordingly if it found one of\nthese on a machine. If Stuxnet determined it couldn’t bypass a scanner at all,\nit halted the infection and shut itself down.\n\nBut if Stuxnet decided to proceed, the second driver then got activated. This\none had two tasks—the first was to infect any USB flash drive that got\ninserted into the machine, which it would do for only twenty-one days after\nStuxnet infected the machine.[5](part0008.html#c04-ftn5) The second, and most\nimportant, task was to decrypt and load the large .DLL, and its various\ncomponents, into the machine’s memory using the novel techniques O’Murchu had\ndocumented. First it unwrapped and decompressed the .DLL to release the\nsmaller .DLLs inside, then it loaded them into memory. Because the files were\nrunning in memory, any time the machine rebooted, the files got wiped away, so\nthe driver also had to reload them in memory after each reboot.\n\nOnce the large .DLL and its contents were all unpacked and loaded into memory,\nStuxnet searched for new machines to infect and called home to the command-\nand-control servers to report its new conquest—but unless it found the Siemens\nStep 7 or WinCC software installed on the machine, Stuxnet would go dormant on\nthe machine once these steps were done.\n\nSo now the Symantec researchers knew how Stuxnet propagated and loaded its\nfiles, but they still didn’t know why it was created or what it was designed\nto do. The answers to these questions were still buried within its payload.\n\nAs O’Murchu reflected on what they had uncovered so far in the missile portion\nof the code, he couldn’t help but admire the artful handiwork the attackers\nhad put into their attack—the clever ways they solved problems they expected\nto encounter, and the numerous scenarios they had to test before releasing\ntheir code. Not all of Stuxnet’s features were impressive on their own, but as\na whole the attack posed a formidable threat.\n\nAside from the complex ways Stuxnet loaded its files and bypassed security\nsoftware, it used an extensive checklist to ensure all conditions were ideal\non a machine before unleashing its payload. It also carefully tracked all of\nthe resources it used on a machine and made sure to free up each as soon as it\nwas no longer needed to reduce the amount of processing power Stuxnet consumed\non the machine—if Stuxnet used too much power, it ran the risk of slowing the\nmachine down and being discovered. It also overwrote many of the temporary\nfiles it created on a machine once they were no longer needed. All software\nprograms create temporary files, but most don’t bother to delete them, since\nthey’d just be overwritten by the temporary files other applications create.\nThe attackers didn’t want Stuxnet’s files lingering on a system for long,\nhowever, because it raised the risk that they’d be seen.\n\nBut despite all the extra effort the attackers put into their code, there were\nseveral parts that seemed oddly underdesigned. O’Murchu wasn’t the only one\nwho thought so. As the Symantec researchers published their findings about\nStuxnet over several weeks, members of the security community began grumbling\nonline about the code’s many failings, insisting that its authors weren’t\nnearly the elite cadre of hackers original reports made them out to be. Their\ntechnical prowess was inconsistent, some said, and they made a number of\nmistakes that allowed investigators to see more easily what they were trying\nto do.\n\nStuxnet, for example, would have been much more difficult to decipher had the\nattackers used better obfuscation to thwart the researchers’ forensic\ntools—such as more sophisticated encryption techniques that would prevent\nanyone except the target machines from unlocking the payload or even\nidentifying that Stuxnet was targeting Siemens Step 7 software and PLCs.\nStuxnet also used weak encryption and a standard protocol to communicate with\nits command-and-control servers instead of custom-written ones that would have\nmade it more difficult for researchers to establish their sinkhole and read\nthe malware’s traffic.\n\nCryptographer Nate Lawson’s comments dripped with disdain when he wrote in a\nblog post that Stuxnet’s authors “should be embarrassed at their amateur\napproach to hiding the payload” and their use of outmoded methods that\ncriminal hackers had long since surpassed. “I really hope it wasn’t written by\nthe USA,” he wrote, “because I’d like to think our elite cyberweapon\ndevelopers at least know what Bulgarian teenagers did back in the early\n90s.”[6](part0008.html#c04-ftn6) The mix of state-of-the-art tactics and\nHacker 101 techniques made Stuxnet seem like a “Frankenstein patchwork” of\nwellworn methods, others said, rather than the radical skunkworks project of\nan elite intelligence agency.[7](part0008.html#c04-ftn7)\n\nBut O’Murchu had a different take on Stuxnet’s inconsistencies. He believed\nthe attackers deliberately used weak encryption and a standard protocol to\ncommunicate with the servers because they wanted the data traveling between\ninfected machines and the servers to resemble normal communication without\nattracting unusual attention. And since communication with the servers was\nminimal—the malware transmitted only limited information about each infected\nmachine—the attackers didn’t need more advanced encryption to hide it. As for\nsecuring the payload better, there may have been limitations that prevented\nthem from using more sophisticated techniques, such as encrypting it with a\nkey derived from extensive and precise configuration data on the targeted\nmachines so that only those machines could unlock\nit.[8](part0008.html#c04-ftn8) The targeted machines, for example, may not\nhave had the same exact configuration, making it difficult to use a single\npayload encryption key, or there may have been concerns that the configuration\non the machines could change, rendering such a key useless and preventing the\npayload from triggering.\n\nStuxnet’s failings may also have been the consequence of time\nconstraints—perhaps something caused the attackers to launch their code in a\nrush, resulting in last-minute work that seemed sloppy or amateurish to\ncritics.\n\nBut there was another possible explanation for the patchwork of techniques\nused in the threat—Stuxnet was likely created by different teams of coders\nwith different skills and talents. The malware’s modular nature meant\ndevelopment could have been done by different teams who worked on various\nparts simultaneously or at different times. O’Murchu estimated it took at\nleast three teams to code all of Stuxnet—an elite, highly skilled tiger team\nthat worked on the payload that targeted the Siemens software and PLCs; a\nsecond-tier team responsible for the spreading and installation mechanisms\nthat also unlocked the payload; and a third team, the least skilled of the\nbunch, that set up the command-and-control servers and handled the encryption\nand protocol for Stuxnet’s communication. It was possible the division of\nresponsibilities was so well defined and the teams so compartmentalized that\nthey never interacted.\n\nBut although each of the teams had varying levels of skill and experience,\nthey were all at least uniform in one thing—none of them had left any clues\nbehind in the code that could be easily used to track them. Or so it seemed.\n\nATTRIBUTION IS AN enduring problem when it comes to forensic investigations of\nhack attacks. Computer attacks can be launched from anywhere in the world and\nrouted through multiple hijacked machines or proxy servers to hide evidence of\ntheir source. Unless a hacker is sloppy about hiding his tracks, it’s often\nnot possible to unmask the perpetrator through digital evidence alone.\n\nBut sometimes malware writers drop little clues in their code, intentional or\nnot, that can tell a story about who they are and where they come from, if not\nidentify them outright. Quirky anomalies or footprints left behind in\nseemingly unrelated viruses or Trojan horses often help forensic investigators\ntie families of malware together and even trace them to a common author, the\nway a serial killer’s modus operandi links him to a string of crimes.\n\nStuxnet’s code was more sterile than the malware Chien and O’Murchu usually\nsaw. But two things about it did stand out.\n\nChien was sifting through the notes they had taken on Stuxnet’s initial\ninfection dance one day, when something interesting caught his eye—an\ninfection marker that prevented Stuxnet from installing itself on particular\nmachines. Each time Stuxnet encountered a potential new victim, before it\nbegan the process of decrypting and unpacking its files, it checked the\nWindows registry on the machine for a “magic string” composed of a letter and\nnumbers—0x19790509. If it found the string, Stuxnet withdrew from the machine\nand wouldn’t infect it.\n\nChien had seen “inoculation values” like this before. Hackers would place them\nin the registry key of their own computers so that after unleashing attack\ncode in a test environment or in the wild, it wouldn’t come back to bite them\nby infecting their own machine or any other computers they wanted to protect.\nInoculation values could be anything a hacker chose. Generally, they were just\nrandom strings of numbers. But this one appeared to be a date—May 9, 1979—with\nthe year listed first, followed by the month and day, a common Unix\nprogramming format for dates. Other number strings that appeared in Stuxnet,\nand that the researchers knew for certain were dates, were written in the same\nformat.\n\nChien did a quick Google search for the day in question and was only half\nsurprised when one of the results revealed a connection between Israel and\nIran. The 1979 date was the day a prominent Iranian Jewish businessman named\nHabib Elghanian was executed by firing squad in Tehran shortly after the new\ngovernment had seized power following the Islamic Revolution. Elghanian was a\nwealthy philanthropist and respected leader of the Iranian Jewish community\nuntil he was accused of spying for Israel and killed. His death marked a\nturning point in relations between the Jewish community and the Iranian state.\nFor nearly forty years, while Mohammad Reza Shah Pahlavi had been in power,\nIranian Jews had enjoyed a fairly amicable relationship with their Muslim\nneighbors, as did the Islamic nation with the state of Israel. But Elghanian’s\nexecution, just three months after the revolution ousted the shah, was a\n“Kristallnacht” moment for many Persian Jews, making it clear that life under\nthe new regime would be very different. The event sparked a mass exodus of\nJews out of Iran and into Israel and helped fuel hostility between the two\nnations that persists today.\n\nWas the May date in Stuxnet a “Remember the Alamo” message to Iran from\nIsrael—something like the missives US soldiers sometimes scribbled onto bombs\ndropped on enemy territory? Or was it an effort by non-Israeli actors to\nimplicate the Jewish state in the attack in order to throw investigators off\ntheir trail? Or was it simply a case of Chien having an active imagination and\nseeing symbols where none existed? All Chien could do was guess.\n\nBut then the Symantec team found another tidbit that also had a possible link\nto Israel, though it required more acrobatic leaps to make the connection.\nThis one involved the words “myrtus” and “guava” that appeared in a file path\nthe attackers left behind in one of the driver files. File paths show the\nfolder and subfolders where a file or document is stored on a computer. The\nfile path for a document called “my résumé” stored in a computer’s Documents\nfolder on the C: drive would look like this—c:\\documents\\myresume.doc.\nSometimes when programmers run source code through a compiler—a tool that\ntranslates human-readable programming language into machine-readable binary\ncode—the file path indicating where the programmer had stored the code on his\ncomputer gets placed in the compiled binary file. Most malware writers\nconfigure their compilers to eliminate the file path, but Stuxnet’s attackers\ndidn’t do this, either by accident or not. The path showed up as\nb:\\myrtus\\src\\objfre_w2k_x86\\i386\\guava.pdb in the driver file, indicating\nthat the driver was part of a project the programmer had called “guava,” which\nwas stored on his computer in a directory named “myrtus.” Myrtus is the genus\nof a family of plants that includes several species of guava. Was the\nprogrammer a botany nut, Chien wondered? Or did it mean something else?\n\nChien searched further for information about myrtus and found a tangential\nconnection to another prominent event in Jewish history, when Queen Esther\nhelped save the Jews of ancient Persia from massacre in the fourth century\nBCE. According to the story, Esther was a Jewish woman who was married to the\nPersian king Ahasherus, though the king did not know she was Jewish. When she\nlearned of a plot being hatched by the king’s prime minister, Haman, to kill\nall the Jews in the Persian Empire with the king’s approval, she went to the\nking and exposed her identity, begging the king to save her and her people.\nThe king then had Haman executed instead and allowed the Jews in his empire to\nbattle all the enemies that Haman had amassed for their slaughter, resulting\nin a victory for the Jews and 75,000 of their enemies dead. The Purim holiday,\ncelebrated annually by Jewish communities around the world, commemorates this\ndeliverance of Persian Jews from certain death.\n\nOn its face, the story appeared to have no relevance to Stuxnet at all. Except\nthat Chien found a possible connection in Esther’s Hebrew name. Before\nchanging her name and becoming the queen of Persia, Esther had been known by\nthe name Hadassah. Hadassah in Hebrew means myrtle, or myrtus.\n\nThe parallels between ancient and modern Persia were not hard to draw, in\nlight of current events. In 2005, news reports claimed that Iranian president\nMahmoud Ahmadinejad had called for Israel to be wiped off the face of the map.\nThough subsequent reports determined that his words had been mistranslated, it\nwas no secret that Ahmadinejad wished the modern Jewish state to disappear,\njust as Haman had wanted his Jewish contemporaries to disappear centuries\nbefore.[9](part0008.html#c04-ftn9) And on February 13, 2010, around the same\ntime that Stuxnet’s creators were preparing a new version of their attack to\nlaunch against machines in Iran, Rav Ovadia Yosef, an influential former chief\nrabbi of Israel and a political powerhouse, drew a direct line between ancient\nPersia and modern Iran in a sermon he gave before Purim. Ahmadinejad, he said,\nwas the “Haman of our generation.”\n\n“Today we have a new Haman in Persia, who is threatening us with his nuclear\nweapons,” Yosef said. But like Haman and his henchmen before, he said,\nAhmadinejad and his supporters would find their bows destroyed and their\nswords turned against them to “strike their own\nhearts.”[10](part0008.html#c04-ftn10)\n\nNone of this, however, was evidence that the “myrtus” in Stuxnet’s driver was\na reference to the Book of Esther. Especially when read another way, as some\nlater suggested, myrtus could easily have been interpreted as “my RTUs”—or “my\nremote terminal units.” RTUs, like PLCs, are industrial control components\nused to operate and monitor equipment and processes. Given that Stuxnet was\ntargeting Siemens PLCs, it seemed just as possible that this was its real\nmeaning.[11](part0008.html#c04-ftn11) But who could say for sure?\n\nThe Symantec researchers were careful not to draw any conclusions from the\ndata. Instead, in a blog post written by Chien and a colleague, they said\nsimply, “Let the speculation begin.”[12](part0008.html#c04-ftn12)\n\n* * *\n\n[1](part0008.html#c04-ftn1a) Despite the fact that Conficker spread so rapidly\nand so successfully, it never really did anything to most of the machines it\ninfected, leaving an enduring mystery about the motives for creating and\nunleashing it. Some thought the attackers were trying to create a giant botnet\nof infected machines to distribute spam or conduct denial-of-service (DoS)\nattacks against websites—a later variant of Conficker was used to scare some\nusers into downloading a rogue antivirus program. Others feared it might\ninstall a “logic bomb” on infected systems that would cause data to self-\ndestruct at a future date. But when none of these scenarios materialized, some\nthought Conficker might have been unleashed as a test to see how governments\nand the security industry would respond. The attack code morphed over time and\nused sophisticated methods to remain several steps ahead of researchers to\nprevent them from stamping out the worm altogether, leading some to believe\nthe attackers were testing defenses. After Stuxnet was discovered, John\nBumgarner, chief technology officer for U.S. Cyber Consequences Unit, a\nconsulting firm with primarily government clients, claimed Conficker and\nStuxnet were created by the same attackers, and that Conficker was used as a\n“smokescreen” and a “door kicker” to get Stuxnet onto machines in Iran. As\nproof, he cited the timing of the two attacks and the fact that Stuxnet used\none of the same vulnerabilities Conficker had used to spread. But Symantec and\nother researchers who examined Stuxnet and Conficker say they found nothing to\nsupport Bumgarner’s claim. What’s more, the first version of Conficker avoided\ninfecting any machines in Ukraine, suggesting this may have been its country\nof origin.\n\n[2](part0008.html#c04-ftn2a) Melissa wasn’t the first prolific attack,\nhowever. That honor is reserved for the Morris worm, a self-propagating\nprogram created by a twenty-three-year-old computer science graduate student\nnamed Robert Morris Jr., who was the son of an NSA computer security\nspecialist. Although many of Stuxnet’s methods were entirely modern and\nunique, it owes its roots to the Morris worm and shares some characteristics\nwith it. Morris unleashed his worm in 1988 on the ARPAnet, a communications\nnetwork built by the Defense Department’s Advanced Research Projects Agency in\nthe late 1960s, which was the precursor to the internet. Like Stuxnet, the\nworm did a number of things to hide itself, such as placing its files in\nmemory and deleting parts of itself once they were no longer needed to reduce\nits footprint on a machine. But also like Stuxnet, the Morris worm had a few\nflaws that caused it to spread uncontrollably to 60,000 machines and be\ndiscovered. Whenever the worm encountered a machine that was already infected,\nit was supposed to halt the infection and move on. But because Morris was\nconcerned that administrators would kill his worm by programming machines to\ntell it they were infected when they weren’t, he had the worm infect every\nseventh machine it encountered anyway. He forgot to take into account the\ninterconnectedness of the ARPAnet, however, and the worm made repeated rounds\nto the same machines, reinfecting some of them hundreds of times until they\ncollapsed under the weight of multiple versions of the worm running on them at\nonce. Machines at the University of Pennsylvania, for example, were attacked\n210 times in twelve hours. Shutting down or rebooting a computer killed the\nworm, but only temporarily. As long as a machine was connected to the network,\nit got reinfected by other machines.\n\n[3](part0008.html#c04-ftn3a) Self-replicating worms—Conficker and Stuxnet\nbeing the exception—are far rarer than they once were, having largely given\nway to phishing attacks, where malware is delivered via e-mail attachments or\nthrough links to malicious websites embedded in e-mail.\n\n[4](part0008.html#c04-ftn4a) Once virus wranglers extract the keys and match\nthem to the algorithms, they also write a decryptor program so they can\nquickly decrypt other blocks of code that use the same algorithm. For example,\nwhen they receive new versions of Stuxnet or even other pieces of malware that\nmight be written by the same authors and use the same algorithms, they don’t\nhave to repeat this tedious process of debugging all of the code to find the\nkeys; they can simply run their decryptor on it.\n\n[5](part0008.html#c04-ftn5a) In some versions of Stuxnet the attackers had\nincreased the time period to ninety days.\n\n[6](part0008.html#c04-ftn6a) Nate Lawson, “Stuxnet Is Embarrassing, Not\nAmazing,” January 17, 2011, available at [rdist.root.org/2011/01/17/stuxnet-\nis-embarrassing-not-\namazing/#comment-6451](http://www.rdist.root.org/2011/01/17/stuxnet-is-\nembarrassing-not-amazing/#comment-6451).\n\n[7](part0008.html#c04-ftn7a) James P. Farwell and Rafal Rohozinski, “Stuxnet\nand the Future of Cyber War,” _Survival_ 53, no. 1 (2011): 25.\n\n[8](part0008.html#c04-ftn8a) One method for doing this, as Nate Lawson points\nout in his blog post, is to take detailed configuration data on the targeted\nmachine and use it to derive a cryptographic hash for a key that unlocks the\npayload. The key is useless unless the malware encounters a machine with the\nexact configuration or someone is able to brute-force the key by reproducing\nall known combinations of configuration data until it achieves the correct\none. But the latter can be thwarted by deriving the hash from an extensive\nselection of configuration data that makes this unfeasible. Stuxnet did a low-\nrent version of the technique Lawson describes. It used basic configuration\ndata about the hardware it was seeking to trigger a key to unlock its payload,\nbut the key itself wasn’t derived from the configuration data and was\nindependent of it. So once the researchers located the key, they could simply\nunlock the payload with the key without needing to know the actual\nconfiguration. Researchers at Kaspersky Lab did, however, later encounter a\npiece of malware that used the more sophisticated technique to lock its\npayload. That payload has never been deciphered as a result. See [this\npage](part0019.html#page296).\n\n[9](part0008.html#c04-ftn9a) University of Michigan Professor Juan Cole and\nothers pointed out that the Persian language has no such idiom as “wipe off\nthe map,” and that what Ahmadinejad actually said was that he hoped the\nJewish/Zionist occupying forces of Jerusalem would collapse and be erased from\nthe pages of history.\n\n[10](part0008.html#c04-ftn10a) “Rabbi Yosef: Ahmadinejad a New Haman,” Israel\nNational News, February 14, 2010, available at\n[israelnationalnews.com/News/Flash.aspx/180521#.UONaAhimWCU](http://www.israelnationalnews.com/News/Flash.aspx/180521#.UONaAhimWCU).\n\n[11](part0008.html#c04-ftn11a) John Bumgarner, chief technology officer for US\nCyber Consequences Unit, supports this interpretation and also says that\n“guava” in the driver’s file path likely refers to a flow cytometer made by a\nCalifornia firm called Guava Technologies. Flow cytometers are devices used to\ncount and examine microscopic particles and are used, among other things, to\nmeasure uranium isotopes. Bumgarner believes they may have been used at Natanz\nto help scientists gauge the enrichment levels of uranium hexafluoride gas as\nthe U-238 isotopes are separated from the U-235 isotopes that are needed for\nnuclear reactors and bombs. Guava Technologies makes a flow cytometer called\nGuava EasyCyte Plus that can be integrated with PLCs to provide operators with\nreal-time data about the level of isotopes in uranium. Flow cytometers are a\ncontrolled product and would have to be registered under the Trade Sanctions\nReform and Export Enhancement Act of 2000 before being sold to Iran. See John\nBumgarner, “A Virus of Biblical Distortions,” December 6, 2013, available at\n[darkreading.com/attacks-breaches/a-virus-of-biblical-\ndistortions/d/d-id/1141007?](http://www.darkreading.com/attacks-\nbreaches/a-virus-of-biblical-distortions/d/d-id/1141007?).\n\n[12](part0008.html#c04-ftn12a) Patrick Fitzgerald and Eric Chien, “The Hackers\nBehind Stuxnet,” Symantec, July 21, 2010, available at\n[symantec.com/connect/blogs/hackers-behind-\nstuxnet](http://www.symantec.com/connect/blogs/hackers-behind-stuxnet).\n\n\n# CHAPTER 5\n\n# **SPRINGTIME FOR AHMADINEJAD**\n\nA caravan of black, armor-plated Mercedes sedans sped out of Tehran, heading\nsouth toward Natanz at ninety miles an hour. Seated separately in three of the\ncars were Olli Heinonen; his boss, IAEA director Mohamed ElBaradei; and a\nthird colleague from the agency. It was a crisp winter morning in late\nFebruary 2003, six months after Alireza Jafarzadeh’s group blew the lid off\nthe covert plant at Natanz, and the inspectors were finally getting their\nfirst look at the site. Riding with ElBaradei was an elegant professorial man\nwith white hair and a closely trimmed salt-and-pepper beard: Gholam Reza\nAghazadeh, who was vice president of Iran and president of its Atomic Energy\nOrganization.\n\nTwo weeks earlier, Iranian president Sayyid Mohammad Khatami had finally\nacknowledged that Iran was building a uranium enrichment plant at Natanz,\nconfirming what ISIS and others had suspected all along about the facility.\nIran was in fact developing a number of facilities for every stage of the\nfuel-production cycle, the president said in a speech, and Natanz was just one\nof them. But he insisted that Iran’s nuclear aspirations were purely\npeaceful.[1](part0009.html#c05-ftn1) If you had faith, logic, and all the\nadvantages that a great nation like Iran possessed, you didn’t need weapons of\nmass destruction, he said. What he didn’t say, however, was why, if Iran had\nnothing to hide, it was burying the Natanz plant deep underground. If nothing\nillicit was going on, why fortress it beneath layers of cement and dirt? And\nwhy enrich uranium at all if fuel for Iran’s nuclear reactors could be\npurchased from other countries, as most nations with nuclear reactors have\ndone and as Iran had already done in a contract with Russia? These and other\nquestions were lingering in the minds of the IAEA officials as they drove out\nto Natanz.\n\nThe IAEA had come a long way since its inauguration in 1957, when it was\ncreated to promote the peaceful development of nuclear technology. Its other\nrole as nuclear watchdog—to ensure that countries didn’t secretly apply that\ntechnology to weapons development—was supposed to be secondary. But in the\nfive decades since the agency’s inception, the latter task had gradually\nbecome its most critical, as one nuclear crisis arose after another.\nUnfortunately, the agency’s ability to fulfill this role was often thwarted by\nits limited authority to investigate or punish countries that violated their\nsafeguards agreements.\n\nBecause the agency had no intelligence arm to investigate suspicious activity\non its own, it had to rely on intelligence from the thirty-five member states\non its board, like the United States—which made it susceptible to manipulation\nby these countries—or on whatever information inspectors could glean from\ntheir visits to nuclear facilities. But since inspectors only, for the most\npart, visited sites that were on a country’s declared list of nuclear\nfacilities, this left rogue states free to conduct illicit activity at\nundeclared ones. Even when armed with evidence that a nation was violating its\nsafeguards agreement, the IAEA could do little to enforce compliance. All it\ncould do was refer the offending nation to the UN Security Council, which\ncould then vote on whether to levy sanctions.[2](part0009.html#c05-ftn2)\n\nThese weaknesses became glaringly apparent in 1991 after the end of the first\nGulf War, when inspectors entered postwar Iraq to sort through the rubble and\ndiscovered that Saddam Hussein had built an advanced nuclear weapons program\nunder their noses. Prior to the war, the IAEA had certified that Hussein’s\ncooperation with the agency was “exemplary.”[3](part0009.html#c05-ftn3) So\ninspectors were shocked to discover after the war that they had been\ncompletely duped. By some estimates, Iraq had been just a year away from\nhaving enough fissile material to produce a nuclear bomb and two to three\nyears away from having a full-scale nuclear\narsenal.[4](part0009.html#c05-ftn4) Even more shocking was the realization\nthat the illicit activity had been conducted in rooms and buildings next door\nto declared facilities the inspectors examined, but under the rules could not\ninspect spontaneously.[5](part0009.html#c05-ftn5)\n\nInfuriated by Iraq’s duplicity, the IAEA developed a so-called Additional\nProtocol to augment the safeguards agreement that countries signed. This\nincreased the kinds of activities they had to report to the IAEA and also\ngranted the agency leeway to ask more probing questions, request access to\npurchasing records for equipment and materials, and more easily inspect sites\nwhere illicit activity was suspected to have occurred. There was just one\ncatch. The Protocol applied only to countries that ratified it, and in 2003\nwhen the inspectors visited Natanz, Iran wasn’t one of them. As a result, the\ninspectors were limited in the kinds of demands they could place on\nIran.[6](part0009.html#c05-ftn6)\n\nTHE THREE-HOUR DRIVE from Tehran to Natanz dropped the inspectors at their\ndestination midmorning on that February day. Along the way, they passed the\nHoz-e-Soltan Lake on their left, a salt lake that evaporated in the summer and\nwas knee-deep with brackish water in the winter, and the city of Qom on their\nright, a center of Shi’a learning and one of the holiest cities of Islam.\n\nOnce they passed Qom, an endless vista of sand and highway greeted them for 60\nmiles until they reached the town of Kashan. Another twelve miles after that,\nin a wilderness composed of varying shades of brown and beige, a collection of\nbuildings emerged on the horizon, as if sprung from the desert floor.\n\nWhen they reached Natanz, Heinonen was startled to see that construction at\nthe sprawling complex was much further along than he’d expected. In addition\nto the underground halls, a maze of buildings aboveground was already erected,\nincluding a cluster of five prefabricated structures with aluminum siding that\nfanned out from one another like the beams of a disjointed cross. A large\nelectric substation had also been erected to power the buildings and the\ncentrifuges. One of the five buildings turned out to be a pilot fuel-\nenrichment plant, a research facility where technicians could test new\ncentrifuge models and cascades before installing them in the underground\nproduction halls. Once installed in the halls, the centrifuges would be\nexpected to spin for years on end, so the pilot plant was crucial for\nverifying beforehand that the technology and enrichment process worked.\n\nAlthough the underground halls were still a long way from being operational,\ntechnicians already had about 160 centrifuges spinning in the pilot plant, and\ncomponents for hundreds of other centrifuges were waiting to be assembled\nthere.[7](part0009.html#c05-ftn7) The pilot plant was slated to begin\noperation in June, still four months away, but Iran expected to have 1,000\ncentrifuges installed in it by the end of the year, with the first batch of\nlow-enriched uranium produced within six months after that.\n\nAs Aghazadeh led them around the plant, he took pains to insist that no\nuranium hexafluoride had been introduced to Natanz yet, and no enrichment\ntests had been conducted using gas, either. Testing, he said, had only been\ndone using computer simulations. It was an important distinction to make,\nsince enriching uranium without notifying the IAEA would have violated Iran’s\nsafeguards agreement. But Heinonen wasn’t buying the story. The idea that Iran\nhad spent $300 million to construct a uranium enrichment plant without first\ntesting cascades with actual gas to make sure the enrichment process worked\nstretched the boundaries of belief.\n\nFrom the pilot plant, the inspectors were next taken to a showroom where the\nIranians had carefully laid out, like a high-end science project, all of the\nindividual components of an IR-1 centrifuge, as well as a pair of fully\nassembled ones. Aghazadeh told the inspectors that Iran had produced the IR-1s\nfrom a design of its own making. But when Heinonen moved in for a closer look,\nhe noticed that they resembled an early-generation Urenco design that the\nconsortium had made in Europe years earlier. He didn’t know yet that Iran had\nactually purchased the stolen design from A. Q. Khan, but he was already\nsuspicious of the tales Aghazadeh was spinning.\n\nAfter they finished examining the showroom, the inspectors were driven down\nthe U-shaped tunnel that Corey Hinderstein had spotted on satellite images, to\nview the two cavernous halls buried seventy-five feet beneath the ground. Iran\ndidn’t plan to begin filling the halls with centrifuges until 2005, but at\n32,000 square meters each, they were expected to hold about 47,000 centrifuges\nwhen filled.[8](part0009.html#c05-ftn8) For the time being, however, they were\nempty shells.\n\nThroughout the visit, interactions between the inspectors and Iranian\nofficials had been cordial. But things grew tense when the caravan returned to\nTehran in the afternoon and Heinonen asked his hosts to show him their secret\ncache of uranium. Aghazadeh was taken aback by the question and pleaded\nignorance. Heinonen had come armed, however, with intelligence from Western\ngovernment sources that in 1991 Iran had secretly imported uranium from China,\nincluding uranium hexafluoride.[9](part0009.html#c05-ftn9) He brandished a\nletter from Chinese officials confirming the transaction. When the Iranians\nlater produced the uranium, saying they had forgotten they had it, Heinonen\nand his colleagues noticed that the containers were lighter than expected and\nthat some of the uranium hexafluoride gas seemed to be missing. The Iranians\nsaid it must have evaporated through leaks in the containers, but Heinonen\nsuspected it had been used for secretly testing centrifuges.\n\nThat’s when Heinonen insisted on seeing the Kalaye Electric watch factory as\nwell. At its press conference in August, the NCRI had identified Kala\nElectric, a slightly different spelling, as one of the front companies Iran\nhad been using for its secret nuclear program. The NCRI hadn’t said what role\nthe company played in the program, but shortly before the IAEA inspectors\narrived in Iran to visit Natanz, the NCRI conveniently announced that the\nKalaye facilities were used for researching and developing centrifuges. This,\nplus the undisclosed uranium, gave Heinonen the ammunition he needed to insist\non a last-minute visit to the factory.\n\nThe Iranians reluctantly showed them the Kalaye office building, a mostly\nempty structure, but insisted they couldn’t find the keys to open the factory\nitself. The inspectors were scheduled to leave Iran the next day, so they\nextracted a promise to see the factory on their next visit. Unfortunately, by\nthe time they returned to Iran more than a month later, the Iranians had had\nplenty of time to do spring-cleaning. The inspectors noticed obvious signs of\nfreshly painted walls in one of the factory buildings, as well as doors that\nhad been replaced and floor tiles that had been newly grouted. Suspicious that\nthe Iranians were covering something up, the inspectors asked to collect\nenvironmental samples from the building to test for traces of enriched\nuranium.[10](part0009.html#c05-ftn10) Environmental sampling was something the\nIAEA had added to its repertoire after its failure to detect Iraq’s illicit\nnuclear program. Inspectors used special cotton squares and swabs to collect\ndust from walls and surfaces that could be tested to detect uranium particles\nas small as a picogram, determine the type of uranium that was present, and\neven gauge whether it had been enriched and to what\nlevel.[11](part0009.html#c05-ftn11) But the Iranians refused to let them\ncollect any samples.\n\nMonths later, when they were allowed to collect samples at the factory, as\nwell as from the pilot enrichment plant at Natanz, they found low- and highly\nenriched uranium particles that were not on Iran’s list of declared\nmaterials.[12](part0009.html#c05-ftn12) Confronted with evidence of this\ndeception, officials finally admitted that they had enriched uranium gas at\nKalaye, a violation of Iran’s safeguards agreement with the IAEA. But they\nsaid the gas was enriched only to test the centrifuges and was enriched only\nto 1.2 percent. This didn’t jibe with the particles the IAEA had collected,\nhowever, which ranged from 36 percent to 70 percent\nenriched.[13](part0009.html#c05-ftn13)\n\nUranium in its natural state contains less than 1 percent of U-235, the\nisotope needed for reactors and bombs. Most nuclear reactors need uranium\nenriched to just 3 to 5 percent. Highly enriched uranium is enriched to 20\npercent or more. Although 20 percent enrichment can be used for crude nuclear\ndevices, in addition to some types of nuclear reactors, weapons-grade uranium\nis enriched to 90 percent or above.\n\nIranian officials insisted the highly enriched particles must have come from\nresidue left inside used centrifuges that Iran had purchased—an admission that\nthe centrifuge design wasn’t Iran’s own, as they had previously stated, and\nthat some other nation was helping Iran build its program. Suddenly, concern\nover the nuclear program ratcheted up.\n\nThe environmental samples weren’t proof that Iran was working on a covert\nnuclear weapons program, but they were indications that inspectors had a lot\nof work ahead of them to try to uncover the scope of Iran’s nuclear program.\nThey were also indications that nothing Iranian officials said could be\ntrusted. It was the start of a long and exhausting dance that would occupy the\nIAEA the rest of the decade as inspectors tried to piece together the history\nof Iran’s nuclear ambitions and gauge its nuclear weapons capability.\n\nJust as the IAEA was beginning this dance, the NCRI announced in May 2003 that\nit had evidence of additional secret nuclear sites in Iran, including one at a\nvillage called Lashkar Ab’ad. Iran admitted it had a pilot plant there for\nconducting laser enrichment experiments—another method for enriching\nuranium.[14](part0009.html#c05-ftn14) And a couple of months later, the NCRI\nannounced the existence of two more nuclear sites, including one in a\nwarehouse district outside Tehran that was surrounded by auto junkyards to\ndisguise it. The NCRI said it was a secret pilot enrichment plant that Iran\nhad set up after the IAEA’s February visit to Natanz so that technicians could\nconduct enrichment experiments in secret, away from the prying eyes of\ninspectors.[15](part0009.html#c05-ftn15)\n\nWith so many public revelations in rapid succession, it was clear that someone\nwas trying to keep the fire beneath Iranian officials stoked. But the\nrevelations kept IAEA inspectors busy as well, since they now had to add more\nfacilities to their list of sites to monitor. In addition to Bushehr and two\nreactor facilities already on the list, the IAEA added the pilot and\ncommercial enrichment plants at Natanz, the reactor being planned for Arak,\nand a uranium conversion plant at Esfahan, about a hundred miles southwest of\nNatanz, where Iran planned to convert uranium into gas to be enriched at\nNatanz.\n\nWHILE QUESTIONS ABOUT its nuclear program were being raised, Iran defiantly\npressed forward with its uranium enrichment plans. In June, workers at Natanz\nbegan feeding the first batch of uranium hexafluoride gas into ten centrifuges\nat the pilot plant, setting off more alarms. Foreign ministers from the\nEU3—France, Germany, and the UK—urged Iran to suspend its enrichment\nactivities until the IAEA could learn more about its nuclear program. A round\nof negotiations ensued and Iran agreed in October to suspend its enrichment\nactivities temporarily. It also agreed to produce a detailed history of its\nnuclear program to remove “any ambiguities and doubts about the exclusively\npeaceful character” of it.[16](part0009.html#c05-ftn16) Iran stuck to the\nlatter agreement to a degree, but when officials delivered their detailed\nhistory to the IAEA, acknowledging that the centrifuge program had been in\ndevelopment on and off for eighteen years, they left a number of important\ndetails out.[17](part0009.html#c05-ftn17) The IAEA only knew this because\nwhile the agency had been trying to extract information from Iranian\nofficials, it had also begun learning more about the secret nuclear program\nfrom the CIA.\n\nA few years earlier, the CIA had infiltrated the nuclear supply network of A.\nQ. Khan by securing the allegiances of a few of his key European suppliers and\nturning them into moles. From them, the CIA learned that Khan had sold the\ndesigns for Pakistan’s P-1 centrifuge—the design stolen from Urenco—to Iran\nand had also sold prototypes for its more advanced P-2 centrifuge to Libya. If\nKhan sold the P-2 design to Libya, Heinonen reasoned, he must have given it to\nIran as well. Iran hadn’t mentioned the advanced centrifuge in its detailed\nhistory, but if it did possess the centrifuges, then it was possible that\nIran’s uranium enrichment program was much further along than Heinonen\nsuspected. The IAEA pressed Iran to come clean about whether it was producing\nP-2 centrifuges, and officials admitted that they had indeed received a design\nfor the P-2 centrifuge in 1996. Workers had tried to develop centrifuges from\nthe design around 2002, officials said, but had abandoned the project shortly\nthereafter, after encountering problems making the centrifuge rotors. Iranian\nofficials insisted to the IAEA that they hadn’t been trying to hide their work\non the P-2s, but had simply planned to disclose it later.\n\nThings grew worse over the next few months after questions arose about yet\nanother secret facility in Iran, this one a building at the Physics Research\nCenter in Tehran.[18](part0009.html#c05-ftn18) By the time inspectors got\naccess to the site to examine it, however, the building had been razed and the\ntopsoil trucked away, thwarting efforts to collect environmental samples for\ntesting.[19](part0009.html#c05-ftn19) That April, Iran announced plans to\nbegin conducting tests at Esfahan to convert milled uranium ore, or\nyellowcake, into uranium hexafluoride gas. The EU3 considered this a violation\nof Iran’s temporary suspension agreement, since converting ore to gas was a\nprecursor to enriching the uranium, but decided not to press the issue,\nfearing that Iran would cancel the already delicate suspension agreement\naltogether.\n\nThen that May, the IAEA was suddenly gifted with a large cache of documents,\nof mysterious provenance, that further intensified concerns about Iran’s\nnuclear program.\n\nIt began when Heinonen got a call from a woman with an American accent who\nsaid her name was Jackie. He suspected she was from the CIA but didn’t ask.\nShe knew details about his investigation into Iran’s nuclear program and said\nthat she had information that would be of interest to him. Heinonen was wary\nof being manipulated by the CIA, but agreed to meet her at a\nStarbucks.[20](part0009.html#c05-ftn20)\n\nWhen he arrived at the coffeehouse, a young Asian woman was waiting to speak\nwith him. She told him she would arrange a meeting for him with two of the\nCIA’s moles who had been inside the Khan nuclear supply network and who could\nbrief him about Khan’s dealings with Iran. She also said she had a stash of\ndocuments about Iran’s nuclear program that she wanted to show him. The\ndocuments came from a businessman in Tehran who had worked for the government\nin the steel and concrete industries—activity that took him to Natanz and\nEsfahan and put him in touch with the people behind Iran’s nuclear program.\nSomehow he had gained access to a large cache of highly sensitive documents\nabout the nuclear program and had been passing them along to Germany’s\nintelligence agency, the BND. “Dolphin,” as the BND dubbed him, had planned to\nuse the documents as a ticket to asylum in the West for him and his family.\nBut before he could execute his plan, Iranian intelligence agents arrested\nhim. His wife and children managed to flee across the border to Turkey,\nhowever, taking the documents with them.\n\nWhen Heinonen read the documents, he couldn’t believe his eyes. Dolphin’s\ncache laid out in a very concise manner a series of projects that purportedly\ncomposed Iran’s secret nuclear weapons program. They included the country’s\nambitious plans to make its own nuclear fuel by mining uranium ore from a mine\nin southern Iran, then processing it to produce uranium concentrate (or\n“yellowcake”), and finally converting the yellowcake into uranium\ntetrafluoride and uranium hexafluoride gas. Uranium tetrafluoride can be used\nto make uranium metal, which can be used for nonweapons applications but also\nfor bombs.[21](part0009.html#c05-ftn21)\n\nNone of this alone was evidence of a nuclear weapons program. But the most\nalarming documents in the Dolphin stash were ones that described precision\ntests for detonating highly explosive materials. There were also sketches and\ninstructions for building a reentry vehicle for Iran’s fleet of Shahab-3\nmissiles that would contain a heavy round object—suspiciously similar to a\nnuclear warhead—as well as a three-minute video showing a simulated explosion\nof a warhead at 1,970 feet, played to the cheesy Vangelis soundtrack from\n_Chariots of Fire_.[22](part0009.html#c05-ftn22) A detonation at such a high\naltitude made no sense for releasing a chemical or biological weapon, Heinonen\nreasoned, so the warhead being designed must be intended for a nuclear\nweapon.[23](part0009.html#c05-ftn23)\n\nWere the documents authentic? Heinonen couldn’t be sure, but they corroborated\nother information the IAEA had been receiving from member states about Iran’s\nactivities. If he was correct in his interpretation of the documents, then\nthey were the most damning evidence yet that Iran was indeed working on a\nnuclear weapons program.\n\nThe IAEA later confronted Iranian officials about the documents and demanded\nan explanation, but officials said the documents describing the explosives\ntests were just as applicable to conventional warheads as to nuclear ones and\ndenied that the tetrafluoride project existed at all. They accused the IAEA of\nfabricating the documents to get sanctions passed against Iran and to build a\ncase for justifying a US and Israel air strike against\nNatanz.[24](part0009.html#c05-ftn24)\n\nJust when it seemed that tension over its nuclear program couldn’t get any\nworse, Iran agreed again in late 2004 to suspend its uranium conversion plans\nat Esfahan as well as all of its other enrichment activities and to commit to\nformal talks about its nuclear program. The suspension agreement didn’t last\nvery long, however. In June 2005, Mahmoud Ahmadinejad, the mayor of Tehran,\nwas elected president of Iran, and government support for the suspension and\ntalks began to erode. Iran’s nuclear program was becoming an issue of national\npride, and hardliners in the government were beginning to view the suspension\nand talks as weak capitulation to the West. No matter what they did to appease\nthe West it would never be enough, they said, because the real goal of Israel\nand the United States was to topple the Iranian regime.\n\nAs the war in Iraq dragged on and the United States lost the upper hand there,\nIranian leaders became bolder in their defiance. In August 2005, just two\nmonths after Ahmadinejad’s election, international talks over the program\nreached an impasse, and Iran announced it was revoking the suspension\nagreement.[25](part0009.html#c05-ftn25) Iran wasted no time removing seals\nthat the IAEA had placed on equipment at the Esfahan plant during the\nsuspension, and proceeded with its plans to convert uranium oxide into uranium\nhexafluoride gas. Conditions went from bad to worse in December, when\nAhmadinejad ignited a firestorm by declaring in a public speech that the\nHolocaust was a myth.[26](part0009.html#c05-ftn26)\n\nThings were spiraling out of control. Iran’s neighbors in the Middle East were\nso spooked by the growing tension between Iran and Israel that Kuwait’s\nMinistry of Health decided to install fifteen radiation-detection systems\nthroughout the country and at border sites to provide early warning of any\nnuclear activity in the region.[27](part0009.html#c05-ftn27) Efforts to gauge\nhow close Iran was to being able to build a bomb, however, were scattershot.\nNo one had a clear view of its covert program. But Iran didn’t actually have\nto build a nuclear weapon to be a threat. All it had to do was master the\nenrichment process and produce enough low-enriched uranium to make a bomb\nshould it choose to. Once it reached this breakout point, Iran could perch on\nthat threshold indefinitely—all the while maintaining truthfully that it\npossessed no nuclear weapons—until the day it decided to convert the enriched\nuranium into weapons-grade material and build a bomb. Estimates about how long\nit would take Iran to reach the breakout point varied. The US National\nIntelligence Estimate of 2005 concluded that Iran was six to ten years from\nhaving enough material to produce a bomb. But Israel was less optimistic.\nOfficials there estimated it was closer to five\nyears.[28](part0009.html#c05-ftn28)\n\nEnriching uranium is one of the most difficult processes to master in making\nnuclear weapons. It is a delicate undertaking in the best of circumstances,\nfraught with trial and error, and Iran had little experience doing it. Add to\nthis the difficulties involved in manufacturing workable centrifuges, and it\nwas easy to see why Iran’s program had taken so long to reach the point that\nit had. Indeed, it appeared that technicians at Natanz were still having\nproblems with their centrifuges, as Ariel Levite, deputy director general of\nthe Israel Atomic Energy Commission, told the United States in early 2006. It\nwould later be revealed that some of the problems were due to sabotage of\ncomponents that Iran had obtained from Turkey.[29](part0009.html#c05-ftn29)\n\nRegardless of the obstacles, in early 2006, Iran resumed enrichment at the\npilot plant at Natanz. The move prompted Israeli officials to revise their\nprevious estimate, saying now that Iran was just two to four years from\nnuclear weapons capability.[30](part0009.html#c05-ftn30) They warned the\nUnited States that Iran must not be allowed to master its enrichment process\nor it would be “the beginning of the end.” Once that occurred, Iran would be\nable to enrich uranium in secret facilities anywhere in the\ncountry.[31](part0009.html#c05-ftn31) Centrifuge plants, unlike other parts of\nthe fuel cycle, didn’t require special facilities to operate. So once\ntechnicians worked out all of the kinks with the process, they could hide\ncascades of centrifuges anywhere they wanted—even in converted office\nbuildings. “We know Iran is moving elements of its program right now,” Gideon\nFrank, director general of the Israel Atomic Energy Commission, warned US\nofficials in early 2006.[32](part0009.html#c05-ftn32) Factories able to\nproduce parts for centrifuges were already “all over the place,” he said, and\nother parts of the nuclear program were being housed inside heavily fortified\nmilitary facilities, where IAEA inspectors would not be able to examine them,\nand being sequestered underground where air strikes likely would not be\neffective.\n\nThen in May, Iranian officials announced that technicians at the pilot\nenrichment plant at Natanz had succeeded in enriching their first batch of\nuranium to 3.5 percent, using a full cascade of 164 centrifuges. This was\nfollowed by another announcement that technicians would finally begin\ninstalling the first of 3,000 centrifuges in one of the large underground\nhalls. It appeared that Iran had finally overcome its difficulties, and that\nnothing, short of an air strike, could stop it now.\n\nConcerned that its ability to monitor Iran’s nuclear program was rapidly\ndeclining, the IAEA declared Iran in noncompliance with its safeguards\nagreement after years of being urged to do so by the United States. The UN\nSecurity Council adopted a resolution in July 2006, demanding that Iran\nsuspend its enrichment by the end of August or face sanctions. Ahmadinejad\nrefused. “Those who think they can use the language of threats and force\nagainst Iran are mistaken,” he said. “If they don’t realize that now, one day\nthey will learn it the hard way.”[33](part0009.html#c05-ftn33)\n\nWestern intelligence agencies suddenly noticed an uptick in Iranian efforts to\nsecretly procure centrifuge components in Europe and elsewhere using a network\nof foreign and domestic front companies.[34](part0009.html#c05-ftn34) They\nwere “trying to buy like mad,” recalls David Albright of ISIS. They were\nseeking valves, pipes, and vacuum equipment, as well as components that could\nbe used for missile development.[35](part0009.html#c05-ftn35)\n\nRumors began swirling about plans for an air strike, but privately, Secretary\nof State Condoleezza Rice told the IAEA’s ElBaradei that she didn’t think it\nwould come to this. Iran, she said, would surely “buckle.” But Iran wasn’t\nbuckling.\n\nAt the end of 2006, with no choice than to follow through on its threat, the\nUN Security Council adopted a resolution applying sanctions against Iran,\nbanning the supply of materials and technology that could be used for nuclear\ndevelopment. Months later it voted on more sanctions to freeze the assets of\nindividuals and organizations believed to be involved in the nuclear\nprogram.[36](part0009.html#c05-ftn36) Still, Iran remained undeterred.\n\nIn February 2007, Iranian officials announced to the IAEA that technicians at\nNatanz had already begun to install the first centrifuges in one of the\nunderground halls. It had taken more than a decade for Iran to reach this\npoint, but it had at last overcome all the obstacles—technological and\nmanmade—that had been in its way. With nothing left to stop them, technicians\nhad two cascades installed in one of the underground halls by the end of the\nmonth, and another two were in the final stages of installation. They had also\ntransferred nine tons of uranium hexafluoride gas into the hall to begin\nenrichment.[37](part0009.html#c05-ftn37)\n\nBy June 2007, 1,400 centrifuges were installed at Natanz and enriching\nuranium. All of the centrifuges were IR-1s, but technicians had also begun\nproducing IR-2 centrifuges, the more advanced centrifuge based on Pakistan’s\nP-2 design. Iran had revived production of the IR-2s after its initial failure\nto produce rotors for the centrifuges.[38](part0009.html#c05-ftn38) Iran was\nalso developing even more advanced IR-4\ncentrifuges.[39](part0009.html#c05-ftn39)\n\nTension between the United States and Israel flared. Israel accused the United\nStates of dragging its feet with regard to Iran’s program and placing too much\ntrust in sanctions and diplomatic efforts. Israeli prime minister Ehud Olmert\nwarned in a public address that if Iran’s program wasn’t halted, Israel would\nact on its own. “Anyone who threatens us, who threatens our existence, must\nknow that we have the determination and capability of defending ourselves,” he\nsaid. “We have the right to full freedom of action to act in defense of our\nvital interests. We will not hesitate to use it.”[40](part0009.html#c05-ftn40)\n\nBut something happened in December 2007 to throw a wrench not only in US\ndiplomatic efforts but in Israel’s attack plans as well. The US National\nIntelligence Estimate (NIE) came out that month with a startling conclusion\nabout Iran’s nuclear program. It stated with “high confidence” that Iran did\nhave a nuclear weapons program at one time but had halted the program back in\nthe fall of 2003, following the US-led invasion of Iraq. This suggested that\nIran was “less determined to develop nuclear weapons” than previously\nbelieved. NIEs, coordinated by the Office of the Director of National\nIntelligence, are based on information gleaned from US and foreign\nintelligence. But this one seemed to contradict what Adm. Michael McConnell,\ndirector of national intelligence, had told a Senate committee just months\nbefore. “We assess that Tehran seeks to develop nuclear weapons and has shown\ngreater interest in drawing out the negotiations rather than reaching an\nacceptable diplomatic solution,” he told the Senate Armed Services Committee\nthe previous February.[41](part0009.html#c05-ftn41)\n\nAlthough the NIE report also noted that Iran could reverse the decision to\nhalt its weapons program at any point, and a classified version of it\ndiscussed evidence that didn’t make it into the public version—that Iran might\nstill have more than a dozen other covert nuclear facilities doing illicit\nenrichment and weapons development—the report threatened to weaken the case\nfor sanctions against Iran and for military\naction.[42](part0009.html#c05-ftn42) US Defense Secretary Robert Gates, who\nopposed an air strike, nonetheless questioned the report’s conclusion. During\na congressional hearing to discuss it, he warned that Iran was engaged in\nsuspicious procurement activities that suggested its nuclear plans were much\nmore organized and directed than the NIE suggested. Gates wasn’t the only one\nwho disagreed with the NIE conclusion. Privately, German officials told the\nUnited States that their own intelligence indicated that Iran still had a\nweapons program, and Israeli officials also said they had information\nindicating that although Iran had halted its weapons program in 2003, it had\nrevived it in 2005.[43](part0009.html#c05-ftn43)\n\nAs the sun set on 2007, Iran had 3,000 centrifuges installed at Natanz and was\nplanning to double that number in the next year. Experts estimated that 3,000\nP-1 centrifuges alone could already produce enough low-enriched uranium for a\nbomb in less than a year, if Iran decided to further enrich\nit.[44](part0009.html#c05-ftn44)\n\nIt seemed there was nothing anyone could do to halt the enrichment program now\nwithout risking a war.\n\nOr was there?\n\nWhile tensions over the enrichment program approached the breaking point, an\nalternative plan was being secretly set in motion. As Iranian technicians\ncongratulated themselves over the progress they’d made at Natanz and were\nmaking preparations to expand the operation, a digital weapon was silently\nunleashed on computers at the plant with a clear-cut mission embedded in its\ncode. With hundreds of rapidly spinning centrifuges in its sights, the\nprecision weapon stealthily and decisively made its way straight to its\ntarget.\n\n* * *\n\n[1](part0009.html#c05-ftn1a) Khatami was speaking in Tehran on February 9,\n2003, during a meeting between the Ministry of Science, Research and\nTechnology and university chancellors. Parts of his speech were reported at:\n[iranwatch.org/library/government/iran/iran-irna-khatami-right-all-nations-\nnuclear-energy-2-9-03](http://www.iranwatch.org/library/government/iran/iran-\nirna-khatami-right-all-nations-nuclear-energy-2-9-03).\n\n[2](part0009.html#c05-ftn2a) The thirty-five member countries on the IAEA’s\nBoard of Governors can vote to open an inquiry or refer a country to the UN\nSecurity Council for sanctions.\n\n[3](part0009.html#c05-ftn3a) Prior to the war, the IAEA’s deputy director in\ncharge of compliance told Leonard Weiss, staff director of the Senate\nCommittee on Governmental Affairs, that not only was Iraq’s cooperation with\nthe IAEA exemplary but that the IAEA had no hint from anyone that Iraq was\ndoing anything untoward. See Leonard Weiss, “Tighten Up on Nuclear Cheaters,”\n_Bulletin of Atomic Scientists_ 47 (May 1991): 11.\n\n[4](part0009.html#c05-ftn4a) David Albright and Mark Hibbs, “Iraq’s Nuclear\nHide and Seek,” _Bulletin of Atomic Scientists_ 47 (September 1991): 27.\n\n[5](part0009.html#c05-ftn5a) Douglas Frantz and Catherine Collins, _The\nNuclear Jihadist: The True Story of the Man Who Sold the World’s Most\nDangerous Secrets_ (New York: Free Press, 2007), 188.\n\n[6](part0009.html#c05-ftn6a) In 2004, Iran agreed to sign the Additional\nProtocol but didn’t ratify it. Later, in 2006, after the IAEA referred Iran to\nthe UN Security Council for noncompliance with its safeguards agreement, Iran\nretaliated by announcing it would no longer adhere to the Protocol.\n\n[7](part0009.html#c05-ftn7a) David Albright, _Peddling Peril: How the Secret\nNuclear Trade Arms America’s Enemies_ (New York: Free Press, 2010), 192.\n\n[8](part0009.html#c05-ftn8a) David Albright and Corey Hinderstein, “The\nIranian Gas Centrifuge Uranium Enrichment Plant at Natanz: Drawing from\nCommercial Satellite Images,” ISIS, March 14, 2003, available at [isis-\nonline.org/publications/iran/natanz03_02.html](http://www.isis-\nonline.org/publications/iran/natanz03_02.html). See also IAEA Board of\nGovernors, “Implementation of the NPT Safeguards Agreement in the Islamic\nRepublic of Iran” (report, June 6, 2003), 6.\n\n[9](part0009.html#c05-ftn9a) The uranium in question included uranium\nhexafluoride, uranium tetrafluoride, and uranium oxide.\n\n[10](part0009.html#c05-ftn10a) US satellite imagery had captured images of\ntrucks visiting the site, suggesting that Iran had hauled away evidence before\nthe inspectors arrived. See Frantz and Collins, _Nuclear Jihadist_ , 293.\n\n[11](part0009.html#c05-ftn11a) IAEA, “Tools for Nuclear Inspection,” a two-\npage pamphlet published by the agency’s Division of Public Information, which\ndescribes the environmental sampling process. Available at\n[iaea.org/Publications/Factsheets/English/inspectors.pdf](http://www.iaea.org/Publications/Factsheets/English/inspectors.pdf).\n\n[12](part0009.html#c05-ftn12a) IAEA Board of Governors, “Implementation of the\nNPT Safeguards Agreement in the Islamic Republic of Iran” (report, November\n10, 2003), 6–7.\n\n[13](part0009.html#c05-ftn13a) Sharon Squassoni, “Iran’s Nuclear Program:\nRecent Developments” (CRS Report for Congress, November 23, 2005), 3.\n\n[14](part0009.html#c05-ftn14a) The Institute for Science and International\nSecurity maintains a comprehensive page that details Iran’s laser enrichment\nactivity. It’s available at [isisnucleariran.org/sites/by-type/category/laser-\nenrichment](http://www.isisnucleariran.org/sites/by-type/category/laser-\nenrichment).\n\n[15](part0009.html#c05-ftn15a) The information comes from a transcript of an\nannouncement made by NCRI spokesman Alireza Jafarzadeh. “Iran-Nuclear: Iranian\nRegime’s New Nuclear Sites,” available at [ncr-\niran.org/en/news/nuclear/568-iran-nuclear-iranian-regimes-new-nuclear-\nsites](http://www.ncr-iran.org/en/news/nuclear/568-iran-nuclear-iranian-\nregimes-new-nuclear-sites).\n\n[16](part0009.html#c05-ftn16a) Reza Aghazadeh, vice president of Iran, in a\nletter to the IAEA on October 21, 2003, as quoted in IAEA Board of Governors,\n“Implementation of the NPT Safeguards Agreement in the Islamic Republic of\nIran” (report, November 10, 2003), 4.\n\n[17](part0009.html#c05-ftn17a) Ibid., 8.\n\n[18](part0009.html#c05-ftn18a) The NCRI had exposed the site in 2003, but said\nat the time that it was being used for a biological weapons program.\nInformation obtained by IAEA, ISIS, and others in 2004, however, suggested it\nwas being used for nuclear activity, which led the IAEA to request an\ninspection.\n\n[19](part0009.html#c05-ftn19a) Iran claimed the site had been razed beginning\nin December 2003 due to a land dispute between the Ministry of Defense and the\ncity of Tehran. The site was razed in order to return the land to the city.\nSee ISIS, “The Physics Research Center and Iran’s Parallel Military Nuclear\nProgram,” February 23, 2012, available at [isis-online.org/uploads/isis-\nreports/documents/PHRC_report_23February2012.pdf](http://www.isis-\nonline.org/uploads/isis-reports/documents/PHRC_report_23February2012.pdf).\n\n[20](part0009.html#c05-ftn20a) Information about the meeting and the documents\ncomes from an author interview with Heinonen, December 2011. See also\nCatherine Collins and Douglas Frantz, _Fallout: The True Story of the CIA’s\nSecret War on Nuclear Trafficking_ (New York: Free Press, 2011), 112; and\nErich Follath and Holger Stark, “The Birth of a Bomb: A History of Iran’s\nNuclear Ambitions,” _Der Spiegel_ , June 17, 2010.\n\n[21](part0009.html#c05-ftn21a) Nuclear weapons are created by shaping uranium\nmetal into two hemispheres and embedding them in an explosives device\noutfitted with detonators. The detonators are rigged to explode uniformly and\nsimultaneously in order to send the two spheres smashing violently into each\nother and produce a chain reaction.\n\n[22](part0009.html#c05-ftn22a) Iran developed the missile, which had a\n900-mile range, in 1998 and conducted successful tests in May 2002. Iran was\nalso developing a missile with a 1,200-mile range.\n\n[23](part0009.html#c05-ftn23a) Follath and Stark, “The Birth of a Bomb.”\n\n[24](part0009.html#c05-ftn24a) ElBaradei opposed releasing the documents\npublicly since the IAEA was unable to verify their authenticity, and memories\nof the United States’ use of discredited documents to support the invasion of\nIraq were still fresh in his mind. The IAEA, however, pressed Iran repeatedly\nover subsequent years to provide information about the programs described in\nthe documents, but no answers were forthcoming in some cases or incomplete\ninformation was provided in others. Some of the information in the documents\nlater found its way to ISIS. See David Albright, Jacqueline Shire, and Paul\nBrannan, “May 26, 2008 IAEA Safeguards Report on Iran: Centrifuge Operation\nImproving and Cooperation Lacking on Weaponization Issues,” May 29, 2008,\navailable at [isis-online.org/uploads/isis-\nreports/documents/ISIS_Iran_IAEA_Report_29May2008.pdf](http://www.isis-\nonline.org/uploads/isis-\nreports/documents/ISIS_Iran_IAEA_Report_29May2008.pdf).\n\n[25](part0009.html#c05-ftn25a) Mohamed ElBaradei provides a good behind-the-\nscenes description of the negotiations in his memoir and explains why Iran\nfelt cheated by them and justified in rejecting them. _The Age of Deception:\nNuclear Diplomacy in Treacherous Times_ (New York: Metropolitan Books, 2011),\n141–47.\n\n[26](part0009.html#c05-ftn26a) Karl Vick, “Iran’s President Calls Holocaust\n‘Myth’ in Latest Assault on Jews,” _Washington Post_ , Foreign Service,\nDecember 15, 2005.\n\n[27](part0009.html#c05-ftn27a) “06Kuwait71, Kuwait’s Country Wide Radiation\nMonitoring System,” US State Department cable from the US embassy in Kuwait to\nthe State Department in Washington, DC, January 2006. Published by WikiLeaks\nat\n[wikileaks.org/cable/2006/01/06KUWAIT71.html](http://www.wikileaks.org/cable/2006/01/06KUWAIT71.html).\n\n[28](part0009.html#c05-ftn28a) The assessment comes from Ariel (Eli) Levite,\ndeputy director general of the Israel Atomic Energy Commission, in a September\n2005 US State Department cable from the Tel Aviv embassy, published by\nWikiLeaks at\n[wikileaks.org/cable/2005/09/05TELAVIV5705.html](http://www.wikileaks.org/cable/2005/09/05TELAVIV5705.html).\n\n[29](part0009.html#c05-ftn29a) “06TelAviv293, Iran: Congressman Ackerman’s\nJanuary 5 Meeting at,” US State Department cable from the US embassy in Tel\nAviv, January 2006. Published by WikiLeaks at\n[wikileaks.org/cable/2006/01/06TELAVIV293.html](http://www.wikileaks.org/cable/2006/01/06TELAVIV293.html).\nSee [this page](part0015.html#page200) in this book for an explanation of the\nproblems.\n\n[30](part0009.html#c05-ftn30a) Privately, Israel and Russia both told the\nUnited States they believed Iran could actually master its enrichment\ndifficulties within six months. See “06Cairo601, Iran; Centrifuge Briefing to\nEgyptian MFA,” US State Department cable, February 2006, published by\nWikiLeaks at\n[wikileaks.org/cable/2006/02/06CAIRO601.html](http://www.wikileaks.org/cable/2006/02/06CAIRO601.html).\n\n[31](part0009.html#c05-ftn31a) “06TelAviv688, Iran-IAEA: Israeli Atomic Energy\nCommission,” US State Department cable, February 2006, published by WikiLeaks\nat\n[wikileaks.org/cable/2006/02/06TELAVIV688.html](http://www.wikileaks.org/cable/2006/02/06TELAVIV688.html).\n\n[32](part0009.html#c05-ftn32a) Ibid.\n\n[33](part0009.html#c05-ftn33a) “Iran Defiant on Nuclear Deadline,” BBC News,\nAugust 1, 2006, available at\n[news.bbc.co.uk/2/hi/5236010.stm](http://www.news.bbc.co.uk/2/hi/5236010.stm).\n\n[34](part0009.html#c05-ftn34a) “07Berlins1450, Treasury Under Secretary Levey\nDiscusses Next,” US State Department cable from the embassy in Berlin, July\n2007, published by WikiLeaks at\n[wikileaks.org/cable/2007/07/07BERLIN1450.html](http://www.wikileaks.org/cable/2007/07/07BERLIN1450.html).\nThe cable mentions that at least thirty Iranian front companies had been\nestablished for procurement. Also per author interview with David Albright in\nJanuary 2012.\n\n[35](part0009.html#c05-ftn35a) Albright, _Peddling Peril_ , 200–1.\n\n[36](part0009.html#c05-ftn36a) The UN Security Council applied economic\nsanctions against Iran in December 2006, and in March 2007 it voted\nunanimously to freeze the financial assets of twenty-eight Iranians linked to\nits nuclear and military programs.\n\n[37](part0009.html#c05-ftn37a) Just when matters with Iran were at their most\ntense, North Korea tested a nuclear device. The deteriorating nuclear\nsituation on multiple fronts prompted the _Bulletin of Atomic Scientists_ on\nJanuary 17, 2007, to move the minute hand of its famous Doomsday Clock two\nminutes closer to midnight. Instead of seven minutes to Doomsday, it was now\nset to five.\n\n[38](part0009.html#c05-ftn38a) Due to export controls and other difficulties\nproducing the rotors from maraging steel, as the centrifuge design required,\nIran had abandoned production of the IR-2s in 2002. But Iranian scientists\nmodified the design to substitute a carbon fiber rotor instead and sometime\nafter 2004 resumed production.\n\n[39](part0009.html#c05-ftn39a) Collins and Frantz, _Fallout_ , 259.\n\n[40](part0009.html#c05-ftn40a) “Prime Minister Ehud Olmert’s Address at the\n2007 Herzliya Conference,” January 24, 2007. A translation is available at\n[pmo.gov.il/English/MediaCenter/Speeches/Pages/speechher240107.aspx](http://www.pmo.gov.il/English/MediaCenter/Speeches/Pages/speechher240107.aspx).\n\n[41](part0009.html#c05-ftn41a) “McConnell Fears Iran Nukes by 2015,”\n_Washington Times_ , February 27, 2007.\n\n[42](part0009.html#c05-ftn42a) The _New York Times_ wrote, “Rarely, if ever,\nhas a single intelligence report so completely, so suddenly, and so\nsurprisingly altered a foreign policy debate.” It noted that the report “will\ncertainly weaken international support for tougher sanctions against Iran,…\nand it will raise questions, again, about the integrity of America’s\nbeleaguered intelligence agencies.” Steven Lee Myers, “An Assessment Jars a\nForeign Policy Debate About Iran,” _New York Times_ , December 4, 2007.\n\n[43](part0009.html#c05-ftn43a) Germany’s deputy national security adviser Rolf\nNikel told US officials in early 2008 that the NIE report complicated efforts\nto convince the German public and German companies that sanctions against Iran\nhad merit. US State Department cable, February 2008, published by WikiLeaks at\n[wikileaks.org/cable/2008/02/08BERLIN180.html](http://www.wikileaks.org/cable/2008/02/08BERLIN180.html).\nSee also\n[wikileaks.org/cable/2007/12/07BERLIN2157.html](http://www.wikileaks.org/cable/2007/12/07BERLIN2157.html).\nWith regard to the Israeli comments, according to a US State Department cable\npublished by WikiLeaks in May 2009, IDF intelligence chief Maj. Gen. Amos\nYadlin made the comments to Congressman Robert Wexler. See\n[wikileaks.cabledrum.net/cable/2009/05/09TELAVIV](http://www.wikileaks.cabledrum.net/cable/2009/05/09TELAVIV).\nThe NIE had other repercussions. A German-Iranian trader named Mohsen Vanaki\nwas on trial in Germany for smuggling dual-use equipment to Iran. He was\ncharged in June 2008 under the War Weapons Control and Foreign Trade Acts. But\nhe asserted in his defense that he couldn’t have been supplying equipment for\na nuclear weapons program in Iran because the NIE had said Iran had no such\nprogram. All charges against him were dismissed, in large part because of the\n2007 NIE report. Prosecutors appealed, however, and in 2009 the dismissal of\ncharges was overturned and he was later convicted, in large part based on BND\nintelligence about suspicious procurements made by entities associated with\nIran’s military.\n\n[44](part0009.html#c05-ftn44a) International Institute for Strategic Studies,\n_Iran’s Strategic Weapons Programmes: A Net Assessment_ (London: Routledge,\n2005), 33.\n\n\n# CHAPTER 6\n\n# **DIGGING FOR ZERO DAYS**\n\nIt was a Friday evening in late August, and Liam O’Murchu was celebrating his\nthirty-third birthday at a swanky rooftop lounge in Venice, California. He’d\nrented out a section of the open-air, U-shaped bar on top of the Hotel Erwin\noverlooking the Pacific Ocean, and was tipping back beer and cocktails with\nhis girlfriend, his sister and brother-in-law visiting from Ireland, and a\ndozen good friends. This being Southern California, a reality-TV crew was\nfilming a couple sitting nearby, going through the awkward motions of a\n“private” date.\n\nO’Murchu’s group had already been at the bar for three hours when Eric Chien\nshowed up around nine p.m. His mind wasn’t on partying, though. He was itching\nto show his friend and colleague an e-mail that had popped up on a security\nlist earlier that day. But he was reluctant to bring it up because he knew\nonce O’Murchu saw it, he wouldn’t be able to put it out of his mind. “I’ll\nshow you this one thing,” Chien told O’Murchu. “But then we’re not going to\ntalk about it the rest of the night, OK?” O’Murchu agreed.\n\nChien pulled out his BlackBerry and brought up the e-mail—a note from a\nresearcher at another antivirus firm hinting that there might be additional\nzero-day exploits hidden in Stuxnet. O’Murchu looked at Chien. They’d been\nworking on Stuxnet for weeks trying to reverse-engineer its components and had\nseen a few clues that suggested there might be another zero-day embedded in\nit, but they hadn’t had time to pursue them. The clues were in the missile\nportion of the code responsible for spreading Stuxnet, but they had been\nfocused on the payload, the part of the code that affected the Siemens\nsoftware and PLCs.\n\nThe e-mail was vague on details, and it wasn’t clear from the message whether\nthe other researcher had actually _found_ more zero-days in Stuxnet or had\nsimply seen the same clues they had seen. Either way, O’Murchu’s competitive\nspirit was sparked. “That’s it,” he told Chien. “I’m not drinking any more\ntonight.” The next morning, a Saturday, O’Murchu was back in the office\ndigging through Stuxnet.\n\nThe office was deserted, so O’Murchu was left to work without distraction. The\nSymantec team had already mapped out most of Stuxnet’s missile portion before\nmoving to the payload, so now it was just a matter of combing through the code\ncarefully for signs of an exploit. This wasn’t as simple as it sounded. Zero-\nday exploits weren’t the sort of thing you found just by opening a malicious\nfile and peering at the code. You had to track each reference the code made to\nthe operating system or to other software applications on the machine to spot\nany suspicious ways it interacted with them. Was it forcing an application to\ndo something it shouldn’t? Jumping security barriers or bypassing system\nprivileges? The missile portion, when reverse-engineered, consisted of\nthousands of lines of code, each of which had to be examined for suspicious\nbehavior.\n\nStuxnet’s structure wasn’t linear, so trying to track what it was doing was\ndoubly difficult. The commands skipped and jumped around, and O’Murchu had to\nfollow their movement at every step.\n\nAfter about an hour, however, he was pretty sure he’d nailed a second exploit.\nHe searched the archive for any sign that the vulnerability it attacked had\nbeen exploited before, but found none. Then he tested the exploit on a machine\nwith the latest Windows software installed, to be certain he wasn’t making a\nmistake. Sure enough, Stuxnet was using a zero-day vulnerability in a Windows\nkeyboard file to gain escalated privileges on the machine.\n\nZero-day vulnerabilities were valuable commodities and to use two of them at\nonce in a single attack, and risk having them both discovered, seemed an odd\nwaste of resources, O’Murchu thought. But he didn’t stop to ponder it. He\nsimply documented his findings and turned back to the code.\n\nHours later, he thought he spotted yet another exploit—signs that Stuxnet was\nusing a vulnerability in the Windows print-spooler function to spread between\nmachines that shared a printer. Once again, he tested it on a machine and\nsearched the archive for any evidence that it had been exploited before, but\nfound none. The feeling that had made his hair stand on end weeks earlier was\nbeginning to return. He documented his findings and turned back to the code to\ncontinue foraging.\n\nBy midafternoon, when Chien came into the office to check on him, O’Murchu was\nbleary-eyed and needed a break. He handed his findings off to Chien, who\ncontinued working on the code until evening. They worked on it some more on\nSunday and by the end of the weekend, they’d uncovered an astonishing three\nzero-day exploits. These, plus the .LNK exploit already discovered, made four\nzero-day exploits in a single attack.[1](part0010.html#c06-ftn1)\n\nThis was crazy, they thought. One zero day was bad enough. Two was overkill.\nBut four? Who did that? And why? You were just burning through valuable zero\ndays at that point. A top-notch zero-day bug and exploit could sell for\n$50,000 or more on the criminal black market, even twice that amount on the\nclosed-door gray market that sold zero-day exploits to government cyber armies\nand spies. Either the attackers had an unlimited supply of zero days at their\ndisposal and didn’t care if they lost a handful or more, or they were really\ndesperate and had a really good reason to topload their malware with spreading\npower to make certain it reached its target. Chien and O’Murchu suspected that\nboth might be true.\n\nChien contacted Microsoft to report the new zero-day exploits they’d found,\nbut discovered that Kaspersky Lab in Russia had already beat them to it. Right\nafter news of Stuxnet had broken, Kaspersky assembled a team of ten analysts\nto examine the missile portion of the code and within days they had found a\nsecond zero-day exploit, followed a week later by the third and fourth. At the\ntime, they had reported the vulnerabilities to Microsoft, which was now\nworking on patches to fix them, but couldn’t go public with the news, under\nthe rules of responsible disclosure, until Microsoft patched the software\nholes.[2](part0010.html#c06-ftn2)\n\nThe four zero-day exploits in Stuxnet were remarkable, but this wasn’t the end\nof the story. During Chien and O’Murchu’s weekend marathon with the code, they\nalso discovered four additional ways that Stuxnet spread, without the use of\nzero-day vulnerabilities, for a total of eight different propagation methods.\nThe attack code had a virtual Swiss Army knife of tools to pry its way into a\nsystem and propagate.\n\nThe most important of these involved infecting the Step 7 project files that\nprogrammers used to program PLCs, and hijacking a username (winccconnect) and\npassword (2WSXcder) that Siemens had hard-coded into its Step 7\nsoftware.[3](part0010.html#c06-ftn3) The Step 7 system used the name and\npassword to gain automatic access to a backend database where they injected\ncode to infect the machine on which the database was stored. The database is a\nshared system that all the programmers working on a Step 7 project can use.\nStuxnet would then infect the machine of any programmer who accessed the\ndatabase. Both of these infection methods increased the likelihood that\nStuxnet would reach a PLC the next time the programmer connected his laptop or\na USB flash drive to one to program it. The attackers used a vulnerability in\nan obscure feature of the Step 7 system to infect the Step 7 project files,\nindicating they had deep knowledge of the system that few others\npossessed—another sign of the extensive skill that went into the\nattack.[4](part0010.html#c06-ftn4)\n\nIn addition to these spreading mechanisms, Stuxnet had a peer-to-peer\ncomponent that let it update old versions of itself when new ones were\nreleased. This let them update Stuxnet remotely on machines that weren’t\ndirectly connected to the internet but were connected to other machines on a\nlocal network. To spread an update, Stuxnet installed a file-sharing server\nand client on each infected machine, and machines that were on the same local\nnetwork could then contact one another to compare notes about the version of\nStuxnet they carried; if one machine had a newer version, it would update the\nothers. To update all the machines on a local network, the attackers would\nhave only had to introduce an update to one of them, and the others would grab\nit.\n\nIt was clear from all the methods Stuxnet used to propagate that the attackers\nwere ruthlessly intent on getting their malware to spread. Yet unlike most\nmalware that used e-mail or malicious websites to spread to thousands of\nmachines at a time, none of Stuxnet’s exploits leveraged the\ninternet.[5](part0010.html#c06-ftn5) Instead, they relied on someone carrying\nthe infection from one machine to another via a USB flash drive or, once on a\nmachine, via local network connections. Based on this, it appeared the\nattackers were targeting systems they knew were not connected to the internet\nand, given the unprecedented number of zero-day exploits they used to do it,\nthey must have been aiming for a high-value, high-security target.\n\nBut this roundabout way of reaching their goal was a messy and imprecise\nmethod of attack. It was a bit like infecting one of Osama bin Laden’s wives\nwith a deadly virus in the hope that she would have passed it on to the former\nal-Qaeda leader. The virus was bound to infect others along the way and\nthereby increase the likelihood of exposing the plot. And, in the end, this is\nexactly what occurred with Stuxnet. It spread to so many collateral machines\nthat it was only a matter of time before something went wrong and it was\ncaught.\n\nAs Chien reviewed the long list of methods and exploits the attackers had\nused, he realized the collection was far from arbitrary. Each accomplished a\ndifferent task and overcame different obstacles the attackers needed to\nachieve their goal. It was as if someone had drafted a shopping list of\nexploits needed for the attack—something to escalate privileges, something to\nspread inside a victim’s network, something to get the payload to a PLC—then\ngave someone the task of buying or building them. It was another indication of\nhow much planning and organization had gone into the attack.\n\nOf all the methods and exploits the hackers used, however, the most crucial to\nthe attack were the .LNK exploit and the infection of the Step 7 project\nfiles, because these were the ones that were most likely to get Stuxnet to its\nfinal target—the Siemens PLCs. PLC programmers often crafted their commands on\nworkstations that were connected to the internet but not connected to the\nproduction network or to PLCs on a plant floor. To transfer commands to a PLC,\nsomeone had to transfer them via a laptop connected directly to a PLC with a\ncable or to carry them on a USB flash drive to a programming machine, called a\nField PG—a Windows laptop used in industrial-control settings. The Field PG is\nnot connected to the internet but is connected to the production network and\nthe PLCs. By infecting Step 7 project files and investing Stuxnet with the\npower to jump the air gap as a USB stowaway, the attackers had essentially\nturned every engineer into a potential carrier for their weapon.\n\nOnce Chien and O’Murchu documented all of the exploits and vulnerabilities\nthat Stuxnet used to spread, they realized there was something else that stood\nout about them. A number of them had actually been seen before. Although\nVirusBlokAda believed the .LNK vulnerability had never been exploited before,\nMicrosoft discovered that another attack had used an .LNK exploit in November\n2008. It had been used by criminal hackers to install a variant of the Zlob\nTrojan onto victim machines.[6](part0010.html#c06-ftn6) Although various\nantivirus scanners had caught the Trojan at the time it was used, they had\nfailed to spot the zero-day exploit that came with it, leaving the\nvulnerability open to attack by Stuxnet. The print-spooler exploit had also\nmade a prior appearance—in a Polish security magazine in April 2009. The\nmagazine had published an article about the hole, along with source code for\nan exploit to attack it.[7](part0010.html#c06-ftn7) News of the vulnerability\nnever reached Microsoft at the time, however, so that vulnerability also\nremained unpatched. The hard-coded Siemens password also had been exposed\nbefore, when someone published it online to a Siemens user forum in April\n2008.[8](part0010.html#c06-ftn8)\n\nChien and O’Murchu wondered if a team of curators had scouted hacker forums\nand security sites to collect information about holes and exploits that the\nStuxnet attackers could use in their assault or if they had simply purchased\nthe exploits readymade from brokers.\n\nOddly, of all the exploits Stuxnet used, only the print-spooler exploit\nappeared in the first version of the attack, the one unleashed in 2009. The\nrest showed up for the first time in the March 2010 attack, which was the one\nthat spread wildly out of control.[9](part0010.html#c06-ftn9) The 2009 version\nof Stuxnet did spread via USB flash drives, but it used a trick that took\nadvantage of the Autorun feature of Windows to do\nthis.[10](part0010.html#c06-ftn10) As noted previously, the Autorun feature\ncould be turned off to thwart malware. So when the next version of Stuxnet was\nreleased in March 2010, the attackers swapped out the code for the Autorun\nfeature and replaced it with the .LNK zero-day exploit.\n\nThe authors also added one other important feature to the 2010 versions of\nStuxnet—the RealTek certificate used to sign the\ndrivers.[11](part0010.html#c06-ftn11)\n\nIn looking at modifications the attackers made from 2009 to 2010, it appeared\nto Chien and O’Murchu that the attack had been deliberately altered to become\nmore aggressive over time, beginning conservatively in 2009, then amping it up\nin 2010 by adding more spreading mechanisms—perhaps in a desperate bid to\nreach their target more quickly or to reach different machines than they had\nhit in their first attack. The .LNK exploit used in 2010, for example, was a\nmuch more efficient spreading mechanism than the Autorun exploit they had used\nin 2009.[12](part0010.html#c06-ftn12) But while it increased the chance that\nStuxnet would reach its target, it also increased the risk that it would\nspread to other machines. Indeed, with this and other exploits added to the\nMarch 2010 version, the malware spread to more than 100,000 machines in and\noutside Iran.[13](part0010.html#c06-ftn13) None of these collateral infections\nhelped the attackers reach their goal; they only increased their chance of\ngetting caught.[14](part0010.html#c06-ftn14) They had to have known the risk\nthey were taking in super-sizing Stuxnet’s spreading power. But apparently it\nwas a risk they were willing to take.\n\nIt was easy, in fact, for the researchers to track the exact paths that\nStuxnet took in spreading. Tucked inside every copy of Stuxnet, the\nresearchers found a little gem that helped them trace the course the malware\nhad traveled in trying to reach its goal—a small log file containing data\nabout every machine that it had infected. As the worm slithered its way\nthrough machines in search of its target, it logged the IP address and domain\nname of each of its victims, as well as a timestamp of when the infection\noccurred based on the machine’s internal clock. It stored the data, about 100\nbytes in size, in the log file, which grew as the worm passed from machine to\nmachine. Thus, every copy of Stuxnet collected from infected machines\ncontained a history of every computer it had infected up to that point,\nleaving a trail of digital breadcrumbs that Chien and O’Murchu could trace\nback to the initial victims. The log had been designed to help the _attackers_\ntrack the path Stuxnet took, but they likely hadn’t counted on someone else\nusing it for the same purpose.[15](part0010.html#c06-ftn15)\n\nChien and O’Murchu examined 3,280 copies of Stuxnet collected from infected\nmachines by various antivirus firms, and based on the data in the log files,\nit appeared the attackers had launched their offensive against a cluster of\nfive companies in Iran, likely chosen for their ability to provide a gateway\nfor Stuxnet to reach its target. Each of the companies was hit by one or more\nversions of the malware launched in June 2009 and in March and April 2010.\nSymantec counted 12,000 infections at these five targets, and from these\ninitial victims Stuxnet then spread to more than 100,000 machines in more than\n100 countries.\n\nSymantec has never publicly identified the companies, due to its policy of not\nnaming victims, and has only referred to them as Domain A, B, C, D, and E in\npublic documents. But the names of the victims are in the log files for others\nto see. They were Foolad Technique, Behpajooh, Kala, Neda Industrial Group,\nand a company only identified in the file as CGJ, believed to be Control\nGostar Jahed. Kala was believed to refer to the same Kala Electric, or Kalaye\nElectric, that the Iranian opposition group, NCRI, had mentioned in their 2002\npress conference as a front company for Iran’s uranium enrichment program.\n\nAlthough the attack struck some of the companies multiple times, not always\nthe same machines were hit each time, suggesting the attackers may have been\nlooking for better-placed machines each time they unleashed their attack or\nfor ones that offered different routes to the targets to increase the\nlikelihood that they would succeed. Only one of the companies, Behpajooh, was\nhit in all three attacks, suggesting it may have provided the best route to\nthe targeted machines. This company was also, however, the victim that caused\nthe most collateral damage. It was the only target hit in the March 2010\nattack, which was the one that spread out of control. Of 12,000 infections\nthat occurred at these five companies, 69 percent of them could be traced to\nthis single victim.\n\n* * *\n\n[1](part0010.html#c06-ftn1a) The fourth exploit they uncovered attacked a\nvulnerability in the Windows task scheduler. This and the Windows keyboard\nexploits were used to gain Stuxnet higher privileges on a machine. If the user\naccount on a machine had limited privileges that prevented Stuxnet from\ninstalling itself or performing any other functions, the two exploits\nescalated these to system-level or “administrative” privileges that gave\nStuxnet permission to do what it wanted without displaying any warnings or\nasking for an actual administrator’s approval.\n\n[2](part0010.html#c06-ftn2a) Microsoft and Kaspersky Lab began publishing\ninformation about the three other zero-day vulnerabilities in mid-September.\n\n[3](part0010.html#c06-ftn3a) A hard-coded password is one that the software\nmaker embeds in their code so that the system can do certain things\nautomatically, without the user needing to enter a password. Often, the\npasswords can’t be changed without creating problems for the system. But hard-\ncoded passwords are a security hazard because it means that every system has\nthe same password, and someone can discover the password by reading the code.\n\n[4](part0010.html#c06-ftn4a) Chien and O’Murchu learned about the obscure\nnature of the vulnerability in the Step 7 system after consulting with control\nsystem experts like Eric Byres of Tofino Security, who had deep knowledge of\nthe Siemens software. The vulnerability lay in the fact that the files were\ndesigned so that programmers could add more than simple data to a Siemens\nproject file. It wasn’t a vulnerability per se, but a feature, since Siemens\nhad intentionally included this in the design of its files. But Stuxnet\nexploited it to slip its .DLL into the files. This alone wasn’t sufficient to\nget Stuxnet to infect a system when a project file was opened, however.\nStuxnet also had to modify critical portions of the project file, including\nconfiguration data, to make sure the .DLL got loaded to any machine that\nopened the file.\n\n[5](part0010.html#c06-ftn5a) The seventh method Stuxnet used to spread was via\nnetwork shares—by infecting resources and files that were shared by multiple\ncomputers on a local network. The eighth method involved an exploit that\ntargeted a two-year-old Windows vulnerability that Microsoft had already\npatched. It was a vulnerability that Conficker had used previously in November\n2008. Microsoft patched the vulnerability in October 2008 after hackers in\nChina had used it first to spread a Trojan horse. Microsoft issued a rare out-\nof-band patch for the hole—out-of-band patches are ones released ahead of a\ncompany’s regular patch schedule when a security hole was serious—after\nrealizing the hole could be easily used to spread a worm. Unfortunately, the\nmakers of Conficker realized this too, and didn’t waste time using it to\nspread their worm the next month. Even though Microsoft had released a patch\nby then, the Conficker team gambled on the fact that many computer users don’t\nkeep current with patches. They won the bet. An estimated one-third of Windows\nmachines remained unpatched, and by April 2009 Conficker had infected millions\nof them. When Stuxnet was released two months later, its attackers gambled on\nthe same bet. But Stuxnet only used this exploit to spread under certain\nconditions; it wasn’t a primary method of propagation.\n\n[6](part0010.html#c06-ftn6a) Zlob generated pop-up windows on infected\nmachines that looked like legitimate Microsoft alerts, warning users that\ntheir machines were infected and urging them to click a link to download an\nantivirus program. The antivirus program that got downloaded, however, was a\nmalicious backdoor that allowed the attacker to do various things on infected\nmachines. The .LNK exploit was an ingenious attack, but it wouldn’t have been\nmuch use to the Zlob gang and other cybercriminals, whose goal was to infect\nas many machines as possible in a short amount of time. The .LNK exploit\nspread malware at a slow rate since it was reliant on a USB flash drive being\nhand-carried from machine to machine. The Zlob gang was better off using an\nexploit that could infect thousands of machines over the internet.\n\n[7](part0010.html#c06-ftn7a) Carsten Kohler, “Print Your Shell,” _Hakin9_ ,\nApril 1, 2009, available at [hakin9.org/print-your-\nshell](http://www.hakin9.org/print-your-shell).\n\n[8](part0010.html#c06-ftn8a) The password was posted in April 2008 by someone\nnamed “Cyber” after another user complained that his Siemens system had\nstopped working after he changed the hard-coded default password. He couldn’t\nremember the original password to restore it, so “Cyber” posted it online to\nhelp him out. The passwords were subsequently deleted from the Siemens forum\nafter someone chastised Cyber for posting them online. But the same passwords\nwere also posted to a Russian-language Siemens forum by someone named “Cyber”\nand were still there when Stuxnet was discovered, though the page where they\nwere posted has since moved or been deleted. The English-language forum where\nthe password was posted is available at:\n[automation.siemens.com/forum/guests/PostShow.aspx?PostID=16127&16127&Language=en&PageIndex=3](http://www.automation.siemens.com/forum/guests/PostShow.aspx?PostID=16127&16127&Language=en&PageIndex=3).\n\n[9](part0010.html#c06-ftn9a) In all three versions of Stuxnet—June 2009 and\nMarch and April 2010—the only part of the attack that changed was the missile\nportion of the code with the spreading mechanisms; the payload targeting the\nPLCs remained the same.\n\n[10](part0010.html#c06-ftn10a) The Autorun trick doesn’t count as a zero-day\nvulnerability since it’s a feature of the Windows system, which attackers\nsimply have found to be advantageous for spreading their malware. See\n[footnotes 7](part0005.html#c01-ftn7) and [8](part0005.html#c01-ftn8), for\nprevious discussion of Autorun.\n\n[11](part0010.html#c06-ftn11a) The attackers had to add the certificate to the\n2010 version of Stuxnet because in late 2009, Microsoft released a new version\nof its operating system, Windows 7, which, as previously noted on [this\npage](part0005.html#page11), included a new security feature that prevented\ndrivers from installing unless they were digitally signed with a valid\ncertificate.\n\n[12](part0010.html#c06-ftn12a) As previously noted, many companies disable\nAutorun because it’s a security risk. The .LNK feature couldn’t be disabled in\nthe same way, and because the vulnerability affected every version of Windows\nsince Windows 2000, it made more machines vulnerable to it.\n\n[13](part0010.html#c06-ftn13a) There’s a caveat regarding the extensive spread\nof the 2010 version compared to the 2009 version. Chien and O’Murchu examined\n3,280 copies of Stuxnet collected from infected machines by various antivirus\nfirms. The June 2009 version of Stuxnet accounted for only 2 percent of these;\nthe rest were from the March and April 2010 versions. The limited number of\n2009 samples found is presumed to be due to the fact that this version spread\nless and infected fewer machines outside of Iran. But it could also be that\nthe 2009 version got replaced on machines by the March 2010 version when it\nwas released. Anytime Stuxnet encountered a machine, it looked to see if an\nolder version of itself was already on the machine and replaced it with the\nnew version. This could have resulted in fewer 2009 samples in the wild for\nresearchers to find. It’s just as likely, however, that the limited number of\n2009 copies was due to the limited ways in which it could spread.\n\n[14](part0010.html#c06-ftn14a) The fact that Stuxnet spread via USB flash\ndrives and local networks instead of through the internet should have made it\nless likely to spread so widely, yet it did. This probably occurred because\nsome of the companies infected in Iran had satellite offices outside Iran or\nused contractors who had clients in other countries and spread the infection\neach time they connected an infected laptop to another client’s network or\nused an infected USB flash drive at multiple sites. After Stuxnet was\ndiscovered, the Symantec researchers sifted through their archive for any\ncopies of Stuxnet that might have been caught and flagged as suspicious by\ntheir automated reporting system before VirusBlokAda discovered it in June\n2010. They found one copy of the March 2010 version of the code on a\ncustomer’s machine in Australia that had been flagged by their reporting\nsystem the month that version of Stuxnet was released. This showed just how\nfar the malware traveled in a short time and how inevitable it was that it was\ngoing to eventually get caught.\n\n[15](part0010.html#c06-ftn15a) The attackers could have retrieved the log\nremotely from an infected system that contacted their command servers.\n\n\n# CHAPTER 7\n\n# **ZERO-DAY PAYDAYS**\n\nStuxnet’s zero-day exploits raised a lot of troubling questions about the\nburgeoning role of governments in the secret sale and use of such\nexploits—questions that have yet to be considered by Congress or resolved in\npublic debate, despite evidence that the practice is creating dangerous\nvulnerabilities for corporations, critical infrastructure, and individual\ncomputer users alike.\n\nAlthough the market for zero-day vulnerabilities and exploits has been around\nfor more than a decade, until recently it was fairly small and lurked in the\nclosed, underground world of hackers and criminals. In the last few years,\nhowever, it has gone commercial and exploded as the number of buyers and\nsellers has ballooned, along with prices, and the once murky trade has become\nlegitimized with the entry of government dollars into the arena to create an\nunregulated cyberweapons bazaar.\n\nOne of the first hints of the free-market commercialization of zero days\nappeared in December 2005, when a seller named “fearwall” posted a zero-day\nvulnerability for sale on eBay and sparked fears that legitimate security\nresearchers and bug hunters would soon go the way of mercenaries and sell\ntheir skills and wares to the highest bidder instead of handing information\nabout software holes over to vendors to be fixed. Before putting his Windows\nExcel zero day on the auction block, fearwall did disclose information about\nthe vulnerability to Microsoft, as “responsible” researchers were expected to\ndo, but the software giant was noncommittal about fixing it, and Microsoft\ndidn’t have a bounty program at the time that paid researchers for the bugs\nthey disclosed. So fearwall decided to offer his bug to the open market to\nembarrass the software giant and force it to fix the hole faster. The bidding\nreached only $60 before eBay yanked the listing. But the aborted sale was a\nforeshadowing of things to come.\n\nToday the markets for zero-day vulnerabilities and exploits are legion—from\nthe white-market bug bounty programs offered by software makers and website\nowners themselves to the thriving underground black markets run by criminal\nhackers to the clandestine gray markets that feed the bottomless demand of law\nenforcement and intelligence agencies around the world.\n\nThe white-market bounty programs offered by Google, Microsoft, and other\ncompanies now pay for information about security holes in their software, and\nhave made the companies more responsive about fixing them. Third-party\nsecurity firms like HP TippingPoint also pay for zero days, which they use to\ntest the security of customer networks and protect them against attacks.\nTippingPoint discloses the vulnerabilities privately to software vendors so\nthey can be fixed, but patches can take weeks or months to produce, and during\nthat time TippingPoint gets a leg up on competitors by being able to protect\ncustomers from attacks that they don’t know about yet.\n\nThe thriving underground black market that caters to crooks and corporate\nspies sells not just zero-day vulnerabilities and exploits but also the\npayloads to weaponize the exploits—Trojan horses, spy kits, and other\nmalicious tools designed to steal online banking credentials and company\nsecrets or amass armies of zombie computers for a botnet. Vulnerabilities sold\non this market become known to the public and vendors only after attacks that\nuse them are discovered, something that can take years to occur, as evidenced\nby the length of time it took researchers to discover the .LNK exploit that\nStuxnet, and the Zlob Trojan before it, used.\n\nBut the underground criminal sales—troubling as they are—are rapidly being\neclipsed by the newest market for zero-day vulnerabilities and exploits, one\nthat critics predict will soon have a more serious effect on security than the\ncriminal market. This is the flourishing gray market of digital arms\ndealers—defense contractors and private marketeers—whose government customers\nhave driven up the price of zero days and enticed sellers away from the vendor\nbounty programs where the holes will be fixed and into the arms of people who\nonly want to exploit them.\n\nThe market is “gray” only because the buyers and sellers are presumed to be\nthe good guys, acting in the interest of public safety and national security.\nBut one person’s national security tool can be another’s tool of oppression,\nand there’s no guarantee that a government that buys zero days won’t misuse\nthem to spy on political opponents and activists or pass them to another\ngovernment that will. Even if a government agency is using a zero day for a\nlegitimate national security purpose, vulnerabilities sold on the gray market\nare not disclosed to vendors for patching, which leaves anyone who doesn’t\nknow about them—including other government agencies and critical\ninfrastructure owners in the buyer’s own country—open to attack should foreign\nadversaries or independent hackers discover the same security holes and\nexploit them.\n\nThe sale of exploits is legal and largely unregulated. Though export controls\nin the United States that govern the sale of conventional software would also\nprohibit the sale of exploits to countries like Iran and North Korea, exploits\ndon’t come with a copyright notice identifying their maker or country of\norigin, so anyone selling to these markets would not likely be caught.\n\nThe price of zero days varies greatly, depending on the rarity of the\nvulnerability—systems that are more difficult to crack produce fewer holes—as\nwell as the time and difficulty involved in finding a hole and developing an\nexploit for it, the ubiquity of the software it exploits, and the exclusivity\nof the sale. An exploit sold exclusively to one customer will naturally bring\nmore than one that’s sold to many. Exploits that require more than a single\nvulnerability to provide the attacker root-level access to a machine also\ndemand a higher price, as do ones that bypass antivirus and other security\nprotections on a system without producing any side effects, such as crashing\nthe browser or the machine or otherwise tipping off the computer owner that\nsomething is amiss.\n\nA zero-day exploit for Adobe Reader can go for $5,000 or $30,000, while an\nexploit for the Mac OS can cost $50,000. But an exploit for Flash or Windows\ncan jump to $100,000 or more because of the programs’ ubiquity in the\nmarketplace. An exploit for Apple’s iOS can also go for $100,000 because the\niPhone is more difficult to crack than competing mobile phones. Browser\nexploits that attack Firefox, Internet Explorer, and Chrome can sell for\nanywhere from $60,000 to more than $200,000, depending on their ability to\nbypass security protections the vendors have put in the\nsoftware.[1](part0011.html#c07-ftn1)\n\nWhatever the price on the gray market, however, it far surpasses in most cases\nwhat a seller can get from the white-market bounty programs. The Mozilla\nFoundation pays just $3,000 for bugs found in its Firefox browser and\nThunderbird e-mail client, for example, while Microsoft, which was criticized\nfor years for having no bug bounty program, began offering just $11,000 in\n2013 for bugs found in the preview release of its new Internet Explorer 11\nbrowser. The company, however, also now offers $100,000 for vulnerabilities\nthat can help an attacker bypass the security protections in its software\nproducts, plus an additional $50,000 for a solution to fix it. Google usually\npays just $500–$20,000 for bugs found in its Chrome browser and web\nproperties, such as Gmail and YouTube, though it will pay $60,000 for some\ntypes of holes found in Chrome during an annual contest it sponsors. But while\nsome vendors are making attempts to compete with the black market, they’re\nstill no match, in most cases, for the price some governments will pay on the\ngray market. And Apple and Adobe still offer no bounty programs whatsoever to\npay for bugs in software used by millions of people.\n\nThe gray market for zero days has been around for about a decade, but only\nrecently has it emerged in its current, robust form. For many years it\noperated ad-hoc, with sales occurring only quietly in private between security\nfirms and researchers and their government contacts. If someone wanted to sell\nan exploit but had no government contacts, it was difficult to sniff out a\nbuyer.\n\nBeginning in 2006, for example, one security firm sold several zero-day\nexploits to a contact at a large US defense firm, according to a former\nemployee who worked there. The zero days, all browser exploits targeting\nsecurity holes in Safari, Firefox, and Internet Explorer, sold for about\n$100,000 each. The security firm got $50,000 up front for each sale it made\nand $10,000 a month thereafter until the price was paid off—payments were\nspread out to discourage them from reselling the exploits to other buyers or\ndisclosing them to the vendors for patching.\n\nOne of the first people to openly admit selling exploits to the government is\nsecurity researcher Charlie Miller, a former NSA hacker who was recruited by\nthe spy agency in 2000 after earning a PhD in mathematics from the University\nof Notre Dame. Miller worked for the intelligence agency about five years,\ninitially cracking codes on its behalf before turning his skills to cracking\ncomputers—doing reconnaissance scans to map foreign networks and conduct\n“computer network exploitations against foreign targets,” according to his\nNSA-cleared résumé. CNE in spy-speak means hacking systems and networks to\nsiphon data and intelligence. After leaving the NSA, Miller earned prominence\nin the security community for hunting zero-day bugs and creating exploits, not\nall of which he sold to the government. He was the first, with a colleague, to\ncrack the security of the iPhone after its debut in 2007, and he’s a four-time\nwinner of Pwn2Own, an annual hacking contest sponsored by HP TippingPoint that\npays contestants for zero-day bugs found in specific software targets.\n\nBut in 2006, Miller was working for a small security firm, doing a little bug\nhunting on the side, when he sold a zero-day exploit to a US government\ncontractor for $50,000. He sold the exploit to someone he knew from his days\nat the NSA, but says he has no idea where it went after the sale or how it was\nused. The contracts he signed for this and other exploits he sold never\nstipulated what the buyer could do with them. “I don’t know if he did anything\ngood or bad with it; I do know that he worked for the US government,” Miller\nsays. “They’re buying the intellectual property, you know? They can do\nwhatever they want with it.”\n\nMiller caused an uproar in 2007 when he published a paper about the zero-day\nmarket and admitted publicly that he sold exploits to the\ngovernment.[2](part0011.html#c07-ftn2) He wrote the paper because he wanted\npeople to know the practice existed and to help other researchers navigate the\npitfalls of the trade that he’d experienced. At the time, selling exploits was\nthe security industry’s dirty little secret. Researchers occasionally\ndiscussed the practice among themselves, but no one was willing to talk about\nit openly. Miller soon learned why. Colleagues in the security community\naccused him of putting users at risk, and some called for his CISSP (certified\ninformation systems security professional) certification to be revoked for\nviolating the industry’s code of ethics. “I talked about it … I got beat up\nfor it. And I don’t talk about it anymore,” Miller\nsays.[3](part0011.html#c07-ftn3)\n\nBut to him, it didn’t make sense to hand over bugs to vendors for free—only a\ncouple of vendor bounty programs existed at the time, and they paid little for\nbugs and exploits. It was also a time when vendors were less likely to thank\nresearchers for disclosing a hole than threaten them with a lawsuit or\ncriminal prosecution for probing their system or software to discover it.\n\nMiller abandoned the zero-day trade years ago—he now works on Twitter’s\nsecurity team—but he still sees nothing wrong with selling zero days to the\ngovernment and gets annoyed when people talk about the ethics of it. “No one\ngets mad that, you know, companies sell the government guns and tanks,” he\nsays, noting that while US researchers are selling zero days to their\ngovernment, Chinese and Russian hackers are doing the same for their\ngovernments. It’s better for the United States to pay top dollar for exploits,\nhe says, than allow them to get into the hands of enemies.\n\n“I don’t think it’s earth-shattering that researchers can sell exploits to the\ngovernment,” Miller told me, “but I think people should … be aware that it\nhappens. I’m OK with the government doing it out in the open.… I don’t know\nwhy they don’t just set up a public program [and say] ‘find a zero day, we’ll\nbuy it.’ ”[4](part0011.html#c07-ftn4)\n\nBut in the years since Miller’s days on the exploit hunt, the gray-market\ndemand for zero days has mushroomed, as evidenced by the fact that exploits\nthat might have taken months to sell before now do so within days or weeks. A\nburgeoning ecosystem has emerged to meet the demand—populated by small firms\nwhose primary business is bug hunting as well as by large defense contractors\nand staffing agencies that now employ teams of professional hackers dedicated\nto the task of creating exploits for governments. There are also more\nmiddlemen willing to broker exploit sales for independent sellers.\n\nOne such middleman is a South African security researcher based in Thailand\nwho is known in the security community by his hacker handle “The Grugq.” The\nGrugq brokers exploit sales between his hacker friends and government\ncontacts, pocketing a 15 percent commission per transaction. He only launched\nhis business in 2011, but by 2012 sales were so good, he told a reporter he\nexpected to make $1 million in commissions. A published photo of him taken at\na Bangkok bar showed a satchel of cash at his feet, evidently payment from one\nof his sellers, though he later said the photo was just a\njoke.[5](part0011.html#c07-ftn5)\n\nMost of the exploits he sold went to government buyers in the United States\nand Europe, he told _Forbes_ , because they were willing to pay more than\nothers. One Apple iOS exploit he sold to a US government contractor went for\n$250,000, though he later concluded he’d asked too little because the buyer\nwas way too happy with the sale. He attributed his success to the\nprofessionalism he put into marketing the exploits and the support he gave to\nhis clients. “You’re basically selling commercial software, like anything\nelse,” he told _Forbes._ “It needs to be polished and come with\ndocumentation.”\n\nBut the really big trade in exploits these days is not done by middlemen and\nindividual sellers like Miller and The Grugq, but by the security firms and\ndefense contractors who have made the development and sale of exploits for\ngovernment part of the new military industrial complex.\n\nAlthough governments still produce their own exploits—the NSA employs teams\nfor this—they also outsource to other firms because the demand for exploits\nhas grown, as has the cost of producing them: two or three years ago, a single\nvulnerability was sufficient to gain root-level access to a machine. But\ntoday, it can take multiple ones to bypass security protections to achieve the\nsame results.\n\nMost of the companies involved in the trade are secretive about their work in\nthis area, not only because it’s classified but because they don’t want to be\ntargeted by activists who oppose the work or by adversaries who might hack\nthem to steal their exploits. Because zero days can be used for both defending\na system and attacking it, many of the companies also hide their offensive\nactivity behind a cover of defensive work. US companies like Endgame Systems,\nHarris, Raytheon, Northrop Grumman, SAIC, Booz Allen Hamilton, and Lockheed\nMartin have all been in the exploit game to varying degrees. Companies in\nEurope include the boutique firms ReVuln in Malta, which creates exploits for\nindustrial control systems, and VUPEN in France, which sells to law\nenforcement and intelligence agencies. Hacking Team in Italy and the Gamma\nGroup in the UK both sell surveillance tools for law enforcement and\nintelligence agencies that use zero-day exploits to get installed.\n\nThe zero-day work of Endgame Systems, a Georgia-based firm, was a badly kept\nsecret in the security community for years but wasn’t widely known outside of\nthe community until 2011, when hackers with the Anonymous collective broke\ninto servers belonging to another firm called HBGary Federal and dumped\nthousands of its e-mails online, including correspondence with executives at\nEndgame. The e-mails discussed Endgame’s exploit work as well as its efforts\n“to maintain a very low profile” on the advice of its government customers.\nThe e-mails, which included PowerPoint presentations for prospective Endgame\nclients, described the company’s mission to enhance the “Information\nOperations capability of the United States intelligence and military\norganizations.” The head of Endgame’s board of directors is also the chief\nexecutive of In-Q-Tel, the CIA’s venture capital firm.\n\nPublicly, Endgame was offering services to protect customers against viruses\nand botnets, while privately selling vulnerability and exploit packages\ncontaining information that could “lead to actionable intelligence for CNA\nefforts.” CNA, or computer network attacks, is military-speak for hacking that\nmanipulates or destroys data or systems or retards or halts the performance of\nsystems. The company launched in 2008 and its business prospects were so rosy\nthat two years later it raised $30 million in venture capital, followed by $23\nmillion in a subsequent round. In 2011, Endgame CEO Christopher Rouland told a\nlocal paper in Atlanta that the company’s revenue was “more than doubling\nyearly.”[6](part0011.html#c07-ftn6)\n\nThe stolen e-mails described three different packages Endgame offered, called\nMaui, Cayman, and Corsica. For $2.5 million a year, the Maui package provided\nbuyers with a bundle of twenty-five zero-day exploits. The Cayman package,\nwhich cost $1.5 million, provided intelligence about millions of vulnerable\nmachines worldwide already infected with botnet worms like Conficker and other\nmalware. A sample map in the e-mails showed the location of vulnerable\ncomputers in the Russian Federation and a list of infected systems in key\ngovernment offices and critical infrastructure facilities that included the IP\naddress of each machine and the operating system it used. The list showed 249\ninfected machines at the Central Bank of the Russian Federation, and a handful\nof machines at the Ministry of Finance, the National Reserve Bank, the\nNovovoronezh Nuclear Power Plant, and the Achinsk Oil Refinery Plant. Endgame\ncollected the data in part by setting up sinkholes to communicate with\nmachines infected with Conficker—when the malware contacted the sinkhole,\nEndgame collected intelligence about the machine. A similar map for Venezuela\nshowed the location of web servers in that country and the software running on\nthem. Web servers, if breached and poorly configured, can often provide\nattackers access to back-end systems and databases. The systems on the list\nincluded servers for Corporación Andina de Fomento—a development bank that\nprovides financing to eighteen member countries in Latin America, the\nCaribbean, and Europe—as well as Venezuela’s central budget office, the Office\nof the Presidency, the Ministry of Defense, and the Ministry of Foreign\nAffairs. After it was hacked, Endgame began telling reporters in 2012 that it\nwas getting out of the exploit business, and in early 2014 it made a formal\nannouncement to this effect.\n\nWhile Endgame made a concerted effort to hide its exploit business, one\ncompany that’s positively garrulous about its role in the zero-day trade is\nVUPEN Security, based in Montpellier, France. VUPEN bills itself as a boutique\nsecurity firm creating and selling exploits to intelligence agencies and law\nenforcement for offensive cyber security operations and lawful intercept\nmissions. Originally launched in 2008 to protect government clients from zero-\nday attacks, the company began creating exploits for offensive operations two\nyears later. In 2011, it earned $1.2 million in revenue, nearly 90 percent of\nwhich came from sales outside France. In 2013, it announced that it was\nopening an office in the United States.\n\nVUPEN’s founder and CEO, Chaouki Bekrar, is a bold and cheeky sort who likes\nto rile critics on Twitter who think supplying exploits to governments is\nunethical. He also often challenges his secretive competitors to come clean\nabout their own zero-day trade. “We are the only company in the world saying\nclearly that we are doing this stuff,” he says. “There are some companies in\nthe US or in Europe, for example, doing this, but they are doing this\nundercover. But we have chosen to do it clearly, just because we want to be\nvery transparent.”[7](part0011.html#c07-ftn7)\n\nWhere Endgame and others take pains to keep a low profile, Bekrar and his\nresearchers regularly travel the security conference circuit, participating in\ncontests like Pwn2Own, to increase the company’s profile. At the CanSecWest\nconference (an annual computer security conference in Canada) in 2012, where\nthe Pwn2Own competition is held, Bekrar and a team of four of his researchers\ntook first place wearing matching black hoodies with the company’s name on the\nback.\n\nBut VUPEN’s transparency goes only so far. Bekrar won’t discuss his background\nor answer other personal questions, deflecting attention to his company\ninstead. “I’m just an actor. I want to talk about the movie,” he says. But\nwhen it comes to the company, he’s equally close-mouthed—he won’t say how many\nemployees he has, just that the company is small, or reveal their last names.\n\nVUPEN’s researchers devote all their time to finding zero-day vulnerabilities\nand developing exploits—both for already-known vulnerabilities as well as for\nzero days. Bekrar won’t say how many exploits they’ve sold since they began\nthis part of their business, but says they discover hundreds of zero days a\nyear. “We have zero days for everything,” he says. “We have almost everything\nfor every operating system, for every browser, for every application if you\nwant.”\n\nHow much of Bekrar’s boasting is true and how much is strategic marketing is\nunclear, but whatever the case, his tactics seem to be working. In 2012,\nseveral months after his team won the Pwn2Own contest, the NSA purchased a\none-year subscription for VUPEN’s “Binary Analysis and Exploits (BAE)”\nservice. The contract, released under a public records request, was heavily\nredacted and didn’t reveal the price paid for the subscription. But a\nbusiness-consulting firm, which named VUPEN entrepreneurial company of the\nyear in 2011, indicated the subscription runs about $100,000 a year. According\nto VUPEN’s website, the BAE service provides “highly technical reports for the\nmost critical and significant vulnerabilities to understand their root cause,\nexploitability techniques, mitigations and both exploit-based and\nvulnerability-based attack detections.”[8](part0011.html#c07-ftn8)\n\nVUPEN also offers a Threat Protection Program that provides detailed research\non exclusive vulnerabilities discovered by its researchers to allow customers\n“to reduce their exposure to zero-day attacks,” according to a company\nbrochure that got leaked to WikiLeaks.[9](part0011.html#c07-ftn9) Both of\nthese programs are described as if they’re meant to help customers defensively\nprotect themselves from zero-day attacks—zero-day exploits can be used to test\na system for its vulnerability to an attack—but the information provided in\nthem can also be used to offensively attack other unpatched systems. The\ncompany’s Threat Protection Package even provides customers with ready-made\nexploits for attacking the vulnerabilities it reveals. And VUPEN has a third\nservice for law enforcement and intelligence agencies that’s clearly designed\nsolely for covertly attacking targeted machines to gain remote access to them.\n“Law enforcement agencies need the most advanced IT intrusion research and the\nmost reliable attack tools to covertly and remotely gain access to computer\nsystems,” Bekrar is quoted saying in the brochure. “Using previously unknown\nsoftware vulnerabilities and exploits which bypass Antivirus products and\nmodern operating system protections … could help investigators to successfully\nachieve this task.”\n\nThe intrusion program is restricted to police and intelligence agencies in\nNATO, ANZUS, and ASEAN, as well as the partner countries of these\nassociations—what Bekrar describes as “a limited number of countries.”\n\n“It’s very sensitive, so we want to keep the number of customers small,” he\nsays. But NATO has twenty-eight member countries, including Romania and\nTurkey, and another some forty countries are considered its partners,\nincluding Israel, Belarus, Pakistan, and Russia. Bekrar insists that VUPEN\nwon’t sell to all of them, however, just because they’re on the lists.\n\nThe company sells exploits that attack all the top commercial products from\nMicrosoft, Apple, Adobe, and others, as well as that target enterprise\ndatabase and server systems made by companies like Oracle. But browser\nexploits are the most coveted item, and Bekrar says they have exploits for\nevery brand. The company sells only exploits and what Bekrar calls\nintermediate payloads that allow a customer to burrow into a network. It’s the\ncustomer’s job to weaponize the exploit with a final payload.\n\nAfter Stuxnet was discovered, VUPEN also turned its attention to industrial\ncontrol systems when customers began inquiring about exploits for them.\nStuxnet’s exploits, which he said his team analyzed after the attack was\nexposed, were admirable. “The vulnerabilities themselves were really nice, and\nthe exploit to take advantage of them was nicer,” he says. “They were not very\neasy to exploit.…” But to seriously develop attacks for industrial control\nsystems requires access to special hardware and facilities for testing, and\nBekrar says, “We don’t have such things and we don’t want to have such\nthings.”\n\nSubscribers to their exploit service have access to a portal, where they can\nshop a menu of existing zero days, or special-order exploits for a specific\noperating system or application. Exploits are priced at four levels, according\nto the brochure. Subscribers purchase a set number of credits, which can be\napplied to the purchase of exploits worth 1, 2, 3, or 4 credits. Each exploit\ncomes with a description of the software it targets and an indication of how\nreliable the exploit is. Customers can also obtain real-time alerts any time a\nnew vulnerability is discovered and an exploit is available. VUPEN monitors\nannouncements from Microsoft and other vendors to see when a vulnerability one\nof their exploits attacks is discovered or patched, and alerts customers that\nthe bug and exploit have been burned—sometimes with an announcement through\nTwitter.\n\nBekrar says his company doesn’t offer exclusivity on exploits but sells the\nsame exploits to multiple buyers. The more an exploit is used, however, the\nmore likely it will be caught, which would make it less attractive to an\nagency like the NSA, where stealth and secrecy are priorities. Bekrar insists\nthat VUPEN works with only a limited number of governments, and says customers\ndon’t use the exploits “in massive operations,” so there is “almost no chance”\nthey will be widely deployed.\n\nBekrar, like Miller, has little sympathy for people who criticize the sale of\nexploits and has said in the past that software vendors created this\ngovernment market for exploits by initially refusing to pay researchers for\nvulnerabilities they discovered, then refusing to pay top dollar, leaving them\nlittle choice but to turn to other buyers willing to compensate them for their\nwork. He also insists, however, that he’s not in the exploit trade for the\nmoney. “We are not businessmen, we don’t care about sales. We mainly care\nabout security, about ethics,” he said.\n\nAt the Pwn2Own contest, when Google offered to pay $60,000 for an exploit and\ninformation about a vulnerability the VUPEN team used against Google’s Chrome\nbrowser, Bekrar refused to hand over the\ninformation.[10](part0011.html#c07-ftn10) He joked that he might consider it\nif Google offered $1 million. But later in private he said even for $1\nmillion, he wouldn’t hand over the exploit, preferring to keep it for his\ncustomers. Asked if VUPEN’s customers had such money to pay for an exploit, he\nlaughed and said, “No, no, no, no. Never.… They don’t have the budget.”\n\nBut he insisted his reasons for supplying to governments went deeper than\nmoney: “We mainly work with governments who are facing national security\nissues … we help them in protecting their democracies and protecting lives.…\nIt’s like any surveillance method. The government needs to know if something\nbad is being prepared and to know what people are doing, to protect national\nsecurity. So there are many ways to use the exploits for national security and\nto save lives.”\n\nBut critics argue that companies like VUPEN have no way of knowing where their\nexploits will end up or how they will be used, such as for domestic spying on\ninnocent citizens. Bekrar acknowledges that VUPEN’s customer agreement doesn’t\nexplicitly prohibit a government buyer from using VUPEN exploits to spy on its\ncitizens. “But we say that the exploits must be used in an ethical way,” he\nsays.\n\nBekrar says they can’t spell it out more specifically in the contract, because\nthe legal agreements need to be general to cover all possible cases of\nunethical use. “For us it’s clear,” he said. “You have to use exploits in\nrespect of ethics, in respect of international regulations and national laws\nand you cannot use exploits in massive operations.” But ethics, of course, are\nin the mind of the beholder, and Bekrar acknowledges that he has no way to\ncontrol how customers interpret ethical injunctions. “My only way, at my side,\nto control this, is to control to which country I sell. And we only sell to\ndemocratic countries.”\n\nChristopher Soghoian of the American Civil Liberties Union is one of VUPEN’s\nbiggest critics. He calls exploit sellers like VUPEN “modern-day merchants of\ndeath” and “cowboys,” who chase government dollars to supply the tools and\nbullets that make oppressive surveillance and cyberwarfare possible—putting\neveryone at risk in the process.[11](part0011.html#c07-ftn11) He acknowledges\nthat governments would make and use their own zero days whether or not\ncompanies like VUPEN sold them, but says the free-market sellers are a\n“ticking bomb” because there’s no control over their trade.\n\n“As soon as one of these weaponized zero-days sold to governments is obtained\nby a ‘bad guy’ and used to attack critical US infrastructure, the shit will\nhit the fan,” Soghoian told an audience of computer professionals at a\nconference in 2011. “It’s not a matter of if, but when.… What if a low-paid,\ncorrupt police officer sells a copy of one of these weaponized exploits to\norganized crime or terrorists? What if Anonymous hacks into a law enforcement\nagency’s network and steals one of these weaponized\nexploits?”[12](part0011.html#c07-ftn12)\n\nIn 2013, initial steps were taken to try to regulate the sale of zero days and\nother cyberweapons. The Wassenaar Arrangement—an arms-control organization\ncomposed of forty-one countries, including the United States, the UK, Russia,\nand Germany—announced that it was for the first time classifying software and\nhardware products that can be used for hacking and surveillance and that “may\nbe detrimental to international and regional security and stability” as dual-\nuse products. The dual-use designation is used to restrict materials and\ntechnology (such as maraging steel used in centrifuges) that can be used for\nmilitary ends as well as peaceful ones. Although the organization’s\ndeclarations are not legally binding, member states are expected to implement\nrequirements for export licenses in their countries and cooperate with one\nanother in controlling sales of dual-use\nproducts.[13](part0011.html#c07-ftn13) Germany, a Wassenaar member, already\nhas a law that effectively prohibits the sale of exploits as well as the\npractice of giving them away for free, something that security researchers do\nregularly among themselves to test systems and improve security. Lawmakers in\nthe United States with the Senate Armed Services Committee introduced\nlegislation in 2013 that calls on the president to establish a policy “to\ncontrol the proliferation of cyberweapons through unilateral and cooperative\nexport controls, law enforcement activities, financial means, diplomatic\nengagement, and such other means as the President considers appropriate.” But\nit’s unclear exactly how such controls would work, since zero days and other\ndigital weapons are much more difficult to monitor than conventional weapons,\nand such controls requiring export licenses for the foreign sale of exploits\nand the screening of buyers can increase the cost for legitimate sellers, but\nnot all sellers are interested in legitimacy.\n\nFurthermore, these kinds of controls are meant to keep exploits only out of\nthe hands of criminals and rogue actors, such as terrorists. They’re not meant\nat all to curb government use of them for law enforcement or national security\npurposes. The thriving gray market for zero days makes it clear that law\nenforcement and spy agencies are anxious to get their hands on exploits like\nthe ones that Stuxnet used—and are willing to pay generously for the\nprivilege. That frenzied demand for zero days is only likely to grow, and with\nit, the number of state-sponsored programs that use them.\n\n* * *\n\n[1](part0011.html#c07-ftn1a) See Andy Greenberg, “Shopping for Zero-Days: A\nPrice List for Hackers’ Secret Software Exploits,” _Forbes_ , March 23, 2012.\nZero-day vulnerabilities have become more challenging to find in recent years\nas the makers of some of the most targeted software programs have added\nfeatures to make them more secure. Google and other companies have built so-\ncalled sandboxes into their browsers, for example, that erect a protective\nbarrier to contain malicious code and prevent it from spilling out of the\nbrowser into the operating system or other applications on a machine. As a\nresult, exploits that allow an attacker to escape a sandbox are valuable.\n\n[2](part0011.html#c07-ftn2a) Charlie Miller, “The Legitimate Vulnerability\nMarket: Inside the Secretive World of 0-Day Exploit Sales,” Independent\nSecurity Evaluators, May 6, 2007, available at\n[weis2007.econinfosec.org/papers/29.pdf](http://www.weis2007.econinfosec.org/papers/29.pdf).\n\n[3](part0011.html#c07-ftn3a) Author interview with Charlie Miller, September\n2011.\n\n[4](part0011.html#c07-ftn4a) Ibid.\n\n[5](part0011.html#c07-ftn5a) Greenberg, “Shopping for Zero-Days: A Price List\nfor Hackers’ Secret Software Exploits.”\n\n[6](part0011.html#c07-ftn6a) Tonya Layman, “Rouland’s Tech Security Firm\nGrowing Fast,” _Atlanta Business Chronicle_ , June 11, 2011.\n\n[7](part0011.html#c07-ftn7a) This and all quotes from Bekrar in this chapter\nare from an author interview in March 2012, unless otherwise cited.\n\n[8](part0011.html#c07-ftn8a) From a press release titled “VUPEN Gets\nEntrepreneurial Company of the Year Award in the Vulnerability Research\nMarket,” June 1, 2006, available at\n[vupen.com/press/VUPEN_Company_of_the_year_2011.php](http://www.vupen.com/press/VUPEN_Company_of_the_year_2011.php).\n\n[9](part0011.html#c07-ftn9a) The brochure is available at\n[wikileaks.org/spyfiles/files/0/279_VUPEN-THREAD-\nEXPLOITS.pdf](http://www.wikileaks.org/spyfiles/files/0/279_VUPEN-THREAD-\nEXPLOITS.pdf).\n\n[10](part0011.html#c07-ftn10a) VUPEN had already won $60,000 from HT Tipping\nPoint for the contest, but Google was offering an additional $60,000 on top of\nthat to obtain information about the hole in order to fix it. The Pwn2Own\ncontest generally requires contestants to hand over the exploit and\ninformation about a hole so that it can be fixed, but not for exploits that\nbypass a browser’s security sandbox, which is what VUPEN said its exploit did.\nThe Google staffer accused VUPEN of showboating at the expense of users.\n“We’re trying to get information out of somebody so that we can fix it …\n[Without that information] it’s not about protecting users anymore, it’s about\nshowing off. It’s good for stroking egos, but aside from that it doesn’t make\nthe web safer,” a Google staffer told me.\n\n[11](part0011.html#c07-ftn11a) Ryan Naraine, “0-Day Exploit Middlemen Are\nCowboys, Ticking Bomb,” [ZDNet.com](http://www.ZDNet.com), February 16, 2012,\navailable at [zdnet.com/blog/security/0-day-exploit-middlemen-are-cowboys-\nticking-bomb/10294](http://www.zdnet.com/blog/security/0-day-exploit-\nmiddlemen-are-cowboys-ticking-bomb/10294).\n\n[12](part0011.html#c07-ftn12a) Ibid.\n\n[13](part0011.html#c07-ftn13a) “The Wassenaar Arrangement on Export Controls\nfor Conventional Arms and Dual-Use Goods and Technologies,” Public Statement\n2013 Plenary Meeting, available at\n[wassenaar.org/publicdocuments/2013/WA%20Plenary%20Public%20Statement%202013.pdf](http://www.wassenaar.org/publicdocuments/2013/WA%20Plenary%20Public%20Statement%202013.pdf).\n\n\n# CHAPTER 8\n\n# **THE PAYLOAD**\n\nNico Falliere was hunched over his desk on the eighth floor of the forty-story\nTour Egée, a triangular glass-and-concrete building in the La Défense business\ndistrict of Paris. Outside, a grim forest of office towers rose in front of\nhis window, obscuring his view of the pigeons and summer tourists ambling\ntoward the steps of La Grande Arche. But Falliere wasn’t focused on the view.\nHe was focused intently on making his first foray into Stuxnet’s complicated\npayload.\n\nIt was early in August 2010, a mere two weeks into the Symantec team’s\nanalysis of Stuxnet, before Chien and O’Murchu discovered the unprecedented\nnumber of zero days that were hiding in the worm. During these first two\nweeks, Falliere had been working with O’Murchu to analyze the malware’s large\nWindows .DLL, but he knew Stuxnet’s real secrets lay in its payload, and he\nwas anxious to get at them.\n\nHe had just returned from lunch with friends when he began digging through the\npayload files, separating each one out and trying to understand its format and\nstructure. He noticed that one of them was a .DLL file with a familiar name.\nThe Symantec researchers had by this point obtained copies of the Siemens Step\n7 software, so Falliere scrolled through the Step 7 program files installed on\nhis test system. It didn’t take long to find what he was looking for—a Siemens\nStep 7 .DLL that had the same name as the Stuxnet file. Hmm, he thought,\nthat’s interesting.\n\nHe quickly determined that anytime Stuxnet found itself on a computer with the\nSiemens Step 7 or WinCC software installed, it unpacked its .DLL file with the\nmatching name from inside its larger Windows .DLL and decrypted it.\n\nFalliere used the key embedded in the malware to decrypt the .DLL and found\nthat it contained all of the same functionality as the legitimate Step 7 .DLL.\nBut it also contained some suspicious code that included commands like “write”\nand “read.” Falliere had seen enough malware in his career to know exactly\nwhat he was looking at—Stuxnet’s Step 7 .DLL was acting as a rootkit, lurking\non the system silently, waiting to hijack, or hook, these functions anytime\nthe system attempted to read or write code blocks to or from the targeted\nPLCs. Similar to the rootkit in the missile portion of Stuxnet, this one was\nhooking the read function to hide something that Sutxnet was doing to the\nPLCs. It was the first time, as far as he knew, that anyone had created a\nrootkit for an industrial control system. It was another first in the growing\nlist of Stuxnet firsts.\n\nFalliere couldn’t tell if Stuxnet’s rogue .DLL was hooking the read function\nto simply monitor the PLCs passively and gather intelligence about their\noperations, or if it had more sinister aims in mind. But the fact that it was\nalso intercepting the “write” function suggested it was probably the latter\nand was attempting to halt the operation of the PLCs or change their operation\nin some way. He glanced at his watch and noted that it was around five a.m. in\nCalifornia—too early to call Chien—so he decided to keep digging.\n\nHe continued for several more hours, and when he had all the pieces of the\npuzzle he needed—it was exactly what he’d suspected. Stuxnet was indeed\nintercepting commands passing from the Siemens .DLL to the PLCs and replacing\nthem with its own. He couldn’t say for sure what it was instructing the PLC to\ndo—he couldn’t find the code blocks that Stuxnet injected into the PLC—but he\nwas pretty sure it wasn’t good. By now it was nine a.m. in California, so he\npicked up the phone and called Chien.\n\nNormally the two of them spoke once a week to exchange a quick update about\nwhatever Falliere was working on; the calls were efficient and to-the-point\nand lasted no more than a few minutes. But this time Falliere recounted\neverything he had found in detail. Chien listened intently, amazed at what he\nheard. The attack kept getting more and more complex. Every corner they turned\nwith Stuxnet they found a new surprise.\n\nChien agreed that Falliere should drop everything to find the code blocks that\nStuxnet injected into the PLC. They also decided Falliere should make a brief\nannouncement on their blog about the PLC rootkit. The rest of the information\nthey would keep under wraps, for the time being, until Falliere could\ndetermine the nature of what Stuxnet was injecting into the PLC.\n\nThat night on the Métro on his way home from work, Falliere was charged with\nnervous energy. For four years he’d been deconstructing viruses and worms and\nhad seen so many malicious programs during that time that it was hard to get\nexcited about them anymore. But this one was different. An attack on a PLC was\nunprecedented and had the potential to usher in an entirely new breed of\nmalicious attacks.\n\nDespite his excitement, he knew the road ahead was filled with hurdles. The\nSiemens .DLL that Stuxnet replaced was huge, and the structure of the Step 7\nsoftware and the PLCs it controlled was largely undocumented. Falliere and\nChien were completely in the dark about how the system worked, and the\ntechnical challenges of deciphering the payload were going to be formidable.\nWhat’s more, there was no guarantee they’d even crack it. There were so many\nthings Falliere didn’t know at this point. But one thing he did know was that\nhe was in for a long and exhausting ride.\n\nFALLIERE WAS TWENTY-EIGHT, with the dark, Gallic looks of someone who seemed\nlike he’d be more at home DJing trance music in an underground Paris nightclub\nthan poring over reams of printed computer code during a commute on the Métro.\nIn reality, he was fairly shy and reserved, and sifting through dense computer\ncode was in fact a much bigger draw to him than spending sweaty nights in a\nthrobbing club.\n\nFalliere was a master reverse-engineer who specialized in deep-dive analysis\nof malicious code. Reverse-engineering is a bit of a dark art that involves\ntaking the binary language of ones and zeroes that a computer can read and\ntranslating it back to a programming language that humans can read. It\nrequires a lot of intense focus and skill, particularly with code as complex\nas Stuxnet. But Falliere didn’t mind. The more complicated the code, the more\nsatisfying it was when he finally cracked it.\n\nHe first honed his skills as a teenager in France breaking “crackme”\nfiles—code games that programmers wrote for one another to test their reverse-\nengineering skills. Coders would write small programs coated in an encrypted\nshell, and reverse-engineers would have to crack it open and bypass other\nprotections to unearth the secret message hidden inside, then send it back to\nthe author to prove that they had solved it. Viruses and worms were just\nanother type of crackme file in one sense, though some were more sophisticated\nthan others. The only difference now was that Falliere got paid to crack them.\n\nFalliere was born and raised near Toulouse in southern France, home of the\nAirbus aerospace corporation and a center for satellite technology. In a\nregion dominated by engineers, aeronautical and otherwise, it seemed natural\nthat Falliere would be drawn to technology. But his early influences actually\nveered toward the mechanical. His father was an automobile mechanic who owned\nand operated his own garage. Falliere’s introduction to computers in high\nschool, however, led him in a different direction—to study computer science at\nthe National Institute for Applied Sciences in France. The spread of the\nprolific Code Red worm in 2001, which struck more than 700,000 machines, got\nhim interested in computer security. While still in college, he wrote several\nsecurity articles for a small French technical magazine, as well as a paper\nfor SecurityFocus, a security website that Symantec\nowned.[1](part0012.html#c08-ftn1) In late 2005 while doing his master’s\nprogram in computer science, he was told he needed a six-month internship\nunder his belt to complete it. So he reached out to his contacts at\nSecurityFocus, who referred him to Chien. The timing couldn’t have been more\nfortuitous. Symantec was still in the midst of its Dublin hiring spree, and\nChien was desperate to find experienced reverse-engineers. He told Falliere\nthat rather than a six-month internship at Symantec he could offer him a full-\ntime job instead. “How much do you want to make?” he asked Falliere.\n\n“I don’t need any money,” Falliere told him. “Just an internship.”\n\n“Are you crazy?” Chien replied. “I’ll send you an offer in an e-mail. Just\naccept it.”\n\nA few weeks later, Falliere was settled in Dublin. He adjusted to his new life\nfairly quickly, but after two years of constant plane rides back to France to\nsee his girlfriend, he asked for a transfer to Paris, where Symantec had a\nsales and marketing office. He turned out to be the only technical person in\nthe office, which left him feeling isolated at times, but also helped focus\nhim on his work.\n\nHis desk, in an office shared with two colleagues, was an orchestrated mess of\ntechnical papers and books scattered around a test machine that he used to run\nmalware and a laptop containing the debugger software that he used to analyze\ncode. A cylinder-shaped Rubik’s puzzle was the only personal item on the desk,\nwhich he fingered like worry beads whenever he butted up against an unwieldy\npatch of code that resisted cracking.\n\nThough Falliere was a whiz at reverse-engineering, he was actually doing very\nlittle of it when Stuxnet came along. Over time, he’d become Symantec’s de-\nfacto tool guy, whipping together programs and tools to make deciphering\nmalware more efficient for other analysts. The job snuck up on him over time.\nHe began by tweaking forensic tools for himself that he found clunky and\ninefficient, then began doing it for colleagues as well, even creating new\ntools after they began submitting requests. Eventually, he was spending more\ntime working on tools than deciphering code. He only jumped on the occasional\nmalware threat if Chien made a special request, which he did in the case of\nStuxnet.\n\nFALLIERE BEGAN HIS analysis of the payload by studying the Siemens Step 7\nsoftware. The Step 7 software that Stuxnet attacked was Siemens’s proprietary\napplication for programming its S7 line of PLCs. It ran on top of the Windows\noperating system and allowed programmers to write and compile commands, or\nblocks of code, for the company’s PLCs. The system wasn’t complete without the\nSimatic WinCC program, a visualization tool used for monitoring the PLCs and\nthe processes they controlled. PLCs, connected to monitoring stations via a\nfacility’s production network, were in a constant state of chatter with the\nmachines, sending frequent status reports and updates to give operators a\nreal-time view of whatever equipment and operations the PLC controlled. The\nSiemens .DLL was central to both the Step 7 and WinCC programs, serving as\nmiddleman to create commands for the PLCs or receive status reports from them.\nThat’s where Stuxnet’s rogue .DLL came in. It did everything the real .DLL was\ndesigned to do, and more.\n\nTo understand how the doppelgänger .DLL worked, Falliere had to first\nunderstand how the Step 7 system and the legitimate .DLL worked. He searched\nonline for experts to consult, and even thought about reaching out to Siemens\nfor help, but he didn’t know whom to call there. The Step 7 .DLL was just one\nin a galaxy of .DLLs the Siemens software used, and to locate the two or three\nprogrammers behind the code who knew it well enough to help would take just as\nlong as it would take for him to figure it out on his own. And in the end,\nthere was a certain amount of pride to be had in cracking it himself.\n\nTo reverse the .DLL files—the original and the doppelgänger—Falliere opened\nthem in a disassembler, a tool designed for translating binary code into\nassembly language, which was one step back from binary. The disassembler\nallowed him to add notations and comments to the code or rearrange sections to\nmake it easier to read. He worked on small bits of code at a time, labeling\neach with a description of the function it performed as he went along.\n\nAs researchers typically did when examining complex malware like this,\nFalliere combined static analysis (viewing the code on-screen in a\ndisassembler/debugger) with dynamic analysis (observing it in action on a test\nsystem, using the debugger to stop and start the action so he could match\nspecific parts of the code with the effect it was having on the test machine).\nThe process could be excruciatingly slow under the best of circumstances,\nsince it required jumping back and forth between the two machines, but it was\nall the more difficult with Stuxnet due to its size and complexity.\n\nIt took two weeks of documenting every action the .DLL took before Falliere\nfinally confirmed what he’d suspected all along, that Stuxnet was kidnapping\nthe Siemens .DLL and putting the doppelgänger in its place to hijack the\nsystem. It did this by changing the name of the Siemens .DLL from s7otbxdx.DLL\nto s7otbxsx.DLL and installing the rogue .DLL with the original’s name in its\nplace, essentially stealing its identity. Then when the system called up the\nSiemens .DLL to perform any action, the malicious .DLL answered instead.\n\nOnce the rogue .DLL was in place, what it did was quite remarkable.\n\nWhenever an engineer tried to send commands to a PLC, Stuxnet made sure its\nown malicious command code got sent and executed instead. But it didn’t just\noverwrite the original commands in a simple swap. Stuxnet increased the size\nof the code block and slipped its malicious code in at the front end. Then to\nmake sure its malicious commands got activated instead of the legitimate ones,\nStuxnet also hooked a core block of code on the PLC that was responsible for\nreading and executing commands. A lot of knowledge and skill were required to\ninject the code seamlessly in this way without “bricking” the PLCs (that is,\ncausing them to seize up or become nonfunctional), but the attackers pulled it\noff beautifully.\n\nThe second part of the attack was even more ingenious. Before Stuxnet’s\nmalicious commands went into action, the malware sat patiently on the PLC for\nabout two weeks, sometimes longer, recording legitimate operations as the\ncontroller sent status reports back to monitoring stations. Then when\nStuxnet’s malicious commands leapt into action, the malware replayed the\nrecorded data back to operators to blind them to anything amiss on the\nmachines—like a Hollywood heist film where the thieves insert a looped video\nclip into surveillance camera feeds. While Stuxnet sabotaged the PLC, it also\ndisabled automated digital alarms to prevent safety systems from kicking in\nand halting whatever process the PLC was controlling if it sensed the\nequipment was entering a danger zone. Stuxnet did this by altering blocks of\ncode known as OB35 that were part of the PLC’s safety system. These were used\nto monitor critical operations, such as the speed of a turbine the PLC was\ncontrolling. The blocks were generated every 100 milliseconds by the PLC so\nthat safety systems could kick in quickly if a turbine began spinning out of\ncontrol or something else went wrong, allowing the system or an operator to\nset off a kill switch and initiate a shutdown. But with Stuxnet modifying the\ndata the safety system relied on, the system was blind to dangerous conditions\nand never had a chance to act.[2](part0012.html#c08-ftn2)\n\nThe attack didn’t stop there, however. If programmers noticed something amiss\nwith a turbine or other equipment controlled by the PLC and tried to view the\ncommand blocks on the PLC to see if it had been misprogrammed, Stuxnet\nintervened and prevented them from seeing the rogue code. It did this by\nintercepting any requests to read the code blocks on the PLC and serving up\nsanitized versions of them instead, minus the malicious commands. If a\ntroubleshooting engineer tried to reprogram the device by overwriting old\nblocks of code on the PLC with new ones, Stuxnet intervened and infected the\nnew code with its malicious commands too. A programmer could reprogram the PLC\na hundred times, and Stuxnet would swap out the clean code for its modified\ncommands every time.\n\nFalliere was stunned by the attack’s complexity—and by what it implied. It was\nsuddenly clear that Stuxnet wasn’t trying to siphon data out of the PLC to spy\non its operations, as everyone had originally believed. The fact that it was\ninjecting commands into the PLC and trying to hide that it was doing so while\nat the same time disabling alarms was evidence that it was designed not for\nespionage but for sabotage.\n\nBut this wasn’t a simple denial-of-service attack either. The attackers\nweren’t trying to sabotage the PLC by shutting it down—the PLC remained fully\nfunctional throughout the attack—they were trying to physically destroy\nwhatever process or device was on the other end of the PLC. It was the first\ntime Falliere had seen digital code used not to alter or steal data but to\nphysically alter or destroy something on the other end of it.\n\nIt was a plot straight out of a Hollywood blockbuster film. A Bruce Willis\nblockbuster, to be exact. Three years earlier, _Live Free or Die Hard_ had\nimagined such a destructive scenario, albeit with the typical Hollywood flair\nfor bluster and creative license. In the film, a group of cyberterrorists, led\nby a disgruntled former government worker, launch coordinated cyberattacks to\ncripple the stock market, transportation networks, and power grids, all to\ndistract authorities from their real aim—siphoning millions of dollars from\ngovernment coffers. Chaos ensues, along with the requisite _Die Hard_\nexplosions.\n\nBut Hollywood scenarios like this had long been dismissed by computer security\npros as pure fantasy. A hacker might shut down a critical system or two, but\nblow something up? It seemed improbable. Even most of the explosions in _Die\nHard_ owed more to physical attacks than to cyber ones. Yet here was evidence\nin Stuxnet that such a scenario might be possible. It was leaps and bounds\nbeyond anything Falliere had seen before or had expected to find in this code.\n\nFor all of its size and success, Symantec was in the end just a nerdy company,\nin the business of protecting customers. For fifteen years the adversaries\nthey had battled had been joy-riding hackers and cybercriminals or, more\nrecently, nation-state spies hunting corporate and government secrets. All of\nthem were formidable opponents to varying degrees, but none were bent on\ncausing physical destruction. Over the years, malware had gone through a\ngradual evolution. In the early days, the motivations of malware writers\nremained pretty much the same. Though some programs were more disruptive than\nothers, the primary goal of virus writers in the 1990s was to achieve glory\nand fame, and a typical virus payload included shout-outs to the hacker’s\nslacker friends. Things changed as e-commerce took hold and hacking grew into\na criminal enterprise. The goal wasn’t to gain attention anymore but to remain\nstealthy in a system for as long as possible to steal credit card numbers and\nbank account credentials. More recently, hacking had evolved into a high-\nstakes espionage game where nation-state spies drilled deep into networks to\nremain there for months or years while silently siphoning national secrets and\nother sensitive data.\n\nBut Stuxnet went far beyond any of these. It wasn’t an evolution in malware\nbut a revolution. Everything Falliere and his colleagues had examined before,\neven the biggest threats that targeted credit card processors and Defense\nDepartment secrets, seemed minor in comparison. Stuxnet thrust them into an\nentirely new battlefield where the stakes were much higher than anything they\nhad dealt with before.\n\nThere had long been a story floating around that suggested something like this\nmight have occurred before, but the tale has never been substantiated.\nAccording to the story, in 1982 the CIA hatched a plot to install a logic bomb\nin software controlling a Russian gas pipeline in order to sabotage it. When\nthe code kicked in, it caused the valves on the pipeline to malfunction. The\nresult was an explosive fireball so fierce and large that it was caught by the\neyes of orbiting satellites.[3](part0012.html#c08-ftn3)\n\nBack in Culver City, Chien wondered if there had been unexplained explosions\nin Iran that could be attributed to Stuxnet. When he searched the news\nreports, he was startled to find a number of them that had occurred in recent\nweeks.[4](part0012.html#c08-ftn4) Toward the end of July, a pipeline carrying\nnatural gas from Iran to Turkey had exploded outside the Turkish town of\nDogubayazit, several miles from the Iranian border. The blast, which shattered\nwindows of nearby buildings, left a raging blaze that took hours to\nextinguish.[5](part0012.html#c08-ftn5)\n\nAnother explosion occurred outside the Iranian city of Tabriz, where a\n1,600-mile-long pipeline delivered gas from Iran to Ankara. Yet a third\nexplosion ripped through a state-run petrochemical plant on Kharg Island in\nthe Persian Gulf and killed four people.[6](part0012.html#c08-ftn6) Weeks\nlater, a fourth gas explosion occurred at the Pardis petrochemical plant in\nAsalouyeh, killing five people and injuring three.[7](part0012.html#c08-ftn7)\nIt occurred just a week after Iranian president Mahmoud Ahmadinejad had\nvisited the plant.\n\nThe explosions didn’t all go unexplained. Kurdish rebels claimed\nresponsibility for the ones at Dogubayazit and Tabriz, and the Iranian news\nagency, IRNA, attributed the Kharg Island fire to high-pressure buildup in a\ncentral boiler.[8](part0012.html#c08-ftn8) The explosion at Pardis was blamed\non a leak of ethane that ignited after workers began welding a pipeline. But\nwhat if one or more of the explosions had actually been caused by Stuxnet?\nChien wondered.\n\nThis was much more than anyone on the team had bargained for when they first\nbegan deconstructing Stuxnet weeks earlier. If Stuxnet was doing what Chien\nand his colleagues thought it was doing, then this was the first documented\ncase of cyberwarfare.\n\nChien, O’Murchu, and Falliere convened on the phone to discuss their options.\nThey still didn’t know what exactly Stuxnet was doing to the PLC or even the\nidentity of its target, but they knew they had to reveal what they’d learned\nabout its payload so far. So on August 17, 2010, they went public with the\nnews that Stuxnet wasn’t an espionage tool as everyone had believed but a\ndigital weapon designed for sabotage. “Previously, we reported that Stuxnet\ncan steal code … and also hide itself using a classic Windows rootkit,”\nFalliere wrote in his typical understated tone, “but unfortunately it can also\ndo much more.”[9](part0012.html#c08-ftn9)\n\nTo illustrate Stuxnet’s destructive capability, they referenced the 1982\nattack on the Siberian pipeline. Their words had been carefully parsed by the\ncompany’s PR team, but there was no denying the shocking nature of what they\nimplied. As soon as the post went public, they waited on edge for the\ncommunity’s response. But instead of the dramatic reaction they thought they\nwould get, all they got in return was, in Chien’s words, “silence like\ncrickets.”\n\nChien was confused by the lack of response. After all, they were talking about\ndigital code that was capable of blowing things up. They had assumed, at the\nvery least, that once they published their findings, other researchers would\npublish their own research on Stuxnet. That was the way malware research\nworked—whenever new attack code was uncovered, teams of competing researchers\nat different firms worked to decipher the code simultaneously, each one racing\nto be the first to publish their results. As soon as one team published, the\nothers quickly weighed in to deliver their own findings. If multiple groups\narrived at the same results, the duplicate work served as an informal peer-\nreview process to validate all of their findings. The silence that greeted\ntheir post about Stuxnet, then, was unusual and disconcerting—Chien began to\nwonder if they were the only team examining the payload or if anyone else even\ncared about it.\n\nFor a brief moment, he questioned their decision to devote so much time to the\ncode. Had everyone else seen something that made them dismiss it as\ninsignificant, something that Chien and his team had completely missed? But\nthen he reviewed everything they had discovered in the past few weeks. There\nwas no possible way they could have been wrong about the code, he\nconcluded—either about Stuxnet’s importance or its aggressive intentions.\n\nAs for continuing their research, there was no question anymore that they had\nto press on. If anything, their work on the code seemed more urgent than\nbefore. They had just announced to the world that Stuxnet was a digital weapon\ndesigned for physical destruction. But they still hadn’t identified the\nmalware’s target. Having made a public declaration about the code’s\ndestructive aim, they worried that the attackers might suddenly feel pressure\nto accelerate the mission and destroy their target. That is, if they hadn’t\nalready done so.\n\nAnd apparently, they weren’t the only ones concerned about the possibility of\nthings blowing up. Five days after they published their announcement, the\nsteady stream of traffic still coming into their sinkhole from Stuxnet-\ninfected machines in Iran suddenly went dark. It seemed that someone in the\nIslamic Republic had taken note of their news. To prevent the attackers or\nanyone else from remotely accessing the infected machines and doing some\ndamage, someone in Iran had finally got wise and given the order to sever all\noutbound connections from machines in that country to Stuxnet’s two command-\nand-control domains.\n\n* * *\n\n[1](part0012.html#c08-ftn1a) Symantec acquired SecurityFocus in 2002.\n\n[2](part0012.html#c08-ftn2a) There was very little whimsy in Stuxnet or\nanything that seemed superfluous. But in the part of the code responsible for\nintercepting the OB35 blocks, the attackers had placed a “magic marker” (a\nvalue placed in code that signifies a condition or triggers an action) that\nseemed like a bit of an inside joke—0xDEADF007. The marker was the hexadecimal\nrepresentation of a number. When Stuxnet checked conditions on the system it\nwas sabotaging to determine when it should start disabling the safety system,\na magic marker was produced to indicate when conditions were right to disable\nthe system. The attackers could have chosen any random number—1234—but chose\none that when written in hexadecimal produced a word and numbers—DEADF007. It\nwasn’t uncommon for programmers to use whimsical values in their code to spell\nwords in hexadecimal. For example, the first four bytes of Java class files\ntranslate to “0xCAFEBABE” in hexadecimal. 0xDEADBEEF is another hexadecimal\nvalue that in hacker-speak refers to a software crash. So Chien wondered if\n0xDEADF007 in Stuxnet might actually mean “dead fool”—a derogatory way to\nindicate when the safety system was no longer functional—or “dead foot.” Dead\nfoot is an expression used by airplane pilots to refer to an engine failure,\n“Dead foot, dead engine” being the maxim to help pilots realize quickly in a\nstressful situation that when a foot pedal is dead it means an engine is\nout—the pilot essentially has no control of the engine. Similarly “DEADF007”\nin Stuxnet signaled the point at which operators in Iran lost control of their\nPLCs while Stuxnet was sabotaging them, preventing both the safety system from\ninitiating its own automatic shutdown or operators from stepping in to do an\nemergency manual shutdown. It made Chien wonder if one or more of Stuxnet’s\nauthors were pilots.\n\n[3](part0012.html#c08-ftn3a) For more on the story of the alleged pipeline\nsabotage, see [this page](part0015.html#c11-01).\n\n[4](part0012.html#c08-ftn4a) Con Coughlin, “Who’s Blowing up Iran’s Gas\nPipelines?” _The Telegraph_ , August 18, 2010, available at\n[blogs.telegraph.co.uk/news/concoughlin/100050959/whos-blowing-up-irans-gas-\npipelines](http://www.blogs.telegraph.co.uk/news/concoughlin/100050959/whos-\nblowing-up-irans-gas-pipelines).\n\n[5](part0012.html#c08-ftn5a) Agence France-Presse, “Suspected Kurd Rebels Blow\nup Iran–Turkey Gas Pipeline,” July 21, 2010, available at\n[institutkurde.org/en/info/latest/suspected-kurd-rebels-blow-up-iran-turkey-\ngas-pipeline-2372.html](http://www.institutkurde.org/en/info/latest/suspected-\nkurd-rebels-blow-up-iran-turkey-gas-pipeline-2372.html).\n\n[6](part0012.html#c08-ftn6a) “Petrochemical Factory Blast Kills 4 in Iran,”\nAssociated Press, July 25, 2010, available at\n[gainesville.com/article/20100725/news/100729673](http://www.gainesville.com/article/20100725/news/100729673).\n\n[7](part0012.html#c08-ftn7a) “Explosion in Petrochemical Complex in Asalouyeh\nKills 5,” Tabnak News Agency, August 4, 2010, available at\n[tabnak.ir/en/news/180](http://www.tabnak.ir/en/news/180).\n\n[8](part0012.html#c08-ftn8a) Ivan Watso and Yesim Comert, “Kurdish Rebel Group\nClaims Responsibility for Gas Pipeline Blast,” CNNWorld, July 21, 2010,\navailable at [articles.cnn.com/2010-07-21/world/turkey.pipeline.blast_1_pkk-\nkurdistan-workers-party-ethnic-kurdish-\nminority?_s=PM:WORLD](http://www.articles.cnn.com/2010-07-21/world/turkey.pipeline.blast_1_pkk-\nkurdistan-workers-party-ethnic-kurdish-minority?_s=PM:WORLD).\n\n[9](part0012.html#c08-ftn9a) Nicolas Falliere, “Stuxnet Introduces the First\nKnown Rootkit for Industrial Control Systems,” Symantec blog, August 6, 2010,\navailable at [symantec.com/connect/blogs/stuxnet-introduces-first-known-\nrootkit-industrial-control-\nsystems](http://www.symantec.com/connect/blogs/stuxnet-introduces-first-known-\nrootkit-industrial-control-systems). Note that the date on the blog post is\nAugust 6, but that’s the date the post was first published with news of the\nPLC rootkit. They updated it when they added the news that Stuxnet was bent on\nsabotage.\n\n\n# CHAPTER 9\n\n# **INDUSTRIAL CONTROLS OUT OF CONTROL**\n\nFifty miles outside Idaho Falls, Idaho, on a vast desert prairie owned by the\nDepartment of Energy’s Idaho National Lab, a handful of engineers shivered\nagainst the cold as they paced around a generator the size of a small bus\nparked on a slab of concrete. It was March 4, 2007, and the workers were\nmaking final safety checks for a groundbreaking test they were about to\nconduct.\n\nAbout a mile away at the lab’s visitor’s center, a group of officials from\nWashington, DC, as well as executives from the power industry and NERC, the\nNorth American Electric Reliability Corporation, gathered in a theater warming\ntheir hands around cups of steaming coffee as they waited for a live feed of\nthe demo to begin.\n\nIn 2010, when the Symantec researchers discovered that Stuxnet was designed to\nsabotage Siemens PLCs, they believed it was the first documented case in which\ndigital code had been used to physically destroy equipment. But three years\nearlier, on this Idaho plain, the Aurora Generator Test had demonstrated the\nviability of such an attack.\n\nIt was around eleven thirty a.m. that March day when a worker back in Idaho\nFalls got the signal to launch a stream of vicious code against the target. As\nthe generator’s 5,000-horsepower diesel engine roared over speakers in the\nlab’s small theater, the spectators stared intently at a screen searching for\nsigns of the code’s effects. At first, there were none. But then they heard a\nloud snap, like a heavy chain slapping against a metal drum, and the steel\nbehemoth rattled briefly as if shaken awake. Several seconds passed and they\nheard another snap—this time the generator lurched and shuddered more\nviolently as if jolted by a defibrillator. Bolts and bits of rubber grommet\nejected from its bowels toward the camera, making the observers wince. About\nfifteen seconds passed before another loud snap sent the machine lurching\nagain. This time, after the vibrations subsided, the generator spit out a puff\nof white smoke. Then suddenly, _bam!_ the machine heaved again before coming\nto a final rest. After a lengthy pause, when it seemed the beast might have\nsurvived the assault, a plume of angry black smoke billowed from its chambers.\n\nOnly three minutes had elapsed since the test began, but that was all it took\nto reduce the colossal machine to a smoldering, lifeless mess of metal and\nsmoke. When it was all done, there was no applause in the theater, just\nstunned silence. To rock a piece of equipment the size of a tank should have\nrequired exceptional force. Yet all it had taken in this case was twenty-one\nlines of malicious code.\n\nThe test had been exhaustively planned and modeled for weeks, yet the force\nand violence of the attack still took its engineers by surprise—“a moment of\nincredible vividness,” Michael Assante, one of the architects of the test,\nsaid.[1](part0013.html#c09-ftn1) It was one thing to simulate an attack\nagainst a small motor perched atop a table, but quite another to watch a\ntwenty-seven-ton machine bounce like a child’s toy and fly apart.\n\nThe test provided certified proof that a saboteur didn’t need physical access\nto destroy critical equipment at a power plant but could achieve the same\nresult remotely with just a piece of well-crafted code. Three years later,\nwhen Stuxnet was found on machines in Iran, no one who worked on the Aurora\nproject was surprised that a digital attack could cause physical destruction.\nThey were only surprised that it had taken so long for such an attack to show\nup.\n\nWHEN THE SYMANTEC researchers discovered in August 2010 that Stuxnet was\ndesigned for physical sabotage of Siemens PLCs, they weren’t the only ones who\nhad no idea what a PLC was. Few people in the world had ever heard of the\ndevices—this, despite the fact that PLCs are the components that regulate some\nof the most critical facilities and processes in the world.\n\nPLCs are used with a variety of automated control systems that include the\nbetter-known SCADA system (Supervisory Control and Data Acquisition) as well\nas distributed control systems and others that keep the generators, turbines,\nand boilers at power plants running smoothly.[2](part0013.html#c09-ftn2) The\nsystems also control the pumps that transmit raw sewage to treatment plants\nand prevent water reservoirs from overflowing, and they open and close the\nvalves in gas pipelines to prevent pressure buildups that can cause deadly\nruptures and explosions, such as the one that killed eight people and\ndestroyed thirty-eight homes in San Bruno, California, in 2010.\n\nThere are less obvious, but no less critical, uses for control systems as\nwell. They control the robots on car assembly lines and dole out and mix the\nproper portion of ingredients at chemical and pharmaceutical plants. They’re\nused by food and beverage makers to set and monitor temperatures for safely\ncooking and pasteurizing food to kill deadly bacteria. They help maintain\nconsistent temperatures in the furnaces and kilns where glass, fiberglass, and\nsteel are made to ensure the integrity of skyscrapers, cars, and airplanes.\nThey also control traffic lights, open and close cell doors at high-security\nfederal prisons, and raise and lower bridges on highways and waterways. And\nthey help route commuter trains and freight trains and prevent them from\ncrashing. On a smaller scale, they control the elevators in high-rise\nbuildings and the heating and air conditioning in hospitals, schools, and\noffices. In short, control systems are the critical components that keep\nindustries and infrastructures around the world functioning properly. They\nneed to be reliable and secure. Yet, as Stuxnet clearly showed, they are\nanything but.\n\nAnd now with that code available in the wild for anyone to study and copy, the\ndigital weapon can serve as a blueprint to design other attacks targeting\nvulnerable control systems in the United States and elsewhere—to manipulate\nvalves in a gas pipeline, for example, or to release sewage into waterways, or\npossibly even to take out generators at a power plant. It wouldn’t necessarily\nrequire the resources of a wealthy nation to pull off such attacks. With most\nof the core research and development already done by Stuxnet’s creators to\nexpose the vulnerabilities in these systems, the bar has been lowered for\nother attackers, state and nonstate players alike, to get in the game. From\nanarchic hacker groups like Anonymous and LulzSec to extortionists looking to\nhold the controls of a power plant hostage to hackers-for-hire working for\nterrorist groups, the door is now open for a variety of attackers who never\nhave to venture beyond their borders, or even their bedrooms, to launch an\nassault. And although Stuxnet was a surgical attack targeting specific\nmachines while leaving others untouched, not all attacks would be so targeted\nor skilled, raising the possibility of assaults that create widespread\ndisruption or damage—whether intentionally or not.\n\nAttackers wouldn’t need to design a sophisticated worm like Stuxnet, either.\nAn ordinary run-of-the-mill virus or worm can have detrimental effects as\nwell.[3](part0013.html#c09-ftn3) In 2003, train-signaling systems on the East\nCoast went dark after computers belonging to CSX Corporation in Florida got\ninfected with the Sobig virus. CSX operates rail systems for passenger and\nfreight trains in twenty-three states, and as a result of the signals going\nout, trains running between Pennsylvania and South Carolina and in the DC\nBeltway had to be halted.[4](part0013.html#c09-ftn4) Similarly, the Slammer\nworm took out the safety monitoring system and process control network at the\nDavis-Besse nuclear power plant in Ohio for about five hours that same\nyear.[5](part0013.html#c09-ftn5)\n\nOn a scale of one to ten measuring the preparedness of US critical\ninfrastructure to withstand a destructive cyberassault, one being least\nprepared and ten being most prepared, NSA Director Gen. Keith Alexander told a\nSenate committee in 2013 that the nation is at three, due in part to the lack\nof security with control systems.[6](part0013.html#c09-ftn6)\n\n“We’ve been working on offensive cyber capabilities for more than a decade in\nthe Department of Defense,” Jim Lewis of the Center for Strategic and\nInternational Studies has said. “But … I think people … just don’t realize\nthat behind the scenes, there’s this new kind of vulnerability that really\nputs a lot of things at risk.”[7](part0013.html#c09-ftn7)\n\nIn truth, the problems with control systems are not new; Stuxnet just exposed\nthem for the first time to the public. But some control-systems experts had\nknown about them for years.\n\nPLCS WERE FIRST developed in the 1960s, when computer hackers and viruses were\nstill the stuff of science fiction.[8](part0013.html#c09-ftn8) They were\ndesigned for the automotive industry to replace hardwired relay logic systems\nthat controlled the assembly lines on factory floors. With hardwired relay\nsystems, the only way to make an adjustment to a line was to send an\nelectrician to physically rewire the relays. PLCs made it easy to update the\nsystems with just a few hundred lines of code, though technicians still had to\nupdate the systems in person, traveling out to devices in the field to upload\nthe commands from a tape cartridge.\n\nAs the use of digital control systems grew in the ’90s, operators pressured\nvendors to provide them with the ability to log into systems remotely via\ndial-up modem. Hackers were by then becoming legion, but operators still\nweren’t concerned about the security of their systems, because control systems\nran on standalone networks, using custom protocols to communicate and having\nproprietary software that was incompatible with other programs and systems.\nYou couldn’t just plug any computer into a control system and communicate with\nit. And even if you did have a system that could talk to the machines, the\nuniverse of people who understood how control systems worked and had the\nability to manipulate them was small.\n\nAll of this began to change in the late ’90s, however. Congress passed\nenvironmental laws requiring companies to monitor and control their factory\nemissions, and the Federal Energy Regulatory Commission began to require\naccess to electricity transmission systems to monitor their output and\ndistribution. Suddenly compliance officers and corporate executives demanded\naccess to data and systems that were previously accessible only to plant\noperators. Out went proprietary operating systems that no one could\ncommunicate with or understand, and in came control systems that ran on\ncommercial operating systems, such as Windows and Linux, making it easy for\nother computers on a company’s corporate network to connect and communicate\nwith them. The switch to Windows, however, meant that control systems were now\nvulnerable to the same viruses and worms that plagued personal PCs. And as the\nsystems became increasingly connected to the internet, or to dial-up modems to\nmake them remotely accessible to operators, they also became increasingly\nvulnerable to remote attack from hackers.\n\nIn March 1997, a teenage hacker in Massachusetts who went by the name “Jester”\ngave a small preview of what could occur when he dialed into the Bell Atlantic\ncomputer system via modem and knocked out systems that managed phone and radio\ncommunications for the air traffic control tower at Worcester Airport, as well\nas phone service for six hundred homes in a nearby town. Communications for\nthe airport’s security and fire departments were down for six hours, as was\nthe system pilots used to activate the runway lights. Air traffic controllers\nhad to use cell phones and battery-powered radios to direct planes during the\noutage.[9](part0013.html#c09-ftn9) No accidents occurred, but an air traffic\ncontrol manager told CNN, “We dodged a bullet that\nday.”[10](part0013.html#c09-ftn10)\n\nThat same year, the specially convened Marsh Commission published a report\nexamining the vulnerability of critical infrastructure systems to attack—both\nphysical and digital. The commission had been charged with investigating the\nmatter after Timothy McVeigh blew up a federal building in Oklahoma City in\n1995 and took out a number of key data and communication centers in the\nprocess. The commissioners warned of the increasing perils created from\nconnecting critical systems for oil, gas, and electricity to the internet.\n“The capability to do harm … is growing at an alarming rate; and we have\nlittle defense against it,” they wrote. The right commands sent over a network\nto a power-generating station’s control computer, they wrote, “could be just\nas devastating as a backpack full of explosives.… We should attend to our\ncritical foundations before we are confronted with a crisis, not after.\nWaiting for disaster would prove as expensive as it would be\nirresponsible.”[11](part0013.html#c09-ftn11)\n\nA second report released the same year by the White House National Security\nTelecommunications Advisory Committee warned that the nation’s power grid and\nthe utilities feeding it were pockmarked with security holes that made them\nvulnerable to attack. “An electronic intruder … could dial into an unprotected\nport and reset the breaker to a higher level of tolerance than the device\nbeing protected by the breaker can withstand,” investigators wrote,\nanticipating the Aurora Generator Test a decade before it occurred. “By doing\nthis, it would be possible to physically destroy a given piece of equipment\nwithin a substation.”[12](part0013.html#c09-ftn12)\n\nDespite these early warnings, there were no signs yet that anyone was\ninterested in conducting such attacks. That is until 2000, when a former\nworker sabotaged the pumps at a water treatment plant in Australia, in what is\nconsidered to be the first publicly reported case of an intentional control-\nsystem hack.\n\nMAROOCHY SHIRE ON Queensland’s Sunshine Coast is the kind of place made for\npicture postcards, with a lush rain forest, rugged volcanic peak, and azure\ncoastal waters bordered by white sandy beaches. But in early 2000, the shire’s\nbeauty took an ugly turn when, over the course of four months, a hacker caused\nmore than 750,000 gallons of raw sewage to spill from a number of wells and\npour into public waterways.\n\nAt first it was just a small amount of sewage spilling from a well at the\nHyatt Regency Hotel into a lagoon on the five-star resort’s PGA golf course.\nBut after workers cleaned it up, the well overflowed again and again. The\nworst spills occurred, however, in Pacific Paradise, a suburb along the\nMaroochy River. Here several hundred thousand gallons of sewage poured into a\ntidal canal, endangering the health of children playing in backyards abutting\nthe canal, and into the Maroochy River itself, where it killed off fish and\nother marine life.\n\nThe problems began on New Year’s Eve 1999, after Maroochy Water Services\ninstalled a new digital management system. The treatment plant’s control\nsystem had been installed in stages by Hunter WaterTech, a contract firm, and\nwas just nearing completion when settings for the pump stations responsible\nfor moving sewage to the treatment plant began to mysteriously change. Pumps\nwould turn off or continue to run in defiance of operator instructions, and\nthe two-way radio network used to broadcast instructions to pump stations\nwould become clogged with traffic, preventing operators from communicating\nwith the stations. Alarms that should have sounded when things went awry\ndidn’t.[13](part0013.html#c09-ftn13)\n\nThe pumps were controlled by two central computers, using proprietary Hunter\nWaterTech software, which communicated with a remote terminal unit at each\npump station via two-way radio signals. Signals got transmitted from the\ncomputers to the RTUs, or between the RTUs, via repeater stations in the field\nthat operated on nonpublic frequencies. Only someone on the central computers\nor within range of a repeater station, using Hunter WaterTech proprietary\nsoftware and the proper communication protocols, could send commands to the\npumping stations. Hunter WaterTech initially suspected an outside hacker was\nbehind the attacks, but the water district had no intrusion-detection tools or\nlogging system in place to detect a breach. But even after they installed\nthese systems they were still unable to detect a breach.\n\nThe attacks continued on and off for weeks and reached a peak one night in\nMarch when more than two-dozen incidents occurred. Investigators finally\nconcluded it must be a rogue insider sending malicious commands in the field\nvia two-way radio signals.[14](part0013.html#c09-ftn14) They zeroed in on a\nformer contractor named Vitek Boden, a forty-nine-year-old engineer who had\nworked for Hunter WaterTech until his contract expired in December, around the\ntime the first water pump failed. Boden had subsequently sought a full-time\njob with the water district but was turned down in January—which coincided\nwith when the bulk of the problems began.\n\nSure enough, when police caught up with Boden one night in April after alarm\nsystems at four pump stations were disabled, they found a laptop in his car\nwith Hunter WaterTech’s proprietary software installed and a two-way radio set\nto the nonpublic frequency the water district used to communicate with pumping\nstations. They also found an RTU Boden had apparently used to send out the\nbogus commands.[15](part0013.html#c09-ftn15)\n\nBoden’s case was the first cyberattack against a critical infrastructure\nsystem to come to light, but it likely wasn’t the first to occur. Others no\ndoubt had simply gone undetected or unreported.[16](part0013.html#c09-ftn16)\nIn the wake of the Maroochy incident, workers from other utilities told\ninvestigators that they would never have pursued criminal charges against\nBoden as Maroochy had done, in order to keep the matter\nquiet.[17](part0013.html#c09-ftn17)\n\nThe case should have been a wake-up call to control-system operators around\nthe world, but many dismissed it because it involved an inside attacker who\nhad extensive knowledge of the Maroochy Shire system and access to the\nspecialized equipment needed to conduct the attack. No outsider could have\ndone what Boden did, they argued, ignoring a number of security problems with\nMaroochy’s control-system network that outsiders could have exploited to\nachieve similar attacks. Peter Kingsley, one of the investigators on the case,\nlater warned attendees at a control-system conference that although the\nMaroochy hack had been an inside job, breaches from outsiders were by no means\nimpossible. “Some utilities believe they’re protected because they themselves\ncan’t find an unauthorized way to access their systems,” he said. “But hackers\ndon’t restrict themselves to ordinary\ntechniques.”[18](part0013.html#c09-ftn18)\n\nKingsley’s words seemed quaint in 2002 because there were still few signs that\noutsiders were interested in hacking critical infrastructure systems. And in\nthe absence of any major disaster, the security of control systems simply\nwasn’t a concern.\n\nIt was around this time that Joe Weiss became an evangelist for control-system\nsecurity.\n\nWeiss is a lean and energetic sixty-four-year-old who works out of his home in\nCupertino, California, the heart of Silicon Valley, and is used to thinking\nabout catastrophic scenarios. He lives just five miles from California’s\nnotorious San Andreas Fault and the seventy-year-old Stevens Creek Dam. When\nthe Loma Prieta earthquake struck the area in 1989, chimneys toppled,\nstreetlights and phones died for several days, and shockwaves in the swimming\npool at nearby DeAnza College ejected polo players from the water and onto the\npavement like beached seals.\n\nWeiss first became aware of the security problems with control systems in\n1999. A nuclear engineer by training, he was working for the Electric Power\nResearch Institute when the Y2K issue arose. Armageddon warnings in the press\npredicted dystopian meltdowns when computer clocks struck midnight on New\nYear’s Eve because of a programming error that failed to anticipate the\nmillennial rollover to triple zeroes on January 1, 2000. Weiss began to\nwonder: if such a minor thing as a change of date could threaten to bring\ncontrol systems to a halt, what would more serious issues do? More important,\nif Y2K could accidentally cause huge problems, what might an intentional\nattack from hackers do?\n\nDozens of security conferences held around the world each year focused on\ngeneral computer security, but none of them addressed control systems. So\nWeiss began attending them to learn what security guidelines the control-\nsystem community should adopt. But the more conferences he attended, the more\nworried he got. When network administrators talked about using encryption and\nauthentication to prevent unauthorized users from accessing their systems,\nWeiss realized that control systems had none of the standard protections that\nnormal computer networks used. When security experts asked him what brand of\nfirewall control-system operators at energy plants used or how often they\nreviewed their network logs for evidence of intruders, Weiss had to reply, “We\ndon’t have firewalls. No network logs, either.”[19](part0013.html#c09-ftn19)\nAnd when he began to ask control-system makers about the security of their\nproducts, he got blank stares in response. They told him no one had ever asked\nabout security before.\n\nThen two planes struck the Twin Towers in September 2001 and not long\nafterward, authorities uncovered suspicious patterns of searches on government\nwebsites in California. The searchers appeared to be exploring digital systems\nused to manage utilities and government offices in the San Francisco region.\nThe activity, which appeared to originate from IP addresses in Saudi Arabia,\nIndonesia, and Pakistan, showed a particular interest in emergency phone\nsystems, power and water plants, and gas\nfacilities.[20](part0013.html#c09-ftn20) Other searches focused on programming\ncontrols for fire-dispatch systems and pipelines.\n\nThe following year, US forces in Kabul seized a computer in an al-Qaeda office\nand found models of a dam on it along with engineering software that could be\nused to simulate its failure.[21](part0013.html#c09-ftn21) That same year, the\nCIA issued a Directorate of Intelligence Memorandum stating that al-Qaeda had\n“far more interest” in cyberterrorism than previously believed and had begun\nto contemplate hiring hackers.\n\nThere were signs that others might be interested in US critical infrastructure\ntoo.[22](part0013.html#c09-ftn22) In 2001, hackers broke into servers at the\nCalifornia Independent System Operator, or Cal-ISO, a nonprofit corporation\nthat manages the transmission system for moving electricity throughout most of\nthe state. The attackers got in through two unprotected servers and remained\nundetected for two weeks until workers noticed problems with their\nmachines.[23](part0013.html#c09-ftn23) Cal-ISO officials insisted the breach\nposed no threat to the grid, but unnamed sources told the _Los Angeles Times_\nthat the hackers were caught just as they were trying to access “key parts of\nthe system” that would have allowed them to cause serious disruptions in\nelectrical service. One person called it a near “catastrophic breach.” The\nattack appeared to originate from China, and came in the midst of a tense\npolitical standoff between China and the United States after a US spy plane\ncollided in midair with a Chinese fighter jet over the South China Sea.\n\nIn response to growing concerns about critical infrastructure, and in\nparticular the security of the nation’s power grids, the Department of Energy\nlaunched a National SCADA Test Bed program in 2003 at the Idaho National Lab\n(INL). The goal was to work with the makers of control systems to evaluate\ntheir equipment for security vulnerabilities, and was an initiative that\nultimately led to the 2007 Aurora Generator Test.[24](part0013.html#c09-ftn24)\n\nThere are 2,800 power plants in the United States and 300,000 sites producing\noil and natural gas.[25](part0013.html#c09-ftn25) Another 170,000 facilities\nform the public water system in the United States, which includes reservoirs,\ndams, wells, treatment facilities, pumping stations, and\npipelines.[26](part0013.html#c09-ftn26) But 85 percent of these and other\ncritical infrastructure facilities are in the hands of the private sector,\nwhich means that aside from a few government-regulated industries—such as the\nnuclear power industry—the government can do little to force companies to\nsecure their systems. The government, however, could at least try to convince\nthe makers of control systems to improve the security of their products. Under\nthe test-bed program, the government would conduct the tests as long as the\nvendors agreed to fix any vulnerabilities uncovered by\nthem.[27](part0013.html#c09-ftn27)\n\nAround the same time, DHS also launched a site-assessment program through its\nIndustrial Control System Cyber Emergency Response Team (ICS-CERT) to evaluate\nthe security configuration of critical infrastructure equipment and networks\nalready installed at facilities. Between 2002 and 2009, the team conducted\nmore than 100 site assessments across multiple industries—oil and natural gas,\nchemical, and water—and found more than 38,000 vulnerabilities. These included\ncritical systems that were accessible over the internet, default vendor\npasswords that operators had never bothered to change or hard-coded passwords\nthat couldn’t be changed, outdated software patches, and a lack of standard\nprotections such as firewalls and intrusion-detection systems.\n\nBut despite the best efforts of the test-bed and site-assessment researchers,\nthey were battling decades of industry inertia—vendors took months and years\nto patch vulnerabilities that government researchers found in their systems,\nand owners of critical infrastructure were only willing to make cosmetic\nchanges to their systems and networks, resisting more extensive ones.\n\nWeiss, who worked as a liaison with INL to help develop its test-bed program,\ngot fed up with the inertia and launched a conference to educate critical-\ninfrastructure operators about the dangerous security problems with their\nsystems. In 2004, he resorted to scare tactics by demonstrating a remote\nattack to show them what could be done. The role of hacker was played by Jason\nLarsen, a researcher at INL, who demonstrated an attack against a substation\nin Idaho Falls from a computer at Sandia National Laboratory in New Mexico.\nExploiting a recently discovered vulnerability in server software, Larsen\nbypassed several layers of firewalls to hack a PLC controlling the substation\nand release his payload in several stages. The first stage opened and closed a\nbreaker. The second stage opened all of the breakers at once. The third stage\nopened all of the breakers but manipulated data sent to operator screens to\nmake it appear that the breakers were closed.\n\n“I call it my ‘wet pants’ demo,” Weiss says. “It was a phenomenal success.”\n\nWeiss followed the demo a few years later with another one and then another,\neach time enlisting different security experts to demonstrate different modes\nof attack. The only problem was, they were ahead of their time. Each time\nengineers would leave his conference fired up with ideas about improving the\nsecurity of their networks, they would run up against executives back home who\nbalked at the cost of re-architecting and securing the systems. Why spend\nmoney on security, they argued, when none of their competitors were doing it\nand no one was attacking them?\n\nBut what Weiss and the test lab couldn’t achieve in a decade, Stuxnet achieved\nin a matter of months. The digital weapon shone a public spotlight on serious\nvulnerabilities in the nation’s industrial control systems for the first time,\nand critical equipment that for so long had remained obscure and unknown to\nmost of the world now caught the attention of researchers and hackers, forcing\nvendors and critical-infrastructure owners to finally take note as well.\n\nTHE NEWS IN August 2010 that Stuxnet was sabotaging Siemens PLCs caught the\ninterest of a twenty-five-year-old computer security researcher in Austin,\nTexas, named Dillon Beresford. Beresford, like most people, had never heard of\nPLCs and was curious to see how vulnerable they might be. So he bought several\nSiemens PLCs online and spent two months examining and testing them in the\nbedroom of his small apartment. It took just a few weeks to uncover multiple\nvulnerabilities that he could use in an attack.\n\nHe discovered, for example, that none of the communication that passed between\na programmer’s machine and the PLCs was encrypted, so any hacker who broke\ninto the network could see and copy commands as they were transmitted to the\nPLCs, then later play them back to a PLC to control and stop it at will. This\nwould not have been possible had the PLCs rejected unauthorized computers from\nsending them commands, but Beresford found that the PLCs were promiscuous\ncomputers that would talk to any machine that spoke their protocol language.\nThey also didn’t require that commands sent to them be digitally signed with a\ncertificate to prove that they came from a trustworthy source.\n\nAlthough there was an authentication packet, or password of sorts, that passed\nbetween a Step 7 machine and the PLC, Beresford was able to decode the\npassword in less than three hours. He also found that he could simply capture\nthe authentication packet as it passed from a Step 7 machine to the PLC and\nreplay it in the same way he replayed commands, eliminating the need to decode\nthe password at all. Once he had control of a PLC, he could also issue a\ncommand to change the password to lock out legitimate\nusers.[28](part0013.html#c09-ftn28)\n\nBeresford found other vulnerabilities as well, including a back door that\nSiemens programmers had left in the firmware of their PLCs—firmware is the\nbasic software that is resident on hardware devices to make them work. Vendors\noften place global, hard-coded passwords in their systems to access them\nremotely to provide troubleshooting for customers—like an OnStar feature for\ncontrol systems. But backdoors that allow vendors to slip in also let\nattackers in.[29](part0013.html#c09-ftn29) The username and password for\nopening the Siemens back door was the same for every system—“ _basisk_ ”—and\nwas hard-coded into the firmware for anyone who examined it to see. Using this\nback door, an attacker could delete files from the PLC, reprogram it, or issue\ncommands to sabotage whatever operations the PLC\ncontrolled.[30](part0013.html#c09-ftn30)\n\nBeresford reported his findings to ICS-CERT, which worked with Siemens to get\nthe vulnerabilities fixed. But not all of them could be. Some, like the\ntransmission of unencrypted commands and the lack of strong authentication,\nwere fundamental design issues, not programming bugs, which required Siemens\nto upgrade the firmware on its systems to fix them or, in some cases, re-\narchitect them. And these weren’t just problems for Siemens PLCs; they were\nfundamental design issues that many control systems had, a legacy of their\npre-internet days, when the devices were built for isolated networks and\ndidn’t need to withstand attacks from outsiders.\n\nBeresford’s findings defied longstanding assertions by vendors and critical-\ninfrastructure owners that their systems were secure because only someone with\nextensive knowledge of PLCs and experience working with the systems could\nattack them. With $20,000 worth of used equipment purchased online and two\nmonths working in his spare time, Beresford had found more than a dozen\nvulnerabilities and learned enough about the systems to compromise them.\n\nSince Beresford’s findings, other researchers have uncovered additional\nvulnerabilities in Siemens and other control systems. According to a database\nof control-system vulnerabilities managed by Wurldtech Security, a maker of\nsystems for protecting critical infrastructure, about 1,000 vulnerabilities\nhave been found in control systems and control-system protocols since 2008.\nMost of them would simply allow an attacker to prevent operators from\nmonitoring their system, but many of them would also allow an attacker to\nhijack the system.[31](part0013.html#c09-ftn31)\n\nIn 2011, a security firm hired by a Southern California utility to evaluate\nthe security of controllers at its substations found multiple vulnerabilities\nthat would allow an attacker to control its equipment. “We’ve never looked at\na device like this before, and we were able to find this in the first day,”\nKurt Stammberger, vice president of Mocana said. “These were big, major\nproblems, and problems frankly that have been known about for at least a year\nand a half, but the utility had no clue.”[32](part0013.html#c09-ftn32)\n\nThe security problems with control systems are exacerbated by the fact that\nthe systems don’t get replaced for years and don’t get patched on a regular\nbasis the way general computers do. The life-span of a standard desktop PC is\nthree to five years, after which companies upgrade to new models. But the\nlife-span of a control system can be two decades. And even when a system is\nreplaced, new models have to communicate with legacy systems, so they often\ncontain many of the same vulnerabilities as the old ones.\n\nAs for patching, some control systems run on outdated versions of Windows that\nare no longer supported by Microsoft, meaning that if any new vulnerabilities\nare discovered in the software, they will never get patched by the vendor. But\neven when patches are available, patching is done infrequently on control\nsystems because operators are wary of buggy patches that might crash their\nsystems and because they can’t easily take critical systems—and the processes\nthey control—out of service for the several hours it can take to install\npatches or do other security maintenance.[33](part0013.html#c09-ftn33)\n\nAll of these problems are compounded by a growing trend among vendors to\npackage safety systems with their control systems. Safety systems used to be\nhardwired analog systems configured separately from control systems so that\nany problems with the control system wouldn’t interfere with the safety\nsystem’s ability to shut down equipment in an emergency. But many vendors are\nnow building the safety system into their control system, making it easier to\ndisable them both in a single attack.[34](part0013.html#c09-ftn34)\n\nMany of the vulnerabilities in control systems could be mitigated if the\nsystems ran on standalone networks that were “air-gapped”—that is, never\nconnected to the internet or connected to other systems that are connected to\nthe internet. But this isn’t always the case.\n\nIn 2012, a researcher in the UK found more than 10,000 control systems that\nwere connected to the internet—including ones belonging to water-treatment and\npower plants, dams, bridges, and train stations—using a specialized search\nengine called Shodan that can locate devices like VoIP phones, SmartTVs, and\ncontrol systems that are connected to the\ninternet.[35](part0013.html#c09-ftn35)\n\nIn 2011 a hacker named pr0f accessed the controls for a water plant in South\nHouston after finding the city’s Siemens control system online. Although the\nsystem was password-protected, it used a three-character password that was\neasily guessed. “I’m sorry this ain’t a tale of advanced persistent threats\nand stuff,” pr0f told a reporter at the time, “but frankly most compromises\nI’ve seen have been a result of gross stupidity, not incredible technical\nskill on the part of the attacker.”[36](part0013.html#c09-ftn36) Once in the\nSCADA system, pr0f took screenshots showing the layout of water tanks and\ndigital controls, though he didn’t sabotage the system. “I don’t really like\nmindless vandalism. It’s stupid and silly,” he wrote in a post he published\nonline. “On the other hand, so is connecting interfaces to your SCADA\nmachinery to the internet.”[37](part0013.html#c09-ftn37)\n\nMany SCADA field devices, if not connected directly to the public internet,\nare accessible via modem and are secured only with default passwords. Switches\nand breakers for the power grid, for example, are often set up this way with\ndefault passwords so that workers who need to access them in an emergency will\nremember the password. For the same reason, control systems aren’t generally\ndesigned to lock someone out after several failed password attempts—a standard\nsecurity feature in many IT systems to prevent someone from brute-forcing a\npassword with multiple guesses—because no one wants a control system to lock\nout an operator who mistypes a password a few times in a state of panic. In\n2011, a test team led by security researcher Marc Maiffret penetrated the\nremote-access system for a Southern California water plant and was able to\ntake control of equipment the facility used for adding chemicals to drinking\nwater. They took control of the system in just a day, and Maiffret said it\nwould have taken just a couple of additional steps to dump chemicals into the\nwater to make it potentially undrinkable.[38](part0013.html#c09-ftn38)\n\nMaking critical systems remotely accessible from the internet creates obvious\nsecurity risks. But if Stuxnet proved anything, it’s that an attacker doesn’t\nneed remote access to attack a system—instead, an autonomous worm can be\ndelivered via USB flash drive or via the project files that engineers use to\nprogram PLCs. In 2012, Telvent Canada, a maker of control software used in the\nsmart grid, was hacked by intruders linked to the Chinese military, who\naccessed project files for the SCADA system the company produced—a system\ninstalled in oil and gas pipelines in the United States as well as in water\nsystems. Telvent used the project files to manage the systems of customers.\nThough the company never indicated whether the attackers modified the project\nfiles, the breach demonstrated how easily an attacker might target oil and gas\npipelines by infecting the project files of a company like\nTelvent.[39](part0013.html#c09-ftn39)\n\nDirect computer network intrusions aren’t the only concern when it comes to\ncritical infrastructure, however. There are documented cases involving\nelectromagnetic pulses interfering with SCADA systems and field devices. In\nNovember 1999, the radar system from a US Navy ship conducting exercises\ntwenty-five miles off the coast of San Diego interrupted the wireless networks\nof SCADA systems at local water and electric utilities. The disturbance\nprevented workers from opening and closing valves in a pipeline, forcing them\nto dispatch technicians to remote locations to manually activate the valves\nand prevent water from overflowing reservoirs. Electromagnetic pulse (EMP)\ndisturbances were also responsible for a gas explosion that occurred near the\nDutch naval port of Den Helder in the late ’80s when a naval radar system\ncaused the SCADA system for a natural gas pipeline to open and close a\nvalve.[40](part0013.html#c09-ftn40)\n\nOVER THE YEARS, numerous Doomsday scenarios have explored the possible\nconsequences of a massive cyberattack.[41](part0013.html#c09-ftn41) But to\ndate, no such attack has occurred, and unintentional events involving control\nsystems have far outnumbered intentional ones.\n\nBut one need only look at accidental industrial disasters to see the extent of\ndamage a cyberattack _could_ wreak, since often the consequences of an\nindustrial accident can be replicated for an intentional attack. A smart\nhacker could simply study the causes and effects of an accidental disaster\nreported in the news and use them to design an attack that would achieve the\nsame destructive results.\n\nThe NSA’s Keith Alexander has cited the catastrophic accident that occurred at\nthe Sayano-Shushenskaya hydroelectric plant in southern Siberia as an example\nof what could occur in an attack.[42](part0013.html#c09-ftn42) The thirty-\nyear-old dam, the sixth largest in the world, was eight hundred feet high and\nspanned about half a mile across a picturesque gorge on the Yenisei River,\nbefore it collapsed in 2009, killing seventy-five people.\n\nJust after midnight on August 17, a 940-ton turbine in the dam’s power-\ngeneration plant was hit with a sudden surge of water pressure that knocked it\noff its bolts and caused it to shoot in the air. As a geyser of water flooded\nthe engine room from the shaft where the turbine had been, it caused massive\ndamage to more than half a dozen other turbines, triggering multiple\nexplosions and causing the roof to cave in.\n\nThe catastrophe was attributed in part to a fire at the Bratsk power station\nsome five hundred miles away that caused the energy output from Bratsk to\ndrop. This forced the turbines at Sayano-Shushenskaya to pick up the load. But\none of those turbines was already at the end of its life and had been\nvibrating dangerously on and off for a while. A new control system had been\ninstalled months earlier to stabilize the machine, but vibrations from the\nadded workload proved to be too much. The turbine sheared off the bolts\nholding it down and became unmoored. Surveillance images showed workers\nscrambling over equipment to flee the site. In addition to killing seventy-\nfive workers and flooding the surrounding community, the plant spilled 100\ntons of oil into the Yenisei River and killed 4,000 tons of trout in local\nfisheries. Experts calculated that repairs would take four years and cost $1.3\nbillion.[43](part0013.html#c09-ftn43)\n\nThe June 1999 pipeline explosion in Washington state also presented a\nblueprint for hackers to follow. In that case, a 16-inch-diameter pipeline\nbelonging to the Olympic Pipe Line Company in Bellingham ruptured and spewed\nmore than 237,000 gallons of gasoline into a creek in Whatcom Falls Park. Gas\npoured out of the pipe for ninety minutes before it ignited into a fireball\nthat stretched 1.5 miles downstream, killing two ten-year-old boys and a teen\nand injuring eight others. Although multiple issues contributed to the\ndisaster, including improperly configured valves and a backhoe that weakened\npart of the pipe, an unresponsive control system also played a role. “[I]f the\nSCADA system computers had remained responsive to the commands of the Olympic\ncontrollers,” investigators found, “the controller operating the accident\npipeline probably would have been able to initiate actions that would have\nprevented the pressure increase that ruptured the\npipeline.”[44](part0013.html#c09-ftn44)\n\nIt took operators more than an hour to register the leak, and by then\nresidents were already calling 911 to report a strong smell of petroleum in\nthe creek. Although the gas leak wasn’t caused by hackers, investigators found\na number of security problems with Olympic’s system that made it vulnerable to\nattack. For example, the company had set up remote dial-in access for its\nSCADA control system that was secured only with a username and password, and\nits business and SCADA networks were interconnected. Although they were\nconnected by a bridge that provided some security from a casual intruder, the\nconnection lacked a robust firewall as well as virus protection or access\nmonitoring, raising the possibility that a determined attacker could break\ninto the business network from the internet, then jump to the critical SCADA\nnetwork.\n\nThe natural-gas pipeline explosion in San Bruno, California, in 2010 was\nanother worst-case scenario that served as a cautionary tale. The explosion\noccurred after maintenance on an uninterrupted power supply unit, or UPS,\ncaused electricity to the SCADA system to go out. A control valve on the\npipeline was programmed to fall open automatically if the SCADA system lost\npower; as a result, gas poured into the pipeline unimpeded, causing pressure\nto build in the aging structure until it burst. Since the SCADA system had\nlost power, operators couldn’t see what was happening in the\npipeline.[45](part0013.html#c09-ftn45)\n\nThen there was the collapse of a dike in Missouri in December 2005. The\ndisaster began when sensors on the dam wall became detached from their mounts\nand failed to detect when the dam’s 1.5 billion-gallon reservoir was full. As\npumps continued to feed water to the reservoir, a “fail-safe” shutdown system\nalso failed to work.[46](part0013.html#c09-ftn46) The overflow began around\n5:10 a.m. and within six minutes a 60-foot section of the parapet wall gave\nway. More than a billion gallons of water poured down Proffit Mountain,\nsweeping up rocks and trees in its massive embrace before entering Johnson’s\nShut-Ins State Park and washing away the park superintendent’s home—with him\nand his family still in it—and depositing them a quarter of a mile\naway.[47](part0013.html#c09-ftn47) No one was seriously injured, but cars on a\nnearby highway were also swept up in the torrent, and a campground at the park\nwas flooded. Luckily, because it was winter, the campsite was empty.\n\nRailway accidents also provide blueprints for digital attacks. The systems\nthat operate passenger trains combine multiple, often interconnected\ncomponents that provide possible avenues for attack: access-control systems to\nkeep nonticketed pedestrians out of stations, credit-card processing systems,\ndigital advertising systems, lighting management, and closed-circuit TVs, not\nto mention the more critical systems for fire and emergency response,\ncrossings and signals control, and the operation of the trains themselves. In\nthe past, these systems were separate and did not communicate with one another\nexcept through wires. But today the systems are increasingly digital and\ninterconnected, including systems that communicate via radio signals and\ntransmit unencrypted commands in the clear. Although rail systems have\nredundancies and fail-safe mechanisms to prevent accidents from occurring,\nwhen many systems are interconnected, it creates the opportunity for\nmisconfigurations that could allow someone to access the safety systems and\nundermine them.\n\nOn June 22, 2009, a passenger train in the DC Metro system collided during the\nafternoon rush hour with another train stopped on the tracks, killing one of\nthe operators and eight passengers, and injuring eighty others. Malfunctioning\nsensors on the track had failed to detect the presence of the stopped train\nand communicate that to the moving train. Although the latter train was\nequipped with anti-collision sensors that should have triggered its brakes\nwhen it got within 1,200 feet of the other cars, that system had failed too,\nand for some reason the operator never applied the manual brakes. A decade\nearlier, communication relays on the same Metro system had sent incorrect\ninstructions to trains on several occasions—one time telling a train to travel\n45 miles per hour on a section of track with a 15 mile per hour speed\nlimit.[48](part0013.html#c09-ftn48)\n\nThese incidents were all accidental, but in Poland in 2008 a fourteen-year-old\nboy in Lódz caused several trains to derail when he used the infrared port of\na modified TV remote control to hijack the railway’s signaling system and\nswitch the tram tracks. Four trams derailed, and twelve people were\ninjured.[49](part0013.html#c09-ftn49)\n\n![](../images/00007.jpeg)\n\nALTHOUGH THERE ARE many different ways to attack critical infrastructure, one\nof the most effective is to go after the power grid, since electricity is at\nthe core of all critical infrastructure. Cut the power for a prolonged period,\nand the list of critical services and facilities affected is long—commuter\ntrains and traffic lights; banks and stock exchanges; schools and military\ninstallations; refrigerators controlling the temperature of food and blood\nsupplies; respirators, heart monitors, and other vital equipment in hospitals;\nrunway lights and air traffic control systems at airports. Emergency\ngenerators would kick in at some critical facilities, but generators aren’t a\nviable solution for a prolonged outage, and in the case of nuclear power\nplants, a switch to generator power triggers an automatic, gradual shutdown of\nthe plant, per regulations.\n\nOne way to target electricity is to go after the smart meters electric\nutilities have been installing in US homes and businesses by the thousands,\nthanks in part to a $3 billion government smart-grid program, which has\naccelerated the push of smart meters without first ensuring that the\ntechnology is secure.\n\nOne of the main problems security researchers have found with the system is\nthat smart meters have a remote-disconnect feature that allows utility\ncompanies to initiate or cut off power to a building without having to send a\ntechnician. But by using this feature an attacker could seize control of the\nmeters to disconnect power to thousands of customers in a way that would not\nbe easily recoverable. In 2009, a researcher named Mike Davis developed a worm\nthat did just this.\n\nDavis was hired by a utility in the Pacific Northwest to examine the security\nof smart meters the company planned to roll out to customers. As with the\nSiemens PLCs that Beresford examined, Davis found that the smart meters were\npromiscuous and would communicate with any other smart meters in their\nvicinity as long as they used the same communication protocol. They would even\naccept firmware updates from other meters. All an attacker needed to update\nthe firmware on a meter was a network encryption key. But since all the meters\nthe company planned to install had the same network key embedded in their\nfirmware, an attacker only had to compromise one meter to extract the key and\nuse it to deliver malicious updates to other meters. “Once we had control of\none device, we had pretty much everything we needed,” Davis said. “That was\nthe case across a bunch of meters that we had looked at from different\nvendors.”[50](part0013.html#c09-ftn50)\n\nThe meters communicated with one another via radio and were always in\nlistening mode to detect other meters nearby. Some meters could communicate\nwith one another from miles away. The ones Davis examined had a reach of about\n400 feet, a little longer than the length of a football field—which was more\nthan enough to propagate a malicious update between neighboring houses that\nwould shut off the electricity and spread the worm to additional meters. Davis\ndidn’t even need to compromise an existing meter at a house to get the\ninfection going; he could simply buy his own meter of the same brand—as long\nas it spoke the same protocol—and load it with malware and the necessary\nencryption key, then place it in the vicinity of a metered house. “Because of\nthe radio, it’s going to get picked up automatically [by other meters around\nit],” Davis says. Once the update was complete, the victim meter would restart\nwith the new firmware in place and automatically begin spreading its update to\nother meters within range, setting off a chain reaction. Operators wouldn’t\nknow anything had changed with the meters until power started dropping out in\nneighborhoods.\n\nNormally the vendor’s meters got upgraded remotely through a utility company’s\ncentral network, or via a technician in the field who used a special dongle\nconnected to a laptop to communicate wirelessly with the meters. So when Davis\nand his team told the vendor they could write software that propagated\nautomatically from one meter to another without using the central computer or\na dongle, the vendor scoffed and said the meters didn’t have the ability to\ninitiate a firmware update to other meters. “They told us … that wasn’t part\nof their feature set,” Davis recalls. “We said we know, we added the feature\n[to our malicious firmware update].” The vendor still didn’t believe a worm\nwould have much effect, so Davis wrote a program to simulate an infection in a\nresidential neighborhood of Seattle that in a day spread to about 20,000 smart\nmeters.[51](part0013.html#c09-ftn51) “We had pretty much full compromise by\nthe end of the twenty-four-hour cycle,” he says. The infection spread one\nmeter at a time, but a real-world attack would move much more quickly since an\nattacker could send out a plague of firmware updates from multiple patient\nzeros located strategically throughout a city.\n\nThe vendor scoffed at Davis’s simulation, too, saying a worm would take two to\nfour minutes to update each meter’s firmware, and in that time, technicians\nwould spot the outage before too many customers lost electricity and send out\na remote firmware update to turn the power back on to them.\n\nThat’s when Davis delivered his final blow and told the vendor that his\nmalicious software didn’t just turn the power off, it also deleted the\nfirmware update feature on the meters so they couldn’t be updated again to\nrestore power. Technicians would have to replace the meter at each house or\ntake them back to the lab and flash their chips with new firmware. “That\nactually seemed to get their attention more than anything,” he says. “We were\nable to prove the point that this could get out of hand well before they would\nbe able to figure out what’s going on.”\n\nSince conducting the simulation, Davis has seen vendors improve their meters.\nSome vendors now use multiple network keys on their meters, assigning a\ndifferent key for different neighborhoods to limit the damage an attacker\ncould do with a single key. But the remote disconnect is still a problem with\nmost smart meters, since an attacker who breaches a utility’s central server\ncould do what Davis’s worm did, but in a much simpler way. “Were [the remote\ndisconnect] not in there, none of this would really be all that much of an\nissue,” Davis says. “In my opinion, if it’s got the remote disconnect relay in\nit, whether it’s enabled or not … it’s a real big, ugly issue.”\n\nGoing after smart meters is an effective way to cut electricity. But an even\nmore effective and widespread attack would be to take out generators that feed\nthe grid or the transmission systems that deliver electricity to customers.\nDefense Secretary Leon Panetta said at his confirmation hearing in June 2011\nthat the next Pearl Harbor the nation experiences could very well be a\ncyberattack that cripples the grid.\n\nThe North American power grid is large and complex and actually consists of\nthree large regional grids—known as the Eastern, Western, and Texas\nInterconnections. The grids are composed of more than 450,000 miles of high-\nvoltage transmission lines owned and operated by about three thousand\nutilities. Because power is traded on energy markets, it sometimes gets routed\nlong distances between and within states to fulfill demand, such as by Cal-\nISO, the entity that was hacked in 2001. Although the existence of many\nindependent systems means that an attack on one utility or substation will\nhave a limited effect, their interconnectedness means that a coordinated and\nstrategic attack on a number of systems could cause cascading blackouts that\nare difficult to fix and plunge users into darkness for\nweeks.[52](part0013.html#c09-ftn52)\n\nFor example, circuit breakers that monitor distribution lines are designed to\nsense a dangerous surge on the lines and open to disconnect them from the grid\nto prevent them from being damaged. When one breaker trips, however, the power\nfrom that line gets redirected to other lines. If those lines reach capacity,\ntheir breakers will also trip, creating a blackout. But a well-crafted attack\ncould trip the breakers on some lines while manipulating the settings on\nothers to prevent them from tripping, causing the lines to overheat when they\nexceed capacity.\n\nWhen distribution lines overheat, it causes them to sag or melt. Sagging lines\nwere the cause of the 2003 Northeast blackout that cut power to 50 million\npeople in eight states and parts of Canada. Although a digital attack wasn’t\nthe cause of the outage, a software bug thwarted early detection and\nprevention of the cascade.\n\nThe problem began in Ohio when sagging power lines tangled with trees, but it\nwas exacerbated by the fact that the emergency alert system at FirstEnergy’s\ncontrol center in Akron failed to register faults in the system, leaving\noperators ignorant about deteriorating conditions. About two and a half hours\nbefore the blackout occurred, industrial customers and even other power plants\nwere calling FirstEnergy to report low voltages and tripping transmission\nlines—indications that major problems were brewing in the grid. But because\nFirstEnergy operators didn’t see any sign of trouble on their control screens,\nthey assumed the problem lay elsewhere. “[American Electric Power] must have\nlost some major stuff,” one First-Energy operator told a caller, pointing the\nfinger at another utility.[53](part0013.html#c09-ftn53) It wasn’t until the\nlights in FirstEnergy’s own control room went dark that operators realized the\nproblem was with their own system. They eventually traced the glitch in the\nalert system to a software bug. “[The bug] had never evidenced itself until\nthat day,” a FirstEnergy spokesman later said. “This fault was so deeply\nembedded, it took them weeks of poring through millions of lines of code and\ndata to find it.”[54](part0013.html#c09-ftn54)\n\nAn even more destructive attack than targeting distribution lines, however,\nwould be to target equipment at substations that feed electricity to those\nlines. The grid consists of more than 15,000 nodes, or substations, divided\ninto three types—generator substations that create power, transmission\nsubstations that transfer it between power lines, and distribution substations\nthat deliver it to consumers. The majority of these are transmission\nsubstations, which are responsible for “stepping up” the voltage to transmit\nit long distances and then “stepping down” the voltage before it gets\ndistributed to end users. A recent study by the Federal Energy Regulatory\nCommission found that an attack that took out just nine critical\nsubstations—four in the Eastern grid, three in the Western grid, and two in\nthe Texas grid—could cause a national power outage for weeks, possibly months,\ncreating panic and leading to loss of life.[55](part0013.html#c09-ftn55)\n\nThe good news is that because grid systems are owned and operated by different\nutilities, they use different equipment and configurations, thwarting a one-\nsize-fits-all attack and making a single widespread attack on energy systems\ndifficult to pull off. But regional attacks and blackouts are not out of the\nreach of average hackers. And an attack that also destroyed industrial-sized\ngenerators at power-generation plants would make recovery more difficult. This\nwas precisely the point of the Aurora Generator Test.\n\nNAMED AFTER THE Roman goddess who was mother to the four winds, the test had\nits origins in the cascading Northeast blackout of 2003. That blackout lasted\nfor only two days, but it got people thinking about the possibility of remote\nattacks against power-generation plants that might not be so recoverable. Mike\nAssante was in charge of pulling a team together to test the hypothesis.\n\nWhile a naval intelligence officer in 2001, Assante had been assigned to work\nat the FBI’s new National Infrastructure Protection Center in Washington, DC,\nto research the risks posed by cyberattacks against energy infrastructures.\nAfter a year, he left the Navy to take a job with American Electric Power\n(AEP) in Ohio, one of the largest electric utilities in the country. AEP\nwanted help developing an infrastructure protection program, and it was during\nthis time that Assante began to think about attacks that might cause physical\ndestruction to the grid.\n\nWhile at AEP, Assante was struck by a _Washington Post_ story about the Idaho\nNational Lab’s SCADA test-bed program, in which workers there terrified the\nchairman of the Federal Energy Regulatory Commission with a simulation showing\nhim how easily a hacker could destroy a utility’s turbine by shutting down the\nmechanism responsible for lubricating the machine. Without oil greasing the\nmoving metal parts, the turbine seized up and tore itself\napart.[56](part0013.html#c09-ftn56) The chairman’s reaction to the demo was\nvisceral. “I wished I’d had a diaper on,” he told the _Post_ after the\ntest.[57](part0013.html#c09-ftn57)\n\nAssante visited the INL lab for himself and was impressed with the group of\nexperts the lab had recruited for its program. In addition to control-system\nengineers, the lab had hired a group of code warriors fresh out of high school\nand college who knew how to hack them. They cut through the control-system\nnetworks with little resistance, exploiting weaknesses that were invisible to\nthe engineers who had worked on them for years. The lab also had its own\nsubstations and mini-grid—a sevenmile section of redundant grid that\nresearchers could isolate from the public grid—to run live tests. Assante was\nso intrigued by the possibilities for conducting real security research on the\ngrid—not just simulated tests—that he quit his job at AEP in 2005 and took a\nposition with the lab.\n\nOnce there, Assante and his colleagues began to consider scenarios for how\nequipment might be destroyed. Until then, most of the cyber concern around the\nsecurity of the grid had been focused on someone getting into a power network\nto open breakers and create an outage. A power outage, however, could be\nresolved fairly quickly by resetting the breakers. But what about an attack\nthat defeated or bypassed security and safety systems to physically destroy a\ngenerator that couldn’t be easily fixed?\n\nThey decided to get at the generator by focusing the attack on protective\nrelays—safety devices that monitor changes in the grid and are responsible for\ntripping breakers if conditions enter a danger zone that could harm\ntransmission lines. Disabled protective relays played a role in a large outage\nin February 2008, when nearly 600,000 people in Florida lost power after a\nfield engineer with Florida Power and Light turned off the protective relays\nat a substation while investigating a malfunctioning\nswitch.[58](part0013.html#c09-ftn58) When a fault occurred on the line that he\nwas examining, there was nothing to keep it from radiating out. The result was\na cascading outage that spread to thirty-eight substations, including one that\nfed electricity to a nuclear plant, causing the plant to go into automatic\nshutdown.\n\nBut protective relays don’t just trigger breakers on transmission lines, they\nalso disconnect generators and other equipment from the grid if conditions\ngrow dangerous. The power grid operates at 60 Hz—or sixty cycles a second—and\ndevices connected to it have to be in sync or they can be damaged. Plug\nsomething into the grid when it’s out of sync and it creates torque that can\ndestroy the equipment. When a generator connects to the grid, the load from\nthe grid pushes back, like the gravitational force that pushes against a car\nclimbing a hill. But when a breaker opens up and disconnects the generator\nfrom the grid, the still-running generator speeds up in the absence of any\nload pushing against it. Within just 10 milliseconds, the generator will be\nout of sync with the grid. If the breaker then closes, bringing the generator\nback onto the grid while the two are out of sync, the effect is similar to a\ncar hitting a brick wall. The generator expends too much energy that has\nnowhere to go, and once it hits the slower grid, the force of that energy\nslams back against it. It’s a well-known phenomenon that has been the cause of\naccidents in the past.\n\nSo the question Assante’s team posed for their test was simple: If protective\nrelays were supposed to prevent equipment from being damaged, what if they\ncould be subverted to aid the equipment’s destruction? Designing such an\nattack turned out to be only slightly more complicated than the question. The\nhack involved writing malicious code to change the settings of the digital\nrelays so that the breaker for a generator opened and closed in rapid\nsuccession, causing the equipment to disconnect from the grid quickly and\nrepeatedly and then reconnect when it was out of sync. Without the protection\nof the relays, there was nothing to prevent the generator from destroying\nitself. “This is what made it so damn insidious,” says Joe Weiss. “The thing\nthat was supposed to stop an attack like this from happening was the thing\nthey used to conduct the attack.” By abruptly opening and closing the\nprotective circuit, the relay went from “providing maximum protection to\ninflicting maximum damage,” the DHS later wrote in a report about the\ntest.[59](part0013.html#c09-ftn59)\n\nFor their victim, they chose a Wärtsilä generator that had been retired from\nthe oil fields in Alaska and was purchased through a broker for one-third of\nits $1 million price tag brand-new.[60](part0013.html#c09-ftn60)\n\nThe attack lasted three minutes but could have achieved its aim in just\nfifteen seconds. The researchers had built in pauses to the attack to give\nengineers time to assess the damage and check safety systems at each stage.\nEach time the circuit breaker closed on the out-of-sync generator, connecting\nit back to the grid, the machine jumped and vibrated from the force of its own\nenergy hitting back, until eventually the coupling between the diesel engine\nand the generator broke.[61](part0013.html#c09-ftn61)\n\nWorkers in the operations center who monitored the grid for anomalies and\nweren’t told of the attack before it occurred never noticed anything amiss on\ntheir monitors. The safety system that was designed to ride out little spikes\nand valleys that normally occurred on the grid also never registered the\ndestructive interruption. “We could do the attack, essentially open and close\na breaker so quickly that the safety systems didn’t see it,” said Perry\nPederson, who headed DHS’s control-system security program at the time and\noversaw the test.[62](part0013.html#c09-ftn62)\n\nReplacing a twenty-seven-ton generator that was destroyed in this way wouldn’t\nbe trivial, but it was doable. But there were 800-megawatt generators at large\npower plants and other facilities that would take months or a year to replace,\nsince generators that size are often built to order overseas. Not all\ngenerators powering the grid would be susceptible to this attack in the same\nway—it would depend on how the power on that part of the grid is balanced. But\nthe same thing could happen with critical equipment, powering things other\nthan the grid, that isn’t easily replaced. A substation powering a bank of\npumps responsible for delivering drinking water to a major metropolitan area,\nfor example, would cause major disruptions if taken out of commission. “I\ndon’t know what would happen to a big 50,000 horsepower pump, but I could\nimagine it would be just as bad as a generator,” Pederson\nsaid.[63](part0013.html#c09-ftn63)\n\nSince the Aurora test took place in 2007, there have been other demonstrations\nof destructive cyberattacks. In a 2009 report on _60 Minutes_ , researchers at\nSandia National Lab showed how they could cause components at an oil refinery\nto overheat by simply changing the settings of a heating element and disabling\nthe recirculation pumps that helped regulate the\ntemperature.[64](part0013.html#c09-ftn64)\n\nSTUXNET AND THE Maroochy Shire incident aside, there have been no really\ndestructive digital attacks recorded in the world to date. Experts have\noffered a number of possible reasons for why this is the case—such attacks are\nmore difficult to pull off than the evidence presented here seems to indicate,\nand those who possess the skills and resources to conduct them have simply\nlacked the motivation to take action thus far, while others who have the will\nto launch such an attack don’t yet have the way.\n\nOne thing, however, seems certain: given the varied and extensive\npossibilities for conducting such attacks, and the proof of concept provided\nby Stuxnet, it is only a matter of time until the lure of the digital assault\nbecomes too irresistible for someone to pass up.\n\n* * *\n\n[1](part0013.html#c09-ftn1a) Author interview with Assante, September 2011.\n\n[2](part0013.html#c09-ftn2a) SCADA systems are generally used where the\nsystems being managed are geographically dispersed over large areas—such as in\npipelines, railway systems, and water and electrical distribution. Distributed\ncontrol systems, on the other hand, are best for when operators need extensive\nand complex control in confined facilities like refineries and water-treatment\nand power-generation plants, although power plants also use SCADA systems to\nmonitor remote substations in the field. SCADA systems consist of an\noperator’s station, a communications network, and a remote terminal unit, or\nRTU, in the field. The RTUs, which are similar to PLCs, send data back through\nthe network to the operator’s monitoring station. The operator’s station\ngenerally runs on Windows—with all of its inherent vulnerabilities—and the\nfield devices use specialized operating systems, which generally have little\nsecurity built into them.\n\n[3](part0013.html#c09-ftn3a) Industrial control system incidents are tracked\nin the RISI database (Repository of Industrial Security Incidents), which\nbegan recording incidents in 2001 but fell dormant between 2006 and 2009. The\nsubscription database is maintained by the Security Incidents Organization and\ncan be found at [securityincidents.org](http://www.securityincidents.org).\n\n[4](part0013.html#c09-ftn4a) Marty Niland, “Computer Virus Brings Down Train\nSignals,” Associated Press, August 20, 2003, available at\n[informationweek.com/news/13100807](http://www.informationweek.com/news/13100807).\n\n[5](part0013.html#c09-ftn5a) The worm arrived via the corporate network of the\nutility company that operated the plant, and spread from the plant’s business\nnetwork to the control network. Luckily, the plant had been offline for nearly\na year due to other issues, so no harm was done. Plant operators also said\nthey had manual controls that would have served as backup with the automated\nones down. See Kevin Poulsen, “Slammer Worm Crashed Ohio Nuke Plant Network,”\nSecurityFocus, August 19, 2003, available at\n[securityfocus.com/news/6767/](http://www.securityfocus.com/news/6767/).\n\n[6](part0013.html#c09-ftn6a) “Cybersecurity: Preparing for and Responding to\nthe Enduring Threat,” Speech to the Senate Committee on Appropriations, June\n12, 2013, available at\n[hsdl.org/?view&did=739096](http://www.hsdl.org/?view&did=739096).\n\n[7](part0013.html#c09-ftn7a) Lewis was speaking on the Diane Rehm radio show,\nbroadcast by WAMU in Southern California, on June 4, 2012. Interview available\nat [thedianerehmshow.org/shows/2012-06-04/growing-threat-\ncyberwarfare](http://www.thedianerehmshow.org/shows/2012-06-04/growing-threat-\ncyberwarfare).\n\n[8](part0013.html#c09-ftn8a) Gregory Benford, a physicist, is credited with\none of the first mentions of a computer virus in a story he wrote in 1969\ncalled “The Scarred Man,” which was published in the May 1970 issue of\n_Venture_ magazine. The notion of digital worms originated in John Brunner’s\n1975 science-fiction book _The Shockwave Rider_ , which featured a digital\ntapeworm that slithered from machine to machine.\n\n[9](part0013.html#c09-ftn9a) “Teen Hacker Pleads Guilty to Crippling Mass.\nAirport,” _Boston Globe_ , March 19, 1998.\n\n[10](part0013.html#c09-ftn10a) “Teen Hacker Faces Federal Charges,” CNN, March\n18, 1998, available at\n[edition.cnn.com/TECH/computing/9803/18/juvenile.hacker/index.html](http://www.edition.cnn.com/TECH/computing/9803/18/juvenile.hacker/index.html).\n\n[11](part0013.html#c09-ftn11a) “Critical Foundations: Protecting America’s\nInfrastructures,” President’s Commission on Critical Infrastructure\nProtection, October 1997. The report is available at\n<https://www.fas.org/sgp/library/pccip.pdf>.\n\n[12](part0013.html#c09-ftn12a) “Electric Power Risk Assessment,” National\nSecurity Telecommunications Advisory Committee, Information Assurance Task\nForce, available at\n[solarstorms.org/ElectricAssessment.html](http://www.solarstorms.org/ElectricAssessment.html).\n\n[13](part0013.html#c09-ftn13a) Information about the Maroochy Shire case comes\nfrom an author interview conducted August 2012 with Robert Stringfellow, a\nwater district engineer who helped investigate the case, as well as from\nredacted court documents and a police report written by forensic examiner\nPeter Kingsley. Some details from the court documents were first published by\nJoe Weiss in his book _Protecting Industrial Control Systems from Electronic\nThreats_ (New York: Momentum Press, 2010).\n\n[14](part0013.html#c09-ftn14a) Between March 14 and April 23 about ninety\nincidents occurred. A worker traced some of the activity to the RTU at pump\nstation 14, where the malicious radio signals seemed to originate. He knew it\nwas easy to alter the address of an RTU simply by flipping certain switches on\nthe device, so he concluded the intruder must be using a rogue RTU that had\nits switches set to 14 to send out malicious commands as if they were coming\nfrom the real pump station 14. To set a trap, he changed the address for pump\nstation 14 to 3. If an intruder _was_ sending spoofed messages, he wouldn’t\nknow the address had changed and would continue sending his messages under the\nold address. That’s exactly what occurred one night when a flood of malicious\ntraffic sailed across the network from pump station 14 aimed at crashing the\ncentral computer. Investigators concluded, then, that the attacker must be an\ninsider with knowledge of the Maroochy system and access to Hunter WaterTech\nsoftware and equipment.\n\n[15](part0013.html#c09-ftn15a) Boden was convicted and sentenced in October\n2001 to two years in prison. He later appealed, at which point his conviction\non two of the charges was set aside, but his conviction on other charges\nremained, as well as his sentence.\n\n[16](part0013.html#c09-ftn16a) A survey of utilities conducted by the\nElectronic Power Research Institute in 1996 found that only 25 percent of\nrespondents reported using any intrusion detection methods. The survey, the\nEPRI Summer 1996 Electronic Information Security Survey, and the statistic are\nreferenced at\n[solarstorms.org/ElectricAssessment.html](http://www.solarstorms.org/ElectricAssessment.html).\n\n[17](part0013.html#c09-ftn17a) Maroochy Water Services had little choice but\nto involve law enforcement in the case, because the spillages were so public\nand threatened public safety. The incidents also brought heavy scrutiny from\nAustralia’s environmental protection agency and from regional government\nofficials who demanded an explanation for why they occurred.\n\n[18](part0013.html#c09-ftn18a) Kingsley was speaking at the AusCERT2002\nconference in Australia. In a report examining the Maroochy case in 2008,\neight years after it occurred, the authors concluded that some of the issues\nraised by the incident were just beginning to be addressed by companies, while\n“some are unresolved with no solution in sight.” See Marshall Abrams and Joe\nWeiss, “Malicious Control System Cyber Security Attack Case Study–Maroochy\nWater Services, Australia,” February 23, 2008, available at\n[csrc.nist.gov/groups/SMA/fisma/ics/documents/Maroochy-Water-Services-Case-\nStudy_report.pdf](http://www.csrc.nist.gov/groups/SMA/fisma/ics/documents/Maroochy-\nWater-Services-Case-Study_report.pdf).\n\n[19](part0013.html#c09-ftn19a) This and other quotes from Weiss in this\nchapter come from an author interview, June 2012.\n\n[20](part0013.html#c09-ftn20a) Barton Gellman, “Cyber-Attacks by Al Qaeda\nFeared,” _Washington Post_ , June 27, 2002.\n\n[21](part0013.html#c09-ftn21a) Ibid.\n\n[22](part0013.html#c09-ftn22a) “Critical infrastructure” in the United States\nis broadly defined by the government as any facility or system that falls into\none of sixteen categories that include: agriculture and food, banking and\nfinance, chemical, commercial facilities, critical manufacturing, dams,\ndefense industrial base, drinking-water and water-treatment systems, emergency\nservices, energy, government facilities, information technology, nuclear\nreactors and waste, public health and health care, telecommunications, and\ntransportation. See [dhs.gov/critical-infrastructure-\nsectors](http://www.dhs.gov/critical-infrastructure-sectors).\n\n[23](part0013.html#c09-ftn23a) Dan Morain, “Hackers Victimize Cal-ISO,” _Los\nAngeles Times_ , June 9, 2001.\n\n[24](part0013.html#c09-ftn24a) A previous SCADA testing program had launched\nat Sandia National Laboratory in 1998, but didn’t involve vendors. INL is the\nDepartment of Energy’s lead lab for nuclear energy research and runs the\nlargest test reactor in the world. The Atomic Energy Commission took over the\nland in Idaho after World War II to build a nuclear research lab. Over the\nyears, the lab’s work expanded to include research on the electric grid and,\nafter the Bush administration released its National Strategy to Secure\nCyberspace in February 2003, the security of industrial control systems. That\nstrategy called for the Department of Energy and the Department of Homeland\nSecurity (DHS) to partner with private industry to address the security of\ncontrol systems.\n\n[25](part0013.html#c09-ftn25a) Department of Homeland Security, “The National\nStrategy for the Physical Protection of Critical Infrastructures and Key\nAssets” (report, The White House, February 2003), 9. Available at\n[dhs.gov/xlibrary/assets/Physical_Strategy.pdf](http://www.dhs.gov/xlibrary/assets/Physical_Strategy.pdf).\n\n[26](part0013.html#c09-ftn26a) Ibid., 39.\n\n[27](part0013.html#c09-ftn27a) One problematic loophole in the test program,\nhowever, is that the reports vendors receive describing the vulnerabilities\nfound in their systems are covered by a nondisclosure agreement and the\nvendors are not required to tell customers about the vulnerabilities found in\ntheir systems.\n\n[28](part0013.html#c09-ftn28a) Kim Zetter, “Hard-Coded Password and Other\nSecurity Holes Found in Siemens Control Systems,”\n[Wired.com](http://www.Wired.com), August 3, 2011, available at\n[wired.com/2011/08/siemens-hardcoded-\npassword](http://www.wired.com/2011/08/siemens-hardcoded-password).\n\n[29](part0013.html#c09-ftn29a) Joe Weiss estimates that more than half of all\ncontrol systems have a back door embedded in them by the vendor.\n\n[30](part0013.html#c09-ftn30a) Beresford also found one more surprise—an\n“Easter egg” that a Siemens programmer had hidden in the firmware. Easter eggs\nare inside jokes that coders bury in their programs for users to find. Often\nthey can be seen only if a user types a specific sequence of keys or accesses\nan obscure part of the program. In Siemens’s case, the Easter egg consisted of\nan animated image of dancing chimpanzees that appeared on-screen with a German\nproverb. Translated loosely the proverb said, “All work and no play makes Jack\na dull boy.” Though the Easter egg wasn’t malicious, it raised serious\nconcerns about Siemens’s security. If a programmer had slipped the joke past\nthe company’s internal code reviewers, what else might have slipped by them?\n\n[31](part0013.html#c09-ftn31a) In 2013, two researchers found problems with a\npopular protocol used by control centers to communicate with PLCs and RTUs\ninstalled at substations. An intruder who couldn’t gain direct access to the\ncontrol-center machine via the internet could compromise the communication\ndevice at a remote substation—either by accessing it physically or hacking\ninto the wireless radio network it uses to communicate with the control\ncenter—and exploit a vulnerability in the protocol to send malicious commands\nto the control center. In this way an attacker could either crash the control-\ncenter machine or use it to distribute malicious commands to all of the\nsubstations with which that machine communicates, potentially taking out\ndozens or even hundreds of substations at a time, depending on the size of the\nutility. See Kim Zetter, “Researchers Uncover Holes That Open Power Stations\nto Hacking,” [Wired.com](http://www.Wired.com), October 16, 2013, available at\n[wired.com/2013/10/ics](http://www.wired.com/2013/10/ics).\n\n[32](part0013.html#c09-ftn32a) Jordan Robertson, “Science Fiction–Style\nSabotage a Fear in New Hacks,” Associated Press, October 23, 2011, available\nat [news-yahoo.com/science-fiction-style-sabotage-fear-\nhacks-120704517.html](http://www.news-yahoo.com/science-fiction-style-\nsabotage-fear-hacks-120704517.html).\n\n[33](part0013.html#c09-ftn33a) In 2003, according to Joe Weiss, when the SQL\nSlammer worm hit the internet, one controlsystem supplier warned its customers\nnot to install a patch released by Microsoft to combat the worm, because the\npatch would shut down their system.\n\n[34](part0013.html#c09-ftn34a) Safety systems at nuclear plants, luckily, are\nstill controlled by analog means, according to Joe Weiss, and the horror of a\ncore meltdown being caused by a cyber incident is very low for existing\nnuclear plants. But that could change, since designs for next-generation\nplants include digital, networked systems, he says, that could make it easier\nto attack such plants.\n\n[35](part0013.html#c09-ftn35a) Kim Zetter, “10K Reasons to Worry About\nCritical Infrastructure,” [Wired.com](http://www.Wired.com), January 24, 2012,\navailable at [wired.com/2012/01/10000-control-systems-\nonline](http://www.wired.com/2012/01/10000-control-systems-online). Researcher\nEireann Leverett was unable to determine how many of the control systems were\nworking systems as opposed to demo systems, and couldn’t tell how many of them\nwere critical systems as opposed to simply an office heating system at a\nplant. But he did identify control systems for water facilities in Ireland and\nsewage facilities in California among them, and even controls for a heating\nsystem can sometimes be leveraged by attackers to access other parts of a\nnetwork. And only 17 percent of the 10,000 systems he found required\nauthorization to connect to them. In some cases, the owners weren’t even aware\ntheir systems were accessible online.\n\n[36](part0013.html#c09-ftn36a) Paul F. Roberts, “Hacker Says Texas Town Used\nThree Character Password to Secure Internet Facing SCADA System,” Threatpost\nblog, November 20, 2011, available at [threatpost.com/blogs/hacker-says-texas-\ntown-used-three-character-password-secure-internet-facing-scada-\nsystem-11201/75914](http://www.threatpost.com/blogs/hacker-says-texas-town-\nused-three-character-password-secure-internet-facing-scada-\nsystem-11201/75914).\n\n[37](part0013.html#c09-ftn37a) His statements appeared on the Pastebin site on\nNovember 18, 2011. See\n[Pastebin.com/Wx90LLum](http://www.Pastebin.com/Wx90LLum).\n\n[38](part0013.html#c09-ftn38a) Ken Dilanian, “Virtual War a Real Threat,” _Los\nAngeles Times_ , March 28, 2011.\n\n[39](part0013.html#c09-ftn39a) Kim Zetter, “Chinese Military Linked to Hacks\nof More Than 100 Companies,” [Wired.com](http://www.Wired.com), February 19,\n2013, available at [wired.com/2013/02/chinese-army-linked-to-\nhacks](http://www.wired.com/2013/02/chinese-army-linked-to-hacks). For more\ninformation on the specifics of the Telvent hack, see also Kim Zetter, “Maker\nof Smart-Grid Control Software Hacked,” [Wired.com](http://www.Wired.com),\nSeptember 26, 2012, available at [wired.com/2012/09/scada-vendor-telvent-\nhacked](http://www.wired.com/2012/09/scada-vendor-telvent-hacked).\n\n[40](part0013.html#c09-ftn40a) “Report of the Commission to Assess the Threat\nto the United States from Electromagnetic Pulse (EMP) Attack,” April 2008,\navailable at\n[empcommission.org/docs/A2473-EMP_Commission-7MB.pdf](http://www.empcommission.org/docs/A2473-EMP_Commission-7MB.pdf).\nSee also [footnote 25](part0015.html#c11-ftn25) for a description of an\nintentional electromagnetic pulse attack plan.\n\n[41](part0013.html#c09-ftn41a) A 1996 RAND study titled “The Day After … in\nCyberspace” was one of the first to imagine the consequences of a multipronged\nattack that targeted planes, trains, phone systems, and ATMs on a number of\ncontinents. See Robert H. Anderson and Anthony C. Hearn, “An Exploration of\nCyberspace Security R&D Investment Strategies for DARPA: The Day After … in\nCyberspace II,” RAND, 1996, available at\n[rand.org/pubs/monograph_reports/MR797.html](http://www.rand.org/pubs/monograph_reports/MR797.html).\n\n[42](part0013.html#c09-ftn42a) Bill Gertz, “Computer-Based Attacks Emerge as\nThreat of Future, General Says,” _Washington Times_ , September 13, 2011.\n\n[43](part0013.html#c09-ftn43a) Joe P. Hasler, “Investigating Russia’s Biggest\nDam Explosion: What Went Wrong,” _Popular Mechanics_ , February 2, 2010.\n\n[44](part0013.html#c09-ftn44a) “Pipeline Rupture and Subsequent Fire in\nBellingham, Washington June 10, 1999,” published by the National\nTransportation Safety Board, 2002, available at\n[ntsb.gov/doclib/reports/2002/PAR0202.pdf](http://www.ntsb.gov/doclib/reports/2002/PAR0202.pdf).\n\n[45](part0013.html#c09-ftn45a) “Pacific Gas and Electric Company Natural Gas\nTransmission Pipeline Rupture and Fire,” National Transportation Safety Board,\nSeptember 9, 2010, available at\n[ntsb.gov/investigations/summary/PAR1101.html](http://www.ntsb.gov/investigations/summary/PAR1101.html).\n\n[46](part0013.html#c09-ftn46a) J. David Rogers and Conor M. Watkins, “Overview\nof the Taum Sauk Pumped Storage Power Plant Upper Reservoir Failure, Reynolds\nCounty, MO,” presented at the 6th International Conference on Case Histories\nin Geotechnical Engineering, Arlington, VA, August 11–16, 2008, available at\n[web.mst.edu/~rogersda/dams/2_43_rogers.pdf](http://www.web.mst.edu/~rogersda/dams/2_43_rogers.pdf).\n\n[47](part0013.html#c09-ftn47a) Emitt C. Witt III, “December 14th, 2005 Taum\nSauk Dam Failure at Johnson’s Shut-Ins Park in Southeast Missouri,” National\nOceanic and Atmospheric Administration, available at\n[crh.noaa.gov/lsx/?n=12_14_2005](http://www.crh.noaa.gov/lsx/?n=12_14_2005).\n\n[48](part0013.html#c09-ftn48a) Lyndsey Layton, “Metro Crash: Experts Suspect\nSystem Failure, Operator Error in Red Line Accident,” _Washington Post_ , June\n23, 2009.\n\n[49](part0013.html#c09-ftn49a) Graeme Baker, “Schoolboy Hacks into City’s Tram\nSystem,” _Telegraph_ , January 11, 2008.\n\n[50](part0013.html#c09-ftn50a) From author interview, August 2012.\n\n[51](part0013.html#c09-ftn51a) A YouTube video of the simulation can be seen\nonline at:\n[youtube.com/watch?v=kc_ijB7VPd8](http://www.youtube.com/watch?v=kc_ijB7VPd8).\nOr see links to Davis’s presentation slides and two other smart meter\nsimulations at\n[ioactive.com/services_grid_research.html](http://www.ioactive.com/services_grid_research.html).\n\n[52](part0013.html#c09-ftn52a) NERC has cyber security regulations that\nutilities are supposed to follow, but they apply only to bulk electric systems\n(defined as facilities and systems that operate at or above 100 kilovolts) and\ncompliance doesn’t guarantee a system won’t get hacked. Security is an\nevolving condition, not a static one, and can change anytime new equipment is\ninstalled or configurations are changed.\n\n[53](part0013.html#c09-ftn53a) US-Canada Power System Outage Task Force,\n“Final Report on the August 14th Blackout in the United States and Canada,”\nApril 2004, available at <https://reports.energy.gov/BlackoutFinal-Web.pdf>.\n\n[54](part0013.html#c09-ftn54a) Kevin Poulsen, “Software Bug Contributed to\nBlackout,” [SecurityFocus.com](http://www.SecurityFocus.com), February 11,\n2004, available at\n[securityfocus.com/news/8016](http://www.securityfocus.com/news/8016).\n\n[55](part0013.html#c09-ftn55a) Rebecca Smith, “U.S. Risks National Blackout\nfrom Small-Scale Attack,” _Wall Street Journal_ , March 12, 2004.\n\n[56](part0013.html#c09-ftn56a) The scenario was similar to a real-life\nincident that occurred at a Coors bottling plant in 2004 when an employee\nmistakenly changed the settings on a system responsible for greasing the\nbearings on a bottling line. Instead of greasing the bearings every twenty\nminutes he set it to grease them every eight hours, and eventually the\nbottling line seized up.\n\n[57](part0013.html#c09-ftn57a) Justin Blum, “Hackers Target US Power Grid,”\n_Washington Post_ , March 11, 2005.\n\n[58](part0013.html#c09-ftn58a) Florida Power and Light, “FPL Announces\nPreliminary Findings of Outage Investigation,” February 29, 2008, available at\n[fpl.com/news/2008/022908.shtml](http://www.fpl.com/news/2008/022908.shtml).\n\n[59](part0013.html#c09-ftn59a) From an undated DHS slide presentation obtained\nthrough a FOIA request made by the author. The slide presentation is titled\n“Control Systems Vulnerability—Aurora.”\n\n[60](part0013.html#c09-ftn60a) The figure comes from a cost assessment\ndeveloped for the Aurora test and released by DHS in the author’s FOIA\nrequest.\n\n[61](part0013.html#c09-ftn61a) As an example of what can happen when the\ncoupling on a turbine is damaged, in 2011, a steam turbine generator at a\npower plant in Iran exploded in Iranshahr and was attributed to a coupling\nfailure. The explosion was so forceful that investigators couldn’t even _find_\nthe power turbine after the accident. Couplings need to be inspected regularly\nfor signs of wear and need to be lubricated to maintain operations and prevent\naccidents. The plant in Iranshahr had three oil burners in the room where the\ngenerator was installed, which likely exacerbated the explosion when it\noccurred. The explosion could indeed have been the result of badly maintained\ncoupling or faulty installation, but there were some at the time who thought\nit might have been the result of sabotage on par with the Aurora attack.\n\n[62](part0013.html#c09-ftn62a) Author interview, August 2012.\n\n[63](part0013.html#c09-ftn63a) Ibid.\n\n[64](part0013.html#c09-ftn64a) _60 Minutes_ , “Cyber War: Sabotaging the\nSystem,” original air date November 6, 2009, CBS.\n\n\n# CHAPTER 10\n\n# **PRECISION WEAPON**\n\nRalph Langner sat in his Hamburg office and watched as his two engineers fed a\nstream of artful lies to the Stuxnet code they had installed on their test\nmachine. Langner, an expert in the arcane field of industrial-control-system\nsecurity, had been working with his colleagues for days to identify and re-\ncreate the precise conditions under which the stubborn code would release its\npayload to their PLC, but it was proving to be more difficult than they’d\nexpected.\n\nDays earlier, Langner’s team had set up a computer with the Siemens Step 7\nsoftware installed and connected it to a Siemens PLC they happened to have on\nhand. They also installed a network analyzer to watch data as it passed\nbetween the Step 7 machine and the PLC. Unlike the Symantec researchers,\nLangner and his team worked with PLCs all the time and knew exactly what kind\nof traffic should pass between the Step 7 machine and the PLC; as a result,\nthey assumed it would be easy to spot any anomalies in the communication. But\nwhen they initially infected their Step 7 system with Stuxnet, nothing\nhappened. Stuxnet, they discovered, as others had before, was on the hunt for\ntwo _specific_ models of Siemens PLC—the S7-315 and S7-417—and they didn’t\nhave either of these models on hand.\n\nSo they installed a Windows debugger on their test machine to observe the\nsteps Stuxnet took before releasing its payload and devised a way to trick the\ncode into thinking it had found its target. Stuxnet ran through a long\nchecklist pertaining to the target’s configuration, each seemingly more\nspecific than the last. Langner and his colleagues didn’t know what exactly\nwas on the checklist, but they didn’t need to know. As Stuxnet queried their\nsystem for each item on the list, they fed it a series of manufactured\nresponses, until they landed on the answers Stuxnet wanted to hear. It was a\ncrude, brute-force method of attack that took several days of trial and error.\nBut when they finally got the right combination of answers and ran the code\nthrough its paces one last time, they saw exactly what the Symantec\nresearchers had described: Stuxnet injected a series of rogue code blocks into\ntheir PLC. “That’s it,” Langner recalls thinking. “We got the little\nmotherfucker.”[1](part0014.html#c10-ftn1)\n\nThey only noticed the rogue code going into the PLC because the blocks of code\nwere slightly larger than they should have been. Before infecting their Step 7\nsystem with the malware, they had transferred blocks of code to the PLC and\ncaptured them with the analysis tool to record their basic size and\ncharacteristics. After infecting the machine with Stuxnet, they transferred\nthe same blocks of code again and saw that they had suddenly grown.\n\nThey couldn’t yet see what the Stuxnet code was doing to the PLC, but the\ninjection itself was big news. It was way beyond anything they’d ever warned\ncustomers about and way beyond anything they expected to see in the first\nknown attack against a PLC.\n\nWHEN SYMANTEC HAD revealed on August 17 that Stuxnet was bent on sabotaging\nPLCs, it might have seemed to Chien and Falliere that no one was listening.\nBut six thousand miles away, Langner was sitting in his small office in a\nleafy suburb of Germany, reading Symantec’s words with great interest. Langner\nhad been warning industrial clients for years that one day someone would\ndevise a digital attack to sabotage their control systems and now, it\nappeared, the day had finally arrived.\n\nLangner was the owner of a three-man boutique firm that specialized in the\nsecurity of industrial control systems. It was the only thing his company did.\nHe had no interest in general computer security and couldn’t care less about\nannouncements warning of the latest viruses and worms infecting PCs. Even\nzero-day exploits held no allure for him. So when Stuxnet first made headlines\nin the technology press and became the subject of extensive chatter on\nsecurity forums, he paid it little notice. But when Symantec wrote that\nStuxnet was sabotaging Siemens PLCs, Langner was immediately intrigued.\n\nSymantec didn’t reveal what Stuxnet was doing to the PLCs, only that it was\ninjecting code into the so-called ladder logic of the PLC—whether that meant\nbringing the PLC to its knees, or worse, the antivirus firm didn’t\nsay.[2](part0014.html#c10-ftn2) But it struck Langner that thousands of\nSiemens customers, including many of his own clients, were now facing a\npotential killer virus and were waiting anxiously for Siemens or Symantec to\ntell them what exactly Stuxnet was doing to their PLCs. But, oddly, after\nmaking their startling announcement, the Symantec researchers had gone quiet.\n\nLangner suspected the researchers had hit a wall, due to their lack of\nexpertise with PLCs and industrial control systems. But curiously, Siemens had\nalso gone silent. This was strange, Langner thought. It was, after all,\nSiemens controllers that were being attacked; the company had an obligation to\nanalyze the malevolent code and tell customers what it might be doing to their\nsystems. But after a couple of brief announcements the German company had made\nin July, it had gone mum.[3](part0014.html#c10-ftn3)\n\nLangner was incensed. Although Stuxnet appeared to be targeting only Siemens\nStep 7 machines, no one really knew what the malicious code was capable of\ndoing or if it might be laced with bugs that could damage other PLCs. And\nthere was one more important concern: the vulnerability that let Stuxnet\ninject its malicious code into the ladder logic of a Siemens PLC also existed\nin other controllers.[4](part0014.html#c10-ftn4) Samples of Stuxnet were\nalready available for download on the internet; any random hacker, criminal\nextortionist, or terrorist group could study the code and use it as a\nblueprint to devise a more wide-scale and destructive attack against other\nmodels of PLCs.\n\nThis made the silence of two other parties even more perplexing—the CERT-Bund,\nGermany’s national computer emergency response team; and ICS-CERT in the\nUnited States. Both organizations were tasked with helping to secure critical\ninfrastructure systems in their respective countries, but neither party had\nsaid much about Stuxnet. There was no talk in an ICS-CERT alert about\ninjecting ladder logic into the Siemens PLCs, or even any mention of\nsabotaging them. There was also nothing at all about the dangers that Stuxnet\npresented for future attacks.[5](part0014.html#c10-ftn5) The silence of German\nauthorities was even stranger, since Siemens controllers were installed in\nalmost every German plant or factory Langner could name.\n\nLangner talked it over with his two longtime engineers, Ralf Rosen and Andreas\nTimm. None of them had any experience reverse-engineering viruses or worms,\nbut if no one else was going to tell them what Stuxnet was doing to the\nSiemens PLCs, then they would have to take it apart themselves. It would mean\ndays of doing pro bono work squeezed in between other assignments from paying\ncustomers, but they concluded they didn’t have a choice.\n\nLangner and his colleagues made an odd but effective team. In a profession\nsometimes characterized by frumpy, pale, and ponytailed engineers, Langner, a\nvigorous fifty-two-year-old with short dark hair minus any gray, sported crisp\nbusiness suits and finely crafted leather shoes. He had piercing blue eyes in\na vacation-tanned face and the trim, toned frame of a seasoned mountaineer—the\nby-product of ski excursions in the Alps and rugged hikes in the hills. If\nLangner’s dapper appearance didn’t set him apart from the pack, his brusque\nand bold manner did. He had a reputation for being an outspoken maverick, and\noften made provocative statements that riled his colleagues in the control-\nsystem community. For years he had railed about security problems with the\nsystems, but his blunt, confrontational manner often put off the very people\nwho most needed to listen. Rosen and Timm, by contrast, were both graybeard\nengineers in their forties who had a more relaxed approach to dress and\nfitness and took a quieter, more backseat role to Langner’s conspicuous one.\n\nAlthough the three of them seemed in many ways mismatched, there was probably\nno better team suited to the task of examining Stuxnet. Timm had worked for\nLangner as a control-system expert for at least a decade, and Rosen for three\nyears longer than that. During that time, they’d amassed extensive knowledge\nabout industrial control systems in general, and Siemens controllers in\nparticular. Siemens, in fact, was a longtime customer. The company bought\nsoftware products from Langner’s firm, and he and his engineers sometimes\ntrained Siemens employees on their own systems. There were probably only a\nhandful of Siemens employees who knew the Siemens systems better than they\ndid.\n\nLangner’s path to ICS security had been a circuitous one, however. He was a\ncertified psychologist by training, something seemingly far removed from the\nworld of control systems. But it was his psychology background that actually\nled to his present career. In the 1970s, while studying psychology and\nartificial intelligence at the Free University of Berlin, he began writing\nsoftware to do statistical analysis of data collected from experiments. He\nalso wrote a program that modeled human decision-making patterns to arrive at\npsychiatric diagnoses.\n\nBut it was a driver program he wrote to connect his home computer to the\nuniversity’s mainframe that ended up launching his ICS career. In college,\nLangner owned an early-generation PC that lacked the computational power\nneeded to conduct statistical analysis. Whenever he wanted to crunch data\ncollected from one of his experiments, he had to travel to the campus and plug\nhis computer into the college mainframes. Langner hated the commute to campus,\nso he studied the protocols needed to communicate with the servers remotely\nand wrote a driver program that let him dial in via modem from home.\n\nIt wasn’t much of a stretch when, after graduating college, he launched a\nsoftware-consulting firm, using his driver program as the basis for the\nbusiness. It was considered a breakthrough product at the time, and it wasn’t\nlong before control-system engineers began seeking it out to communicate with\ntheir sensors and controllers in the field. The methods they had been using at\nthe time often dropped data during transmission, and Langner’s driver proved\nto be very reliable.\n\nIn 1997, Rosen joined the firm to design custom systems for clients who wanted\nto connect desktop computers to their Siemens PLCs. As he and Langner studied\nthe Siemens protocols and PLCs to make the connections work, they were\nsurprised to find a host of security problems with the systems—the same flaws\nother researchers would find more than a decade later. They were also\nsurprised to learn that owners and operators of industrial control systems\nwere completely oblivious to these gaps in security and had therefore done\nnothing to protect their systems from attack. Instead of layered or segmented\nnetworks where critical systems were gated off from everyday business\ncomputers, they had flat network architectures that provided access to PLCs\nfrom any machine on the network. They also had systems that were directly\nconnected to the internet, with no firewalls or passwords in place to keep\nintruders out, or they used default and hardcoded passwords that never got\nchanged.\n\nLangner and his team launched a consulting business to help clients rebuild\ntheir networks more securely. But the concept of control-system security\nturned out to be a hard sell. For years, the ICS community had been largely\nimmune to the deluge of malware and hacker attacks that had pummeled the\ngeneral IT community, and as a result, most in the community didn’t think they\nwere at risk. Langner warned customers that eventually they would pay for\ntheir complacency and often demonstrated for them how an attacker with little\nskill could knock their operations offline. But few did anything to address\nthe problem. “Nobody wanted to listen,” Langner says, “except for some very\nfew companies who invested in control-system security.”\n\nNow, a decade later, Stuxnet was the bellwether Langner had warned about. But\neven he was surprised by the strength and furor of the attack when it finally\narrived. He had imagined a number of scenarios over the years for how hackers\nwould attack PLCs once the security vulnerabilities in them became publicly\nknown; but none of them involved rogue ladder logic injected into the PLC.\nComputer attacks typically evolved over time and developed incrementally.\nHackers first pulled off simple attacks that required the least amount of\neffort and skill to succeed, and security firms and software makers responded\nwith fixes to stop them. The attackers then found alternative paths into\nsystems, until the defenders defeated these as well. Each round of attack got\nprogressively more sophisticated, as defenses to defeat them did too.\nSimilarly, in the case of control systems, Langner had expected hackers would\nstart out with simple denial-of-service attacks—sending a stop command to a\nPLC to halt whatever process it controlled—then escalate to logic bombs and\nother simple techniques to alter settings. But Stuxnet bypassed the\nrudimentary stages of development and jumped straight into one of the most\nsophisticated attacks someone could devise against a PLC.\n\nOf everything that Langner saw in the code, it was the man-in-the-middle\nattack against the safety system and operator monitoring stations that really\nblew his mind. The way Stuxnet smoothly disabled the former and deviously\nrecorded the normal operations of the PLC to play them back to operators\nduring the attack was astounding to him—the digital equivalent of a six-ton\ncircus elephant performing a one-legged handstand. It was a level of grace and\nfinesse he’d never seen or even considered possible.\n\nIt was also the most aggressive scenario he could imagine, because once an\nattacker disabled the logic responsible for feeding important data to a safety\nsystem, it was only a matter of time before someone got seriously injured or\nkilled. Disable the safety system and sensors at a chemical plant or gas\nrefinery, and you could release poisonous gas or flammable liquids without\nanyone knowing until it was too late. Stuxnet’s authors might not have\nintended to injure or kill anyone with their attack, but copycat hackers who\nlearned from Stuxnet’s techniques might not be so careful.\n\nLangner estimated there were maybe a few dozen people in the world who had the\nlevel of Siemens control-system knowledge needed to design this kind of\nattack, and three of them were sitting in his office. But even they could not\nhave pulled it off with the sophistication the attackers did.\n\nTHREE WEEKS INTO their examination of Stuxnet, Langner walked into the\nconference room where he and his colleagues had been gathering each morning to\ndiscuss their progress on the code. Rosen and Timm looked him over, amused.\nOrdinarily he was crisply dressed and alert. But today he looked scruffy and\nhaggard after a sleepless night bent over a computer doing research online.\nHe’d been following one trail after another, chasing lead after lead down a\nrabbit hole trying to figure out what Stuxnet was attacking until finally he\ngrasped hold of a tail and pulled. When he retrieved his hand he was surprised\nat what he’d found. “I know what this is about,” he blurted to his colleagues.\n“This is about taking down Iran’s nuclear program. This is about taking out\nBushehr.”\n\nBushehr, as noted previously, was the nuclear power plant in southwest Iran\nthat had been under construction on and off for several decades. It had gone\nthrough many delays and cancellations over the years and had finally been\nscheduled to begin operation that month. But shortly before it was about to\nlaunch, officials announced another delay. Since the delay coincided with the\ndiscovery of Stuxnet, it seemed logical to Langner that a cyberattack might be\nat play.[6](part0014.html#c10-ftn6)\n\nRosen and Timm stared at him in disbelief. No one was dumb enough to take out\na nuclear power plant, Rosen thought. Wouldn’t they risk releasing radioactive\nmaterial? And why use an unreliable worm to do the job when they could more\nreliably damage it with a bomb? But as Langner connected the dots, his crazy\ntheory actually began to make sense to them.\n\nFor nearly a month now, since they had first observed the malicious code\nStuxnet injected into their PLC, Langner and his team had been searching\nStuxnet’s blocks of code for clues about the facilities they might be\nattacking. The configuration of the systems Stuxnet targeted could reveal as\nmuch if not more about the code’s intentions than the code itself. If they\ncould learn what kinds of devices the PLCs controlled, and whether they were\nconfigured in any distinct ways, they could narrow the range of possible\ntargets.\n\nThey labored for several weeks to decipher the blocks, working out of the\nsmall office suite they occupied on the upper floor of a two-story building.\nThe quiet, residential street where they worked was dense with trees and was a\nsharp contrast to Symantec’s modern glass complex. Instead of multiple stories\nlined with cubicles, they had one open room where Timm and Rosen worked, a\nmeeting room for clients, and office space for Langner and his assistant.\n\nEach morning they gathered to review the progress they had made, then worked\non the code the rest of the day, hashing out theories during lunch in the\nconference room and over dinner at nearby restaurants. In between, they\nresponded to customer-support calls. But when clients called to offer them new\nwork, Langner turned them all down, so intent were they on cracking Stuxnet.\nIt’s not as though they could afford to reject the paid work. They didn’t have\nanything near the corporate resources Symantec had, and no outside client was\nbankrolling their research. Instead, Langner had to pay for their time and\nlabor out of the company’s profits. But none of them were complaining. They\nall knew that Stuxnet was the job of a lifetime. “We understood this is the\nbiggest story in malware ever,” Langner recalls. “It was absolutely fantastic\nwork. It was the best work that I have ever done and I’m sure I can’t do any\nbetter.”\n\nAfter weeks of painstaking analysis, they reached a startling conclusion.\nStuxnet wasn’t just attacking two specific models of Siemens PLCs, it was\nattacking a specific facility where the PLCs were used. Stuxnet was a\nmilitary-grade precision weapon aimed at a single target. It wasn’t searching\nfor just any S7-315 and S7-417 PLC it could find: the PLCs had to be\nconfigured in a very precise way. Embedded in the attack code was a detailed\ndossier describing the precise technical configuration of the PLCs it sought.\nEvery plant that used industrial control systems had custom configurations to\nvarying degrees; even companies within the same industry used configurations\nthat were specific to their needs. But the configuration Stuxnet was looking\nfor was so precise that it was likely to be found in only a single facility in\nIran or, if more than one, then facilities configured exactly the same, to\ncontrol an identical process. Any system that didn’t have this exact\nconfiguration would remain unharmed; Stuxnet would simply shut itself down and\nmove on to the next system in search of its target.\n\nThe idea that someone had put so much money and effort into a weapon attacking\na single target left Langner dumbfounded. It could mean only one thing—the\ntarget had to be extraordinarily important. Now they just had to figure out\nwhat it was.\n\nMost of the steps involved in analyzing code are systematic and highly\ntechnical—isolate the components, decrypt the code, reverse-engineer it. But\nmapping digital code to a real-world environment is more art than science. The\nthree of them tossed around a number of hypotheses about what they thought the\ntarget might be, then sifted through the code for evidence to support them.\nMeanwhile, Langner reached out to colleagues in various industries to quiz\nthem about the configuration of their PLCs to see if he could find a match.\nBut after a number of days, they still had little success isolating Stuxnet’s\ntarget. Finally Langner decided to step back from the technical details and\napproach the problem from a different angle, searching news articles and other\nsources for clues. After several late nights spent surfing the web he finally\narrived at his theory of Bushehr.\n\nLangner’s suspicions about the plant were first roused when he recalled a\nphoto he had seen online the previous year, purportedly taken during a press\ntour at Bushehr. The image showed a computer screen with a pop-up message\nindicating that a license for the Siemens WinCC software on the machine had\nexpired. It seemed proof to Langner that Siemens software was being used at\nthe plant.[7](part0014.html#c10-ftn7) Contacts in the control-system community\nconfirmed for Langner that Siemens S7-417 PLCs were installed at Bushehr.\nFurther research revealed that the Russian firm responsible for installing\nequipment at the plant also used Siemens PLCs in other facilities it\nequipped—including a plant in Bulgaria supposedly modeled after Bushehr. The\nBulgarian plant had a steam turbine operated by Siemens controllers, Langner\nlearned, which reminded him of the Aurora Generator Test conducted by the\nIdaho National Lab three years earlier. That test had provided proof that\nmalicious code could destroy a turbine.\n\nAs the three of them sat in the conference room with Langner making his case,\nRosen and Timm found themselves nodding reluctantly in agreement with his\ntheory. They knew there were very few targets in the world that justified the\namount of work that had gone into Stuxnet. But if Langner was right and\nBushehr was the target, and physical sabotage was its goal, then Stuxnet was\nessentially an act of war.\n\nAnd if Stuxnet was an act of war, then what kind of response would its\ndiscovery elicit from Iran once news of this got out? Whoever had launched\nStuxnet might have done so to avert an all-out war with Iran—but its exposure\nnow could very well lead to one.\n\nAfter speaking with Rosen and Timm, Langner was certain he was on the right\ntrack, but just to be sure that Iran’s nuclear program was indeed the target,\nhe called up a client who had extensive knowledge of nuclear plants. The\nclient worked for Enrichment Technology Company, a top European maker of\nuranium enrichment equipment, formerly known as Urenco—the company whose early\ngeneration centrifuge designs Pakistan’s A. Q. Khan had stolen and sold to\nIran. If it wasn’t a turbine that Stuxnet was targeting, Langner thought,\nperhaps it was the centrifuges being used to enrich uranium for Bushehr.\n(Langner believed, mistakenly, that centrifuges for enriching uranium were\nhoused at Bushehr.)\n\n“I have one question for you,” Langner said to his friend over the phone. “Is\nit possible to destroy a centrifuge just by manipulating the controller code?”\n\nThere was a pause on the other end before his friend replied.\n\n“I can’t tell you that, Ralph. It’s classified information,” he said. But then\nhe added, “You know, centrifuges for uranium enrichment are not just used by\nus in Germany and the Netherlands. They’re also used in other countries.”\n\n“Yes, I know,” Langner replied. “For example, in Iran. That’s exactly why I’ve\ncalled you. Because we’re analyzing Stuxnet.”\n\n“I’m sorry,” the man responded firmly. “I can’t tell you anything about\ncentrifuges; it’s all classified.”\n\nThat was enough for Langner. He told Rosen and Timm that they had to go public\nwith the news immediately. If Bushehr was the target, then someone should be\nable to confirm it once they did. Stuxnet and its target were like a key and\nlock. There was just one lock in the world that the key would open, and once\nthey published details about the key’s design, anyone with a lock should be\nable to see if their facility matched.\n\nOn September 13, 2010, nearly a month after Symantec’s revelation that Stuxnet\nwas sabotaging PLCs, Langner published a brief blog post under the title “Hack\nof the Century.” In it, he asserted that Stuxnet was a directed attack\n“against a specific control-system installation,” and left it at that. But\nthree days later he followed up with additional information. “With the\nforensics we now have it is evident and provable that Stuxnet is a directed\nsabotage attack involving heavy insider knowledge,” he wrote. “Here is what\neverybody needs to know right now.”[8](part0014.html#c10-ftn8)\n\nWhat followed was a technical roadmap detailing the precise steps Stuxnet took\nto intercept and inject its commands into the Siemens PLC to sabotage it.\n“This is not some hacker sitting in the basement of his parents’ house,”\nLangner wrote. These were sophisticated nation-state actors with very specific\nknowledge of the system they were attacking. He described in broad terms how\nthe malware injected its rogue code into the PLC to hijack some unknown\ncritical process, then laid out his thoughts about Bushehr, carefully labeling\nthem as speculation. There were still a lot of unknowns, but the forensic\nevidence in the code, he asserted, would ultimately point them not only to the\nexact system Stuxnet attacked but also possibly to the attackers themselves.\n\nWith these few words, the jig was finally up for Stuxnet’s creators. A\ncyberweapon that had taken years and perhaps millions of dollars to plan and\ndevelop had been completely exposed and undone in a matter of weeks by an\nobscure antivirus firm in Belarus, a handful of researchers in California who\nknew nothing about centrifuges and PLCs, and a brash-talking German and his\nband of engineers.\n\nBut now that Stuxnet’s secret was out, Langner began to have the same concerns\nthat Chien had had about how the attackers might respond. Stuxnet was near\nuseless to the attackers once its true purpose was exposed. They must have\nanticipated that their code would eventually be caught and that once it was\nthey would have a narrow window of opportunity to complete their mission.\nWould they now, in a last-ditch effort to achieve their aim, take one final\nand drastic step? Langner believed they would. “We can expect that something\nwill blow up soon,” he wrote in his post. “Something big.” He signed off with\na singular warning: “Welcome to cyberwar.”\n\nAccompanying the post was a picture of the three “Stuxnet busters” snapped in\nfront of a whiteboard in their office, Langner dressed in a crisp, white shirt\nand unbuttoned suit vest, and Rosen and Timm behind him, the latter, in a\ncheeky nod to the covert nature of Stuxnet, sporting a pair of black shades.\n\nOnce he’d written his post Langner sent a press release to several top media\noutlets and waited for an explosion of headlines to hit. But to his dismay,\nnothing happened. Like Symantec’s disclosure before, the revelation was met\nwith deafening silence. “Everyone must think I’m nuts,” he remembers thinking.\n\nAt least one person didn’t think so, however. Frank Rieger, chief technology\nofficer for a German security firm called GSMK, read Langner’s speculation\nabout Bushehr and agreed that Stuxnet was likely built for sabotaging Iran’s\nnuclear program. But he suspected Natanz, several hundred miles north of\nBushehr, was the more likely target.[9](part0014.html#c10-ftn9) The Natanz\nplant, unlike Bushehr, was already operational and had been since 2007. Also\nunlike Bushehr, it was actually filled with thousands of rapidly spinning\ncentrifuges, making it a rich target for anyone wanting to cripple Iran’s\nnuclear program with a digital attack. Rieger detailed his thoughts in a blog\npost and in an article for a German newspaper.[10](part0014.html#c10-ftn10) In\nboth, he referenced an earlier Reuters piece, published right around the time\nStuxnet was unleashed in 2009, describing a “decade-old cyberwarfare project”\nlaunched by Israel against Iran’s nuclear program. The article quoted a US\nsource speculating that “malicious software” could be used to commandeer or\ncrash controls at an enrichment plant.[11](part0014.html#c10-ftn11)\n\nBut there was another reason to suspect that Natanz was Stuxnet’s target. On\nJuly 16, 2009, three weeks after the 2009 version of Stuxnet was released,\nWikiLeaks founder Julian Assange posted a cryptic note to his website about a\npossible accident at Natanz. An anonymous source claiming to be associated\nwith Iran’s nuclear program had told Assange that a “serious” nuclear accident\nhad recently occurred at the plant.[12](part0014.html#c10-ftn12) WikiLeaks\nusually published only documents on its site, not tips from anonymous sources,\nbut Assange broke protocol, he said, because he had reason to believe the\nsource was credible. He linked to a BBC story published that day, which\nannounced the resignation of Gholam Reza Aghazadeh, the head of Iran’s Atomic\nEnergy Organization, who had relinquished his position twenty days earlier for\nunknown reasons.[13](part0014.html#c10-ftn13) The time frame seemed to align\nwith when the 2009 version of Stuxnet was released.\n\nWhether or not Aghazadeh’s resignation was related to an accident at Natanz,\nRieger’s “Natanz theory” got attention and at last catapulted Stuxnet into the\nlimelight. The mainstream US media, which had largely ignored Stuxnet until\nthis point, picked up on his speculations and began reporting on the story\nthemselves. For nearly a decade, Natanz had been the focus of mounting\npolitical tension over repeated efforts to halt the enrichment program there.\nNow it seemed a sophisticated digital weapon, the likes of which had never\nbeen seen before, had been part of those plans. Suddenly the story of Stuxnet\nwas sexy and full of intrigue. Where previously it was just a dry technical\ntale of interest only to the technology press, now it had the aura of mystery\nand underworld spy games, all played out against the backdrop of a high-stakes\nnuclear showdown.\n\nShortly after Langner published his first post about Stuxnet, he contacted Joe\nWeiss in the United States to discuss what he and his team had found. Langner\nand Weiss shared the same confrontational style that didn’t always endear them\nto peers in the control-system community. They’d both been on the same side of\nthe battle for years, trying to convince ICS owners that their systems were\nvulnerable to attack. People in the community tended to sigh at the mention of\neither man’s name, but no one doubted their commitment. Langner was scheduled\nto speak at Weiss’s upcoming ICS conference in Maryland on another topic and\nasked if he could talk about Stuxnet instead. “I don’t know whether to tell\nyou yes or hell yes,” Weiss replied.\n\nLangner was on a flight to the conference the next week. Advance buzz about\nhis talk guaranteed that the conference room would be full. Langner had teased\non his blog that he would reveal full details of his team’s research at the\ngathering, so the audience was primed and eager for what he had to say,\nespecially after two presentations about Stuxnet given by Siemens and someone\nfrom DHS, respectively, turned out to be devoid of any substance.\n\nWeiss had allotted forty-five minutes for Langner’s talk, but it took up an\nhour and a half instead. No one complained, though. More than 100 attendees\nfrom the water, chemical, and electric industries hung on Langner’s words.\n“All of us were sitting with our mouths open while he was talking,” Weiss\nrecalls.[14](part0014.html#c10-ftn14) Langner was among that rare breed of\ntech guys—a skilled and charismatic orator who was adept at delivering dry\ntechnical details with humor and flair. But what he said that day was more\nthan entertaining, it shocked everyone in the room. Slowly, it dawned on the\nowners of industrial control systems that if another more widely targeted\nattack were unleashed on PLCs tomorrow, the control-system community would\nhave no way to stop or even detect it. There were ways to tell if a Windows\ndesktop PC or laptop was compromised, but with the stealth techniques that\nStuxnet used, there would be no way to tell if a PLC was infected. There was\nno such thing as antivirus software for PLCs and no easy way to know if a\ncontroller had rogue code installed if it used the same kind of subterfuge\nthat Stuxnet had used. The only way to detect an attack was at the Windows\nstage before it reached the PLC. But Stuxnet had shown the folly of even that\ndefense, since no antivirus scanner had caught it before it reached the PLCs.\nOperators would never be able to detect a warhead until it was too late.\n\nLangner suspected it would take just six months for the first copycat attacks\nto appear. They wouldn’t be exact replicas of Stuxnet, or as sophisticated in\ndesign, he told attendees, but then they wouldn’t need to be. It wasn’t just\nhigh-value targets like Natanz that were at risk of attack; Stuxnet had put\nevery vulnerable facility potentially in the crosshairs. And while Stuxnet’s\nauthors had skillfully designed their attack to avoid collateral damage on\nmachines that weren’t its target, subsequent attacks might not be as carefully\ncrafted or controlled. A criminal group bent on extorting a power plant by\nseizing control of its PLCs wouldn’t care if their malicious code damaged the\nplant or spread to other control systems as well.\n\nFollowing the conference, Langner spent the weekend in Washington, DC, to meet\nwith Melissa Hathaway, the former national cybersecurity coordinator for the\nWhite House, to brief her on what his team had found. Hathaway immediately\nunderstood the potential for blowback against US critical infrastructure as\nwell as the problem of digital weapons proliferation the world would now\nface—a problem, she later told the _New York Times_ , no country was prepared\nto deal with. “We have about 90 days to fix this,” she told the paper, “before\nsome [copycat] hacker begins using it.”[15](part0014.html#c10-ftn15)\n\nThat weekend while Langner was still in DC, Iranian officials revealed for the\nfirst time that computers at Bushehr had indeed been hit by Stuxnet. They made\nno mention of Natanz, however, and the details about the attack on Bushehr\nmade it doubtful that Stuxnet’s payload had even deployed there. Mahmoud\nJafari, a project manager for the plant, told reporters that only the personal\ncomputers of some of the plant’s workers got hit by the attack, not the\nplant’s production systems. “All computer programs in the plant are working\nnormally and have not crashed due to Stuxnet,” he\nsaid.[16](part0014.html#c10-ftn16) Reza Taghipour, an official with the\nMinistry of Communications and Information Technology, also insisted that\ndamage from the worm was minor and that the malware had been “more or less”\ncontained.[17](part0014.html#c10-ftn17) The reports of limited damage weren’t\nsurprising, given Stuxnet’s selectiveness in unleashing its destructive\npayload. It had likely spread to Bushehr’s Windows machines, then simply shut\nitself down after failing to find the PLCs it was\nseeking.[18](part0014.html#c10-ftn18)\n\nAmidst the comments from Iran, however, there was one odd detail that stood\nout. Mahmoud Jafari said in one of his interviews that _five_ versions of\nStuxnet had been found in Iran.[19](part0014.html#c10-ftn19) Symantec and\nother antivirus researchers had uncovered only three.\n\nAlthough it was possible Jafari was mistaken, the revelation raised the\nintriguing possibility that at least two other versions of Stuxnet had been\nunleashed in the wild. And if two other versions of the code existed, they\nmight contain additional clues about Stuxnet and its authors. Unfortunately,\nhowever, there was little chance that Western researchers would ever see them,\nsince Iranian officials were unlikely to provide copies of the code to anyone\noutside of Iran.[20](part0014.html#c10-ftn20)\n\nFollowing his presentation at Weiss’s conference and his meeting with\nHathaway, Langner needed downtime to make sense of all that had occurred over\nthe previous weeks. That weekend he walked to the National Mall and sat for\nhours on the steps of the Lincoln Memorial staring at the reflecting pool\nwhile tourists around him snapped photos. He thought about the reports from\nICS-CERT and Siemens and their silence about the ladder-logic injections in\nStuxnet and the risks to critical infrastructure posed by copycat attacks.\nThen there was the mind-boggling silence from the public and Congress, who\nseemed to have little concern about the Pandora’s box Stuxnet had opened in\nlegitimizing the use of cyberweapons to resolve political disputes. Neither\ndid they seem alarmed about the digital arms race Stuxnet had launched that\nwould be impossible to curb. It was as if, Langner thought, no one wanted to\ndiscuss these things for fear that it would raise questions about who was\nbehind the attack.\n\nLangner decided that if everyone else was going to be silent, then he should\ngo public with more information about the code. So once he returned to\nGermany, he published additional blog posts laying out the technical details\nthat he had previously disclosed only behind the closed doors of Weiss’s\nconference room. As soon as the posts were up, the blog was besieged with\ntraffic from around the world, including, noticeably, from US government and\nmilitary domains. Langner hoped that, with Stuxnet’s importance now clearly\nestablished, other security firms would pick up the baton where he and his\nteam had left off. Despite everything they had learned so far, there was still\na lot more work to be done. They had only discovered that Stuxnet was bent on\nsabotaging a single facility, a facility that was likely Natanz—but they still\ndidn’t know what it was doing to the plant. That information was still buried\nin the code.\n\nOver the next three weeks, he and his colleagues worked on a couple of\nprojects from paying clients to make up for the income they had lost while\nanalyzing Stuxnet. But when no new information came out about the code from\nSymantec or anyone else, Langner decided they should pick up where they had\nleft off.\n\n“Guys,” he said to Rosen and Timm, “I think we need to reopen the case.”\n\nCONTRARY TO LANGNER’S belief that the US government was ignoring Stuxnet or\nmissing important details about it, there were elements of the government that\n_were_ paying attention—albeit behind a veil of secrecy. In fact, a group of\nDHS analysts had completed most of their own examination of Stuxnet within a\ncouple of days after it was exposed in July and knew even before Symantec and\nLangner did that Stuxnet was sabotaging PLCs.\n\nStuxnet first made its way to the watch floor of the Department of Homeland\nSecurity’s National Cybersecurity and Communications Integration Center, or\nNCCIC, in Arlington, Virginia, on the morning of July 15, 2010, at the same\ntime that security researchers around the globe were getting their first look\nat the code. The files came in from CERT-Bund, after Siemens had contacted the\nComputer Emergency Response Team, to report a malicious attack that was\ntargeting its PLCs.\n\nNCCIC, or N-Kick as it’s commonly pronounced, was just nine months old and was\npart of the government’s new mission control for monitoring and coordinating\nresponses to cyber threats against critical infrastructure and civilian\ngovernment systems. When the files arrived, Sean McGurk, director of the\ncenter, was ironically in the midst of planning for the government’s upcoming\nCyber Storm III exercise, a biennial three-day drill that would simulate\ndigital attacks against US critical infrastructure. It was to be the twenty-\nfour-hour watch center’s first real test of its coordinating abilities since\nthe facility had opened. But the real threat of Stuxnet quickly took priority\nover plans for the faux attack.\n\nThe windowless watch floor was an alphabet soup of three-letter agencies, with\nintelligence analysts from the CIA and NSA sitting next to law enforcement\nagents from the FBI and Secret Service and computer security experts from US-\nCERT and ICS-CERT. Liaisons from all the top telecoms and other critical-\ninfrastructure industries were there as well.\n\nMcGurk sent a copy of Stuxnet to ICS-CERT’s lab in Idaho Falls, where analysts\ndetermined that the attack code unleashed its payload only on specific models\nof Siemens PLCs. Two years earlier, the lab’s test-bed program had conducted a\nvulnerability assessment of the same Step 7 software that Stuxnet was\nattacking, but the PLC they had used for the tests had been returned to\nSiemens. Now they had to request that Siemens send another one before they\ncould watch Stuxnet deliver its payload. It took about three weeks for the PLC\nto arrive, and when it did, a group of Siemens engineers accompanied it.\n\nIn the meantime, the researchers in Idaho reverse-engineered the payload code\nwhile analysts on the watch floor back in Virginia pored over the missile\nportion, documenting each of its functions in an extensive flow chart. Within\ntwo days, McGurk says, they had catalogued some 4,000 functions in the\ncode—more than most commercial software packages contained—and had also\nuncovered the four zero-day exploits that Symantec and Kaspersky would later\nfind.\n\nICS-CERT released an advisory on July 20 announcing to control-system owners\nthat malware targeting the Siemens Step 7 system had been found. But the\nadvisory provided very few details about its operation, saying only that the\n“full capabilities of the malware and intent … are not yet known.” A\nsubsequent advisory provided a few more details about the zero-day exploits\nStuxnet used, plus information about how to detect and remove the malicious\ncode, but said little about what the attack was designed to do and made no\nmention at all of sabotage.[21](part0014.html#c10-ftn21) McGurk says it was\nthe government’s job to help critical-infrastructure owners detect and remove\nStuxnet, not to provide extensive analysis of the\nmalware.[22](part0014.html#c10-ftn22)\n\nA few days after the group’s analysis was complete, McGurk had a conference\ncall with several government agencies and private-industry representatives to\nreview what they had found. In most discussions about malware and\nvulnerabilities, there were always a few critics in the group who downplayed\nthe vulnerability’s importance or claimed that a piece of malicious code was\nnothing new. Sometimes other federal agencies were the naysayers; sometimes it\nwas the owners and operators of critical infrastructure or the vendor that\nmade the control system that was being discussed. But as McGurk laid out the\ndetails of Stuxnet there was only silence on the phone. “Everyone had that ‘oh\nshit’ moment all at the same time,” he says.[23](part0014.html#c10-ftn23)\n\nOddly, the source of Stuxnet never came up, either during the call or on the\nNCCIC watch floor. McGurk says that when the code first arrived, intelligence\nanalysts from various agencies on the floor searched their classified data\nsources for any information or reports related to the worm, but came up with\nnothing. He also says no one on the watch floor wondered out loud if the worm\nhad been spawned by the United States. An outsider might question why no one\non the watch floor turned to the CIA or NSA analysts sitting in the room to\nask with a wink, “Is this one of yours?” But McGurk insists this never\noccurred to them because attribution wasn’t the watch floor’s concern. Their\nmission was to uncover an attack code’s capabilities and determine the best\nway for US networks to defend against it.\n\n“At first when you look at [malware]… your assumption is that it’s not\nfriendly fire. You don’t think the sniper on the roof is one of your guys\nshooting at you,” he says. “It could turn out to be … But in the heat of it,\nat the very beginning, you’re not overly concerned, nor do you naturally\ndefault to [that.]”\n\nBut very quickly, Stuxnet became “an item of high interest” in Washington.\nOver the next few weeks and months, McGurk gave briefings to a number of high-\nlevel groups—to DHS secretary Janet Napolitano, to John Brennan and other\nmembers of the White House National Security staff, to the Senate and House\nintelligence committees, the DoD, and the Defense Intelligence Agency. He even\nwent to Fort Meade to brief Gen. Keith Alexander, director of US Cyber Command\nand the NSA—the very entities that many in the security community suspected\nwere behind the attack.\n\nAt Fort Meade, a dozen senior military, government, and intelligence leaders\nsat listening to McGurk as he described what his team had found, but the\nquestion of whether the United States was behind the attack never came up.\nThey asked McGurk if Stuxnet was directed against US control systems and how\nmany US systems were vulnerable to the malicious\ncode.[24](part0014.html#c10-ftn24) They were also curious to know if McGurk’s\nteam could tell who the intended target was. And finally they asked if there\nwas anything in the code that gave away its source. McGurk told them no, there\nwere no clues revealing who was behind the attack. There weren’t even any\nfamiliar “footprints” in the code that matched the modus operandi of known\nhacker groups or nation-state spies.\n\nMcGurk maintains that never, either in classified briefings or in open\ntestimony with lawmakers, did anyone ask him the question that was on everyone\nelse’s mind. “I don’t think, even jokingly, did someone say in a formal\nbriefing, ‘Hey did we do this?’ Because that’s just not the way those\ninteractions occur. I’m sure there was speculation elsewhere, but it wasn’t\ndone at our level.”\n\nMcGurk says he also never got the impression from anyone he briefed that\nStuxnet was a homemade job. “When I was in a room, regardless of who the\naudience was, whether it was senior intelligence folks—and I mean _senior_\nintelligence folks—I never got the impression that this was all smoke-and-\nmirrors for them,” he says. “The same thing inside the Department of Homeland\nSecurity, when I was briefing up to the secretariat level. Never did I get the\nimpression that, you know, they already knew this … and they were just hoping\nthat I would go away.”\n\nNor did anyone suggest to McGurk that he should pull his team off of Stuxnet\neither. “No one said hey, cease and desist, leave it alone, don’t go there,”\nhe says. “We were actually getting a lot of cooperation from all of those\norganizations … assisting with the analysis and assisting with the\nunderstanding of what type of threat this actually posed.”\n\nBut even if officials in Washington weren’t openly asking the obvious\nquestion, there was little doubt among experts and observers that the United\nStates was behind the attack—either alone or with Israel—and it seemed only a\nmatter of time before the details behind the attack got out.\n\nRalph Langner’s assertion that Stuxnet was a precision weapon aimed at Iran’s\nnuclear program must have caused a lot of consternation and panic in the halls\nof the White House and the Pentagon, as a plot that had been meticulously\nplanned and executed over a number of years was slowly unraveling before their\neyes.\n\n* * *\n\n[1](part0014.html#c10-ftn1a) All quotes from Langner come from interviews\nconducted with him in 2010, 2011, and 2012.\n\n[2](part0014.html#c10-ftn2a) “Ladder logic” is a generic term to describe the\nstructure of commands used to code a control system. The name comes from the\nladderlike structure of the programming, which lays out each process in a\nstep-by-step, sequential fashion.\n\n[3](part0014.html#c10-ftn3a) In its initial announcement, Siemens said it had\nassembled a team of experts to evaluate Stuxnet and would begin alerting\ncustomers to their potential risk of infection from it. The company later said\nthat less than two dozen of its customers were infected with Stuxnet. The\ncompany’s second announcement had to do with the hard-coded database password\nin the Siemens software that Stuxnet used to spread. Siemens warned customers\nagainst changing the password at the risk of disrupting critical functions in\ntheir systems. “We will be publishing customer guidance shortly, but it won’t\ninclude advice to change default settings as that could impact plant\noperations,” a spokesman said a week after Stuxnet was exposed. See Robert\nMcMillan, “After Worm, Siemens Says Don’t Change Passwords,”\n[PCWorld.com](http://www.PCWorld.com), July 19, 2010.\n\n[4](part0014.html#c10-ftn4a) The vulnerability is partly due to the fact that\nthe Siemens system lacked authentication, which allowed rogue ladder logic to\nbe sent to the PLC. If the system had required the code to be digitally\nsigned, the PLC would not have accepted it.\n\n[5](part0014.html#c10-ftn5a) See ICS-CERT Advisory ICSA-10-201-01C, “USB\nMalware Targeting Siemens Control Software,” August 2, 2010, with subsequent\nupdates available at [ics-cert.us-\ncert/gov/advisories/ICSA-10-201-01C](http://www.ics-cert.us-\ncert/gov/advisories/ICSA-10-201-01C); and ICS-CERT Advisory ICSA-10-238-01B,\n“Stuxnet Malware Mitigation,” September 15, 2010, available at [ics-cert.us-\ncert/gov/advisories/ICSA-10-238-01B](http://www.ics-cert.us-\ncert/gov/advisories/ICSA-10-238-01B).\n\n[6](part0014.html#c10-ftn6a) A couple of weeks later, Iranian officials denied\nthat Stuxnet was the cause and instead attributed the delay to a leak in a\npool near the reactor.\n\n[7](part0014.html#c10-ftn7a) The screenshot, taken by a UPI photographer,\nincludes a caption identifying it as a computer screen at Bushehr and says the\nimage was snapped in February 2009. Some critics have disputed the accuracy of\nthe caption, saying the image appears to show a water-treatment facility and\nnot Bushehr, but water-treatment facilities are generally part of nuclear\nplant operations, which would explain how both could be true. The image can be\nseen at [upi.com/News_Photos/Features?The-Nuclear-Issue-in-\nIran/1581/2/](http://www.upi.com/News_Photos/Features?The-Nuclear-Issue-in-\nIran/1581/2/).\n\n[8](part0014.html#c10-ftn8a) “Stuxnet logbook, Sept 16, 2010, 1200 hours\nMESZ,” available at [langner.com/en/2010/09/16/stuxnet-logbook-\nsep-16-2010-1200-hours-mesz](http://www.langner.com/en/2010/09/16/stuxnet-\nlogbook-sep-16-2010-1200-hours-mesz).\n\n[9](part0014.html#c10-ftn9a) The article appeared in the German newspaper\n_Frankfurter Allgemeine Zeitung_ on September 22, 2010. The article is in\nGerman, but he describes its content in English in the blog post published on\nhis website, available at\n[frank.geekheim.de/?p=1189](http://www.frank.geekheim.de/?p=1189).\n\n[10](part0014.html#c10-ftn10a) At the time he speculated about Bushehr,\nLangner wasn’t aware that the nuclear reactor plant didn’t have centrifuges.\nOnce that became clear, he continued to think that Bushehr was the target, but\nthought the equipment Stuxnet was attacking was a turbine or generator at the\nplant. It was only later when more information came out about the exact\ndevices Stuxnet was targeting that he concluded that Natanz was in fact a\nmatch for Stuxnet, not Bushehr.\n\n[11](part0014.html#c10-ftn11a) Dan Williams, “Wary of Naked Force, Israelis\nEye Cyberwar on Iran,” July 7, 2009, available at\n[reuters.com/article/2009/07/07/us-israel-iran-cyberwar-analysis-\nidUSTRES663EC20090707](http://www.reuters.com/article/2009/07/07/us-israel-\niran-cyberwar-analysis-idUSTRES663EC20090707).\n\n[12](part0014.html#c10-ftn12a) The WikiLeaks post can be seen at\n[mirror.wikileaks.info/wiki/Serious_nuclear_accident_may_lay_behind_Iranian_nuke_chief%27s_mystery_resignation/](http://www.mirror.wikileaks.info/wiki/Serious_nuclear_accident_may_lay_behind_Iranian_nuke_chief%27s_mystery_resignation/).\n\n[13](part0014.html#c10-ftn13a) The story was published at:\n[news.bbc.co.uk/2/hi/8153775.dtm](http://www.news.bbc.co.uk/2/hi/8153775.dtm).\nAlthough it’s possible Aghazadeh’s resignation was related to something that\noccurred at Natanz in late June 2009, it was just as likely related to\npolitics. In addition to being head of Iran’s Atomic Energy Organization,\nAghazadeh was Iran’s vice president. He resigned both positions\nsimultaneously, two weeks after Iran’s hotly contested presidential elections\non June 12, 2009. Aghazadeh had aligned himself with President Ahmadinejad’s\npolitical challenger, Mir-Hossein Mousavi, and there was speculation that\nvehement protests over the legitimacy of the election results made it\nimpossible for Aghazadeh to retain his government positions once Ahmadinejad’s\nvictory was sanctioned. There’s also a problem of timing, which doesn’t quite\nalign with the June 2009 version of Stuxnet. According to the BBC report,\nAghazadeh resigned sometime around June 26. But the June 2009 version of\nStuxnet was unleashed June 22, and once it found itself on the right PLC, it\ntook thirteen days for the sabotage to begin. So unless an earlier version of\nStuxnet or something else caused an accident at Natanz, the timing didn’t\nmatch Aghazadeh’s resignation.\n\n[14](part0014.html#c10-ftn14a) Author interview, September 2010.\n\n[15](part0014.html#c10-ftn15a) John Markoff, “A Silent Attack, but Not a\nSubtle One,” _New York Times_ , September 26, 2010.\n\n[16](part0014.html#c10-ftn16a) Laurent Maillard, “Iran Denies Nuclear Plant\nComputers Hit by Worm,” Agence France-Presse, September 26, 2010, available at\n[iranfocus.com/en/index.php?option=com_content&view=article&id=21820](http://www.iranfocus.com/en/index.php?option=com_content&view=article&id=21820).\n\n[17](part0014.html#c10-ftn17a) David E. Sanger, “Iran Fights Malware Attacking\nComputers,” _New York Times_ , September 25, 2010.\n\n[18](part0014.html#c10-ftn18a) Six months later, a report from the Iranian\nPassive Defense Organization, a military organization chaired by Revolutionary\nGuard General Gholam-Reza Jalali, which is responsible for defending Iran’s\nnuclear facilities, contradicted these statements. It stated that Stuxnet had\nso thoroughly infected computers at Bushehr that work at the plant had to be\nhalted indefinitely. The report claimed that if Bushehr went online, the worm\nwould “bring the generators and electrical power grid of the country to a\nsudden halt.” There were plenty of reasons to doubt the report’s conclusions,\nhowever, since it contained a number of exaggerations about Stuxnet’s known\ncapabilities—such as the claim that the worm could “destroy system hardware\nstep-by-step”—and the fact that the configuration Stuxnet was seeking didn’t\nmatch what one would find at the nuclear power plant. All of this suggested\nthat Iran might be using Stuxnet as an excuse to explain delays at Bushehr.\nBut there was also the possibility that a different digital attack—a modified\nversion of Stuxnet—might have been released separately against Bushehr. See\nKen Timmerman, “Computer Worm Wreaking Havoc on Iran’s Nuclear Capabilities,”\nNewsmax, April 27, 2011, available at [newsmax.com/KenTimmerman/iran-natanz-\nnuclear-\nstuxnet/2011/04/27/id/394327](http://www.newsmax.com/KenTimmerman/iran-natanz-\nnuclear-stuxnet/2011/04/27/id/394327).\n\n[19](part0014.html#c10-ftn19a) Maillard, “Iran Denies Nuclear Plant Computers\nHit by Worm.”\n\n[20](part0014.html#c10-ftn20a) There were other statements made by officials\nthat, if true, suggested that other versions of Stuxnet existed. Mahmoud\nLiayi, head of the information technology council at the Ministry of\nIndustries, told reporters that when Stuxnet got activated, “the industrial\nautomation systems start[ed] transmitting data about production lines” to an\noutside destination. Gen. Gholam-Reza Jalali had stated at a press conference\nin 2011 that the worm was discovered communicating with systems in Israel and\nTexas. There, data about infected machines was processed by the worm’s\narchitects, who then engineered plots to attack the nuclear program. (See\n“Iran Military Official: Israel, US Behind Stuxnet Computer Worm,” Associated\nPress, April 16, 2011, available at [haaretz.com/news/world/iran-military-\nofficial-israel-u-s-behind-stuxnet-computer-\nworm-1.356287](http://www.haaretz.com/news/world/iran-military-official-\nisrael-u-s-behind-stuxnet-computer-worm-1.356287).) But the three versions of\nStuxnet that were discovered communicated with command servers in Denmark and\nMalaysia. This doesn’t discount that another version was somehow traced to\nTexas or that a spy tool that preceded Stuxnet might have been traced to\nTexas. But although the NSA does in fact have an elite hacking team based in\nthe Lone Star state, it seems unlikely that they would have made a mistake\nthat allowed the worm or a spy tool to be traced to them.\n\n[21](part0014.html#c10-ftn21a) ICS-CERT Advisory ICSA-10-201-01, “USB Malware\nTargeting Siemens Control Software” and ICS-CERT Advisory ICSA-10-238-01B,\n“Stuxnet Malware Mitigation.”\n\n[22](part0014.html#c10-ftn22a) The ICS-CERT advisories did provide a link to\nSymantec’s website for additional information about the code, but didn’t\nspecify what readers would find there.\n\n[23](part0014.html#c10-ftn23a) All quotes from McGurk from author interview,\nSeptember 2012.\n\n[24](part0014.html#c10-ftn24a) The Siemens Step 7 system, it turned out, made\nup less than 10 percent of the US control-system market. Analysts at NCCIC\ndetermined this by consulting a database used by research firms that provides\nstatistics on the market penetration of various products—including the number\nof industrial control systems made by specific vendors that had been sold in\nthe United States. They determined that most of the US Step 7 systems were\nbeing used in manufacturing facilities, though there were also some Step 7\nsystems used in agriculture and water treatment and power plants.\n\n\n# CHAPTER 11\n\n# **A DIGITAL PLOT IS HATCHED**\n\nThe halls of the White House may have been troubled over Stuxnet in 2010 after\nit was discovered, but in May 2008, optimism reigned among those who knew\nabout the covert program, as the plot behind the digital weapon was unfolding\nexactly as planned.\n\nAt the time, the US presidential campaign was in full swing as candidates\nBarack Obama and John McCain were battling it out for the lead in the polls.\nPresident Bush was just beginning the final lap of his presidency when, during\na visit to Israel to mark that country’s sixtieth anniversary, he was\nconfronted with a bold request. The Israelis wanted US support and endorsement\nfor an air strike to take out the uranium enrichment plant at Natanz.\n\nThe Israelis had been gunning for an air strike since at least 2003, when IAEA\ninspectors got their first look at Natanz and found highly enriched uranium\nparticles in environmental samples taken from the plant. Talk of an air strike\ndied down for a while after Iranian officials agreed to suspend their\nenrichment activities in 2003 and 2004, but returned in 2006 when Iran\nwithdrew from the suspension agreement and proceeded to install the first\ncentrifuges in one of the underground halls at the plant. Now, with 3,000\ncentrifuges already in place and spinning, and the number expected to double\nsoon, talk of a strike was growing louder than ever before.\n\nIsrael wasn’t the only one urging an attack. Behind closed doors, its Arab\nneighbors were just as adamant about halting Iran’s nuclear program, according\nto secret government cables released by WikiLeaks. “We are all terrified,”\nEgyptian President Hosni Mubarak told US diplomats at one\npoint.[1](part0015.html#c11-ftn1) Saudi Arabia’s King Abdullah privately urged\nthe United States to do them all a favor where Iran and Ahmadinejad were\nconcerned and “cut off the head of the snake.”[2](part0015.html#c11-ftn2) A\nnuclear-armed Iran threatened the peace of the entire region, not just Israel,\nMohammad bin Zayed, crown prince of Abu Dhabi said. If Iran got the bomb, “all\nhell will break loose,” he said, warning that Egypt, Saudi Arabia, Syria, and\nTurkey would all seek nuclear weapons to maintain\nparity.[3](part0015.html#c11-ftn3) There were hawks within the Bush\nadministration who supported an air strike as well—the “bomber boys,” as Bush\ncalled them. Vice President Dick Cheney, who had supported Israel’s attack on\nSyria the previous year, was among them.[4](part0015.html#c11-ftn4)\n\nBut Bush opposed an air strike. “I think it’s absolutely absurd that people\nsuspect I am trying to find a pretext to attack Iran,” he said in\n2007.[5](part0015.html#c11-ftn5) Even if he did support a strike, he would\nhave had difficulty drumming up widespread backing for one. A November 2007\nGallup poll showed that 73 percent of Americans preferred sanctions and\ndiplomacy to an air strike against Iran, and the National Intelligence\nEstimate, released that year, asserted that Iran was not actively developing\nnuclear weapons, which also undermined support for an air strike.\n\nIsrael had, of course, been in this position before, seeking US support for a\nstrike—in 1981 when it took out Iraq’s Osirak reactor, and again in 2007 when\nit bombed the suspected nuclear reactor in Syria.[6](part0015.html#c11-ftn6)\nIsraeli intelligence agents had obtained crucial information about the latter\nfacility in 2006 when they tailed a senior Syrian official to London and\ninstalled a Trojan horse on his laptop after he unwisely left it behind in his\nhotel room one day. The malware siphoned dozens of documents from the\ncomputer, including blueprints and photos showing construction of the Al Kibar\ncomplex, which the Israelis believed was a nuclear reactor the Syrians were\nbuilding to develop weapons. They won US support to attack the site after\nproviding evidence that North Korea was helping Syria build\nit.[7](part0015.html#c11-ftn7)\n\nLate in the evening on September 5, 2007, Operation Orchard commenced when\nIsraeli military jets departed from a base in Northern Israel and headed west\ntoward the sea before suddenly banking east. They flew low as they crossed the\nborder into Syria and took out a radar station near the Turkish border using\nelectronic attacks and precision bombs. About twenty minutes later, they\nunloaded their cargo onto the Al Kibar complex before safely returning home\nwithout incident. Syrian president Bashar al-Assad downplayed the strike,\nsaying the Israelis hit nothing but an empty military building. “There’s no\npeople in it, there’s no army, there’s nothing in it,” he\nsaid.[8](part0015.html#c11-ftn8) But US intelligence determined that the\nreactor had been just weeks away from being operational before the Israelis\ntook it out.[9](part0015.html#c11-ftn9)\n\nNow the Israelis wanted to do the same in Iran. They believed an air strike\nwould set Iran’s nuclear program back at least three years. But an attack on\nIran carried many more complications and risks than the attacks on Syria and\nIraq. In both of those cases, the Israelis had targeted a single, aboveground\nfacility that was not heavily fortified, and in the case of Syria, the target\nwas close enough to home that pilots could make their strike quickly and\nreturn before the Syrians had time to respond. A strike against Iran, however,\nwould require refueling and a flight through large swaths of Arab airspace.\nAnd, instead of a single target, the planes would have to strike at least half\na dozen sites dispersed throughout the country—the enrichment plant at Natanz\nand the uranium conversion plant at Esfahan being just two of them—some of\nwhich were underground. Iran had learned from the Israeli attack on Iraq\ndecades earlier that the key to preserving its nuclear program was to disperse\nfacilities around the country, and US officials had “little confidence” that\nIsrael even knew the location of all the facilities it needed to strike to\ncripple the program.[10](part0015.html#c11-ftn10) Israel’s national security\nadviser Giora Eiland even admitted as much when he told a US congressional\ndelegation in 2006, “We don’t know all the sites and we don’t know what we\ndon’t know.”[11](part0015.html#c11-ftn11)\n\nIn his State of the Union address in January 2002, President Bush had\nidentified Iran as part of the “axis of evil,” along with Iraq and North\nKorea, that threatened the peace of the world. The United States, he said,\nwould not permit “the world’s most dangerous regimes” to “threaten us with the\nworld’s most destructive weapons.”[12](part0015.html#c11-ftn12) They were\nstrong words. But in the intervening years—years filled with the difficulties\nof prosecuting a war in Iraq—Bush had softened his stance. US Defense\nSecretary Robert M. Gates was convinced an attack on Iran would not only fail\nbut would have wide-ranging repercussions on US troops in Iraq and\nAfghanistan. It might also trigger terrorist retaliation against Israel from\npro-Iran groups in Lebanon and the Gaza Strip and disrupt oil prices, sending\neconomic shockwaves around the world. Most important, instead of curbing\nIran’s nuclear ambitions, it could set Iran on an even more determined course\nto nuclear weapons and cause officials to kick IAEA inspectors out of the\ncountry, taking their nuclear activities even further underground and out of\nsight.\n\nFor all of these reasons and more, Bush rejected Israel’s push for an air\nstrike, but not without an alternative strategy to take its\nplace.[13](part0015.html#c11-ftn13)\n\nTwo years earlier, Bush’s advisers had offered him what seemed like an even\nbetter solution to the problem with Iran, possibly even a brilliant one. And\nin the spring of 2008, while he was touring Israel for the last time as\npresident, it looked like they might actually pull it off.\n\nIT’S NOT CLEAR exactly when the first planning and development on Stuxnet\nbegan, but sometime in 2006, after Iran withdrew from its suspension\nagreement, US military and intelligence officials reportedly brought the\nproposal for the cyber operation, later dubbed “Olympic Games,” to the\npresident. Bush had been weighing his options for a while. With two protracted\nand complex wars already being fought in Iraq and Afghanistan, he had already\ndecided he wanted no part in a third battle in the Middle East. On-the-ground\ncovert attacks that physically sabotaged Iran’s nuclear sites also were ruled\nout, since they, too, would likely spark a war.[14](part0015.html#c11-ftn14)\n\nSo his advisers proffered a third option—a digital bunker buster that, if\ndesigned and executed carefully, could achieve some of the same results as its\nkinetic counterparts, without all of the risks and consequences of those other\nattacks.\n\nThe military and intelligence communities had been preparing for an attack\nlike this for nearly a decade and had engaged in smaller cyber operations\nbefore, but nothing at the scale they were proposing now. Most previous\noperations were simply spy missions carried out with digital tools or digital\noperations conducted as adjuncts to conventional warfare—cyber activities\nmeant to simply assist troops on the battlefield, not take their\nplace.[15](part0015.html#c11-ftn15)\n\nThis innovative new plan, however, called for a digital attack against the\ncentrifuges and computer systems at Natanz to physically sabotage Iran’s\nuranium enrichment efforts. The requirements and restrictions for such an\noperation were extensive. It had to be a surgical strike capable of homing in\non the specific machines the United States wanted to attack while leaving\nother systems unharmed. The code had to bypass internal security systems so\nthat it could do its dirty deed undetected for months. And it had to cause\nenough damage for the results to have meaningful effects, without drawing\nattention to itself.\n\nBut if the attack succeeded, the potential payoff was huge. If a cyberstrike\ncould destroy some of Iran’s IR-1 centrifuges or otherwise slow the country’s\nrapid race to nuclear breakout, it would relieve some of the pressure on\ndiplomatic efforts and give the IAEA and intelligence agencies more time to\ngather evidence about Iran’s nuclear aspirations. It would also get the\nIsraelis off their backs for a while. Israeli officials had accused the United\nStates of dragging its feet on Iran; a digital attack on the nuclear program\nwould prove that the United States wasn’t just sitting idly by, waiting for\nsanctions and diplomacy to succeed.\n\nMore important, if centrifuges were destroyed and uranium gas was wasted in\nthe process, it would deplete Iran’s already dwindling supply of precious\nmaterials for the nuclear program. Experts estimated that Iran had only enough\nmaterials to build 12,000 to 15,000 centrifuges; if an attack could force Iran\nto waste a few thousand of the devices, it would cut sharply into that supply.\nIf luck was on their side, it could also create a political rift in the\nIranian regime. There was already pressure on Ahmadinejad and his supporters\nto achieve progress in the nuclear program; if a covert attack thwarted their\nefforts and set the program back a few years, it could very well sow\ndissension within the regime.\n\nThe advantages of a cyberattack over other forms of attack were many. A\ndigital bomb could achieve some of the same effects as a kinetic weapon\nwithout putting the lives of pilots at risk. It could also achieve them\ncovertly in a way a physical bomb could never do, by silently damaging a\nsystem over weeks and months without being detected. The Iranians would\neventually see the effects of the digital sabotage, but if done well, they\nwould never know its cause, leaving them to wonder if the problem was a\nmaterial defect, a programming error, or something else. Even if the Iranians\ndiscovered the malware, a digital attack done properly left no fingerprints to\nbe traced back to its source. This plausible deniability was key, since the\nUnited States was trying to prevent a war, not start one.\n\nThere were other benefits to a digital attack. Air strikes had obvious\ndisadvantages when it came to bombing facilities buried deep underground, as\nNatanz and other Iranian facilities were.[16](part0015.html#c11-ftn16) But a\ndigital attack could slip past air-defense systems and electrified fences to\nburrow effortlessly into infrastructure deep underground that was otherwise\nunreachable by air and other means. It could also take out centrifuges not\njust in known facilities but in _unknown_ ones. You couldn’t bomb a plant you\ndidn’t know about, but you could possibly cyberbomb it. If Iran had other\nsecret enrichment plants distributed throughout the country that used the same\nequipment and configuration as Natanz, a digital weapon planted in the\ncomputers of the contractors who serviced them all could spread from known\nfacilities to unknown ones.\n\nDigital sabotage, albeit on a far less sophisticated level, wasn’t without\nprecedent. In the 1980s, the CIA, the DoD, and the FBI had run a joint\noperation to sabotage software and hardware headed to the Soviet Union. It\nbegan after Lt. Col. Vladimir Ippolitovich Vetrov, a forty-eight-year-old\nofficial in the Line X division of the KGB’s Technology Directorate, began\nleaking intelligence to the French about a decade-long Soviet operation to\nsteal technology from the West.\n\nVetrov leaked about three thousand documents, dubbed the “Farewell Dossier” by\nthe French, detailing a long list of technologies the Soviets had already\npilfered from the West as well as a wish list of items still to be procured.\nWhen the wish list made its way to Dr. Gus Weiss, an economics adviser to\nReagan’s National Security Council, he proposed a shrewd plan to then-CIA\ndirector William Casey. The CIA would let the Soviets continue to obtain the\ntechnology they wanted—but with the spy agency slipping modified designs and\nblueprints into the mix to misdirect their scientific efforts toward money-\nwasting ventures. He also proposed modifying products and components before\nthey reached the Iron Curtain so that they would pass any quality-assurance\ntests the Soviets might subject them to, then fail at a later date. The plan\nwas a veritable win-win because even if the Soviets discovered the\ncounterintelligence operation, they would forever be suspicious of any\ninformation or technology later acquired from the West, never certain how or\nif it had been altered or when it might malfunction. It would be a “rarity in\nthe world of espionage,” Weiss later wrote in an internal CIA newsletter\ndescribing the scheme: “an operation that would succeed even if\ncompromised.”[17](part0015.html#c11-ftn17)\n\nUnder the scheme, “contrived computer chips found their way into Soviet\nmilitary equipment, flawed turbines were installed on a gas pipeline, and\ndefective plans disrupted the output of chemical plants and a tractor\nfactory,” Weiss wrote. Additionally, the Soviets were fed misleading\ninformation about stealth and tactical aircraft as well as Western space\ndefense programs. The Soviet Space Shuttle was also built on “a rejected NASA\ndesign” that had been slipped to the Soviets, Weiss\nrevealed.[18](part0015.html#c11-ftn18)\n\nThe Farewell operation was never discovered, according to Weiss, but Vetrov\nwas not so lucky. He was imprisoned in 1982 after stabbing his mistress, a\nmarried KGB colleague, and was exposed as a double agent—though the CIA’s\nsabotage efforts remained a secret.[19](part0015.html#c11-ftn19) In 1986, the\nCIA shuttered the operation.\n\nWeiss, who is now dead, never specified the effects of the contrived computer\nchips and other defective parts that were slipped into the Soviet supply\nchain, but in 2004, Thomas C. Reed, who worked with Weiss on the National\nSecurity Council, wrote a book that briefly mentioned the Farewell Dossier and\nattributed a 1982 Siberian pipeline explosion to the CIA scheme—the same\npipeline explosion that Symantec referenced in its blog post about Stuxnet.\nAccording to Reed, one of the items on the Line X shopping list was software\nfor controlling the pumps, valves, and turbines on the Trans-Siberian\nPipeline, which was being built to carry natural gas from the Urengoi gas\nfields in Siberia to countries in Europe. When the CIA learned the Soviets\nwere trying to obtain the software from a company in Canada, the agency, in\ncooperation with the firm, embedded a logic bomb in the code. The code was\ndesigned to reset pump speeds and valve settings on the pipeline to “produce\npressures far beyond those acceptable to the pipeline joints and welds,” Reed\nwrote.[20](part0015.html#c11-ftn20) The software “ran the pipeline\nbeautifully—for a while,” he noted. But then at some predetermined point it\ncaused the pumps and valves to go haywire, creating a gas-pressure buildup so\nimmense it set off a three-kiloton explosion—the “most monumental non-nuclear\nexplosion and fire ever seen from space,” according to Reed.\n\nThere are many who believe the story of the exploding pipeline is apocryphal;\na former KGB official has denied the tale and believes Reed and Weiss confused\ntheir facts.[21](part0015.html#c11-ftn21) Regardless, the Farewell Dossier\noperation did exist and served as inspiration for later sabotage schemes\nfocused on Iran’s nuclear program.\n\nOne such operation occurred after the CIA infiltrated A. Q. Khan’s nuclear\nsupply network around 2000 and began inserting doctored parts into components\nheaded to Iran and Libya—where Khan had also begun peddling his illicit\nnuclear services. A weapons expert at Los Alamos National Laboratory worked\nwith the CIA to alter a series of vacuum pumps so that they would malfunction\nat random intervals. As with the operation against the Soviets, the plan was\nto sabotage the parts so subtly that they would work fine for a little while\nbefore breaking down in such a way that it would be difficult to spot a\npattern or pinpoint the problem.\n\nOf seven pumps the CIA compromised, six of them went to Libya; but the seventh\none ended up in Iran. IAEA inspectors later stumbled across it by chance when\nthey visited Natanz.[22](part0015.html#c11-ftn22) The Iranians apparently\ndidn’t know the pump had been altered.\n\nThey did, however, discover another sabotage operation that occurred in 2006.\nThis one involved UPSes—uninterruptible power supplies—obtained from Turkey.\nUPSes help regulate the flow of electricity and are important to the operation\nof centrifuges, which require reliable and consistent energy to spin for long\nperiods of time at uniform speeds. If the electrical current wavers, the\ncentrifuges will speed up and slow down, sabotaging the enrichment process and\neven throwing the centrifuges themselves off balance.\n\nThe Khan network evidently purchased the devices from two businessmen in\nTurkey and secretly shipped them to Iran and\nLibya.[23](part0015.html#c11-ftn23) But in early 2006, when Iran attempted to\nenrich its first batch of uranium in a small cascade at the pilot plant at\nNatanz, things went terribly wrong. The cascade ran fine for about ten days,\nbut then the sabotage kicked in and all of the centrifuges had to be replaced.\nNo one said anything about it at the time. But a year later, during a\ntelevised interview, the head of Iran’s Atomic Energy Organization described\nwhat had occurred. Technicians had installed 50 centrifuges in the cascade, he\nexplained, but one night “all 50 had exploded.” The UPS controlling the\nelectricity “had not acted properly,” he said, and created a surge. “Later we\nfound out that the UPS we had imported through Turkey had been manipulated.”\nHe also said that after the incident occurred they began checking all imported\ninstruments before using them.[24](part0015.html#c11-ftn24)\n\nThere have been other known plans to alter parts and components for Iran’s\nnuclear program, but at least one was aborted, while others failed to work as\nplanned.[25](part0015.html#c11-ftn25) What Bush’s advisers were proposing in\n2006, however, promised to take the black art of sabotage to a whole new\nlevel.\n\nWhat they proposed was a stand-alone surgical strike involving code that could\noperate independently once unleashed, that had the intelligence to know when\nit had found its target and would only release its payload when conditions\nwere right, that also disguised its existence by carefully monitoring attempts\nto detect it, and that had the ability to destroy physical equipment not\nthrough bold, explosive strokes but through subtle, prolonged ones.\n\nSome officials in the Bush administration were skeptical that such an attack\ncould work, likening it to an untried science\nexperiment.[26](part0015.html#c11-ftn26) But the planners weren’t expecting\nmiracles from the operation. They didn’t expect to destroy Iran’s uranium\nenrichment program altogether, just to set it back and buy some time. And even\nif the operation were discovered and the Iranians learned that their computers\nhad been infiltrated, it would still be a win-win situation, as Weiss had\npointed with the Farewell Dossier, since it would succeed in sowing doubt and\nparanoia among the Iranians. Even if technicians wiped their machines clean\nand reprogrammed them, they could never be certain that the systems wouldn’t\nbe infected again or that their enemies wouldn’t try a different tack. They\nwould always be on guard for any signs of trouble, and if something did go\nwrong, they would never know for certain if the cause had been a material\ndefect or enemy sabotage. They’d also be much more wary of any equipment\nprocured outside of Iran for fear that it might have already been compromised.\n\nThe daring and sophisticated scheme, which combined both covert and\nclandestine activities, was reportedly conceived by US Strategic Command—the\nDefense Department division that operates and oversees the country’s nuclear\nweapons—with Gen. James Cartwright as one of its\narchitects.[27](part0015.html#c11-ftn27) A former senior U.S. official\ndescribed General Cartwright as the concept man, while former NSA Director\nKeith Alexander was responsible for executing the plan. “Cartwright’s role was\ndescribing the art of the possible, having a view or a vision,” the official\ntold the _Washington Post._ But Alexander had the “technical know-how and\ncarried out the actual activity.”[28](part0015.html#c11-ftn28) The code was\nthen developed by an elite team of programmers at the NSA, at least initially.\nLater versions reportedly combined code from the NSA with code from the\nIsraeli Defense Force’s Unit 8200—Israel’s version of the NSA. Once the code\nwas designed, however, it would have been handed off to the CIA to oversee\ndelivery to its destination, since only the CIA has legal authority to conduct\ncovert operations.\n\nThe technical challenges of the operation were daunting, but there were legal\nissues to work out as well, since they were proposing to attack another\ncountry’s infrastructure outside of a declaration of war. Covert action\nrequires a legal document known as a Presidential Finding to authorize it, as\nwell as notification to Congress. And before Bush signed off on the operation,\nthere would have been extensive review to consider the risks\ninvolved.[29](part0015.html#c11-ftn29)\n\nLuckily, sabotaging the centrifuges in a cascade carried no risk of a nuclear\naccident. Uranium hexafluoride gas was destructive to lungs and kidneys if\ninhaled in sufficient quantities, but an entire cascade contained only tens of\ngrams of gas, which would dissipate quickly once released into the air.\n\nBut if there was no risk of a nuclear incident to consider, there were still\nother consequences to weigh, including the risk of bricking the computers at\nNatanz if the code contained an error or a bug that was incompatible with the\nsystems, thereby tipping off the Iranians to the attack and ruining the\noperation. There was also the risk of retaliation if Iran discovered that the\nUnited States was behind the attack, as well as the risk of blowback if\nsomeone altered the code and used it against American critical infrastructure.\n\nPerhaps the biggest consideration of all was the risk of tipping off Iran and\nother enemies to US cyber capabilities. The problem with using a cyberweapon,\nsays one former CIA agent, is that “once it’s out there, it’s like using your\nstealth fighter for the first time—you’ve rung that bell and you can’t pretend\nthat the stealth fighter doesn’t exist anymore. So the question is, which air\nbattle do you really want to use that stealth fighter\nfor?”[30](part0015.html#c11-ftn30)\n\nWas the operation against Iran worth exposing this new capability? And what\nabout losing the moral high ground if it became known that the United States\nwas behind the attack? A digital assault that destroyed another country’s\ncritical infrastructure—and Iran would no doubt claim that the centrifuges\n_were_ critical infrastructure—was essentially an act of war. It would be very\nhard for the United States to point an accusing finger at any nation that used\ndigital attacks thereafter.\n\nIt’s unclear how much advance research and work had already been done by the\ntime Bush’s advisers proposed their plan in 2006. But once he gave the go-\nahead for the covert operation to advance, it reportedly took just eight\nmonths to finalize the scheme.[31](part0015.html#c11-ftn31)\n\nIt was an ingenious plot that proceeded exactly as planned.\n\nUntil suddenly it didn’t.\n\n* * *\n\n[1](part0015.html#c11-ftn1a) _Spiegel_ staff, “Cables Show Arab Leaders Fear a\nNuclear Iran,” _Der Spiegel_ , December 1, 2010.\n\n[2](part0015.html#c11-ftn2a) US State Department cable, from CDA Michael\nGfoeller, April 20, 2008, available at\n[nytimes.com/interactive/2010/11/28/world/20101128-cables-\nviewer.html#report/iran-08RIYADH649](http://www.nytimes.com/interactive/2010/11/28/world/20101128-cables-\nviewer.html#report/iran-08RIYADH649).\n\n[3](part0015.html#c11-ftn3a) “Cables Show Arab Leaders Fear a Nuclear Iran,”\n_Der Spiegel_.\n\n[4](part0015.html#c11-ftn4a) Jeffrey Goldberg, “The Point of No Return,” _The\nAtlantic Monthly_ , September 2010.\n\n[5](part0015.html#c11-ftn5a) Catherine Collins and Douglas Frantz, _Fallout:\nThe True Story of the CIA’s Secret War on Nuclear Trafficking_ (New York: Free\nPress, 2011), 212.\n\n[6](part0015.html#c11-ftn6a) In June 1991 when then–Defense Secretary Cheney\nvisited Israel, he reportedly gave Israeli Maj. Gen. David Ivry a satellite\nimage of the Osirak reactor taken after it was obliterated. Cheney annotated\nthe image: “For General Ivry, with thanks and appreciation for the outstanding\njob he did on the Iraqi Nuclear Program in 1981, which made our job much\neasier in Desert Storm.” See Douglas Frantz and Catherine Collins, _The\nNuclear Jihadist: The True Story of the Man Who Sold the World’s Most\nDangerous Secrets_ (New York: Free Press, 2007), 190.\n\n[7](part0015.html#c11-ftn7a) Erich Follath and Holger Stark, “The Story of\n‘Operation Orchard’: How Israel Destroyed Syria’s Al Kibar Nuclear Reactor,”\n_Der Spiegel_ , November 2, 2009. For information about the electronic warfare\nused to take out the radar station, see David A. Fulghum, “U.S. Watches\nIsraeli Raid, Provides Advice,” _Aviation Week_ , November 21, 2007.\n\n[8](part0015.html#c11-ftn8a) Julian Borger, “Israeli Airstrike Hit Military\nSite, Syria Confirms,” _Guardian_ , October 1, 2007.\n\n[9](part0015.html#c11-ftn9a) David Albright notes that when fully operational,\nthe reactor could have produced enough plutonium for a nuclear weapon every\none to two years. David Albright, _Peddling Peril: How the Secret Nuclear\nTrade Arms America’s Enemies_ (New York: Free Press, 2010), 3.\n\n[10](part0015.html#c11-ftn10a) Tim Shipman, “U.S. Pentagon Doubts Israeli\nIntelligence Over Iran’s Nuclear Program,” _Telegraph_ , July 5, 2008.\n\n[11](part0015.html#c11-ftn11a) US State Department cable, “Israeli NSA Eiland\non Iranian Nuclear Threat,” April 26, 2006, published by WikiLeaks at\n<http://wikileaks.org/cable/2006/04/06TELAVIV1643.html>.\n\n[12](part0015.html#c11-ftn12a) Erich Follath and Holger Stark, “The Birth of a\nBomb: A History of Iran’s Nuclear Ambitions,” _Der Spiegel_ , June 17, 2010.\n\n[13](part0015.html#c11-ftn13a) David E. Sanger, “U.S. Rejected Aid for Israeli\nRaid on Iranian Nuclear Site,” _New York Times_ , January 10, 2009.\n\n[14](part0015.html#c11-ftn14a) David E. Sanger, “Iran Moves to Shelter Its\nNuclear Fuel Program,” _New York Times_ , September 1, 2011.\n\n[15](part0015.html#c11-ftn15a) See [chapter 12](part0016.html) for more on the\nhistory of the US government’s cyberwarfare capabilities.\n\n[16](part0015.html#c11-ftn16a) In mid-2007, Western satellites spotted\nevidence of a possible tunnel being built into a mountain adjacent to Natanz,\npossibly to sequester materials and equipment from an anticipated attack on\nthe plant. The NCRI reported that Iran was in fact constructing secret tunnels\nin more than a dozen locations around the country to protect missile and\nnuclear installations from potential attack. Israel had secured an agreement\nto obtain a new generation of bunker-busting bombs from the United States—said\nto be ten times more powerful than the previous generation and capable of\nbreaking through cement and penetrating deep underground. But the new bombs\nweren’t expected to be ready until 2009 or 2010 and there was no guarantee\nthey would work against Natanz. See David Albright and Paul Brannan, “New\nTunnel Construction at Mountain Adjacent to the Natanz Enrichment Complex,”\nISIS, July 9, 2007, available at [isis-online.org/uploads/isis-\nreports/documents/IranNatanzTunnels.pdf](http://www.isis-\nonline.org/uploads/isis-reports/documents/IranNatanzTunnels.pdf). See also\nWilliam Broad, “Iran Shielding Its Nuclear Efforts in Maze of Tunnels,” _New\nYork Times_ , January 5, 2010.\n\n[17](part0015.html#c11-ftn17a) The newsletter was later declassified. See Gus\nWeiss, “The Farewell Dossier: Strategic Deception and Economic Warfare in the\nCold War,” in _Studies in Intelligence_ , 1996, available at\n<https://www.cia.gov/library/center-for-the-study-of-intelligence/csi-\npublications/csi-studies/studies/96unclass/farewell.htm>.\n\n[18](part0015.html#c11-ftn18a) According to Weiss, the CIA also launched a\nmisinformation campaign around a laser weapons technology to convince the\nSoviets that the unproven technology was something they should pursue. When\nthe CIA found Soviet documents discussing the technology, the agency arranged\nfor renowned physicists to plant stories about it in _Nature_ and another\nreputable publication to create buzz about it as if it were a promising\ndiscovery. Then they abruptly halted publication of information on the matter,\nto make the Soviets think the technology had strategic importance and that\nconversations about it had been stifled. Weiss said the Soviets must have\ntaken the bait because years later, when the Soviet Union collapsed, evidence\nwas found that the Soviets had been pursuing research on the laser technology.\n\n[19](part0015.html#c11-ftn19a) The complete story of Vetrov’s life and the\nFarewell Dossier is recounted in Sergei Kostin and Eric Raynaud, _Farewell:\nThe Greatest Spy Story of the Twentieth Century._ The book, published in\nFrench in 2009, was translated into English by Catherine Cauvin-Higgins and\npublished in 2011 by Amazon Crossing. The book was made into a French film\nreleased in 2009 titled _L’affaire Farewell._\n\n[20](part0015.html#c11-ftn20a) Thomas C. Reed, _At the Abyss: An Insider’s\nHistory of the Cold War_ (New York: Presidio Press, 2004), 268–69.\n\n[21](part0015.html#c11-ftn21a) Reed’s account of the pipeline explosion, the\nfirst to be published, has taken on a life of its own and been re-reported\nmany times as fact, though no reporters have been able to substantiate it.\nThere are reasons to doubt the story. According to Reed, the explosion was\ncaptured by US infrared satellites and caused a stir among members of the\nNational Security Council at the time, who were trying to determine whether\nthe Soviets had detonated an atomic device in Siberia when Weiss told them not\nto worry about it. Weiss never explained why they shouldn’t worry about it,\nbut twenty years later when Reed was writing his book, Weiss told him the\ncause of the explosion they had been concerned about was CIA sabotage. But\nVasily Pchelintsev, the former head of the KGB in the region where Reed said\nthe explosion occurred has said it never happened, and that Weiss may have\nconflated his memory of the Farewell Dossier incident with an explosion that\noccurred in April 1982 in a different region. But that explosion, Pchelintsev\nsaid, was caused by shifting pipes that moved when snow melted, not by CIA\nsabotage. See Anatoly Medetsky, “KGB Veteran Denies CIA Caused ’82 Blast,”\n_Moscow Times_ , March 18, 2004.\n\nAsked if he believed Weiss’s account of the pipeline, Reed told me in a phone\ninterview in October 2010, “I don’t really know if it happened.… Clearly the\nwhole Dossier episode happened. The agency had a very major campaign to adjust\nthe tech of stuff that was being sent off to the Russians.” He said he does\nrecall that an explosion occurred at the time he was on the NSC. “I remembered\nthere was a great event that puzzled the intelligence community.” But whether\nthat was in fact a pipeline explosion, “that was thirty years ago,” he said,\nacknowledging that both his and Weiss’s memories may have been altered in the\nensuing years. “I have respect for Russian historians who say there was no\nexplosion in connection with Dossier.… So it could be there was an explosion,\nbut it was not a result of a Trojan horse.… Whether it was true or not I do\nnot know.” It may be too much to hope, however, that any future retellings of\nthe pipeline tale will be done with the appropriate caveats.\n\n[22](part0015.html#c11-ftn22a) When IAEA inspectors saw the pump at Natanz, it\nstood out for them because a sticker was affixed to it identifying it as\nproperty of the Los Alamos National Lab, which they thought was odd. When the\nIAEA investigated, the agency found that the serial number on the pump was\nconsecutive with the serial numbers of pumps they had seen in Libya,\nindicating the pumps had all come from the same batch. The inspectors traced\nthe order for the pumps to the US lab. No one was ever able to figure out how\nthe Los Alamos sticker got onto the pump at Natanz, or why the Iranians\nweren’t suspicious of it. See Collins and Frantz, _Fallout_ , 138.\n\n[23](part0015.html#c11-ftn23a) Frantz and Collins, _Nuclear Jihadist_ , 238.\n\n[24](part0015.html#c11-ftn24a) Gholam Reza Aghazadeh interview, January 2007,\nwith _Ayande-ye_ (New Future). The interview itself is not online, but it’s\nreferenced in Sheila MacVicar and Farhan Bokhari, “Assessing Iran’s Nuclear\nProgram,” CBS News, April 4, 2007, available at [cbsnews.com/news/assessing-\nirans-nuclear-program](http://www.cbsnews.com/news/assessing-irans-nuclear-\nprogram).\n\n[25](part0015.html#c11-ftn25a) One ill-conceived plan conjured by the Mossad\nand the CIA, as described in James Risen’s _State of War_ , involved using an\nelectromagnetic pulse to fry computers used in Iran’s nuclear facilities.\nSpies planned to smuggle equipment into Iran that would deliver the\nelectromagnetic pulse to power transmission lines outside the facilities. The\nCIA dropped the plan, however, after realizing that the equipment was far too\nbig to truck into Iran and position stealthily. Risen, _State of War: The\nSecret History of the CIA and the Bush Administration_ (New York: Free Press),\n208–9.\n\n[26](part0015.html#c11-ftn26a) Sanger, “U.S. Rejected Aid for Israeli Raid.”\n\n[27](part0015.html#c11-ftn27a) _Clandestine_ operations involve secret\nactivity that isn’t meant to be detected or noticed, such as surveillance and\nintelligence collection activities to uncover information about a target that\nmight be later attacked. _Covert_ activity, however, is meant to be noticed,\nsince it’s intended to influence conditions—political, economic, or\nmilitary—although the party responsible for the activity is hidden, such as\nthe CIA. The Stuxnet operation involved both clandestine and covert activity.\nThe clandestine activity involved the initial reconnaissance to gather\nintelligence about the plant. But the planting of malicious code in a control\nsystem to send centrifuges spinning off their axis was covert since it was\nmeant to be noticed while hiding the hand behind it.\n\n[28](part0015.html#c11-ftn28a) Ellen Nakashima and Joby Warrick. “Stuxnet Was\nWork of U.S. and Israeli Experts, Officials Say,” _Washington Post_ , June 2,\n2012.\n\n[29](part0015.html#c11-ftn29a) Sanger, “U.S. Rejected Aid for Israeli Raid.”\n\n[30](part0015.html#c11-ftn30a) Author interview, 2012.\n\n[31](part0015.html#c11-ftn31a) David E. Sanger, _Confront and Conceal: Obama’s\nSecret Wars and Surprising Use of American Power_ (New York: Crown, 2012),\n193.\n\n\n# CHAPTER 12\n\n# **A NEW FIGHTING DOMAIN**\n\nBy the time Bush’s advisers floated the idea of a precision digital weapon\naimed at sabotaging Iran’s centrifuges to him, plans for developing such\ncapabilities had already been in the works for a decade, born out of the\nrealization that the military’s own networks were vulnerable to enemy attack.\n\nAcademics and military experts had been pondering the concept of cyberwarfare\nand the potential for digital weaponry even longer than that. As early as\n1970, the Defense Science Board had examined the potential military advantages\nof subverting computer networks to render them unreliable or useless in what\nwas then known as information warfare. Few operations were computerized at the\ntime, however, and the internet didn’t exist, so the theoretical possibilities\nhad to wait for reality to catch up.\n\nIt finally did in the ’90s, around the same time the term “cyberwar” was\ncoined in a seminal 1993 RAND article titled “Cyberwar Is Coming!”: “We\nanticipate that cyberwar may be to the 21st century what _blitzkrieg_ was to\nthe 20th century,” John Arquilla and his coauthor wrote at the\ntime.[1](part0016.html#c12-ftn1) Arquilla, now a professor at the Naval\nPostgraduate School in California and a military consultant, recognized the\npotential for digital attacks during the first Gulf War when the United States\nused a special radar system to spot moving targets in Iraq and realized it\ncould easily have been thwarted if the Iraqis found a way to disrupt it. It\nstruck Arquilla that the computerized technologies that made a modern army\nstrong also made it potentially very weak. “What made that thought even more\nchilling was the notion that this power existed in the hands of a few\nhackers,” he later said, not just in the hands of government armies. And the\ndisruptive power of these peripheral groups was “growing by leaps and\nbounds.”[2](part0016.html#c12-ftn2)\n\nThe military already had its first taste of their capabilities in the 1980s,\nwhen a German named Markus Hess, who was reportedly recruited by the KGB,\nhacked into hundreds of military systems and research facilities, such as\nLawrence Berkeley National Laboratory, in search of intelligence about\nsatellites and the Star Wars defense system.[3](part0016.html#c12-ftn3) Other\nscares followed. In 1990 in the run-up to the first Gulf War, Dutch teens\nbroke into nearly three-dozen US military computers seeking information about\nPatriot missiles, nuclear weapons, and the operation against Iraq. Officials\nfeared the teens planned to sell the intelligence to Iraq. Then in 1994, a\nsixteen-year-old British hacker, mentored by a twenty-one-year-old in Wales,\nbreached US Air Force systems and used them to hack into a South Korean\nnuclear research institute, as well as attacking one hundred other victims.\nWith the breach appearing to come from US military computers, it became clear\nthat the potential consequences of such intrusions weren’t limited to\nintelligence theft. The United States was engaged in delicate nuclear\nnegotiations with North Korea at the time, and the military feared that if the\nhackers had targeted a facility in North Korea instead, they could have\nbrought the two nations to the brink of battle.[4](part0016.html#c12-ftn4)\n\nBut connectivity was a double-edged sword. If US systems were vulnerable to\nattack, so were the systems of adversaries. Although the United States didn’t\nhave the capabilities to pull off such attacks yet, the wheels were being set\nin motion.\n\nThe Air Force was the first to take steps in this direction in 1993, when it\ntransformed its Electronic Warfare Center into the Air Force Information\nWarfare Center and established, two years later, the 609 Information Warfare\nSquadron—the military’s first cybercombat unit.[5](part0016.html#c12-ftn5)\nLocated at Shaw Air Force Base in South Carolina, its job was to combine\noffensive and defensive cyber operations in support of combat\ncommands.[6](part0016.html#c12-ftn6) Offensive operations were largely still\nacademic at this point, so the unit focused mostly on defensive tactics. But\nthe military quickly learned that there were advantages to having defensive\nand offensive operations intertwined, because in defending its own networks\nagainst enemy attack it gained the intelligence and skills needed to hack\nback. In 1996, the squadron organized a red team/blue team exercise to test\nthe unit’s offensive and defensive skills, and within two hours the red team\nhad seized full control of the blue team’s Air Tasking Order System.\n\nIn 1997 the military conducted a more organized exercise to measure its\ndefensive capabilities against enemy network attacks. The exercise, dubbed\n“Eligible Receiver,” pitted a red team of NSA hackers against the networks of\nthe US Pacific Command in Hawaii. The team was prohibited from using inside\nknowledge to conduct the attack or anything but off-the-shelf tools that were\navailable to ordinary hackers. When the attack began, they launched their\noffensive through a commercial dial-up internet account and barreled straight\ninto the military’s networks with little resistance. The system administrators\nin Hawaii, who had no advance knowledge of the exercise, spotted only two of\nthe multiple intrusions the attackers made over the course of ninety days, but\neven then they thought nothing of the breaches because they resembled the kind\nof ordinary traffic that administrators expected to see on the network. It\nwasn’t unlike the attack on Pearl Harbor in 1941, when an alert operator at\nthe Opana Radar Site on the island of Oahu spotted inbound aircraft heading\ntoward the island but didn’t raise an alarm because his superiors believed\nthey were friendlies.\n\nThe red-team hackers dropped marker files onto the systems to plant a virtual\nflag, proving they were there, and also created a number of simulated attacks\nshowing how they could have seized control of power and communications\nnetworks in Oahu, Los Angeles, Chicago, and Washington, DC. Had they wanted\nto, they could have seized control of a system used to command hundreds of\nthousands of troops or set up “rolling blackouts and other activities that\nwould cause social unrest,” according to Lt. Gen. John H. Campbell, a now-\nretired Air Force general who headed the Pentagon’s information operations at\none time. The exercise “scared the hell out of a lot of folks,” Campbell later\nsaid, “because the implications of what this team had been able to do were\npretty far-reaching.”[7](part0016.html#c12-ftn7)\n\nAfterward, when military leaders were briefed about the exercise, they assumed\nthe red team had used classified tools and techniques for the attack and were\nsurprised to learn that the NSA had used the same techniques any teenage\nhacker would use.\n\nThe next year, in fact, a group of teenagers broke into military networks\nusing the same kinds of low-level techniques, in a case dubbed Operation Solar\nSunrise. The intruders, who pilfered sensitive data across five hundred\nsystems, turned out to be two California teens on a digital joyride, egged on\nby an Israeli hacker named Ehud Tenenbaum. At the time, the DoD was\nprosecuting two military campaigns, in Bosnia and Herzegovina and in Iraq. The\nintrusion, to military leaders, looked a lot like what enemy attackers would\ndo if they were trying to gain a battlefield advantage. Deputy Defense\nSecretary John Hamre, in fact, thought the attacks “might be the first shots\nof a genuine cyber war, perhaps by Iraq.”[8](part0016.html#c12-ftn8) It was a\nreal-life _War Games_ moment that underscored the difficulty of distinguishing\na nation-state attack from teenagers testing their limits. “Everything we\nlearned in Eligible Receiver, we relearned in Solar Sunrise,” Hamre later said\nof the intrusion. “There’s nothing like a real-world experience to bring the\nlessons home.”[9](part0016.html#c12-ftn9)\n\nThe real lesson, though, came afterward when Hamre called a meeting to discuss\nthe intrusion and looked around a room filled with two-dozen people to ask,\n“Who’s in charge? Who’s responsible for protecting us?” and learned that when\nit came to cyberattacks, no one apparently was in charge. The shock of this\nrealization led to the creation of the Joint Task Force–Computer Network\nDefense (JTF-CND) in December 1998, the first military group charged with\nfiguring out how to defend the military’s\nnetworks.[10](part0016.html#c12-ftn10)\n\nThe task force, led by Campbell, was a motley group composed of a couple of\nAir Force and Navy fighter pilots, a Marine officer, some Airborne Rangers, a\nsubmarine pilot, intelligence staff, and a few contractors. One officer\ndescribed them as “some guys in flight jackets …[and] a bunch of civilians\nwith no ties.”[11](part0016.html#c12-ftn11) Only a few of them were geeks who\nknew their way around a network. Initially they had no office and no support\nstaff and had to work out of temporary trailers in a parking lot. But\neventually the group grew to more than 150 people.\n\nTheir mission was to develop doctrines and methods for defending DoD networks\nagainst attack, but before they got started, they had two questions for the\nmilitary brass: Should they develop a NORAD-type structure to defend civilian\ncritical infrastructure as well? And what about offense? “All of us wanted to\nget into the attack mode,” recalls Marcus Sachs, an Army engineer and one of\nthe task force’s initial members. “Everyone was thinking about the potential\nfor launching digital bullets.… We wanted to go down that road and kind of\nflush out what would it mean for us to be\noffensive.”[12](part0016.html#c12-ftn12)\n\nIt was the era of hacker conferences like Def Con and HOPE, two confabs held\nin Las Vegas and New York that became popular forums for hackers and\nresearchers to talk about security holes and hacking\ntools.[13](part0016.html#c12-ftn13) The FBI and intelligence agencies were\nalready lurking undercover at Def Con each year, so Sachs decided to attend as\nwell and had his eyes opened to the possibilities of what the military might\ndo. But the task force was told to slow down, that the military wasn’t ready\nfor offensive operations yet. “The legal questions hadn’t been worked out,”\nSachs explains.\n\nThere was another reason for caution, however. A cyberweapon was the “type of\nweapon that you fire and it doesn’t die. Somebody can pick it up and fire it\nright back at you,” Sachs says. “That was a very strong motivator to not do\nthis.”\n\nWhat Sachs didn’t know at the time was that the previous year, the secretary\nof defense had already given the NSA authority to begin developing computer\nnetwork attack (CNA) techniques, a task the spy agency embraced as an\nextension of its existing electronic warfare duties, which included jamming\nenemy radar systems and taking out communication\nchannels.[14](part0016.html#c12-ftn14) The NSA believed its technical geniuses\ncould play a critical role on the emerging digital battlefield as well.\n\nThe advantages of digital combat over kinetic warfare were clear, the NSA\nwrote in an internal newsletter in 1997.[15](part0016.html#c12-ftn15) In an\nage of televised warfare, when images of body bags brought the stark realities\nof war back to the homefront, cyberwarfare offered an antiseptic alternative\nthat the public could more easily embrace. But there were other advantages\ntoo, the report noted: the low cost of entry to conduct such campaigns; a\n“flexible base of deployment,” where being “in range” of a target wasn’t a\nnecessity; and a diverse and ever-expanding set of targets as more and more\ncritical systems became computerized.\n\nThe spy agency, in fact, was already contemplating, a decade before Stuxnet,\nthe offensive opportunities presented by the world’s growing reliance on\ncomputerized control systems in critical infrastructure. Another article in\nthe same newsletter proposed building a road map to track the technologies\nthat were already on the shelves, as well as those that were still “a twinkle\nin some engineer’s eye,” in order to develop attack capabilities against\nthem.[16](part0016.html#c12-ftn16) The newsletter also suggested compiling a\nlist of public hacking tools already available for use—viruses, worms, logic\nbombs, Trojan horses, and back doors. These powerful tools “if effectively\nexecuted,” the author noted, “[could be] extremely destructive to any\nsociety’s information infrastructure.”[17](part0016.html#c12-ftn17) That\nincluded, however, US infrastructure. “So … before you get too excited about\nthis ‘target-rich environment,’ ” the newsletter cautioned the agency’s would-\nbe cyberwarriors, “remember, General Custer was in a target-rich environment\ntoo!”[18](part0016.html#c12-ftn18)\n\nDespite obvious interest in pursuing digital attacks, however, the legal\nissues continued to confound. In the spring of 1999, as NATO forces were\nraining bombs onto Yugoslavia, the Air Force Association convened a closed-\ndoor symposium in Texas to ponder the capabilities of what was still referred\nto as “information warfare.” Gen. John Jumper, commander of US Air Forces in\nEurope, told the gathering that while information warfare conjured images of\nseizing an enemy’s “sacred infrastructure,” the military was not there yet.\nCyberweapons were still largely laboratory fare, and the only information\nwarfare being waged at that point was between the lawyers, policymakers, and\nmilitary leaders in Washington who were still arguing over the value and\nlegality of network attacks.[19](part0016.html#c12-ftn19) Jumper told the\ngathering, “I picture myself around that same targeting table where you have\nthe fighter pilot, the bomber pilot, the special operations people and the\ninformation warriors. As you go down the target list, each one takes a turn\nraising his or her hand saying, ‘I can take that target.’ When you get to the\ninfo warrior, the info warrior says, ‘I can take the target, but first I have\nto go back to Washington and get a [presidential]\nfinding.”[20](part0016.html#c12-ftn20)\n\nSomething began to change in 2000, however, when the Pentagon’s network\ndefense task force was suddenly told to add offensive operations to its\nmission and to develop a doctrine for their use. The change in focus also led\nto a name change. Instead of Joint Task Force–Computer Network Defense, they\nwere now to be called Joint Task Force–Computer Network Operations. The change\nwas subtle to avoid attracting attention, Sachs says, but internally it\nsignaled the military’s readiness to begin seriously planning offensive\noperations.\n\nThe questions the task force now had to ponder were many. Was an offensive\nnetwork attack a military action or a covert operation? What were the\nparameters for conducting such attacks? Taking out computerized communication\nsystems seemed like an obvious mission for an offensive operation, but what\nabout sabotaging the computer controls of a weapons system to misdirect its\naim or cause it to misfire?[21](part0016.html#c12-ftn21) And who should be\nresponsible for conducting such operations? Until then, if the Air Force\nneeded an enemy’s radar system taken out, it worked jointly with the NSA’s\nelectronic warfare team. But the NSA was an intelligence outfit whose primary\njob was intercepting communications. Taking out the computers that controlled\nan artillery system seemed more the territory of combat units.\n\nWith the addition of the offensive mission to the task force, Maj. Gen. James\nD. Bryan became the task force’s new commander. But Deputy Defense Secretary\nHamre made it clear that defense was still the group’s priority, and that\noffensive operations were to be mere accessories to conventional military\noperations, not a replacement for them.\n\nThat is, until the terrorist attacks on 9/11, which Bryan recalled, “changed\nthe dynamics for us.” Offensive operations suddenly took on more importance,\nand for the first time, the group began to approach offensive cyberattacks the\nway they approached kinetic ones—as a means of taking out targets, not just\nexploiting computers for intelligence-gathering purposes or to retard their\nperformance. “We actually went out into the combatant commands and asked them\nfor their target list,” he later recalled. “And we actually went through the\ndrill of weighting them and analyzing them and prioritizing them on a global\nscale.”[22](part0016.html#c12-ftn22)\n\nUS offensive operations advanced further in 2003 when the Pentagon prepared a\nsecret “Information Operations Roadmap” aimed at turning information warfare\ninto a core military competency on par with air, ground, maritime, and special\noperations.[23](part0016.html#c12-ftn23) The classified report, released with\nredactions a few years later, noted that a comprehensive process was already\nunder way to evaluate the capabilities of cyberweapons and spy tools and\ndevelop a policy for their use. The latter included trying to determine what\nlevel of data or systems manipulation constituted an attack or use of force\nand what qualified as mere intelligence gathering. What actions could be\nlegally undertaken in self-defense, and what level of attribution was needed\nbefore the United States could attack back? Also, could the United States use\n“unwitting hosts” to launch an attack—that is, transit through or control\nanother system to attack an adversary—if the unwitting host faced retribution\nas a result?\n\nIn 2004, to accommodate this increased focus on offensive operations, the\nDefense Department split its offensive and defensive cyber operations into two\ndivisions, a move that signaled for many the beginning of the militarization\nof cyberspace. The defensive division became known as Joint Task Force–Global\nNetwork Operations, while the offensive division was called the Joint\nFunctional Component Command–Network Warfare. The latter was housed at Fort\nMeade, home of the NSA, but placed under the US Strategic Command and the\nleadership of Marine Corps Gen. James E. Cartwright. But the following year,\nsome say, is when the “cult of offense” really began—when Gen. Keith Alexander\ntook over as director of the NSA from Gen. Michael Hayden, and the focus on\ndeveloping cyberweapons for warfare ramped up. It was during this period that\nOperation Olympic Games and Stuxnet were hatched.\n\nSix years later, in May 2010, as Stuxnet was spreading wildly on computers\naround the world and was about to be exposed, the Pentagon recombined its\ndefensive and offensive cyber operations under the newly formed US Cyber\nCommand. The new division was still part of the US Strategic Command but was\nunder the command of NSA director Alexander, giving the spy leader\nunprecedented authority over both intelligence operations and cyber military\nones. Three months after the US Cyber Command was formed, the Pentagon\nformally recognized cyberspace as the “fifth domain” of warfare after air,\nland, sea, and space.\n\nThis was all just formal recognition, however, of activity that had already\nbeen occurring in varying degrees for a decade. Due to the classified nature\nof offensive operations, however, the public has only had minor hints of these\nactivities as they have leaked out over the years.\n\nIn the late ’90s in Kosovo, for example, NATO forces may have used certain\ncyber techniques “to distort the images that the Serbian integrated air\ndefense systems were generating,” according to John Arquilla, who worked for\nUS Strategic Command at the time.[24](part0016.html#c12-ftn24) President\nClinton also reportedly approved a covert cyber operation to target the\nfinancial assets of Yugoslavian president Slobodan Miloševic in European\nbanks, though there are conflicting reports about whether the operation\nactually occurred.[25](part0016.html#c12-ftn25) In 2003, when a similar\ncyberattack was proposed to freeze the financial assets of Saddam Hussein,\nhowever, it was nixed by the secretary of the US Treasury out of concern that\nan attack like this could have cascading effects on other financial accounts\nin the Middle East, Europe, and the United\nStates.[26](part0016.html#c12-ftn26)\n\nIn 2007, the US reportedly assisted Israel with a cyberattack that accompanied\nits bombing of the Al Kibar complex in Syria by providing intelligence about\npotential vulnerabilities in the Syrian defense systems. As previously noted,\nbefore Israeli pilots reached the facility, they took out a Syrian radar\nstation near the Turkish border using a combination of electronic jamming and\nprecision bombs. But the Israelis also reportedly hacked Syria’s air-defense\nsystem using on-board technology for an “air-to-ground electronic attack” and\nthen further penetrated the system through computer-to-computer links,\naccording to US intelligence analysts.[27](part0016.html#c12-ftn27) A recent\nreport from the US Government Accountability Office describes air-to-ground\nattacks as useful for reaching “otherwise inaccessible networks” that can’t be\nreached through a wired connection.[28](part0016.html#c12-ftn28)\n\nIn 2011, during the civilian uprising in Libya, there had also been talk of\nusing cyberattacks to sever that country’s military communications links and\nprevent early-warning systems from detecting the arrival of NATO warplanes.\nThe plan was nixed, however, because there wasn’t enough time to prepare the\nattack. The need for a longer lead time is one of the primary drawbacks of\ndigital operations—designing an attack that won’t cascade to nontargeted\ncivilian systems requires advance reconnaissance and planning, making\nopportunistic attacks difficult.[29](part0016.html#c12-ftn29)\n\nMore recently, leaks from former NSA systems administrator Edward Snowden have\nprovided some of the most extensive views yet of the government’s shadowy\ncyber operations in its asymmetric war on terror. The documents describe NSA\nelite hacker forces at Fort Meade and at regional centers in Georgia, Texas,\nColorado, and Hawaii, who provide US Cyber Command with the attack tools and\ntechniques it needs for counterterrorism operations. But the government\ncyberwarriors have also worked with the FBI and CIA on digital spy operations,\nincluding assisting the CIA in tracking targets for its drone assassination\ncampaign.\n\nTo track Hassan Ghul, an associate of Osama bin Laden who was killed in a\ndrone strike in 2012, the NSA deployed “an arsenal of cyber-espionage tools”\nto seize control of laptops, siphon audio files, and track radio\ntransmissions—all to determine where Ghul might “bed down” at night, according\nto Snowden documents obtained by the _Washington\nPost_.[30](part0016.html#c12-ftn30) And since 2001, the NSA has also\npenetrated a vast array of systems used by al-Qaeda associates in Yemen,\nAfrica, and elsewhere to collect intelligence it can’t otherwise obtain\nthrough bulk-data collection programs from internet companies like Google and\nYahoo or from taps of undersea cables and internet nodes.\n\nTerrorism suspects aren’t the NSA’s only targets, however. Operations against\nnation-state adversaries have exploded in recent years as well. In 2011, the\nNSA mounted 231 offensive cyber operations against other countries, according\nto the documents, three-fourths of which focused on “top-priority” targets\nlike Iran, Russia, China, and North Korea. Under a $652-million clandestine\nprogram code named GENIE, the NSA, CIA, and special military operatives have\nplanted covert digital bugs in tens of thousands of computers, routers, and\nfirewalls around the world to conduct computer network exploitation, or CNE.\nSome are planted remotely, but others require physical access to install\nthrough so-called interdiction—the CIA or FBI intercepts shipments of hardware\nfrom manufacturers and retailers in order to plant malware in them or install\ndoctored chips before they reach the customer. The bugs or implants operate as\n“sleeper cells” that can then be turned on and off remotely to initiate spying\nat will.[31](part0016.html#c12-ftn31) Most of the implants are created by the\nNSA’s Tailored Access Operations Division (TAO) and given code names like\nUNITEDDRAKE and VALIDATOR. They’re designed to open a back door through which\nNSA hackers can remotely explore the infected systems, and anything else\nconnected to them, and install additional tools to extract vast amounts of\ndata from them. The implants are said to be planted in such a way that they\ncan survive on systems undetected for years, lasting through software and\nequipment upgrades that normally would eradicate\nthem.[32](part0016.html#c12-ftn32) In 2008, the NSA had 22,252 implants\ninstalled on systems around the world. By 2011, the number had ballooned to\n68,975, and in 2013, the agency expected to have 85,000 implants installed,\nwith plans to expand this to millions. But the embarrassment of riches\nprovided by so many implants has created a problem for the NSA. With so many\nimplants lurking on systems around the world, the spy agency has been unable\nin the past to take advantage of all the machines under its control. In 2011,\nfor example, NSA spies were only able to make full use of 10 percent of the\nmachines they had compromised, according to one Snowden document. To remedy\nthis, the agency planned to automate the process with a new system code named\nTURBINE, said to be capable of managing millions of implants\nsimultaneously.[33](part0016.html#c12-ftn33)\n\nAll of these operations, however—from Kosovo to Syria to Libya, and the ones\nexposed in the Snowden documents—have focused on stealing or distorting data\nor using cyber methods to help deliver physical bombs to a target. None\ninvolved a digital attack as _replacement_ for a conventional bomb. This is\nwhat made Stuxnet so fundamentally different and new.\n\nStuxnet stands alone as the only known cyberattack to have caused physical\ndestruction to a system. But there are hints that the United States has been\npreparing for others. In October 2012, President Obama ordered senior national\nsecurity and intelligence officials to produce a list of foreign\ntargets—“systems, processes and infrastructures”—for possible cyberattack,\naccording to a top-secret Presidential Directive leaked by\nSnowden.[34](part0016.html#c12-ftn34) Whether the United States actually\nintends to attack them or just wants to have plans in place in case a\nsituation arises is unclear. But such operations, the directive noted, could\nprovide “unique and unconventional” opportunities “to advance US national\nobjectives around the world with little or no warning to the adversary or\ntarget and with potential effects ranging from subtle to severely damaging.”\n\nThe surge in offensive operations and the planning for them has been matched\nby an equal surge in the demand for skilled hackers and attack tools needed by\nthe NSA to conduct these operations. Although most of the implants used by the\nNSA are designed in-house by the agency’s TAO division, the NSA also budgeted\n$25.1 million in 2013 for “covert purchases of software vulnerabilities” from\nprivate vendors—that is, the boutique firms and large defense contractors who\ncompose the new industrial war complex that feeds the zero-day gray\nmarket.[35](part0016.html#c12-ftn35) This trend in government outsourcing of\noffensive cyber operations is visible in the job announcements that have\nsprung up from defense contractors in recent years seeking, for example,\nWindows “attack developers” or someone skilled at “analyzing software for\nvulnerabilities and developing exploit code.” One listing for defense\ncontractor Northrop Grumman boldly described an “exciting and fast-paced\nResearch and Development project” for an “Offensive Cyberspace Operation\n(OCO),” leaving little ambiguity about the nature of the work. Others are more\nsubtle about their intentions, such as a listing for Booz Allen Hamilton, the\ncontractor Snowden worked for while at the NSA, seeking a “Target Digital\nNetwork Analyst” to develop exploits “for personal computer and mobile device\noperating systems, including Android, BlackBerry, iPhone and iPad.” Many of\nthe job listings cite both CND (computer network defense) and CNA (computer\nnetwork attack) among the skills and expertise sought, underscoring the double\nduty that vulnerability and exploit research can perform in both making\nsystems secure and attacking them.\n\nWho are the people filling these jobs? Sometimes they’re people like Charlie\nMiller, the mathematician mentioned in [chapter 7](part0011.html) who was\nrecruited by the NSA for code and computer cracking. And sometimes they’re\nformer hackers, wanted by law enforcement as much for breaking into US\ngovernment systems as they are coveted by spy agencies for their ability to do\nthe same against an adversary. A shortage of highly skilled candidates in the\nprofessional ranks who can fill the demand for elite cyberwarriors has led the\nmilitary and intelligence agencies to recruit at hacker conferences like Def\nCon, where they may have to forgive a hacker’s past transgressions or lower\ntheir expectations about office attire and body piercings to attract the\nchoicest candidates. One code warrior employed by a government contractor told\nan interviewer that he worried that his history hacking US government systems\nwould preclude him from working with the feds, but the staffing company that\nhired him “didn’t seem to care that I had hacked our own government years ago\nor that I smoked pot.”[36](part0016.html#c12-ftn36)\n\nHe described a bit of the work he did as part of a team of five thousand who\nlabored out of an unmarked building in a nondescript office park in Virginia.\nWorkers were prohibited from bringing mobile phones or other electronics into\nthe building or even leaving them in their car.\n\nAs soon as he was hired, the company gave him a list of software programs they\nwanted him to hack, and he quickly found basic security holes in all of them.\nHis group, he said, had a huge repository of zero-day vulnerabilities at their\ndisposal—“tens of thousands of ready-to-use bugs” in software applications and\noperating systems for any given attack. “Literally, if you can name the\nsoftware or the controller, we have ways to exploit it,” he said. Patched\nholes didn’t worry them, because for every vulnerability a vendor fixed, they\nhad others to replace it. “We are the new army,” he said. “You may not like\nwhat the army does, but you still want an army.”[37](part0016.html#c12-ftn37)\n\nThis expansion in government bug-hunting operations highlights an important\nissue that got little consideration when the DoD task force was first\ndeveloping its offensive doctrine a decade ago, and that even today has\nreceived little public attention and no debate at all in Congress—that is, the\nethical and security issues around stockpiling zero-day vulnerabilities and\nexploits in the service of offensive operations. In amassing zero-day exploits\nfor the government to use in attacks, instead of passing the information about\nholes to vendors to be fixed, the government has put critical-infrastructure\nowners and computer users in the United States at risk of attack from criminal\nhackers, corporate spies, and foreign intelligence agencies who no doubt will\ndiscover and use the same vulnerabilities for their own operations.\n\nAs noted previously, when researchers uncover vulnerabilities, they generally\ndisclose them to the public or privately to the vendor in question so that\npatches can be distributed to computer users. But when military and\nintelligence agencies need a zero-day vulnerability for offensive operations,\nthe last thing they want to do is have it patched. Instead, they keep fingers\ncrossed that no one else will discover and disclose it before they’ve finished\nexploiting it. “If you’ve built a whole operational capability based on the\nexistence of that vulnerability, man, you’ve just lost a system that you may\nhave invested millions of dollars and thousands of man hours in creating,”\nAndy Pennington, a cybersecurity consultant for K2Share said at a conference\nin 2011. Pennington is a former weapons-systems officer in the Air Force whose\njob before retiring in 1999 was to review new cyberspace technologies and\nengineer next-generation weapons for the Air\nForce.[38](part0016.html#c12-ftn38) “You are not going to hire teams of\nresearchers to go out and find a vulnerability and then put it on the web for\neverybody to see if you’re trying to develop [an attack for it],” he later\nsaid in an interview.[39](part0016.html#c12-ftn39) “We’re putting millions of\ndollars into identifying vulnerabilities so that we can use them and keep our\ntactical advantage.”\n\nBut it’s a government model that relies on keeping everyone vulnerable so that\na targeted few can be attacked—the equivalent of withholding a vaccination\nfrom an entire population so that a select few can be infected with a virus.\n\nOdds are that while Stuxnet was exploiting four zero-day vulnerabilities to\nattack systems in Iran, a hacker or nation-state cyberwarrior from another\ncountry was exploiting them too. “It’s pretty naïve to believe that with a\nnewly discovered zero-day, you are the only one in the world that’s discovered\nit,” Howard Schmidt, former cybersecurity coordinator for the White House and\nformer executive with Microsoft, has said. “Whether it’s another government, a\nresearcher or someone else who sells exploits, you may have it by yourself for\na few hours or for a few days, but you sure are not going to have it alone for\nlong.”[40](part0016.html#c12-ftn40)\n\nCertainly the .LNK vulnerability that Stuxnet used was already known by the\nZlob banking gang in 2008, two years before Stuxnet used it. Information about\nthe print-spooler vulnerability was also in the public domain for others to\ndiscover and use.[41](part0016.html#c12-ftn41) Who knows how long the other\nzero days Stuxnet used might have been known and used by others in different\nattacks? In 2007, Immunity, a security firm in Florida, determined that the\naverage zero-day exploit survived in the wild 348 days before being discovered\non systems. The ones with the longest life-span could live in hiding for\nnearly three years.[42](part0016.html#c12-ftn42) Today the situation isn’t\nmuch different, with the average life-span of a zero day now ten months, and\nothers lurking in systems undiscovered for as long as two and a half\nyears.[43](part0016.html#c12-ftn43)\n\nShortly after he took office in 2009, President Obama announced that\ncybersecurity in general and securing the nation’s critical infrastructure in\nparticular were top priorities for his administration. But withholding\ninformation about vulnerabilities in US systems so that they can be exploited\nin foreign ones creates a schism in the government that pits agencies that\nhoard and exploit zero days against those, like the Department of Homeland\nSecurity, that are supposed to help secure and protect US critical\ninfrastructure and government systems.\n\nIn his remarks at the 2011 conference, Andy Pennington acknowledged that there\nwere “competing interests” in government when it came to the vulnerability\nissue, but he said when the government found vulnerabilities it wanted to\nexploit, it used “coordinated vulnerability disclosure”—a kind of limited\ndisclosure—to “facilitate the defense of the United States” in a way that\nstill allowed the government to retain the ability to attack. He said the DoD\nworked “very closely with Microsoft on the enterprise side,” as well as with\nthe makers of control systems, to let them know about vulnerabilities found in\ntheir systems. “But I would like to stress again that the objective is to\nhandle this … so that we can sustain operations,” he said. To that end, you\nwould want to be “very deliberate [in] how you disclose it and how it’s\nfixed.”[44](part0016.html#c12-ftn44) Though he didn’t elaborate on what\nlimited disclosure involved, others have suggested it’s about providing\ninformation about vulnerabilities to DoD administrators—so they can take steps\nto protect military systems from being attacked—while still withholding it\nfrom the vendor and the public, to prevent adversaries from learning about\nthem. Microsoft also reportedly gives the government and private companies\nadvance notice when it learns of new security holes found in its software, to\nhelp the government take steps to protect its systems before a patch is\navailable. But this can equally serve as a handy tipoff to the NSA to retire\nany exploits already being used to attack that vulnerability—before Microsoft\ndiscloses it publicly—or, conversely, to quickly exploit machines using the\nvulnerability before it gets patched.[45](part0016.html#c12-ftn45)\n\nGreg Schaffer, former assistant secretary of Homeland Security, told NPR that\nDHS, which helps protect the government’s nonmilitary systems, does\noccasionally get assistance “from the organizations that work on the offensive\nmission,” though he didn’t indicate if this meant sharing information with DHS\nabout vulnerabilities so they could be patched.[46](part0016.html#c12-ftn46)\nBut “whether they bring their work [to us] is something they have to decide,”\nhe said. “That is not something that we worry about.”\n\nAnother DHS official, however, says he can’t recall having “ever seen a\nvulnerability come to us from DoD in a disclosure.… We would like to have as\nmany vulnerabilities disclosed and coordinated as possible to give us the best\ndefensive posture.” But while it was frustrating not to get such disclosures,\nhe recognized that it was “the nature of the beast” if the government was to\nstill retain its ability to attack adversaries, and he didn’t see any way to\nresolve it.[47](part0016.html#c12-ftn47)\n\nThough information about vulnerabilities might not get passed from the\noffensive side to the defensive side to be fixed, there were in fact times\nwhen vulnerabilities uncovered by the defensive side got passed to the\noffensive side. This might occur, for example, to make sure that a\nvulnerability in a control system already being exploited by the NSA or other\nagencies wasn’t disclosed and patched too soon. A former DHS official said\nthat this “vulnerabilities equities process” for control systems, as it’s\ncalled, began some time after the Aurora Generator Test was conducted in 2007.\nSince then, vulnerabilities that government researchers find in other control\nsystems get vetted by an equities panel to make sure their disclosure won’t\nharm ongoing operations. “If someone is using it … under their authorities for\na legitimate purpose … well, we’d have to balance the necessity of disclosing\nit based on the value of leaving it open for a while,” the former official\nsaid.\n\nThe equities process in government has a long tradition. In World War II, for\nexample, when the British cracked Germany’s Enigma code and discovered that\nAllied convoys were being targeted by the Germans, they had to weigh the\nbenefits of redirecting convoys away from attack—and thus risk tipping off the\nGermans that their code had been cracked—against the cost of sacrificing a\nconvoy to continue exploiting a critical intelligence source.\n\nThe US equities process involves a central committee composed of\nrepresentatives from multiple departments and agencies—DoD, Justice\nDepartment, State Department, Homeland Security, the White House, and the\nintelligence community—and is patterned after one developed by the Committee\non Foreign Investment in the United States, known as the CFIUS process, which\nweighs the national security implications of foreign investments in the United\nStates.\n\nIn the case of software vulnerabilities, if government researchers discover a\nsecurity hole in a PLC that is commonly used, for example, they submit the\nfinding to the committee to see if anyone has an equity interest in it.\n“Everyone has a say in the likelihood of impacts to companies or systems [from\nthe vulnerability being disclosed or not],” the official said. “It’s all done\nvia e-mail on a classified network, and everyone comes back and says yea or\nnay. And if there’s a yea, then we discuss it. If everything is nay, then we\njust go on our normal responsible vulnerability disclosure process.”\n\nAsked if DHS ever passed information about vulnerabilities to the offensive\nside so that they could specifically be exploited, he said no. But he\nacknowledged that the very act of discussing vulnerabilities with the equities\ncommittee might inadvertently provide members with ideas about new\nvulnerabilities to exploit. While he says he never heard anyone on the\ncommittee tell an industrial control system representative not to publicly\ndisclose a vulnerability so they could exploit it, he acknowledged that they\nprobably wouldn’t be so overt about it. “They would probably just silently\ntake notes, and we may never ever know [if they developed an exploit for] it,”\nhe said.\n\n* * *\n\n[1](part0016.html#c12-ftn1a) John Arquilla and David Ronfeldt, “Cyberwar Is\nComing!” published by RAND in 1993 and reprinted as chapter 2 in Arquilla and\nRonfeldt’s book _In Athena’s Camp: Preparing for Conflict in the Information\nAge_ (RAND, 1997).\n\n[2](part0016.html#c12-ftn2a) He was speaking to PBS _Frontline_ in 2003 for\nits show “CyberWar!” Interview available at\n[pbs.org/wgbh/pages/frontline/shows/cyberwar/interviews/arquilla.html](http://www.pbs.org/wgbh/pages/frontline/shows/cyberwar/interviews/arquilla.html).\n\n[3](part0016.html#c12-ftn3a) The operation was thwarted by a system\nadministrator named Cliff Stoll, who stumbled upon the intrusion while\ninvestigating the source of a seventy-five-cent billing discrepancy. Stoll\nrecounts the story in his now-classic book _The Cuckoo’s Egg: Tracking a Spy\nThrough a Maze of Computer Espionage_ (New York: Doubleday, 1989).\n\n[4](part0016.html#c12-ftn4a) Jonathan Ungoed-Thomas, “How Datastream Cowboy\nTook U.S. to the Brink of War,” _Toronto Star_ , January 1, 1998.\n\n[5](part0016.html#c12-ftn5a) Information warfare didn’t just involve offensive\nand defensive cyber operations, it also included psychological operations,\nelectronic warfare, and physical destruction of information targets.\n\n[6](part0016.html#c12-ftn6a) A thirty-nine-page book recounts the history of\nthe 609th. A copy of the book, titled _609 IWS: A Brief History Oct. 1995–June\n1999_ , was obtained under a FOIA request and is available at\n[securitycritics.org/wp-\ncontent/uploads/2006/03/hist-609.pdf](http://www.securitycritics.org/wp-\ncontent/uploads/2006/03/hist-609.pdf).\n\n[7](part0016.html#c12-ftn7a) John “Soup” Campbell speaking as part of a panel\ntitled “Lessons from Our Cyber Past: The First Military Cyber Units,” at the\nAtlantic Council, March 5, 2012. Campbell was the first commander of the Joint\nTask Force-Computer Network Defense in December 1998 and later was principal\nadviser to the CIA director on military issues. A transcript of the panel\ndiscussion can be found at [atlanticcouncil.org/news/transcripts/transcript-\nlessons-from-our-cyber-past-the-first-military-cyber-\nunits](http://www.atlanticcouncil.org/news/transcripts/transcript-lessons-\nfrom-our-cyber-past-the-first-military-cyber-units).\n\n[8](part0016.html#c12-ftn8a) Bradley Graham, “U.S. Studies a New Threat: Cyber\nAttack,” _Washington Post_ , May 24, 1998.\n\n[9](part0016.html#c12-ftn9a) Ibid.\n\n[10](part0016.html#c12-ftn10a) Some of the information about the first task\nforce and the history of the military’s cyber activities comes from a March\n2012 interview with Jason Healey, head of the Cyber Statecraft Initiative at\nthe Atlantic Council in Washington, DC, and an original member of the\nmilitary’s first cyber taskforce. Healey also recounts some of the history of\ncyber conflict in a book he edited, which is one of the first to examine it.\nSee _A Fierce Domain: Conflict in Cyberspace, 1986 to 2012_ (Cyber Conflict\nStudies Association, 2013).\n\n[11](part0016.html#c12-ftn11a) Maj. Gen. James D. Bryan, founding commander of\nthe JTF-Computer Network Operations, speaking on the panel “Lessons from Our\nCyber Past: The First Military Cyber Units.”\n\n[12](part0016.html#c12-ftn12a) This and other quotes from Sachs come from\nauthor interview, March 2012.\n\n[13](part0016.html#c12-ftn13a) “HOPE” stands for Hackers on Planet Earth.\n\n[14](part0016.html#c12-ftn14a) Electronic warfare, which dates to World War I,\ninvolves the use of electromagnetic and directed energy to control the\nelectromagnetic spectrum to retard enemy systems. Computer network attacks, by\ncontrast, are defined as operations designed to disrupt, deny, degrade, or\ndestroy information resident on computers and computer networks, or the\ncomputers or networks themselves, according to Department of Defense Directive\n3600.1.\n\n[15](part0016.html#c12-ftn15a) Author redacted, “IO, IO, It’s Off to Work We\nGo,” _Cryptolog: The Journal of Technical Health_ (Spring 1997): 9.\n_Cryptolog_ is an internal classified quarterly newsletter produced by and for\nNSA employees that includes everything from book reviews to employee profiles\nto technical articles about topics of interest. In 2013, the agency\ndeclassified issues published between 1974 and 1999 and released them\npublicly, though parts of them are still redacted. The archive is available at\n[nsa.gov/public_info/declass/cryptologs.shtml](http://www.nsa.gov/public_info/declass/cryptologs.shtml).\n\n[16](part0016.html#c12-ftn16a) Author redacted, “Thoughts on a Knowledge Base\nto Support Information Operations in the Next Millennium,” _Cryptolog: The\nJournal of Technical Health_ (Spring 1997): 32.\n\n[17](part0016.html#c12-ftn17a) William B. Black Jr., “Thinking Out Loud About\nCyberspace,” _Cryptolog: The Journal of Technical Health_ (Spring 1997): 4.\n\n[18](part0016.html#c12-ftn18a) Author redacted, “IO, IO, It’s Off to Work We\nGo.”\n\n[19](part0016.html#c12-ftn19a) William M. Arkin, “A Mouse that Roars?”\n_Washington Post_ , June 7, 1999.\n\n[20](part0016.html#c12-ftn20a) In 1999, the DoD’s Office of the General\nCounsel examined a range of existing treaties and international laws and\nconcluded there was no international legal principle or corpus that clearly\naddressed the kind of cyber operations the military proposed conducting.\nDepartment of Defense Office of the General Counsel, _An Assessment of\nInternational Legal Issues in Information Operations_ , published May 1999,\navailable at [au.af.mil/au/awc/awcgate/dod-io-legal/dod-lo-\nlegal.pdf](http://www.au.af.mil/au/awc/awcgate/dod-io-legal/dod-lo-legal.pdf).\n\n[21](part0016.html#c12-ftn21a) As an example of how reliant weapons systems\nare on software, during Operation Desert Storm in 1991, a Patriot missile\ndefense system installed in Dhahran, Saudi Arabia, failed to intercept\nincoming Scud missiles because of a software problem in the control system\nthat caused it to look for incoming Scuds in the wrong place. The Scud attack\nkilled twenty-eight US soldiers. See “Software Problem Led to System Failure\nat Dhahran, Saudi Arabia,” US Government Accountability Office, February 4,\n1992, available at\n[gao.gov/products/IMTEC-92-26](http://www.gao.gov/products/IMTEC-92-26).\n\n[22](part0016.html#c12-ftn22a) Bryan, “Lessons from Our Cyber Past.”\n\n[23](part0016.html#c12-ftn23a) “The Information Operations Roadmap,” dated\nOctober 30, 2003, is a seventy-four-page report that was declassified in 2006,\nthough the pages dealing with computer network attacks are heavily redacted.\nThe document is available at <http://information-retrieval.info/docs/DoD-\nIO.html>.\n\n[24](part0016.html#c12-ftn24a) Arquilla _Frontline_ “CyberWar!” interview. A\n_Washington Post_ story indicates that attacks on computers controlling air-\ndefense systems in Kosovo were launched from electronic-jamming aircraft\nrather than over computer networks from ground-based keyboards. Bradley\nGraham, “Military Grappling with Rules for Cyber,” _Washington Post_ ,\nNovember 8, 1999.\n\n[25](part0016.html#c12-ftn25a) James Risen, “Crisis in the Balkans:\nSubversion; Covert Plan Said to Take Aim at Milosevic’s Hold on Power,” _New\nYork Times_ , June 18, 1999. A _Washington Post_ story says the plan never\ncame to fruition. “We went through the drill of figuring out how we would do\nsome of these cyber things if we were to do them,” one senior military officer\ntold the paper. “But we never went ahead with any.” Graham, “Military\nGrappling with Rules for Cyber.”\n\n[26](part0016.html#c12-ftn26a) John Markoff and H. Sanker, “Halted ’03 Iraq\nPlan Illustrates US Fear of Cyberwar Risk,” _New York Times_ , August 1, 2009.\nAccording to Richard Clarke, it was the secretary of treasury who vetoed it.\nSee Richard Clarke and Robert Knake, _Cyber War: The Next Threat to National\nSecurity and What to Do About It_ (New York: Ecco, 2010), 202–3. In general,\nnations have observed an unspoken agreement against manipulating financial\nsystems and accounts out of concern over the destabilizing effect this could\nhave on global markets and economies.\n\n[27](part0016.html#c12-ftn27a) David A. Fulghum, Robert Wall, and Amy Butler,\n“Israel Shows Electronic Prowess,” _Aviation Week_ , November 25, 2007. The\narticle is no longer available on the _Aviation Week_ website but has been\npreserved in full at [warsclerotic.wordpress.com/2010/09/28/israel-shows-\nelectronic-prowess](http://www.warsclerotic.wordpress.com/2010/09/28/israel-\nshows-electronic-prowess).\n\n[28](part0016.html#c12-ftn28a) “Electronic Warfare: DOD Actions Needed to\nStrengthen Management and Oversight,” published by the US Government\nAccountability Office, July 2012.\n\n[29](part0016.html#c12-ftn29a) Eric Shmitt and Thom Shanker, “US Debated\nCyberwarfare in Attack Plan on Libya,” _New York Times_ , October 17, 2011.\n\n[30](part0016.html#c12-ftn30a) Greg Miller, Julie Tate, and Barton Gellman,\n“Documents Reveal NSA’s Extensive Involvement in Targeted Killing Program,”\n_Washington Post_ , October 16, 2013.\n\n[31](part0016.html#c12-ftn31a) Barton Gellman and Ellen Nakashima, “U.S. Spy\nAgencies Mounted 231 Offensive Cyber-Operations in 2011, Documents Show,”\n_Washington Post_ , August 30, 2013.\n\n[32](part0016.html#c12-ftn32a) The NSA accomplishes this by installing the\nimplant in the BIOS of machines as well as in the master boot record—core\nparts of the hard drive that don’t get wiped when software on the computer\ngets upgraded or erased. See “Interactive Graphic: The NSA’s Spy Catalog,”\n_Spiegel Online_ , available at\n[spiegel.de/international/world/a-941262.html](http://www.spiegel.de/international/world/a-941262.html).\n\n[33](part0016.html#c12-ftn33a) In one case, the NSA and the UK spy agency\nGovernment Communications Headquarters, or GCHQ, used a sophisticated method\ncalled Quantum Insert to hack the machines of Belgian telecom workers to gain\naccess to the telecom’s network and to a router the company used for\nprocessing the traffic of mobile phone users. The elaborate attack involved\nusing high-speed servers the NSA had set up at key internet switching points\nto intercept the surfing traffic of system administrators who worked for the\ntelecom. The spy agencies first collected extensive intelligence on the\nworkers—their e-mail addresses, IP addresses, and possible surfing habits—then\nthe high-speed servers watched for requests from the employees’ machines for\nspecific web pages, such as the victim’s own LinkedIn profile page. When the\nvictim tried to access the LinkedIn page, the server would intercept the\nrequest before it reached LinkedIn and would feed a fake LinkedIn page to the\nvictim that injected malware into his machine. Once on the system\nadministrator’s machine, the spy agencies could then use his credentials to\ngain access to other parts of the telecom network to subvert the router.\n\n[34](part0016.html#c12-ftn34a) Glenn Greenwald and Ewen MacAskill, “Obama\nOrders US to Draw up Overseas Target List for Cyber-Attacks,” _Guardian_ ,\nJune 7, 2013. The eighteen-page Presidential Policy Directive 20 was issued in\nOctober 2012, and refers to offensive cyberattacks as Offensive Cyber Effects\nOperations.\n\n[35](part0016.html#c12-ftn35a) Gellman and Nakashima, “US Spy Agencies Mounted\n231 Offensive Cyber-Operations.”\n\n[36](part0016.html#c12-ftn36a) Roger A. Grimes, “In His Own Words: Confessions\nof a Cyber Warrior,” _InfoWorld_ , July 9, 2013.\n\n[37](part0016.html#c12-ftn37a) Ibid.\n\n[38](part0016.html#c12-ftn38a) Pennington was speaking at the Industrial\nControl System-Joint Working Group conference in 2011. The conference is\nsponsored by the Department of Homeland Security.\n\n[39](part0016.html#c12-ftn39a) Author interview, November 2011.\n\n[40](part0016.html#c12-ftn40a) Joseph Menn, “Special Report: US Cyberwar\nStrategy Stokes Fear of Blowback,” Reuters, May 10, 2013, available at\n[reuters.com/article/2013/05/10/us-usa-cyberweapons-specialreport-\nidUSBRE9490EL20130510](http://www.reuters.com/article/2013/05/10/us-usa-\ncyberweapons-specialreport-idUSBRE9490EL20130510).\n\n[41](part0016.html#c12-ftn41a) See [chapter 6](part0010.html) for previous\nmention of how these two vulnerabilities had already been discovered by others\nbefore Stuxnet’s authors used them in their attack.\n\n[42](part0016.html#c12-ftn42a) Summer Lemon, “Average Zero-Day Bug Has 348-Day\nLifespan, Exec Says,” IDG News Service, July 9, 2007, available at\n[computerworld.com/s/article/9026598/Average_zero_day_bug_has_348_day_lifespan_exec_says](http://www.computerworld.com/s/article/9026598/Average_zero_day_bug_has_348_day_lifespan_exec_says).\n\n[43](part0016.html#c12-ftn43a) Robert Lemos, “Zero-Day Attacks Long-Lived,\nPresage Mass Exploitation,” Dark Reading, October 18, 2012, available at\n[darkreading.com/vulnerabilities—threats/zero-day-attacks-long-lived-presage-\nmass-\nexploitation/d/d-id/1138557](http://www.darkreading.com/vulnerabilities—threats/zero-\nday-attacks-long-lived-presage-mass-exploitation/d/d-id/1138557). The research\nwas conducted by Symantec.\n\n[44](part0016.html#c12-ftn44a) Pennington, Industrial Control Systems–Joint\nWorking Group Conference, 2011.\n\n[45](part0016.html#c12-ftn45a) Michael Riley, “U.S. Agencies Said to Swap Data\nwith Thousands of Firms,” Bloomberg, June 14, 2013, available at\n[bloomberg.com/news/2013-06-14/u-s-agencies-said-to-swap-data-with-thousands-\nof-firms.html](http://www.bloomberg.com/news/2013-06-14/u-s-agencies-said-to-\nswap-data-with-thousands-of-firms.html).\n\n[46](part0016.html#c12-ftn46a) Tom Gjelten, “Stuxnet Raises ‘Blowback’ Risk in\nCyberwar,” _Morning Edition_ , NPR, November 2, 2011, available at\n[npr.org/2011/11/02/141908180/stuxnet-raises-blowback-risk-in-\ncyberwar](http://www.npr.org/2011/11/02/141908180/stuxnet-raises-blowback-\nrisk-in-cyberwar).\n\n[47](part0016.html#c12-ftn47a) Author interview, 2012.\n\n\n# CHAPTER 13\n\n# **DIGITAL WARHEADS**\n\nLiam O’Murchu was growing tired and bored. He’d been sitting at his desk for\ntwo hours diligently plugging virtual hardware components, piece after piece,\ninto a Step 7 emulator, making a last-ditch effort to identify what Stuxnet\nwas attacking, but he was having no luck.\n\nIt was early October, weeks after Ralph Langner had identified Stuxnet as a\nprecision weapon aimed at a single target, and both teams—in Hamburg and\nCalifornia—were now working independently, without the other knowing it, to\nidentify the digital weapon’s target.\n\nOne of the things the Symantec researchers discovered was that right before\nStuxnet unleashed its destructive payload on a 315 PLC, it searched the PLC\nfor three “magic values”—combinations of numbers and letters embedded in the\ndata blocks of the PLC itself. When Stuxnet encountered a 315 PLC, it rifled\nthrough these blocks in search of the magic values 2C CB 00 01, 7050h, and\n9500h—and knew it had reached its target when it found all three.\n\nEric Chien had done a Google search on the values but found nothing that made\nsense in the context of Stuxnet. The researchers suspected the first one was\nsome kind of part or serial number for a hardware component that got plugged\ninto the PLC, so O’Murchu had set up a simulated Step 7 PLC environment to try\nto determine its identity. The Step 7 system included an emulator feature for\nbuilding a virtual PLC network to test different hardware configurations\nbefore building the real network in a plant. The emulator featured a long list\nof hardware components that engineers could virtually plug into the\nconfiguration one at a time simply by clicking on a name from the menu. Each\ntime an engineer selected an item from the list, an ID number for the\ncomponent popped up on the screen. O’Murchu was hoping the mysterious 2C CB 00\n01 was among them. But for two hours he’d been systematically plugging in one\ndevice after another and still hadn’t found a match after trying more than a\nhundred components. It was beginning to feel like an exercise in futility,\nuntil, that is, he reached a cluster of Profibus and Profinet cards on the\nlist—devices that transmitted data between PLCs and the components they\ncontrolled. O’Murchu clicked on a Profibus CP 342-5 card and, just like that,\nthe value popped up.\n\nThe Profibus card was just one half of the puzzle, however. He still didn’t\nknow what devices the PLC controlled. Encouraged by this bit of success,\nhowever, he quickly plugged in the rest of the components on the list, but\nneither of the other magic values appeared. It didn’t matter. They’d made a\nbig leap with this new finding anyway. They now knew that Stuxnet was looking\nfor a system with six of these network cards attached, and they knew it was\nonly a matter of time before they solved the rest of the configuration\nmystery.\n\nTHREE MONTHS INTO the discovery of Stuxnet, the rest of the world now knew\nabout the mysterious code that had evidently targeted Iran. Yet speculation\nthat it had specifically targeted the uranium enrichment program at Natanz\nremained just that—speculation. Symantec’s engineers were about to find the\nproof they needed in the code. But first, they needed a crash course in PLCs.\n\nDiscovering that Stuxnet was sabotaging the Siemens PLCs had certainly been a\nbig breakthrough for Falliere and his colleagues. But Langner had been right\nthat they had hit a wall in their research and were stymied by the PLCs. “We\nquickly knew that we knew nothing,” Chien says.[1](part0017.html#c13-ftn1)\n\nIf that weren’t enough, in discovering that Stuxnet was injecting malicious\ncode into the PLCs, Falliere had also discovered that Stuxnet didn’t have just\none payload, but _two._ Stuxnet sent out dual warheads to attack the PLCs,\nlike special ops commandos. One targeted the Siemens S7-315 PLC; the other\nhomed in on the S7-417.\n\nJust a few kilobytes of malicious code got injected into each PLC, but\ncracking that code was the key to solving Stuxnet’s biggest puzzle. There was\njust one problem. The code was written in a format and language that Falliere\ndidn’t understand. Stuxnet’s missile portion was written in C and C++ and\ncompiled into Intel x86 assembly—the most common and widely known computer\nassembly language. But the digital warheads used an obscure programming\nlanguage, unique to the Siemens PLCs, called STL.[2](part0017.html#c13-ftn2)\nTo program Siemens PLCs, engineers wrote their commands in STL, then converted\nthem into MC7, an assembly language, before compiling that into binary that\nthe PLCs could read. All of this meant that even if Falliere succeeded in\nreversing the ones and zeros of the binary back to STL, he still would have no\nidea what it said. It was a bit like unscrambling the coded message of the\nCIA’s famous _Kryptos_ sculpture only to find that the unencrypted message was\nwritten in Greek. In Symantec’s August 17 announcement, they had put out a\ncall for anyone with knowledge of PLCs and STL to contact them, but they got\nno response.\n\nThey wouldn’t have needed to seek help from the public if Siemens had been\nable to assist them, but unfortunately that turned out not to be the case.\nChien contacted the company early in their analysis and throughout the months\nthat they worked on Stuxnet. But whenever he sent the German firm questions\nabout how the Step 7 system worked, Siemens took days or weeks to respond.\nUsually by then the Symantec researchers had discovered the answer on their\nown and had prepared a new set of questions for Siemens to\nanswer.[3](part0017.html#c13-ftn3)\n\nThere was also another group of people who could have helped them out. Langner\nand his team excelled in the very areas that confounded Symantec. It would\nhave been the perfect marriage of skills—Symantec with its expertise in\nWindows systems and reverse-engineering malicious code, and Langner’s team\nwith their extensive knowledge of the Siemens software and PLCs. But any hopes\nof collaboration were quickly dashed after a brief e-mail exchange between the\ntwo groups, followed by a couple of blog posts, led to misunderstandings and\nbad feelings on both sides. It was a communication lapse that might have been\neasily resolved with a quick phone call, but neither side was motivated to\nmake it.\n\nIn the absence of any help, the Symantec researchers did the only thing they\ncould do—they bought a handful of books about STL online and proceeded to\nteach themselves how the code worked. The best way to reverse-engineer STL\ncode, they reasoned, was to learn how to write it.\n\nEach day on the Métro during his morning and evening commutes, Falliere pored\nover the books trying to make sense of the code. He made little progress for\ndays until he discovered an open-source tool online that someone had created\nto program Siemens PLCs as a freeware alternative to the Step 7 software.\nFalliere studied the tool to see how STL code looked when it was compiled into\nMC7 and then used this as a road map to take Stuxnet’s MC7 code in reverse.\n\nIt took weeks of picking through the code to get it all reversed, and, when he\nfinally did, the few kilobytes of binary that Stuxnet injected into the PLCs\nhad ballooned into more than 4,000 lines of instructions for the 315 attack\nand more than 13,000 lines for the 417 attack. It was too large and unwieldy\nfor Falliere to read in this format, not to mention too complicated for him to\nfollow. So he decided to translate it into something resembling C code to give\nhimself fewer and simpler commands to read. All of this only provided him with\na static reading of the code, however; without a PLC, he still couldn’t see\nthe attack in action. So he wrote a small program to simulate a PLC on his\nWindows machine and unleashed the code on that. Between this and a static\nreading of the reversed code, he was finally able to piece the attack\ntogether.\n\nOne of the first things that struck him about the attack was that it unfolded\nin six stages that repeated over weeks and months. Once the attack was done,\nit recycled itself and began again. This meant that rather than launching a\nsingle blow that caused catastrophic failure, as the researchers originally\nbelieved Stuxnet was designed to do, the attackers were going for subtle\nsabotage that extended over time. This, combined with the man-in-the-middle\nattack that concealed the sabotage from operators as it occurred, would have\nmade it hard for anyone to detect and pinpoint the source of problems. The\nattackers, Falliere realized, had expected to go undetected for months, and\nindeed they had.\n\nThe first part of the attack, a reconnaissance stage, lasted about thirteen\ndays, during which Stuxnet sat silently on the PLC recording normal operations\nin order to loop that data back to operators when the sabotage began. Stuxnet\nrecorded data at least once a minute and only progressed to the next stage\nafter recording data at least 1.1 million times.\n\nOnce enough data was recorded, a two-hour countdown commenced. Then when the\ncount reached zero, the sabotage began. It lasted just fifteen minutes,\nhowever, and once it was done, normal operations on the PLC and the devices it\ncontrolled resumed. Then, after a five-hour interval passed, the entire\nsequence began again, with Stuxnet this time waiting about twenty-six days to\nstrike, and recording twice the amount of data it recorded the first time. And\nwhen the sabotage kicked in this time, it lasted fifty minutes instead of\nfifteen. As before, once the sabotage was done, operations returned to normal\nfor another twenty-six days, and the whole cycle repeated again. Each time the\nsabotage occurred thereafter, it alternated between fifteen minutes and fifty\nminutes in length, though the reconnaissance stage remained twenty-six days.\n\nFalliere had no idea why the length of the sabotage changed or what the\ndifference was between the two sequences. Without knowing what devices were\nbeing attacked, he had no way of knowing the nature of the assault. It was a\nbit like watching tracer bullets fly through the night sky without having any\nidea what they would hit.\n\nTHE FINAL BREAK in the Stuxnet puzzle came in early November when a Dutch\nprogrammer named Rob Hulsebos, an expert on the Profibus protocol, sent Chien\nan e-mail. He was responding—albeit belatedly—to a second call for help the\nSymantec researchers had posted on their blog, asking anyone with knowledge of\nProfibus cards and critical infrastructure to contact them. Hulsebos’s e-mail\ncontained just two paragraphs, most of it information about Profibus that\nChien already knew, but one sentence stood out. Hulsebos wrote that every\nperipheral device connected to a Profibus network card had a unique ID\nassigned to it by Profibus. Each ID was about 2 bytes in size, or 16 bits,\nHulsebos wrote.\n\nChien recalled that the two mystery values they were trying to crack—7050h and\n9500h—were exactly 16 bits each.\n\nHe walked over to O’Murchu’s cubicle and showed him the e-mail on his\nBlackBerry. As Chien watched anxiously over his shoulder, O’Murchu did a\nGoogle search on Profibus device IDs and got a series of links for product\nbrochures. Chien pointed to one, a PDF listing devices commonly used with\nProfibus network cards. O’Murchu opened the file, and alongside the name of\neach device on the list was the unique Profibus ID the e-mail had described.\nO’Murchu scrolled down the list until he reached the bottom, and there it\nwas—one of the magic values that they (and Stuxnet) were seeking—9500h.\nAccording to the manual, the ID corresponded to a brand of frequency converter\nmade by a company in Finland. Chien dug around on the site for information\nabout the other ID but couldn’t find anything. So he wrote an e-mail to\nProfibus asking the company to identify the 7050h. He didn’t expect a response\nand was surprised when he got a reply indicating it was a frequency converter\nmade by a company in Iran.\n\nFrequency converters are power supplies that control the electric current fed\nto motors and rotors to modulate their speed. Increase the frequency of the\ndrive and the speed of the motor increases. The 9500h ID was for a frequency\nconverter made by a company named Vacon in Finland; the 7050h ID was an\nunspecified model of converter made by a company named Fararo Paya in Iran.\nO’Murchu suspected the Fararo Paya converters were an Iranian knock-off of the\nFinnish one.[4](part0017.html#c13-ftn4) If this was the case, there was likely\nno other facility outside of Iran that used the converters from Fararo Paya.\n\nThey downloaded everything they could find about frequency converters,\nincluding a dozen manuals for various brands. None of them were manuals for\nthe Vacon and Fararo Paya converters, but some of them listed commands for\ncontrolling the converters that were identical across different brands of\ndevices. One of the STL commands Falliere had pulled from the Stuxnet code was\n“47F and 1,” and sure enough, when they looked in one of the manuals they\nfound these words: “To start the frequency converter, send down the word 47F\nand set the value to 1.” O’Murchu’s fingers hovered above the keyboard as he\nread the line aloud. He couldn’t believe it. For four months they’d been\nstruggling to solve the mystery of what Stuxnet was attacking, working nights\nand weekends to understand what it was doing, and now with a couple of simple\nGoogle searches they had found their answer. It was as exhilarating and\ngratifying as it was anticlimactic.\n\nIt was the end of the day and the two of them were exhausted, so they sent a\nquick e-mail to Falliere letting him know what they’d found, along with a few\nof the PDF manuals showing the commands. “Take a look at these and see if you\nfind anything in here that works,” Chien told Falliere.\n\nWhen Falliere awoke that morning and saw the e-mail, he raced to the office.\nHe pulled out a list of all the configuration data and commands he’d extracted\nfrom Stuxnet and sifted through them side-by-side with the manuals. It didn’t\ntake long before he found matches for all of them. He’d already suspected that\nStuxnet might be changing the frequency of something on the other end of the\nPLC—the attack code contained numbers like 10640, which he suspected was 1,064\nHz expressed in deciHertz. Now the new information confirmed it.\n\nHe used the manuals to translate all of Stuxnet’s commands and within an hour\nor two had a complete blueprint of the attack, which he sent to O’Murchu and\nChien.\n\nBefore Stuxnet began its assault on the S7-315 PLC, it made sure the system\nwas using frequency converters made by Vacon and Fararo Paya, and that the\nconverters were operating at a frequency somewhere between 807 Hz and 1,210\nHz. Stuxnet was looking for a plant that had up to 186 of the converters\ninstalled, all of them operating above 800 Hz. Frequency converters were used\nin a number of varied applications, but converters that operated at 600 Hz or\nhigher had limited use—so limited, in fact, that when Chien did a search\nonline he discovered they were regulated for export in the United States by\nthe Nuclear Regulatory Commission. There could be no doubt about it now.\nStuxnet was targeting a nuclear facility. Langner had gone out on a limb\nasserting that Stuxnet was targeting Iran’s nuclear program, but now they had\nevidence in the code to back it up.\n\nChien was stunned by how beautifully everything now fell into place.\n\nThey had struggled for months to decipher the code, achieving their progress\nin increments of inches rather than miles, worried that they would never reach\nthe end of the road. Now in hindsight, it all seemed so elegant and complete.\nWith the final details resolved, Falliere laid out a step-by-step description\nof the attack from start to finish.\n\nOnce Stuxnet found a Step 7 machine, it unpacked its Step 7 .DLL doppelgänger\nand kidnapped the Siemens .DLL to take its place. Then it waited patiently for\na programmer to launch the Step 7 program to read or create code blocks for an\nS7-315 PLC. Stuxnet then injected its malicious code into the blocks and\nwaited until the programmer connected his laptop to a PLC or copied the\ncommands to a USB flash drive to transfer them to a PLC. It could take days or\nweeks for the malicious commands to land on a PLC, but once they did, the\nattack unfolded without resistance.\n\nAfter the initial reconnaissance stage recording data for thirteen days,\nStuxnet first increased the frequency of the converters to 1,410 Hz for\nfifteen minutes, then reduced it to 1,064 Hz, presumably the normal operating\nfrequency, for about twenty-six days. Once Stuxnet recorded all of the data it\nneeded to record during these three weeks, it dropped the frequency\ndrastically to 2 Hz for fifty minutes, before restoring it to 1,064 Hz again.\nAfter another twenty-six days, the attack began again. Each time the sabotage\ncommenced, the man-in-the-middle attack fed false frequency readings back to\nthe operators and safety system to keep them blind to what was happening.\n\nSYMANTEC AT LAST knew exactly what Stuxnet was doing to the S7-315 PLC. But\nthe attack targeting the S7-417 PLC remained a mystery. The two digital\nweapons arrived with the same missile but operated completely independent of\neach other.\n\nThe S7-417 was Siemens’s high-end PLC, which came with 30 megabytes of RAM and\na price tag of more than $10,000 compared to about $500 for the S7-315. As if\nto match its higher status, the attack targeting this PLC was also much\nlarger, with many more blocks of code—40 blocks of code compared to 15 blocks\nfor the 315 attack—some of which got generated on the fly based on conditions\nStuxnet found on the system it was attacking.\n\nThe 417 attack code was also far more complex, both in terms of the steps that\ngot executed and the conditions under which the attack was unleashed. In\naddition, it had bizarre constructs that made it a huge pain to reverse-\nengineer. There were pointers leading to pointers leading to pointers, which\nmade it difficult to follow the sequence of events in the code. The difference\nin structure between the two attacks made it appear as if the codes had been\ncreated by completely different teams using different tools.\n\nThe attackers had obviously put a lot of thought and effort into the 417 code,\nso Falliere was perplexed when he discovered that it didn’t work—that in fact\nthe attackers had intentionally disabled it. In part of the code responsible\nfor fingerprinting the 417 PLC to see if its configuration matched the target\nconfiguration Stuxnet was seeking, the attackers had inserted an exception—a\nprogramming trick that involved introducing an intentional error into the code\nto abort a mission before it began. What’s more, there was no sign the attack\nhad ever been active. Stuxnet needed to generate a crucial block of code on\nthe fly to make the attack work, but the code that was supposed to create that\nblock was incomplete.\n\nIt wasn’t clear if the attackers had disabled the code because it was still a\nwork in progress or if it had been completed at one point and later disabled\nfor a different reason. Falliere recalled the recent news story quoting an\nIranian official saying that _five_ versions of Stuxnet were found in\nIran.[5](part0017.html#c13-ftn5) Symantec and other researchers had seen only\nthree versions of Stuxnet so far. But was there, perhaps, another version of\nStuxnet in the wild that contained a complete version of the 417 attack?\n\nBased on clues Falliere and his colleagues had found in the three versions of\nStuxnet discovered so far, it seemed there might in fact be another version\nout in the wild. The version numbers of the three variants, for example, were\nout of sequence. The attackers themselves had numbered them—the June 2009\nvariant was version 1.001, while the March and April 2010 variants were 1.100\nand 1.101. Gaps in the numbers suggested that other variants had at least been\ndeveloped—including a 1.00 version that pre-dated all three of the ones\nalready identified—even if they were never released in the wild.\n\nWhatever the 417 code was attacking, it was different from the 315 attack.\nUnlike the 315 attack, the 417 code targeted a system that consisted of 984\ndevices configured into six groups of 164. And during the attack, only 110 of\nthe 164 devices in each group got sabotaged. Unfortunately, the 417 code\ncontained no magic values to help the Symantec team identify what it\nattacked—like the ones that helped identify the frequency converters. Langner\nand his team, who analyzed the 417 code at the same time Symantec did,\nsurmised that the 417 code might be targeting the cascade itself, not the\nindividual centrifuges, perhaps the pipes and valves that controlled the flow\nof gas in and out of the cascades. But without more details in the code to\noffer definitive proof, neither Langner nor Symantec could say for sure what\nthe 417 attack was doing. After months of work and extensive progress in other\nregards, they all had to resign themselves to the fact that they had reached\nanother dead end—it seemed that Stuxnet was determined to hold on to at least\none of its mysteries.\n\nIn the absence of a clear understanding of the 417 attack code, the Symantec\nresearchers decided to publish what they _did_ know—which were the final\ndetails of the 315 assault.\n\nSo on November 12, 2010, exactly four months after VirusBlokAda had first\nannounced its discovery of the Stuxnet code, Symantec published a blog post\nannouncing that Stuxnet was attacking a very unique configuration of specific\nfrequency converters. “Stuxnet’s requirement for particular frequency\nconverter drives and operating characteristics focuses the number of possible\nspeculated targets to a limited set of possibilities,” Chien wrote in the\nSymantec team’s typically cryptic and cautious\nstyle.[6](part0017.html#c13-ftn6) He never mentioned the Iranian nuclear\nprogram by name, or even centrifuges, but the message behind his words was\nclear.\n\nFour days after Symantec published its post, technicians at Natanz brought all\nof the spinning centrifuges at the plant to a complete halt. For six days,\nuntil November 22, all enrichment activity at the facility stopped. Iranian\nofficials offered no explanation for the sudden freeze, but the Symantec\nresearchers suspected administrators at the plant were tearing apart the\ncomputers for any lingering traces of Stuxnet. Although information about the\nworm had been in the public domain for months, the revelations until now\nhadn’t been specific about what devices Stuxnet attacked or how it conducted\nits operation, and Stuxnet had been meticulously crafted to make it hard for\nanyone to find its malicious code on the PLCs or to trace the sabotage to its\nsource. Symantec’s latest report, however, provided all the evidence operators\nneeded to connect the problems they were having at Natanz to the digital\nweapon. Although antivirus firms had long ago released signatures to detect\nStuxnet’s files, they could only detect the ones on Windows machines—not the\nrogue code that Stuxnet injected into the PLCs. And since Stuxnet was like an\noctopus with many tentacles to help it spread, technicians at Natanz would\nhave had to wipe and restore every machine at the plant to completely\ndisinfect the stubborn code from their systems.\n\nIt was clear now that Stuxnet’s days were finally over. Not only would it no\nlonger be able to mess with the centrifuges at Natanz, but any future problems\nwith systems at the plant would immediately spark suspicion that malicious\ncode was the cause. It would be much more difficult to pull off a similar\nstealth attack in the future without scrutiny quickly focusing on the control\nsystems.\n\nWith nearly all the mysteries of Stuxnet now resolved, the Symantec\nresearchers focused on tidying up some loose ends and finalizing their lengthy\ndossier about the code before turning their attention to other things.\n\nBut a week after the halted centrifuges at Natanz resumed their operation, the\nstory of Stuxnet took a darker and more sinister turn, suggesting that efforts\nto thwart the enrichment program weren’t yet done. If the use of malicious\ncode was no longer a viable option, other means to halt the program were still\nat the attackers’ disposal.\n\nTHE RUSH-HOUR TRAFFIC on Artesh Boulevard in northern Tehran was particularly\ncongested the morning of November 29, 2010, when Majid Shahriari, a slim\nforty-year-old professor of nuclear physics maneuvered his Peugeot sedan\nthrough the bumper-to-bumper gridlock on his way to work. It was only seven\nforty-five on that Monday morning, but a layer of smog already hovered in the\nair as Shahriari inched his way toward Shahid Beheshti University, where he\nwas a lecturer. With him in the car were his wife, also a nuclear physics\nprofessor and mother of two, and a bodyguard.\n\nAs the sedan approached a busy intersection, assailants on a motorcycle\nsuddenly pulled alongside Shahriari’s vehicle and brazenly slapped a “sticky”\nbomb to the driver’s-side door. Seconds after they zipped away, the bomb\nexploded, shattering the car’s rear window and leaving the driver’s-side door\na twisted mess of molten metal. Shahriari was instantly killed; his wife and\nbodyguard were injured, though spared. A small pit in the asphalt next to the\ncar testified to the force of the blast.[7](part0017.html#c13-ftn7)\n\nNot long after, in another part of the city, Fereydoon Abbasi, a fifty-two-\nyear-old expert in nuclear isotope separation, was also making his way through\ntraffic toward the same destination, when, out of the corner of his eye, he\nspotted a motorcycle approaching. A second later he heard the distinctive\nsound of something being attached to his door. Abbasi was a member of Iran’s\nRevolutionary Guard, so his defensive instincts were more honed than\nShahriari’s. He quickly leapt from the car and pulled his wife from her seat.\nAlthough the two were injured when the bomb exploded, both of them survived\nthe attack.\n\nNews reports indicated the two scientists were targeted for their prominent\nroles in Iran’s nuclear program. “They’re bad people,” an unnamed US official\nsaid afterward, “and the work they do is exactly what you need to design a\nbomb.”[8](part0017.html#c13-ftn8)\n\nShahriari was an expert in neutron transport—essential to creating nuclear\nchain reactions for reactors and bombs—and Western news reports claimed that\nonly political appointees ranked higher than Shahriari in Iran’s nuclear\nprogram. Iran’s nuclear chief, Ali Akbar Salehi, told reporters that he had\nbeen working on a “major project” for Iran’s Atomic Energy Organization\n(AEOI), but didn’t elaborate.[9](part0017.html#c13-ftn9)\n\nAbbasi was even more important to the program. He was one of only a few\nspecialists in Iran who had expertise in separating uranium isotopes, a core\npart of the uranium enrichment process. He was also on the UN Security\nCouncil’s sanctions list for his role as a senior scientific adviser to Iran’s\nMinistry of Defense and for his close working relationship with Mohsen\nFakhrizadeh-Mahabadi, an officer in the Iranian Revolutionary Guard. If Iran\ndid indeed have a nuclear weapons program, Fakhrizadeh-Mahabadi was believed\nto be its architect.\n\nPresident Ahmadinejad wasted no time laying blame for the attacks on “the\nZionist regime and Western governments.”[10](part0017.html#c13-ftn10) Saeed\nJalili, general secretary of Iran’s Supreme National Security Council, called\nthe attacks an act of desperation by powerless\nenemies.[11](part0017.html#c13-ftn11) “When the enemy sees no other option, he\nresorts to the methods of terror,” he said. “This is not a sign of strength,\nbut of weakness.”[12](part0017.html#c13-ftn12) After his recovery, Abbasi was\nappointed head of the AEOI, as if to assert Iran’s determination to achieve\nits nuclear goals despite enemy plots against it. Abbasi was said to keep a\nphoto of Shahriari in his office to remind him of that\nresolve.[13](part0017.html#c13-ftn13)\n\nBut the two attacks on busy streets in broad daylight had their desired effect\nand sent a message to anyone involved in Iran’s nuclear program that no one\nwas safe or beyond the reach of assassins. Other Iranian scientists reportedly\ncalled in sick to work for several days after the bombings to avoid the fate\nof their colleagues.[14](part0017.html#c13-ftn14)\n\nIn response to the accusations from Ahmadinejad, the US State Department\noffered only a brief statement. “All I can say is we decry acts of terrorism\nwherever they occur and beyond that, we do not have any information on what\nhappened,” spokesman Philip J. Crowley said.[15](part0017.html#c13-ftn15)\nIsrael declined to respond, at least directly. Instead, on the day of the\nattacks, Israeli prime minister Benjamin Netanyahu announced the retirement of\nMossad chief Meir Dagan after eight years of service as the spy agency’s\nleader. The timing of the announcement seemed to suggest that the attacks on\nthe scientists and on the centrifuges at Natanz were part of Dagan’s swan\nsong. Dagan was known to favor assassination as a political\nweapon.[16](part0017.html#c13-ftn16) Upon his appointment as head of Mossad in\n2002, then–Prime Minister Ariel Sharon crudely praised him for his skill at\nseparating Arabs from their heads.\n\nThe day of the assaults on the scientists, President Ahmadinejad seemed to tie\nthe attacks to Stuxnet and provide what appeared to be the first official\nconfirmation that the digital weapon had struck Natanz. As he condemned Israel\nand the West for the bombing attacks, he also blamed them for a virus attack\nthat he said had been unleashed on Iran’s nuclear program a year earlier. The\nvirus had been embedded in software “installed in electronic parts,” he said,\nand had damaged some of Iran’s centrifuges. But he downplayed the effects of\nthe attack, saying the worm had created problems for only “a limited number of\nour centrifuges,” before workers discovered and immobilized\nit.[17](part0017.html#c13-ftn17) Though he didn’t identify the digital attack\nby name or the facility where the centrifuges were damaged, it seemed clear to\neveryone that he was referring to Stuxnet and Natanz.\n\nWhen news of the attacks on the scientists reached Ralph Langner in Germany,\nhis stomach dropped. He wondered if his team’s work exposing Stuxnet had\npushed the attackers to take even more drastic measures than he’d expected\nthem to take once their digital attack was exposed. It underscored for him the\nreality that their work on Stuxnet had placed them in the midst of a very dark\nand bloody business.\n\nSymantec’s researchers were no less shaken by the news. During the months they\nhad worked on Stuxnet, black humor and paranoia had hung in the air, a by-\nproduct of the uncertainty about who was behind the attack or what they were\ncapable of doing. O’Murchu began hearing strange clicking sounds on his phone,\nmaking him think it was tapped, and one Friday afternoon as he left the office\nto go home, he joked to Chien and Falliere that if he turned up dead over the\nweekend, he wanted them to know in advance that he wasn’t suicidal. Chien for\nhis part had begun glancing around his neighborhood each morning when he left\nthe house to see if anyone was watching him. He never seriously believed he\nwas in danger, though, and the day that news of the attacks on the scientists\nbroke, he joked to O’Murchu that if motorcyclists ever approached his car,\nhe’d take out the driver with a quick swerve of his wheels. But when he drove\naway from work that day and stopped at the first traffic light, he was\nmomentarily startled when he saw a motorcyclist pull up behind in his rearview\nmirror.\n\nNone of them really thought assassins would target them for their work on\nStuxnet, but it was clear that the dynamics of virus hunting had changed with\nStuxnet, and that going forward companies like theirs would be forced to make\nnew risk calculations about the information they exposed.\n\nAt various points in their work on Stuxnet, they had indeed debated at times\nwhether to withhold information they uncovered or to release it anonymously.\nIn the end, although they did withhold some of the details they found—such as\nthe identity of Stuxnet’s five initial victims—they decided in favor of\ndisclosure, believing that the more information they released, the better it\nwould be for everyone to defend against Stuxnet and any copycat attacks. There\nwas just one thing, they concluded, that would have merited censorship, and\nthat was the identity of the attackers. But in the end this was a moot point,\nsince they never did uncover definitive proof of who was behind the attack.\n\nIn fact, they also never found incontrovertible proof that Stuxnet targeted\nNatanz. Although the information about the frequency converters added a major\npiece to the Stuxnet puzzle, they found no evidence that the specific\nconfiguration Stuxnet targeted existed at Natanz. It took David Albright and\nhis colleagues at the Institute for Science and International Security to\nprovide the last bit of evidence.\n\nSYMANTEC PUBLISHED ITS last report on the frequency converters in mid-\nNovember, but it wasn’t until two weeks later that Albright made the final\nconnection. It happened one day in December when he was sitting in a meeting\nwith his staff at ISIS, along with a handful of centrifuge experts they had\ninvited to their office to discuss Iran’s nuclear program, and the group began\npuzzling over a mystery that had been bothering them for more than a year.\n\nISIS had published the satellite images of Natanz back in 2002 to pressure\nIran into letting UN inspectors examine the enrichment plant, and Albright and\nhis staff had been following Iran’s nuclear progress ever since, sometimes\ngleaning information from government sources but mostly gathering it from the\nquarterly reports the IAEA published about its inspections. The latter reports\nwere the only inside view that most Iran-watchers had of Natanz.\n\nFor eighteen months, Albright and his staff had been scratching their heads\nover fluctuating numbers that appeared in the reports. Every three months, the\ninspectors listed the number of centrifuges and cascades the Iranians had\ninstalled at Natanz, as well as the number of centrifuges that were actually\nenriching gas, as opposed to the ones that were just sitting in cascades\nempty. They also reported the amount of gas Iranian technicians fed into the\ncentrifuges and the amount of enriched gas the centrifuges produced from this.\n\nFor most of 2007 and 2008 all of these numbers had risen fairly steadily with\noccasional glitches. But in mid- to late 2009, the numbers began to noticeably\nchange. The amount of enriched gas being produced by the centrifuges suddenly\ndropped, and centrifuges that were once spinning in eleven out of eighteen\ncascades in one of the rooms at Natanz were eventually disconnected. There was\nno indication in the reports about why this occurred, though it was clear that\nsomething was wrong.\n\nAlbright and his colleagues had puzzled over the changes for many months,\nconsidering the data from various angles: perhaps the problems were due to\npoorly manufactured components or inferior materials, or perhaps the\ntechnicians had simply installed the pipes and valves in the cascades\nincorrectly, causing gas to leak out of them. None of the explanations,\nhowever, seemed to account for all of the changes they had seen in the\nreports. Now in December 2010 as they sat with their guests discussing the\nanomalies, someone mentioned Stuxnet and Symantec’s recent report about the\nfrequency converters. Albright hadn’t read the report, but knew that Iran used\nfrequency converters made by Vacon, the Finnish company mentioned by Symantec,\nand that it had also purchased converters in the past from Turkey and Germany.\nBut he had never heard of Fararo Paya converters before. This was significant:\nhe and his staff closely followed Iran’s procurement and manufacturing\nactivities for the nuclear program and weren’t aware that Iran was making its\nown converters. If Iran was using such converters at Natanz, then the\nattackers had knowledge of the enrichment program that even some of its\nclosest watchers didn’t possess.\n\nWhen the meeting was over and he went back to his desk, Albright pulled up the\nreport from Symantec to examine it carefully. He also found a report that\nLangner had written about the disabled 417 attack code. He spent the next\ncouple of weeks sifting through the technical details of the attacks and even\ncontacted Chien for explanations about some of the things he didn’t\nunderstand. As he and Chien were talking one day, something struck him that he\nhadn’t noticed before. Each time Stuxnet completed a round of sabotage on the\nfrequency converters, it reset their frequency to 1,064 Hz. The number leapt\nout at him. Albright knew that centrifuge motors had different optimal\nfrequencies for operating, depending on the model of the centrifuge and the\nmaterials from which it was made. And the optimal frequency for the IR-1\ncentrifuges at Natanz was exactly 1,064 Hz.\n\nWhat’s more, the 1,064 Hz frequency was very specific to IR-1 centrifuges. No\nother centrifuge had this nominal frequency, and there was no country outside\nof Iran that used them. (Although the IR-1s were based on the P-1 centrifuge\ndesign that Pakistan had used during the early years of its enrichment\nprogram, Pakistan had since moved on to more advanced designs, which operated\nat different frequencies.)\n\nThe optimal frequency for the IR-1s wasn’t widely known, however. Albright\nknew it only because a government source had told him in 2008. But even though\nthe optimal frequency was 1,064 Hz, the source told him that Iran actually\noperated its centrifuges at a slightly lower frequency, which Albright and his\nstaff learned was 1,007 Hz, due to their tendency to break at higher speeds.\nAlbright thought about the discrepancy for a minute. Either the Stuxnet\nattackers weren’t aware that Iran had made this change, or Iran had reduced\nthe frequency of its centrifuges some time after the attackers had already\nwritten their code.\n\nBut this wasn’t the only detail that stood out to Albright. He also noticed\nthat when Stuxnet conducted its attack, it increased the frequency of the\nconverters to 1,410 Hz for fifteen minutes, which was nearly the maximum\nfrequency an IR-1 rotor could withstand before it would begin to break from\nstress.\n\nThen he looked at what Symantec and Langner had written about the 417 attack\ncode. Although what they knew about the attack was still pretty sketchy, they\nknew it targeted devices that were configured into six arrays of 164 devices\neach. Centrifuges at Natanz, Albright knew, were installed 164 to a cascade,\nsuggesting the 417 attack had targeted six cascades containing 984\ncentrifuges.\n\nChien also told Albright that instead of changing frequencies like the 315\nattack, the 417 attack sequence appeared to simply be turning devices on or\noff. Albright and his colleagues ran down the list of components in a uranium\nenrichment plant that might fit this scenario, and the only one that made\nsense to them was valves.\n\nCentrifuges at Natanz each had three valves that controlled the movement of\ngas in and out of them, plus auxiliary valves that controlled the movement of\ngas in and out of the cascade and between rows of centrifuges in a cascade.\nAlbright and his staff ran through various scenarios to determine what would\nhappen if certain valves were opened or closed with malicious intent for\nextended periods of time, and in each scenario the outcome was likely damaged\nor destroyed centrifuges.\n\nIt was clear to Albright that they had finally found the answer to the\npuzzling numbers they had seen in the IAEA reports. In statements made to the\npress, Ahmadinejad had insisted that the damage done to centrifuges by the\nvirus sent by the West was limited. But to Albright, the numbers that appeared\nin IAEA reports around the time that Iran said the virus had struck appeared\nto indicate that at least 1,000 centrifuges might have been damaged or\nreplaced during that period.\n\nAlbright published a paper discussing his thoughts that appeared to resolve\nthe Natanz question once and for all. Then, shortly after he did, the _New\nYork Times_ came out with a story that seemed to resolve Stuxnet’s most\nenduring mystery—who had created and launched it. The story surprised no one\nin its findings. The paper reported that Stuxnet was a joint operation between\nIsrael and the United States, with a little bit of assistance, witting or\notherwise, from the Germans and the British.[18](part0017.html#c13-ftn18)\n\nAccording to the story, which relied on anonymous sources, the worm had been\nwritten by US and Israeli coders and tested at Israel’s Dimona complex in the\nNegev Desert—the site that developed Israel’s own illicit nuclear weapons\nprogram in the 1960s. Dimona was enlisted to set up a test-bed of Siemens\ncontrollers and centrifuges, which were identical to the IR-1s at Natanz, to\nmeasure the effectiveness of the worm at destroying the spinning devices. But\na US lab also played a role in the tests. In 2004, the Oak Ridge National\nLaboratory in Tennessee had obtained some P-1 centrifuges, the type that\nIran’s IR-1s were modeled on, and the British, who were partners in the Urenco\nconsortium that had created the original centrifuge designs, may have played a\nrole. When testing was completed, the United States and Israel worked together\nto target the machines in Iran.\n\nWhen asked about the role the United States might have played in Stuxnet, Gary\nSamore, Obama’s chief adviser on weapons of mass destruction and arms control,\nsimply smiled at a _Times_ reporter and said, “I’m glad to hear they are\nhaving troubles with their centrifuge machines, and the US and its allies are\ndoing everything we can to make it more\ncomplicated.”[19](part0017.html#c13-ftn19)\n\nThe news of US involvement in developing and releasing the digital weapon\nshould have created a stir in Washington and in other government circles\nbeyond. But it was largely met with silence, despite the fact that it raised a\nnumber of troubling questions—not only about the risks it created for US\ncritical infrastructures that were vulnerable to the same kind of attack, but\nabout the ethical and legal considerations of unleashing a destructive digital\nattack that was essentially an act of war. Ralph Langner had been right in\nsigning off his original post about Stuxnet the way he did. With confirmation,\nalbeit unofficial, that Israel and the United States were behind the attack,\nthe world had now formally entered the age of cyberwarfare.\n\n* * *\n\n[1](part0017.html#c13-ftn1a) This and all quotes from Chien are from author\ninterviews in 2010 and 2011.\n\n[2](part0017.html#c13-ftn2a) “STL” stands for Statement List programming\nlanguage.\n\n[3](part0017.html#c13-ftn3a) Chien had no idea why Siemens wasn’t more\nresponsive. It was possible the company didn’t consider the issue an urgent\none, since only about a dozen Siemens customers reported being infected by\nStuxnet. It was also possible Siemens wasn’t used to dealing with in-depth\nquestions about its software. The Symantec researchers weren’t asking\nquestions that could be answered easily by product reps; they were fundamental\nengineering questions about how the Siemens code worked. This required the\ncompany to track down programmers who’d worked on the Step 7 system. But it’s\nalso possible that Siemens was relatively quiet on Stuxnet because the company\ndidn’t want to stir up discussions about its business in Iran. The company had\nrecently found itself in hot water after a shipment of its controllers was\nseized in Dubai on its way to Iran for the uranium enrichment program. Another\nshipment of Siemens turbo processors was intercepted in Hamburg by export\nauthorities as it was on its way to Iran. Both of these shipments violated\nEuropean Union export controls prohibiting the sale of dual-use equipment to\nIran without a permit. Siemens claimed it didn’t know the shipments were\nheaded to Iran, but the incidents eventually forced the company’s CEO to\nannounce in January 2010 that Siemens would not initiate any new business with\nIran after mid-2010. When Stuxnet was discovered in Iran a few months later,\nSiemens’s relative silence about the code may have been in part an effort to\nnot stir up a discussion about how its controllers got to be at the uranium\nenrichment plant in the first place. There were Siemens workers who urged the\ncompany to take a more active role in examining Stuxnet, but they were\nsilenced. Siemens in effect wanted the issue to go away and had hoped that\nSymantec and other researchers would give up.\n\n[4](part0017.html#c13-ftn4a) Because Iran had been the victim of sabotage in\n2006 when parts purchased from Turkey for its nuclear program were reportedly\nsabotaged (see [this page](part0015.html#page200)), Iranian officials may have\ndecided they needed to manufacture their own frequency converters to avoid\nsaboteurs who were targeting the supply chain and manipulating ones they\nbought abroad.\n\n[5](part0017.html#c13-ftn5a) See [this page](part0014.html#page183).\n\n[6](part0017.html#c13-ftn6a) Eric Chien, “Stuxnet: A Breakthrough,” Symantec\nblog, November 12, 2010, available at [symantec.com/connect/blogs/stuxnet-\nbreakthrough](http://www.symantec.com/connect/blogs/stuxnet-breakthrough).\n\n[7](part0017.html#c13-ftn7a) “Iranian Nuclear Scientist Killed in Motorbike\nAttack,” BBC, November 29, 2010, available at [bbc.co.uk/news/world-middle-\neast-11860928](http://www.bbc.co.uk/news/world-middle-east-11860928).\n\n[8](part0017.html#c13-ftn8a) William Yong and Robert F. Worth, “Bombings Hit\nAtomic Experts in Iran Streets,” _New York Times_ , November 29, 2010.\n\n[9](part0017.html#c13-ftn9a) Ibid.\n\n[10](part0017.html#c13-ftn10a) Ibid.\n\n[11](part0017.html#c13-ftn11a) Dieter Bednarz and Ronen Bergman, “Israel’s\nShadowy War on Iran: Mossad Zeros in on Tehran’s Nuclear Program,” _Spiegel\nOnline_ , January 17, 2011, available at\n[spiegel.de/international/world/israel-s-shadowy-war-on-iran-mossad-zeros-in-\non-tehran-s-nuclear-\nprogram-a-739883.html](http://www.spiegel.de/international/world/israel-s-\nshadowy-war-on-iran-mossad-zeros-in-on-tehran-s-nuclear-\nprogram-a-739883.html).\n\n[12](part0017.html#c13-ftn12a) “Iran’s Chief Nuclear Negotiator: ‘We Have to\nBe Constantly on Guard,’ _Der Spiegel_ , January 18, 2011.\n\n[13](part0017.html#c13-ftn13a) Shahriari and Abassi were not the first Iranian\nscientists targeted. In 2007, Ardeshire Hassanpour, a nuclear physicist\nworking at the uranium conversion plant at Esfahan died under mysterious\ncircumstances, though his death was reported as an industrial accident. Then,\nten months before Shahriari’s death, a colleague of his, Massoud Alimohammadi,\nwas killed in a car bombing attack. Iran accused the Mossad of masterminding\nthe attack on Alimohammadi, but questions arose later when news reports\nrevealed he was not a nuclear scientist at all but a quantum field theorist.\nIn December that year, a twenty-six-year-old kickboxer named Majid Jamali\nFashi was arrested for the crime and later told a bizarre story on Iranian TV\nof having been recruited and trained by the Mossad, after visiting Turkey in\n2007. He said he was paid $30,000 up front for the assassination and promised\n$20,000 more after the attack. Iranian news agencies reported that Fashi was\nexecuted by hanging in May 2012. In a 2014 interview, Alimohammadi’s widow\nsaid that her husband had indeed been secretly working on Iran’s nuclear\nprogram. See Scott Peterson, “Covert War Against Iran’s Nuclear Scientists: A\nWidow Remembers,” _Christian Science Monitor_ , July 17, 2014.\n\n[14](part0017.html#c13-ftn14a) As a further intimidation tactic, an Iranian\nofficial revealed in a 2014 interview that the Mossad had once ordered a\nbouquet of flowers to be sent from an Iranian florist to the family of an\nIranian nuclear engineer with a card expressing condolences over his death.\nThe engineer was still alive and well, however. The spy agency, he said, also\ncreated videos of fake Iranian news broadcasts showing the images of murdered\nIranian scientists and sent the videos to the still-living scientists as a\nwarning. See “How West Infiltrated Iran’s Nuclear Program, Ex-Top Nuclear\nOfficial Explains,” _Iran’s View_ , March 28, 2014, [www.iransview.com/west-\ninfiltrated-irans-nuclear-program-ex-top-nuclear-official-\nexplains/1451](http://www.www.iransview.com/west-infiltrated-irans-nuclear-\nprogram-ex-top-nuclear-official-explains/1451).\n\n[15](part0017.html#c13-ftn15a) Yong and Worth, “Bombings Hit Atomic Experts in\nIran Streets.”\n\n[16](part0017.html#c13-ftn16a) Dagan was reportedly pushed out by Prime\nMinister Netanyahu and Defense Minister Ehud Barak because he opposed an air\nstrike against Iran.\n\n[17](part0017.html#c13-ftn17a) Yong and Worth, “Bombings Hit Atomic Experts in\nIran Streets.”\n\n[18](part0017.html#c13-ftn18a) William J. Broad, John Markoff, and David E.\nSanger, “Israeli Test on Worm Called Crucial in Iran Nuclear Delay,” _New York\nTimes_ , January 15, 2011.\n\n[19](part0017.html#c13-ftn19a) Ibid.\n\n\n# CHAPTER 14\n\n# **SON OF STUXNET**\n\nAs spring arrived in 2011, the story of Stuxnet seemed to be winding down.\nSymantec had resolved the mystery of the devices the digital weapon attacked,\nAlbright had made the final connection between Stuxnet and the centrifuges at\nNatanz, and although the US government still hadn’t made a formal admission of\nresponsibility for the attack, the _New York Times_ had confirmed what\neveryone suspected—that the United States and Israel were behind it.\n\nSymantec, for its part, was ready to move on. The researchers had spent half a\nyear tearing apart the code and had produced a seventy-page dossier of all\ntheir findings. They were relieved to finally be done with it. But they hadn’t\nput the project aside for long when startling new evidence emerged in\nEurope—evidence suggesting that Stuxnet was just one in an arsenal of tools\nthe attackers had used against Iran and other targets.\n\nBOLDIZSÁR BENCSÁTH TOOK a bite from his sandwich and stared at his computer\nscreen. The software he was trying to install on his machine was taking\nforever to load, and he still had a dozen things to do before the Fall 2011\nsemester began at the Budapest University of Technology and Economics, where\nhe taught computer science. Despite the long to-do list, however, he was\nfeeling happy and relaxed. It was the first day of September and was one of\nthose perfect, late-summer afternoons when the warm air and clear skies made\nyou forget that cold autumn weather was lurking around the corner.\n\nBencsáth, known to his friends as Boldi, was sitting at his desk in the\nuniversity’s Laboratory of Cryptography and System Security, aka CrySyS Lab,\nwhen the telephone interrupted his lunch. It was Jóska Bartos, CEO of a\ncompany for which the lab sometimes did consulting\nwork.[1](part0018.html#c14-ftn1)\n\n“Boldi, do you have time to do something for us?” Bartos asked.\n\n“Is this related to what we talked about before?” Bencsáth said, referring to\na previous discussion they’d had about testing new services the company\nplanned to offer customers.\n\n“No, something else,” Bartos said. “Can you come now? It’s important. But\ndon’t tell anyone where you’re going.”\n\nBencsáth wolfed down the rest of his lunch and told his colleagues in the lab\nthat he had a “red alert” and had to go. “Don’t ask,” he said as he ran out\nthe door.\n\nA while later, he was at Bartos’s office, where a triage team had been\nassembled to address the problem they wanted to discuss. “We think we’ve been\nhacked,” Bartos said.\n\nThey’d found a suspicious file on a developer’s machine that had been created\nlate at night when no one was working. The file was encrypted and compressed\nso they had no idea what was inside, but they suspected it was data the\nattackers had copied from the machine and planned to retrieve later. A search\nof the company’s network found a few more machines that had been infected as\nwell. The triage team felt confident they had contained the attack but wanted\nBencsáth’s help determining how the intruders had broken in and what they were\nafter. The company had all the right protections in place—firewalls,\nantivirus, intrusion-detection and -prevention systems—and still the attackers\ngot in.\n\nBencsáth was a teacher, not a malware hunter, and had never done such forensic\nwork before. At the CrySyS Lab, where he was one of four advisers working with\na handful of grad students, he did academic research for the European Union\nand occasional hands-on consulting work for other clients, but the latter was\nmostly run-of-the-mill cleanup work—mopping up and restoring systems after\nrandom virus infections. He’d never investigated a targeted hack before, let\nalone one that was still live, and was thrilled to have the chance. The only\ncatch was, he couldn’t tell anyone what he was doing. Bartos’s company\ndepended on the trust of customers, and if word got out that the company had\nbeen hacked, they could lose clients.\n\nThe triage team had taken mirror images of the infected hard drives, so they\nand Bencsáth spent the rest of the afternoon poring over the images in search\nof anything suspicious. By the end of the day, they’d found what they were\nlooking for—a combination keystroke logger/infostealer that was designed to\nrecord passwords and other keystrokes on infected machines, as well as steal\ndocuments and take screenshots. It also catalogued any devices or systems that\nwere connected to the machines so the attackers could build a blueprint of the\ncompany’s network architecture. The malware didn’t immediately siphon the\nstolen data from infected machines but instead stored it on the machines in a\ntemporary file, like the one the triage team had found. The file grew fatter\neach time the infostealer sucked up data, until at some point the attackers\nwould reach out to the machine to retrieve it from a command-and-control\nserver in India.[2](part0018.html#c14-ftn2)\n\nBy now it was the end of the day, so Bencsáth took the mirror images and the\ncompany’s system logs with him, after they had been scrubbed of any sensitive\ncustomer data, and over the next few days scoured them for more malicious\nfiles, all the while being coy to his colleagues back at the lab about what he\nwas doing. The triage team worked in parallel, and after several more days\nthey had uncovered three additional suspicious files—including a kernel-mode\ndriver, and another driver that was found on some infected systems but not\nothers.\n\nWhen Bencsáth examined the kernel driver, his heart quickened—it was signed\nwith a valid digital certificate from a company in Taiwan. Wait a minute, he\nthought. Stuxnet used a driver that was signed with a certificate from a\ncompany in Taiwan. That one came from RealTek Semiconductor, but this\ncertificate belonged to a different company, C-Media Electronics. The driver\nhad been signed with the certificate in August 2009, around the same time\nStuxnet had been unleashed on machines in Iran.\n\nCould the two attacks be related? he wondered. He mulled it over for a minute,\nbut then dismissed it. Anyone could have stolen C-Media’s signing key and\ncertificate, he reasoned, not just the attackers behind Stuxnet.\n\nThen a member of the triage team noticed something else about the driver that\nseemed familiar—the way it injected code into a certain process on infected\nmachines. “I know only one other attack that does this,” he told Bencsáth. He\ndidn’t have to say the name; Bencsáth knew he was talking about Stuxnet. But\nBencsáth dismissed this connection too, since he was pretty sure the technique\nwasn’t unique to Stuxnet.\n\nTwice more over the next few days, Bencsáth and the triage team found\nsomething in the attack code that reminded them of Stuxnet. But each time they\nconvinced themselves it was just a coincidence. There was just no way\nlightning would strike twice, they reasoned. Besides, there was no sign that\nthis new attack was targeting PLCs.\n\nAfter working on the project for a week, Bencsáth began wondering if anyone\nelse had been infected with the files, so he decided to see if he could smoke\nout other victims, or the attackers themselves, with a sly test. On September\n8, he posted hashes for the malicious files on his personal website,\nboldi.phishing.hu, along with a cryptic note: “Looking for friends [or] foes\nof 9749d38ae9b9ddd8ab50aad679ee87ec to speak about. You know what I mean. You\nknow why.” His site, an odd compendium of fish recipes and culinary reviews of\ncanned fish (the domain name, phishing, was a pun on the computer security\nterm for malicious e-mail), was the perfect cover for posting the covert\nmessage, since the only way someone would find the hashes was if they\nspecifically did a Google search looking for them—either another victim who\nfound the same files on their machine and was searching the internet for\ninformation about them, or the attackers themselves, who might want to see if\nany victims had found the files and were discussing them online. If someone\ndid visit his site in search of the hashes, Bencsáth would be able to see\ntheir IP address.\n\nUnfortunately, he got no nibbles on his bait, so he deleted the hashes after a\nfew days.\n\nBy now the fall semester had begun, and Bencsáth got busy with other things.\nHe had classes to teach and office hours with students to keep. He also had a\nresearch paper to deliver at a conference in Dubrovnik. But through it all,\nthe attack nagged at him in the back of his mind. When he returned to Budapest\nafter the conference, he and the triage team decided to compare the code of\none of the drivers they had found on their machines with one of the drivers\nthat had been used with Stuxnet—just to settle once and for all that the two\nattacks weren’t related. When they put the codes into a hexadecimal (hex)\neditor to examine them side-by-side, however, they got a big surprise. The\nonly difference between them was the digital certificates used to sign them.\n\nBencsáth immediately called Bartos, the company’s CEO, and told him he needed\nto bring the other members of the CrySyS Lab onto the investigation. This\nwasn’t a simple hack anymore; it looked like it might be a nation-state attack\nwith national-security implications. Bartos agreed, but only on condition that\nBencsáth not reveal the company’s name to any of his colleagues. The only\npeople aside from Bencsáth who knew the company had been hacked was the local\ngovernment Computer Emergency Response Team, and they had been notified only\nbecause of the nature of the company’s business.[3](part0018.html#c14-ftn3)\n\nBencsáth made plans to tell his colleagues the following Monday. Over the\nweekend, he collected all the technical literature he could find on\nStuxnet—including the lengthy dossier Symantec had prepared—and reread it to\nrefresh his memory. When he reached the part discussing the encryption\nroutines that Stuxnet used to conceal its code, he pulled up the encryption\nroutines for the new attack and got another surprise. They were nearly\nidentical. The new attack code even used one of the same decryption keys that\nStuxnet used.[4](part0018.html#c14-ftn4)\n\nThen he examined the six kernel hooks the new code used—specific functions on\nthe machine that the malware hooked or hijacked to pull off its attack—and\ncompared them to the functions hooked by other known malicious attacks. He\nfound some that hooked two or three of the same functions, but none that\nhooked all six. He sifted through the Stuxnet literature to examine what\nStuxnet hooked, and there it was—the digital weapon hooked all six of the same\nfunctions. There was no doubt in his mind now that the two attacks were\nrelated.\n\nIt didn’t mean the codes were written by the same people, but it was clear the\ncreators of the new code had developed their attack from the same source code\nand framework that had been used to develop Stuxnet. Stuxnet had sabotaged\nIran’s uranium enrichment program but who knew what this new attack was doing\nand how many systems it had infected?\n\nBencsáth dashed off an e-mail to Bartos telling him what he’d found. Until now\nthey’d been working at a leisurely pace, looking at the code whenever they had\ntime. But now he realized they needed to determine what the attack was doing\nquickly and get the information out to the public before anyone could stop\nthem. After Symantec had published its research on Stuxnet, there were some\nwho wondered why the US government had never tried to thwart them. Bencsáth\nworried that this time someone would try to intervene.\n\nThe next day he told his colleagues, Levente Buttyán and Gábor Pék, about the\nattack. The three of them knew they weren’t equipped to do a thorough analysis\nof the files on their own—none of them had ever done malware analysis like\nthis before and had little experience using the debugging tools needed to\nreverse-engineer it. But they knew they had to do enough analysis to convince\nother, more experienced, researchers to look at it. The CrySyS Lab, like\nVirusBlokAda, was hardly a familiar name in the computer security world, and\nthey needed solid evidence to connect the attack to Stuxnet or no one else\nwould agree to examine it.\n\nThey set a deadline ten days away and decided to focus only on the parts of\nthe attack that were similar to Stuxnet. But to their surprise, there were\nmore similarities than they expected. At the end of the ten days, they had a\nsixty-page report. Bartos gave Bencsáth permission to share it with Symantec,\nbut only on condition that if they went public with the report, the CrySyS Lab\nwould not be named in it. Bartos worried that if anyone knew the lab was in\nHungary, it wouldn’t take long to identify the victim.\n\nThey sent the report to the government CERT, to Chien and his team at\nSymantec, and to a few others—Péter Szor, a Hungarian researcher at McAfee;\nsomeone at VeriSign, because VeriSign would need to revoke the digital\ncertificate the malware used; and to a researcher at\nMicrosoft.[5](part0018.html#c14-ftn5) Bencsáth’s heart was pounding as he\nclicked Send to e-mail the report. “I was really excited,” he says. “You throw\ndown something from the hill, and you don’t know what type of avalanche there\nwill be [as a result].”\n\n![](../images/00007.jpeg)\n\nWHEN CHIEN AWOKE on October 14, a Friday, he immediately reached for his\nBlackBerry to check his e-mail. The subject line of one message caught his\neye. It read simply, “important malware,” and came with an attachment. It had\nbeen sent by two computer scientists at an obscure university lab in Hungary,\nwho wrote in stilted English that they’d discovered a new attack that bore\n“strong similarities” to Stuxnet. They dubbed it “Duqu” (dew queue)—because\ntemporary files the malware created on infected machines all had names that\nbegan with ~DQ—and were certain it would “open a new chapter in the story of\nStuxnet.”\n\n“As we don’t really have experience with this sort of incidents yet [_sic_],\nwe are uncertain about the next steps that we should make,” they wrote. “We\nare ready to collaborate with others, including you, by providing access to\nthe malware and participating in its further analysis.”\n\nChien forwarded the e-mail to the rest of the incident-response team at\nSymantec and sent a text message to O’Murchu telling him to read it as soon as\nhe woke up. Then he headed to the office feeling cautiously excited.\n\nOver the past year, Chien had grown wary of people contacting him with false\nalarms about new Stuxnet sightings. Working for an antivirus firm, he was\nalready used to friends and neighbors appealing to his expertise whenever they\nthought their computers were infected with a virus. But after his team’s work\non Stuxnet got widely publicized, random strangers began contacting him too,\ninsisting that the government was spying on them with Stuxnet. One guy even\nsent an envelope stuffed with fifty pages of printed-out screenshots and\nnetwork traffic logs that he’d highlighted in yellow. On one, he’d circled the\nURL of a website he’d visited that contained the letters “en/us”—proof that\nthe US government was watching his computer, he\nsaid.[6](part0018.html#c14-ftn6) Another correspondent, a female cookbook\nauthor, sent Chien a few e-mails via Hushmail—an anonymous encrypted e-mail\nservice used by activists and criminals to hide their identity. When Chien\nignored the e-mails, she tracked down his phone number and left a message.\nShe, too, was certain someone was spying on her with Stuxnet, she said,\nbecause every time she went to the library and inserted a USB flash drive into\na computer there, her home computer later got infected with a virus from the\nsame USB flash drive.\n\nDespite Chien’s cynicism about every new Stuxnet claim that crossed his desk,\nhe only had to read the first two pages of the report from Hungary before he\nknew that this one was different. “This is Stuxnet,” he said with certainty.\n\nDespite their lack of experience analyzing malicious code, the Hungarians had\nproduced an impressive report, although they apologized that “many questions\nand issues remain unanswered or unaddressed.” They had included snippets of\ndecompiled code showing Duqu’s likeness to Stuxnet and produced a side-by-side\nchecklist highlighting more than a dozen ways the two attacks were the same or\nsimilar. There was no attack against PLCs in this code—in fact, there was no\nreal payload at all, unless you considered the keylogger a payload. But the\nfingerprints of Stuxnet’s creators were all over it. Duqu was either written\nby the same team that was behind Stuxnet or, at the very least, by people with\naccess to the same source code and tools.\n\nChien e-mailed Bencsáth to let him know they’d received the report, then\nwaited anxiously for O’Murchu to arrive, feeling a mix of emotions. They had\nlong hoped that they or someone else would uncover additional clues to help\nthem resolve their remaining questions about Stuxnet. And Duqu looked like it\nmight provide some of the answers they were seeking. But their analysis of\nStuxnet had required months of work, including nights and weekends, and he\nfeared the new code might exact the same amount of time and energy.\n\n![](../images/00007.jpeg)\n\nO’MURCHU WAS STILL half-asleep when he saw Chien’s text message that morning,\nbut his grogginess quickly dispersed when he opened the attachment and read\nthe report. There was nothing like staring down the barrel of a suspected\ncyberweapon to clear the fog in your mind. “I’ve got to get to the office,” he\ntold his girlfriend as he threw on some clothes and dashed out the door.\n\nAs he drove to work, he tried to wrap his mind around what he’d just seen and\ncouldn’t believe the Stuxnet gang was still active. After all the media\nattention and finger pointing at Israel and the United States, he thought for\nsure the attackers would have laid low for a while to let things cool off. At\nthe very least he thought they would have altered their methods and code a\nlittle to make sure that any attack they unleashed hereafter couldn’t be\ntraced back to them if found. But judging by the report from Hungary, it\nappeared they hadn’t bothered to alter their signature moves at all. They\nreally had balls, he thought. They were determined to do whatever they had to\ndo and didn’t care who knew it was them. Either that, or they were already so\ninvested in using the Duqu code that they were loath to replace it even after\nStuxnet had been caught.\n\nWhen O’Murchu got to the office, Chien and their colleagues were already\nbuzzing about the new attack. They contacted Falliere, who had by now\nrelocated from Paris to the States and was now working out of Symantec’s\noffice in Northern California. They downloaded the binary files for Duqu that\nthe Hungarians had sent and worked on the code throughout the day and the\nweekend. They were happy to discover that Duqu was much smaller than Stuxnet\nhad been and consisted of just a few files that were fairly easy to decipher.\nBy Monday, they knew pretty much everything there was to know about the code.\n\nDuqu was essentially a remote-access Trojan, or RAT, which operated as a\nsimple back door to give the attackers a persistent foothold on infected\nmachines. Once the back door was installed, however, Duqu contacted a command-\nand-control server, from which the attackers could download additional modules\nto give their attack code more functionality, such as the keystroke\nlogger/infostealer the Hungarians had found on one of their systems.\n\nAs for Duqu’s intent, it was pretty clear it wasn’t a saboteur like Stuxnet,\nbut an espionage tool. Whereas Stuxnet was a black ops mission bent on\ndestruction, Duqu appeared to be the forward scout, sent out to collect\nintelligence for future assaults. Symantec suspected it was the precursor to\nanother Stuxnet-like attack. Duqu’s life-span was limited, however; a kill\ndate in the code forced it to self-destruct after thirty-six days, deleting\nall traces of itself from an infected machine.[7](part0018.html#c14-ftn7)\n\nAll of this seemed fairly straightforward, but as they examined Duqu’s files,\nthey stumbled across a surprise that seemed to connect it to another mystery\nattack that had been puzzling them for months. Six months earlier, officials\nin Iran had announced that computers there had been struck by a second digital\nattack in the wake of Stuxnet. The announcement came months after Iranian\nofficials had finally acknowledged that computers controlling centrifuges in\nIran had been attacked. Although the Iranians had never identified the\nspecific virus that struck the centrifuges, they gave this new attack the name\n“Stars.” Gholam-Reza Jalali, commander of Iran’s Civil Defense Organization,\ndidn’t say why they called it Stars, nor did he provide much information about\nthe attack other than to say it was aimed at stealing data. He also said it\nwas likely “to be mistaken [on computers] for executable files of the\ngovernment,” suggesting the malware may have arrived in a phishing attack,\nwith a malicious file attached that masqueraded as a document from a\ngovernment source.[8](part0018.html#c14-ftn8)\n\nSymantec and other security researchers didn’t know what to make of the report\nat the time, since Iran didn’t release any samples of the malware for outside\nresearchers to examine. The fact that no one else in the world had reported\ninfections from “Stars” led some researchers to dismiss the report, believing\nthat Iran had either fabricated the story to accuse the West of launching more\ncyberattacks or had simply mistaken a run-of-the-mill virus with a nation-\nstate attack.\n\nBut something they found in Duqu suggested it might be Stars. When Duqu’s\nattackers sent their keylogger to infected machines, they embedded it in a\n.JPEG file—an ordinary image file—to slip it through firewalls unnoticed. The\ncontent of most of the image in that file had been deleted so the keylogger\ncode could be tucked inside. As a result, only an inch or so of the image\nappeared on-screen when O’Murchu opened the file—it consisted of just a few\nwords of white text printed on a dark background. The words were cut off so\nonly their top half was visible, but it was still possible to make them out:\n“Interacting Galaxy System NGC 6745.” A Google search on the words revealed\nthe entire picture—a March 1996 image produced from the Hubble Space\nTelescope. The striking image depicted a thick cluster of luminous blue and\nwhite stars enveloped in a gossamer veil of golden matter and gases—the\naftermath, a caption revealed, of two galaxies “colliding” after a small\ngalaxy of stars grazed the top of a larger one. Was it possible that Duqu was\nthe mysterious “Stars” that struck Iran?[9](part0018.html#c14-ftn9) It seemed\nto Symantec and the CrySyS Lab that it was.\n\nSymantec wanted to go public with the news of Duqu, but before the researchers\ncould do so, they worked with Bencsáth to scrub the sample files and CrySyS\nreport of anything that might identify the victim or the\nlab.[10](part0018.html#c14-ftn10) On October 18, the Symantec team published\nthe anonymized CrySyS report, as well as their own analysis of Duqu,\nidentifying the victim only as “an organization based in Europe” and the\nCrySyS Lab as a “research lab with strong international\nconnections.”[11](part0018.html#c14-ftn11)\n\nWithin an hour after the announcement broke, Bencsáth got the first hit to his\npersonal website from someone searching for the hashes he’d posted weeks\nearlier. Although he’d deleted them from his site, Google cache had preserved\nhis post, and online security forums were buzzing with questions about the\ndeleted message. The next day he got more than four hundred hits to his domain\nas word spread quickly that this strange Hungarian site about canned fish was\nsomehow connected to Duqu. There was no contact information for Bencsáth on\nthe site, but it didn’t take long for someone to look up the registration for\nthe site’s domain and find his name. From there it took only a simple Google\nsearch to connect him to the CrySyS Lab.\n\nIt was futile to hide the lab’s identity at this point, so on October 21,\nBencsáth published a brief statement on the lab’s website, acknowledging their\nrole in discovering Duqu, and urged everyone to stop speculating about the\nvictim’s identity. It was too late for this, however. Word was already\nspreading that Duqu’s victim was a certificate authority in Europe after Péter\nSzor, the McAfee researcher who had received Bencsáth’s original report, wrote\na blog post titled “The Day of the Golden Jackal” saying that Duqu was\ntargeting certificate authorities and advising CAs to check their systems to\nmake sure they hadn’t been infected. Since the CrySyS Lab was in Hungary,\npeople assumed the victim was too. And since there were only a few certificate\nauthorities in that country—NetLock and Microsec e-Szigno being the primary\nones—it didn’t take long for a few researchers to zero in on NetLock as the\nvictim, though none of them went public with the\nnews.[12](part0018.html#c14-ftn12)\n\nThe implications were alarming. Certificate authorities are at the core of the\ntrust relationship that makes the internet function. They issue the\ncertificates that governments, financial institutions, and companies use to\nsign their software and websites, providing users with assurance that they are\ndownloading a legitimate program made by Microsoft or entering their account\nlogin credentials at a legitimate website operated by Bank of America or\nGmail. Attacking such an authority would allow the attackers to issue\nthemselves legitimate certificates in the name of any company and use it to\nsign malware. It went a step beyond Stuxnet’s tactic of compromising\nindividual companies like RealTek, JMicron, and C-Media. If Duqu was the work\nof the United States or Israel, it meant that a NATO country or ally had\ncompromised a fundamental part of the trusted infrastructure that made\ntransactions on the internet possible, all for the sake of advancing a covert\ncampaign. If the United States was behind the attack, it also meant that while\none branch of the government was touting the importance of securing critical\ninfrastructure at home and developing acceptable norms of behavior for the\ninternet, another was busy compromising critical systems belonging to a NATO\nally that were important for the security of the internet, and establishing\nquestionable norms of behavior that others would copy. But because the\nidentity of the victim was never disclosed at the time Duqu was exposed, the\npublic was denied an opportunity to debate these issues.\n\nDespite the omission of this important detail, when the news of Duqu broke, it\nelicited a far different response from the security community than Stuxnet\nhad. Research teams that had sat on the bleachers while Symantec had worked\nfor months to deconstruct Stuxnet’s payload quickly jumped on Duqu’s code to\nexamine it—in part because it was less complex than Stuxnet and didn’t have a\nPLC payload, but also because they had seen what sitting on the sidelines got\nthem. Stuxnet had signaled the dawn of a new era, and many researchers had\nchosen to sit it out.[13](part0018.html#c14-ftn13)\n\nOne security firm that was determined not to be left behind this time was\nKaspersky Lab in Russia. The Kaspersky researchers hadn’t sat idly when\nStuxnet was discovered; they had put in extensive work to deconstruct the\nWindows portion of the attack and had been the first private researchers to\ndiscover additional zero days in Stuxnet and report them to Microsoft. But\nbeyond its menagerie of exploits, they hadn’t considered Stuxnet a\nparticularly interesting threat. The unfamiliar PLC code was a barrier to\nexamining the payload, and ultimately they had determined there was little to\nbe gained from deciphering it. So once they’d completed their analysis of the\nmissile portion, they had moved on. But they weren’t going to make that\nmistake again.\n\nCOSTIN RAIU, DIRECTOR of Kaspersky’s Global Research and Analysis Team, was in\nBeijing when news of Duqu broke, preparing to board an early-morning flight to\nHong Kong for a meeting. His first thought was to call his colleagues back in\nMoscow, but they were still asleep. So before boarding his plane, he quickly\ndownloaded the Duqu files Symantec made available to researchers and examined\nthem during his flight.\n\nAs soon as he landed in Hong Kong, he contacted Alexander Gostev in Moscow, a\nyoung, highly skilled reverse-engineer and the company’s chief malware\nresearcher. Symantec and the CrySyS Lab had examined the Duqu files\nthoroughly, but Raiu and Gostev suspected there was much more intelligence to\nbe gleaned from the threat, and they were right.\n\nIt was clear to them immediately that Duqu was the work of master programmers.\nThe code was remarkably different from other spyware that crossed their\ndesks—Raiu likened it to the difference between Vincent Van Gogh’s _Starry\nNight_ and an art-school student’s amateur rendition of a star-filled night.\nThe master brushstrokes and genius in the code were evident to the practiced\neye.\n\nRaiu was a thirty-three-year-old Romanian who worked for Kaspersky out of a\ntiny office in Bucharest with one other researcher and a handful of marketing\nfolks. He had dark, close-cropped, graying hair and a maturity and wisdom that\nbelied his age. The latter made him a natural mentor to younger members of his\nresearch team. He also had a calm, Buddha-like demeanor that served him well\nunder pressure when they were juggling multiple complex projects at a time. It\nwas a quality that would prove invaluable over the many months that followed\nas his team’s research into the Stuxnet-Duqu gang intensified and they began\nto draw the attention of intelligence agencies.\n\nRaiu had joined the company in 2000 at the age of twenty-three, when it had\njust a few dozen employees. He was hired to work on its Prague project, the\nname the company gave the next-generation antivirus engine it was building.\n\nGrowing up in Communist Romania, Raiu’s passion hadn’t been computers but\nchemistry. He was fascinated by the combustible reaction of certain chemicals\nwhen mixed and by the fundamental knowledge that chemistry imparted about the\nnature and structure of the world. But when one of his experiments nearly blew\nup his parents’ apartment, they bought him a locally made PC clone to steer\nhim toward less lethal pursuits. It wasn’t long before he’d taught himself\nprogramming and, while still a teenager, designed an antivirus engine from\nscratch called RAV.\n\nHis work on RAV began when his high school network got infested with a virus\nthe school’s antivirus scanner didn’t detect. Raiu spent a night writing\nsignatures and crafting a detection tool for it. Over time, he added more code\nand features, and eventually began distributing it for free under the name\nMSCAN. When word of his creation got out, a Romanian entrepreneur hired him to\nwork for his company, GeCAD Software, which began marketing his program under\nthe name RAV, for Romanian Anti-Virus. It quickly became the company’s top-\nselling product, reliably beating out competitors in test after test, which\ndrew the attention of Microsoft. In 2003, the software giant acquired RAV from\nGeCAD, but by then Raiu had already jumped ship to work for\nKaspersky.[14](part0018.html#c14-ftn14)\n\nKaspersky Lab was relatively unknown at the time in the United States, where\nSymantec and McAfee dominated the antivirus market. As a Russian firm,\nKaspersky faced a battle of mistrust in the West—particularly since founder\nEugene Kaspersky had been schooled in a KGB-backed institute and had served in\nRussia’s military intelligence. But the company slowly made a name for itself\nin eastern Europe and elsewhere, particularly in the Middle East, where the\nUnited States and US firms faced a similar battle of mistrust.\n\nRaiu began with Kaspersky as a programmer, but in 2004 when the company\nlaunched a research team to investigate and reverse-engineer malware, Raiu\njoined the group. In 2010, he became its director, overseeing research teams\non several continents. Now, with the discovery of Duqu, several of these teams\nwent into action.\n\nThe technical work was led by Gostev, a whippet-thin analyst with short, light\nbrown hair and a slight stoop that was suggestive of all the hours he spent\nbent in concentration over a computer. As he and his colleagues picked through\nthe code, they were struck by a number of things.\n\nOne particularly interesting part was the component the attackers used to\ndownload additional payload modules to a victim’s machine to siphon data.\nUnlike every other Duqu and Stuxnet module, this one was written not in C or\nC++ but in a language Gostev and Raiu had never seen before. They tried for\nweeks to identify it and even consulted experts on programming languages, but\nstill couldn’t figure it out. So they put out a call for help on their blog\nand were finally able to conclude, piecing bits of clues together, that the\nattackers had employed a rarely used custom dialect of C, along with special\nextensions to contort the code and make it small and\nportable.[15](part0018.html#c14-ftn15) It was a programming style common to\ncommercial software programs produced a decade ago, but not to modern-day\nprograms, and certainly not to malware. It was clear these weren’t hot-shot\ncoders using the latest techniques, but old-school programmers who were\ncautious and conservative. Sometimes C++ could produce compiled code that was\nunpredictable and executed in unintentional ways. So the attackers had chosen\nC instead, Raiu surmised, to give them the greatest control over their\nmalicious code, then modified it during compilation to make it more compact\nand easy to deliver to victims.[16](part0018.html#c14-ftn16)\n\nTheir constraints on Duqu extended to its spreading mechanisms. In this regard\nDuqu was as tightly controlled as Stuxnet had been uncontrolled. The attack\ndidn’t appear to have any zero-day exploits to help it spread, and it also\ncouldn’t spread autonomously as Stuxnet did. Instead, once on a machine, it\nwould infect other machines only if the attackers manually sent instructions\nfrom their command server to do so.[17](part0018.html#c14-ftn17) Duqu was also\nmuch stealthier in communicating with its command servers than Stuxnet had\nbeen.[18](part0018.html#c14-ftn18) The communication was encrypted with a\nstrong encryption algorithm known as AES, to prevent anyone from reading it,\nand was also tucked inside a .JPEG image file to help conceal it. And unlike\nStuxnet, which struck more than 100,000 machines, researchers would eventually\nuncover only about three dozen Duqu infections.[19](part0018.html#c14-ftn19)\n\nThe victims were scattered among various countries and ranged from military\ntargets to manufacturers of industrial equipment, such as pipes and valves.\nAll of them appeared to have been carefully targeted for their “strategic\nassets”—products they produced or services they\nrendered.[20](part0018.html#c14-ftn20) Not surprisingly, many of the victims\nKaspersky uncovered had a connection to Iran; either they had an office in the\nIslamic Republic or they had some kind of trade relationship with Iran. The\nonly victim so far that didn’t appear to have a connection to Iran was the\ncompany in Hungary that discovered the attack.\n\nBased on information gleaned from log files provided by some of the victims,\nthe attackers appeared to be particularly interested in swiping AutoCAD\nfiles—especially ones related to industrial control systems used in various\nindustries in Iran. AutoCAD, which stands for computer-aided design, is\nsoftware used for drafting 2D and 3D architectural blueprints and designing\ncomputer boards and consumer products; but it’s also used for mapping the\nlayout of computer networks and the machinery on plant floors. The latter\nwould come in handy for someone planning to bomb a factory or launch a digital\nattack like Stuxnet.\n\nThe attackers were systematic in how they approached their victims, compiling\nnew attack files for each target and setting up separate command servers\nthroughout Europe and Asia so that only two or three infected machines\nreported to a single server. This segmentation no doubt helped them track\ndifferent operations and sets of victims, but it also ensured that if any\noutsider got access to one of the servers, their view of the operation would\nbe very limited. The servers, in fact, turned out to be proxy machines—way\nstations for the attackers to redirect stolen data to other machines—to\nfurther prevent anyone from seeing the entire operation or tracking stolen\ndata back to the attackers. Data from the victim in Hungary, for example, was\nfirst sent to a server in India before being redirected to one in the\nPhilippines, where it was sent somewhere else. Data from victims in Iran went\nto a server in Vietnam before going to Germany and somewhere beyond. The\nresearchers tried to follow the trail, but after hitting three different\nproxies in a row each time, they figured they’d never reach the end of the\ntrail, and gave up.\n\nWith help from some of the companies that hosted the servers, however,\nKaspersky obtained mirror images of five of the machines, including one in\nVietnam that controlled infections in Iran. They discovered that on October\n20, two days after Symantec had gone public with news of Duqu, the attackers\nhad conducted a massive cleanup operation in a panicked attempt to scrub data\nfrom the servers. Why it took them two days to respond to the news was\nunclear.[21](part0018.html#c14-ftn21) But in their haste to eliminate\nevidence, they left behind traces of logs that provided Kaspersky with clues\nabout their activity.[22](part0018.html#c14-ftn22) The logs showed, for\nexample, that the attackers had signed into one of the command servers in\nGermany in November 2009, two years before Duqu was discovered. This suggested\nthat Duqu was likely in the wild for at least that long. Perhaps, the\nKaspersky researchers posited, Duqu was really a _precursor_ to Stuxnet, not a\nsuccessor to it, as Symantec assumed. It wouldn’t be long before they found\nthe evidence to support this.\n\nIT WAS INITIALLY unclear to anyone how Duqu infected machines. Stuxnet had\nused the .LNK exploit embedded on USB flash drives to drop its malicious\ncargo. But the CrySyS Lab had found no dropper on machines at Bartos’s company\nand no zero-day exploits, either. After Symantec published its paper about\nDuqu, however, Chien asked Bencsáth to have the Hungarian victim search their\nsystems again for anything suspicious that occurred around August 11, the date\nthe infection occurred. That’s when they found an e-mail that had come in then\nwith a Word document attached to it. The attachment was 700k in size—much\nlarger than any documents the company usually received—which drew their\nattention. Sure enough, when the CrySyS team opened the e-mail on a test\nsystem in their lab, Duqu’s malicious files dropped onto\nit.[23](part0018.html#c14-ftn23)\n\nGiven that the attack code had gone undetected until now, the CrySyS guys\nsuspected a zero-day exploit was at play. Bencsáth sent the dropper to the\nSymantec team, who determined that it was indeed exploiting a zero-day buffer-\noverflow vulnerability in the TrueType font-parsing engine for Windows. The\nfont-parsing engine was responsible for rendering fonts on-screen. When font\ncode for a character appeared in a Word document, the engine consulted the\nproper font file to determine how the character should look. But in this case\nwhen the engine tried to read the font code, a vulnerability in the parsing\nengine triggered the exploit instead.\n\nThe exploit was quite “badass,” in the words of one researcher, because a\nnormal exploit attacking a buffer-overflow vulnerability generally got hackers\nonly user-level access to a machine, which meant they needed a second\nvulnerability and exploit to get them administrative-level privileges to\ninstall their malicious code undeterred.[24](part0018.html#c14-ftn24) But this\nexploit cut through layers of protection to let them install and execute\nmalicious code at the kernel level of the machine without interference.\nBuffer-overflow vulnerabilities that could be exploited at the kernel level\nare rare and difficult to exploit without causing the machine to crash, but\nthe Duqu exploit worked flawlessly. It was several orders of magnitude more\nsophisticated than the .LNK exploit Stuxnet had used. The .LNK exploit had\nbeen copied by cybercriminals in no time after Stuxnet was exposed in July\n2010, but this one would take months before anyone would successfully\nreplicate it.[25](part0018.html#c14-ftn25)\n\nThe exploit was notable in itself, but the attackers had also embedded a\ncouple of Easter eggs in their code—perhaps to taunt victims. The name they\ngave the fake font that executed their attack was Dexter Regular, and in the\ncopyright notice for the fake font they wrote—“Copyright © 2003 Showtime Inc.\nAll rights reserved. Dexter Regular.”[26](part0018.html#c14-ftn26)\n\nIt was clear they were referencing the popular TV show _Dexter_ , which was\nthen airing on the Showtime network. But the show didn’t begin airing until\nOctober 1, 2006, which made the 2003 copyright date seem odd. It was unclear\nif the Easter egg had any meaning or if it was just a joke. But the reference\ndid appear to have one parallel to Stuxnet. The Showtime series focused on\nDexter Morgan, a forensic scientist and vigilante killer who only murdered\ncriminals, making him a killer with a moral code—a murderer who killed for the\nsake of the greater societal good. At least that’s how Dexter saw it.\nArguably, it was also the way the United States and Israel might have viewed\nthe cyberattack on Iran, or the attacks on Iran’s nuclear scientists—as a\nmeans to a greater good.[27](part0018.html#c14-ftn27)\n\nThe font name and copyright date offered a bit of distraction for the\nresearchers, but the more notable part of the dropper was its compilation\ndate—February 21, 2008—providing a clue about how long Duqu might have been\naround. Not long after this dropper was found, Kaspersky got its hands on a\nsecond one, found on a machine in Sudan, that had been compiled even\nearlier.[28](part0018.html#c14-ftn28)\n\nSudan had close military ties to Iran—it received $12 million worth of arms\nfrom Iran between 2004 and 2006—and was a vocal supporter of Iran’s nuclear\nprogram. In 2006, Iran had publicly vowed to share its nuclear expertise with\nSudan. Sudan was also a target of UN sanctions. Duqu’s victim in Sudan was a\ntrade services firm that had been infected in April 2011, four months before\nthe infection in Hungary. The malicious code arrived via a phishing attack\nusing the same Dexter zero-day exploit that was used in Hungary. The malicious\ne-mail, purporting to come from a marketing manager named B. Jason, came from\na computer in South Korea, though the machine had likely been hacked to send\nthe missive.[29](part0018.html#c14-ftn29) “Dear Sir,” the e-mail read, “I\nfound the details of your company on your website, and would like to establish\nbusiness cooperation with your company. In the attached file, please see a\nlist of requests.” The attached document contained a handful of survey\nquestions as well as an image of a green Earth with plants sprouting from its\ntop. When the victim opened the attachment, the Dexter exploit sprang into\naction and deposited its illicit cargo onto the victim’s machine.\n\nThe dropper that installed Duqu in this case had been compiled in August 2007,\nwhich further confirmed that Duqu had been around for years before its\ndiscovery in Hungary. This wasn’t the only evidence supporting that early\ntimeline, however. The researchers also found evidence that Duqu’s infostealer\nfile had existed years earlier as well. They only stumbled upon this clue\nbecause of a mistake the attackers had made.\n\nWhen Duqu’s self-destruct mechanism kicked in after thirty-six days, it was\nsupposed to erase all traces of itself from infected machines so a victim\nwould never know he had been hit. But the Kaspersky team discovered that when\nDuqu removed itself, it forgot to delete some of the temporary files it\ncreated on machines to store the data it stole. One of these files, left\nbehind on a machine in Iran, had been created on the machine on November 28,\n2008.\n\nKaspersky and Symantec had always suspected that prior to Stuxnet’s assault on\nthe centrifuges in Iran, the attackers had used an espionage tool to collect\nintelligence about the configuration of the Siemens PLCs. The information\ncould have come from a mole, but now it seemed more likely that a digital spy\nlike Duqu had been used.\n\nIt seemed plausible that the Stuxnet attackers might also have used Duqu to\nsteal the digital signing keys and certificates from RealTek and JMicron,\nsince this was the tool they had used against the certificate authority in\nHungary.\n\nIf Duqu had indeed been in the wild infecting systems undetected since 2007,\nor longer, its sudden discovery in Hungary in 2011 seemed strange. Why now?\nRaiu wondered. He concluded that it must have been a case of hubris and a bad\nchoice of target. After remaining stealthy for so long, the attackers grew\nconfident that they’d never get caught. They likely considered Stuxnet’s\ndiscovery the previous year an anomaly that occurred only because the digital\nweapon had spread too far. But Duqu was carefully controlled and its targets\nhandpicked, which made its discovery less likely. Except, in Hungary, the\nattackers finally picked the wrong target. The Hungarian certificate authority\nwas much more security conscious than the trading companies and manufacturers\nDuqu had previously hit. And this was Team Duqu’s\nfailing.[30](part0018.html#c14-ftn30)\n\nThough Stuxnet and Duqu shared some of the same code and techniques, Raiu and\nhis team ultimately concluded that they had been built by separate teams from\nthe same base platform, a platform they dubbed “Tilde-d”—because both Stuxnet\nand Duqu used files with names that began with\n~D.[31](part0018.html#c14-ftn31)\n\nIn fact, Kaspersky discovered evidence that an arsenal of tools might have\nbeen built from the same platform, not just Stuxnet and Duqu. They found at\nleast six drivers that shared characteristics and appeared to have been built\non the Tilde-d platform. Two of them had been used in the known Stuxnet\nattacks, and a third one was the driver that had been used with\nDuqu.[32](part0018.html#c14-ftn32) But they also found three “phantom drivers”\nthat were discovered by themselves, without any Stuxnet or Duqu files with\nthem, making it difficult to determine if they had been used with either of\nthese attacks or with different attacks altogether. All three of the drivers\nused algorithms and keys that were the same as or similar to those that the\nStuxnet and Duqu drivers used, making it clear they were connected to the\nTilde-d team.\n\nThe first of these was the driver that had been found in July 2010 by the\nSlovakian antivirus firm ESET and was signed with the JMicron\ncertificate.[33](part0018.html#c14-ftn33) Because the driver was found days\nafter the news of Stuxnet broke, everyone assumed it was related to Stuxnet,\nthough it was not found on any system infected with Stuxnet. The driver was a\nhybrid of the Stuxnet and Duqu drivers, using code that was nearly identical\nto the Stuxnet driver and some of the same functions and techniques that the\nDuqu driver used. But it also used a seven-round cipher for its encryption\nroutine instead of the four-round cipher that Stuxnet’s driver used, making it\nmore complex. This made Raiu and Gostev suspect it was designed for a\ndifferent variant of Stuxnet or different malware altogether.\n\nThe second phantom driver was discovered when someone submitted it to\nVirusTotal.[34](part0018.html#c14-ftn34) It was compiled on January 20, 2008.\nIt also had a seven-round cipher, suggesting that it and the JMicron driver\nmight have been created for use with the same attack—perhaps with a different\nversion of Stuxnet or something else altogether.\n\nThe third mystery driver was also submitted to VirusTotal, from an IP address\nin China on May 17, 2011, months before Duqu infected the Hungarian machines\nin August.[35](part0018.html#c14-ftn35) This driver used a four-round cipher\nlike the Stuxnet drivers and an identical encryption key; it was also compiled\nthe same day the Stuxnet drivers were compiled and was signed with the RealTek\ncertificate that had been used to sign Stuxnet’s drivers, though it was signed\nMarch 18, 2010, instead of January 25, 2010, the date the Stuxnet drivers were\nsigned. March 18 was just weeks before the attackers unleashed their April\n2010 variant of Stuxnet, but for some reason they didn’t use this driver with\nthat assault. Instead, they reused the driver from the June 2009 attack. This\nsuggested that the third phantom driver might have been prepared for a\ndifferent attack.\n\nThe burning questions for Gostev and Raiu, of course, were what attacks were\nthe phantom drivers created for and who were their victims? Were they evidence\nthat other undetected Stuxnet attacks had occurred prior to June 2009 or after\nApril 2010?\n\nIt seemed the story of Stuxnet was still incomplete.\n\n* * *\n\n[1](part0018.html#c14-ftn1a) Jóska Bartos is a pseudonym. The company asked\nBencsáth not to disclose its identity or the identities of people working for\nit. The description of these events comes from an interview with Bencsáth\nexcept where otherwise noted.\n\n[2](part0018.html#c14-ftn2a) They uploaded the keylogger to VirusTotal, a free\nonline virus tool that researchers use to detect malicious files, to see if it\nwas known malware. VirusTotal aggregates nearly four dozen antivirus engines\nfrom multiple companies to detect malicious files. Two scanners flagged the\nfile as suspicious, but it was unclear if it was a known keylogger or\nsomething new. It was flagged by BitDefender and AVIRA scanners. Technically\nit was also detected by F-Secure and G-DATA, but only because both of these\nscanners use BitDefender’s engine. VirusTotal is sometimes used by attackers\nto test their malware before unleashing it to make sure virus engines won’t\ndetect it. But the fact that this keylogger was flagged by two of the engines\nsuggests the attackers either hadn’t bothered to test it against these two\nscanners before unleashing it or they weren’t expecting their victims to be\nusing the two engines.\n\n[3](part0018.html#c14-ftn3a) Confirmation of the nature of the company’s\nbusiness did not come from Bencsáth or his lab but was gleaned from other\nsources who were familiar with the breach and the victim.\n\n[4](part0018.html#c14-ftn4a) The inoculation value that Stuxnet had\nused—0x19790509 (which Symantec had interpreted to be a date—May 9, 1979)—also\nshowed up in this new attack code. In Stuxnet it had been used to prevent the\nworm from infecting machines that had this value in their registry, but here\nit was part of the encryption.\n\n[5](part0018.html#c14-ftn5a) The Microsoft researcher, Tareq Saade, was on the\nlist because the government CERT had already sent Microsoft a copy of the\nkeylogger file after it was discovered, so Bencsáth thought Microsoft should\nsee the CrySyS Lab report as well.\n\n[6](part0018.html#c14-ftn6a) The “en/us” letters in the URL merely indicated\nthat the man had visited a site that was localized for English-speaking\nreaders in the United States.\n\n[7](part0018.html#c14-ftn7a) Researchers eventually uncovered multiple\nversions of Duqu, with varying removal times. In some cases it removed itself\nafter 30 days, in other versions it was 36 days. In at least one case, the\nresearchers found a version that lasted 120 days before deletion.\n\n[8](part0018.html#c14-ftn8a) Dugald McConnel, “Iranian Official: New Computer\nWorm Discovered,” CNN, April 27, 2011. Available at\n[cnn.com/2011/TECH/web/04/26/iran_computer_worm](http://www.cnn.com/2011/TECH/web/04/26/iran_computer_worm).\n\n[9](part0018.html#c14-ftn9a) After news of Duqu broke, someone on Twitter who\nidentified himself as an Iranian malware researcher in Virginia published a\ntweet saying that according to investigations by Iran’s CERT, “#Duqu is\nupgraded version of #Stars malware.” He deleted the tweet very quickly after\nposting it, however, and not long afterward also deleted his entire Twitter\naccount. It’s unclear if there was any significance to the image of the\ngalaxies in Duqu or if the attackers had just chosen a random picture, but\nBencsáth thought it might have been used as a secret signal to identify Duqu\nas “friendly fire.” Sometimes various intelligence branches of the same\ngovernment will target the same computers. If the United States or Israel was\nbehind Duqu, the image might have been a signal to “friendlies” who came\nacross the keylogger on an infected machine—in the course of trying to hack it\nthemselves—that the machine was already infected by a compatriot.\n\n[10](part0018.html#c14-ftn10a) Some criticized Symantec’s decision to go\npublic so quickly. A more strategic approach would have been to remain quiet\nwhile gathering more intelligence about the attack—for example, asking\ncompanies hosting the command-and-control servers for a mirror image of the\nservers to see what the attackers were doing on them—before signaling to the\nattackers that they had been caught. It was an ongoing tension that existed\nbetween investigative and forensic needs and the needs of customers, who would\nwant to know quickly if they had been infected so they could shore up their\nnetwork against other attacks and determine if the intruders had stolen\nanything. But the CrySyS Lab had already sent its report to someone at McAfee,\na competing antivirus firm, who might go public with the news or inadvertently\ntip off the attackers that they’d been caught. There were other drawbacks to\nwaiting to go public. Without widening the net of people who knew about the\nmalware, it would be difficult to obtain other samples of Duqu that could tell\nthem more about the attack. The malware was very targeted, infecting only a\nsmall number of victims, and every file related to Duqu that they could\ncollect from victims gave them a little more information about the attack.\n\n[11](part0018.html#c14-ftn11a) Symantec’s Duqu report is available at\n[symantec.com/content/en/us/enterprise/media/security_response/whitepapers/w32_duqu_the_precursor_to_the_next_stuxnet.pdf](http://www.symantec.com/content/en/us/enterprise/media/security_response/whitepapers/w32_duqu_the_precursor_to_the_next_stuxnet.pdf).\n\n[12](part0018.html#c14-ftn12a) I was able to confirm the identity of the\nvictim as NetLock from several sources not associated with the CrySyS Lab.\n\n[13](part0018.html#c14-ftn13a) It wasn’t just security companies that\nresponded differently this time. The government did as well. For some reason,\nduring the many months the Symantec researchers had been analyzing Stuxnet and\npublishing pleas for help from PLC experts, ICS-CERT had remained distant,\neven though its analysts possessed the exact PLC expertise Symantec sought. A\nDHS official later acknowledged in an author interview that the department\nmade a mistake in not reaching out to Symantec. This time around, ICS-CERT\nhandled it differently and contacted Symantec to compare notes about its own\nfindings about Duqu.\n\n[14](part0018.html#c14-ftn14a) Microsoft’s Security Essentials program is\nbased on Raiu’s RAV antivirus engine.\n\n[15](part0018.html#c14-ftn15a) The attackers used a custom object-oriented C\ndialect known as OO-C.\n\n[16](part0018.html#c14-ftn16a) While this component displayed masterful\nskills, there were other parts that were less masterful. The implementation of\nencryption, for example, was weak. Duqu was built like an elegant Chinese box\nwith multiple layers of encryption to obfuscate its components and thwart\ndetection. But the way the attackers implemented it was poorly done. One part\nhad an encrypted configuration block that held a key to decrypt a registry;\ninside the registry was another key to decrypt Duqu’s main .DLL file. The\ndesign was supposed to make it hard for anyone who got hold of the .DLL to\ndecrypt it without first obtaining the other two keys. But the programmers had\nundermined their security by making the keys for the registry and the .DLL\nidentical and making the key for the configuration block 0. Once someone\nunlocked the configuration block, he already had the key to decrypt the main\n.DLL, bypassing the need for a separate registry key. Stuxnet, by contrast,\nhad used different keys for each stage of encryption. The encryption algorithm\nused in Stuxnet was also a four-round cipher, while Duqu used a weaker one-\nround cipher. Clearly different but related teams had designed Duqu and\nStuxnet, but even though both teams had strong and advanced methods of\nencryption at their disposal, the Duqu team hadn’t bothered to use them.\n\n[17](part0018.html#c14-ftn17a) To accomplish this, they had to first seize\ncontrol of the administrative account on an infected machine, then set up a\ntask instructing the malware to spread via network shares.\n\n[18](part0018.html#c14-ftn18a) Team Duqu also stored some of the scripts for\ncontrolling the operation at other locations, rather than on the command\nservers, so that anyone who seized control of these front-end servers couldn’t\nseize and examine the scripts to determine what Duqu was doing.\n\n[19](part0018.html#c14-ftn19a) There may have been more victims over the\nyears, but these were the only ones uncovered after Duqu was discovered.\nSymantec found victims in eight countries—one each in France, India, the\nNetherlands, Switzerland, Sudan, Vietnam, and Ukraine, and at least two in\nIran. Kaspersky found eleven more infections in Iran, three in Europe, and\nfour in Sudan. Other antivirus vendors found victims in Austria, Indonesia,\nand the UK.\n\n[20](part0018.html#c14-ftn20a) Kelly Jackson Higgins, “Same Toolkit Spawned\nStuxnet, Duqu, and Other Campaigns,” Dark Reading, January 3, 2012, available\nat [darkreading.com/advanced-threats/167901091/security/attacks-\nbreaches/232301225/same-toolkit-spawned-stuxnet-duqu-and-other-\ncampaigns.html](http://www.darkreading.com/advanced-\nthreats/167901091/security/attacks-breaches/232301225/same-toolkit-spawned-\nstuxnet-duqu-and-other-campaigns.html).\n\n[21](part0018.html#c14-ftn21a) If Israel was behind Duqu, the delay might have\nhad something to do with the fact that October 18, the date Symantec published\nits report, fell during the Sukkot holiday in Israel, which ran from October\n13 to 19 that year. Sukkot commemorates the forty years the Israelites spent\nin the Sinai desert after escaping slavery in Egypt. In Israel, the first day\nof the festival was a work holiday. Although the remaining six days were not\nmandatory holidays, many Israelis took them off anyway since schools were\nclosed. Sukkot would have concluded on the nineteenth, with workers back to\nwork on the twentieth—including, presumably, Duqu’s server team.\n\n[22](part0018.html#c14-ftn22a) They left behind other traces as well. The\nnight before stories about Duqu broke, the attackers had changed Duqu’s\nencryption keys and recompiled their Duqu files with the new keys before\npushing out the new files to infected machines. The attackers likely intended\nfor the new version of Duqu to replace older versions on infected systems, but\nthey didn’t count on a quirk in the Windows operating system that caused\ntraces of the older version to remain, which researchers later found when\ntheir antivirus products scanned the systems. The attackers may have changed\nthe encryption keys because they sensed the malware had been discovered and\nwere trying to outrun detection. But if they suspected they had been caught,\nthey didn’t seem to comprehend the degree to which their mission was about to\nbe exposed, because they also released an update to extend the malware’s life-\nspan beyond thirty-six days, as if they fully expected to continue their\noperation for a while undisturbed. Once the news broke and they understood\nthat their entire operation was toast, however, they had initiated the cleanup\noperation to wipe all the data from their servers.\n\n[23](part0018.html#c14-ftn23a) The dropper didn’t immediately install its\nmalicious cargo. Instead it waited until the computer was idle at least ten\nminutes before springing into action. The date on the computer also had to be\nwithin an eight-day window in August or Duqu wouldn’t install its files,\nfurther evidence of the amount of caution and control the attackers maintained\nover their code.\n\n[24](part0018.html#c14-ftn24a) A blogger for the Finnish antivirus firm\nF-Secure called it “one badass exploit.” November 2, 2011, “Duqu Attack’s\nInstaller Discovered,” available at\n[f-secure.com/weblog/archives/00002263.html](http://www.f-secure.com/weblog/archives/00002263.html).\n\n[25](part0018.html#c14-ftn25a) Researchers saw signs of cybercriminals trying,\nbut failing, to replicate the Duqu exploit in June 2012, eight months after\nSymantec published information about the vulnerability. They finally succeeded\nin October 2012, after which Kaspersky saw a spike in attacks using copycat\nversions of the exploit in December 2012. Microsoft had patched the\nvulnerability in December 2011, however, so attackers could use the exploit\nonly against unpatched machines.\n\n[26](part0018.html#c14-ftn26a) The Kaspersky researchers found something else\nthey thought might be an Easter egg in the code. A decryption key in one\nversion of the Duqu driver had a value—0xAE240682—that also appeared to be a\ndate: June 24, 1982. When Raiu looked it up it turned out to be the day a\nfamous event in aviation history occurred—the date British Airways Flight 09\nhit a volcanic ash cloud en route from London to New Zealand. The plane had\njust taken off after a stopover in Malaysia when gritty ash spewing from Mount\nGalunggung choked all four of the 747’s engines, leaving it dead in the air.\nThe pilots attempted to glide it to a landing, and as the plane descended from\n37,000 to 12,000 feet, oxygen masks dropped from the ceiling. That’s when the\nBritish captain, Eric Moody, made one of the most famous understatements in\nthe history of aviation. “Ladies and gentlemen,” he told the passengers, “this\nis your captain speaking. We have a small problem. All four of the engines\nhave stopped. We are doing our damnedest to get them going again. I trust you\nare not in too much distress.” (See “When Volcanic Ash Stopped a Jumbo at\n37,000ft,” BBC, April 15, 2010. Available at\n[news.bbc.co.uk/2/hi/uk_news/magazine/8622099.stm](http://www.news.bbc.co.uk/2/hi/uk_news/magazine/8622099.stm).)\nThe pilots managed to restart the engines after about fifteen minutes and land\nin Jakarta. Was it a coincidence that this seemed to be the second aviation\nreference after the DEADF007 reference in Stuxnet? Or were the attackers just\nplaying with researchers now and dropping little Easter eggs in the code to\nkeep them guessing? Or was the value in the code simply a random number with\nno significance?\n\n[27](part0018.html#c14-ftn27a) Kaspersky’s Costin Raiu bought all past\nepisodes of the Dexter show to see if there was some reason the attackers\nreferenced it in Duqu. Only one episode seemed remotely relevant. In it,\nDexter’s sister, Debra, received a marriage proposal from Det. Joey Quinn.\nDuring a discussion about the proposal with her brother, he mused that if she\nwere to marry Quinn, her initials would be DQ.\n\nRaiu did see one other episode that reminded him of Duqu. To confuse\ninvestigators who were hot on the serial killer’s trail, Dexter crafted a\nthirty-page manifesto littered with biblical references to distract them.\nWhile the investigators wasted time sifting through the meaningless document\nfor clues, Dexter continued his killing spree. The parallels weren’t lost on\nRaiu, who pondered the hours he’d wasted watching the TV show for clues about\nDuqu.\n\n[28](part0018.html#c14-ftn28a) The dropper file, a driver, tried to pass\nitself off as a graphics driver from Intel, and was responsible for loading\nthe Duqu back door onto a victim’s machine.\n\n[29](part0018.html#c14-ftn29a) There were two attempts to infect the victim,\nfirst on April 17, 2011, which got blocked by the victim’s Outlook spam\nfilter, and then on April 21, which succeeded.\n\n[30](part0018.html#c14-ftn30a) At the time it was hacked, the Hungarian\ncompany would have been doubly alert for a breach because of two\nother—seemingly unrelated—assaults on certificate authorities that had\noccurred in the previous months. In March of that year, someone breached the\naccount of a partner company that worked with Comodo Group, a certificate\nauthority based out of New Jersey and the UK. The hacker, who used an IP\naddress in Iran, parlayed the access to issue himself eight fraudulent\ncertificates for mail.google.com, login.yahoo.com, and six other domains that\nwould allow him to impersonate these sites in a man-in-the-middle attack. Four\nmonths later, a Dutch certificate authority named DigiNotar was also hacked.\nThe intruders in this case generated more than 200 fraudulent digital\ncertificates for top domains owned by Google, Yahoo, and Mozilla, as well as\nfor the websites of the Mossad, MI6, and the CIA. These intrusions put other\ncertificate authorities on guard, and the company in Hungary had likely\nstepped up inspection of its network as a result.\n\n[31](part0018.html#c14-ftn31a) Duqu’s keylogger/infostealer created file names\nthat began with ~DQ, but other parts of the malware created files whose names\nbegan with ~DO and ~DF. Stuxnet also created temporary files whose names began\nwith ~D.\n\n[32](part0018.html#c14-ftn32a) Multiple versions of the Duqu driver showed up\non infected machines, each time bearing a different name. Each version\nappeared to contain the same code, however, and was compiled the same day.\nNotably, one variant of the Duqu driver that was found on the machines in\nHungary was unsigned and tried to pass itself off as a product of JMicron—the\nTaiwanese company whose certificate was used to sign a driver that was found\nby ESET in July 2010 and was believed to have been associated with Stuxnet. In\nthe “properties” description of the driver, the attackers had indicated that\nit was a JMicron Volume Snapshot Driver. It was yet another detail that\nconnected Duqu and Stuxnet.\n\n[33](part0018.html#c14-ftn33a) The driver file name was jmidebs.sys.\n\n[34](part0018.html#c14-ftn34a) The name of this driver was rndismpc.sys.\n\n[35](part0018.html#c14-ftn35a) The name of this driver was rtniczw.sys.\n\n\n# CHAPTER 15\n\n# **FLAME**\n\nBy the Spring of 2012, the team at Kaspersky had completed their analysis of\nDuqu and its servers, but they were sure there was more to the story than had\nso far been exposed. Even they, however, could not have imagined the discovery\nthey were about to make: that Stuxnet—a program that awed with its boldness\nand destructive potential—was just an offshoot of a cyberspying operation that\nwas orders of magnitude larger than this single digital weapon.\n\nTHE REVELATIONS BEGAN that April, when a virus began running wild on computers\nat the Iranian Oil Ministry and the Iranian National Oil Company, wiping out\nthe hard drive of every system it touched. The damage was systematic and\ncomplete, destroying gigabytes of data at a time. First, the malware\neliminated documents and data files, then it went after system files, zapping\ncore parts of the hard drive to cause them to crash and burn.\n\nIt was unclear how many computers were affected, but there were rumors that\nthe destruction had begun on some computers as early as December. No one\nnoticed the trend initially, until it spread and became impossible to ignore.\nIt also was not clear how long the virus had lurked on machines before it\nturned destructive, but each time it did, the destruction began around the\ntwentieth day of the month. Iranian officials dubbed it “Wiper” and pointed to\nthe United States and Israel as the source. They insisted, however, that the\nattack caused no lasting damage, because all of the deleted data had been\nbacked up.\n\nWhen Raiu and the Kaspersky team got hold of a mirror image of one of the\nerased hard drives from Iran, it was filled with gibberish. Not only were all\nof the documents and critical system files gone, any sign of the Wiper malware\nwas erased from the disk too. But one important clue remained—a single\nreference inside the registry key to a temporary file named ~DF78.tmp that had\nbeen created on the system at some point before the destruction began. The\nfile itself was now gone, but its name lingered on, a ghost betraying its\nformer presence. The ~D prefix in its name was a familiar signifier to the\nresearchers by now. It was the same distinctive naming convention that Duqu\nhad used for the temporary files it created on infected machines, as well as\nthe naming convention that Stuxnet used for some of its files.\n\nHad Duqu, or some other program written by the same team, been on the machine\nbefore Wiper erased it?[1](part0019.html#c15-ftn1) Was Wiper a creation of the\nsame team behind Duqu?\n\nRaiu and his team programmed Kaspersky’s antivirus tools to search for the\n~DF78.tmp file—and for good measure, to flag any other temporary file that had\na name that began with ~D. They got a number of hits on machines in various\ncountries, but the majority of them showed up on machines in Iran. When they\nobtained a copy of one of the files—this one named ~DEB93D.tmp—they discovered\nit was a log for a “sniffer” component that recorded passwords as they flitted\nacross the infected machine’s local network. With a little digging, they also\nfound a module that appeared to be responsible for creating the sniffer\nlog.[2](part0019.html#c15-ftn2) It turned out to be one of their most\nsignificant finds.\n\nThe module didn’t resemble Stuxnet or Duqu and didn’t appear to be Wiper,\neither—it contained no code for erasing the hard drive of infected machines.\nThey searched their archive to see if anything resembling it had come through\ntheir automated reporting system in the past, and to their surprise, module\nafter module popped up, as if they’d just been sitting in the archive waiting\nto be discovered. They found twenty different files in all, each with odd\nnames like Euphoria, Munch, Limbo, Frog, and Snack. The files all appeared to\nbe plug-ins or components for a related attack.\n\nWhat intrigued them most, however, was that one of the files had come in\nthrough their system in October 2010 and was tagged by the system as a Stuxnet\nfile. At the time, this hadn’t made sense to them because when they had\nexamined the file, it didn’t look anything like Stuxnet. But now when they\nexamined it again they discovered what the two had in common—both files\ncontained a zero-day exploit that they and Symantec had overlooked when they\nexamined Stuxnet two years earlier.\n\nThe exploit had been embedded in a part of Stuxnet called Resource 207, which\nappeared only in the June 2009 version of the attack code, not the 2010\nversions—which explained why they had overlooked it before. Most of the\nStuxnet files Kaspersky and Symantec examined had come from the 2010 attacks.\nVery few samples of the 2009 variant had ever been found on infected machines.\n\nResource 207 contained the code that Stuxnet 2009 used to trick the Autorun\nfeature in Windows machines to spread itself via USB flash drives. But it also\ncontained this overlooked exploit that was now in the new attack code. The\nexploit gave the attackers escalated privileges on infected machines by\nexploiting a buffer-overflow vulnerability in the wallpaper feature of\nWindows. The vulnerability had been a zero day when the attackers created the\nexploit in February 2009, but by the time they released Stuxnet four months\nlater that June, Microsoft had patched the hole.[3](part0019.html#c15-ftn3)\nWhen it came time to release the next version of Stuxnet in March 2010, the\nattackers had eliminated this exploit, along with the Autorun code, and\nreplaced it with the .LNK exploit and two other privilege-escalation exploits\nthat were still zero days at the time.\n\nThe discovery of the wallpaper exploit meant that instead of four zero-day\nexploits—which was already an impressive record—Stuxnet had actually used five\nzero-day exploits during its lifetime. More important, though, the link\nbetween Stuxnet and this new attack provided further evidence that Stuxnet was\npart of a suite of malicious tools created by the same team.\n\nKASPERSKY’S ALEX GOSTEV and his team divvied up the twenty modules they had\nfound for this new attack and went to work reverse-engineering them to see how\nthey were connected. They worked day and night, fueled by caffeine and the\nexcitement of knowing they had just uncovered another tool in the Stuxnet\narsenal.\n\nAt the end of three weeks, they had a digital spy kit on their hands that was\nlarger than anything they had seen before. They dubbed it “Flame,” after the\nname of one of the main modules in the attack.[4](part0019.html#c15-ftn4)\n\nStuxnet had tipped the scales at 500 kilobytes when compressed, but Flame was\nat least 20 megabytes with all of its components combined, and consisted of\nmore than 650,000 lines of code. It also had astounding complexity to match\nits girth. They estimated it would have taken a team of half a dozen\nprogrammers at least three years to code it all, and it would take the entire\nKaspersky team years more to completely decipher it. Instead, they settled for\ndeciphering just enough of the code to understand it.\n\nThe Kaspersky team had seen a lot of digital spy tools over the years—many of\nthem believed to be nation-state tools from China—but this one rewrote the\nbook. If James Bond’s Q Branch had a digital armory, Flame would have been\npart of it. It came with a cornucopia of spy gadgetry aimed at collecting\nintelligence from victims in a multitude of ways. Among them was one module\nthat siphoned documents from infected machines, and another that recorded\nkeystrokes and captured screenshots every fifteen to sixty seconds. A third\nmodule surreptitiously engaged an infected computer’s internal microphone to\neavesdrop on conversations in its vicinity. A fourth module used the\ncomputer’s Bluetooth function to swipe data from any discoverable smartphones\nand other Bluetooth-enabled devices in the area.\n\nFlame appeared to be a multipurpose espionage tool created to meet every need,\ndepending on the mission. Not every victim got the full Flame treatment,\nthough. Each component was installed as needed. A 6 MB starter kit got loaded\nonto many infected machines first, which included a back door through which\nthe attackers could install new spy modules from their command server at\nwill.[5](part0019.html#c15-ftn5)\n\nThe infrastructure set up to support Flame was also massive and like nothing\nthe researchers had seen before. They found at least eighty domains operating\nas command servers in Germany, the Netherlands, Switzerland, and elsewhere\nthrough which the attackers controlled infected machines and collected\nsiphoned documents from them.[6](part0019.html#c15-ftn6) The attackers had\nlikely set up so many domains in order to manage different operations and\ngroups of victims separately.\n\nThey used various fake identities to register the domains—Ivan Blix, Paolo\nCalzaretta, Traian Lucescu—and purchased some of them with prepaid credit\ncards so they couldn’t be traced. The Kaspersky researchers got traffic for\nabout thirty of the domains redirected to a sinkhole that they controlled, and\nas soon as it was set up, infected machines in Iran and around the world began\ncalling in. Stolen files intended for the attackers also poured in, though the\nfiles were encrypted so the researchers weren’t able to see what the attackers\nwere stealing.\n\nAfter adding signatures for Flame to Kaspersky’s antivirus tools, infections\nshowed up on several hundred machines. Iran, no surprise, was at the top of\nthe list. At least 189 machines were infected there. But there were also 98\nvictims in the Palestinian Territories, and about 30 victims each in Sudan and\nSyria.\n\nWhile Kaspersky was still examining Flame’s modules, Bencsáth in Hungary\ncontacted Raiu with news of a suspicious file found in Iran that someone had\nsent him. They had become well acquainted with Bencsáth when they had worked\non Duqu, so it wasn’t unusual for him to contact them. The file he had\nreceived from Iran turned out to be one of the same modules Raiu and his team\nhad already been examining. Bencsáth also passed the file to Chien at\nSymantec, who began to examine the threat in parallel with Kaspersky. When the\nSymantec researchers added signatures to their antivirus engine to detect it,\nthey uncovered more victims in Austria, Hungary, Lebanon, Russia, the United\nArab Emirates, and Hong Kong.\n\nMore than 1,000 victims were eventually uncovered, many more than the 36\nvictims Duqu was known to have hit, although nowhere near the more than\n100,000 machines that Stuxnet had struck. But that’s because unlike Stuxnet,\nFlame couldn’t spread automatically. All of its spreading mechanisms worked\nonly when deployed and commanded by the attackers. So while the majority of\nStuxnet’s victims were collateral damage, everyone Flame hit was presumably an\nintended target. Raiu suspected the victims were infected in groups, based on\nwhatever mission the attackers were conducting at the time.\n\nThere was no discernable pattern to the pool of victims—Flame targeted\nindividuals, private companies, government agencies, and academic\ninstitutions. But it wasn’t difficult to see what types of files the attackers\nwere after, since the malware contained a list of file extensions it sought,\nincluding Microsoft Word documents, PowerPoint presentations, and Excel files.\nBut also high on the list were AutoCAD drawings, which had been targeted by\nDuqu as well. Flame, notably, was also looking to steal digital certificates.\n\nAlthough Flame had a long list of files it was seeking, it didn’t steal every\nfile it found. Instead, it extracted 1 KB of text from each and transmitted it\nback to one of the command servers. From there it was likely passed to another\nlocation, where Raiu suspected the attackers had a supercomputer set up to\nsift through all the text samples that came in and determine which files the\nattackers wanted to grab in full. Notably, a year later when the NSA documents\nleaked by Edward Snowden were published, they described a system codenamed\nTURBINE that was designed to do something very similar to this. (See [this\npage](part0016.html#page218).)\n\nWith such an elaborate operation set up for Flame, it was no surprise that the\nattack had been around for a while. The earliest infection uncovered, on a\nmachine in Europe, occurred in December 2007.[7](part0019.html#c15-ftn7) A\nmachine in Dubai was struck in April 2008. Some of the domains the attackers\nused for their command servers were also registered around this time. A\nhandful of others were registered in 2009 and 2010, but the majority were\nregistered in 2011, after Stuxnet was exposed. All of this meant that Flame\nhad been active in the wild infecting systems for at least five years before\nit was discovered and was active during the same time that Stuxnet and Duqu\nwere being developed and unleashed.\n\nA clear picture was beginning to emerge of a digital arsenal filled with spy\ntools and weapons created to attack not just Iran’s nuclear program but other\ntargets as well. Two separate platforms had been used to create the malicious\ncode discovered so far. One was the Flame platform, upon which the massive\nFlame spy tool had been built. The other was the Tilde-d platform, upon which\nDuqu had been built. The Flame platform was much more dense and complex than\nthe Tilde-d platform, and had therefore probably been created in parallel by a\ndifferent team. Both platforms, however, were used to develop Stuxnet at\nvarious stages.\n\nRaiu surmised that the development of Flame likely began in 2005 or 2006, due\nto the fact that some of the custom code the attackers wrote for their command\nservers had been developed in December 2006.[8](part0019.html#c15-ftn8)\nDevelopment of the spy tool likely reached maturity in early 2007. The\nearliest known dates for Duqu were August 2007, when one of Duqu’s droppers\nwas compiled, and November 2008, when Duqu’s infostealer showed the first\nsigns of being in the wild.\n\nRaiu believed that when it came time to build Stuxnet, the attackers used\nFlame to jumpstart the digital weapon, then later switched to the Duqu\nplatform for subsequent versions of the attack. He based this in part on the\nfact that Resource 207 found in the 2009 version of Stuxnet—which contained\nthe Autorun code and the wallpaper exploit—looked a lot like an early version\nof Flame’s main module. Flame would have already existed as a basic espionage\ntool by 2007, and when it came time to write the missile portion of Stuxnet in\n2009, it appeared that the team behind Flame shared source code for Resource\n207 with the Stuxnet crew, essentially kick-starting the creation of the\nmissile code. The payload was already created by then, and the attackers just\nneeded something to deliver it. “Probably there was some kind of urgency to\nget [Stuxnet] out the door, so that’s why they took this already mature plug-\nin from Flame and used it in Stuxnet,” Raiu says.\n\nAfter this, however, Stuxnet and Flame diverged. The programmers behind Flame\ncontinued to build their platform into a massive espionage tool, and in 2010\nwhen the attackers behind Stuxnet prepared the next version of their code for\na subsequent assault, they switched to the Tilde-d platform—which had already\nbeen used to create Duqu—to recraft the missile for launching their attack.\nThe switch to the Duqu platform likely occurred because the missile portion of\nthe variant Stuxnet 2010, with all of its zero-day exploits and additional\nspreading mechanisms, was much more complicated and required more code. And\nthe Tilde-d platform was a much simpler and more compact tool to use.\n\nThe sequence of events determined by Raiu and his team seemed to match the\nscenario depicted by _New York Times_ reporter David Sanger, who reported in\nhis book _Confront and Conceal_ , citing current and former government\nofficials, that the earliest version of Stuxnet was developed by the United\nStates, while later versions were developed by the United States and Israel.\nRaiu believed that Flame and the Flame platform were created by the United\nStates, while Israel created Duqu and the Tilde-d platform. Both then used\ntheir respective platforms to build their portions of Stuxnet.\n\nWhatever Flame’s role in Stuxnet, the whole spy operation around it came\ncrashing down on May 28, 2012, when Kaspersky and Symantec went public with\nnews of its discovery in near-simultaneous\nannouncements.[9](part0019.html#c15-ftn9) Once news of the spy tool was out,\nthe response of Flame’s operators was swift. Within an hour of the first news\nstories being published, command servers used for the spy tool went dark as\nthe attackers shuttered their operation, thus ending a massively successful\nfive-year espionage campaign in a matter of minutes. It was almost as if they\nhad been waiting for the news to break.\n\nFlame’s reign was now over, but its effects would live on. Days after the\nservers went dark, Microsoft announced that it had found an even more\ndisturbing discovery about the Flame attack that the Kaspersky and Symantec\nresearchers had missed.\n\nIT WAS THE Memorial Day holiday in the United States when news of Flame broke,\nand not many people at Microsoft headquarters in Redmond, Washington, were\nworking. But when engineers in the company’s Security Response Center learned\nthat a new attack campaign, attributed to the same team behind Stuxnet and\nDuqu, had been uncovered, they immediately grabbed samples of the Flame files\nmade available by researchers. They wanted to see if the new attack used any\nzero-day vulnerabilities in Windows, as Stuxnet and Duqu had done. But as they\nexamined one of the files they received, they realized they were looking at\nsomething much worse than a zero day—Flame was performing a sophisticated\nattack against part of Microsoft’s Windows Update system to spread itself\nbetween machines on a local network.\n\nWindows Update is the automated system Microsoft uses to distribute software\nupdates and security patches to millions of customers. To obtain the updates,\na client-side tool sits on each customer machine and contacts the Microsoft\nservers to download patches whenever they’re available.\n\nFor years, the security community had warned of the security nightmare that\nwould occur if hackers ever hijacked the Windows Update system to deliver\nmalicious code, threatening the security of millions of Windows customers.\nThis attack didn’t rise to that level exactly, but it was just as dangerous.\nInstead of subverting the actual Microsoft servers that delivered Windows\nsoftware updates to millions of customers, it subverted the Windows Update\ntool that sat on customer machines. The distinction was subtle but important.\nIf the attackers had subverted Microsoft’s servers, they could have\ncompromised machines on a global scale. But the way they performed the attack\nmeant they could compromise machines only on specific networks that they\ntargeted, leaving anyone else unaffected.\n\nLike the Windows software, the update tool itself gets periodically updated by\nMicrosoft. Each time the tool launches on a customer’s machine, it sends out a\nkind of beacon to Microsoft servers to see if a new version of itself is\navailable. Microsoft distributes the updates through a series of so-called\n.CAB files, signed with a Microsoft certificate to verify their legitimacy.\n\nThe attackers subverted this process by first infecting one machine on a\nvictim’s network with Flame. Then when the update client on any other machine\non that victim’s network sent out a beacon to Microsoft servers to check for\nupdates to the Windows Update tool, the infected machine intercepted the\nbeacon and sent a malicious Flame file, masquerading as a legitimate Microsoft\n.CAB file, to the new machine instead, thus infecting it with the spy tool.\nThis wasn’t the most sophisticated part of the attack, however. To pull off\nthe hijack, the attackers had signed their malicious .CAB file with a\nlegitimate Microsoft certificate—except in this case the certificate indicated\nthat the company it belonged to was “MS,” not Microsoft Corporation, as it\nshould have said. When Microsoft’s research team saw this, they immediately\nsuspected something was wrong. The certificate appeared to have been issued\nand signed by Microsoft’s Terminal Services Licensing Certificate Authority in\nFebruary 2010, but it was clearly a rogue certificate, which the CA should not\nhave generated and signed. Had Microsoft’s server been compromised or its\ncert-signing key stolen? The engineers had to quickly figure out how the\nattackers obtained the cert before anyone else could repeat the feat. They put\nout a call for any colleagues available to work on the holiday and quickly\nassembled a team.\n\nIt turned out the attackers had pulled this off using something called an MD5\nhash collision. An MD5 hash is a cryptographic representation of data—in this\ncase the data on the certificate—generated by a cryptographic algorithm known\nas MD5. Hashes are supposed to function like a fingerprint, so that every data\nset run through the algorithm produced a unique hash. If the data changed, the\nalgorithm would produce a different hash. The MD5 algorithm, however, had been\nfound years earlier to have a weakness that would allow someone to create the\nsame hash from different data sets.[10](part0019.html#c15-ftn10) This was\ncalled a hash collision. Many companies had stopped using the MD5 algorithm\nfor this reason. But Microsoft hadn’t changed the algorithm used for its\nTerminal Services (TS) Licensing service since 1999, when the system was\narchitected.\n\nTS Licensing is a system used by Microsoft corporate customers when setting up\na server with Microsoft software running on it so that multiple employees or\nmachines can use the software. The customer purchases licenses from\nMicrosoft—say 100 licenses for 100 employees or machines—then submits a\nrequest for a certificate to Microsoft’s Terminal Services Licensing\nCertificate Authority. Microsoft’s CA generates a certificate with the\ncustomer’s name on it, as well as a timestamp indicating when the certificate\nwas issued and a serial number for the digital document.\n\nWhen Microsoft issues the certificate, it runs all of the data on the\ncertificate, including the timestamp and serial number, through the MD5\nalgorithm to create a hash, then signs the hash and sends the cert to the\ncustomer. The customer then uses the signed certificate to ensure that only\nauthorized machines or people issued the certificate use the software licensed\nfrom Microsoft. But in this case, the attackers used the hash from Microsoft\nto sign their rogue certificate and then to sign their malicious .CAB files.\n\nBefore the attackers submitted their certificate request to Microsoft, they\ncreated a rogue certificate that contained information that they anticipated\nthe real Microsoft certificate would contain, as well as some minor\nalterations—alterations that they had to be sure would produce a hash that was\nidentical to the one Microsoft would issue. This was no easy task. Among other\nchallenges, it required running thousands and thousands of different\nvariations of the data on their rogue certificate through the MD5 algorithm to\nget one that produced an identical bit-for-bit hash as the legitimate\nMicrosoft certificate that contained different data, a feat that required a\nlot of computational power. It also required anticipating the serial number\nthat Microsoft would give the certificate and the exact time when Microsoft’s\nlicensing server would sign the legitimate certificate, since the timestamp\nand serial number were part of the hash that Microsoft generates and\nsigns.[11](part0019.html#c15-ftn11) If they estimated the wrong time by even a\nmillisecond, the signed hash would not be transferable to their rogue\ncertificate, since the two hashes would no longer\nmatch.[12](part0019.html#c15-ftn12) The attackers would have needed to\nresearch the Microsoft system extensively and test multiple\ncertificates—possibly hundreds—before they got the timing and serial number\nright.[13](part0019.html#c15-ftn13)\n\nThe attackers then used the signed hash with their rogue certificate to sign\ntheir malicious .CAB files. It appeared to be a legitimate certificate, since\nit had the signed hash generated by Microsoft.\n\nThe Windows Update hijack was a brilliant feat that pushed the boundaries of\nmathematics and could only have been achieved by world-class\ncryptographers.[14](part0019.html#c15-ftn14) When the Kaspersky researchers\nlearned of it, they dubbed it the “God-mode exploit,” since it was so\ntechnically astute and so much more potent than spreading malware via a zero-\nday exploit.[15](part0019.html#c15-ftn15) The only thing that would have made\nit more powerful and dangerous was if the attackers had actually subverted the\nWindows Update patch servers themselves.\n\nMicrosoft’s engineers initially estimated it would take just twelve days for\nother well-resourced attackers to learn everything they needed to know about\nMicrosoft’s certificate and update system to pull off a copycat attack to\nspread their own malware. But when they did a test run, walking through all\nthe steps someone would need to take to copy the Windows Update hijack, and\ntimed themselves while doing it, they realized that someone could actually\npull off a less-sophisticated version of the attack—one that didn’t require an\nMD5 hash collision—in just three days.[16](part0019.html#c15-ftn16)\n\nWorking against the clock, Microsoft rushed out an emergency out-of-band patch\nto fix the vulnerabilities that allowed the attack to occur. The company had\nreleased only one out-of-band patch in all of 2011, the previous year, and\nreserved such releases for only the most significant vulnerabilities, so it\nwas an indication of just how seriously Microsoft viewed the Flame exploit\nthat it took this step.\n\nThe attackers behind Duqu and Stuxnet had already struck at the underpinnings\nof the validation system that made the internet possible—first by stealing\nindividual security certificates from the companies in Taiwan to sign the\nStuxnet drivers, then by sending Duqu to steal data from a certificate\nauthority itself. But this exploit went even further than that by subverting\nthe trust between the world’s biggest software maker and its customers.\nAssuming that the perpetrators behind it were American, they likely justified\nthe operation and even got legal approval for it by arguing that they weren’t\nsubverting the Microsoft Windows servers themselves—thereby putting all of\nMicrosoft’s customers at risk—but simply subverting the Windows client on\nindividual customer machines. In this way, they could focus the attack on\nvictims and machines that weren’t in the States.[17](part0019.html#c15-ftn17)\n\nBut ultimately it mattered little that they hadn’t subverted Microsoft’s\nservers. Subverting the update client tool was enough to create customer\nmistrust in the integrity of the update service itself—which could lead users\nto disable the tool and prevent them from receiving the security updates that\nwere critical for the safety of their systems.\n\nWho _was_ responsible for threatening this trust between Microsoft and its\ncustomers? About three weeks after the news of Flame broke, former US\ngovernment officials claimed ownership, telling the _Washington Post_ that\nFlame had been a joint operation between the NSA, the CIA, and Israel’s\nmilitary.[18](part0019.html#c15-ftn18)\n\nThe unnamed sources said Flame had been developed sometime around\n2007—confirming the general timeframe Raiu and his team had established for\nit—to collect intelligence about Iranian officials and to map computer systems\nthat were part of Iran’s nuclear program. But the officials also suggested\nthat Flame had been an early-generation tool that had since been surpassed by\nothers.\n\n“This is about preparing the battlefield for another type of covert action,” a\nformer US intelligence official told the paper, adding that cyber collection\nagainst the Iranian program was “way further down the road than this.” He may\nhave been referring to things like the implants the NSA uses that can transmit\nstolen data via radio waves from infected machines. (See [this\npage](part0020.html#page314).)\n\nNotably, the _Post_ ’s sources also cleared up a mystery about the Wiper\nattack that had struck Iran earlier that year. They told the paper that the\nattack, which had erased hard drives on machines at Iran’s oil ministry and\nhad led to the discovery of Flame, was also a nation-state construct. But\nunlike Flame and Stuxnet, which had been joint operations of Israel and the\nUnited States, Wiper, one source said, had been launched against Iran by\nIsrael alone. An official told the _Post_ , in fact, that the United States\nhad been caught off guard by the destructive attack.\n\nTHE REVELATIONS ABOUT nation-state attacks were coming at a rapid pace now,\nwith one operation after another being exposed, after years of remaining\nstealth. And the revelations weren’t done yet. The Kaspersky researchers would\nsoon find evidence that still _more_ malicious tools created by the same teams\nwere lurking in the wild.\n\nThe key break came for them when they obtained access to some of the command\nservers used by Flame. They discovered that ten days before the news of Flame\nbroke, the attackers had launched a massive cleanup campaign to cover their\ntracks and erase any trace of their activity from the servers, suggesting\nfurther that, indeed, the attackers had had advance notice that their\noperation was about to be exposed.[19](part0019.html#c15-ftn19) But they had\nmade one big mistake that left a server in Malaysia with its data largely\nintact. Several weeks before the cleanup operation, the attackers had\ncarelessly changed the settings on the server and inadvertently locked\nthemselves out. As a result, they weren’t able to get back in to wipe it\nclean, leaving a wealth of forensic data for Kaspersky to\nfind.[20](part0019.html#c15-ftn20)\n\nLeft intact was the control panel the attackers had used to deliver the Flame\nmodules to infected machines and to process stolen data retrieved from them.\nThe control panel was designed to resemble a publishing platform for a\nbusiness called NewsforYou, so that if any outsiders got access to the server,\nthey’d think it belonged to a newspaper or media company. Malicious modules\nthe attackers planned to install on victim machines were stored in directories\nthe attackers named “News” and “Ads,” while a directory called “Entries”\nstored the data and files that were swiped from victim machines.\n\nThe Kaspersky researchers also found logs listing the IP address of every\ninfected machine that had contacted the server. The server had only recently\nbeen set up, on March 25, but during a ten-day span of its operation, at least\n5,377 infected machines in dozens of countries had contacted it. About 3,702\nof these were in Iran, and another 1,280 in Sudan. Other countries had fewer\nthan 100 infections.\n\nRaiu and his team realized that if just one command server, out of more than\neighty the attackers had registered, communicated with 5,000 infected machines\nin just ten days, and the malware had been in the wild since 2007 or 2008, the\ntotal number of victims had to be tens of thousands more than they originally\ncalculated. They also found a file on the Malaysian server that was stuffed\nwith 5.7 GB of data stolen from victim machines during the same ten-day\nperiod. If the attackers had purloined this much data in just ten days, Raiu\nsuspected their total booty must have amounted to terabytes of data over the\nfive-plus years that Flame had operated.[21](part0019.html#c15-ftn21)\n\nBut these revelations paled in comparison to another piece of evidence the\nFlame engineers left behind, which showed that the Malaysian server was\nconfigured to communicate with not just one piece of malware, but _four._ They\nwere identified by the attackers as SP, SPE, FL, and IP, and had been created\nin that order, with SP being the oldest. Each of them was designed to\ncommunicate with the command server using a different custom protocol the\nattackers had written.[22](part0019.html#c15-ftn22)\n\nFL referred to Flame, but the other three attack codes were a mystery. The\nKaspersky researchers knew for certain that SPE existed, because they had seen\nevidence of it in the wild. When they had created their sinkhole to intercept\ndata headed for the Flame servers, about ninety machines in Lebanon, Iran, and\nFrance infected with the SPE code had contacted their sinkhole thousands of\ntimes attempting to communicate with it using that code’s specific protocol.\nThe other two malicious programs had yet to turn up, though. They hadn’t been\nable to obtain a copy of SPE, so they still didn’t know what it did.\n\nBut all of this confirmed that as shocking as the revelations about Stuxnet,\nDuqu, and Flame were, they likely were just the shallow tip of a stockpile of\ntools and weapons the United States and Israel had built.\n\nIndeed, a couple of weeks after the news of Flame broke, Kaspersky stumbled\nupon yet another nation-state spy tool that had evaded detection for years.\n\nEvery time Raiu’s team discovered new files or a little more information about\nStuxnet, Flame, or Duqu, they would refine the signatures in their antivirus\nproducts and tweak the search terms they used to dig through their archive to\nsee if they could find other variants of the same files. During one search of\ntheir archive, they found a suspicious file that had come in through their\nautomated reporting system from a customer machine in the Middle East. The\nfile had been flagged by the system as a Flame module and communicated with\nthe same command-and-control servers as Flame. But it clearly wasn’t Flame or\nany of the other three mysterious programs—SP, SPE, or IP.\n\nThey added signatures for the file to their antivirus engine and found about\n2,500 victims infected with it in twenty-five countries. More than 1,600 of\nthe victims were in Lebanon. The next highest number, 482, were in Israel, and\nanother 261 were in the Palestinian Territories. About 40 victims were in the\nUnited States, and only 1 was in Iran.\n\nAs they reverse-engineered the code and began to analyze it, they saw that it\ncontained some of the same libraries, algorithms, and base code that Flame\ncontained, which explained why their system had flagged it as such. The coders\nhad even left path and project data in some of the files, which showed that\nthe files had been stored on the attackers’ machines in a directory they had\ncalled Flamer.[23](part0019.html#c15-ftn23)\n\nThe Kaspersky researchers dubbed this new attack “Gauss,” after the name the\nattackers had given one of its main modules. The name appeared to pay tribute\nto noted mathematician Johann Carl Friedrich Gauss—since other modules were\nnamed Lagrange and Gödel, apparently after mathematician Joseph-Louis Lagrange\nand cryptographer Kurt Gödel. The reverence for math and cryptography became\nclear when the researchers discovered that the attack had a payload that used\na highly complex and sophisticated encryption scheme worthy of a master\ncryptographer.\n\nLike Flame, this new mystery malware was an espionage tool, but it was much\nsmaller than Flame and was clearly part of a separate spy operation. The\nmalware contained a handful of modules for stealing system passwords,\nrecording configuration data, and swiping login credentials for social\nnetworking, e-mail, and instant-messaging accounts. There was also a module\nfor infecting USB flash drives with the same .LNK exploit Stuxnet had used.\n\nBut there was something else the new attack had that the researchers had never\nseen in a nation-state tool before—a Trojan program for stealing login\ncredentials to bank accounts. This wasn’t a run-of-the-mill banking Trojan,\nthough. Rather, it focused on customers of banks in Lebanon—the Bank of\nBeirut, EBLF, BlomBank, ByblosBank, FransaBank, and Credit Libanais. There was\nno sign the Trojan was being used to steal money from the accounts, but some\nof Lebanon’s banks were suspected of being used to launder funds for Iran’s\nnuclear program and for the Iranian-backed Hezbollah, so the attackers may\nhave been monitoring balances and transactions to map relationships between\naccounts and trace the movement of money.\n\nThere were two mysteries with the code that the researchers couldn’t\nresolve—one involved a custom font file the attackers called Palida Narrow\nthat Gauss installed on infected machines. Like Duqu’s Dexter Regular, Palida\nNarrow was a fabricated font name. But unlike Duqu, the Palida Narrow file\ncontained no exploit or malicious code. In fact, it appeared to have no\nfunctionality at all so the researchers were clueless as to why the attackers\ninstalled it.[24](part0019.html#c15-ftn24)\n\nBut a bigger mystery lay in an encrypted payload that Gauss deposited onto\nsome machines, which was locked in an impenetrable shell.\n\nUnlike Stuxnet, which delivered its payload to every machine it infected but\nexecuted the payload only on machines with a specific configuration, Gauss\nonly delivered its payload to machines that had a specific configuration. It\nseemed the attackers had learned from mistakes made with Stuxnet. By limiting\nthe number of machines to which they spread the Gauss payload, they greatly\nreduced the chance that it would be discovered.\n\nGauss delivered its warhead in a very restricted manner via USB flash drives.\nIt would infect only one USB flash drive inserted into an infected machine and\nno more. When that flash drive then got inserted into another machine, it\npassed the payload to the machine only if the machine had the specific\nconfiguration Gauss was seeking. It also collected the configuration data from\nany machine it entered and stored it on the USB flash drive in a hidden file.\nIf the flash drive was inserted into any other machine that was infected with\nGauss and that was also connected to the internet, Gauss transmitted the\nhidden file back to the attackers’ command server. In this way, the attackers\nwould know when Gauss had reached its target.\n\nGauss also took another precaution with its payload. Unlike Stuxnet, the keys\nfor unlocking this mysterious payload were not stored in the malware. Instead,\nthe warhead could only be decrypted with a key that was dynamically generated\nfrom the configuration data on the machine it was targeting.\n\nBut to generate the key, the malware went through a series of elaborate\ncontortions to ensure that it wouldn’t unload on the wrong machine and that no\none would be able to unlock it using brute force. First it collected very\nspecific configuration data from the targeted machine—information about\ndirectories, program files, and other resident data—then combined the names of\neach file, one by one, with the name of the top directory in the Windows\nProgram Files folder on the machine. To this string of data it added a special\nvalue, then ran it through the MD5 hash algorithm 10,000 times, rehashing the\nresulting hash to produce a new hash each time.[25](part0019.html#c15-ftn25)\nIf, at the end, it generated the correct hash it was seeking, the malware\nproceeded to the next step.\n\nEven when Gauss arrived at the hash it was seeking, it didn’t immediately\nunlock the payload. Instead, it recalculated the 10,000th hash using a\ndifferent added value. The hash from _this_ operation then became the key that\nunlocked the warhead. Once the payload was unlocked, Gauss used the same path\nand program data that produced the very first hash, added yet a new value to\nit, then decrypted a second section in the attack code, before repeating the\nsame steps to decrypt yet a third section.\n\nIf you were trying to run an exceptionally careful and controlled operation,\nthis was the way to do it. Stuxnet’s payload had hardly been secured at all by\ncomparison, allowing researchers to easily unlock it and determine what it was\ndoing. But the complex encryption scheme used for Gauss’s payload ensured that\nthe warhead remained locked in an impenetrable vault that no one could break.\n\nIndeed, although the Kaspersky researchers tried millions of data pairings to\nuncover the configuration that unlocked Gauss’s payload, they were unable to\nproduce a key that could crack it. They had to wonder what was so special\nabout Gauss’s payload that the attackers had gone to so much trouble to secure\nit. They couldn’t rule out the possibility that it was something destructive\nlike Stuxnet or Wiper or that it was extra-sensitive because it had something\nto do with Gauss’s banking Trojan and financial networks.\n\nGauss’s locked payload prevented the researchers from fully deciphering the\nattack, but in the course of analyzing this threat, they stumbled upon another\nfind that had eluded them until then: a sample of the mysterious SPE malware.\n\nSPE was one of the four programs that communicated with Flame’s command\nservers and that had contacted their Flame sinkhole months earlier. They\ndiscovered that it was actually a standalone module, instead of another attack\nentirely, that could be used either on its own or in conjunction with Flame or\nGauss to expand the spying powers of either of these\ntools.[26](part0019.html#c15-ftn26) The module, which Kaspersky dubbed “mini-\nFlame,” was the first direct link they found that connected Gauss and Flame.\nPreviously they had believed the two attacks were entirely separate operations\nrun by the same attackers, but mini-Flame proved otherwise. Kaspersky even\nfound one machine in Lebanon that was infected with all three programs—Flame,\nGauss, and mini-Flame.[27](part0019.html#c15-ftn27)\n\nThis junior Flame opened a back door onto infected computers and also operated\nas an infostealer, allowing the attackers to remotely examine the\nconfiguration of machines and map any other systems connected to them. The\nattackers likely first infected a system with Flame or Gauss to collect basic\nintelligence about it and determine if it was a high-value target, then\ninstalled mini-Flame only on key machines belonging to high-profile victims\nwhen they needed to directly control the machine, swipe specific data from it,\nor further explore the victim’s local network. Once mini-Flame was installed,\nthe attackers likely sent out a module from their command servers to delete\nthe larger Flame spy kit from the machine and thereby reduce their footprint.\n\nKaspersky found only about fifty victims infected with mini-Flame, located\nprimarily in Iran and other parts of the Middle East, but also in Lithuania\nand the United States. Among the victims, they found six different variants of\nthe module, all created between October 2010 and September 2011. But the\ndevelopment of the first mini-Flame module likely occurred in 2007, when\nStuxnet, Duqu, and the larger Flame were created, since this is when the\nprotocol that mini-Flame used to communicate with command servers was created.\nOddly, though mini-Flame communicated with Kaspersky’s sinkhole some 14,000\ntimes over a four-month period in the summer of 2012, it completely halted\ncommunication with the sinkhole between July 4–7 of that year—a gap that\nKaspersky could never explain.\n\nWITH THE DISCOVERY of this last module, Kaspersky’s work on code created by\nthe Stuxnet gang began to wind down—in part because the detailed work that\nRaiu and his team had done to expose all of these covert nation-state tools\nwas starting to bring the researchers unwanted attention.\n\nAs they released one finding after another, there were some in the security\ncommunity who began to question their motives. Just as Symantec had been\ncriticized for disloyalty to the United States in exposing Stuxnet and harming\nUS national security interests, some wondered if the Moscow-based Kaspersky\nLab was doing the bidding of Russian intelligence by exposing and sabotaging\nWestern spy operations.\n\nRaiu says, however, that they were never influenced or guided in their work by\nany government or intelligence agencies. He and his team considered their work\nabove and beyond politics, and their only aim, like those of the Symantec\nresearchers, was to exercise their reverse-engineering skills in the service\nof defending customers and contributing to the security of the computing\ncommunity. In fact, their work exposing the Stuxnet and Flame gangs actually\n_conflicted_ with their company’s own business interests. Kaspersky Lab was in\nthe midst of a major push to expand into the US market, and founder Eugene\nKaspersky had been making a concerted effort to cultivate friends in\nWashington and Israel to this end. It was no help, then, that while he was\ncourting these two governments, his researchers were busy exposing their\ncovert operations.\n\nBut it wasn’t just the company’s business interests that were at risk of being\naffected by their work. The Symantec researchers had been worried during their\nanalysis of Stuxnet that their work might be secretly monitored by Israel and\nthe United States, or even by Iran, though they never saw any concrete signs\nthat this actually occurred. Raiu, however, became certain that he was being\nfollowed while in Munich for a conference in the spring of 2012. It was\nshortly after they had discovered Flame, but before they’d gone public with\nthe news. Raiu noticed someone lurking at the front desk of his Munich hotel\nwhen he checked in, as if trying to discover his room number. Later he noticed\nothers tailing him when he went to the restroom or his hotel room. When he\nmentioned his concern to colleagues, they noticed it too. He suspected the\npeople shadowing him were from a foreign intelligence agency, but he couldn’t\nbe sure. Then he was approached by three Israelis who wanted to speak with him\nabout his work on Duqu, and by a woman who wanted to know if Kaspersky had the\nability to recover wiped files from a hard drive. The latter question was a\nbit unsettling, since Kaspersky was in the midst of trying to recover files\nfrom systems in Iran that had been trashed with the Wiper malware.\n\nIt was yet another stark reality check that the world of virus hunting had\nchanged dramatically with Stuxnet. Previously the only risk researchers faced\nfrom exposing digital threats was the wrath of cybercriminals who might take\nissue with them for interfering with their livelihood. But the dismantling of\nnation-state threats introduced a whole new world of concerns, and Raiu\ndecided, for the sake of his young family, that he should lower his profile.\nAfter the incidents occurred at the Munich conference, he withdrew from\nspeaking publicly about Kaspersky Lab’s nation-state work and left it to\ncolleagues to handle the media duties thereafter.\n\nIt was no coincidence then, when, not long after this, the Kaspersky\nresearchers turned their attention away from the Stuxnet-Duqu-Flame family of\nthreats to focus on other projects—in particular one believed to be the work\nof Russian actors. The operation, dubbed “Red October,” targeted diplomats,\ngovernments, and research institutes, primarily in eastern Europe and central\nAsia, with the principal aim of collecting confidential documents and\ngeopolitical intelligence. Raiu and his colleagues suspected it was the work\nnot of nation-state actors but of Russian cybercriminals or freelance spies\nwho were seeking the intelligence to sell it.\n\nWith the Red October operation, the Kaspersky team seemed to put the Stuxnet\ngang behind them for good. But this didn’t mean that everyone had heard the\nlast from Stuxnet. It turned out that the digital weapon still had one more\nsurprise waiting to be revealed.\n\nIT WAS NOVEMBER 2012, more than two years after Stuxnet had been discovered,\nwhen even Duqu and Flame were becoming distant memories, that the Symantec\nresearchers stumbled upon a missing link that they had long given up hope they\nwould ever find—an early version of Stuxnet that preceded all other known\nvariants.\n\nThey found it while scouring their archive for any malicious files that had\nfingerprints matching Stuxnet’s—something they periodically did with malware\nsignatures to make sure they hadn’t missed anything important. In doing this,\na component popped up that they hadn’t seen before. It had been sitting in\ntheir archive since November 15, 2007, when someone had submitted it to\nVirusTotal, which meant the first Stuxnet attack had been unleashed much\nearlier than previously believed.[28](part0019.html#c15-ftn28) As noted\npreviously, they had always suspected other versions of Stuxnet existed, due\nto gaps in the version numbers of the 2009 and 2010 variants—1.001, 1.100, and\n1.101. They had even suspected there might be an early version of Stuxnet that\nhad preceded all other known ones. Now they had found it—Stuxnet version 0.5.\n\nAs they uncovered more files associated with the component, however, they\ndiscovered that this wasn’t just any version of Stuxnet. It was one that\ncontained the complete 417 attack code, fully intact and enabled.\n\nTheir previous attempt to unravel Stuxnet’s attack against the Siemens S7-417\nPLC had failed because the code was incomplete and disabled in later versions\nof Stuxnet. Symantec’s Nicolas Falliere had thought perhaps the attackers had\ndisabled it because they were waiting for a critical bit of configuration data\nto complete their attack. But now it was clear they had disabled it because\nthey had decided to change their tactics. Although the later versions\ncontained both the 315 and the disabled 417 attack codes, this early variant\nhad no sign of the 315 attack code in it, just the code that attacked the\nSiemens 417 PLC. It was clear from this that the attackers had first focused\ntheir assault on 417 PLCs at Natanz and then for whatever reason—the attack\nhadn’t achieved their aim or was taking too long to achieve it—had\nrecalibrated and turned their sights on the 315 PLCs instead.\n\nNow that the Symantec team—minus Falliere, who had left Symantec for a job at\nGoogle—had their hands on this early variant, they were finally able to\ndetermine what the 417 PLCs were controlling and what Stuxnet was doing to\nthem. It turned out this version was targeting the valves that managed the\nflow of uranium hexafluoride gas into and out of the centrifuges and cascades\nat Natanz.[29](part0019.html#c15-ftn29) Stuxnet was opening and closing the\nvalves to increase the pressure inside the centrifuges to five times its\nnormal level. At that pressure, the gas would likely begin to solidify,\nruining the enrichment process, and causing the centrifuges, spinning at high\nspeed, to careen dangerously off balance and crash into other centrifuges\naround them. Or at least this was likely the plan. It may not have worked as\nwell or as quickly as the attackers had hoped, so in 2009 they changed tactics\nand focused on attacking the frequency converters instead—a more direct method\nof damaging the centrifuges.\n\nAlthough Stuxnet 0.5 had no kill date and should have still been active when\nlater versions of Stuxnet were released, researchers never found this version\non any machines when Stuxnet was discovered in\n2010.[30](part0019.html#c15-ftn30) This may have been because it got erased.\nOne of the first things later versions of Stuxnet did when they landed on a\nmachine was check for earlier versions of Stuxnet on the machine and replace\nthem. So it was likely that Stuxnet 0.5 got automatically replaced on infected\nmachines when the June 2009 version was launched.[31](part0019.html#c15-ftn31)\n\nIt’s also possible that samples of Stuxnet 0.5 were never found because this\nversion was much more tightly controlled than later ones and only infected a\nlimited number of machines. Instead of using zero-day exploits to spread, it\nspread in just one way—by infecting Siemens Step 7 project files. These were\nthe files that programmers shared among themselves that were used to program\nthe Siemens S7 line of PLCs, making them ideal for getting Stuxnet onto the\ntargeted PLCs. The fact that this version only spread via Step 7 files\nsuggested the attackers had an inside track to get it onto core systems at\nNatanz. Stuxnet 0.5 was therefore likely never caught because patient zero—the\nfirst machine it infected—may have been one of the very programming machines\nthe attackers were targeting. With later versions of the malware, they may\nhave lost this access, which forced them to bulk up Stuxnet with extra\nspreading power to increase the odds of reaching their\ntarget.[32](part0019.html#c15-ftn32) Unfortunately, this spreading power in\nlater versions, and the location of patient zero in an office outside of\nNatanz, were the factors that got Stuxnet caught.[33](part0019.html#c15-ftn33)\n\nStuxnet 0.5 was completely autonomous once unleashed, so the attackers had no\nneed to control it. But if it found itself on a machine that was connected to\nthe internet, it still contacted one of four command servers, from which the\nattackers could send new code to update the digital weapon if\nneeded.[34](part0019.html#c15-ftn34) Stuxnet was programmed to stop\ncommunicating with the servers on January 11, 2009, but by then the attackers\nwere already preparing the next version of their assault—a driver they\ncompiled January 1, 2009, for use with the next version of Stuxnet, which they\nunleashed five months later.\n\nThe submission of Stuxnet 0.5 to VirusTotal in 2007, along with other dates\nassociated with the code, forced the researchers to revise their estimate of\nwhen work on Stuxnet began.[35](part0019.html#c15-ftn35) It appeared that\npreliminary work on the attack had begun as early as November 2005. This is\nwhen some of the domains for the command-and-control servers used with Stuxnet\n0.5 were registered. Code for other command servers later used in the 2009 and\n2010 Stuxnet attacks—the todaysfutbol.com and mypremierfutbol.com domains—was\ncompiled in May 2006. Though Stuxnet itself wasn’t unleashed in 2006—Bush’s\nadvisers proposed it to him only that year—the command infrastructure for\ncontrolling it was already being set up during this time. It’s possible the\ncommand servers were initially set up to communicate with Flame, Duqu, or\nanother spy tool the attackers used to collect intelligence for the operation,\nthen were used again for Stuxnet. These early dates certainly coincided with\nwhen the Kaspersky researchers believed work on Flame began.\n\nThe dates also coincided with the period when the political situation over\nIran’s nuclear program was reaching a breaking point: In August 2005, two\nmonths after Ahmadinejad was elected president, international talks over\nIran’s nuclear program collapsed, and Iran announced it was withdrawing from\nthe suspension agreement. Three months later, the attackers registered the\ncommand-and-control servers for Stuxnet 0.5.\n\nIran did have centrifuges installed at Natanz during this time, but only in\nthe pilot plant. In February 2006, three months after the command servers were\nregistered, Iran attempted to enrich its first batch of uranium in a small\ncascade at the pilot plant. But the operation didn’t go well, since fifty of\nthe centrifuges exploded. It’s possible an early version of Stuxnet was\nresponsible for this; Iranian authorities attributed the sabotage to UPSes\nfrom Turkey that they said had been manipulated to cause a sudden power surge.\n\nIran quickly recovered from that setback and in May announced that technicians\nhad achieved 3.5 percent enrichment in a full-size cascade at the pilot plant.\nPlans to begin installing the first of 3,000 centrifuges in one of the\nunderground cascade halls commenced. It took until early 2007, however, for\nthe first centrifuges to be installed in the hall. By November that year,\nabout 3,000 centrifuges were in place. That same month, Stuxnet showed up in\nthe wild for the first time when someone submitted Stuxnet 0.5 to VirusTotal.\n\nWITH THE DISCOVERY of this early version of Stuxnet, the researchers now had\nwhat was likely to be the most complete picture they were ever going to have\nabout what occurred with this groundbreaking attack against Iran.\n\nIt had been a long and improbable ride that was made possible only by a series\nof unfortunate events and flubs that should never have occurred—from the zero-\nday exploits that launched Stuxnet on its wild odyssey through thousands of\nmachines around the world to the crashing machines in Iran that first gave it\naway; from the green researchers in Belarus who lacked the skill and\nexperience to tackle a threat like Stuxnet to the Symantec researchers who\nbumbled their way through the PLC code; from the Wiper tool in Iran that led\nthe Kaspersky team to uncover Flame to the server in Malaysia that locked the\nattackers out and preserved a mountain of forensic evidence for the\nresearchers to find. There were so many things that had to go wrong for\nStuxnet and its arsenal of tools to be discovered and deciphered that it’s a\nwonder any of it occurred.\n\nWhen it was all done, the Kaspersky and Symantec researchers looked back over\nthe two years of work they had put into reverse-engineering and analyzing the\nStuxnet gang’s malicious tools and were left to marvel at the level of skill\nand craftsmanship that went into building them. But they were also left\nscratching their heads at the shocking rapidity at which operations that had\nremained stealth for so many years had unraveled so quickly in their\nhands—like the errant string of a sweater that when yanked causes the entire\ngarment to disintegrate.\n\nThe attackers had no doubt assumed, even counted on, the Iranians not having\nthe skills to uncover or decipher the malicious attacks on their own. But they\nclearly hadn’t anticipated that the crowdsourced wisdom of the hive—courtesy\nof the global cybersecurity community—would handle the detection and analysis\nfor them.\n\nWith Stuxnet, a new world order was born in which security researchers and\nreverse-engineers became the unwitting draftees in a new kind of militia—one\nenlisted to dismantle and defend against the digital weapons that nations\nlobbed at one another. This new order created a host of new ethical and\nnational security dilemmas for researchers caught between the needs of\ncomputer users and the interests of intelligence agencies and governments. If\nStuxnet signaled the beginning of the militarization of cyberspace, it also\nsignaled the beginning of the politicization of virus research.\n\n“There’s a new good guy/bad guy question here that puts us potentially in a\nvery difficult position,” Eric Chien said in 2012 after their analysis of\nStuxnet was done. Their work on Stuxnet had been unmarred and unimpeded by\npolitical influences, and he hoped to never be in a position where they were\nforced to choose between customers and the interests of national security. But\nhe wasn’t so naïve to think that it would never come to that.\n\n“It sounds a little cheesy, but we’re just trying to help people and do what’s\nright,” he says. “If we get to a point where we have to ask that question,\nit’s going to be a very hard question [to answer]. I think we’ll be in a bad\nplace if we get to that point.”[36](part0019.html#c15-ftn36)\n\n* * *\n\n[1](part0019.html#c15-ftn1a) Another clue uncovered from the ravaged system\nalso seemed to point to the attackers behind Stuxnet and Duqu. The clue\nindicated that the first thing Wiper did when it landed on a system was hunt\ndown and obliterate any file that had a .PNF extension. Raiu recalled that the\npayload file in Stuxnet as well as some of its other files all had .PNF\nextensions. Duqu also had files with a .PNF extension, an extension that was\nrarely used in malicious tools.\n\n[2](part0019.html#c15-ftn2a) The log also contained the internal computer\nnames of systems in Iran that had been infected.\n\n[3](part0019.html#c15-ftn3a) Microsoft patched it on June 9, about two weeks\nbefore the June version of Stuxnet was released on June 22, 2009.\n\n[4](part0019.html#c15-ftn4a) With regard to whether Flame was connected to\nWiper, there was some confusion between the two attacks after the Kaspersky\nresearchers uncovered a Flame module that was named _Viper._ But the job of\nthis module was to transmit stolen data to a command server, not to wipe the\nhard drive of infected machines. Its existence, though, raised questions\ninitially about whether the Wiper malware the Iranians found was actually a\ncomponent of Flame. It didn’t help that some Iranian reports identified Wiper\nas Viper, due to a transliteration error from Persian to English. But in the\nend, Kaspersky found no direct connection between Wiper and Flame.\n\n[5](part0019.html#c15-ftn5a) Most of the machines that were infected had the 6\nMB version installed on them. But they also found a smaller starter kit that\nwas about 900 KB with no extra modules included with it and that may have been\nused to infect machines over slow network connections, since the 6 MB module\nwould take forever to install remotely in countries with slow and unreliable\ninternet connections.\n\n[6](part0019.html#c15-ftn6a) The malware’s configuration file contained a list\nof five static domains—among them traffic-spot.biz, dailynewsupdater.com, and\nbannezone.in—as well as another list that could be altered at random whenever\nthe attackers added new command servers.\n\n[7](part0019.html#c15-ftn7a) The attackers were more careful with Flame to\nalter timestamps in files to prevent researchers from dating the work.\nAlthough some of the timestamps appeared to be accurate, others that indicated\nfiles had been compiled in 1994 and 1995 were clearly incorrect because the\nfiles contained code from libraries that hadn’t been created until 2010.\n\n[8](part0019.html#c15-ftn8a) The server code actually had a liner note the\nprogrammers had inserted to identify the authors and date of creation. The\nnote read: “@author OCTOPUS in 12/3/2006; @author DeMO (modifications).” The\nnames were likely code names for the individuals or teams that set up the\nservers.\n\n[9](part0019.html#c15-ftn9a) While Kaspersky had been examining the Flame\nfiles it obtained, Symantec had been examining the one it received from\nBencsáth as well as other modules they obtained from the machines of infected\ncustomers after adding detection to their antivirus tools. Neither of the\nteams communicated with each other about their work, though each secretly\nlearned that the other was researching the code. When the Symantec researchers\ndiscovered that the Kaspersky researchers planned to publish their results on\nMemorial Day, they rushed to complete their analysis to publish the same day.\nThe author was contacted by both companies separately—first by Kaspersky and\nthen by Symantec—in advance of the announcements. See Kim Zetter, “Meet Flame,\nthe Massive Spy Malware Infiltrating Iranian Computers,”\n[Wired.com](http://www.Wired.com), May 28, 2012, available at\n[wired.com/threatlevel/2012/05/flame](http://www.wired.com/threatlevel/2012/05/flame).\n\n[10](part0019.html#c15-ftn10a) Its weakness has been known since at least\n2004.\n\n[11](part0019.html#c15-ftn11a) Generally a certificate is generated and signed\nwithin seconds after a request is submitted to Microsoft’s servers. The\nattackers could have been able to gauge how long it took Microsoft to issue\nsigned certificates by submitting a number of certificate requests to the\ncompany to detect a pattern. But one former Microsoft employee suggested to me\nthat the attackers could also have been sitting on Microsoft’s internal\nnetwork watching the requests come in to see exactly how long it took for\nrequests to arrive from outside and be processed. There’s no evidence this is\nthe case, however.\n\n[12](part0019.html#c15-ftn12a) In addition to all of this work, they also had\nto modify the certificate to use it to install their malware on Windows Vista\nmachines, since in its original form it would not have been accepted by any\nsystem using Vista or a later version of the Windows operating system. The\nmodification involved getting rid of an extension on the certificate. They\ndidn’t remove the extension, which might have caused it to fail the computer’s\ncode-signing check; instead, they “commented out” a bit on the\ncertificate—surrounded it with markers to make the machine simply ignore the\nextension. This allowed it to work on Vista machines. Only 5 percent of the\nmachines that Kaspersky saw infected with Flame had Windows Vista installed,\nhowever. Most of the machines were using Windows 7 or Windows XP.\n\n[13](part0019.html#c15-ftn13a) According to sources, Microsoft tried to\ninvestigate who had submitted the requests and how many requests for a\ncertificate came in from this entity, but too much time had passed between\nwhen the certificate was issued—in February 2010—and when Flame was discovered\nin 2012. Microsoft’s logs get rewritten over time, and the logs for that time\nperiod were no longer available.\n\n[14](part0019.html#c15-ftn14a) Dutch cryptographer and academic Marc Stevens,\nwho with colleague Benne de Weger developed one of the first practical MD5\nhash collision attacks for research purposes in 2007, described the Flame\nattack as “world-class cryptoanalysis” that broke new ground and went beyond\nthe work they and others had done with collisions. Stevens and de Weger were\npart of a group of researchers, including Alexander Sotirov, who demonstrated\na similar, though technically different, collision attack in 2008 at the Chaos\nComputer Club Congress—a hacker conference held annually in Germany. They used\na cluster of two hundred Playstation 3s to do their computational work to\ngenerate an identical hash for a certificate. Their certificate masqueraded as\na different company, not as Microsoft. When they conducted their experiment,\nhowever, they kept guessing the wrong timestamp and had to generate a hash\nfour times before they got it right. When the Flame attack was discovered in\n2012, Sotirov estimated that it was ten to a hundred times more difficult to\npull off than the attack he and his colleagues had done. Slides for the\npresentation by Sotirov and his colleagues can be found at\n[events.ccc.de/congress/2008/Fahrplan/attachments/1251_md5-collisions-1.0.pdf](http://www.events.ccc.de/congress/2008/Fahrplan/attachments/1251_md5-collisions-1.0.pdf).\n\n[15](part0019.html#c15-ftn15a) It should be noted that after going through all\nof this trouble to obtain their rogue certificate, the attackers should not\nhave been able to use it to sign their malicious code. But they were able to\ndo so because Microsoft had failed to implement certain restrictions so that\nthe certificates it issued for TS Licensing would be designated for “software\nlicensing” purposes only.\n\n[16](part0019.html#c15-ftn16a) This low-rent certificate would allow the\nmalware to at least slip past Windows XP machines, though not Windows Vista\nmachines, which had stronger security.\n\n[17](part0019.html#c15-ftn17a) Some would say, however, that this attack was\neven worse than subverting the Microsoft Windows Update servers to deliver\nmalicious software, because in subverting those servers, although the\nattackers would be able to send malicious software to customers from\nMicrosoft’s servers, customer machines would reject the code if it wasn’t also\nsigned by Microsoft. But by undermining Microsoft’s certificate process to\nsign their malicious code, the attackers didn’t need Microsoft’s Update\nservers. They could deliver their malware to machines from any server and pass\nit off as legitimate Microsoft code.\n\n[18](part0019.html#c15-ftn18a) Ellen Nakashima, “U.S., Israel Developed Flame\nComputer Virus to Slow Iranian Nuclear Efforts, Officials Say,” _Washington\nPost_ , June 19, 2012.\n\n[19](part0019.html#c15-ftn19a) With Duqu, the attackers had launched their\ncleanup operation _after_ news of the malware broke, but the fact that the\nteam behind Flame launched their cleanup about ten days before news of Flame\nbroke, suggested they had known in advance that their cover was about to be\nblown. The Kaspersky researchers had likely tipped them off inadvertently when\nthey connected a test machine infected with Flame to the internet. As soon as\nthe machine went online, the malware reached out to one of Flame’s command\nservers. The attackers must have realized the machine wasn’t on their list of\ntargets and may even have identified it as a Kaspersky machine and concluded\nthat Flame’s days were numbered. In a panic, they wiped the command servers\nand sent out a kill module, called Browse32, to infected machines to erase any\ntrace of the malware so victims would never know they had been infected.\n\nThe cleanup campaign was successful for the most part. But Browse32 had a\nfatal flaw; it left behind one telltale file, ~DEB93D.tmp, that gave it away.\nThis was a temporary file that got created whenever Flame performed a number\nof different operations on an infected machine. Once the operation was done,\nFlame was supposed to delete the temp file automatically. Because of this, the\nattackers hadn’t put it on the list of files that Browse32 was supposed to\ndelete, since they weren’t expecting it to be on machines. In a twist of fate,\nhowever, if the Browse32 kill module arrived to a machine while Flame was\nstill performing one of the operations that had created the temp file, the\nkill module erased Flame before it could delete the temporary file. Kaspersky\nfound the orphan temp file abandoned on hundreds of systems that had been\ninfected with Flame. It was this file, in fact, left behind on a machine in\nIran, that led the Kaspersky researchers to stumble across Flame in the first\nplace.\n\n[20](part0019.html#c15-ftn20a) This wasn’t the only mistake they made. They\nalso botched the cleanup operation on the servers they could access. They had\ncreated a script called LogWiper.sh to erase activity logs on the servers to\nprevent anyone from seeing the actions they had taken on the systems. Once the\nscript finished its job, it was also supposed to erase itself, like an\nOuroboros serpent consuming its own tail. But the attackers bungled the delete\ncommand inside the script by identifying the script file by the wrong name.\nInstead of commanding the script to delete LogWiper.sh, they commanded it to\ndelete logging.sh. As a result, the LogWiper script couldn’t find itself and\ngot left behind on servers for Kaspersky to find. Also left behind by the\nattackers were the names or nicknames of the programmers who had written the\nscripts and developed the encryption algorithms and other infrastructure used\nby Flame. The names appeared in the source code for some of the tools they\ndeveloped. It was the kind of mistake inexperienced hackers would make, so the\nresearchers were surprised to see it in a nation-state operation. One, named\nHikaru, appeared to be the team leader who created a lot of the server code,\nincluding sophisticated encryption. Raiu referred to him as a master of\nencryption. And someone named Ryan had worked on some of the scripts.\n\n[21](part0019.html#c15-ftn21a) The attackers seemed to have managed their\nproject like a tightly run military operation, with multiple teams handling\ncarefully compartmentalized tasks. There was a management team that oversaw\nthe operation and chose the victims; there were coders who created the Flame\nmodules and a command-and-control team who set up and managed the servers,\ndelivered the Flame modules to infected machines, and retrieved stolen data\nfrom machines; and finally there was an intelligence team responsible for\nanalyzing the stolen information and submitting requests for more files to be\npurloined from machines that proved to have valuable data. It was exactly the\nkind of setup that the Snowden documents suggested the NSA had.\n\nThe team operating the command servers had limited visibility into the overall\noperation and may not even have known the true nature of the missions their\nwork facilitated. The process for uploading new modules to infected machines\nwas tightly controlled so that neither they nor any outsiders who might gain\naccess to the servers could alter the modules or create new ones to send to\ninfected machines. The command modules, for example, were delivered to the\nservers prewritten, where they got automatically parsed by the system and\nplaced in a directory for delivery to victims by the server team, who only had\nto press a button to send them on their way. Data stolen from victims was also\nencrypted with a sophisticated algorithm and public key. The private key to\ndecrypt it was nowhere to be found on the server, suggesting that the data was\nlikely passed to a separate team who were the only ones capable of decrypting\nand examining it.\n\n[22](part0019.html#c15-ftn22a) The protocols were identified as Old Protocol,\nOld E Protocol, SignUp Protocol, and Red Protocol.\n\n[23](part0019.html#c15-ftn23a) Two names—Flame and Flamer—appeared in\ndifferent parts of the code. Kaspersky decided to call the malware Flame, but\nSymantec opted to call it Flamer in their report about it.\n\n[24](part0019.html#c15-ftn24a) It was possible that at one point Gauss might\nhave contained the same Windows font exploit that Duqu had used to install\nitself on machines, though there was no sign of it. If it had been used, the\nattackers might have removed it after Microsoft patched the vulnerability it\nexploited in 2011.\n\n[25](part0019.html#c15-ftn25a) The attackers were checking to see whether a\nvery specific program was installed on the machine, a program that was\nprobably unique to the region in which it was located. The target program was\nunknown, but the Kaspersky researchers say it began with an odd character, and\nthey believed, therefore, that the program might have had an Arabic or Hebrew\nname.\n\n[26](part0019.html#c15-ftn26a) The discovery of SPE left two of the four\npieces of malware used with the Flame servers undiscovered—SP and IP. Raiu\nguessed that SP was likely an early version of SPE that was not encrypted.\n\n[27](part0019.html#c15-ftn27a) Gauss’s files were named after elite\nmathematicians and cryptographers, but SPE adopted a more populist approach,\nusing names such as Fiona, Sonia, Tiffany, Elvis, and Sam.\n\n[28](part0019.html#c15-ftn28a) When malicious files are submitted to\nVirusTotal, the website will send a copy of the file to any of the antivirus\ncompanies whose scanner failed to detect the file, though it will also\nsometimes send files that do get detected as well. The VirusTotal record for\nthe submission of this early Stuxnet file shows that the file was submitted at\nleast twice to the site, on November 15 and 24. Both times, only one out of\nthirty-six virus scanners on the site flagged the file as suspicious, which\nwould have been good news for the attackers. Oddly, there is information\nmissing in the submission record that generally appears in the records of\nother files submitted to the site. The category indicating the total number of\ntimes the file was submitted to the site is blank, as is the category\nindicating the source country from where the file was submitted, which might\nhave provided valuable intelligence about the location of the attackers, if\nthey were the ones who submitted the file, or about the first victim, if the\nfile was submitted by someone infected with the file. It’s not clear whether\nthat information was intentionally scrubbed from the record. VirusTotal was\nfounded by a team of engineers in Spain, but Google acquired it in September\n2012, just a couple of months before Symantec stumbled across this early\nStuxnet version. Google did not respond to queries about why the data was\nmissing from the record.\n\n[29](part0019.html#c15-ftn29a) It was even easier to see from the\nconfiguration data in this version of Stuxnet than in later versions that\nStuxnet was seeking the precise setup at Natanz. The code indicated it was\nseeking a facility where the systems it was targeting were labeled A21 through\nA28. Natanz had two cascade halls, Hall A and Hall B. Only Hall A had\ncentrifuges in it when Stuxnet struck. The hall was divided into cascade\nrooms, or modules, that were each labeled Unit A21, A22, and so on, up to A28.\n\n[30](part0019.html#c15-ftn30a) Stuxnet 0.5 had an infection kill date of July\n4, 2009. Once this date arrived, it would no longer infect new machines,\nthough it would have remained active on machines it already infected unless it\ngot replaced by another version of Stuxnet. The next version of Stuxnet was\nreleased June 22, 2009, just two weeks before Stuxnet 0.5’s kill date.\n\n[31](part0019.html#c15-ftn31a) Like later versions of Stuxnet, this one had\nthe ability to update itself on infected machines that weren’t connected to\nthe internet. It did this through peer-to-peer communication. All the\nattackers had to do was deliver an update from one of the command servers to a\nmachine that was connected to the internet, or deliver it via a USB flash\ndrive, and other machines on the local network would receive the update from\nthat machine.\n\n[32](part0019.html#c15-ftn32a) One other note about this version is that it\nhad a driver file that caused a forced reboot of infected Windows machines\ntwenty days after they were infected. It’s interesting to note that Stuxnet\nwas discovered in 2010 after machines in Iran kept crashing and rebooting.\nAlthough the version of Stuxnet found on those machines was not 0.5, it raises\nthe possibility that this version of Stuxnet or its driver might have been\nlurking on those machines and caused them to reboot repeatedly. Although\nVirusBlokAda never found Stuxnet 0.5 on the machines, they may simply have\nmissed it.\n\n[33](part0019.html#c15-ftn33a) After discovering Stuxnet 0.5 in their archive,\nthe Symantec researchers did a search for it and found a number of errant and\ndormant infections in Iran but also in the United States, Europe, and Brazil.\n\n[34](part0019.html#c15-ftn34a) The servers were set up in the United States,\nCanada, France, and Thailand. The command servers were designed to masquerade\nas an internet advertising firm called Media Suffix to conceal their true\nintention if someone were to gain access to them. The domains for the\nservers—smartclick.org, best-advertising.net, internetadvertising4u.com, and\nad-marketing.net—each had the same home page for the fake advertising company,\nwhich had a tagline that read “Deliver What the Mind Can Dream.” The home page\nread: “The internet is widely becoming the hottest advertising and marketing\nmedium in the world. MediaSuffix focuses extremely in the internet segment of\nadvertising. MediaSuffix is ready to show your company how to capitalize on\nthis unbelievable growing market. Don’t be left behind.… We offer clients an\nunparalleled range of creative answers to the varied needs of our clients.”\n\n[35](part0019.html#c15-ftn35a) Stuxnet 0.5 may have been unleashed earlier\nthan November 2007, but this is the first record of its appearance. According\nto the compilation date found in the Stuxnet component submitted to\nVirusTotal, it was compiled in 2001, though Chien and O’Murchu believe the\ndate is inaccurate.\n\n[36](part0019.html#c15-ftn36a) Author interview conducted with Chien, April\n2011.\n\n\n# CHAPTER 16\n\n# **OLYMPIC GAMES**\n\nIn 2012, Chien may have been contemplating the dark and complicated future\nStuxnet wrought, but four years earlier, the architects of the code were\ncontemplating a different dark future if Iran succeeded in building a nuclear\nbomb.\n\nIn April 2008, President Ahmadinejad took a much-publicized tour of the\nenrichment facilities at Natanz, to mark the second anniversary of the plant’s\noperation, and in the process gave arms-control specialists their first\nmeaningful look inside the mysterious plant. Wearing the white lab coat and\nblue shoe booties of plant technicians, Ahmadinejad was snapped by\nphotographers as he peered at a bank of computer monitors inside a control\nroom, flashed an ironic “peace” sign at the cameras, and led an entourage of\nstern-looking scientists and bureaucrats down two rows of gleaming, six-foot-\ntall centrifuges standing erect at attention like military troops in full\ndress trotted out for inspection.\n\nThe president’s office released nearly fifty images of the tour, thrilling\nnuclear analysts with their first peek at the advanced IR-2 centrifuges they\nhad heard so much about. “This is intel to die for,” one London analyst wrote\nof the images.[1](part0020.html#c16-ftn1)\n\nBut among the retinue accompanying Ahmadinejad on his visit to Natanz was the\nIranian defense minister—an odd addition to the party given Iran’s insistence\nthat its uranium enrichment program was peaceful in nature.\n\nIranian technicians had spent all of 2007 installing 3,000 centrifuges in one\nof the underground halls at Natanz, and during his visit Ahmadinejad announced\nplans to begin adding 6,000 more, putting Iran in the company of only a\nhandful of nations capable of enriching uranium at an industrial level. It was\na sweet triumph over the many obstacles Iran had faced in the past\ndecade—including technical difficulties, procurement hurdles and sanctions,\nand all of the political machinations and covert sabotage that had been aimed\nat stopping its program. The success of the enrichment program now seemed\nassured.\n\nBut Natanz wasn’t out of the woods just yet. Producing enriched uranium at an\nindustrial scale required thousands of centrifuges spinning at supersonic\nspeed for months on end with little or no\ninterruption.[2](part0020.html#c16-ftn2) And while Ahmadinejad was taking his\nvictory lap among the devices, something buried deep within the bits and bytes\nof the machines that controlled them was preparing to stir up more trouble.\n\nIT WAS LATE in 2007 when President Bush reportedly requested and received from\nCongress $400 million to fund a major escalation in covert operations aimed at\nundermining Iran’s nuclear ambitions. The money was earmarked for\nintelligence-gathering operations, political operations to destabilize the\ngovernment and stimulate regime change, and black-ops efforts to sabotage\nequipment and facilities used in the nuclear\nprogram.[3](part0020.html#c16-ftn3) The latter included the experimental\nefforts to manipulate computer control systems at Natanz.\n\nAlthough Bush’s advisers had reportedly proposed the digital sabotage sometime\nin 2006, preparations for it had begun long before this, possibly even years\nbefore, if timestamps in the attack files are to be believed—the malicious\ncode blocks that Stuxnet injected into the 315 and 417 PLCs had timestamps\nthat indicated they had been compiled in 2000 and 2001, and the rogue Step 7\n.DLL that Stuxnet used to hijack the legitimate Siemens Step 7 .DLL had a 2003\ntimestamp.[4](part0020.html#c16-ftn4)\n\nIt’s likely, however, that the clock on the computer used to compile the files\nwas out of date or that the coders manipulated the timestamps to throw\nforensic investigators off. But if the timestamps were accurate, it would mean\nthe attackers had held the malicious code in reserve for three to six years\nwhile the United States waited to see how the diplomacy game with Iran played\nout, then pulled out the code only in 2006 when it was clear that negotiations\nand sanctions had failed.\n\nSome of the attack code was generic to a lot of Siemens systems, and not\nspecifically tailored to the ones at Natanz, so it _was_ possible that parts\nof the attack code grew out of a general research project aimed at uncovering\nvulnerabilities in all Siemens PLCs, not just the ones at Natanz. Siemens\ncontrol systems were used extensively throughout Iran in various\nindustries—the oil and gas industries, as well as the petrochemical and\nmineral industries—not just in its nuclear program. They were also used\nextensively in other regions of the Middle East. With cyberwarfare already on\nthe horizon in the late ’90s, it would have made sense for the United States\nand Israel to invest in early research to uncover vulnerabilities in the Step\n7 system and related Siemens PLCs—which came on the market in the mid ’90s—in\nanticipation that the knowledge would come in handy later.\n\nNot all of the code was so generically applicable to Siemens systems, however:\nthe blocks targeting the frequency converters and valves were specific to the\nconfiguration at Natanz and would have required foreknowledge of the exact\ncomponents Iran planned to install at the plant, as well as intelligence about\ntheir precise configuration and operation. For the timestamps in these code\nblocks to be reliable, the programmers would have had to know in 2001 what\nequipment was going to be installed at a plant that wasn’t even constructed\nyet.\n\nThat part is not as outlandish as it seems: Iran had already tested its\nuranium enrichment process in small cascades of centrifuges at the Kalaye\nElectric factory sometime around 1999. Furthermore, in 2000 and 2002, the CIA\nrecruited key suppliers in the Khan network who provided the agency with\nintelligence about some of the components the network had supplied to Iran and\nother Khan customers. So by the time ground broke on Natanz in 2000, the\nintelligence agency may already have known what equipment Iran planned to\ninstall at the plant, including the Siemens control systems.\n\nDavid Albright of ISIS agrees that much of the information about Natanz could\nhave been known in 2001.\n\n“The cascade details, including the 164 centrifuges per cascade, number of\nstages [in the cascade], most valves, pressure transducers, and piping, could\nhave been known [that early],” he says.[5](part0020.html#c16-ftn5) But\ninformation about the Vacon and Fararo Paya frequency converters may not have\nbeen available then. “Frequency converters would be another matter, since Iran\nwas acquiring them abroad back in that period from a variety of companies. So\nit would be hard to believe that Stuxnet’s designers in 2001 could count on\nthem being from Finland or domestically assembled [by Fararo Paya]. Moreover,\nthe first module [of cascades installed at Natanz in 2007] was built with a\nrange of imported frequency converters.”[6](part0020.html#c16-ftn6)\n\nIn 2003, when the timestamp for the Step 7 doppelgänger indicates it was\ncompiled, there was more information available about Natanz.\n\nWhen IAEA inspectors paid their first visit to Natanz in February 2003, Iran\nalready had a small cascade in place at the pilot plant and was preparing to\ninstall up to 1,000 centrifuges there by the end of the year. And as part of\nthe IAEA’s inquiry into Iran’s nuclear program, Iran had to provide lists of\nequipment procured for Natanz and other nuclear facilities—lists that included\nmachine tools, valves, and vacuum pumps.[7](part0020.html#c16-ftn7)\nIntelligence agencies also had been monitoring Iran’s secret procurement\nactivities and knew that a company named Neda Industrial Group—a leading\nindustrial automation firm in Tehran—was involved in procurement for the\nnuclear program. The company worked with Kalaye Electric, the former watch\nfactory that had been converted into a centrifuge factory, to install\nequipment at Natanz.[8](part0020.html#c16-ftn8) Neda was also Siemens’s local\npartner in Iran, and in 2000 and 2001, according to the company’s website, it\nhad installed Siemens S7 PLCs in other facilities in the country—the same\nmodel of PLCs that Stuxnet attacked. It wasn’t a stretch to think that if Neda\ninstalled these systems in other facilities, it had installed them at Natanz\nas well.\n\nSiemens, in fact, did a brisk business selling automation equipment to various\nnon-nuclear industries in Iran, but its machines found their way into nuclear\nones as well. A 2003 letter from one Iranian firm to another, which Western\nsources later obtained, revealed that Siemens S7-300 and S7-400 controllers,\nalong with the SIMATIC software needed to communicate with them, had been\nprocured by a company named Kimia Maadan that was involved in uranium\nprocessing in Iran.[9](part0020.html#c16-ftn9) It was believed the controllers\nwere purchased for Iran’s Gachin mine, where Iran planned to mine natural\nuranium for processing in centrifuges.[10](part0020.html#c16-ftn10) All of\nthis information would have been known to the United States and Israel.\n\nAlthough the initial plot might have been hatched by US Strategic Command\nunder Gen. James Cartwright, it was up to the cyberwarriors of the NSA and US\nCyber Command, working in conjunction with coders from Israel’s elite Unit\n8200, to execute it.\n\nTo pull off the attack required a lot more intelligence than just knowledge of\nthe equipment at Natanz. The attackers needed to know, for example, the exact\nfrequency at which the converters operated and the exact configuration of the\nequipment. They couldn’t rely only on old blueprints and plans that might be\nout of date. They also needed extensive knowledge about how the Step 7 system\nworked and how the computers at Natanz were networked in order to reassure\nWhite House legal advisers that the code wouldn’t cause cascading effects on\nother systems. If they assumed there wasn’t a connection with outside\ncomputers and there was, the code would break loose and spread to other\nmachines, possibly damaging them and exposing the operation. This is where\ntools like Flame and Duqu would have come in handy to gather data from the\ncomputers of systems administrators, who helped install and maintain the\nnetworks, and from contractors and others who programmed the PLCs. If Duqu was\nused, it could have been delivered via a phishing attack—like the one used to\ninfect the Hungarian company. This worked for machines connected to the\ninternet, such as a programmer’s laptop. But buried in the PLCs that weren’t\nconnected to the internet was also configuration data about things like the\nnumber of Profibus cards connected to them and the model and number of\nfrequency converters.\n\nTo get to that data, if it couldn’t be obtained another way, the attackers\nneeded a flash drive to jump the air gap and get their spy tool onto a machine\nconnected to the PLCs. Since, as previously noted, PLC programmers generally\nwork on laptops not connected to the control network, then connect their\nlaptop physically to a machine on the PLC network or copy their programming\nfiles to a flash drive and carry it to a machine on that network, this would\nhave been a simple way to achieve that. The attackers could have retrieved\ndata about the PLCs and control network in reverse—using malware that recorded\ndata from these systems onto the flash drive, which the programmer would have\nbrought back to his internet-connected laptop, where it could be retrieved.\nIt’s also been reported that the intelligence agencies used special implants\nembedded in non-networked machines in Iran that transmitted data about\ninfected systems via radio waves.[11](part0020.html#c16-ftn11)\n\nIt might have taken months to obtain the data the attackers needed. But some\nof the reconnaissance work could have been done as early as 2005, when the\ndomains for the command-and-control servers used with Stuxnet 0.5 were\nregistered. Although Stuxnet wasn’t released until later, the domains could\ninitially have been used to communicate with spy tools. The reconnaissance\nalso might have been done around May 2006, when researchers found that code\nfor the command-and-control servers used with later versions of Stuxnet was\ncreated.\n\nOnce information about the systems was gathered, final work on the attack code\ncould have occurred. Symantec estimated that two separate teams created the\n315 and 417 attack codes based on the distinct ways they were written. Whether\nthe United States and Israel worked on both of them together or the Israelis\nonly worked on the missile portion while the Americans handled the payloads is\nunknown. A third team may have worked on the code that hijacked the Step 7\nsystem to swap out the legitimate .DLL for Stuxnet’s rogue one and inject the\nmalicious commands into the PLCs. Symantec estimated that it took about six\nmonths to write this Step 7 portion of the code and a little less time to\nwrite the malicious PLC code blocks. The testing, however, would have also\ntaken time.\n\nWhoever was responsible for the actual code, this part of the operation had to\nbe precise. There were so many ways for the attack to go wrong, but there was\nno room for error, and it would be difficult to gauge the effects of the code\nin the field or tweak it once it was unleashed. This meant the attackers had\nto do extensive testing—not only on a Siemens test-bed to make sure their code\ndidn’t brick the Step 7 system or the PLCs, but also, in the case of the\nvariants unleashed in 2009 and 2010, on all versions of the Windows operating\nsystem to make sure the malware spread and installed seamlessly without\ndetection.[12](part0020.html#c16-ftn12)\n\nMost of all, the attackers needed precise knowledge of how each change of the\ncode would affect the centrifuges, particularly because what they were aiming\nfor was not a brute-force attack but a finessed one. The tiniest mistake and\nthey could destroy the centrifuges too quickly or destroy too many at once and\nexpose the sabotage, blowing the operation.\n\nTo pull this off, they would have needed a team of material scientists and\ncentrifuge experts who understood the density and strength of the aluminum\nrotors and centrifuge casings, and who understood how the bearings at the\nbottom of each centrifuge, which kept them spinning in balance, would respond\nto increased vibration. They also needed to calculate the normal wall pressure\ninside the centrifuges and determine how much it would increase as the gas\npressure inside the centrifuges grew.[13](part0020.html#c16-ftn13)\n\nTo do all of this, they needed actual centrifuges against which to test the\nattacks. Luckily, as noted previously, the Department of Energy’s Oak Ridge\nNational Laboratory in Tennessee possessed a number of P-1 centrifuges, upon\nwhich the IR-1s at Natanz were based.\n\nThe story behind Oak Ridge’s acquisition of the centrifuges began in August\n2003, three years after the CIA infiltrated A. Q. Khan’s illicit nuclear\nsupply network and six months after the IAEA made its first visit to Natanz.\nThe spy agency intercepted a shipment of black-market uranium enrichment\ncomponents—including 25,000 centrifuge casings as well as pumps, tubes, and\nother components—headed from Malaysia to a secret enrichment plant in Libya.\nThe seized crates were used by the West to confront Libyan dictator Muammar\nGaddafi with evidence of his secret nuclear program and to pressure him into\nabandoning it. On December 19, Libya’s foreign minister announced on national\ntelevision that the country was renouncing its nuclear weapons and chemical\nweapons programs—programs it hadn’t until then acknowledged possessing.\n\nThe IAEA learned there was more enrichment equipment already in Libya that US\nauthorities planned to dismantle and ship back to the Oak Ridge lab. So over\nthe Christmas holiday, Olli Heinonen; his boss, Mohamed ElBaradei; and other\nIAEA colleagues raced to Tripoli to inventory the equipment before it\ndisappeared. There they found more than one hundred tons of equipment worth\nabout $80 million—including UPS regulators from Turkey (similar to the ones\nthat would later be sabotaged in Iran in 2006), two hundred P-1 centrifuges\nfrom Pakistan that the Libyans had already assembled into a small cascade, as\nwell as components for building about four thousand other\ncentrifuges.[14](part0020.html#c16-ftn14) By March 2004, the seized equipment\nhad been packed up and sent to the Y-12 National Security Complex at Oak\nRidge, where it was protected by guards armed with assault rifles while put on\ndisplay for journalists to see.\n\n“By any objective measure,” US Secretary of Energy Spencer Abraham told the\nassembled reporters at the time, “the United States and the nations of the\ncivilized world are safer as a result of these efforts to secure and remove\nLibya’s nuclear materials.”[15](part0020.html#c16-ftn15) This may have been\nso, but what the captured booty really meant was that the United States now\nhad the chance to assemble a secret plant to study the centrifuges and test an\nattack against them.[16](part0020.html#c16-ftn16)\n\nTHE OAK RIDGE National Laboratory, established in 1943 and located outside of\nKnoxville, is managed by UT-Battelle—a nonprofit company founded in 2000 by\nBattelle Memorial Institute and the University of Tennessee—and touts itself\nas a science facility focused on advanced materials research, nuclear science,\nclean energy, and supercomputing. But it’s the lucrative classified national\nsecurity work the lab does for the Defense Department, Department of Energy,\nand intelligence agencies—focused on nuclear nonproliferation, intelligence\ndata mining, encryption cracking, and other areas—that really keeps it in\nbusiness.\n\nThe secret centrifuge plant, part of a now decade-long classified program to\nresearch the destruction of centrifuges, was constructed sometime after 2005\non a backwoods lot on the 35,000-acre Oak Ridge Reservation, invisible and\ninaccessible to the majority of lab workers who held security clearances.\nDubbed “the Hill” or sometimes “the chicken ranch” according to one person who\nknew about it, the covert facility was reached via an unmarked road that\nmeandered for ten miles, blanketed on either side by a thick forest of trees,\nbefore delivering cars to first one security gate and then\nanother.[17](part0020.html#c16-ftn17)\n\nThe Hill actually consisted of two facilities—one aboveground, the other\nbeneath. The underground hall, a preexisting structure built long before for\nanother purpose, was requisitioned for the first stage of the centrifuge\nprogram, which initially focused just on figuring out how the centrifuges\nobtained from Libya worked. The lab had obtained both P-1 and P-2 centrifuges\nfrom Libya to study, but the devices arrived for the most part as unassembled\ncomponents without a manual. The researchers had drawers and drawers filled\nwith the parts, but had no prior experience working with the designs and\ntherefore spent a lot of their time initially just trying to figure out how to\npiece the components together and get them to work.\n\nThe researchers at Oak Ridge experienced some of the same problems the\nIranians experienced in operating the temperamental and fragile devices. The\nscoops and ball bearings proved to be particularly problematic for them and\ndelayed their progress for a while.\n\nIn the beginning, the program wasn’t about building a virus to attack the\ncentrifuges; it was simply about learning how the centrifuges and cascades\nworked in order to understand their capabilities and gauge how far along the\nIranians were in their enrichment program and to determine how close they\nmight be to having enough enriched uranium to make a nuclear bomb. When the\nOak Ridge scientists completed their initial research and testing, they\nestimated it would take Iran about twelve to eighteen months to produce enough\nfissile material for a bomb.\n\nThe study of centrifuges wasn’t foreign to Oak Ridge. The lab has a long\nhistory of centrifuge research and development, having produced some of the\nfirst rotor centrifuges in the 1960s. But in 1985, its centrifuge program was\nterminated after lasers replaced centrifuges as the primary method of\nenriching uranium in the United States. The closure displaced thousands of\nskilled workers and researchers whose specialized knowledge was no longer\nneeded.\n\nThen in 2002, around the time the world was learning about Iran’s secret\nenrichment facility at Natanz, centrifuge enrichment made a comeback, and Oak\nRidge resurrected its program to design a new generation of centrifuges for\nthe United States Enrichment Corporation, now a producer of enriched uranium\nfor commercial nuclear power plants in the United States. To staff that\noperation, the lab pulled many of its former centrifuge experts out of\nretirement—some of them now in their seventies and eighties—to work alongside\nyounger scientists.\n\nAfter the cache of valuable centrifuges was seized from Libya, many of these\nscientists were reassigned to study the devices. According to someone familiar\nwith the program, he believed the work was conducted under the auspices of the\nNational Nuclear Security Administration (NNSA), a division of the Department\nof Energy that manages the security of the nation’s nuclear weapons but also\noperates a nuclear nonproliferation research and development program known as\nNA-22.[18](part0020.html#c16-ftn18) The latter collects human intelligence\nabout illicit nuclear operations and does remote sensing and environmental\ntesting to collect evidence of covert enrichment activity and nuclear\ndetonations by rogue regimes and actors.[19](part0020.html#c16-ftn19)\n\nThe NNSA had been trying to get its hands on Iranian centrifuges for a while,\nso the shipment of P-1s and P-2s obtained from Libya in 2004, on which the\nIranian centrifuges were based, was a huge boon.\n\nEventually, they also obtained parts directly from the Iranian program, via\nintelligence sources. These parts were highly valuable—North Korea was\nbelieved to be using centrifuges of the same general design—and workers were\ntold to be very careful and expeditious in using the components because in\nsome cases intelligence sources had given their lives to obtain them. In other\nwords, there was no easy way to replace them and therefore every test on the\nequipment had to count.\n\nResearch on the devices was already under way in 2006, when Iran announced it\nwould begin enriching uranium at Natanz, but the research was slow-moving,\naccording to someone familiar with the program. But in 2007, the operation\ncame together in earnest as Iran began installing its first centrifuges in the\nunderground hall at Natanz.\n\nIn the meantime, the aboveground hall was constructed for the sole purpose of\ntesting—and destroying—centrifuges. It’s believed that some of this research\nmay have initially focused on determining the possible destructive effects\nfrom a kinetic attack, such as an aerial bombardment on centrifuges buried\ndeep underground, and that a cyberattack became part of the equation only\nlater. Then when a digital operation _was_ proposed, initially the goal wasn’t\nto destroy the centrifuges at Natanz with a virus but simply to plant\nsurveillance code in equipment at the plant to collect data that would help\nscientists determine where Iran was in its enrichment process. But at some\npoint, the centrifuge destruction program and the reconnaissance operation\nmerged to produce a plan for a digital kinetic attack. Likely, most of the\nscientists testing the centrifuges never knew about the plan for such an\nattack but were simply focused on assessing the effects of various conditions\non the centrifuges—such as increased and decreased speed or increased wall\npressure inside the centrifuge—in a manner that was divorced from the causes\nof those conditions.\n\nInside the large testing hall, tall racks of control systems from Siemens and\nother vendors were arranged like stacks in a library at the front of the\ncavernous space, while more than a dozen man-sized centrifuges were spaced\nthroughout the hall across from them. Jury-rigged cables attached to sensors\nsnaked out from some of the centrifuges to record diagnostics and measure such\nthings as the heat of the casing or the wobbling and vibration of the pin and\nball bearing that kept the centrifuge balanced.\n\nSome of the centrifuges spun for months, while data on them was collected.\nThese were the research specimens, however. There were others whose fate was\nmore dire. Just inside the entrance to the hall was a large reinforced cage\nmade of acrylic and metal mesh—what a hospital baby-viewing room might look\nlike if it were designed by the team from _MythBusters_ —where condemned\ncentrifuges went to die. Workers at the plant always knew when a centrifuge\nwas being destroyed in the protective cage because it made a horrific\nexplosive sound, accompanied by a rumbling in the ground.\n\nThe operation was in full swing by 2008, with centrifuges being destroyed\nsometimes on a daily basis. “You could tell the budget had jumped\nsignificantly,” the source says. President Bush, perhaps not coincidentally,\nhad just managed to obtain $400 million from Congress for covert operations\nagainst Iran’s nuclear program.\n\nWhile tests were being conducted at Oak Ridge, other tests were reportedly\ndone on centrifuges at Israel’s nuclear facility in Dimona. It’s unclear how\nlong all of these tests took or when officials decided they had enough\nconclusive data to conduct a successful attack.\n\nDuring the 2006 testing, the development of the attack code was already under\nway. The exact timeline for that development is unclear, but the Symantec\nresearchers found that a key function used in the attack code appeared to have\nbeen modified in May 2006. It was the code that Stuxnet used to initiate\ncommunication with the frequency converters in the attack on the 315 PLCs. And\nas noted, code used for the two command servers that were used with that\nversion of Stuxnet—mypremierfutbol.com and todaysfutbol.com—was also compiled\nin May 2006. Other key functions in the attack code were modified in September\n2007. Just two months after that, in November 2007, Stuxnet version 0.5 popped\nup on the VirusTotal website after it was submitted by either the testers or\nan infected victim.\n\nAt some point, some of the centrifuges at Oak Ridge or another lab were taken\noff for another kind of test—to directly measure the efficacy of the digital\nweapon against the centrifuges. When the proof-of-concept tests were done,\nofficials reportedly presented Bush with the results of their labor—the\ndetritus of a destroyed centrifuge that proved the outrageous plan might\nactually succeed.[20](part0020.html#c16-ftn20) Like the Aurora Generator Test,\nconducted by the Oak Ridge Lab’s sister facility in Idaho in early 2007, the\ncentrifuge test showed that heavy machinery was no match for a piece of well-\ncrafted code.\n\nHOW OR WHEN Stuxnet 0.5 was introduced to the computers at Natanz is still a\nmystery.[21](part0020.html#c16-ftn21) Because the industrial control systems\nat Natanz were not directly connected to the internet and this version of\nStuxnet had few spreading mechanisms, the attackers had to jump the air gap by\nwalking it into the facility or sending it via email. This version of Stuxnet\nhad only one way to spread—via infected Step 7 project files. This meant it\nhad to be introduced directly into a programmer’s or operator’s machine either\nwith a USB flash drive—perhaps by an unwitting contractor who didn’t realize\nhe was a carrier for the worm or by a paid mole—or by emailing an infected\nproject file to someone at Natanz.[22](part0020.html#c16-ftn22) From a\nprogrammer’s or operator’s machine, it was just a step or two into the\ntargeted PLC. Unlike subsequent versions that kept a log file of every system\nthey infected, as well as a timestamp indicating when each infection occurred,\nresearchers found no digital breadcrumbs to trace the path that Stuxnet 0.5\ntook.\n\nThis version didn’t target the 315 PLC and frequency converters but instead\nattacked the 417 PLC and valves, opening and closing the latter to manipulate\nthe flow of uranium gas.\n\nCascades at Natanz were configured into fifteen stages, with a different\nnumber of centrifuges installed at each stage; as the gas moved from one stage\nto the next, and the amount of gas being enriched diminished as it progressed\nthrough the stages, the number of centrifuges needed to enrich the gas also\ndiminished.\n\nStage ten, for example, which was the “feed stage,” where new batches of gas\nwere pumped into the cascade, had twenty-four centrifuges. As the rotors\ninside the centrifuges spun at high speed and separated the isotopes, gas\ncontaining the U-235 concentrate was scooped out and sent to stage nine, which\nhad twenty centrifuges, where it was further enriched, and then to stage\neight, which had sixteen centrifuges. In the meantime, the depleted gas\ncontaining the concentration of U-238 isotopes got diverted to stage eleven,\nwhere it was further separated. The concentration of U-235 from this stage\nthen got passed to stage eight when it was ready to join the other enriched\ngas. This continued until the enriched gas reached the final stage of the\ncascade and the final depleted gas was discarded. The last stage of the\ncascade, where the enriched uranium was sent, usually consisted of just one\ncentrifuge and a spare in case it malfunctioned.\n\nEach cascade had auxiliary valves that controlled the gas into and out of the\ncascade and into and out of each enrichment stage. Additionally, each IR-1\ncentrifuge had three narrow pipes at its top, with valves on each pipe that\ncontrolled the flow of gas into and out of the centrifuge. The feed valve\nopened to inject gas into the centrifuge, after which the enriched uranium got\nscooped out through the product valve, while depleted gas was extracted via\nthe tail valve and pipe.\n\nStuxnet didn’t attack all of the valves at Natanz. Rather, it was selective in\nits assault. The underground hall where the centrifuges were installed was\ndivided into modules, or cascade rooms. Each module could hold 18 cascades\ncontaining 164 centrifuges each, for a total of about 3,000 cascades per room.\nAt the time Stuxnet was unleashed, only one room in the underground hall was\ncomplete—filled with 18 cascades. But Stuxnet targeted only six cascades. Not\nall of the centrifuges in each cascade were affected, either. Stuxnet targeted\nthe valves on only 110 of the 164 centrifuges in these cascades, leaving\nvalves on the remaining 54 untouched.\n\nOnce this version of Stuxnet found itself on a system at Natanz, it lay\ndormant for about thirty days before launching its assault, conducting system\nchecks to make sure that various valves, pressure transducers—for measuring\nthe gas pressure—and other components were present and monitoring their\nactivity.[23](part0020.html#c16-ftn23)\n\nWhile it mapped the system, Stuxnet also recorded various data pertaining to\nthe normal operation of the cascade to play it back to operators once the\nsabotage commenced, just as the 315 attack code did. For example, it briefly\nopened valves in the last stage of a cascade to take a pressure reading, then\nreplayed this normal-pressure reading back to operators during the attack, to\nconceal the fact that the pressure had increased.\n\nOnce it collected all the data it needed, it waited until certain conditions\non the cascade were met before proceeding. An individual cascade, for example,\nhad to have been operating more than 35 days before the attack commenced, or\nall six of the targeted cascades—if they were all running—had to have been\noperating a total of 298 days or more.\n\nOnce it began, Stuxnet closed various valves, except the ones in the feed\nstage where the gas entered the cascade. In stage nine, for example, it closed\nthe exit valves on only fourteen of the twenty centrifuges, and in stage\neight, it closed the exit valves on thirteen of the sixteen centrifuges. The\nvalves it closed in each stage were randomly chosen through a complex process.\n\nWith all of these valves closed, Stuxnet sat and waited for the pressure\ninside the centrifuges to increase as gas continued to pour into them but\ncouldn’t escape. It waited two hours, or until the pressure in the centrifuges\nincreased fivefold, whichever was first. Once either of these effects was\nachieved, Stuxnet proceeded to the next step, opening all of the auxiliary\nvalves except three valves believed to be near the feed stage. Then it waited\nabout three minutes and fed more fake data to operators while preventing any\nchanges from being made to the system for an additional seven minutes. Toward\nthe end of the attack, it opened a set of about twenty-five valves. Albright\nand his colleagues at ISIS suspected these valves were in the “dump line.”\nEach stage of the cascade had a pipe that connected to a dump line so that if\nsomething went wrong with the centrifuges or the enrichment process, the gas\ncould be dumped from the cascade into a cooled tank. If Stuxnet opened valves\nfor the dump line, then gas inside the cascade would exit into the tank,\ncausing it to be wasted.\n\nOnce all of this was done, the attack ended and reset itself.\n\nThe fact that only some of the centrifuge valves were affected and that the\nattack lasted just two hours, during which operators were fed false readings,\ncreated great confusion among the technicians at Natanz, who would have seen\nproblems occurring in the centrifuges over time, as well as a decrease in the\namount of uranium that was enriched, without being able to spot a pattern or\npinpoint the cause.\n\nResearchers still don’t know precisely which valves were opened and closed by\nStuxnet, so it’s impossible to say definitively what the effects were. But\nbased on certain assumptions, Albright and his colleagues posited two\nscenarios. In one, the final product and tail valves at the end of the cascade\nwere closed, so that gas would keep pumping into the cascade but couldn’t get\nout. In this scenario, the pressure would increase rapidly, and once it\nreached five times the normal level, the uranium gas inside the centrifuges\nwould begin to condense and solidify. As the resulting solid got caught in the\ncentrifuge’s spinning rotor, it would damage the rotor or cause it to become\nimbalanced and strike the wall of the centrifuge. This wobbling would also\ndestabilize the bearings at the bottom of the centrifuge, causing the\ncentrifuge to teeter off balance. A whirling centrifuge detaching itself from\nits mooring at high speed is a destructive thing and would take out other\ncentrifuges around it.\n\nIn this scenario, the pressure would have built up in the later stages of the\ncascade faster than earlier ones, causing these centrifuges to fail first.\nAlbright and his team estimated that such an attack might have destroyed about\n30 centrifuges per cascade. It’s believed that by focusing its effort on\ncentrifuges in the later stages of the cascades, where the enriched uranium\nwas most concentrated, the sabotage would have had more impact. If a\ncentrifuge was destroyed near the feed stage, where the concentration of U-235\nwas the smallest, less time and work were lost than if the gas had passed\nthrough the entire cascade and been enriched nearly to the point of completion\nbefore the end centrifuges were destroyed and the gas was lost.\n\nIt’s also possible, however, that Stuxnet didn’t close the product and tail\nvalves at the end of the cascade. If that’s the case, Stuxnet’s primary effect\nwould have been more modest—it would have simply reduced the amount of gas\nbeing enriched. Gas would have been fed into the cascade, but with valves on\n110 of the 164 centrifuges closed, it would only have been able to pass\nthrough the 54 centrifuges in each cascade that weren’t affected by Stuxnet,\nwhich would have resulted in a smaller amount of gas being enriched and less\nenrichment achieved.\n\nWhile Stuxnet conducted its sabotage and fed false data to operators, it also\ndisabled a safety system on the cascade designed to isolate centrifuges before\nthey could cause damage. The safety system was fairly elaborate and included\nan accelerometer on each centrifuge—to monitor the vibration of the\ncentrifuge—as well as a couple dozen pressure transducers per cascade to\nmonitor the pressure. If a centrifuge was at risk of crashing, the emergency\nresponse system acted rapidly—within milliseconds of detecting a problem—to\nclose the valves on the centrifuge to isolate the gas inside\nit.[24](part0020.html#c16-ftn24) The kinetic energy from a troubled centrifuge\nwould create a pulse of hot gas that, if not contained, would radiate out\nthrough the cascade and damage other centrifuges. The emergency response\nsystem was supposed to act quickly to halt the flow of gas from that\ncentrifuge, but Stuxnet disabled that system so there was nothing to isolate\nthe damage.\n\nThe assault capabilities of Stuxnet 0.5 then were multipronged—it increased\nthe gas pressure to damage the centrifuges and spoil the gas, it dumped some\nof the gas from the cascade so that it couldn’t be enriched, and finally it\nreduced the number of working centrifuges so that the amount of enriched\nuranium that came out of the end of the cascade was reduced. It is unclear\njust how successful this version of Stuxnet was. But judging by IAEA reports,\nit did appear to have some effect on the program.\n\nTHE INSTALLATION OF cascades at Natanz occurred in three stages, each of which\nthe IAEA inspectors tracked during their visits.[25](part0020.html#c16-ftn25)\nFirst, the cascade infrastructure—pipes, pumps, and valves—was put in place.\nNext the centrifuges were installed, and their motors turned on to start them\nspinning. At this point, the vacuum pumps removed air that might cause\nexcessive friction and heat. When the centrifuges reached optimal speed, the\ngas was piped in to begin enrichment.\n\nIran had begun installing centrifuges in Hall A, one of Natanz’s two cavernous\nunderground halls in early 2007. As previously noted, the hall was designed to\nhave eight large rooms or units—A21 through A28—with eighteen cascades in\neach. Each cascade was designed to hold 164 centrifuges, for a total of 2,952\ncentrifuges in each unit.[26](part0020.html#c16-ftn26)\n\nTechnicians began installing the first centrifuges in Unit A24 in February\nthat year and planned to have all eighteen cascades in the unit by May. But\nthat didn’t happen.[27](part0020.html#c16-ftn27) By mid-August, only twelve\nwere installed and enriching gas. It took until November to get the rest of\nthem in place. But by then, there were signs of trouble. Technicians were\nfeeding less gas into the centrifuges than they were designed to hold and were\nholding back some of the gas in a “process buffer,” between the feed point and\nthe cascades. From February to November, they fed about 1,670 kg of gas into\nthe feed hull, but held 400 kg of it back in the buffer zone so that only\n1,240 kg actually made it to the cascades. What’s more, the gas that got into\nthe cascades produced much less enriched uranium than expected. It should have\nproduced 124 kg of low-enriched uranium—10 percent of the amount fed into the\ncascades. But instead the Iranians got only 75 kg out of\nit.[28](part0020.html#c16-ftn28) It’s a trend that remained constant for most\nof 2007, with more feed going into the centrifuges than product was coming\nout. The level of enrichment was also low. Technicians claimed they were\nenriching at 4.8 percent, but IAEA tests indicated the gas was enriched to\nbetween 3.7 percent and 4.0 percent.\n\nWas Stuxnet 0.5 at play, messing with the valves and the enrichment levels?\nIt’s hard to know for sure, but the problems didn’t go unnoticed by outsiders.\nThe 2007 National Intelligence Estimate released by the United States in\nDecember that year noted that Iran was having “significant technical problems\noperating” its centrifuges. Centrifuges were crashing at a rate 20 percent\nhigher than expected. A senior IAEA official told David Albright that the\nbreakage resulted in partially enriched gas being dumped into waste\nreceptacles, which was likely the cause of the low production\nnumbers.[29](part0020.html#c16-ftn29)\n\nAt the time, Albright and his colleagues attributed the high breakage rate to\nthe poor centrifuge design and the fact that Iran was still “learning the\ndifficulties of operating centrifuges in large numbers.” But the problems were\nconsistent with what would have occurred if the valves were being manipulated\nby Stuxnet 0.5.\n\nWhatever the cause, Iran couldn’t afford to waste uranium gas. It had a\nlimited supply of uranium imported from abroad and its Gachin mine doesn’t\nproduce enough uranium to sustain its nuclear\nprogram.[30](part0020.html#c16-ftn30)\n\nBetween November 2007 and February 2008 technicians installed no new cascades\nin the hall and focused instead on trying to resolve whatever was creating the\nproblems. Things appeared to turn around after February, however. By the time\nAhmadinejad took his triumphant tour of the plant that spring, the cascades\nwere operating in a more stable manner, with fewer breaking. Enrichment levels\nwere hovering at a steady 4 percent, and where previously technicians had fed\nthe centrifuges only half the amount of gas they could handle, they were now\nfeeding them 85 percent of their capacity. Even the performance of individual\ncentrifuges had increased.\n\nBy all accounts, Iran appeared to have mastered its problems with the\ncascades. Technicians began installing cascades at a breakneck pace—a pace\nthat was much more rapid than reason or caution advised. As soon as one\ncascade was in place, they began feeding it gas, then moved on to the next\ncascade. In May 2008, Iran had 3,280 centrifuges enriching gas, but by August,\nthe number had grown to 3,772, an increase of 500 centrifuges in three\nmonths.[31](part0020.html#c16-ftn31)\n\nThere was a lot of political pressure inside Iran to move quickly on the\nnuclear program. UN sanctions and the lack of progress in negotiations with\nthe West irritated Iranian leaders, and they were tired of the delays. But the\nsudden ramp-up was ill-advised and likely was not supported by Iranian\nscientists and engineers. Even under normal conditions, installing centrifuges\nand getting them to run properly was a tricky business. Add to this the\ninherent fragility of the IR-1s and it didn’t make sense to move this fast.\n\n“From an engineering point of view, it’s kind of a reckless procedure, because\nif you barely operated a 164-machine centrifuge cascade, why would you want to\nrace and try to operate eighteen or thirty cascades all at once?” says\nAlbright. “An engineer would say do this very slowly, and make sure that\nyou’ve understood how to work all these things as a unit before you start\nscaling up like that.”[32](part0020.html#c16-ftn32)\n\nBut few problems occurred during this period, and by the end of the summer,\nthe technicians at Natanz must have begun to grow confident that they had put\nearlier troubles behind them. Then conditions began to go south again.\n\nThe IAEA reports told the story in a series of dry numbers.\n\nDuring his April 2008 tour, Ahmadinejad had announced optimistically that\ntechnicians would soon add 6,000 centrifuges to the 3,000 centrifuges already\ninstalled in the underground hall. But after reaching just 3,772 centrifuges\nthat August, the technicians stopped, and no new centrifuges were added in the\nnext three months. Production levels were also way down. Since the start of\nenrichment in early 2007, technicians had fed 7,600 kg of gas into the\ncascades, but by August 2008 the centrifuges had produced only 480 kg of\nenriched uranium, instead of the 760 they should have produced. The low\nproduction numbers continued the rest of 2008. Between August and November\ntechnicians fed 2,150 kg of gas into the cascades but produced only 150 kg of\nenriched uranium during that time. As in 2007, they appeared to be losing an\nunusual amount of gas.\n\nDespite all of these problems, however, 2008 overall was a better year for\nIran than 2007.[33](part0020.html#c16-ftn33) Whereas Natanz had produced only\n75 kg of enriched uranium in all of 2007, by the end of 2008, this had jumped\nto 630 kg. Albright and his colleagues at ISIS estimated that with further\nenriching under optimal conditions, Iran could turn 700 to 800 kg of low-\nenriched uranium into 20 to 25 kg of weapons-grade uranium, enough for a crude\nnuclear weapon. Nonetheless, there was no getting around the fact that Iran’s\nnuclear program wasn’t at the level it should have been at that point.\n\nThe timing of the problems in late 2008 appeared to coincide with how Stuxnet\n0.5 was designed to work. Once Stuxnet infected a 417 PLC, the sabotage took\ntime to unfold. The reconnaissance stage took at least a month while Stuxnet\nrecorded data to play back to operators, and the cascades had to be active for\na period of time before the sabotage kicked in—at least 35 days in the case of\na single cascade, or more than 297 days for all six cascades combined. Once\nthe attack was finished, another 35 days passed before it began again. The\nproblems in late 2008 seemed to be concentrated in unit A26, where technicians\nhad begun to install centrifuges in the spring. If Stuxnet was introduced to\ncontrollers for that unit in late 2007 or early 2008, it could have taken\nmonths for the attack’s negative effects—from the increase of pressure inside\nthe centrifuges—to show.\n\nNotably, around this time, a Canadian-Iranian man tried to purchase a batch of\npressure transducers from two Western manufacturers to ship to Iran. The\ndevices were used for, among other things, measuring the pressure of gas\ninside a centrifuge. Between December 2008 and March 2009, Mahmoud Yadegari\nbought ten transducers at a cost of $11,000 and shipped two of them to Iran\nvia Dubai. He placed an order for twenty more from a second firm, but the\ncompany rejected the order after he failed to certify the identity of the end\nrecipient. He was arrested that April after authorities were tipped off about\nthe suspicious order.[34](part0020.html#c16-ftn34) Was Iran attempting to\npurchase transducers to replace ones that appeared to be failing at Natanz or\nwas there no connection between Yadegari’s efforts and the problems that\noccurred at Natanz?\n\nAs Iran entered 2009, technicians began rapidly adding new centrifuges and\ncascades to unit A26. Nine cascades were under vacuum in this unit by\nFebruary. But instead of being fed gas, the centrifuges sat in their cascades\nempty. In the past, technicians had begun to feed gas into new cascades as\nsoon as they were installed, but for some reason now they weren’t. At the same\ntime, the number of separative work units—a measurement of how much work each\ncentrifuge expends in the enrichment process—fell dramatically from .80 to .55\nfor the centrifuges that were enriching in A24 and A26. The level of\nenrichment also dropped from 4 percent, where it had hovered through most of\n2008, to 3.49 percent. If the effects were caused by Stuxnet, it appeared the\ndigital weapon was doing exactly what it was designed to accomplish.\n\nBut then the attackers decided to switch things up.\n\nAS 2009 BEGAN, president-elect Barack Obama was invited to the White House to\nmeet with President Bush for the standard debriefing that passed between\nincoming presidents and their predecessor as the two prepared to exchange the\nbaton. During the conversation, Bush laid out the details of the digital\nattack and the subtle magic it had been working over the last year to\nundermine the centrifuges at Natanz.[35](part0020.html#c16-ftn35) There had\nbeen progress in setting the Iranian program back a bit, but the operation\nneeded more time to succeed. If it was to continue, however, it needed to be\nauthorized by a sitting president, which meant Obama had to renew the\nPresidential Finding that approved it. Given that other options had failed up\nto then, and an airstrike was the only likely alternative, Obama ultimately\nneeded little persuasion.[36](part0020.html#c16-ftn36)\n\nIn the summer of 2008, while still in the midst of his presidential campaign,\nObama had made a whistle-stop tour in Israel, where he told the Israelis that\nhe felt their pain. A nuclear-armed Iran, he said, would be “a grave threat”\nto peace not just in the Middle East, but around the\nworld.[37](part0020.html#c16-ftn37) He promised that under his leadership all\noptions would remain on the table to prevent Iran from obtaining nuclear\nweapons. Although in essence this meant a military option as well, Obama, like\nBush, wanted to avoid a military engagement at all costs. Therefore, a covert\noperation that used bytes over bombs was a more welcome choice.\n\nComing into office, Obama already faced a lot of pressure on multiple fronts.\nLittle progress had been made with Iran via diplomatic channels, and sanctions\nweren’t having much of their desired effect either. And there was concern that\nthe Israelis might take matters into their own hands if the United States\ndidn’t show results soon. For these and other reasons, Obama decided not only\nto reauthorize the digital sabotage program but to accelerate it. It was in\nthis environment that he gave the green light for a new, more aggressive,\nversion of Stuxnet to launch—the one that targeted the frequency converters at\nNatanz.\n\nWhy fire off a new attack when the first one seemed to be succeeding? The\noperation against the valves was effective but slow. Stuxnet’s creators were\nrunning out of time and needed a faster attack that would target the\ncentrifuges more directly and set Iran’s program back more definitively. They\nalso wanted to confuse technicians with a different set of problems.\n\nThe irony was that while Obama was authorizing this new attack against Iran’s\ncomputer systems, he was also announcing new federal initiatives to secure\ncyberspace and critical infrastructure in the United States—to protect them,\nthat is, from the very sort of destruction that Stuxnet\nproduced.[38](part0020.html#c16-ftn38) The nation’s digital infrastructure was\na strategic national asset, he said during a speech weeks after his\ninauguration, and protecting it was a national security priority. “We will\nensure that these networks are secure, trustworthy and resilient,” he said.\n“We will deter, prevent, detect and defend against attacks and recover quickly\nfrom any disruptions or damage.”[39](part0020.html#c16-ftn39)\n\nWhile Obama was reauthorizing the covert operation, its details were already\nat risk of being exposed. It was no secret that the United States and its\nallies were engaged in efforts to sabotage Iran’s nuclear program. In February\n2009, the _Telegraph_ in London reported that Israel had launched an extensive\ncovert war against Iran’s nuclear program that included hit men, front\ncompanies, double agents, and sabotage.[40](part0020.html#c16-ftn40) In the\narticle, a former CIA officer seemed to hint at Stuxnet’s existence by\nrevealing that the sabotage was designed to slow the progress of the program\nin such a way that the Iranians would never know what caused it. The goal, he\nsaid, was to “delay, delay, delay until you can come up with some other\nsolution or approach.… It’s a good policy, short of taking them out\nmilitarily, which probably carries unacceptable risks.”\n\nAround the same time, the _New York Times_ also revealed that a new covert\ncampaign against Iran had been launched, but didn’t go into\ndetail.[41](part0020.html#c16-ftn41)\n\nIt’s unclear if the Iranians saw these news stories or, if they did, connected\nthem to the problems they were having at Natanz. They were certainly well\naware of the risks of sabotage, having already experienced it in 2006 with the\npower regulators from Turkey. But suspecting that something was being\nsabotaged was one thing. Homing in on the part or component that was causing\nit was another.\n\nAs the attackers were preparing to launch the next version of Stuxnet, Obama\nmade good on another of the campaign pledges he’d made with regard to Iran.\nDuring the campaign, he had promised to engage in more robust diplomacy with\nthe Islamic Republic. As part of this promise, he made the unprecedented move\nof directly addressing the Muslim world during his televised inauguration\nspeech. “We seek a new way forward, based on mutual interest and mutual\nrespect,” he said. “To those leaders around the globe who seek to sow\nconflict, or blame their society’s ills on the West—know that your people will\njudge you on what you can build, not what you\ndestroy.”[42](part0020.html#c16-ftn42)\n\nHe addressed Iranians directly again on March 20, when he appealed to the\nIslamic Republic’s leaders and its people in a speech broadcast through _Voice\nof America_ on Nowruz, the Persian New Year.\n\n“In this season of new beginnings, I would like to speak clearly to Iranian\nleaders,” he said. The United States was interested in pursuing constructive\nties with Iran that were “honest and grounded in mutual respect,” he said, and\nwas seeking a future in which the Iranian people, their neighbors, and the\nwider international community could live “in greater security and greater\npeace.” He closed his address with a quote from the Persian poet Saadi: “The\nchildren of Adam are limbs to each other, having been created of one essence.”\nThe United States, he said, was prepared to extend a hand in friendship and\npeace, “if you are willing to unclench your\nfist.”[43](part0020.html#c16-ftn43)\n\nBut while Obama was extending one metaphorical hand in peace to the Iranian\npeople, other hands were preparing a new round of digital attacks on Natanz.\n\n* * *\n\n[1](part0020.html#c16-ftn1a) The comment appeared in a post about\nAhmadinejad’s tour published on the Arms Control Wonk website. William J.\nBroad, “A Tantalizing Look at Iran’s Nuclear Program,” _New York Times_ ,\nApril 29, 2008.\n\n[2](part0020.html#c16-ftn2a) It took only a day or two for a batch of gas to\nrun through a cascade and finish enriching, according to Albright, but\ncentrifuges spin nonstop for years as new batches of gas are constantly fed\ninto them.\n\n[3](part0020.html#c16-ftn3a) Joby Warrick, “U.S. Is Said to Expand Covert\nOperations in Iran,” _Washington Post_ , June 30, 2008.\n\n[4](part0020.html#c16-ftn4a) The code that infected the OB1 and OB35 blocks in\nthe PLCs—organizational blocks that controlled the reading of commands on the\nPLCs and the alarm system—had a compilation date of February 7, 2001. The code\nthat sabotaged the frequency converters and manipulated the valves had similar\ntimestamps. For example, there were thirty blocks of code in the 315 attack\nthat sabotaged the Vacon and Fararo Paya frequency converters; two of these\nappeared to have been compiled in May 2000, while the timestamp for the\nremaining blocks was September 23, 2001. The code blocks used to manipulate\nthe valves in the 417 attack had a timestamp from the same September day,\nthough three hours later, as if the person compiling them had taken a dinner\nbreak, then returned to finish the job.\n\n[5](part0020.html#c16-ftn5a) As noted previously, cascades are configured into\na number of enrichment stages, with each stage containing a different number\nof centrifuges, depending on how many are needed for that stage in the\nenrichment process.\n\n[6](part0020.html#c16-ftn6a) Author interview with Albright, November 2013.\nThe first module of cascades, known as A24, is believed to have been struck by\nStuxnet version 0.5, which targeted only valves on the centrifuges, not the\nfrequency converters. Later versions that targeted the frequency converters\nare believed to have focused on a different module, A26, which Iran began\ninstalling in late 2007 or early 2008.\n\n[7](part0020.html#c16-ftn7a) Iran has accused the IAEA of providing the United\nStates and Israel with intelligence about its nuclear program. But even if the\nIAEA didn’t provide information willingly, hacking IAEA computers to obtain\ninformation about Natanz was an option for Western and Israeli intelligence\nagencies. Recent news stories have revealed how US intelligence agencies spied\non the UN Security Council, the IAEA’s umbrella organization, and hacked into\nthe videoconferencing system of the UN to glean information about UN\nactivities.\n\n[8](part0020.html#c16-ftn8a) See [this page](part0021.html#page340) for more\ninformation about Neda.\n\n[9](part0020.html#c16-ftn9a) The contents of the document dated May 4, 2003,\nand titled, “Related to a PLC device Siemens TTE sold to Kimian Madaan [_sic_]\nfor G’chin mine” was shared with me by someone who was given access to it. The\nletter was from Tehran Tamman Engineering to Kimia Maadan and indicated that\nIran had obtained hardware and software for monitoring and controlling a\nSIMATIC S7-300 PLC in 2002. The next year, according to the document, Iran\nobtained another S7-300 and two S7-400s, as well as Siemens SIMATIC WinCC\nsoftware to monitor the PLCs. The equipment was described in the letter as a\n“computerized system to monitor and control industrial process via information\nreceived from physical measurement transmitters, such as pressure,\ntemperature, and controllers on valves, heating/cooling, using specialized\nsoftware.” The description closely matches what a control system for a cascade\nwould do.\n\n[10](part0020.html#c16-ftn10a) When Stuxnet was discovered in 2010 and it was\nrevealed that the digital weapon was attacking Siemens controllers, many in\nthe public wondered if Iran even had Siemens controllers installed at Natanz.\nBut just the previous year, the British Navy had intercepted a secret shipment\nof 111 boxes of Siemens controllers at a port in Dubai that were apparently\nbound for Iran’s uranium enrichment program. Siemens had shipped them to a\nbuyer in China, where they were forwarded to Iran through Dubai. The discovery\nof the shipment caused a bit of an international incident—since the sale of\ntechnology for Iran’s nuclear program is banned under UN sanctions—and\neventually forced Siemens to announce in early 2010 that it would initiate no\nnew business in Iran after the summer of 2010.\n\n[11](part0020.html#c16-ftn11a) David E. Sanger and Thom Shanker, “N.S.A.\nDevises Radio Pathway into Computers,” _New York Times_ , January 14, 2014.\n\n[12](part0020.html#c16-ftn12a) In 2011, Ralph Langner suggested that tests the\nIdaho National Lab conducted in the summer of 2008 on the Siemens PCS7\nsystem—which included the Step 7 and WinCC software and S7-400 PLCs—were used\nto uncover vulnerabilities for Stuxnet to attack. The tests were done as part\nof the lab’s vendor-assessment program, whereby researchers examined various\nindustrial control systems for security vulnerabilities. Langner first\nsuggested the INL tests played a role in developing Stuxnet after he uncovered\na PowerPoint presentation that INL had produced about the tests. But the INL\ntests were conducted between July and September 2008, and we now know that the\nearliest-discovered version of Stuxnet—Stuxnet 0.5—had been developed before\nthese tests occurred and was already in the wild in November 2007, when\nsomeone had uploaded it to the VirusTotal website. And if the timestamp on\nStuxnet’s rogue Step 7 .DLL is to be believed, it was compiled in 2006. INL\nleaders insisted to reporters during a tour of the lab in 2011, in which the\nauthor participated, that it did not provide information about vulnerabilities\nin the Siemens system to anyone to develop Stuxnet.\n\n[13](part0020.html#c16-ftn13a) It’s been suggested by some that Germany and\nGreat Britain, two countries in the Urenco consortium that produced the\noriginal centrifuges that served as the design for Iran’s IR-1s, may have\nprovided some assistance with understanding the centrifuges.\n\n[14](part0020.html#c16-ftn14a) The numbers vary depending on the account. The\nUnited States told reporters that Libya had been caught with 4,000\ncentrifuges, but by ISIS’s count, it was more like 200. The rest were simply\ncomponents for centrifuges—the casings were there (the hollow aluminum\ncylinder) as well as other components, but they were missing the rotors to\nmake them work.\n\n[15](part0020.html#c16-ftn15a) Jody Warrick, “U.S. Displays Nuclear Parts\nGiven by Libya,” _Washington Post_ , March 15, 2004.\n\n[16](part0020.html#c16-ftn16a) William J. Broad, John Markoff, and David E.\nSanger, “Israeli Test on Worm Called Crucial in Iran Nuclear Delay,” _New York\nTimes_ , January 15, 2011.\n\n[17](part0020.html#c16-ftn17a) Oak Ridge sits on former farmland, and “chicken\nranch” may refer to a real chicken ranch that existed on the land in the 1940s\nbefore the farmers were displaced when the government bought up their land for\nthe war effort.\n\n[18](part0020.html#c16-ftn18a) The NNSA is housed at Oak Ridge in the Multi-\nProgram Research Facility, or MRF, a large SIGINT facility that contains a\nsupercomputer in its basement that is used in part for doing data mining for\nthe NSA. Other staff at the MRF, many of them former CIA and NSA employees,\nare technically astute and work on various other compartmentalized programs,\nincluding efforts to crack encryption and data fusion—what workers sometimes\ncall “data diarrhea”—which involves fusing data from various branches of\nintelligence around the world.\n\n[19](part0020.html#c16-ftn19a) Various methods are used to do this, such as\nexamining gas plumes from suspect factories for trace particles or measuring\nthe temperature of water near suspect sites. Many nuclear facilities are built\nnear rivers and other water sources and the temperature of the water can be\nindicative of nuclear activity. Another method involves measuring the\nflickering of lights in factory windows from long distances. Since centrifuges\noperate at specific frequencies, the pattern in flickering lights can\nsometimes provide clues as to the presence and kind of centrifuges being used\nin a building.\n\n[20](part0020.html#c16-ftn20a) David E. Sanger, _Confront and Conceal_ (New\nYork: Crown, 2012), 197.\n\n[21](part0020.html#c16-ftn21a) Given that the first version of Stuxnet\nappeared in the field in November 2007, it suggests the sabotage might have\nbegun that year. David Sanger writes that multiple versions of the worm were\nreleased while Bush was still in office; only one version from that period has\nbeen found by researchers. The others date from Obama’s term in office.\n\n[22](part0020.html#c16-ftn22a) In 2008, Iran hanged an Iranian electronics\nvendor named Ali Ashtari, who Iranian news reports say confessed to trying to\nintroduce Mossad-produced viruses and GPS units into equipment used by members\nof the Revolutionary Guard. After Stuxnet was discovered, there were reports\nthat said he helped get Stuxnet into Natanz. But news from Iran is often\nunreliable, since it generally comes from state-affiliated publications with\nan agenda. Over the years Iran has accused many people of being spies for the\nMossad, often with little evidence to support the claim.\n\n[23](part0020.html#c16-ftn23a) Stuxnet 0.5 expected its target, for example,\nto have between two and twenty-five auxiliary valves and between three and\nthirty pressure transducers for measuring the gas pressure at each stage of\nthe cascade.\n\n[24](part0020.html#c16-ftn24a) Together, various systems constantly monitor\nthe flow of electricity to the centrifuges, their speed and vibration, as well\nas the gas pressure and temperature, and the temperature of water used to heat\nor cool them.\n\n[25](part0020.html#c16-ftn25a) The IAEA inspectors visited Natanz about\ntwenty-four times a year. Every three months, the inspectors published a\nreport listing the number of centrifuges during their most recent visit that\nwere spinning and under vacuum—but did not yet have gas in them—and the number\nthat were actually enriching gas. The reports also tracked how much gas the\ntechnicians fed into the cascades, and how much enriched uranium was produced\nfrom it.\n\n[26](part0020.html#c16-ftn26a) See [note 29](part0019.html#c15-ftn29) for\nprevious discussion of the setup of Hall A, and Stuxnet’s precise knowledge of\nit. Iran would later increase the number of centrifuges per cascade in\nNovember 2010, but until then, the number of centrifuges per cascade remained\nconstant at 164.\n\n[27](part0020.html#c16-ftn27a) IAEA Report to the Board of Governors,\n“Implementation of the NPT Standards Agreement and Relevant Provisions of\nSecurity Council Resolution 1737 (2006) in the Islamic Republic of Iran,”\nFebruary 22, 2007, available at\n[iaea.org/Publications/Documents/Board/2007/gov2007-08.pdf](http://www.iaea.org/Publications/Documents/Board/2007/gov2007-08.pdf).\n\n[28](part0020.html#c16-ftn28a) IAEA Report to the Board of Governors,\n“Implementation of the NPT Safeguards Agreement and Relevant Provisions of\nSecurity Council Resolutions 1737 (2006) and 1747 (2007) in the Islamic\nRepublic of Iran,” November 15, 2007, available at\n[iaea.org/Publications/Documents/Board/2007/gov2007-58.pdf](http://www.iaea.org/Publications/Documents/Board/2007/gov2007-58.pdf).\n\n[29](part0020.html#c16-ftn29a) An IAEA official told ISIS privately about the\nbreaking centrifuges and the lost gas.\n\n[30](part0020.html#c16-ftn30a) David Albright, Jacqueline Shire, and Paul\nBrannan, “Is Iran Running Out of Yellowcake?,” Institute for Science and\nInternational Security, February 11, 2009, available at <http://isis-\nonline.org/publications/iran/Iran_Yellowcake.pdf>; Barak Ravid, “Israel Slams\nClinton Statement on Nuclear Iran,” _Ha’aretz_ , July 22, 2009; Mark\nFitzpatrick, “Statement Before the Senate Committee on Foreign Relations,”\nMarch 3, 2009, available at [iranwatch.org/sites/default/files/us-sfrc-\nfitzpatrick-\niranrealities-030309.pdf](http://www.iranwatch.org/sites/default/files/us-\nsfrc-fitzpatrick-iranrealities-030309.pdf).\n\n[31](part0020.html#c16-ftn31a) In addition to the eighteen cascades in A24\nthat were being fed gas, five cascades in A26 were being fed gas, another\ncascade was under vacuum, and construction on the remaining twelve cascades in\nthat module was continuing. See IAEA Board of Governors Report,\n“Implementation of the NPT Safeguards Agreement and Relevant Provisions of\nSecurity Council Resolutions 1737 (2006), 1747 (2007) and 1803 (2008) in the\nIslamic Republic of Iran,” September 15, 2008, available at\n[iaea.org/Publications/Documents/Board/2008/gov2008-38.pdf](http://www.iaea.org/Publications/Documents/Board/2008/gov2008-38.pdf).\n\n[32](part0020.html#c16-ftn32a) Author interview with Albright, January 2012.\n\n[33](part0020.html#c16-ftn33a) David Albright, Jacqueline Shire, and Paul\nBrannan, “IAEA Report on Iran: Centrifuge Operation Significantly Improving;\nGridlock on Alleged Weaponization Issues,” September 15, 2008, available at\n[isis-\nonline.org/publications/iran/ISIS_Report_Iran_15September2008.pdf](http://www.isis-\nonline.org/publications/iran/ISIS_Report_Iran_15September2008.pdf).\n\n[34](part0020.html#c16-ftn34a) Yadegari was convicted, and an explanation from\nthe Ontario Court of Justice detailing the reasons for his conviction can be\nfound on the website of the Institute for Science and International Security:\n[isis-online.org/uploads/isis-\nreports/documents/Yadegari_Reasons.pdf](http://www.isis-\nonline.org/uploads/isis-reports/documents/Yadegari_Reasons.pdf).\n\n[35](part0020.html#c16-ftn35a) Broad, Markoff, and Sanger, “Israeli Test on\nWorm Called Crucial in Iran Nuclear Delay.”\n\n[36](part0020.html#c16-ftn36a) Mike Shuster, “Inside the United States’ Secret\nSabotage of Iran,” [NPR.org](http://www.NPR.org), May 9, 2011, available at\n[npr.org/2011/05/09/135854490/inside-the-united-states-secret-sabotage-of-\niran](http://www.npr.org/2011/05/09/135854490/inside-the-united-states-secret-\nsabotage-of-iran). The meeting between President Bush and Barack Obama is\ndescribed by Sanger, _Confront and Conceal_ , 200–3.\n\n[37](part0020.html#c16-ftn37a) Rebecca Harrison, “Obama Says Nuclear Iran\nPoses ‘Grave Threat,’ ” Reuters, July 23, 2008, available at\n[reuters.com/article/2008/07/23/us-Iran-usa-Obama-\nidUSL23104041320080723](http://www.reuters.com/article/2008/07/23/us-Iran-usa-\nObama-idUSL23104041320080723).\n\n[38](part0020.html#c16-ftn38a) In May that year, he announced the creation of\na cybersecurity czar position to help secure US critical infrastructure\nagainst cyberattacks.\n\n[39](part0020.html#c16-ftn39a) Kim Zetter, “Obama Says New Cyberczar Won’t Spy\non the Net,” _Wired_ , May 29, 2009, available at\n[wired.com/threatlevel/2009/05/netprivacy](http://www.wired.com/threatlevel/2009/05/netprivacy).\n\n[40](part0020.html#c16-ftn40a) Philip Sherwell, “Israel Launches Covert War\nAgainst Iran,” _Telegraph_ , February 16, 2009.\n\n[41](part0020.html#c16-ftn41a) David Sanger, “U.S. Rejected Aid for Israeli\nRaid on Iranian Nuclear Site,” _New York Times_ , January 10, 2009.\n\n[42](part0020.html#c16-ftn42a) See [whitehouse.gov/blog/inaugural-\naddress](http://www.whitehouse.gov/blog/inaugural-address).\n\n[43](part0020.html#c16-ftn43a) See\n[whitehouse.gov/the_press_office/videotaped-remarks-by-the-president-in-\ncelebration-of-nowruz](http://www.whitehouse.gov/the_press_office/videotaped-\nremarks-by-the-president-in-celebration-of-nowruz).\n\n\n# CHAPTER 17\n\n# **THE MYSTERY OF THE CENTRIFUGES**\n\nThe two weeks leading up to the release of the next attack were tumultuous\nones in Iran. On June 12, 2009, the presidential elections between incumbent\nMahmoud Ahmadinejad and challenger Mir-Hossein Mousavi didn’t turn out the way\nmost expected. The race was supposed to be close, but when the results were\nannounced—two hours after the polls closed—Ahmadinejad had won with 63 percent\nof the vote over Mousavi’s 34 percent. The electorate cried foul, and the next\nday crowds of angry protesters poured into the streets of Tehran to register\ntheir outrage and disbelief. According to media reports, it was the largest\ncivil protest the country had seen since the 1979 revolution ousted the shah,\nand it wasn’t long before it became violent. Protesters vandalized stores and\nset fire to trash bins, while police and Basijis, government-loyal militias in\nplainclothes, tried to disperse them with batons, electric prods, and bullets.\n\nThat Sunday, Ahmadinejad gave a defiant victory speech, declaring a new era\nfor Iran and dismissing the protesters as nothing more than soccer hooligans\nsoured by the loss of their team. The protests continued throughout the week,\nthough, and on June 19, in an attempt to calm the crowds, the Ayatollah Ali\nKhamenei sanctioned the election results, insisting that the margin of\nvictory—11 million votes—was too large to have been achieved through fraud.\nThe crowds, however, were not assuaged.\n\nThe next day, a twenty-six-year-old woman named Neda Agha-Soltan got caught in\na traffic jam caused by protesters, and was shot in the chest by a sniper’s\nbullet after she and her music teacher stepped out of their car to observe.\n\nTwo days later on June 22, a Monday, the Guardian Council, which oversees\nelections in Iran, officially declared Ahmadinejad the winner, and after\nnearly two weeks of protests, Tehran became eerily quiet. Police had used tear\ngas and live ammunition to disperse the demonstrators, and most of them were\nnow gone from the streets. That afternoon, at around four thirty p.m. local\ntime, as Iranians nursed their shock and grief over events of the previous\ndays, a new version of Stuxnet was being compiled and\nunleashed.[1](part0021.html#c17-ftn1)\n\nWHILE THE STREETS of Tehran had been in turmoil, technicians at Natanz had\nbeen experiencing a period of relative calm. Around the first of the year,\nthey had begun installing new centrifuges again, and by the end of February\nthey had about 5,400 of them in place, close to the 6,000 that Ahmadinejad had\npromised the previous year. Not all of the centrifuges were enriching uranium\nyet, but at least there was forward movement again, and by June the number had\njumped to 7,052, with 4,092 of these enriching gas.[2](part0021.html#c17-ftn2)\nIn addition to the eighteen cascades enriching gas in unit A24, there were now\ntwelve cascades in A26 enriching gas. An additional seven cascades had even\nbeen installed in A28 and were under vacuum, being prepared to receive gas.\n\nThe performance of the centrifuges was improving too. Iran’s daily production\nof low-enriched uranium was up 20 percent and remained consistent throughout\nthe summer of 2009.[3](part0021.html#c17-ftn3) Despite the previous problems,\nIran had crossed a technical milestone and had succeeded in producing 839 kg\nof low-enriched uranium—enough to achieve nuclear-weapons breakout\ncapability.[4](part0021.html#c17-ftn4) If it continued at this rate, Iran\nwould have enough enriched uranium to make two nuclear weapons within a\nyear.[5](part0021.html#c17-ftn5) This estimate, however, was based on the\ncapacity of the IR-1 centrifuges currently installed at Natanz. But Iran had\nalready installed IR-2 centrifuges in a small cascade in the pilot plant, and\nonce testing on these was complete and technicians began installing them in\nthe underground hall, the estimate would have to be revised. It took 3,000\nIR-1s to produce enough uranium for a nuclear weapon in one year, but it would\ntake just 1,200 IR-2 centrifuges to do the same.\n\nCue Stuxnet 1.001, which showed up in late June.\n\nTo get their weapon into the plant, the attackers launched an offensive\nagainst computers owned by four companies. All of the companies were involved\nin industrial control and processing of some sort, either manufacturing\nproducts and assembling components or installing industrial control systems.\nThey were all likely chosen because they had some connection to Natanz as\ncontractors and provided a gateway through which to pass Stuxnet to Natanz\nthrough infected employees.\n\nTo ensure greater success at getting the code where it needed to go, this\nversion of Stuxnet had two more ways to spread than the previous one. Stuxnet\n0.5 could spread only by infecting Step 7 project files—the files used to\nprogram Siemens PLCs. This version, however, could spread via USB flash drives\nusing the Windows Autorun feature or through a victim’s local network using\nthe print-spooler zero-day exploit that Kaspersky and Symantec later found in\nthe code.\n\nBased on the log files in Stuxnet, a company called Foolad Technique was the\nfirst victim. It was infected at 4:40 a.m. on June 23, a\nTuesday.[6](part0021.html#c17-ftn6) But then it was almost a week before the\nnext company was hit.\n\nThe following Monday, about five thousand marchers walked silently through the\nstreets of Tehran to the Qoba Mosque to honor victims killed during the recent\nelection protests. Late that evening, around 11:20 p.m., Stuxnet struck\nmachines belonging to its second victim—a company called Behpajooh.\n\nIt was easy to see why Behpajooh was a target. It was an engineering firm\nbased in Esfahan—the site of Iran’s new uranium conversion plant, built to\nturn milled uranium ore into gas for enriching at Natanz, and was also the\nlocation of Iran’s Nuclear Technology Center, which was believed to be the\nbase for Iran’s nuclear weapons development program. Behpajooh had also been\nnamed in US federal court documents in connection with Iran’s illegal\nprocurement activities.[7](part0021.html#c17-ftn7)\n\nBehpajooh was in the business of installing and programming industrial control\nand automation systems, including Siemens systems. The company’s website made\nno mention of Natanz, but it did mention that the company had installed\nSiemens S7-400 PLCs, as well as the Step 7 and WinCC software and Profibus\ncommunication modules at a steel plant in Esfahan. This was, of course, all of\nthe same equipment Stuxnet targeted at Natanz.\n\nAt five a.m. on July 7, nine days after Behpajooh was hit, Stuxnet struck\ncomputers at Neda Industrial Group, as well as a company identified in the\nlogs only as CGJ, believed to be Control Gostar Jahed. Both companies designed\nor installed industrial control systems.\n\nNeda designed and installed control systems, precision instrumentation, and\nelectrical systems for the oil and gas industry in Iran, as well as for power\nplants and mining and process facilities. In 2000 and 2001 the company had\ninstalled Siemens S7 PLCs in several gas pipeline operations in Iran and had\nalso installed Siemens S7 systems at the Esfahan Steel\nComplex.[8](part0021.html#c17-ftn8) Like Behpajooh, Neda had been identified\non a proliferation watch list for its alleged involvement in illicit\nprocurement activity and was named in a US indictment for receiving smuggled\nmicrocontrollers and other components.[9](part0021.html#c17-ftn9)\n\nAbout two weeks after it struck Neda, a control engineer who worked for the\ncompany popped up on a Siemens user forum on July 22 complaining about a\nproblem that workers at his company were having with their machines. The\nengineer, who posted a note under the user name Behrooz, indicated that all\nPCs at his company were having an identical problem with a Siemens Step 7 .DLL\nfile that kept producing an error message. He suspected the problem was a\nvirus that spread via flash drives.[10](part0021.html#c17-ftn10)\n\nWhen he used a DVD or CD to transfer files from an infected system to a clean\none, everything was fine, he wrote. But when he used a flash drive to transfer\nfiles, the new PC started having the same problems the other machine had. A\nUSB flash drive, of course, was Stuxnet’s primary method of spreading.\nAlthough Behrooz and his colleagues scanned for viruses, they found no malware\non their machines. There was no sign in the discussion thread that they ever\nresolved the problem at the time.\n\nIt’s not clear how long it took Stuxnet to reach its target after infecting\nmachines at Neda and these other companies, but between June and August the\nnumber of centrifuges enriching uranium at Natanz began to drop. Whether this\nwas the result solely of the new version of Stuxnet or the lingering effects\nof the previous version is unknown. But by August that year, only 4,592\ncentrifuges were enriching at the plant, a decrease of 328 centrifuges since\nJune. The problem, again, was in unit A26, where previous issues had occurred.\nIn June, there had been twelve cascades in this unit enriching gas. But by\nNovember, gas had been removed from half of them and only six of the A26\ncascades were now enriching. The total number of centrifuges enriching at\nNatanz had dropped to 3,936, a decrease of 984 in five months. What’s more,\nalthough new machines were still being installed, none of them were being fed\ngas. In A28 as well, seventeen cascades were now installed, but none of these\nnearly 3,000 centrifuges was enriching gas.\n\nClearly there were problems with the cascades, and technicians had no idea\nwhat they were. The changes mapped precisely, however, to what Stuxnet was\ndesigned to do.\n\nThis version of Stuxnet, as mentioned previously, increased the frequency of\nthe centrifuge rotors to 1,410 Hz for fifteen minutes—a speed of almost 1,000\nmiles per hour—then after three weeks decreased it to 2 Hz for fifty\nminutes.[11](part0021.html#c17-ftn11) The changes, after a number of cycles,\nwould have begun to damage the centrifuges and affect the level of enrichment\nin the gas.\n\nBut Albright and his colleagues determined that it would have taken the\ncentrifuge motors longer than fifteen minutes to reach 1,410 Hz—the frequency\nthat would have been most damaging to the centrifuges. They likely would only\nhave reached 1,324 to 1,381 Hz in that time. Nonetheless, as the varying speed\nand constant acceleration and deceleration continued over time, it would have\ncreated incremental stress and damage to the centrifuge rotors. The increased\nspeed would also have caused the aluminum centrifuges to expand and become\nimbalanced.\n\nThe IR-1s were already fragile by design, and the slightest imperfection could\nset them off—dust in the chamber, for example, could cause them to self-\ndestruct. The head of Iran’s Atomic Energy Organization, Gholam Reza\nAghazadeh, revealed during an interview in 2006 that in the early days of the\nenrichment program, the IR-1s had disintegrated frequently due to _germs_ on\nthe machine. Initially, they couldn’t figure out why the centrifuges were\nexploding, but he said they ultimately attributed the problem to technicians\nassembling the centrifuges without gloves. Microbes left behind on the\nmachines literally pulverized them once the machines began to spin. “When we\nsay a machine is destroyed,” he told the interviewer, “we mean that it turns\ninto powder.”[12](part0021.html#c17-ftn12)\n\nThe centrifuges had bearings at their top and base that helped keep them\nsteady, like a spinning top.[13](part0021.html#c17-ftn13) A spinning\ncentrifuge had to be brought up to speed slowly. Once it was going, it was\nbeautiful and elegant to watch. But in the blink of an eye everything could go\nwrong. If a centrifuge began to wobble, it would spiral quickly out of\ncontrol. The centrifuge casing itself was hefty and wouldn’t shatter, but it\nmight split lengthwise, like a hot dog in a microwave, or bend and cause the\ncaps at each end to blow out. And inside the casing, the rotor and other\ncomponents would break apart.\n\nThe increased speed caused by Stuxnet could have induced vibrations that would\nhave eventually worn down the bearings after a number of attack cycles,\ncausing the centrifuges to become imbalanced and topple. But with false data\nbeing fed back to operators, they wouldn’t have seen the destruction coming or\nhave been able to figure out in the aftermath what had gone wrong.\n\nThe second attack sequence, which reduced the frequency of the centrifuges to\n2 Hz for fifty minutes, made it appear the attackers were also trying to\ndegrade the enriched uranium, not just damage the centrifuges. A centrifuge\nspinning at 1,064 Hz would take time to slow down to 2 Hz. In fifty minutes,\nit would likely only decrease to about 864 Hz, Albright and his team\ndetermined, before the sabotage ended and the speed returned to normal. But by\nreducing the speed of a centrifuge even just 50 to 100 Hz, Stuxnet could\nreduce the enrichment by half. In uranium enrichment, centrifuges need to spin\nconsistently at high speed to separate the U-235 and U-238 isotopes in the\ngas. If the speed varies, particularly if it slows for fifty minutes, this\ndisrupts the separation process. Technicians at Natanz would have been\nexpecting to get one grade of uranium from the cascade but would have received\nsomething else instead. This effect was much more subtle than destroying\ncentrifuges outright, and would not have been enough on its own to slow Iran’s\nprogram. But combined with the other effects, it worked to sabotage the\nprogram from a different angle. In this attack sequence not only was the\npercentage of the enrichment affected, but the volume of the enriched uranium\nthat was produced became erratic. In February 2009, the centrifuges had been\nproducing about .62 separative work units, but in May this had dropped to .49.\nAnd in June and August, it varied between .51 and .55.\n\nBack in the United States, Albright and his colleagues at ISIS read the IAEA\nreports, noting the changes at Natanz, and weren’t surprised to see that Iran\nwas having problems, given how rapidly technicians had installed the cascades\nin unit A26. He learned from sources that technicians at Natanz had reduced\nthe speed of the centrifuges in an effort to address the problems, but\nAlbright suspected that something more than routine breakage and technical\ndifficulties was going on. He contacted sources in the government and at the\nIAEA to get a reading on what was happening but got no definitive answers.\n\nAs 2010 arrived, the numbers at Natanz continued to drop. The number of\ninstalled centrifuges was at 8,692, but the number of centrifuges actively\nenriching uranium now was down to 3,772, a drop of 1,148 since June. Until\nnow, the problems had been confined to A26, but now they appeared to be\nspreading to A24 and A28 as well. The gas had been removed from one cascade in\nA24, for example.[14](part0021.html#c17-ftn14)\n\nMost telling, however, was the fact that technicians had begun to disconnect\nand remove centrifuges from some of the cascades. In August, the IAEA had\ninstalled more cameras in the underground hall to keep pace with the\nfacility’s growth as technicians installed more cascades. Now they were\ncapturing images of workers scurrying about as they removed centrifuges from\nthe units. In January, the IAEA reported that technicians had removed an\nunspecified number of centrifuges from eleven of the cascades in A26 and had\nalso removed all 164 centrifuges from a cascade in A28. None of the remaining\nsixteen cascades in A28 were enriching.[15](part0021.html#c17-ftn15) The\n_Washington Post_ would later report that 984 centrifuges were replaced during\nthis period, the equivalent of six entire cascades.\n\nBut Stuxnet’s work still wasn’t done.\n\nAS 2009 CAME to a close, pressure on the United States to halt Iran’s nuclear\nprogram was growing.\n\nIn late September, while the numbers at Natanz were dropping, President Obama\nannounced at the UN Security Council Summit on Nuclear Nonproliferation and\nNuclear Disarmament that a new secret uranium enrichment facility had been\ndiscovered in Iran. This one was located on a military base, buried more than\n150 feet beneath a mountain at Fordow, about 30 kilometers from the holy city\nof Qom.\n\nThe plant was much smaller than the one at Natanz and was designed to hold\nonly 3,000 centrifuges, compared to Natanz’s 47,000. But it was big enough to\nenrich uranium for one or two bombs a year, if Iran decided to use it for that\npurpose. “Iran has a right to peaceful nuclear power that meets the energy\nneeds of its people. But the size and configuration of this facility is\ninconsistent with a peaceful program,” Obama said during his announcement\nabout Fordow.[16](part0021.html#c17-ftn16)\n\nThe Iranians told the IAEA’s Mohamed ElBaradei that the plant was just a\nbackup for Natanz, that the threat of a military strike against Natanz had\nprompted them to build it as a contingency. The new plant was still under\nconstruction and wasn’t expected to be completed until 2011, but according to\nUS intelligence, work on it had likely begun sometime between 2002 and 2004,\nwhich meant IAEA inspectors had passed the secret site numerous times on their\nway to Natanz over the years without knowing of its existence. Obama learned\nabout the plant earlier that year during his pre-inauguration briefing at the\nWhite House, but intelligence agencies had known about it since at least 2007,\nwhen the head of Iran’s Revolutionary Guard defected to the West and told the\nCIA that Iran was building a second secret enrichment plant somewhere within\nits borders. Since then, satellite reconnaissance had uncovered the site at\nFordow.[17](part0021.html#c17-ftn17)\n\nThe Fordow plant, though smaller than Natanz, actually presented a much graver\ndanger than Natanz. With IAEA inspectors closely monitoring the latter site,\nit was unlikely Iran could secretly divert nuclear material from that plant to\nenrich it to weapons-grade material. Secret plants like Fordow, however, where\nweapons-grade enrichment could be done without the IAEA’s knowledge, were far\nmore worrying.\n\nFordow was also a particular concern because it was being built under more\nthan a hundred feet of solid rock, putting it out of reach of the current crop\nof bunker-busting bombs and possibly even a new generation of bombs the United\nStates was developing.[18](part0021.html#c17-ftn18)\n\nThe UK’s prime minister, Gordon Brown, responded to the news of Fordow by\ncalling Iran’s nuclear program “the most urgent proliferation challenge that\nthe world faces today.” He said that the international community had no choice\nbut to “draw a line in the sand” over Iran’s “serial deception of many\nyears.”[19](part0021.html#c17-ftn19)\n\nIranian officials, however, seemed unperturbed by the revelations about\nFordow, asserting defiantly that they planned to build ten more uranium\nenrichment plants in the coming decades to fuel a fleet of nuclear power\nplants they also planned to build.[20](part0021.html#c17-ftn20) The enrichment\nplants would all be buried deep under mountains to protect them from attack,\nthe head of the AEOI said.[21](part0021.html#c17-ftn21)\n\nIn the wake of the Fordow news, Israel became more insistent that something\nhad to be done about Iran’s nuclear program. At a November meeting in Tel\nAviv, an Israeli military leader told US officials that 2010 would be a\n“critical year” in the showdown with Iran. If they didn’t act soon, Iran would\nharden its nuclear sites, and it would become more and more difficult to take\nthem out.[22](part0021.html#c17-ftn22) The US had already secretly promised\nIsrael a shipment of the new generation of bunker-busting bombs it was\nproducing, but that ordnance was still six months away from delivery.\n\nIn January of 2010, the pressure mounted when a document leaked to the media\ndisclosed a secret military branch of Iran’s nuclear research program known as\nthe FEDAT. The branch was said to be headed by Mohsen Fakhrizadeh, a professor\nat Imam Hossein University in Tehran.[23](part0021.html#c17-ftn23) The next\nmonth, the IAEA indicated it had received “broadly consistent and credible”\ninformation that Iran had been developing nuclear weapons. “This raises\nconcerns about the possible existence in Iran of past or current undisclosed\nactivities related to the development of a nuclear payload for a\nmissile.”[24](part0021.html#c17-ftn24)\n\nOn top of this, negotiations meant to ease concerns over Iran’s growing\nstockpile of low-enriched uranium collapsed. For years, Iran had said it\nneeded the uranium to produce fuel rods for its research reactor in Tehran to\nconduct cancer research and oncology treatments, but the United States and\nothers had always been concerned that the uranium at some point would be\nfurther enriched for weapons. So in mid-2009, a White House adviser devised a\nclever compromise to resolve the West’s concerns over the uranium. Under the\nWhite House plan, Iran would send most of this low-enriched uranium to Russia\nand France so that these two countries could turn it into fuel rods for the\nIranian reactor. The proposal was an ingenious one because it would provide\nIran with all the fuel it said it needed for its reactor, while robbing\nIranian officials of the opportunity to further enrich their stockpile into\nweapons-grade material.\n\nIranian officials had said in 2009 that they needed time to consider the\nproposal. But on January 19, they announced that they were rejecting it. That\nwasn’t all. They also announced that they had already taken some of the low-\nenriched uranium produced in the underground hall at Natanz and begun to\nfurther enrich it to nearly 20 percent in the pilot plant—a level they said\nthey needed for medical research.[25](part0021.html#c17-ftn25)\n\nSix days later, the team behind Stuxnet began preparations for a new round of\nattacks.\n\nThroughout his first year in office, President Obama had kept close tabs on\nthe digital weapon’s progress. There was a lot riding on its success, and so\nfar the news had been good. In fact, it was better than expected. Even though\nStuxnet had targeted limited numbers of centrifuges, the Iranians were\nmagnifying its effects by disabling entire cascades of centrifuges in their\neffort to uncover the source of the problems, thus contributing to further\ndelays in their program. They still seemed to have no idea that the problems\nlay in the computers controlling their cascades, so there was no reason at\nthis point to stop the sabotage. Particularly when the pressure to take\nmilitary action against Iran was growing.\n\nSo on January 25, the attackers signed Stuxnet’s two driver files with the\ndigital certificate stolen from RealTek in Taiwan. On March 1, they compiled\ntheir code. Then they appeared to wait.\n\nOn March 20, Nowruz arrived, and Obama again delivered a pointed message about\npeaceful cooperation to the Iranian people as he’d done during the previous\nPersian New Year celebration. But this time, he spoke directly about Iran’s\nnuclear program. “Together with the international community, the United States\nacknowledges your right to peaceful nuclear energy—we insist only that you\nadhere to the same responsibilities that apply to other nations,” he said. “We\nare familiar with your grievances from the past—we have our own grievances as\nwell, but we are prepared to move forward. We know what you’re against; now\ntell us what you’re for.”\n\nHis tone grew darker as he made a veiled reference to Iran’s recent rejection\nof the compromise proposal for nuclear fuel. “Faced with an extended hand,”\nObama said, “Iran’s leaders have shown only a clenched\nfist.”[26](part0021.html#c17-ftn26)\n\nIn the weeks prior to his speech, Iranian technicians had been working hard to\nrecover from the problems created by Stuxnet, getting the number of cascades\nin unit A24 back up to capacity with all eighteen cascades enriching, and\nrestoring centrifuges they had removed from several cascades in A26. They also\nincreased the amount of gas they were feeding into the centrifuges that were\nstill operating to make up for the lost time and to increase the output of\nenriched gas. But they had no idea they were about to get hit again.\n\nCelebrations for the Persian New Year ran for thirteen days in Iran, though\nonly the first four days were an official public holiday. It was on March 23,\nthe fourth day of the holiday when most workers were still at home with their\nfamilies and friends, that the next wave of Stuxnet struck. The payload was\nidentical to the one unleashed the previous June, but this version included\nthe larger collection of zero-day exploits and other spreading mechanisms,\nincluding the .LNK exploit that ultimately led to its discovery.\n\nDespite all of these extra bells and whistles, however, the attackers appeared\nto target only a single company this time—Behpajooh. It’s not clear when they\nunleashed their code, but it struck the first machines at Behpajooh around six\na.m. on March 23. Behpajooh had been hit in the 2009 attack as well, and it\nwould be hit in a subsequent attack that struck the following month, in April\n2010. It was, in fact, the only company known to have been hit in all three\nrounds, suggesting it might have had a higher value as a conduit to reach the\ntarget computers at Natanz than the others. It was also, unfortunately, the\nvictim that launched thousands of other infections in and outside Iran.\n\nOver subsequent days, as vacationing workers returned to their offices, the\nworm began to replicate wildly, spreading first through Behpajooh’s offices in\nIran, the UK, and Asia before breaking free and infecting other companies in\nthose countries and beyond.[27](part0021.html#c17-ftn27) Later, when the\nSymantec researchers analyzed various samples of Stuxnet gathered from\ninfected computers, they were able to trace thousands of infections back to\nthese initial infections at Behpajooh.[28](part0021.html#c17-ftn28)\n\nWhy the attackers increased their firing power to reach their target at this\npoint is unclear. Perhaps the two years they’d spent inside Natanz’s computers\nhad merely made them reckless, overconfident. But the most likely explanation\nis that the earlier versions of Stuxnet had been delivered via an insider or\nsomeone with close access to the target machines. If Stuxnet’s creators had\nsubsequently lost this access, they would’ve felt the need to ramp up the\nspreading power to improve their chances of reaching their target. One piece\nof circumstantial evidence supporting this explanation is the different delays\nbetween when the attacks were compiled and when they infected their first\nvictims. In the June 2009 attack, only about twelve hours had passed between\nthe time the worm was compiled and when it struck its first\nvictim.[29](part0021.html#c17-ftn29) But the March 2010 version was compiled\non the morning of March 1, then didn’t infect its first machine until March\n23. (The last known version to be released, in April, had a similarly long\ndelay of twelve days between the compilation date and infection.) The short\ninfection time in 2009 suggested that the attackers may have used an inside\naccomplice or unwitting victim who had been preselected for the operation.\nWhen it came time to unleash subsequent versions of Stuxnet, the attackers may\nhave had to wait longer until an opportunity arose to unleash it.\n\nAs Stuxnet spread far and wide, it phoned home to its controllers via the\ncommand-and-control servers—and so it wasn’t long before officials in\nWashington learned that their worm had gone rogue. At that point it became\nclear that an operation that had been one of the most tightly held secrets in\nWashington for more than three years was suddenly at risk of being exposed.\n\nHow had a digital weapon so carefully crafted and controlled for so long come\nundone now? Fingers pointed to Israel initially. In the spring of 2010 the\nWhite House, the NSA, and the Israelis had reportedly “decided to swing for\nthe fences” with their sights on a specific group of 1,000 centrifuges they\nwanted to attack.[30](part0021.html#c17-ftn30) This likely was a group of six\ncascades in unit A26. The previous round of Stuxnet had reduced A26 from\ntwelve cascades enriching uranium to just six. It may have been these final\nsix that the attackers now wanted to take out. Six cascades of 164 centrifuges\neach added up to 984 centrifuges. The Israelis apparently added the final\ntouches—the extra zero days and other spreading mechanisms—in order to\nsupersize it. Sanger reports that sources told him that the worm was launched\ninside Natanz and escaped when an Iranian scientist connected his laptop to an\ninfected control computer at the plant and then carried the infection out on\nhis laptop to the internet. But this doesn’t correspond to the forensic\nevidence researchers found in the code. As previously noted, each sample of\nStuxnet contained a log file that tracked every machine it infected. These\nfiles showed that the first infections occurred at computers belonging to\nBehpajooh and the other companies, computers that appeared to be generic\nsystems, not programming computers inside Natanz that contained Step 7 files\nor the Siemens software. It was possible that these were laptops belonging to\ncontractors who were working inside Natanz. But Sanger also writes that the\nworm should have recognized when its environment changed and it landed on\nmachines outside of its target environment. There was nothing in any of the\nversions of Stuxnet that researchers examined, however, that served as a\nmechanism for recognizing this and preventing Stuxnet from spreading outside\nNatanz. The only limitations Stuxnet had were on where it ignited its payload,\nnot where it spread.\n\nIt’s important to note, however, that the operators who managed the command\nservers that communicated with Stuxnet _did_ have the ability to halt the\nspread of the weapon once they saw it getting out of control. Stuxnet had a\ndisinfect feature that allowed the attackers to remove it from an infected\nmachine. As Stuxnet began to spread wildly out of control and the attackers\nstarted seeing infected machines reporting in to their server from Indonesia,\nAustralia, and elsewhere, they could have sent out a disinfect command to\ndelete the code from those machines. There were a limited number of possible\nreasons that they didn’t do this. “Either they didn’t care that it was\nspreading or it was spreading faster than they expected and they couldn’t\nstrike it down,” says O’Murchu. O’Murchu doesn’t think it was due to\nincompetence. “They had total control over infected machines, and I think it\nwas a conscious decision to [do nothing].” Even after news of Stuxnet’s spread\nmade it back to Washington, a remarkable decision was made to let the\noperation continue with still no apparent attempt to halt its spread.\nAlthough, again, the details are murky, according to Sanger’s sources, at\nleast two more versions of Stuxnet were released after March, but were tweaked\nto remove the “bug” that caused the previous one to spread.\n\nOn April 14, the attackers did compile another version of Stuxnet, but the\npayload this time was exactly the same as the March one. Although the same\nspreading mechanisms were in this one, it didn’t spread as far and wide as the\nMarch version.[31](part0021.html#c17-ftn31) No other versions of Stuxnet\ndating after this have been found in the wild.\n\nIt’s possible that subsequent versions of Stuxnet were unleashed but were so\nmuch more tightly controlled that they’ve never been found. There was a hint\nof this when researchers found the random driver file in July 2010 that they\nthought was associated with Stuxnet. It was the driver discovered by ESET that\nhad been signed with the certificate from J-Micron. As noted, the driver was\nfound by itself, without any main Stuxnet file accompanying it, but it’s\nbelieved this may have been part of another Stuxnet attack.\n\nIn the April attack, Foolad Technique was the first victim that was hit, as it\nhad been in the June 2009 attack. The worm struck the company on April 26 and\nappeared to infect the same computer it had infected the previous year. Weeks\nlater on May 11, the digital weapon was unleashed on three computers belonging\nto a company using the domain name Kala, believed to be Kala Electric or Kala\nElectronics, the front company that Iran used to manage Natanz and secretly\nprocure components for its nuclear program—the same company that Alireza\nJafarzadeh had mentioned in his 2002 press conference exposing\nNatanz.[32](part0021.html#c17-ftn32) Behpajooh was hit with this same version\nof Stuxnet on May 13.\n\nNotably, although Neda Industrial Group doesn’t show up in the logs for the\n2010 infection samples that researchers examined, Behrooz, the control\nengineer who had posted to the Siemens user forum the previous year, popped up\nagain complaining of continued problems. On June 2, he wrote that all Windows\ncomputers at his company were still experiencing the same problem they had the\nprevious year.\n\nWorkers at other companies chimed in to say that they, too, were having the\nsame problem. One user, who also wrote that all of the PCs at his company were\ninfected, said the problem appeared to be confined to Iran. “[B]ecause you can\nsee many people in Iran [on the forum] have the same problem from at least 1\n[month] ago,” he wrote. The discussion continued throughout July, with Behrooz\nso frustrated at times that he ended some of his messages with an angry, red-\nfaced emoticon. Then suddenly, on July 24, he posted a message saying finally\nthe mystery had been solved. He included a link to a news article about\nStuxnet, which had recently been publicly exposed, and ended his message with\nthree grinning emoticons. Of course it would be several more months before he\nand the rest of the world learned what it was targeting.\n\nUNLIKE THE 2009 assault, it’s unclear what effect the attacks in 2010 had on\nNatanz. Sanger writes that after the attackers unleashed a third version of\nStuxnet in 2010, it caused 984 centrifuges to come “to a screeching\nhalt.”[33](part0021.html#c17-ftn33) As noted previously, there were at this\ntime exactly 984 centrifuges enriching in six cascades in unit A26, but there\nis no indication in IAEA reports that they stopped enriching. In September,\nthere were still six cascades in unit A26 enriching gas and another six\nspinning under vacuum. It’s possible that the centrifuges in question did halt\nand then recovered or were replaced at some point between the IAEA’s May and\nSeptember reports. It’s also possible that Sanger’s sources confused the dates\nand were referring to the 1,000 or so centrifuges that technicians removed in\nlate 2009 and early 2010 that the IAEA had captured with their cameras.\n\nIt’s difficult to know what exactly occurred with the centrifuges in 2010\nbecause in June that year, officials in Iran began accusing the IAEA of\nleaking information to the press about its operations. In a June 3 letter,\nIran warned the agency that if confidential information about the nuclear\nprogram “leaks, in any way, and/or [is] conveyed to the media,” there would be\nconsequences, the first being that Iran would withdraw its approval for some\nof the IAEA inspectors who were allowed to visit its nuclear\nfacilities.[34](part0021.html#c17-ftn34) That same month, Iran made good on\nthe threat and removed two names from its approved list of about 150 IAEA\ninspectors, citing “false and wrong statements” the IAEA had made in its May\nreport. The report had claimed that some nuclear equipment had gone missing in\nIran. Then in September, two more inspectors were banned, on grounds that they\nhad leaked information to the media before the IAEA had released it publicly\nin its report.[35](part0021.html#c17-ftn35)\n\nThe rebuke appeared to have a detrimental effect on the amount of public\ninformation the IAEA published about Natanz thereafter. By November, the IAEA\nhad stopped listing details about the centrifuges in its quarterly reports.\nInstead of listing the number of centrifuges installed and enriching in each\nunit, it aggregated the numbers from all three units—A24, A26, and A28—into a\nsingle count. This eliminated the primary means the public had for determining\nthe effects Stuxnet had on the plant.[36](part0021.html#c17-ftn36)\n\nWhat we do know is that in July 2010, the centrifuges were still only\nproducing at 45 to 66 percent capacity. ISIS noted for the first time in one\nof its reports, published in July, that “sabotage” might be the cause of some\nof the problems at Natanz.[37](part0021.html#c17-ftn37) Stuxnet had by then\nbeen discovered and publicly exposed, but its link to Iran’s nuclear program\nand Natanz was still several months away.\n\nIt’s also clear that the number of installed and enriching centrifuges\nfluctuated radically in 2010. In November 2009, at the plant’s peak, Iran had\n8,692 centrifuges installed. That number was down to 8,528 in May 2010 (with\n3,936 enriching), but increased to 8,856 in September (with 3,772 enriching)\nbefore dropping to 8,426 in November (with 4,816 enriching). It’s possible\ncentrifuges continued to break during the year even after Stuxnet was\ndiscovered and that this was the reason for the fluctuation. Although the\nlarge jump of 1,000 centrifuges enriching from September to November suggests\nthat the plant had recovered from the lingering effects of Stuxnet, Iran still\nhad 3,600 centrifuges installed that were just sitting in cascades, not\nenriching.[38](part0021.html#c17-ftn38) This suggests at least some continuing\nproblems. It wasn’t long after this, on November 16, that officials at Natanz\nshut down the plant completely for six days following Symantec’s revelation\nthat Stuxnet was designed to sabotage frequency\nconverters.[39](part0021.html#c17-ftn39) Some time that same month, they also\nadded more centrifuges to six of the cascades, suggesting they may have been\ntrying to alter the configuration of the cascades to thwart Stuxnet’s\npayload.[40](part0021.html#c17-ftn40)\n\nBACK IN WASHINGTON, conversations about Stuxnet had continued throughout 2010.\nSometime during the early summer, CIA director Leon Panetta and Gen. James\nCartwright had broken the news of the worm’s out-of-control spreading to the\npresident. The revelation prompted a lot of questions from Obama. Was there\nany sign that the Iranians had discovered it yet? If yes, could they determine\nwhat it was doing or trace it back to its source? He was also concerned about\ncollateral damage to the machines infected outside Natanz. And taking all of\nthis into account, should they now cancel the operation? His advisers reminded\nhim that the worm was a highly targeted precision weapon that launched its\npayload only on machines that met a specific criteria; although it would\naffect other machines to a certain degree, simply by the nature of infecting\nthem, it wouldn’t harm them.\n\nSatisfied that the operation was still in their control for the most part,\nObama ordered them to proceed.[41](part0021.html#c17-ftn41)\n\nGiven Stuxnet’s complexity and the long odds against it being uncovered or\ndeciphered, the decision must have seemed completely reasonable at the time.\nIndeed, even the initial reaction from Symantec and other security companies\nafter Stuxnet was exposed seemed to confirm that their covert operation was\nsafe—every sign indicated that the security community, stymied by the\nmalware’s complexity and unfamiliarity, had abandoned their work on the code\nafter releasing signatures to detect it and had moved on.\n\nBut Washington hadn’t counted on the dogged determination of the Symantec\nresearchers to get to the bottom of the mysterious code or on Ralph Langner’s\nblunt and vocal candor about what it was attacking. As the months went on and\nmore information came out from Langner and Symantec, all anyone in Washington\nand Tel Aviv could do was sit and watch as each piece of the puzzle fell into\nplace, until finally the picture was complete.\n\n* * *\n\n[1](part0021.html#c17-ftn1a) A timestamp in the version of Stuxnet that was\nlaunched in June 2009 indicates that the attackers compiled the malware June\n22 at 4:31 p.m. local time (the local time on the computer that compiled the\ncode) and that it struck its first victim the following day at 4:40 a.m. (the\nvictim’s local time), an apparent difference of twelve hours, depending on the\ntime zone the compilation computer was in. The infection time came from a log\nfile that was buried in every sample of Stuxnet that was found. Each time\nStuxnet infected a computer, it recorded the time (based on the computer’s\ninternal clock) in this log. It’s not known if the attackers launched the\nattack right after they compiled it—and the malware then took twelve hours to\nreach its victim—or if they waited to launch it until the next day.\n\n[2](part0021.html#c17-ftn2a) David Albright, _Peddling Peril: How the Secret\nNuclear Trade Arms America’s Enemies_ (New York: Free Press, 2010), 202–3.\n\n[3](part0021.html#c17-ftn3a) David Albright and Jacqueline Shire, “IAEA Report\non Iran: Centrifuge and LEU Increases; Access to Arak Reactor Denied; No\nProgress on Outstanding Issues,” June 5, 2009, available at [isis-\nonline.org/publications/iran/Iran_IAEA_Report_Analysis_5June2009.pdf](http://www.isis-\nonline.org/publications/iran/Iran_IAEA_Report_Analysis_5June2009.pdf).\n\n[4](part0021.html#c17-ftn4a) Albright, _Peddling Peril_ , 202–3.\n\n[5](part0021.html#c17-ftn5a) Albright and Shire, IAEA Report, June 5, 2009.\n\n[6](part0021.html#c17-ftn6a) Foolad Technique appears to operate under the\ndomain name ISIE. It may be that ISIE was either acquired by Foolad or was a\ndivision of that company.\n\n[7](part0021.html#c17-ftn7a) In 2006 an Iranian American was indicted for\nattempting to smuggle banned weapons technology into Iran. The defendant had\npurchased pressure sensors from a company in Minneapolis and sent them to a\nmiddleman in Dubai who was supposed to forward them to Behpajooh. See “Dubai\nFirm Implicated in Iran ‘Bomb Component’s Investigation in US,” _Khaleej\nTimes_ , May 12, 2006.\n\n[8](part0021.html#c17-ftn8a) One of Neda’s other customers was a gas\npressurization station on Kharg Island in Iran, the site of one of the\nexplosions that drew Eric Chien’s attention in 2010 after Stuxnet was\ndiscovered. According to Neda’s website, between 2008 and 2010 the company\nrenovated control systems at the plant’s Turbo Compressor units. There’s no\nevidence that the explosion at the plant was caused by digital sabotage, but\nthe fact that Stuxnet infected computers at Neda shows how simple it could be\nto conduct digital attacks against other types of facilities in Iran.\n\n[9](part0021.html#c17-ftn9a) In 2004, a trading company in Dubai ordered 7,500\nmicrocontrollers from an Arizona firm and diverted the shipment to Neda,\nevidently for use by Iran’s military. The case is _US District Court, Mayrow\nGeneral Trading et al., Indictment_ , September 11, 2008, available at\n[dodig.mil.iginformation/Mayrow%20Mayrow%20Superseding%20Indictment.pdf](http://www.dodig.mil.iginformation/Mayrow%20Mayrow%20Superseding%20Indictment.pdf).\n\n[10](part0021.html#c17-ftn10a) Although he posted his comments under the name\nBehrooz, he signed his messages at the bottom with “M. R. Tajalli.” A search\non Behrooz and the other name led to a LinkedIn profile and others identifying\nhim as Mohammad Reza Tajalli, a control engineer who had been working for Neda\nsince 2006. Tajalli specialized in control systems for the oil industry,\naccording to his LinkedIn profile. He did not respond to queries from the\nauthor.\n\n[11](part0021.html#c17-ftn11a) See chapter 13, [this\npage](part0017.html#page235) and [this page](part0017.html#page246).\n\n[12](part0021.html#c17-ftn12a) William Broad, “A Tantalizing Look at Iran’s\nNuclear Program,” _New York Times_ , April 29, 2008.\n\n[13](part0021.html#c17-ftn13a) The centrifuges have a cap at each end and\nbalance precariously on a ball bearing attached to a pin or needle. The top\npart of the needle is attached to the cap that is located at the bottom of the\ncentrifuge, while the bottom half of the needle, with the bearing, is inserted\nin a cup that is attached to a spring. This entire contraption allows the\ncentrifuge to sway slightly as it spins while also keeping it stabilized. Too\nmuch movement, however, can destabilize the centrifuge and wear out these\nparts.\n\n[14](part0021.html#c17-ftn14a) In author interviews, several sources suggested\nthat the centrifuges in A24 might have been configured differently than those\nin A26—that the frequency converters used to control them were a different\nmodel. If true, it’s possible that Stuxnet 0.5, which targeted the valves on\ncentrifuges and cascades, was used against A24, and that subsequent versions\nof Stuxnet, which targeted frequency converters, were used against the\ncascades in A26. This might explain why the cascades in A24 had problems in\n2008, when Stuxnet 0.5 was released, but had fewer problems in 2009, when the\nlater version of Stuxnet was performing its sabotage.\n\n[15](part0021.html#c17-ftn15a) IAEA, “Implementation of the NPT Safeguards\nAgreement and Relevant Provisions of Security Council Resolution 1737 (2006),\n1747 (2007), 1803 (2008) and 1835 (2008) in the Islamic Republic of Iran,”\nFebruary 18, 2010, available at\n[iaea.org/Publications/Documents/Board/2010/gov2010-10.pdf](http://www.iaea.org/Publications/Documents/Board/2010/gov2010-10.pdf).\n\n[16](part0021.html#c17-ftn16a) “Statements by President Obama, French\nPresident Sarkozy, and British Prime Minister Brown on Iranian Nuclear\nFacility,” September 25, 2009, at the Pittsburgh Convention Center in\nPittsburgh, Pennsylvania, available at [whitehouse.gov/the-press-\noffice/2009/09/25/statements-president-obama-french-president-sarkozy-and-\nbritish-prime-minister-Brown-on-Iranian-Nuclear-\nFacility](http://www.whitehouse.gov/the-press-office/2009/09/25/statements-\npresident-obama-french-president-sarkozy-and-british-prime-minister-Brown-on-\nIranian-Nuclear-Facility).\n\n[17](part0021.html#c17-ftn17a) Satellite images initially captured what looked\nlike tunnels and underground construction occurring at Fordow, then in 2008\nthey captured workers stacking large cement pads outside the entrance to a\ntunnel. The pads resembled the cement platforms that are used in enrichment\nplants to hold cascades. The United States toyed with the idea of sneaking a\nspecial operations team into Iran to rig the pads so that they would destroy\nthe centrifuges at a later date, but the risky endeavor never advanced beyond\nthis. See David E. Sanger, _Confront and Conceal: Obama’s Secret Wars and\nSurprising Use of American Power_ (New York: Crown, 2012), 152, 155.\n\n[18](part0021.html#c17-ftn18a) The Defense Science Board, which advised the\nPentagon to build the weapon in 2004, wrote that a tunnel facility buried deep\nwithin rock could pose “a significant challenge” even to the new bombs.\n“Several thousand pounds of high explosives coupled to the tunnel are needed\nto blow down blast doors and propagate a lethal air blast,” they wrote.\nWilliam Broad, “Iran Shielding Its Nuclear Efforts in Maze of Tunnels,” _New\nYork Times_ , January 5, 2010.\n\n[19](part0021.html#c17-ftn19a) “Statements by President Obama, French\nPresident Sarkozy, and British Prime Minister Brown on Iranian Nuclear\nFacility,” the White House.\n\n[20](part0021.html#c17-ftn20a) A year later, in September 2010, while the\nSymantec researchers and Ralph Langner were still deciphering Stuxnet’s\npayload, the Iranian dissident group that had exposed Natanz claimed it had\ninformation about yet another secret uranium enrichment plant being built near\nAbyek, about 120 kilometers west of Tehran. See David E. Sanger, “Dissidents\nClaim Iran Is Building a New Enrichment Site,” _New York Times_ , September 9,\n2010.\n\n[21](part0021.html#c17-ftn21a) Broad, “Iran Shielding Its Nuclear Efforts.”\n\n[22](part0021.html#c17-ftn22a) US State Department cable, “40th Joint\nPolitical-Military Group: Executive,” November 18, 2009, published by\nWikiLeaks at\n[wikileaks.org/cable/2009/11/09TELAVIV2500.html](http://www.wikileaks.org/cable/2009/11/09TELAVIV2500.html).\n\n[23](part0021.html#c17-ftn23a) Dieter Bednarz, Erich Follath, and Holger\nStark, “Intelligence from Tehran Elevates Concern in the West,” _Der Spiegel_\n, January 25, 2010.\n\n[24](part0021.html#c17-ftn24a) Erich Follath and Holger Stark, “The Birth of a\nBomb: A History of Iran’s Nuclear Ambitions,” _Der Spiegel_ , June 17, 2010.\n\n[25](part0021.html#c17-ftn25a) Olli J. Heinonen, “Iran Ramping Up Uranium\nEnrichment,” Power and Policy blog, July 20, 2011, published by the Belfer\nCenter at Harvard Kennedy School, July 20, 2011, available at\n[powerandpolicy.com/2011/07/20/Iran-ramping-up-uranium-\nenrichment/#.UtM6Z7SYf8M](http://www.powerandpolicy.com/2011/07/20/Iran-\nramping-up-uranium-enrichment/#.UtM6Z7SYf8M).\n\n[26](part0021.html#c17-ftn26a) “Remarks of President Obama Marking Nowruz,”\nthe White House, March 20, 2010, available at [whitehouse.gov/the-press-\noffice/remarks-president-obama-marking-nowruz](http://www.whitehouse.gov/the-\npress-office/remarks-president-obama-marking-nowruz).\n\n[27](part0021.html#c17-ftn27a) It spent nearly a month working its way through\ncomputers at Behpajooh and, on April 24, it struck gold when it hit a computer\nidentified by the name “Manager 115.” Stuxnet recorded that this computer\ncontained a zip folder with Step 7 project files stored in it. Over the next\ncouple of months, the malware broke out of Behpajooh’s network and spread to\nother companies. The companies are identified in the log file only by their\ndomain names, which may or may not also be the company’s name. For example,\nthey include MSCCO, Melal, and S-Adari.\n\n[28](part0021.html#c17-ftn28a) There were ten “patient zeroes” at the five\ncompanies that were infected. That is, ten machines at these five companies\nwere targeted by the attackers. And from these ten machines, the Symantec\nresearchers were able to chart a constellation of about 12,000 other\ninfections. Of these five companies, Behpajooh was responsible for 69 percent\nof those 12,000 infections.\n\n[29](part0021.html#c17-ftn29a) Compilation and infection times aren’t always\naccurate. The system clocks on either the compiling machine or the victim\nmachine in this case could have been out of date or the code could have been\ncompiled in a time zone different from the victim’s time zone. In comparing\nthe amount of time that elapsed between the time the three versions of Stuxnet\nwere compiled and when they infected their first machines, the researchers\nassumed the compiling machine and the victim machines were in the same time\nzone.\n\n[30](part0021.html#c17-ftn30a) Sanger, _Confront and Conceal_ , 204.\n\n[31](part0021.html#c17-ftn31a) Although the attack struck some companies\nmultiple times, it was not always the same machine each time. The attackers\nmight have been looking for better-placed machines each time or ones that gave\nthem different routes of access to the target. It’s not clear why the April\nversion didn’t spread as widely as the March one did, since it had all of the\nsame zero-day spreading mechanisms and also hit Behpajooh, the company hit in\nthe March attack from which Stuxnet spread widely around the world. It’s\npossible the machines hit in the April attack were not as broadly connected as\nthe ones hit in March, reducing its spread.\n\n[32](part0021.html#c17-ftn32a) The domain name of a computer can sometimes\nidentify the name of the company that owns it, but not always.\n\n[33](part0021.html#c17-ftn33a) Sanger, _Confront and Conceal_ , 206. Sanger\nwrites that the NSA picked up intelligence intercepts indicating that the\ncentrifuges had come to a halt.\n\n[34](part0021.html#c17-ftn34a) Iran accused the IAEA of leaking information to\nReuters for a May 14 story and to the Associated Press for a May 30 story.\n\n[35](part0021.html#c17-ftn35a) Fereydoon Abbasi, who was appointed head of the\nIranian Atomic Energy Organization after the attempt on his life in 2010,\naccused the West in a 2014 interview of using the IAEA reports about Iran’s\nnuclear activities to “calibrate” its sabotage against the nuclear program and\nto “size up the level of destruction they have exerted” on Iran’s nuclear\nmachinery with each round of attack. “By accessing the leaked data from our\nreports they can tell how many centrifuges are operating in Iranian nuclear\nfacilities and how many are about to be installed with what parts needed,” he\nsaid. When Iran submits reports to the IAEA about the design of its nuclear\nfacilities and the equipment it plans to procure for the program, intelligence\nagencies use the list to “booby-trap the devices” and “set up viruses in their\ncontrol systems,” he added. The Iranians got more careful over time about\nshowing IAEA inspectors the exact equipment they installed in the cascade\nrooms—at one point they even placed stickers over brand names on equipment to\nprevent inspectors from identifying them. They also followed inspectors around\nwith a camera to watch everything they did. Abassi also said that Stuxnet was\nnot the first or the last such attack by the US and Israel against the nuclear\nprogram, and that they had repeatedly infiltrated the supply chain for Iran’s\nnuclear program to sabotage vacuum valves, valve pumps, and other equipment.\n“Spy agencies adjust their attacks based on our needs; they obstruct\nconventional channels to our purchase and leave open only those that they can\nexert full control over to transfer their modified stuff to our facilities,”\nhe said, accusing Siemens of being complicit in the program. “This is how they\npenetrated our electronic infrastructures, bugged on us, and installed\nmalwares like the Stuxnet. They set up the virus in the gauges we had\npurchased from Siemens and also [put] explosives in the devices.” See “How\nWest Infiltrated Iran’s Nuclear Program, Ex-Top Nuclear Official Explains,”\n_Iran’s View_ , March 28, 2014, [www.iransview.com/west-infiltrated-irans-\nnuclear-program-ex-top-nuclear-official-\nexplains/1451](http://www.iransview.com/west-infiltrated-irans-nuclear-\nprogram-ex-top-nuclear-official-explains/1451).\n\n[36](part0021.html#c17-ftn36a) A former IAEA official told me the reason the\nreports changed in late 2010 had nothing to do with the accusations from Iran,\nbut was due to uncertainty about the accuracy of the data collected. After the\nIranians removed gas from some of the centrifuges in 2009 and 2010 and\ndecommissioned other centrifuges, they continued to operate some cascades with\nfewer than 164 working centrifuges in them. This made IAEA officials realize\nthey had no way of knowing how many centrifuges in each cascade were actually\nfunctional and enriching gas at any one time, he said. They had simply assumed\nin the past that if a cascade was enriching uranium, all of the 164\ncentrifuges in the cascade were involved in enriching the uranium.\n\n[37](part0021.html#c17-ftn37a) David Albright, Paul Brannan, and Andrea\nStricker, “What Is Iran’s Competence in Operating Centrifuges?” ISIS, July 26,\n2010, available at [isis-online.org/isis-reports/detail/what-is-irans-\ncompetence-in-operating-centrifuges/8](http://www.isis-online.org/isis-\nreports/detail/what-is-irans-competence-in-operating-centrifuges/8).\n\n[38](part0021.html#c17-ftn38a) Ivan Oelirch, with the Federation of American\nScientists, notes that in fact there were more centrifuges enriching at this\npoint, but they were only operating at 20 percent of their efficiency.\n\n[39](part0021.html#c17-ftn39a) David Albright et al., “Natanz Enrichment Site:\nBoondoggle or Part of an Atomic Bomb Production Complex?” ISIS, September 21,\n2011, available at [isis-online.org/isis-reports/detail/natanz-enrichment-\nsite-boondoogle-or-part-of-an-atomic-bomb-production-comp](http://www.isis-\nonline.org/isis-reports/detail/natanz-enrichment-site-boondoogle-or-part-of-\nan-atomic-bomb-production-comp).\n\n[40](part0021.html#c17-ftn40a) Sometime in November 2010, technicians\nincreased the number of centrifuges in six cascades from 164 to 174. See IAEA\nBoard of Governors, “Implementation of the NPT Safeguards Agreement and the\nRelevant Provisions of Security Council Resolutions in the Islamic Republic of\nIran” (report, November 23, 2010), available at\n[iaea.org/Publications/Documents/Board/2010/gov2010-62.pdf](http://www.iaea.org/Publications/Documents/Board/2010/gov2010-62.pdf).\nAlthough some observers believe that Iran increased the number of centrifuges\nin order to increase the amount of gas they could enrich in the\ncascades—perhaps to make up for time lost to Stuxnet—an IAEA source told me\nthat the centrifuges were added at the latter stage of the cascades, which\nwouldn’t help increase the amount of gas that could be enriched in the\ncascade. He suggested that the additional centrifuges were simply meant to\nalter the configuration of the cascades in order to prevent any lingering\ncopies of Stuxnet from working on them.\n\n[41](part0021.html#c17-ftn41a) Sanger notes that the meeting between Panetta\nand Obama occurred midsummer, which would make it sometime in July, right\naround the time Stuxnet was exposed. But he also says within weeks after this\nmeeting, the attackers unleashed two other versions of the worm. This suggests\nthat new versions of Stuxnet were released after antivirus firms had already\nreleased signatures to detect it. As noted, no later version of Stuxnet has\nbeen found.\n\n\n# CHAPTER 18\n\n# **QUALIFIED SUCCESS**\n\nA year after IAEA officials first began to notice technicians removing an\nunusual number of centrifuges from the underground hall at Natanz, the mystery\nbehind the disappearing devices was at last solved. But with Stuxnet finally\nidentified as the cause, and with details about the extensive resources behind\nit revealed, a couple of other questions begged to be answered: Just how\nsuccessful had Stuxnet been at achieving its goals? And were the risks, costs,\nand consequences worth it?\n\n“If Stuxnet’s goal was the destruction of all the centrifuges [at Natanz],”\nthen it had certainly failed, David Albright of ISIS noted in a 2010 report.\nBut if the goal was to destroy a limited number of centrifuges in order to set\nIran’s uranium enrichment program back a bit, then “it may have succeeded,” he\nwrote, “at least for a while.”[1](part0022.html#c18-ftn1)\n\nThere was no doubt that Iran’s nuclear program was not where it should have\nbeen in 2010 when Stuxnet was discovered. The two massive underground halls at\nNatanz were capable of holding 47,000 centrifuges, yet more than a decade\nafter their construction was complete, only one of the halls contained any\ncentrifuges at all, and even that one was only one-third full. “Viewed from\nthat perspective—what Iran had originally planned and where the program was\nnow, the situation had worsened …” Albright wrote.\n\nBut how much of this was due to Stuxnet and how much to other\ncauses—sanctions, diplomatic pressure, and the effects of other covert\nsabotage efforts—remains unclear. Ralph Langner believed the attack on Natanz\nwas a huge success and had been “nearly as effective as a military strike”\nwithout all the risks and costs that a military strike entailed. The _New York\nTimes_ said Stuxnet appeared to be the “biggest single factor in putting time\non the nuclear clock.”[2](part0022.html#c18-ftn2)\n\nBut there were varying opinions about just how many centrifuges Stuxnet\naffected and how far Iran’s nuclear program had been set back as a result.\n\nBack in 2003, Israeli officials had warned that Iran would have enough\nenriched uranium for a bomb by 2007 if the nuclear program wasn’t halted. But\ntwo voluntary suspensions and a host of other factors had pushed back the\nclock, causing the Israelis to revise the bomb timeline first to 2008 and then\nto 2010. Now post-Stuxnet, the timeline was pushed back again.\n\nWhen Mossad’s outgoing chief, Meir Dagan, left his job in early 2011, he told\nthe Israeli Knesset that Iran now would not be able to produce a nuclear\narsenal before 2015.[3](part0022.html#c18-ftn3) US officials were less\ngenerous in their estimate, however, saying the program had been set back only\neighteen to twenty-four months, rather than four years. According to US\nSecretary of State Hillary Clinton, the nuclear program had been “slowed” by\ntechnological problems and sanctions, but not to the point at which anyone\ncould relax. “We have time,” she said, “but not a lot of\ntime.”[4](part0022.html#c18-ftn4) Ivanka Barzashka, a research associate at\nthe Centre for Science and Security Studies at King’s College in London,\nbelieved the nuclear program had not been pushed back at all. She examined\ncorrelations between centrifuge numbers in the IAEA reports and the dates that\nStuxnet was active in 2009, and found that evidence of the attack’s impact was\ncircumstantial and inconclusive. If Stuxnet did have an effect on the uranium\nenrichment program, it wore off quickly.\n\n“If sabotage did occur, it was short-lived and most likely happened between\nMay and November 2009,” she concluded. “The malware did not set back Iran’s\nenrichment programme, though perhaps it might have temporarily slowed down\nIran’s rate of expansion.”[5](part0022.html#c18-ftn5)\n\nThe Iranians, in fact, showed a remarkable ability to recover from any damages\nand delays that Stuxnet and other factors had meted out.\n\nIn early 2010, for example, shortly after technicians at Natanz replaced the\ncentrifuges that were causing them problems, they stepped up their enrichment\nactivity, feeding more gas into the centrifuges to increase the output they\nproduced. As a result, Iran’s production of low-enriched uranium actually\n_increased_ in 2010 and remained fairly steady thereafter. In the fall of\n2008, for example, during the period that Stuxnet 0.5 was manipulating valves\non the cascades, the centrifuges were producing only 90 kg of low-enriched\nuranium a month. At the end of 2009, when the next round of Stuxnet hit, the\nnumber dipped slightly to 85 kg a month. But in 2010, despite at least two\nmore rounds of Stuxnet being released, the production level jumped to between\n120 and 150 kg a month, and by 2011, Iran was producing a steady 150 kg of\nlow-enriched uranium per month.\n\nIt should be noted, however, that these production numbers were still well\nbelow what the centrifuges should have produced by design. In 2010, it took\n4,820 centrifuges to produce this volume of enriched gas, but in 2011 Iran was\nusing 5,860 centrifuges to produce the same amount, suggesting the centrifuges\nwere working less efficiently than they had before, possibly due to lingering\neffects from Stuxnet.[6](part0022.html#c18-ftn6)\n\nBut in the end, Iran was still making progress and still producing enriched\nuranium. By mid-2011, the centrifuges had produced a total of 4,400 kg of low-\nenriched uranium.[7](part0022.html#c18-ftn7) What’s more, Iran had transferred\nat least 1,950 kg of this to the pilot plant to be further enriched to 19.75\npercent, and by the beginning of 2011, Iran had 33 kg of uranium enriched to\nthis level and announced plans to triple this amount.\n\nOfficials began enriching the uranium to this higher percentage following the\ndestruction of centrifuges by Stuxnet. Iranian officials claimed they needed\nthe higher-enriched uranium for cancer treatment research. But the higher-\nenriched uranium created a bigger problem for those opposed to the enrichment\nprogram, because at 20 percent enrichment, Iran was closer to the 90-percent\nweapons-grade material it needed for a bomb. “Starting from this higher\nenrichment level means that Iran cuts its time by more than half to produce\nweapons-grade, highly enriched uranium at about 90 percent enrichment,” noted\nBarzashka. In this regard, if “the purpose of [Stuxnet] was to decrease\nIranian nuclear-weapons potential, it clearly\nfailed.”[8](part0022.html#c18-ftn8)\n\nMeanwhile, technicians also began installing more advanced centrifuges at the\npilot enrichment plant at Natanz—IR-2m and IR-4 centrifuges. These centrifuges\nwere much more efficient than the IR-1s. Whereas IR-1s could produce about 1.0\nseparative work units a day by design (though they seldom reached this level),\nthe more advanced centrifuges could produce about three to five times this\nmuch. They were also more resilient than the IR-1s, which meant they were less\nprone to break under the kind of stress that Stuxnet produced.\n\nDespite Iran’s seemingly quick recovery from Stuxnet, the digital weapon did\nhave at least two longer-lasting effects on the enrichment program. First, it\ncut into Iran’s supply of uranium gas. Several tons of enriched uranium ended\nup in dump tanks during the period that Stuxnet was doing its sabotage. The\nwaste likely wasn’t all due to Stuxnet, since technicians experienced a number\nof varied problems with the centrifuges, but Stuxnet no doubt contributed to\nthe loss. As previously noted, Iran had a limited supply of uranium on hand\n(some imported from abroad, some mined from its own land), and any gas that\nwas wasted cut into these reserves.\n\nBut Iran also had a limited supply of centrifuges and materials to make new\nones. With sanctions tighter than ever before, replacing damaged centrifuges\nnow would become more challenging. In 2008, the IAEA estimated that Iran had\nenough components and materials on hand to build 10,000\ncentrifuges.[9](part0022.html#c18-ftn9) If Stuxnet destroyed 1,000 of these,\nthis cut the stockpile of centrifuges by 10 percent. On top of this, Iran lost\nabout 10 percent of centrifuges each year to normal wear and tear. At that\nrate of attrition, “after five years, these guys are cooked,” says the IAEA’s\nOlli Heinonen.[10](part0022.html#c18-ftn10)\n\nBut Heinonen in fact believed that more than 1,000 centrifuges were damaged by\nStuxnet. He believed the number was closer to 2,000. He based his assessment\non the fact that IAEA reports provided only a snapshot of conditions at Natanz\nduring a three-month period and the fact that there had been problems with\ntamper-evident security seals at Natanz, which raised the possibility that\nIran might have secretly replaced some of its damaged centrifuges without the\nIAEA knowing it.[11](part0022.html#c18-ftn11)\n\nAlthough IAEA inspectors visited the plant twenty-four times a year on\naverage, their reports were only publicly disclosed once a quarter, and the\nnumbers in each report were based only on the number of centrifuges the\ninspectors observed at the plant during their most recent visit prior to each\nreport. Thus, there were numerous opportunities in between visits for\ntechnicians to swap out centrifuges away from inspectors’ prying eyes—as long\nas they did so out of the view of the IAEA cameras, which were, in theory,\nsupposed to make such hidden swaps impossible.\n\nEvery time a new module of cascades was constructed at the plant, technicians\nplaced portable walls around it, and made it accessible by only a single\ndoor—a door that an IAEA camera was positioned outside to monitor. Tamper-\nevident seals were also placed on the joints of the walls, to ensure that the\ndoor was indeed the single means of entry, and that technicians couldn’t\nsimply move the walls aside to remove centrifuges out of the view of the\ncameras. But there had been problems at Natanz with security seals\nmysteriously breaking.[12](part0022.html#c18-ftn12) Iranian officials said the\nbreaks were accidental and that operators had been told “to exercise more\nvigilance.” But Heinonen says “an unusual pattern” of broken seals emerged in\nIran, raising the possibility that the walls might have been moved to\nfurtively remove and replace damaged centrifuges.[13](part0022.html#c18-ftn13)\n\nBut even if the number of damaged centrifuges exceeded 1,000, Stuxnet clearly\nwasn’t the magic bullet it might have been had it been designed for more\nimmediate and widespread destruction—to take out thousands of centrifuges in a\nsingle blow—rather than for slower, more incremental effects.\n\nThere were some, in fact, who wondered why Stuxnet _hadn’t_ been designed for\nmore quick and severe damage. But the risk of repercussions for such an\naggressive attack were greater. If Stuxnet had destroyed 3,000 to 4,000\nmachines at once, there would have been little question that the cause was\nsabotage, and Iran would likely have perceived it as a military assault to be\nresponded to in kind. So Stuxnet’s slow and stealthy attack was a compromise\nof sorts that made it harder to achieve more extensive results but also made\nit harder for Iran to make a case for striking back.\n\nQuestions remained, though, about what the digital weapon might have achieved\nhad it not been discovered in 2010. Iran’s enrichment program was just getting\nunder way when Stuxnet struck, and the code was still in the early stages of\nmayhem when it was exposed. There was no telling what it might have\naccomplished over time as Iran installed more centrifuges and cascades. For\nthis reason Barzashka believed the attackers made a mistake in unleashing\nStuxnet too soon. Had it been held in abeyance until more centrifuges were\ninstalled and more uranium gas was in play, its effects on the program might\nhave been more detrimental.\n\nOne thing was certain: it would now be harder for the attackers to repeat the\nfeat. Stuxnet, as Langner had noted, was effectively a one-shot weapon: the\nattack, once discovered, had made the Iranians more cautious, thereby making\nfuture attacks by the same means more difficult to pull off. After this,\nanytime equipment at Natanz malfunctioned, the Iranians would immediately\nsuspect sabotage and respond more swiftly. At the first sign of trouble,\ntechnicians would shut down the systems and examine them more closely for\nmalware or manipulation.\n\nBut regardless of all the factors that limited Stuxnet’s effects and cut its\nlife short, the stealth attack made at least one group very happy.\n\n“In the non-proliferation community, Stuxnet is just a welcome development,”\nDavid Albright says. “It means we won’t have to have a war with\nIran.”[14](part0022.html#c18-ftn14)\n\nBUT EVEN IF the Stuxnet operation bought diplomatic negotiators a little more\ntime, the weapon clearly didn’t put an end to the political crisis or\neliminate the possibility of war entirely. In 2011, a fifth round of UN\nsanctions was being levied against Iran, and the United States was planting\nPatriot missiles throughout the Middle East to protect its allies in the event\nof war. And Iran’s adversaries continued to employ lethal measures against its\nscientists in an attempt to cripple the nuclear program. In July 2011, a\nthirty-five-year-old physicist named Darioush Rezaeinejad was shot in the\nthroat while picking up his daughter from kindergarten in Tehran. The two\ngunmen reportedly escaped on motorcycles. The IAEA said Rezaeinejad had been\ninvolved in developing high-voltage switches for setting off explosions needed\nto trigger a nuclear warhead.[15](part0022.html#c18-ftn15)\n\nThen in January 2012, just a day after Israel’s military chief of staff said\nthat 2013 would be a crucial year for Iran’s nuclear program, motorcycle\nassassins struck again in Iran, this time killing Mostafa Ahmadi Roshan with\nan explosive attached to his car. Roshan was initially identified as a thirty-\ntwo-year-old chemist who worked at Natanz, but an Iranian official later\nrevealed he actually managed the Natanz facility and also worked procuring\nspecialized equipment for Iran’s nuclear program. Roshan’s title was deputy\nfor trade affairs at Kala Electronics Company, which provided parts for\nNatanz. Kala, of course, was one of the companies believed to have been struck\nby Stuxnet.[16](part0022.html#c18-ftn16)\n\nA string of mysterious explosions also began to plague Iran. In November 2011,\na massive explosion at a long-range-missile testing site killed more than\nthirty members of Iran’s Revolutionary Guard, including the general said to be\nthe architect of Iran’s missile program.[17](part0022.html#c18-ftn17) Iran\ndenied the explosion was the result of sabotage, insisting that it was an\naccident. But a Western intelligence source told the _New York Times_ that the\nactual cause mattered little. “Anything that buys us time and delays the day\nwhen the Iranians might be able to mount a nuclear weapon on an accurate\nmissile is a small victory,” he said. “At this point, we’ll take whatever we\ncan get, however it happens.”\n\nThat same month, a blast occurred at the uranium conversion plant in Esfahan,\nreportedly damaging a facility where raw materials for the uranium enrichment\nprogram were stored.[18](part0022.html#c18-ftn18) Then in August 2012,\nexplosions took out power lines feeding electricity from the city of Qom to\nthe underground enrichment plant at Fordow. News reports indicated that one of\nthe explosions occurred when security forces found an electronic monitoring\ndevice disguised as a rock and tried to move it. The booby-trapped device was\nreportedly designed to intercept data from computer and phone lines at the\nenrichment plant.[19](part0022.html#c18-ftn19) In discussing the incident, an\nIranian official revealed that power lines feeding electricity to the plant at\nNatanz were also taken out in a separate incident, though he didn’t say when\nor offer further details.[20](part0022.html#c18-ftn20) Whatever Stuxnet’s\ngains, they weren’t enough to allow the West to relax.\n\nNone of this should have been a surprise to anyone, according to Henry\nSokolski, executive director of the Nonproliferation Policy Education Center.\nEvery president since Bill Clinton had tried covert operations to disrupt\nIran’s nuclear program, he noted to the _New Republic_ , and none had\nsucceeded. “Bush did it, Obama is doing it,” he said. But covert action was\nnever a substitute for sound foreign policy. It could only ever be “a holding\naction” not a solution, he said.[21](part0022.html#c18-ftn21)\n\nQuestions about the true nature of Iran’s nuclear pursuits remained. Toward\nthe end of 2011, an IAEA report, described as “the most damning report ever\npublished” about Iran by the agency, declared that the Islamic Republic had\nbeen working on building a nuclear weapon since 2003, despite earlier\nassertions by US intelligence that Iran had abandoned its weapons program that\nsame year.[22](part0022.html#c18-ftn22) The IAEA report wasn’t based on new\ninformation but on earlier documents the agency had received, including ones\nfrom the Iranian mole known as “Dolphin.” But although the information wasn’t\nnew, the IAEA’s willingness to now assert that the documents were evidence of\na nuclear weapons program was.[23](part0022.html#c18-ftn23) Israeli prime\nminister Benjamin Netanyahu once again renewed his call for a military strike\nagainst Iran. This time, however, the Iranians welcomed it. Iranian foreign\nminister Ali Akbar Salehi said defiantly that Iran was “ready for war” with\nIsrael.[24](part0022.html#c18-ftn24)\n\nIF THERE IS one thing to be said in Stuxnet’s favor, it’s that the digital\nattack, along with other covert operations, did succeed in staving off an ill-\nadvised military attack against Iran. And despite continuing tension and\ngamesmanship, nobody has been willing to take that step in the wake of\nStuxnet—a fact that ultimately left the door open for historic negotiations\nwith Iran over its nuclear program that began in 2013. The initial discussions\nresulted in Iran agreeing to freeze core parts of its nuclear\nprogram—including halting the installation of new centrifuges and limiting the\namount of enriched uranium Iran produces—in exchange for some loosening of\nsanctions against it.[25](part0022.html#c18-ftn25)\n\nBut any Stuxnet gains have to be weighed against the negative residual effects\nas well. At a time when the United States was battling an epidemic of cyber\nespionage attacks from China, attacking Iran made it harder to condemn other\nnations for cyber transgressions against the United States. As the party that\nfired the first known digital weapon, the United States was no longer in a\nposition to preach abstinence to others.\n\nOne final and more lasting consequence of Stuxnet also had to be weighed\nagainst its limited and uncertain benefits: the malware’s release had launched\na digital arms race among countries big and small that will alter the\nlandscape of cyberattacks forever. Stuxnet’s authors had mapped a new frontier\nthat other hackers and nation-state attackers will inevitably follow; and when\nthey do, the target for sabotage will eventually one day be in the United\nStates.\n\n* * *\n\n[1](part0022.html#c18-ftn1a) David Albright, Paul Brannan, and Christina\nWalrond, “Did Stuxnet Take Out 1,000 Centrifuges at the Natanz Enrichment\nPlant? Preliminary Assessment,” Institute for Science and International\nSecurity, December 22, 2010, available at [isis-online.org/isis-\nreports/detail/did-stuxnet-take-out-1000-centrifuges-at-the-natanz-enrichment-\nplant](http://www.isis-online.org/isis-reports/detail/did-stuxnet-take-\nout-1000-centrifuges-at-the-natanz-enrichment-plant).\n\n[2](part0022.html#c18-ftn2a) William J. Broad, John Markoff, and David E.\nSanger, “Israeli Test on Worm Called Crucial in Iran Nuclear Delay,” _New York\nTimes_ , January 15, 2011.\n\n[3](part0022.html#c18-ftn3a) Yossi Melman, “Outgoing Mossad Chief: Iran Won’t\nHave Nuclear Capability Before 2015,” _Ha’aretz_ , January 7, 2011.\n\n[4](part0022.html#c18-ftn4a) Mark Landler, “U.S. Says Sanctions Hurt Iran\nNuclear Program,” _New York Times_ , January 10, 2011.\n\n[5](part0022.html#c18-ftn5a) Ivanka Barzashka, “Are Cyber-Weapons Effective?”\nRoyal United Services Institute for Defense and Security Studies, July 23,\n2013, available at\n[tandfonline.com/doi/pdf/10.1080/03071847.2013.787735](http://www.tandfonline.com/doi/pdf/10.1080/03071847.2013.787735).\nIt should be noted that Barzashka only examined the IAEA reports for 2009 and\ndid not take into consideration other rounds of attack by Stuxnet in 2008 and\n2010.\n\n[6](part0022.html#c18-ftn6a) David Albright and Christina Walrond,\n“Performance of the IR-1 Centrifuge at Natanz,” Institute for Science and\nInternational Security, October 18, 2011, available at [isis-online.org/isis-\nreports/detail/test1](http://www.isis-online.org/isis-reports/detail/test1).\n\n[7](part0022.html#c18-ftn7a) Olli J. Heinonen, “Iran Ramping Up Uranium\nEnrichment,” Power and Policy blog, July 20, 2011, published by the Belfer\nCenter at Harvard Kennedy School, July 20, 2011, available at\n[powerandpolicy.com/2011/07/20/Iran-ramping-up-uranium-\nenrichment/#.UtM6Z7SYf8M](http://www.powerandpolicy.com/2011/07/20/Iran-\nramping-up-uranium-enrichment/#.UtM6Z7SYf8M).\n\n[8](part0022.html#c18-ftn8a) Barzashka, “Are Cyber-Weapons Effective?”\n\n[9](part0022.html#c18-ftn9a) David Albright, Jacqueline Shire, and Paul\nBrannan, “Enriched Uranium Output Steady: Centrifuge Numbers Expected to\nIncrease Dramatically; Arak Reactor Verification Blocked,” Institute for\nScience and International Security, November 19, 2008, available at [isis-\nonline.org/publications/iran/ISIS_analysis_Nov-IAEA-\nReport.pdf](http://www.isis-online.org/publications/iran/ISIS_analysis_Nov-\nIAEA-Report.pdf).\n\n[10](part0022.html#c18-ftn10a) Author interview with Heinonen, June 2011.\n\n[11](part0022.html#c18-ftn11a) Heinonen left the IAEA in October 2010 before\nthe centrifuges were removed, therefore he didn’t have access to the inspector\nreports themselves to see the exact numbers, but he was certain the number of\ndamaged centrifuges exceeded 1,000.\n\n[12](part0022.html#c18-ftn12a) A July 2010 letter from the IAEA to Iran\nreferenced “a number of incidents” involving broken seals at the plant. See\nIAEA Board of Governors, “Implementation of the NPT Safeguards Agreement and\nRelevant Provisions of Security Council Resolutions in the Islamic Republic of\nIran” (report, September 6, 2010), 3; available at\n[iaea.org/Publications/Documents/Board/2010/gov2010-46.pdf](http://www.iaea.org/Publications/Documents/Board/2010/gov2010-46.pdf).\nThe report does not specify whether the references are to seals placed on the\nwalls or seals placed on gas canisters and other equipment, but an IAEA source\ntold me they referred to wall seals.\n\n[13](part0022.html#c18-ftn13a) An IAEA source told me that it was Iran who\nalerted inspectors to the broken seals, rather than the inspectors finding\nthem on their own. The IAEA investigated the broken seals and found no\nwrongdoing on Iran’s part. But the investigation, he said, focused only on\nwhether Iran might have broken the seals to remove nuclear material from the\nrooms out of the view of cameras, not on whether centrifuges might have been\nsecretly removed from the rooms. When inspectors found that all of the uranium\nwas accounted for, they concluded that the seals had not been intentionally\nbroken for illicit purposes, but they left unexplored the possibility that\nthey had been intentionally broken to remove broken centrifuges.\n\n[14](part0022.html#c18-ftn14a) Author interview with Albright, February 2011.\n\n[15](part0022.html#c18-ftn15a) Ulrike Putz, “Mossad Behind Tehran\nAssassinations, Says Source,” _Spiegel Online_ , August 2, 2011, available at\n[spiegel.de/international/world/sabotaging-iran-s-nuclear-program-mossad-\nbehind-tehran-assassinations-says-\nsource-a-777899.html](http://www.spiegel.de/international/world/sabotaging-\niran-s-nuclear-program-mossad-behind-tehran-assassinations-says-\nsource-a-777899.html). See also “Israel Responsible for Iran Killing: Report,”\n_Global Security Newswire_ , August 2, 2011, available at\n[nti.org/gsn/article/israel-responsible-for-iran-killing-\nreport](http://www.nti.org/gsn/article/israel-responsible-for-iran-killing-\nreport).\n\n[16](part0022.html#c18-ftn16a) Roshan was given the title of “young nuclear\nmartyr” after his death, and city streets and plazas were named after him.\nSaeed Kamali Dehghan and Julian Borger, “Iranian Nuclear Chemist Killed by\nMotorbike Assassins,” _Guardian_ , January 11, 2012. See also Zvi Bar’el,\n“Iran Domestic Tensions Boil as West Battles Its Nuclear Program,” _Ha’aretz_\n, April 8, 2014. David Albright noted to me that when a scientist in the\nnuclear program is killed, the intent is to eliminate expertise and cripple\nthe program. But killing someone involved in procurement for the program is\nmeant to send a message and scare others from serving a similar role.\n\n[17](part0022.html#c18-ftn17a) David E. Sanger and William J. Broad, “Blast\nThat Leveled Base Seen as Big Setback to Iran Missiles,” _New York Times_ ,\nDecember 4, 2011.\n\n[18](part0022.html#c18-ftn18a) Sheera Frenkel, “Second Blast ‘Aimed at\nStopping Tehran’s Nuclear Arms Plans’,” _Times_ (London), November 30, 2011.\nIranian news agencies reported the blast initially, though the reports were\nlater removed from websites, and officials retracted statements they had made\nconfirming the blast. In February 2012, an Israeli ad joked about the\nexplosion. The ad, for the Israeli cable TV company HOT, was later pulled\noffline. It featured members of an Israeli comedy series, _Asfur_ , who sneak\ninto Iran in drag dressed as Muslim women—likely a mock reference to the time\nformer Palestinian leader Yasser Arafat was said to have escaped capture\ndressed as a Muslim woman. The three arrive in Esfahan, the site of the\nuranium conversion facility in Iran where the mysterious explosion occurred.\nAs the comedians walk through town, a nuclear facility visible behind them,\none of them spreads sunscreen on his face. When his companions look askance at\nhim, he replies, “What? Don’t you know how much radiation there is here?” The\nbungling travelers then encounter a bored Mossad agent sitting at an outdoor\ncafé who tells them he’s been in town two months conducting surveillance and\nhas been killing time watching on-demand episodes of _Asfur_ on his Samsung\nGalaxy tablet, a gift his wife and he received for subscribing to HOT.\n“Nuclear reactor or no nuclear reactor, I’m not missing _Asfur_ ,” he says.\nOne of the travelers reaches toward the tablet and asks, “What’s this\napplication here?” As he presses something on the screen, a fireball explodes\nbehind them at the nuclear facility. His companions look at him in shock and\nhe replies, “What? Just another mysterious explosion in Iran.”\n\n[19](part0022.html#c18-ftn19a) “Sources: Iran Exposed Spying Device at Fordo\nNuke Plant,” Ynet (online news site for the Israeli newspaper _Yediot\nAhronot_), September 23, 2012, available at\n[ynetnews.com/articles/0,7340,L-4284793,00.html](http://www.ynetnews.com/articles/0,7340,L-4284793,00.html).\n\n[20](part0022.html#c18-ftn20a) Fredrik Dahl, “Terrorists Embedded in UN\nNuclear Watchdog May Be Behind Power Line Explosion,” Reuters, September 17,\n2012, available at [news.nationalpost.com/2012/09/17/terrorists-embedded-in-\nun-nuclear-watchdog-may-be-behind-power-line-explosion-\niran](http://www.news.nationalpost.com/2012/09/17/terrorists-embedded-in-un-\nnuclear-watchdog-may-be-behind-power-line-explosion-iran). An Iranian official\ndisclosed both incidents at the IAEA general conference in Vienna, accusing\nthe IAEA of collusion. He noted that the day after the explosion that took out\npower lines feeding electricity to Fordow an IAEA inspector asked to conduct\nan unannounced inspection there. “Who other than the IAEA inspector can have\naccess to the complex in such a short time to record and report failures?,”\nthe official asked.\n\n[21](part0022.html#c18-ftn21a) Eli Lake, “Operation Sabotage,” _New Republic_\n, July 14, 2010.\n\n[22](part0022.html#c18-ftn22a) George Jahn, “UN Reports Iran Work ‘Specific’\nto Nuke Arms,” Associated Press, November 8, 2011, available at\n[news.yahoo.com/un-reports-iran-specific-nuke-\narms-184224261.html](http://www.news.yahoo.com/un-reports-iran-specific-nuke-\narms-184224261.html).\n\n[23](part0022.html#c18-ftn23a) Ali Vaez, “It’s Not Too Late to Peacefully Keep\nIran from a Bomb,” _The Atlantic_ , November 11, 2011.\n\n[24](part0022.html#c18-ftn24a) “Iran Says United and ‘Ready for War’ with\nIsrael,” _Ha’aretz_ , November 3, 2011.\n\n[25](part0022.html#c18-ftn25a) Anne Gearan and Joby Warrick, “Iran, World\nPowers Reach Historic Nuclear Deal,” _Washington Post_ , November 23, 2013,\navailable at [washingtonpost.com/world/national-security/kerry-in-geneva-\nraising-hopes-for-historic-nuclear-deal-with-\niran/2013/11/23/53e7bfe6-5430-11e3-9fe0-fd2ca728e67c_story.html](http://www.washingtonpost.com/world/national-\nsecurity/kerry-in-geneva-raising-hopes-for-historic-nuclear-deal-with-\niran/2013/11/23/53e7bfe6-5430-11e3-9fe0-fd2ca728e67c_story.html).\n\n\n# CHAPTER 19\n\n# **DIGITAL PANDORA**\n\nOn May 30, 2009, just days before a new version of Stuxnet was unleashed on\ncomputers in Iran, President Barack Obama stood before the White House press\ncorps in the East Room to address the grave state of cybersecurity in the\nUnited States. “We meet today at a transformational moment,” he said, “a\nmoment in history when our interconnected world presents us, at once, with\ngreat promise but also great peril.”\n\nJust as we had failed in the past to invest in the physical infrastructure of\nour roads, bridges, and railways, we had failed to invest in the security of\nour digital infrastructure, Obama said. Cyber intruders, he warned, had\nalready probed our electrical grid, and in other countries had plunged entire\ncities into darkness. “This status quo is no longer acceptable,” he said, “not\nwhen there’s so much at stake.”[1](part0023.html#c19-ftn1)\n\nHow ironic his words turned out to be a year later when Stuxnet was discovered\nspreading in the wild, and the public learned that the United States had not\nonly violated the sovereign space of another nation in an aggressive\ncyberattack, but in doing so had invited similar attacks upon vulnerable US\nsystems in retaliation.\n\nWhile Obama and other officials sounded the alarm about adversaries lurking in\nUS systems and laying the groundwork for future attacks against the power\ngrid, US military and intelligence agencies had been penetrating foreign\nsystems in Iran and elsewhere, building stockpiles of digital weapons, and\nushering in a new age of warfare, all without public discussion about the\nrules of engagement for conducting such attacks or the consequences of doing\nso. Perhaps it was knowledge of what the United States was doing in Iran and\nelsewhere that prompted the president’s urgent warnings about the risks to US\nsystems.\n\nMichael V. Hayden, who was director of the CIA during the time Stuxnet was\ndeveloped and unleashed, told a reporter after the digital weapon was exposed\nthat “somebody had crossed the Rubicon” in unleashing\nit.[2](part0023.html#c19-ftn2) That somebody, it turned out, was the United\nStates. And, as noted, where the United States led, others would follow.\n\nToday there’s a surge among nations around the world to expand existing cyber\ncapabilities or build new ones. More than a dozen countries—including China,\nRussia, the UK, Israel, France, Germany, and North Korea—have digital warfare\nprograms or have announced plans to build one. China began developing its\noffensive operations in the late ’90s, at the same time the United States made\nits first forays into this new fighting domain. Even Iran is developing a\ncyberwarfare program. In 2012, Ayatollah Ali Khamenei announced the creation\nof a defensive and offensive cyber program and told a group of university\nstudents that they should prepare for the coming age of cyberwarfare with\nIran’s enemies.[3](part0023.html#c19-ftn3)\n\nAs for the United States, the Defense Department’s Cyber Command currently has\nan annual budget of more than $3 billion and plans to increase its workforce\nfivefold, from 900 people to 4,900—covering both defensive and offensive\noperations.[4](part0023.html#c19-ftn4) The Defense Advanced Research Projects\nAgency, or DARPA, has also launched a $110 million research project called\nPlan X to develop cyberwarfare technologies to help the Pentagon dominate the\ndigital battlefield. The technology wish list includes a continuously updated\nmapping system to track every system and node in cyberspace in order to chart\nthe flow of data, identify targets to attack, and spot incoming assaults. The\nPentagon also wants a system capable of launching speed-of-light strikes and\ncounterstrikes using preprogrammed scenarios so that human intervention won’t\nbe necessary.[5](part0023.html#c19-ftn5)\n\nOf all the nations that have a cyberwarfare program, however, the United\nStates and Israel are the only ones known to have unleashed a destructive\ncyberweapon against another sovereign nation—a nation with whom it was not at\nwar. In doing so, it lost the moral high ground from which to criticize other\nnations for doing the same and set a dangerous precedent for legitimizing the\nuse of digital attacks to further political or national security goals.\n\n“This was a good idea,” Hayden told _60 Minutes_ about Stuxnet. “But I also\nadmit this was a big idea too. The rest of the world is looking at this and\nsaying, ‘Clearly, someone has legitimated this kind of activity as\nacceptable.’ ”[6](part0023.html#c19-ftn6)\n\nDigital assaults could now be considered a viable option by other states for\nresolving disputes.\n\nCivil War general Robert E. Lee said famously that it was a good thing war was\nso terrible, “otherwise we should grow too fond of\nit.”[7](part0023.html#c19-ftn7) The horrors and costs of war encourage\ncountries to choose diplomacy over battle, but when cyberattacks eliminate\nmany of these costs and consequences, and the perpetrators can remain\nanonymous, it becomes much more tempting to launch a digital attack than\nengage in rounds of diplomacy that might never produce results.\n\nBut the digital weapon didn’t just launch a new age of warfare, it altered the\nlandscape for all cyberattacks, opening the door to a new generation of\nassaults from state and nonstate actors that have the potential to cause\nphysical damage and even loss of life in ways never before demonstrated. “My\nprediction is that we are all going to become nostalgic for the days of fame-\nseeking mass mailers and network worms,” Symantec’s Kevin Haley wrote of the\npost-Stuxnet future.[8](part0023.html#c19-ftn8) LoveLetter, the Conficker\nworm, and even the Zeus banking Trojan would become quaint reminders of the\ndays when attacks were simpler and, by comparison, more innocent.\n\nStuxnet was a remarkable achievement, given its sophistication and single-\nminded focus. But it was also remarkably reckless. Because like the atomic\nbombs detonated over Hiroshima and Nagasaki, it introduced the use of a\npowerful technology that will have consequences for years to come. Kennette\nBenedict, executive director of the _Bulletin of the Atomic Scientists_ ,\nnoted several parallels between Stuxnet and the first atomic bombs in an\narticle she wrote for that publication about the lack of foresight that went\ninto developing and unleashing both technologies. In both cases, government\nand scientific leaders raced to develop the weapons for the United States out\nof fear that adversaries would create and unleash them first. The long-term\nconsequences of dropping the atomic bombs were also as poorly understood in\nthe 1940s as the consequences of unleashing digital weapons are today—not only\nwith regard to the damages they would cause, but to the global arms race they\nwould create. “We have come to know how nuclear weapons can destroy societies\nand human civilization,” Benedict wrote. “We have not yet begun to understand\nhow cyberwarfare might destroy our way of life.”\n\nAnd in another parallel with atomic bombs, despite alarm bells sounded about\ntheir use, the United States continued to develop first atomic weapons and now\ndigital ones without public discussion about how they should be used or their\nimpact on global security and peace.[9](part0023.html#c19-ftn9) How ironic\nthen, Benedict noted, “that the first acknowledged military use of\ncyberwarfare is ostensibly to prevent the spread of nuclear weapons. A new age\nof mass destruction will begin in an effort to close a chapter from the first\nage of mass destruction.”\n\nDespite the parallels, there is at least one crucial difference between the\natomic bombs of the 1940s and Stuxnet. The bar was high for someone to build\nor obtain a nuclear weapon—or any conventional missile and bomb, for that\nmatter. But cyberweapons can be easily obtained on underground markets or,\ndepending on the complexity of the system being targeted, custom-built from\nscratch by a skilled teenage coder, a task made simpler by the fact that every\ncyberweapon carries the blueprints for its design embedded within it. When you\nlaunch a cyberweapon, you don’t just send the weapon to your enemies, you send\nthe intellectual property that created it and the ability to launch the weapon\nback against you.[10](part0023.html#c19-ftn10) It would be comparable to a\nscenario where, if in 1945, it wasn’t just radioactive fallout that rained\ndown from the bombs onto Hiroshima and Nagasaki but all of the scientific\nequations and schematics for constructing them as well.\n\nThe nations, of course, that are most at risk of a destructive digital attack\nare the ones with the greatest connectivity. Marcus Ranum, one of the early\ninnovators of the computer firewall, called Stuxnet “a stone thrown by people\nwho live in a glass house.”[11](part0023.html#c19-ftn11)\n\nStuxnet was proof that a digital attack, consisting of nothing more than\nbinary commands, could achieve some of the same destructive results as a\nconventional bomb. But it also showed how even a powerful nation like the\nUnited States, with unmatched air and sea defenses, could be vulnerable to a\nsimilar assault from adversaries who never had to venture beyond their borders\nto launch an attack. As Mike McConnell, the former director of national\nintelligence, told a US Senate committee in 2011, “If the nation went to war\ntoday, in a cyberwar, we would lose. We’re the most vulnerable. We’re the most\nconnected. We have the most to lose.”[12](part0023.html#c19-ftn12)\n\nThe targets most in danger from a digital attack in the United States are not\njust military systems but civilian ones—transportation, communication, and\nfinancial networks; food manufacturing and chemical plants; gas pipelines,\nwater, and electric utilities; even uranium enrichment\nplants.[13](part0023.html#c19-ftn13) “We now live in a world where industrial\ncontrol systems can be attacked in the event of a crisis,” Stewart Baker,\nformer DHS assistant secretary has said. “We do not have a serious plan for\ndefending our industrial control systems even though our entire civil society\ndepends on it.”[14](part0023.html#c19-ftn14)\n\nCritical infrastructure has always been a potential target in times of war.\nBut civilian infrastructure in the United States has long enjoyed special\nprotection due to the country’s geographical distance from adversaries and\nbattlefields. That advantage is lost, however, when the battlefield is\ncyberspace. In a world of networked computers, every system is potentially a\nfront line. There are “no ‘protected zones’ or ‘rear areas’; all are equally\nvulnerable,” Gen. Kevin Chilton, commander of the US Strategic Command, told\nCongress.[15](part0023.html#c19-ftn15)\n\nThe laws of war prohibit direct attacks on hospitals and other civilian\ninfrastructure unless deemed a necessity of war, with military leaders subject\nto war crimes charges should they violate this. But the protections provided\nby law crumble when attribution is a blur. Since a hack from a cyber army in\nTehran or Beijing can be easily designed to look like a hack from Ohio, it\nwill be difficult to distinguish between a nation-state attack launched by\nIran and one launched by a group of hackers simply bent on random mayhem or\ncivil protest. Stuxnet was sophisticated and came with all the hallmarks of a\nnation-state attack, but not every attack would be so\ndistinguishable.[16](part0023.html#c19-ftn16)\n\nSome have argued that nation-state attacks would be easy to spot because they\nwould occur in the midst of existing tension between nations, making the\nidentity of the aggressor clear—such as the volley of denial-of-service\nattacks that disabled government websites in Georgia in 2008 in advance of a\nRussian invasion of South Ossetia. But even then it would be easy for a third\nparty to exploit existing tension between two nations and launch an anonymous\nattack against one that appeared to come from the other in order to ignite a\ncombustible situation.[17](part0023.html#c19-ftn17)\n\nIn November 2013, Israel held a simulated exercise at Tel Aviv University that\nillustrated the difficulties of identifying an attacker, particularly when\nthird parties enter a conflict with the intention of escalating hostilities\nbetween others. Using what were described as extreme but realistic scenarios,\nthe war game pitted Iran and Iran-backed Hezbollah in Lebanon and Syria\nagainst Israel, and began with a series of simulated physical skirmishes\nagainst Israel that escalated into cyberattacks that threatened to pull the\nUnited States and Russia into the conflict to defend their allies.\n\nThe simulation began with an explosion at an offshore drilling platform, with\nrockets lobbed over the border from Lebanon into Northern Israel and blasts in\nTel Aviv, and was followed by network disruptions that paralyzed a hospital in\nIsrael. The cyberattacks were traced to an Iranian server, but Iran denied\nresponsibility, insisting the Israelis were trying to put the blame on it in\norder to generate Western support for a strike against Tehran. Then the\nnetwork attacks spread to the United States, forcing Wall Street trading to\nhalt and shutting down air traffic control at JFK Airport. The White House\ndeclared a state of emergency after two planes crash-landed and killed 700\npeople. This time the attacks were traced first to a server in California, but\nthen, puzzlingly, to Israel.\n\nWhen the game ended, Israel was preparing to launch physical attacks against\nHezbollah in Syria and Lebanon—over the cyberattacks attributed to them and\nIran—and tensions between the United States and Israel had risen to a\ndangerous boil over questions about who was responsible for the cyberattacks\nagainst the United States.[18](part0023.html#c19-ftn18) “If we hadn’t stopped\nwhen we did, the entire region could have been engulfed in flames,” said Haim\nAssa, the game-theory expert who designed the exercise.\n\nThe simulation was instructive to participants on a number of levels. The\nUnited States “realized how difficult if not impossible it is to ascertain the\nsource of attack,” retired US Army Gen. Wesley Clark, who participated in the\nexercise, said. And an Israeli official noted “how quickly localized cyber\nevents can turn dangerously kinetic when leaders are ill-prepared to deal in\nthe cyber domain.” To this end, they learned that the best defense in the\ndigital realm is not a good offense but a good defense, because without a\nproperly defended critical infrastructure, leaders were left with little room\nto maneuver in their decision making when an attack occurred. When civilian\nsystems were struck and citizens were killed, leaders were under pressure to\nmake quick decisions, often based on faulty and incomplete\nconclusions.[19](part0023.html#c19-ftn19)\n\nIT’S EASY TO see why militaries and governments are embracing cyberweapons.\nAside from offering anonymity and a perceived reduction in collateral damage,\ncyberweapons are faster than missiles, with the ability to arrive at their\ndestination in seconds, and can be tweaked on the fly to combat\ncounterdefenses. If a zero-day vulnerability gets patched, attackers can draw\nfrom a reserve of alternative exploits—as Stuxnet’s developers did—or change\nand recompile code to alter its signatures and thwart detection.\n\n“Cyber, in my modest opinion, will soon be revealed to be the biggest\nrevolution in warfare, more than gunpowder and the utilization of air power in\nthe last century,” Israeli Maj. Gen. Aviv Kochavi has\nsaid.[20](part0023.html#c19-ftn20)\n\nBut cyberweapons have limited use. If tightly configured to avoid collateral\ndamage in the way Stuxnet was, each one can be deployed only against a small\nset of targets without being reengineered. And unlike a bunker-busting bomb or\nstealth missile, a cyberweapon can instantly become obsolete if the\nconfiguration of a target system or network changes. “I am not aware of any\nother weapons systems in the history of warfare that can be disabled by their\ntargets with a click of a mouse button,” Marcus Ranum\nnotes.[21](part0023.html#c19-ftn21) And any time a cyberweapon gets exposed,\nit isn’t just that weapon that gets burned, but any other weapons that use the\nsame novel techniques and methods it employed. “At this point, we can be sure\nthat anyone who builds a gas centrifuge cascade is going to be a little bit\nmore careful about their software than usual,” said Thomas Rid, a war studies\nscholar at King’s College, London.[22](part0023.html#c19-ftn22)\n\nBut another problem with digital weapons is that they can be difficult to\ncontrol. A good cyberweapon should operate in a predictable manner so that it\nhas a controlled impact and produces expected results each time it’s deployed,\ncausing little or no collateral damage. It needs precision design so that it\nexecutes only on command or automatically once it finds its target; and it\nshould be recallable or have a self-destruct mechanism in case conditions\nchange and a mission needs to be aborted. Andy Pennington, the former Air\nForce weapons system officer cited in an earlier chapter, likens an\nuncontrollable cyberweapon to a biological agent out of control. “If you don’t\nhave positive control over the weapon … you don’t have a weapon, you’ve got a\nloose cannon. We created conventions and said we’re not going to use\nbiological and chemical warfare weapons, because we do not have accurate\ntargeting, we do not have access control, they’re not recallable and they’re\nnot self-destruct-capable.”[23](part0023.html#c19-ftn23)\n\nStuxnet had some controls built into it, but lacked others. It was a targeted,\nprecision weapon that unleashed its payload only on the specific systems it\nwas designed to attack. And it had a time-release mechanism so that it\ninitiated its sabotage only when certain conditions on the target machines\nwere met. But once unleashed, Stuxnet couldn’t be recalled, and it had no\nself-destruct mechanism—it only had an infection kill date that prevented it\nfrom spreading beyond a certain date three years in the future. And although\nthe earliest versions of Stuxnet had limited spreading capabilities, the March\n2010 version was clearly a “loose cannon,” albeit a defused one, since\nalthough it spread uncontrollably to thousands of machines that weren’t its\ntarget, it didn’t sabotage them.\n\nWould other digital weapons be as well designed or as lucky, though?\nCollateral damage in cyberspace has a longer reach than in the physical realm.\nA bomb dropped on a target might cause collateral damage, but it would be\nlocal. Computer networks, however, are complex mazes of interconnectivity, and\na cyberweapon’s path and impact once unleashed aren’t always predictable. “We\ndo not yet have the ability to scope collateral damage for all cyberattacks,”\nJim Lewis of the Center for Strategic and International Studies has noted.\n“For attacks that disable networks, there could be unpredictable damage not\nonly to the target, but also to noncombatants, neutrals or even the attacker,\ndepending upon the interconnections of the target network or machine. This\nmakes the political risk of unintended consequences unpredictable (an attack\non a Serbian network, for example, damages NATO allies’ commercial activities)\nand carries with it the risk of escalating a conflict (an attack on North\nKorea damages services in China).”[24](part0023.html#c19-ftn24)\n\nDESPITE THE APPARENT march toward digital warfare that Stuxnet initiated, it’s\nfair to ask what the likelihood is that a catastrophic digital event will ever\noccur. Defense Secretary Leon Panetta has said the United States is in a\n“pre-9/11 moment,” with adversaries plotting and preparing for the right\nopportunity to launch destructive cyberattacks on its systems. But Thomas Rid\nhas called cyberwarfare “more hype than hazard”—the “shiny new thing” that has\ncaught the attention of militaries like a gleaming new train set opened on\nChristmas morning. In reality, he thinks, it will have much less impact than\npeople imagine.[25](part0023.html#c19-ftn25) Any future use of digital weapons\nwill likely be as an enhancement to conventional battle, not as a replacement\nfor it. Critics of digital doomsayers also point to the fact that no\ncatastrophic attack has occurred to date as evidence that the warnings are\noverblown.\n\nBut others argue that no passenger jets had been flown into skyscrapers,\neither, before 9/11. “I think to … say it’s not possible, it’s not likely, is\nreally way too early. All sorts of things could happen over the next couple of\nyears,” says Jason Healey, head of the Cyber Statecraft Initiative at the\nAtlantic Council in Washington, DC, who was an original member of the\nmilitary’s first cyber taskforce. “As more systems get connected to the\ninternet, and cyberattacks progress from simply disrupting ones and zeros to\ndisrupting things made of concrete and steel, things will change, and the days\nwhen no one has died from a cyberattack or the effects of a cyberattack will\nbe over.”[26](part0023.html#c19-ftn26)\n\nSome think the threat is overblown because most actors capable of pulling off\nan attack would be dissuaded by the risk of a counterstrike. In fact, some\nwondered after Stuxnet was discovered if it had been intentionally burned by\nIsrael or the United States to send a message to Iran and other countries\nabout the digital attack capabilities of these two countries. The fact that it\nhad remained undetected for so long and was only discovered by an obscure\nantivirus firm in Belarus led some to believe that Stuxnet had not been\ndiscovered so much as disclosed. Gen. James Cartwright, former vice chairman\nof the Joint Chiefs of Staff—the man said to have played a large role in the\nOlympic Games operation in the United States—was in fact an advocate of making\ndeclarations about US cyber capabilities in the service of deterrence.\n\n“For cyber deterrence to work,” Cartwright said in 2012, “you have to believe\na few things: One, that we have the intent; two, that we have the capability;\nand three, that we practice—and people know that we\npractice.”[27](part0023.html#c19-ftn27) Cartwright has since been investigated\nby the Justice Department for suspicion of leaking classified information\nabout Stuxnet to the _New York Times_ , though as of this writing he has not\nbeen charged with any wrongdoing and has denied the allegations.\n\nBut while deterrence of this sort might work for some nations—as long as they\nbelieve an attack could be attributed to them—irrational actors, such as rogue\nstates and terrorist groups, aren’t deterred by the same things that deter\nothers. “The day a terrorist group gets cyberattack capabilities, they will\nuse them,” Jim Lewis told Congress in 2012.[28](part0023.html#c19-ftn28)\n\nLewis expects that in the future, limited digital conflicts that disrupt\nmilitary command-and-control systems may arise between the United States and\nRussia or China, but these countries likely will not attack critical\ninfrastructure, “because of the risk of escalation.” But once countries like\nIran and North Korea acquire cyberattack capabilities, a strike against\ncivilian targets in the United States will be more likely. As US forces strike\ntargets in their countries, they will feel “little or [no] constraint against\nattacking targets in ours,” he wrote in a 2010\npaper.[29](part0023.html#c19-ftn29) And threats of retaliation made by the\nUnited States to deter such attacks would have little effect on such groups\nsince “their calculus for deciding upon an attack is based on a different\nperception of risks and rewards,” he noted. Likewise, as smaller countries and\nnon-state insurgents acquire the digital means to strike distant targets,\n“disruptions for political purposes and even cyber attacks intended to damage\nor destroy could become routine,” he says. The Taliban in Afghanistan or Al-\nShabaab in Somalia have little chance of launching a conventional retaliatory\nstrike against the US homeland, but when they eventually acquire, or hire, the\nability to launch effective cyberstrikes, this will change. “These strikes\nwill be appealing to them as it creates the possibility to bring the war to\nthe U.S. homeland,” Lewis notes. Although they may not acquire the ability to\npull off massive attacks, “harassment attacks” aimed at specific targets like\nWashington, DC, Lewis says, will certainly be within their means, and\ndepending on the severity of the attack or its cascading effects, essential\nsystems and services could be lost for extended periods of time.\n\nWith cyberweapons in the hands of others, the United States may also find\nitself having to recalculate the risk of blowback when planning conventional\nattacks, Lewis notes. In 2003, US forces invading Iraq met with little\nresistance, but what if Iraq had possessed cyberweapons that it launched in\nretaliation? “These would not have changed the outcome of the invasion but\nwould have provided a degree of vengeance [for Iraq],” he\nsays.[30](part0023.html#c19-ftn30)\n\nIf there are disagreements about the likelihood of digital attacks against\ncritical infrastructure occurring, there are also disagreements over the level\nof damage that such attacks can cause. Leon Panetta and others have warned\nabout digital Pearl Harbors and cyber 9/11s that will strike fear throughout\nthe land. But others note that the kind of digital destruction envisioned by\nthe doomsayers isn’t as easy to pull off as it seems. Conducting a disruptive\nattack that has long lasting effects “is a considerably more complex\nundertaking than flying an airplane into a building or setting off a truck\nfull of explosives in a crowded street,” notes W. Earl Boebert, a former\ncybersecurity expert at Sandia National Laboratories, whose job in part was to\nresearch such scenarios. Networks and systems can be brought down, but they\ncan also be brought back up relatively quickly. “Considerable planning is\nrequired to raise the probability of success to a point where a rational\ndecision to proceed can be made,” he writes.[31](part0023.html#c19-ftn31)\nThough one can argue that the 9/11 attacks required at least as much planning\nand coordination as a destructive cyberattack would require, a well-planned\ndigital assault—even a physically destructive one—would likely never match the\nvisual impact or frightening emotional effect that jets flying into the Twin\nTowers had.\n\nDESPITE THE RISKS and consequences of using digital weapons, there has been\nalmost no public discussion about the issues raised by the government’s\noffensive operations. Critics have pointed out that the Obama administration\nhas been more open about discussing the assassination of Osama bin Laden than\ndiscussing the country’s offensive cyberstrategy and operations. When\nquestions about the rules of engagement for digital attacks were raised during\nthe confirmation hearing for Gen. Keith Alexander to be made head of US Cyber\nCommand in 2010, Alexander refused to address them in public and said he would\nonly answer in a closed session.[32](part0023.html#c19-ftn32) And although\nthere are numerous doctrinal manuals in the public domain that cover\nconventional warfare, the same is not true for digital warfare. Even some who\nhave built their careers on secrecy have noticed the extreme secrecy around\nthis issue. “This may come as a surprise, given my background at the NSA and\nCIA and so on, but I think that this information is horribly over-classified,”\nformer CIA and NSA director Gen. Michael Hayden has said. “The roots to\nAmerican cyberpower are in the American intelligence community, and we frankly\nare quite accustomed to working in a world that’s classified. I’m afraid that\nthat culture has bled over into how we treat all cyber\nquestions.”[33](part0023.html#c19-ftn33)\n\nWithout more transparency, without the willingness to engage in debate about\noffensive operations, there is little opportunity for parties who don’t have a\ndirect interest in perpetuating operations to gauge their success, failure,\nand risks.\n\n“Stuxnet let the genie out of the lamp in terms of how you could do this kind\nof attack. You can now target all kinds of other devices,” says one former\ngovernment worker. “Where does it end? It doesn’t seem like there’s any\noversight of these programs. Sadly, the scientists are not pulling back the\nreins. They’re excited that someone is giving them money to do this research.\nI don’t think I ever saw anyone question what was being done. I don’t think\nthere was a lot of consciousness about it.”\n\nThere have been no public discussions about the repercussions of the digital\narms race launched by Stuxnet, or about the consequences of releasing weapons\nthat can be unpredictable and can be turned back against the United States.\n\nIn a report to Congress in 2011, the intelligence community noted that the\ndefenders of computer networks in the United States are perpetually outgunned\nby attackers and can’t keep pace with the changing tactics they deploy.\nExploits and exploitation methods evolve too quickly for detection methods and\ncountermeasures to keep up, a problem that will only grow worse as nations\ndevelop and deploy increasingly sophisticated attack methods. Until now, the\nevolution of computer attacks has been driven by innovations in the criminal\nunderground, but this will change as nation-state attacks like Stuxnet and\nFlame begin to drive future advancements. Instead of government hackers\nlearning novel techniques from the underground, the underground will learn\nfrom governments. And as countermeasures for digital weapons are developed,\nthe need to produce even more advanced weapons will grow, pushing further\ninnovations in weaponry. One US official has referred to Stuxnet as a first-\ngeneration weapon, on par with “Edison’s initial light bulbs, or the Apple\nII,” suggesting that more sophisticated designs have already replaced\nit.[34](part0023.html#c19-ftn34)\n\nThe criminal underground will benefit from the wealth of government-funded\nresearch and development put into digital weapons and spy tools, as they\nalready have done from Stuxnet and the arsenal of tools used in conjunction\nwith it. After Duqu was discovered in 2011, for example, exploits attacking\nthe same font-rendering vulnerability that it attacked showed up in various\nreadymade toolkits sold in the criminal underground. Within a year after Duqu\nused it, it was the most commonly targeted vulnerability that criminals used\nto surreptitiously install banking Trojans and other malware on\nmachines.[35](part0023.html#c19-ftn35) But even when non-state hackers can’t\nreplicate a sophisticated government attack bit-for-bit, they can still learn\nand benefit from it, as shown by Microsoft’s discovery that it would have\ntaken just three days for criminal hackers to pull off a low-rent version of\nthe Windows Update hijack that Flame performed.\n\nBrad Arkin, senior director of product security and privacy for Adobe, has\nsaid that his company’s primary security concern these days is not the\ncriminal hacker but the high-level, state-sponsored hacker, who comes flush\nwith wealth and a suitcase full of zero-day exploits to attack Adobe’s\nsoftware. “In the last eighteen months, the only [zero-day holes] found in our\nsoftware have been found by … carrier-class adversaries,” he said at a\nconference in 2011. “These are the groups that have enough money to build an\naircraft carrier. Those are our adversaries.”[36](part0023.html#c19-ftn36) The\nexploits used against Adobe products are “very, very expensive and difficult\nto build,” Arkin said, and once they’re designed and used by nation-state\nhackers, they trickle down to the crimeware tools.\n\nThe nation’s chief cyberwarrior, NSA’s General Alexander, acknowledged this\ntrend to a Senate committee in 2013. “We believe it is only a matter of time\nbefore the sort of sophisticated tools developed by well-funded state actors\nfind their way to groups or even individuals who in their zeal to make some\npolitical statement do not know or do not care about the collateral damage\nthey inflict on bystanders and critical infrastructure,” he\nsaid.[37](part0023.html#c19-ftn37) Alexander was referring to the well-funded\ntools that countries like China create to attack the United States, but no one\non the committee asked him about the contributions his own agency was making\nto the pool of tools and techniques that criminal hackers and hacktivists\nwould adopt. Nor did they ask about the ethics and consequences of stockpiling\nzero-day exploits and withholding information about security vulnerabilities\nfrom US system owners so the government can use them to attack the systems of\nadversaries.\n\nMichael Hayden notes that there have always been strategic tradeoffs between\nbuilding offensive capabilities and strengthening defenses. One of the core\nconcepts the government has traditionally used in making trade offs in the\nkinetic realm—that also applies to the cyber realm—is something known as\nNOBUS, or Nobody But Us.\n\n“Nobody but us knows it, nobody but us can exploit it,” he told me. “How\nunique is our knowledge of this or our ability to exploit this compared to\nothers?… Yeah it’s a weakness, but if you have to own an acre and a half of\nCray [supercomputers] to exploit it.…” If it was NOBUS, he said, officials\nmight “let it ride” and take advantage of the vulnerability for a while, at\nthe same time knowing full well “that the longer this goes, the more other\npeople might actually be able to exploit it.”[38](part0023.html#c19-ftn38)\n\nBut given the state of computer security today, and the amount of hammering\nthe United States is taking from cyberattacks, Hayden said he was prepared to\nacknowledge that it might be time to reevaluate this process.\n\n“If the habits of an agency that were built up in a pre-digital, analog age …\nare the habits of an agency [that is] culturally tilted a little too much\ntoward the offense in a world in which everybody now is vulnerable,” he said,\nthen the government might want to reassess.\n\nIn a report issued by a surveillance reform board convened by the White House\nin the wake of the Edward Snowden leaks, board members specifically addressed\nthis issue and recommended that the National Security Council establish a\nprocess for reviewing the government’s use of zero days. “US policy should\ngenerally move to ensure that Zero Days are quickly blocked, so that the\nunderlying vulnerabilities are patched on US Government and other networks,”\nthe review board wrote, noting that only “in rare instances, US policy may\nbriefly authorize using a Zero Day for high priority intelligence collection,\nfollowing senior, interagency review involving all appropriate\ndepartments.”[39](part0023.html#c19-ftn39) In almost all instances, they\nwrote, it is “in the national interest to eliminate software vulnerabilities\nrather than to use them for US intelligence collection.” The group also\nrecommended that cyber operations conducted by the US Cyber Command and NSA be\nreviewed by Congress in the same way the CIA’s covert operations are reviewed\nto provide more accountability and oversight.\n\nRichard Clarke, former cybersecurity czar under the Bush administration and a\nmember of the panel, later explained the rationale for highlighting the use of\nzero days in their report. “If the US government finds a zero-day\nvulnerability, its first obligation is to tell the American people so that\nthey can patch it, not to run off [and use it] to break into the Beijing\ntelephone system,” he said at a security conference. “The first obligation of\ngovernment is to defend.”[40](part0023.html#c19-ftn40)\n\nIn a speech addressing the review board’s report, President Obama ignored both\nof the panel’s recommendations for handling zero days and for conducting\noversight. But during a confirmation hearing for Vice Adm. Michael Rogers in\nMarch 2014 to replace the retiring General Alexander as head of the NSA and US\nCyber Command, Rogers told a Senate committee that the spy agency already had\na mature equities process for handling zero-day vulnerabilities discovered in\ncommercial products and systems and was in the process of working with the\nWhite House to develop a new interagency process for dealing with these\nvulnerabilities. He said it was NSA policy to fully document each\nvulnerability, to determine options for mitigating it, and to produce a\nproposal for how to disclose it.[41](part0023.html#c19-ftn41) In dealing with\nzero days, he said, it was important that the “balance must be tipped toward\nmitigating any serious risks posed to the US and allied networks.” And in\ncases where the NSA opts to exploit a zero day rather than disclose it, he\nsaid the agency attempts to find other ways to mitigate the risks to US\nsystems by working with DHS and other agencies.\n\nA month later, news reports indicated that President Obama had quietly issued\na new government policy on zero-day vulnerabilities in the wake of the Snowden\nrevelations and the review board’s report.[42](part0023.html#c19-ftn42) Under\nthe new policy, any time the NSA discovers a major flaw in software, it must\ndisclose the vulnerability to vendors and others so the flaw can be patched.\nBut the policy falls far short of what the review board had recommended and\ncontains loopholes.[43](part0023.html#c19-ftn43) It applies only to flaws\ndiscovered by the NSA, without mentioning ones found by government\ncontractors, and any flaw that has “a clear national security or law\nenforcement” use can still be kept secret by the government and exploited. The\nreview board had said exploits should be used only on a temporary basis and\nonly for “high priority intelligence collection” before being disclosed.\nObama’s policy, however, gives the government leeway to remain silent about\nany number of critical flaws as long as they can justify their use. There is\nalso no mention in the policy about what the government plans to do with zero-\nday vulnerabilities and exploits already in its arsenal of digital weapons.\n\nONE ISSUE EVEN the review board didn’t address, however, was the implication\nof subverting the trust of digital certificates and the Windows Update system\nto further offensive goals, as Stuxnet and Flame did.\n\nThe ACLU’s Christopher Soghoian has likened the Windows Update hijack to the\nCIA subverting the trusted immunization system to kill Osama bin Laden. In\nthat case, the spy agency reportedly recruited a doctor in Pakistan to\ndistribute immunization shots to residents in a certain neighborhood so the\ndoctor could surreptitiously collect DNA samples from people living in a\nwalled compound where bin Laden was believed to reside.\n\nIn a similar way, the Windows Update hijack, and other attacks like it,\nundermine trusted systems and have the potential to create a crisis of\nconfidence that could lead users to reject systems meant to protect them.\n\n“Automatic security updates are a good thing. They keep us safe. They keep\neveryone safe,” Soghoian told attendees at a conference after Flame’s\ndiscovery.[44](part0023.html#c19-ftn44) “Whatever the short-term advantage of\nhijacking the Windows Update process, it simply isn’t worth it.”\n\nBut Hayden says that sometimes undermining a trusted system _is_ worth it. He\nsays he would have made the same decision CIA director Leon Panetta made to\nsubvert the immunization system to locate bin Laden. “What I’m telling you is,\nthat [kind of decision-making] happened all the time,” he says. Though he\nacknowledges that “[sometimes] we can get it\nwrong.”[45](part0023.html#c19-ftn45)\n\nIf the United States was responsible for the Windows Update hijack in Flame,\nas reports indicate, there are questions about whether the hijack should have\nrequired some kind of notification and consent from Microsoft before it was\ndone. US intelligence agencies can’t do things that might put US businesses at\nrisk unless they have high-level legal authorities sign off on the operation\nand the company consents. They can’t, for example, make IBM an unwitting CIA\naccomplice by having an agent pose as an IBM employee without informing\nsomeone at the company who has fiduciary responsibilities. “The CIA _can_ do\nit,” says Catherine Lotrionte, a law professor at Georgetown University and a\nformer attorney in the CIA’s Office of General Counsel, “but [the agency has]\nto notify the CEO, because he or she has fiduciary duties owed to the\n[company’s] board.”[46](part0023.html#c19-ftn46)\n\nIf the use of Microsoft’s digitally signed certificate was deemed an\n“operational use” of a US company—because it involved using a legitimate\nMicrosoft credential to pass off a rogue file as a legitimate Microsoft\nfile—then Microsoft might have needed to be put on notice. “It depends what is\noperational use in the technical world,” Lotrionte says. “We know what it\nlooks like when it’s a human—[but] that technical business, that’s a hard\none.”\n\nWhen the malware was first exposed, some researchers wondered if Microsoft\nofficials might have known about the Windows Update attack beforehand; but\nothers note that if Microsoft had approved the operation, the attackers\nwouldn’t have needed to go through the trouble of doing an MD5 hash collision\nto obtain the certificate—unless the MD5 hash gave Microsoft plausible\ndeniability of cooperation.\n\n“The question is, would Microsoft have allowed this?” Lotrionte asks. “That’s\nwhat would concern me. The intelligence community will try everything, and I\noften wonder why companies put themselves at risk. I’m thinking if it was\noperational use and if they were put on notice, that’s interesting.”\n\nSources knowledgeable about the situation say that Microsoft was not notified\nand did not provide permission for the operation. “If that happened, it would\nbe the end of the company,” one said. “That’s a gamble nobody [at the company]\nwould take.” He called government subversion of Microsoft’s certification\nprocess “irresponsible” and “beyond shocking.”\n\n“It’s very tricky waters we’ve sailed into,” he said. “Guys who do this type\nof thing are going to create challenges for the private sector that I just\ndon’t think they’ve thought about.”\n\nBut hijacking the trusted Microsoft system didn’t just undermine the\nrelationship Microsoft had with its customers, it also contradicted the\ngovernment’s stated commitment to strengthening computer security in the\nUnited States.\n\nIn 2011, the White House published its International Strategy for Cyberspace,\na comprehensive document laying out the president’s vision for the internet,\nwhich emphasized the government’s responsibility to help make networks and\nsystems more secure and resilient. It aimed to do this in part by establishing\nresponsible norms of conduct and creating a system for sharing vulnerability\ninformation between public and private sectors to shore up systems. But Jason\nHealey says the government’s actions call its sincerity into question.\n\n“If you come out with a policy that subverts Microsoft certificates, subverts\nWindows Updates to spread malware, it’s difficult to get yourself to a\nposition where cyberspace is safer, more secure and resilient,” he says. “In\nsome ways I feel like the Fort Meade crowd are the Israeli settlers of\ncyberspace—it doesn’t matter what the official policy is, they can go out and\nthey can grab these hills, and they’re changing the facts on the ground.… If\nwe’re ever going to get defense better than offense, some things should be\nmore sacrosanct than others.…[But] if we have a norm that it’s OK to go after\nthese things, if we’re creating this crisis of confidence … that’s just going\nto bounce back at us.”\n\nHealey says a cavalier approach to offensive operations that erodes security\nand trust in critical systems creates the potential for the information\nhighway to become dense with street skirmishes and guerrilla warfare. “We can\nthink about attacks getting not just better, but way better. Where cyberspace\nisn’t just Wild West, it’s Somalia.”\n\nNot everyone would agree with Healey and Soghoian that some systems should be\noff-limits. There are parallels in the analog world, for example, where the\nCIA exploits vulnerabilities in door locks, safes, and building security\nsystems to gain access and collect intelligence. No one has ever suggested\nthat the CIA disclose these vulnerabilities to vendors so the flaws can be\nfixed.\n\nBut without lawmakers or an independent body asking the right questions to\nprotect the long-term interests of security and trust on the internet,\ndiscussions about the nation’s offensive operations occur only among insiders\nwhose interests lie in advancing capabilities, not in curbing them, and in\nconstantly pushing the limits of what is possible. “It’s all people that have\nhigh-level security clearances [who are making these decisions], and there are\nprobably few people [among them] that have ever worked a day in the real\nprivate sector where they had to really defend America’s critical\ninfrastructure,” Healey says. “So it’s very easy for them to make these\ndecisions to keep going farther and farther … because the government accrues\nall the benefit. If we use a zero-day for Flame, the government gets the\nbenefit of that. It’s the private sector that’s going to get the\ncounterattacks and that’s going to suffer from the norms the US is now\ncreating that says it’s OK to attack.”\n\nIf the White House and Capitol Hill aren’t concerned about how the\ngovernment’s actions undermine the security of computer systems, they might be\nconcerned about another consequence of the government’s offensive actions. As\nStephen Cobb, a senior security researcher with security firm ESET, noted,\n“When our own government adds to the malware threat it adds to an erosion of\ntrust that undermines the digital economy.”[47](part0023.html#c19-ftn47)\n\nBECAUSE THE GOVERNMENT’S cyber operations are so heavily classified, it’s not\nclear what kind of oversight—by the military or by lawmakers—currently occurs\nto prevent mishaps, or what kinds of investigations, if any, are conducted\nafter mishaps occur.\n\nHayden says the oversight is extensive. “When I was in government,\ncyberweapons were so over-watched, it was my view it would be a miracle if we\never used one.… It was actually an impediment getting in the way of the\nappropriate and proper use of a new class of weapons, it was so hard to get\nconsensus.”\n\nBut in 2009, long after Stuxnet had already been launched against systems in\nIran, the National Academy of Sciences wrote that the “policy and legal\nframework for guiding and regulating US cyberattack capabilities was ill-\nformed, undeveloped, and highly uncertain.”[48](part0023.html#c19-ftn48)\nDespite a decade of cyberoffensive planning and activity, little had been\nresolved regarding the rules of engagement for digital warfare since the first\ntask force had been created in 1998.\n\nThe Pentagon and White House finally took steps to address this in 2011—more\nthan three years after Stuxnet was first launched—when the Defense Department\nreportedly compiled a classified list of all the cyberweapons and tools at its\ndisposal and began to establish a long-overdue framework for how and when they\ncould be used.[49](part0023.html#c19-ftn49) The military regularly compiled a\nlist of approved conventional weapons, but this was the first time\ncyberweapons were included on the list, a senior military official told the\n_Washington Post_ , calling it the most significant development in military\ncyber doctrine in years.\n\nThen in 2012, the president signed a secret directive establishing some\npolicies for computer network attacks, the details of which we know about only\nbecause Edward Snowden leaked the classified\ndocument.[50](part0023.html#c19-ftn50) Under the directive, the use of a\ncyberweapon outside a declaration of war requires presidential approval, but\nin times of war, military leaders have advance approval to take quick action\nat their discretion. Digital attacks have to be proportional to the threat, as\nwell as limit collateral damage and avoid civilian casualties—parameters that\nstill leave the military a lot of discretion.[51](part0023.html#c19-ftn51) Any\ndigital operation that could disrupt, destroy, or manipulate computers or is\n“reasonably likely to result in significant consequences” also requires\npresidential approval. Significant consequences include loss of life, damage\nto property, and serious economic impact, as well as possible retaliation\nagainst the United States or adverse effects on foreign policy.\n\nPresidential authorization is also required to plant a logic bomb in a foreign\nsystem or a beacon marking it for later attack. But is not needed for\nespionage operations that are conducted for the sake of simply collecting data\nor mapping a network, unless the operation involves a worm or other malware\nthat could spread. Notably, before taking action, the military has to weigh\nthe possible effects an operation might have on the stability and security of\nthe internet, and whether it would establish unwelcome norms of international\nbehavior. Though some might argue that Stuxnet and Flame had already violated\nthis guideline and established unwelcome norms of behavior, Herbert Lin, a\ncybersecurity expert with the National Research Council, points out that all\nthe directive says is that military leaders have to ask questions about\nwhether an operation might establish unwelcome norms, not that they can’t\nproceed with it anyway. “Establishing an undesirable norm may in fact have\nbeen a price they were willing to pay to set back the Iranian nuclear\nprogram,” he says of Stuxnet and Flame.[52](part0023.html#c19-ftn52)\n\nThe presidential directive addresses only the _military’s_ use of digital\noperations, however. A list of exceptions in the document excludes\nintelligence agencies like the NSA and CIA from it, as well as law enforcement\nagencies like the FBI and Secret Service. And although it establishes broad\nground rules for conducting offensive military cyber operations, it does not\naddress questions that are raised when the United States is faced with\nresponding to a digital attack. In 2011, Pentagon officials took at least one\nstep in this direction when they announced that any digital attack against the\nUnited States that took out portions of the electric grid or resulted in\ncasualties would be considered an act of war and receive the appropriate\nresponse—even a kinetic military response, if the situation called for it,\nusing “all necessary means.”[53](part0023.html#c19-ftn53) In other words, as\none military official put it, “If you shut down our power grid, maybe we will\nput a missile down one of your smokestacks.”[54](part0023.html#c19-ftn54) At\nleast they didn’t assert, as the Joint Chiefs of Staff did in a statement of\ndoctrine in 2004, that the United States reserved the right to respond to some\ncyberattacks with nuclear weapons. That wording has disappeared in subsequent\nstatements of doctrine from the Joint Chiefs, Lin points out, but members of\nthe Defense Science Board apparently hoped to revive it when they asserted in\n2013 that the United States should not rule out a nuclear response. It’s\nprobably a good thing that the Science Board is just an advisory group and has\nno say in policy.\n\nThough the Snowden leak of the presidential directive hints at some of the\nquestions the government has been asking internally about these issues, the\npublic still has little understanding of what questions have been answered and\nwhich are still unresolved. Lin says that for the sake of transparency there\nare important conversations that could be made public without compromising\nclassified operations. “We could in fact get into a discussion about what is\npossible without saying what the US is actually doing,” he says. It would also\nbe possible for US Cyber Command and the NSA to provide examples of\ncircumstances under which they would use cyberweapons, or explain the\ncircumstances under which they hoard information about zero-day\nvulnerabilities versus when they might allow disclosure of information about a\nsecurity hole to get it fixed. And it would be important to know, at the very\nleast, where the government draws the line in compromising trusted systems\nthat are critical to the integrity of the internet—if it draws a line at all.\n\n“Senators and congressmen need to be educated about this,” Lin says, not to\nmention the public. “And there ought to be an accounting somewhere about all\nthe cyberattacks that the US conducts for any purpose … that tells you what\nwas attacked and under what circumstances.… It can be classified, but at least\nit would give the first step toward better understanding what the US is\nactually doing.” Lawmakers like Rep. Mike Rogers (R-MI) insist that Congress\n_has_ held private discussions on the government’s cyber activities. But so\nfar, Capitol Hill has shown little interest in holding even basic _public_\ndiscussions about the government’s offensive operations.\n\n“I do believe without question there needs to be a full conversation about\ndoctrine and there needs to be a full conversation about rules of engagement,”\nAir Force general Robert Kehler, the current head of US Strategic Command,\nsaid in 2011, before the presidential directive was signed. “I can’t say all\nof that needs to be in the public domain.”[55](part0023.html#c19-ftn55)\n\n![](../images/00007.jpeg)\n\nAS THE UNITED STATES and other countries beat the drum of cyberwarfare, it’s\nnot just policy questions that are still unanswered, however. Many of the\nlegal questions around digital operations are still unresolved.\n\nSome, like Kaspersky Lab founder Eugene Kaspersky, have called for a cyber\narms treaty to control the proliferation of digital weapons and set norms for\ntheir use. But as noted previously, there are obvious problems with trying to\ncontrol the stockpiling of nonphysical weapons. Governments can sign treaties\nto halt the proliferation of nuclear weapons and use satellite imagery and UN\ninspectors to track the movement of nuclear materials. But satellites can’t\ntrack the movement of illicit digital weapons, nor can custom inspections\ncatch the smuggling of malicious code across borders. Nor can anyone monitor\nall of the rogue players who might emerge to exploit the vulnerabilities in\ncritical infrastructure systems that Stuxnet exposed.\n\nAs for developing new laws to govern the use of cyberattacks by nations, the\nconsensus among legal experts seems to be that existing laws of warfare will\nwork just fine—it’s just that new interpretations of these laws need to be\ndeveloped to address cyber.\n\nIn 2013, a group of twenty international legal experts convened by a NATO-\nrelated institute attempted to do just this. The result was the three-hundred-\npage _Tallinn Manual_ , designed to help military legal advisers in NATO\nmember states develop cyber doctrine for their\narmies.[56](part0023.html#c19-ftn56) But despite the manual’s length, it left\nmany questions unanswered. The experts found that while some attacks in\ncyberspace have clear parallels to conventional attacks in physical space,\nothers are murkier.\n\nUnder the UN Charter’s Law of Armed Conflict, for example, they determined\nthat hacking the control system of a dam to unleash water into a valley was\nthe equivalent of breaching the dam with explosives. And launching an attack\nfrom a proxy system located in a neutral country would be prohibited in the\nsame way that an army couldn’t march through a neutral country’s territory to\ninvade an enemy. They also determined that an attack had to cause physical or\npersonal damage to qualify as an act of force—simply erasing hard drives, if\nit didn’t result in physical damage or injury, didn’t qualify. But what about\nan attack on Wall Street that damaged a nation’s economy or aimed to do so?\nHere they found the legal waters less clear. Some of the experts believed such\nan attack qualified, while others were less convinced.\n\nThe experts also made a distinction between an act of force and an armed\nattack. Though the latter is considered more serious, it’s not clearly\ndefined. It’s generally interpreted to refer only to the gravest uses of\nforce, which are judged by the effects the attack has. Under Article 24 of the\nUN Charter, nations can respond to an act of force only with nonforceful\ncountermeasures—such as applying economic sanctions or cutting off diplomatic\nties with the offending nation.\n\nUnder Article 51, however, every state has the right to defend itself with\nlethal force—individually, or collectively on behalf of allies—if it or an\nally suffers an armed attack, as long as the response is necessary and\nproportional to the initial attack and occurs while the threat of the original\nattack is ongoing or there is a threat of a future attack. As for what _level_\nof damage qualifies as an armed attack, and therefore justifies a lethal\nresponse—it’s up to the victim to determine the threshold and defend its\ndecision to the United Nations.[57](part0023.html#c19-ftn57) But what about an\nattack that is intended to cause great harm but fails to achieve it? A missile\nlaunched by one nation against another that gets diverted by a Patriot missile\nis still an attempted armed attack. Would the same hold true in the cyber\nrealm? Catherine Lotrionte says no, since the effect of the attack is what\nmatters, not the intent. But Gary Brown, senior legal adviser to the US Cyber\nCommand from 2010 to 2012, says it likely _would_ be considered an armed\nattack “if you can make an argument [with evidence] that it was going to have\na kinetic effect.”[58](part0023.html#c19-ftn58)\n\nAnd what about espionage? Under international law and US policy, espionage is\nnot an act of war. But since espionage could be the prelude to a destructive\nattack, as it was with Stuxnet and the spy tools the attackers used to collect\nintelligence for that operation, could the discovery of spy tools on a system\nindicate an intention to conduct an armed attack? Under current doctrine, an\narmed attack has to be current or imminent to merit a lethal use of force in\nresponse, but what determines imminence? After 9/11, the United States\nasserted that the invasion of Afghanistan was an act of self-defense, under\nArticle 51, since the country was housing al-Qaeda leaders who were believed\nto be planning additional strikes against the United States.\n\nOne thing the _Tallinn_ experts did agree on unanimously was that Stuxnet was\nan act of force that likely violated international law. They were split,\nhowever, on whether it constituted an armed attack. As an armed attack, Iran\nwould have been within its rights to defend against the digital onslaught with\na counterstrike—digital or kinetic—as long as it was proportional to the\ndamage Stuxnet caused and occurred while the attack was ongoing. Once the\nattack subsided and there was no impending threat to the centrifuges or threat\nof another impending attack—that is, once the weapon was discovered and\ndefused—the proper response was diplomacy or some other nonforceful measure.\n\nIt’s important to note that official US policy, unlike the interpretation of\nthe _Tallinn_ experts, doesn’t distinguish between an act of force and an\narmed attack—the two are considered the same. Under this interpretation, then,\nStuxnet was an illegal armed attack, and Iran could have made a case for\nresponding in self-defense. It also means, though, that if someone were to use\na weapon like Stuxnet against the United States, the US government would\nconsider it an armed attack, something Lotrionte says concerns\nher.[59](part0023.html#c19-ftn59)\n\nThere have been conflicting reactions to some of the _Tallinn Manual_ ’s\nconclusions. Martin Libicki, an expert on cyberwarfare with the RAND\ncorporation, questions the wisdom of allowing cyber conflicts to be resolved\nwith kinetic attacks. He wonders if it wouldn’t be wiser to apply “Las Vegas\nrules” to cyberwarfare so that what happens in cyberspace stays in cyberspace.\n“Your escalation potential, if you go to the kinetic realm than if you stay in\nthe cyber realm, is much greater,” he says. “So a rule that says you can only\nmatch cyber with cyber puts a limit on your topside\nrisk.”[60](part0023.html#c19-ftn60)\n\nLotrionte, however, says the method of a counterattack doesn’t matter, since\nescalation is controlled by the fact that a counterattack must be both\nnecessary and proportional. “Necessary means you have to determine that there\nis no other way to resolve this threat,” she says. “You can’t talk, you can’t\nsanction or call on the Security Council. If there is any other way to stop\nthese attacks, you have to use that, and not use of force. That’s how you stop\nescalation.”[61](part0023.html#c19-ftn61)\n\nOthers point out the difficulty of applying the conventional laws of war to\nthe cyber realm, where attribution is a problem. The Law of Armed Conflict\nrequires that an attacker be identified to conduct a counterstrike. Though\nattribution in a digital attack can sometimes be determined—through\nintelligence means if not forensic ones—the anonymous nature of cyberattacks\nmakes responding quickly to an attack, while the threat is current,\ncomplicated to say the least.\n\n“Smoking guns are hard to find in the counterterrorism environment; smoking\nkeyboards are that much more difficult,” Frank Cilluffo, director of the\nHomeland Security Policy Institute at George Washington University told\nCongress. Cyberspace, he said, “is made for plausible\ndeniability.”[62](part0023.html#c19-ftn62)\n\nIf all of this wasn’t enough to complicate the issue of cyberwarfare, there\nare further problems having to do with the lack of a clear understanding about\nwhat constitutes a cyberweapon. In the kinetic world, a weapon is something\nthat damages, destroys, kills, or injures, which is something very different\nfrom an espionage tool. But Gary Brown notes that so many activities in cyber\nare carried out by “a guy sitting at a keyboard typing commands” and doing\neverything from installing malware and destroying data, to destroying and\ndamaging a system or damaging equipment the system controls. “Does that mean\nthat the software or technique we used to get access to the system turned into\na weapon?” he asks. “That would mean everything [is a weapon]. It’s a very\ncomplicated issue. I don’t feel like we have a very good handle on it.”\n\nBrown says the lack of clarity about what constitutes a digital weapon and\nwhat constitutes attack activity as opposed to espionage raises the risk of\nescalated responses, since the same techniques and tools used for espionage\nand damaging attacks in the digital realm can be indistinguishable to the\nvictim.[63](part0023.html#c19-ftn63)\n\n“Traditional espionage is less likely to be escalatory because it was better\nunderstood,” he says. “Even if you cut through border-fence wire and tiptoed\ninto an office and stole files … it doesn’t look like we we’re starting a\nwar.… In cyber, if somebody got access to a critical system, maybe to the\nnuclear command-and-control … maybe they’re just looking around. Or maybe\nthey’re planning to disable it and launch a nuclear attack.… It’s that kind of\nescalation that worries me.”\n\nClearly Stuxnet and the prospect of digital warfare has raised a host of\nissues that have yet to be adequately addressed. And if it seems the United\nStates is late in getting around to looking at them, it’s not the only one.\n“There are countries [in Europe] that are not even close to writing rules,”\nsays Lotrionte.\n\nIN THE YEARS since Stuxnet was first exposed, a lot has changed—not just for\nthe military but for malware hunters. For the researchers who spent so much\ntime disassembling and analyzing Stuxnet—and its accompanying spy\ntools—deciphering the malware was an incomparable thrill that stretched the\nboundaries of virus research. But it also irrevocably changed the parameters\nof their profession by imbuing it with a degree of risk and politicization it\nhad never known before.\n\nIn one of his team’s final assessments of Stuxnet, Symantec’s Eric Chien wrote\nthat whether Stuxnet would usher in a new generation of real-world attacks\nthat targeted critical infrastructure or was just a once-in-a-decade\nphenomenon, they couldn’t say. But he was clear about his preference. It was\nthe type of threat, he said, “we hope to never see again.”\n\nThankfully, as of this book’s publication there has been no sign yet of the\ncounterstrikes against industrial control systems that Ralph Langner warned\nabout, nor have there been signs of any other types of comparable digital\nattacks launched by the United States or anyone else. Stuxnet still holds the\ndistinction of being the only known case of cyberwarfare on record. But that\ncan change at any time, now that Pandora’s digital box has been opened.\n\n* * *\n\n[1](part0023.html#c19-ftn1a) “Remarks by the President on Securing Our\nNation’s Cyber Infrastructure,” May 29, 2009, available at\n[whitehouse.gov/the-press-office/remarks-president-securing-our-nations-cyber-\ninfrastructure](http://www.whitehouse.gov/the-press-office/remarks-president-\nsecuring-our-nations-cyber-infrastructure). The claim that cyber intruders\nhave plunged foreign cities into darkness has been repeated often by many\nofficials, but has been disputed—though this hasn’t prevented officials from\ncontinuing to repeat it. The claim was first made by CIA senior analyst Tom\nDonahue while speaking at a conference for cybersecurity professionals in\n2008: “We have information that cyberattacks have been used to disrupt power\nequipment in several regions outside the US,” he said. “In at least one case,\nthe disruption caused a power outage affecting multiple cities.” He also said\nthe intrusions were “followed by extortion demands.” (See Thomas Claburn, “CIA\nAdmits Cyberattacks Blacked Out Cities,” _InformationWeek_ , January 18, 2008,\navailable at [informationweek.com/cia-admits-cyberattacks-blacked-out-\ncities/d/d-id/10635137](http://www.informationweek.com/cia-admits-\ncyberattacks-blacked-out-cities/d/d-id/10635137).) Donahue never named the\ncountry where the attacks occurred, but in 2009 _60 Minutes_ identified it as\nBrazil, asserting that a 2007 blackout in Espirito Santo that left 3 million\npeople without power was caused by hackers. (See “Cyber War: Sabotaging the\nSystem,” _60 Minutes_ , November 6, 2009, available at\n[cbsnews.com/news/cyber-war-sabotaging-the-\nsystem-06-11-2009](http://www.cbsnews.com/news/cyber-war-sabotaging-the-\nsystem-06-11-2009).) Others have claimed Donahue was referring to a 2005\noutage in Brazil instead. According to two sources I spoke with in 2009 who\nwere interviewed by _60 Minutes_ for their story, the newsmagazine sent a\nproducer to Brazil to try to verify the hacker/extortion claim but was never\nable to do so, though viewers weren’t told this. The Brazilian government\ndisputed the claim after the _60 Minutes_ show aired, pointing to a lengthy\nreport about the 2007 outage that attributed it to soot and equipment failure.\nFurnas, the Brazilian energy company that experienced the blackouts, is a\ncustomer of Marcelo Branquinho, who operated the only ICS security firm in\nBrazil at the time. Branquinho told me there was no evidence the blackout was\ncaused by anything but equipment failure. “We have full access to the\ndocumentation and [government reports investigating] what happened on these\ntwo blackouts,” he told me in October 2011, referring to both the 2005 and\n2007 incidents. “There is no single evidence that hacking activity happened\nhere. Both events were due to hardware problems, not software problems.”\nWhat’s more, he says the substation that was affected in the 2007 blackout was\nnot even an automated SCADA system that could be controlled by hackers. “It\nwas only hardware, so it couldn’t be hacked anyway,” he says. “I’m not saying\nthat we can’t be hacked. We can be hacked; it’s pretty easy. I believe that\nmost of the electric installations—not only here, but worldwide—have very weak\nsecurity if you compare them with a bank, for example, that has some good\nlevel of security infrastructure. But … in this case, the evidence tells us\nthat we weren’t hacked.” It’s possible the stories about the hacker blackout\nhave been confused with a real cyberextortion incident that occurred in 2005\nor 2006 but that had nothing to do with a blackout. Brazil’s director of\nHomeland Security Information and Communication told\n[Wired.com](http://www.Wired.com) that in this case, attackers breached an\nadministrative machine at a government agency using a default password and\ndeleted files on the machine. They also left a ransom note for return of the\ndata. But the incident involved no power outage. See Marcelo Soares,\n“WikiLeaked Cable Says 2009 Brazilian Blackout Wasn’t Hackers, Either,”\n[Wired.com](http://www.Wired.com), December 6, 2010, available at\n[wired.com/2010/12/brazil-blackout](http://www.wired.com/2010/12/brazil-\nblackout).\n\n[2](part0023.html#c19-ftn2a) David E. Sanger, “Obama Order Sped Up Wave of\nCyberattacks Against Iran,” _New York Times_ , June 1, 2012.\n\n[3](part0023.html#c19-ftn3a) “Iran’s Supreme Leader Tells Students to Prepare\nfor Cyber War,” _Russia Today_ , February 13, 2014, available at\n[rt.com/news/iran-israel-cyber-war-899](http://www.rt.com/news/iran-israel-\ncyber-war-899).\n\n[4](part0023.html#c19-ftn4a) Ellen Nakashima, “Pentagon to Boost Cybersecurity\nForce,” _Washington Post_ , January 27, 2013.\n\n[5](part0023.html#c19-ftn5a) Ellen Nakashima, “With Plan X, Pentagon Seeks to\nSpread U.S. Military Might to Cyberspace,” _Washington Post_ , May 30, 2012.\n\n[6](part0023.html#c19-ftn6a) Interview with Michael V. Hayden, in “Stuxnet:\nComputer Worm Opens New Era of Warfare,” _60 Minutes_ , CBS, originally aired\nJune 4, 2012, available at [cbsnews.com/8301-18560_162-57390124/stuxnet-\ncomputer-worm-opens-new-era-of-\nwarfare/?tag=pop;stories](http://www.cbsnews.com/8301-18560_162-57390124/stuxnet-\ncomputer-worm-opens-new-era-of-warfare/?tag=pop;stories).\n\n[7](part0023.html#c19-ftn7a) Speaking in 1862 after the Battle of\nFredericksburg.\n\n[8](part0023.html#c19-ftn8a) Kevin Haley, “Internet Security Predictions for\n2011: The Shape of Things to Come,” Symantec blog, November 17, 2010,\navailable at [symantec.com/connect/blogs/internet-security-\npredictions-2011-shape-things-\ncome](http://www.symantec.com/connect/blogs/internet-security-\npredictions-2011-shape-things-come).\n\n[9](part0023.html#c19-ftn9a) Kennette Benedict, “Stuxnet and the Bomb,”\n_Bulletin of the Atomic Scientists_ , June 15, 2012, available at\n[thebulletin.org/stuxnet-and-bomb](http://www.thebulletin.org/stuxnet-and-\nbomb).\n\n[10](part0023.html#c19-ftn10a) There are ways to lessen this risk by carefully\nencrypting digital weapons to prevent random parties who get hold of the code\nfrom reverse-engineering it. A digital weapon has to decrypt itself in order\nto engage its payload once it finds the system it’s targeting, but the keys\nfor doing this don’t have to be inside the weapon itself, as they were with\nStuxnet. Instead, the better design is the one that Gauss used, which employed\na complex encryption scheme that used the actual configuration of the system\nit was targeting to generate the decryption key. Gauss only delivered and\ndecrypted its payload once it found this specific configuration. This won’t\nwork, of course, if the configuration on the targeted system changes, thereby\ndefusing the digital weapon, but it will work in cases where the configuration\nof a system isn’t likely to change. See the discussion of Gauss on [this\npage](part0019.html#page295). Also, to limit a digital weapon’s exposure once\nit is decrypted on the system it’s targeting, it could be designed to self-\ndestruct upon completing its mission so that it won’t linger on a system\nlonger than necessary. This won’t work for all weapons, however. Stuxnet\nneeded to remain on a system for a long time to achieve its aim, for example.\nBut it will work for other weapons that do their damage quickly.\n\n[11](part0023.html#c19-ftn11a) Marcus Ranum, “Parsing Cyberwar—Part 4: The\nBest Defense Is a Good Defense,” published on his Fabius Maximus blog, August\n20, 2012, available at\n[fabiusmaximus.com/2012/08/20/41929](http://www.fabiusmaximus.com/2012/08/20/41929).\n\n[12](part0023.html#c19-ftn12a) Grant Gross, “Security Expert: US Would Lose\nCyberwar,” IDG News Service, February 23, 2010, available at\n[computerworld.com/s/article/9161278/Security_expert_U.S._would_lose_cyberwar](http://www.computerworld.com/s/article/9161278/Security_expert_U.S._would_lose_cyberwar).\n\n[13](part0023.html#c19-ftn13a) Though Siemens control systems aren’t as widely\nused in the United States as they are in other parts of the world, the control\nsystems that dominate facilities in the United States operate under the same\ndesign principles with some of the same flaws. An attacker would simply need\nto study the systems to find ways to attack them, which a number of security\nresearchers have already done in the years since Stuxnet was released.\n\n[14](part0023.html#c19-ftn14a) Gerry Smith, “Stuxnet: U.S. Can Launch\nCyberattacks but Not Defend Against Them, Experts Say,” _Huffington Post_ ,\nJune 1, 2012, available at [huffingtonpost/com/2012/06/01/stuxnet-us-\ncyberattack_n_1562983.html](http://www.huffingtonpost/com/2012/06/01/stuxnet-\nus-cyberattack_n_1562983.html).\n\n[15](part0023.html#c19-ftn15a) Prepared statement to the Strategic Forces\nSubcommittee of the House Committee on Armed Services, for a hearing on March\n17, 2009, available at\n[gpo.gov/fdsys/pkg/CHRG-111hhrg51759/html/CHRG-111hhrg51759.htm](http://www.gpo.gov/fdsys/pkg/CHRG-111hhrg51759/html/CHRG-111hhrg51759.htm).\n\n[16](part0023.html#c19-ftn16a) In August 2012, a destructive virus called\nShamoon struck machines at Saudi Aramco, Saudi Arabia’s national oil and\nnatural gas company, and wiped all the data from more than 30,000 machines—an\nattack that provided a stark reminder of how any machine on the internet can\nbecome ground zero for destruction in a political dispute and how difficult it\ncan be to determine attribution afterward. The virus didn’t just wipe data\nfrom the machines, it replaced every file on them with one containing an image\nof a burning US flag—though a bug in the code prevented the flag image from\nfully unfurling on infected machines. Instead, only a snippet of the image\nappeared when files were opened; the rest of the image was blank. US officials\naccused Iran of masterminding the attack, though offered no proof to back the\nclaim. The attack may have been launched by Iran as retaliation for the Wiper\nattack that erased data from machines at the Iranian Oil Ministry and the\nIranian National Oil Company four months earlier, or it may have been\nretaliation for Stuxnet, aimed at a US ally that was less capable of attacking\nback. Or it may simply have been the work of hacktivists opposed to US foreign\npolicy in the Middle East (a group of hackers calling themselves the Cutting\nSword of Justice took credit for the attack). It might even have been a “false\nflag” operation launched by another country to make it look like the\nperpetrator was Iran (NSA documents released by Edward Snowden disclose that\nthe UK sometimes uses false flag operations to pin blame on third parties).\n\n[17](part0023.html#c19-ftn17a) In August 2008, armies of computers with\nRussian IP addresses launched distributed denial-of-service attacks that\nknocked Georgian government and media websites offline, thwarting the\ngovernment’s ability to communicate with the public. The timing of the\nattacks, right before the Russian invasion of South Ossetia, was proof enough\nfor many that the digital campaign was part of the military offensive.\n\n[18](part0023.html#c19-ftn18a) The simulation designers revealed in the end\nthat the bewildering web of attributions behind the cyberattacks had been a\nkey part of their strategy. Under their plan, it was al-Qaeda that had\nactually launched the initial attacks against Israel in the hope of escalating\ntensions between Israel and the Iran-backed Hezbollah in Lebanon. But it was\nIran that launched the attacks on the United States. The latter were done in a\nway to make it look as if Israel had launched with the intention of framing\nIran for them. The US was supposed to think that Israel had played the\nultimate dirty trick—launching an attack against the United States in order to\npoint the finger at Iran and drum up US support for an Israeli airstrike\nagainst Tehran.\n\n[19](part0023.html#c19-ftn19a) Barbara Opall-Rome, “Israeli Cyber Game Drags\nUS, Russia to Brink of Mideast War,” _Defense News_ , November 14, 2013,\navailable at [defensenews.com/article/20131114/DEFREG04/311140020/Israeli-\nCyber-Game-Drags-US-Russia-Brink-Mideast-\nWar](http://www.defensenews.com/article/20131114/DEFREG04/311140020/Israeli-\nCyber-Game-Drags-US-Russia-Brink-Mideast-War).\n\n[20](part0023.html#c19-ftn20a) “Israel Combats Cyberattacks, ‘Biggest\nRevolution in Warfare,’ ” UPI, January 31, 2014, available at\n[upi.com/Business_News?Security-industry/2014/01/31/Israel-combats-\ncyberattacks-biggest-revolution-in-\nwarfare/UPI-24501391198261/](http://www.upi.com/Business_News?Security-\nindustry/2014/01/31/Israel-combats-cyberattacks-biggest-revolution-in-\nwarfare/UPI-24501391198261/).\n\n[21](part0023.html#c19-ftn21a) Marcus Ranum, “Parsing Cyberwar—Part 3:\nSynergies and Interference,” published on his Fabius Maximus blog, August 13,\n2012, available at\n[fabiusmaximus.com/2012/08/13/41567](http://www.fabiusmaximus.com/2012/08/13/41567).\n\n[22](part0023.html#c19-ftn22a) Thomas Rid, “Think Again: Cyberwar” _Foreign\nPolicy_ , March/April 2012.\n\n[23](part0023.html#c19-ftn23a) Author interview with Andy Pennington, November\n2011.\n\n[24](part0023.html#c19-ftn24a) James A. Lewis, “Cyberwar Thresholds and\nEffects,” _IEEE Security and Privacy_ (September 2011): 23–29.\n\n[25](part0023.html#c19-ftn25a) Rid, “Think Again: Cyberwar.”\n\n[26](part0023.html#c19-ftn26a) This and other quotes from Healey come from\nauthor interview, October 2013.\n\n[27](part0023.html#c19-ftn27a) Julian Barnes, “Pentagon Digs In on Cyberwar\nFront,” _Wall Street Journal_ , July 6, 2012.\n\n[28](part0023.html#c19-ftn28a) James A. Lewis in testimony before the\nSubcommittee on Cybersecurity, Infrastructure Protection and Security\nTechnologies, March 16, 2012, available at\n[homeland.house.gov/sites/homeland.house.gov/files/Testimony%20Lewis.pdf](http://www.homeland.house.gov/sites/homeland.house.gov/files/Testimony%20Lewis.pdf).\n\n[29](part0023.html#c19-ftn29a) James A. Lewis, “Thresholds for Cyberwar,”\nCenter for Strategic and International Studies, September 2010, available at\n[csis-org/publication/thresholds-cyberwar](http://www.csis-\norg/publication/thresholds-cyberwar).\n\n[30](part0023.html#c19-ftn30a) Ibid.\n\n[31](part0023.html#c19-ftn31a) W. Earl Boebert, “A Survey of Challenges in\nAttribution,” Proceedings of a Workshop on Deterring Cyber Attacks: Informing\nStrategies and Developing Options for US Policy. Published by the National\nAcademy of Sciences at\n[na.edu/catalog/12997.html](http://www.na.edu/catalog/12997.html).\n\n[32](part0023.html#c19-ftn32a) Rules of engagement are the military orders\nthat take into consideration international law and US policy to draw up a\nsingle document that the military uses to conduct its operations. There are\nrules of engagement for different operations, since the rules will change\nwhether it’s a peacekeeping mission in Bosnia or an aggressive invasion of\nIraq. Separately, there is an overarching set of rules of engagement that\napplies to the military’s day-to-day operations. These latter standing rules,\nwhich are mostly classified, include cyber. According to Gary Brown, who was\nlegal counsel for US Cyber Command from 2009 to 2012, these standing rules\nwere being rewritten during his time with the command and he said in 2014 that\nhe still didn’t know if they were completed. The military was using the second\nversion of the rules that were finished in 2005, known as the Bravo version\nwhen he was there. The third version, known as Charlie, should have been\nfinished in 2010, but still wasn’t completed when Brown left in 2012. The\nBravo version addressed cyber, but only in broad terms. Version Charlie is\nsupposed to address it in more specific terms.\n\n[33](part0023.html#c19-ftn33a) Chris Carroll, “Cone of Silence Surrounds U.S.\nCyberwarfare,” _Stars and Stripes_ , October 18, 2011, available at\n[stripes.com/news/cone-of-silence-surrounds-u-s-\ncyberwarfare-1.158090](http://www.stripes.com/news/cone-of-silence-surrounds-\nu-s-cyberwarfare-1.158090).\n\n[34](part0023.html#c19-ftn34a) David E. Sanger, “America’s Deadly Dynamics\nwith Iran,” _New York Times_ , November 5, 2011.\n\n[35](part0023.html#c19-ftn35a) Duqu was publicly exposed in September 2011,\nand although Microsoft patched the font-rendering flaw it exploited, by late\n2012 “attacks against this single vulnerability had skyrocketed,” Finnish\nsecurity firm F-Secure noted in its 2013 annual report. This vulnerability\nalone “accounted for an amazing 69 percent of all exploit-related detections\nreport.” See page 36 of “Threat Report H1 2013,” F-Secure, available at\n[f-secure.com/static/doc/labs_global/Research/Threat_Report_H1_2013.pdf](http://www.f-secure.com/static/doc/labs_global/Research/Threat_Report_H1_2013.pdf).\n\n[36](part0023.html#c19-ftn36a) Dennis Fisher, “Nation-State Attackers Are\nAdobe’s Biggest Worry,” ThreatPost, a security blog published by Kaspersky\nLab, September 20, 2011, available at [threatpost.com/nation-state-attackers-\nare-adobes-biggest-worry-092011/75673](http://www.threatpost.com/nation-state-\nattackers-are-adobes-biggest-worry-092011/75673).\n\n[37](part0023.html#c19-ftn37a) Speaking to the Senate Committee on\nAppropriations, “Cybersecurity: Preparing for and Responding to the Enduring\nThreat,” June 12, 2013, available at\n[defense.gov/home/features/2013/0713_cyberdomain/docs/Alexander,_General_Keith_Testimony_6.12.13_Cybersecurity_Hearing.pdf](http://www.defense.gov/home/features/2013/0713_cyberdomain/docs/Alexander,_General_Keith_Testimony_6.12.13_Cybersecurity_Hearing.pdf).\n\n[38](part0023.html#c19-ftn38a) All quotes from Hayden here and next page come\nfrom author interview in February 2014.\n\n[39](part0023.html#c19-ftn39a) The President’s Review Group on Intelligence\nand Communications Technologies, “Liberty and Security in a Changing World”\n(report, December 12, 2013), 37. The report is available at\n[whitehouse.gov/sites/default//files/docs/2013-12-12_rg_final_report.pdf](http://www.whitehouse.gov/sites/default//files/docs/2013-12-12_rg_final_report.pdf).\n\n[40](part0023.html#c19-ftn40a) Clarke was speaking at the RSA Security\nConference in San Francisco in February 2014.\n\n[41](part0023.html#c19-ftn41a) “Advance Questions for Vice Admiral Michael S.\nRogers, USN, Nominee for Commander, United States Cyber Command,” available on\nthe Senate Armed Services Committee website at [armed-\nservices.senate.gov/imo/media/doc/Rogers_03-11-14.pdf](http://www.armed-\nservices.senate.gov/imo/media/doc/Rogers_03-11-14.pdf).\n\n[42](part0023.html#c19-ftn42a) David E. Sanger, “Obama Lets N.S.A. Exploit\nSome Internet Flaws, Officials Say,” _New York Times_ , April 12, 2014.\n\n[43](part0023.html#c19-ftn43a) Kim Zetter, “Obama: NSA Must Reveal Bugs Like\nHeartbleed, Unless They Help the NSA,” [Wired.com](http://www.Wired.com),\nApril 15, 2014.\n\n[44](part0023.html#c19-ftn44a) Soghoian was speaking at the Personal Democracy\nForum in June 2012 in New York.\n\n[45](part0023.html#c19-ftn45a) Author interview, 2014.\n\n[46](part0023.html#c19-ftn46a) Lotrionte was with the CIA prior to 2002,\nfollowed by positions as counsel to the president’s foreign intelligence\nadvisory board at the White House and a position as legal counsel for the\nSenate Select Committee on Intelligence. She left government in 2006 around\nthe time Stuxnet was being proposed and prepared.\n\n[47](part0023.html#c19-ftn47a) Stephen Cobb, “The Negative Impact on GDP of\nState-Sponsored Malware Like Stuxnet and Flame,” We Live Security blog, June\n13, 2012, available at [blog.eset.com/2012/06/13/impact-on-gdp-of-state-\nsponsored-malware-like-stuxnet-and-\nflame](http://www.blog.eset.com/2012/06/13/impact-on-gdp-of-state-sponsored-\nmalware-like-stuxnet-and-flame).\n\n[48](part0023.html#c19-ftn48a) William A. Owens, Kenneth W. Dam, and Herbert\nS. Lin, (eds.), “Technology, Policy, Law, and Ethics Regarding US Acquisition\nand Use of Cyberattack Capabilities,” National Academies Press, 2009,\navailable at:\n[steptoe.com/assets/attachments/3785.pdf](http://www.steptoe.com/assets/attachments/3785.pdf).\n\n[49](part0023.html#c19-ftn49a) Ellen Nakashima, “List of Cyber-Weapons\nDeveloped by Pentagon to Streamline Computer Warfare,” _Washington Post_ , May\n31, 2011.\n\n[50](part0023.html#c19-ftn50a) Lolita Baldor, “Pentagon Gets Cyberwar\nGuidelines,” Associated Press, June 22, 2011, available at\n[usatoday30.usatoday.com/news/military/2011-06-22-pentagon-cyber-\nwar_n.htm](http://www.usatoday30.usatoday.com/news/military/2011-06-22-pentagon-\ncyber-war_n.htm).\n\n[51](part0023.html#c19-ftn51a) Glenn Greenwald and Ewen MacAskill, “Obama\nOrders US to Draw Up Overseas Target List for Cyber-Attacks,” _Guardian_ ,\nJune 7, 2013. Presidential Policy Directive 20 was issued in October 2012,\naccording to the paper.\n\n[52](part0023.html#c19-ftn52a) All quotes from Lin in this chapter come from\nan author interview in January 2014.\n\n[53](part0023.html#c19-ftn53a) “International Strategy for Cyberspace:\nProsperity, Security, and Openness in a Networked World,” The White House, May\n2011, available at\n[whitehouse.gov/sites/default/files/rss_viewer/international_strategy_for_cyberspace.pdf](http://www.whitehouse.gov/sites/default/files/rss_viewer/international_strategy_for_cyberspace.pdf).\n\n[54](part0023.html#c19-ftn54a) Siobhan Gorman and Julian E. Barnes, “Cyber\nCombat: Act of War,” _Wall Street Journal_ , May 30, 2011.\n\n[55](part0023.html#c19-ftn55a) Carroll, “Cone of Silence.”\n\n[56](part0023.html#c19-ftn56a) Michael N. Schmitt, general editor, _Tallinn\nManual on the International Law Applicable to Cyber Warfare_ , NATO\nCooperative Cyber Defence Centre of Excellence, available at\n[ccdcoe/org/249.html](http://www.ccdcoe/org/249.html).\n\n[57](part0023.html#c19-ftn57a) Many in the media and government have called\nthe denial-of-service attacks against Estonian websites cyberwarfare, but they\ndon’t qualify as such. The attacks, launched by a botnet of 85,000 machines in\n2007, persisted for three weeks and, at their peak, bombarded nearly sixty\nwebsites, knocking Estonia’s largest bank offline as well as government sites.\nBut when Estonia pointed the finger at Russia as the source of the attacks and\nsought help from NATO by attempting to invoke the collective self-defense\nagreement under Article 5 of the North Atlantic Treaty Organization, it was\nrebuffed. NATO determined that the attack did not constitute an armed attack\nunder the treaty. The problem lay in the fact that the EU and NATO had not\npreviously defined the obligations of its member states in the event of a\ncyberattack against one of them. NATO had also not defined a cyberattack as a\nclear military action, therefore Article 5 did not automatically come into\nplay. Under Article 5 “an armed attack against one or more [members] in Europe\nor North America shall be considered an attack against them all.” In the event\nof such an attack, each member is expected to “assist the Party or Parties so\nattacked by taking forthwith, individually and in concert with the other\nParties, such action as it deems necessary, including the use of armed force,\nto restore and maintain the security of the North Atlantic area.”\n\nEstonian prime minister Andrus Ansip challenged NATO’s conclusion, however,\nasking, “What’s the difference between a blockade of harbors or airports of\nsovereign states and the blockade of government institutions and newspaper\nwebsites?” (See Thomas Rid, “Think Again: Cyberwar,” _Foreign Policy_ ,\nFebruary 27, 2012, available at\n[foreignpolicy.com/articles/2012/02/27/cyberwar](http://www.foreignpolicy.com/articles/2012/02/27/cyberwar).)\nThe question is a valid one that has not been adequately resolved. If blocking\ncommercial shipments can be an act of war, would thwarting e-commerce be the\nequivalent in cyberspace? And what kind of response would it merit? In 2010,\nNATO attempted to resolve the question by concluding that if an ally were hit\nwith a cyberattack, NATO would help defend the victim’s networks, but the\nassistance fell short of offering to help a victim conduct a counterattack.\n\n[58](part0023.html#c19-ftn58a) Author interview with Brown, February 2014.\n\n[59](part0023.html#c19-ftn59a) Harold Koh, former legal adviser to the State\nDepartment, speaking at the US CyberCom Inter-Agency Legal Conference at Fort\nMeade in September 2012, asserted that the government’s position was that a\nuse of force was the same as an armed attack. “In our view, there is no\nthreshold for a use of deadly force to qualify as an ‘armed attack’ that may\nwarrant a forcible response.” See\n[state.gov/s/l/releases/remarks/197924.htm](http://www.state.gov/s/l/releases/remarks/197924.htm).\n\n[60](part0023.html#c19-ftn60a) Author interview with Libicki, October 2012.\n\n[61](part0023.html#c19-ftn61a) All quotes from Lotrionte come from author\ninterview, February 2014.\n\n[62](part0023.html#c19-ftn62a) Cilluffo was speaking at a hearing on the\n“Iranian Cyber Threat to the US Homeland” for a Joint Subcommittee Hearing of\nthe Committee on Homeland Security, April 26, 2012, available at\n[gpo.gov/fdsys/pkg/CHRG-112hhrg77381/pdf/CHRG-122hhrg77381.pdf](http://www.gpo.gov/fdsys/pkg/CHRG-112hhrg77381/pdf/CHRG-122hhrg77381.pdf).\n\n[63](part0023.html#c19-ftn63a) Brown has written a paper on the issue. See\nGary D. Brown and Andrew O. Metcalf, “Easier Said Than Done: Legal Reviews of\nCyber Weapons,” _Journal of National Security Law and Policy_ , published by\nGeorgetown Law, February 12, 2014, available at [jnslp.com/wp-\ncontent/uploads/2014/02/Easier-Said-than-Done.pdf](http://www.jnslp.com/wp-\ncontent/uploads/2014/02/Easier-Said-than-Done.pdf).\n\n\n# **ACKNOWLEDGMENTS**\n\nWhen I first began writing about Stuxnet after its discovery in the summer of\n2010, there was no way to know where it would lead. It wasn’t until months\nlater, after the Symantec researchers and Ralph Langner’s team dug into it\nfurther, that it became clear that there was a larger story that needed to be\ntold—not only about the attack on Iran’s centrifuges and the discovery of the\nworld’s first digital weapon but about the security community and its changing\nnature at the dawn of the era of cyber warfare. It’s a cliché to say that\nsomething is a game-changer, but Stuxnet really is. Everything in malware that\noccurred prior to its appearance might well be labeled BS—Before Stuxnet—since\nthe code that came before it represented simpler, more innocent times when the\nmotives and ambitions of attackers were more straightforward and easier to\ndiscern.\n\nIf Stuxnet was a challenge to decipher, the writing of this book was equally\nso. Combining a narrative structure with complex technical details and a\npolitical-historical context that was as convoluted as the code, while still\noffering a compelling read and doing justice to the intense labor that\nresearchers invested in their analysis of the code, was not an easy task,\nespecially when the subject of that narrative turned out to be a moving\ntarget.\n\nAs I began the book in earnest in early 2012, everything we thought we knew\nabout Stuxnet had to be revised as one new discovery after another was\nmade—first with Duqu, then with Flame, and then, in early 2013, with the\nunveiling of Stuxnet 0.5, the first known version of the digital weapon to be\nfound. And the target is still moving today.\n\nStuxnet, and its ancillary espionage tools, were the state of the art at the\ntime they were developed and unleashed, but that state has no doubt been\nsurpassed by other digital tools developed in its wake that have yet to be\ndetected and may not be for many years.\n\nWhile the writing of this book was difficult, it was made easier by the\nenormous help and support I received from many people.\n\nThe book would not have been possible without the encouragement and support of\nmy agent, David Fugate, who first reached out to me in 2007 following the\npublication of a three-part series I wrote for _Wired_ about the digital\nunderground of carding forums and the fascinating community of bank card\nthieves that inhabit them. Though I decided not to expand that series into a\nbook, David remained in touch over the next few years, periodically reaching\nout to say he was still interested in collaborating and asking if I had any\nproject in mind.\n\nThroughout the proposal process and the writing of this book, he remained a\nsteadfast supporter, providing valuable feedback and the seasoned perspective\nof a publishing veteran while lending the right amount of encouragement when\nneeded the most. He’s the kind of advocate every writer should have in his or\nher corner.\n\nIn addition to David, my editor at Crown/Random House, Julian Pavia, played a\ngreat role in helping to shape the book and keep it on path. This was a\ndifficult project to wrangle, but Julian did it with grace and patience, even\nas the content unexpectedly changed and deadlines passed. Additionally, Julian\ndid a masterful job of streamlining the technical details to balance the\nnarrative flow and refine my sometimes jagged prose.\n\nI’d also like to thank Kim Silverton, editorial assistant at Random House, for\nher timely and helpful feedback on the manuscript during the editing phase, as\nwell as the publicity and marketing teams—Sarah Breivogel, executive publicist\nat Random House, Sarah Pekdemir, senior marketing manager, and Jay Sones,\ndirector of marketing at Crown—for their enthusiastic backing of the book.\n\nThe book would not exist, however, without all of the talented researchers who\ndid the hard work of deciphering Stuxnet and its arsenal of tools and who\nprovided me with untiring assistance to help me get the details right. These\ninclude Sergey Ulasen of VirusBlokAda and now Kaspersky Lab, and Oleg Kupreev\nof VirusBlokAda, who sounded the first alarm and got the rest of the world to\ntake note of the strange code discovered in Iran.\n\nThey also include, of course, the brilliant and hard-working team at\nSymantec—Eric Chien, Liam O’Murchu, and Nicolas Falliere—whose curiosity,\npersistence, and skill provided the most important pieces of the Stuxnet\npuzzle and ensured that the code would not pass quietly into obscurity. The\nthree of them were extremely generous with their time and endured many rounds\nof questions in the midst of busy schedules to share their views and\nexpertise.\n\nI cannot express enough gratitude to them and to the equally brilliant and\ntireless global research and analysis team at Kaspersky Lab—Costin Raiu, Aleks\nGostev, Roel Schouwenberg, Kurt Baumgartner, Vitaly Kamluk, and the rest of\nthe company’s global group of researchers–who impressed me repeatedly with\ntheir skill and devotion to chasing down the tiniest details of very complex\nattacks, even though working with them often involved 6 a.m. phone calls on my\nend to accommodate the time difference with Eastern Europe. I’m particularly\ngrateful to Costin for going beyond the call of duty, sometimes at the expense\nof time with his family, and for his remarkable wisdom, memory, and attention\nto detail, which helped me keep track of the many maddening facts that grew\nmore extensive with each new discovery.\n\nI’m also very grateful to Greg Funaro and Ryan Naraine at Kaspersky Lab who\nhad an uncanny ability to anticipate what I needed before I knew I needed it\nand who had an unwavering commitment to leaving no question unanswered. Ryan’s\nformer job as a top security journalist, combined with his technical\nexpertise, made him the perfect liaison with the research team.\n\nIn addition to the Symantec and Kaspersky research teams, the story of Stuxnet\ncould not be told without the work of Ralph Langner and his colleagues Ralf\nRosen and Andreas Timm. Ralph’s passion for Stuxnet kept it alive in the press\nand brought it to the attention of mainstream media, while his extensive\nknowledge of industrial control systems helped the public understand Stuxnet’s\nbroader implications for the security of critical infrastructure. I’m grateful\nfor the many hours he spent with me on the phone and in person to help me make\nsense of Stuxnet’s broader context. His frank and straightforward manner cut\nto the heart of the issues and ensured that the public could not dismiss or\noverlook the importance of Stuxnet. I’m also grateful to Ralf Rosen for the\ntime he gave to speak to me about their work on Stuxnet and for reviewing some\nof the completed text for accuracy.\n\nSimilarly, Boldizsár Bencsáth was immensely generous with his time and\nexpertise, providing kind and invaluable assistance that helped me unravel a\nfew mysteries and understand the ways in which all of the attacks were\nconnected.\n\nIn addition to these researchers, I’m greatly indebted to David Albright at\nthe Institute for Science and International Security, who helped not only me\nbut also Symantec and Ralph Langner with understanding Stuxnet’s effects on\nNatanz and the enrichment process. Both he and Olli Heinonen, formerly of the\nIAEA and now a senior fellow at Harvard’s Belfer Center for Science and\nInternational Affairs, provided great insight into the Iranian nuclear program\nin general and to the enrichment process at Natanz in particular.\n\nIn addition, I’d like to thank Corey Hinderstein, now with the Nuclear Threat\nInitiative, for providing me with her firsthand memories of the press\nconference where Natanz was first exposed and her work uncovering the infamous\nsatellite images.\n\nI’d also like to thank Dale Peterson, Perry Pederson, Joe Weiss, and Mike\nAssante for helping me understand the wider effects of Stuxnet and weapons\nlike it on critical infrastructure. Dale and Perry were especially helpful in\nreading the chapter on industrial control systems and providing feedback.\n\nSimilarly, I’d like to thank Jason Healey and Marcus Sachs for providing\nbackground information about the early days of the government’s digital\nwarfare program and to Jason for providing perspective on the implications of\nStuxnet and Flame and where we go from here. I’d also like to thank Charlie\nMiller and Chaouki Bekrar for their frankness in discussing the zero-day\nmarket and helping me understand the motivations that drive this market.\n\nIn addition to all of these people, there are others who sat for interviews or\nread through chapters or parts of chapters to provide welcomed and helpful\nfeedback. Some of them I have named here; many others have asked to remain\nanonymous.\n\nOne reader I’d like to thank in particular is Andrea Matwyshyn, a good and\nvalued friend who has been supportive of my work and career for many years and\nwho took some of these chapters with her to conferences and holidays to\nprovide the feedback I needed in a timely manner. I’d also especially like to\nthank Cem Paya, another good friend and supporter of my work who took chapters\non holiday to Turkey and even read various versions of chapters several times\nto ensure that the technical details were accurate and consistent.\n\nThis book on Stuxnet is the culmination of more than a decade of experience\nreporting on cybersecurity, hackers, and the security community, all of which\nhelped sharpen my knowledge and understanding of these complex issues. I’d\nlike to thank the many friends, family, and colleagues who have provided much\nsupport, inspiration, guidance, encouragement, good editing, and a voice of\nreason over the years, including Richard Thieme, Dan Goodin, Elinor Mills, and\nRob Lemos, as well as my _Wired_ colleagues past and present—Chuck\nSquatriglia, Jim Merithew, Kevin Poulsen, Ryan Singel, and David Kravets. I’d\nalso like to thank David Zetter and Mark Zetter for their enduring support and\nmany good memories.\n\n\n\n\n",
    "book_id": "countdown_to_zero_day",
    "book_title": "Countdown to Zero Day: Stuxnet and the Launch of the World's First Digital Weapon",
    "book_author": "Kim Zetter",
    "topic_id": "cybersecurity_history",
    "topic_label": "history",
    "chunk_index": 0
  },
  {
    "chunk_full": "![image](../images/frontcover.jpg)\n\n\n![image](../images/back_blank.jpg)\n\n\n![image](../images/title_001.jpg)\n\n\nFor my BizMgr\n\nCopyright © 2014 by Brian Krebs\n\nCover and internal design © 2014 by Sourcebooks, Inc.\n\nCover design by The Book Designers\n\nSourcebooks and the colophon are registered trademarks of Sourcebooks, Inc.\n\nAll rights reserved. No part of this book may be reproduced in any form or by\nany electronic or mechanical means including information storage and retrieval\nsystems—except in the case of brief quotations embodied in critical articles\nor reviews—without permission in writing from its publisher, Sourcebooks, Inc.\n\nThis publication is designed to provide accurate and authoritative information\nin regard to the subject matter covered. It is sold with the understanding\nthat the publisher is not engaged in rendering legal, accounting, or other\nprofessional service. If legal advice or other expert assistance is required,\nthe services of a competent professional person should be sought.—From a\nDeclaration of Principles Jointly Adopted by a Committee of the American Bar\nAssociation and a Committee of Publishers and Associations\n\nAll brand names and product names used in this book are trademarks, registered\ntrademarks, or trade names of their respective holders. Sourcebooks, Inc., is\nnot associated with any product or vendor in this book.\n\nPublished by Sourcebooks, Inc.\n\nP.O. Box 4410, Naperville, Illinois 60567-4410\n\n(630) 961-3900\n\nFax: (630) 961-2168\n\n[www.sourcebooks.com](http://www.sourcebooks.com)\n\nLibrary of Congress Cataloging-in-Publication Data\n\nKrebs, Brian.\n\nSpam nation : the inside story of organized cybercrime—from global epidemic to\nyour front door / Brian Krebs.\n\npages cm\n\n1\\. Computer crimes—United States. 2. Internet fraud—United States. 3. Spam\n(Electronic mail) 4. Phishing. 5. Organized crime—United States. I. Title.\n\nHV6773.2.K74 2014\n\n364.16’80973—dc23\n\n2014023007\n\n\n## CONTENTS\n\n[Chapter 1: Parasite](01_chapter01.xhtml)\n\n[Chapter 2: Bulletproof](02_chapter02.xhtml)\n\n[Chapter 3: The Pharma Wars](03_chapter03.xhtml)\n\n[Chapter 4: Meet the Buyers](04_chapter04.xhtml)\n\n[Chapter 5: Russian Roulette](05_chapter05.xhtml)\n\n[Chapter 6: Partner(ka)s in (Dis)Organized Crime](06_chapter06.xhtml)\n\n[Chapter 7: Meet the Spammers](07_chapter07.xhtml)\n\n[Chapter 8: Old Friends, Bitter Enemies](08_chapter08.xhtml)\n\n[Chapter 9: Meeting in Moscow](09_chapter09.xhtml)\n\n[Chapter 10: The Antis](10_chapter10.xhtml)\n\n[Chapter 11: Takedown](11_chapter11.xhtml)\n\n[Chapter 12: Endgame](12_chapter12.xhtml)\n\n[Epilogue: A Spam-Free World: How You Can Protect Yourself from\nCybercrime](epilog.xhtml)\n\n[Acknowledgments](acknowledgement.xhtml)\n\n[Sources](back01.xhtml)\n\n[About the Author](back02.xhtml)\n\n\n## WHO’S WHO IN THE CYBERWORLD\n\nPAVEL VRUBLEVSKY, a.k.a “RedEye”—Cofounder of ChronoPay, a high-risk card\nprocessor and payment service provider that was closely tied to the rogue\nantivirus industry. Co-founder of Rx-Promotion pharmacy affiliate program.\n\nYURI KABAYENKOV, a.k.a. “Hellman”—Co-owner of Rx-Promotion along with Pavel\nVrublevsky.\n\nIGOR GUSEV, a.k.a “Desp”—Cofounder of ChronoPay, and co-owner of the pharmacy\nspam partnerships SpamIt and GlavMed.\n\nDMITRY STUPIN—Co-owner, along with Igor Gusev, of the pharmacy partnerships\nSpamIt and GlavMed.\n\nIGOR VISHNEVSKY—A spammer who helped develop the “Cutwail” spam botnet, and a\none-time business partner of Dmitri “Gugle” Nechvolod, a major spammer.\n\nDMITRY NECHVOLOD, a.k.a. “Gugle”—One of SpamIt and Rx-Promotion’s most\nsuccessful spammers, Gugle rented out his “Cutwail” spam botnet for use by\nmany other junk emailers.\n\nGENNADY LOGINOV—A Belarusian man and leader of a militant organized crime\ngroup known as “The Village.” Partner with Alexander Rubatsky and involved in\nthe kidnapping and ransom of Evgeny “Pet” Petrovsky—a rival businessman.\n\nALEXANDER RUBATSKY—A Belarusian hacker closely tied to the child pornography\nindustry who later founded the Russian Business Network (RBN) in St.\nPetersburg, Russia.\n\nEVGENY PETROVSKY, a.k.a. “Pet”—Belarusian owner of companies Sunbill and\nBillCards, credit card processing networks that were deeply involved in\nprocessing payments for child pornography sites.\n\nNIKOLAI MCCOLO, a.k.a “Kolya”—The young entrepreneur behind McColo Corp.,\nwhich until its demise in 2008 was among the most popular Web hosting\nproviders in the cybercrime underground.\n\nLEONID KUVAYEV—A convicted spammer who ran the RxPartners pharmacy spam\naffiliate program. Kuvayev is currently serving a ten-year prison sentence in\nRussia for child molestation and child pornography.\n\nIGOR AND DMITRY ARTIMOVICH, a.k.a. “Engel”—Brothers who allegedly operated the\n“Festi” spam botnet and were close allies of Vrublevsky. The brothers were\nconvicted in 2013 of using Festi to attack the website of Assist, a ChronoPay\ncompetitor, although they deny this.\n\nCOSMA—Spammer for both GlavMed-SpamIt and Rx-Promotion and principal author of\nthe massive Rustock botnet.\n\nSEVERA—Spammer for both GlavMed-SpamIt and Rx-Promotion and the apparent\nauthor of the Waledac and Storm botnets.\n\n\nChapter 1\n\n## PARASITE\n\nThe navy blue BMW 760 nosed up to the crosswalk at a traffic light in downtown\nMoscow. A black Porsche Cayenne pulled alongside. It was 2:00 p.m., Sunday,\nSeptember 2, 2007, and the normally congested streets adjacent to the storied\nSukharevskaya Square were devoid of traffic, apart from the tourists and\nlocals strolling the broad sidewalks on either side of the boulevard. The\nafternoon sun that bathed the streets in warmth throughout the day was\nbeginning to cast long shadows on the street from the historic buildings\nnearby.\n\nThe driver of the BMW, a notorious local scam artist who went by the hacker\nnickname “Jaks,” had just become a father that day, and Jaks and his passenger\nhad toasted the occasion with prodigious amounts of vodka. It was the perfect\ntime and place to settle a simmering rivalry with the Porsche driver over\nwhose ride was faster. Now each driver revved his engine in an unspoken\nagreement to race the short, straight distance to the big city square directly\nahead.\n\nAs the signal flashed green, the squeal of rubber peeling off on concrete\nechoed hundreds of meters down in the main square. Bystanders turned to watch\nas the high-performance machines lurched from the intersection, each keeping\npace with the other and accelerating at breakneck speed.\n\nRoaring past the midpoint of the race at more than 200 kilometers per hour,\nJaks suddenly lost control, clipping the Porsche and careening into a huge\nmetal lamp post. In an instant, the competition was over, with neither car the\nwinner. The BMW was sliced in two, the Porsche a smoldering, crumpled wreck\nclose by. The drivers of both cars crawled and limped away from the scene, but\nthe BMW’s passenger—a promising twenty-three-year-old Internet entrepreneur\nnamed Nikolai McColo—was killed instantly, his almost headless body pinned\nunder the luxury car.\n\n“Kolya,” as McColo was known to friends, was a minor celebrity in the\ncybercriminal underground, the youngest employee of a family-owned Internet\nhosting business that bore his last name—McColo Corp. At a time when law-\nenforcement agencies worldwide were just waking up to the financial and\norganizational threats from organized cybercrime, McColo Corp. had earned a\nreputation as a ground zero for it: a place where cybercrooks could reliably\nset up shop with little worry that their online investments and schemes would\nbe discovered or jeopardized by foreign law-enforcement investigators.\n\nAt the time of Kolya’s death, his family’s hosting provider was home base for\nthe largest businesses on the planet engaged in pumping out junk email or\n“spam” via robot networks. Called “botnets” for short, these networks are\ncollections of personal computers that have been hacked and seeded with\nmalicious software—or “malware”—that lets the attackers control the systems\nfrom afar. Usually, the owners of these computers have no idea their machines\nhave been taken hostage.\n\nNearly all of the botnets controlled from McColo were built to blast out the\nunsolicited junk spam advertisements that flood our inboxes and spam filters\nevery day. But the servers at McColo weren’t generating and pumping spam\nthemselves; that would attract too much attention from Internet vigilantes and\nWestern law-enforcement agencies. Instead, they were merely used by the\nbotmaster businesses to manipulate millions of PCs scattered around the globe\ninto becoming spam-spewing zombies.\n\nBy the time paramedics had cleared the area of Kolya’s accident, gruesome\nimages of the carnage were already being uploaded to secretive Russian\nInternet forums frequented by McColo’s friends and business clients. Among the\nfirst to broadcast the news of Kolya’s death were denizens of Crutop.nu, a\nRussian-language hacker forum that counted among its eight thousand members\nsome of the world’s biggest spammers. The same Crutop.nu members who spread\npictures and news of the incident were some of McColo’s most successful web\nhosting customers, and many felt obligated (or were publicly shamed by forum\nadministrators) to shell out funds to help Kolya’s family pay for his funeral\nexpenses. This was a major event in the cybercrime underworld.\n\nDays later, the motley crew of Moscow-based spammers would gather to pay their\nlast respects at his service. The ceremony was held at the same church where\nKolya had been baptized less than twenty-three years earlier. Among those in\nattendance were Igor “Desp” Gusev and Dmitry “SaintD” Stupin, coadministrators\nof SpamIt and GlavMed, until recently the world’s largest sponsors of\nspam[1](01_chapter01.xhtml#fn1)—and two figures that will play key roles in\nthis book.\n\nAlso at the service was Dmitry “Gugle” Nechvolod, then twenty-five years old\nand a hacker who was closely connected to the Cutwail botnet. Cutwail is a\nmassive crime machine that has infected tens of millions of home computers\naround the globe and secretly seized control over them for sending spam.\nNechvolod had already earned millions of dollars using the botnet to send junk\nemail for GlavMed and SpamIt to millions of people around the world. To this\nday, Cutwail remains one of the largest and most active spam botnets—although\nit is almost undoubtedly run by many different individuals now (more on this\nin Chapter 7, “[Meet the Spammers](07_chapter07.xhtml)”).\n\nSo why is it important to note these three men’s presence at such a momentous\nevent for cybercrime? Because their work (as well as Kolya’s and hundreds of\nothers’) impacts every one of us every day in a strange but significant way:\nspam email.\n\nIndeed, spam email has become the primary impetus for the development of\nmalicious software—programs that strike computers like yours and mine every\nday—and through them, target our identities, our security, our finances,\nfamilies, and friends. These botnets are virtual parasites that require care\nand constant feeding to stay one step ahead of antivirus tools and security\nfirms that work to dismantle the networks. To keep their bot colonies\nthriving, spammers (or botmasters—the term is interchangeable) must work\nconstantly to spread and mutate the digital disorders that support them.\nBecause antivirus programs routinely clean up infected PCs used to send spam,\nbotnet operators need to continuously attack and seize control over additional\ncomputers and create new ways to infiltrate previously infected ones.\n\nThis technological arms race requires the development, production, and\ndistribution of ever-stealthier malware that can evade constantly changing\nantivirus and anti-spam defenses. Therefore, the hackers at the throttle of\nthese massive botnets also use spam as a form of self-preservation. The same\nbotnets that spew plain old spam typically are used to distribute junk email\ncontaining new versions of the malware that helps spread the contagion. In\naddition, spammers often reinvest their earnings from spamming people into\nbuilding better, stronger, and sneakier malicious software that can bypass\nantivirus and anti-spam software and firewalls. The spam ecosystem is a\nconstantly evolving technological and sociological crime machine that feeds on\nitself.\n\nThus far, the criminals responsible for unleashing this daily glut of digital\ndisease are doing a stupendous job of overwhelming the security industry.\nAntivirus companies now report that they are struggling to classify and combat\nan average of 82,000 new malicious software variants attacking computers every\nday, and a large percentage of these strains are designed to turn infected\ncomputers into spam zombies that can be made to do the attacker’s bidding\nremotely. Security giant McAfee said it detected 14 million new pieces of\nmalware in the first quarter of 2013 alone.\n\nBut that also comes at a price to the spammers. In the case of Cutwail, the\nmaintenance needed to sustain it required 24/7 teams of software developers\nand technical support staff. That’s because the software that powers botnets\nlike Cutwail is typically rented out for use by other spammers, who frequently\ndemand code tweaks or add-ons to help the bot programs work properly within\ntheir own criminal infrastructure.\n\nMoscow resident Igor Vishnevsky, in his early thirties, was one of several\nhackers who worked closely with Nechvolod on Cutwail. (Vishnevsky would\neventually strike out on his own, developing a rival version of Cutwail that\nhe too used to spam and rent to other spammers. He agreed to act as our\nvirtual “Virgil” and walk us through this strange and unfamiliar spammer\nunderworld, and he appears throughout this book.) “We had an office for Gugle\n[Nechvolod, pronounced “Google”] with coders and support. Sometimes I visited\nit, but I didn’t work from there,” Vishnevsky recalled in an instant message\nconversation. He said Gugle’s office employed at least five full-time coders\nand as many support staff who rotated shifts around the clock and on weekends\nto better meet the demands of clients.\n\nHosting firms like McColo attracted clientele like Cutwail’s producers because\nthey stayed online in the face of significant pressure from domestic and\nforeign law-enforcement agencies to unplug unsavory or illicit sites they\nhosted. According to Vishnevsky, McColo’s servers were legendary for their\nconsistent speeds and for being “bulletproof,” or immune from shutdown\nrequests lodged by other Internet service providers (ISPs) or foreign law-\nenforcement officials.\n\nShortly after Kolya’s death, McColo was quick to assure the cybercrime\ncommunity that, while the organization’s most recognizable member had passed\naway, the hosting provider would continue business as usual. Kolya’s partner,\nAlexey, spread the message on a number of top cybercrime-friendly forums,\nseeking to reassure the firm’s client base that the incident would result in\nno disruption of service.\n\nThe cybercrime community needed little convincing to stay. The service was\nmainly hosted in the United States, and was cheap, reliable, and fast. For the\nyear following Nikolai’s death, Nechvolod and most of the top spam botmasters\nwould keep their botnet control servers parked at McColo.\n\nThat is, until the evening of November 11, 2008, when an exposé in the\nWashington Post about the high concentration of malicious activity at the\nhosting provider prompted the two suppliers of McColo’s connection to the\nlarger Internet to simultaneously pull the plug on the firm. In an instant,\nspam volumes plummeted by as much as 75 percent worldwide, as millions of spam\nbots were disconnected from their control servers and scattered to the four\nwinds like sheep without a shepherd.\n\nThe McColo takedown hit botmasters like Nechvolod and Vishnevsky directly in\ntheir pocketbooks. Spammers who were renting the botnets flooded Crutop.nu and\nother underground fraud forums with complaints that they had lost substantial\ninvestments, demanding to know what was going to be done about it.\n\n“On McColo, we hosted servers in the USA that had good speed,” Vishnevsky\nrecalled. “When McColo went down, we had to rent much slower servers in China\nand other countries that suck,” in their ability to withstand abuse\ncomplaints, he said.\n\nIn a sign that few thought McColo’s operations would ever go away—even after\nKolya’s death—many spammers actually kept another major and expensive\ncomponent of their operations—huge email address lists—directly on the\ncompany’s servers.\n\n“Everyone lost their lists there,” Vishnevsky said, noting that he and\nNechvolod lost a particularly large and valuable list of more than two billion\nemail addresses after the takedown.\n\nKolya’s death and the dissolution of McColo were watershed events because they\nsignified the beginning of the end of an era in which spammers and cybercrime\nlords were allowed to operate under the radar with relative impunity. At the\ntime, more than 90 percent of all email sent worldwide was unsolicited junk,\nthe bulk of it advertising fly-by-night Internet pharmacy sites. In the\nensuing four years, a series of similar takedowns of rogue ISPs, hosting\nproviders, and large spam botnets would make a major dent in worldwide junk-\nemail volumes and coincide with the arrest or imprisonment of several top\nspammers.\n\nHowever, McColo’s demise also marked the dawn of a new age of spamming through\nthe genesis of a protracted and costly turf war we’ll explore in this book.\nDubbed the “Pharma Wars” by bystanders in the cybercrime and cybersecurity\nworlds, it exploded into a vicious feud between two of the largest sponsors of\npharmaceutical spam—with unsuspecting users like you and me trapped in the\nmiddle.\n\nOn one side of the battle were the aforementioned Dmitry Stupin and Igor Gusev\nand their sister pharmacy operations GlavMed and SpamIt. On the other was Rx-\nPromotion, a competing rogue Internet pharmacy started by Gusev’s former\nbusiness partner, thirty-five-year-old Muscovite Pavel Vrublevsky. Officially,\nVrublevsky was the top executive at a company called ChronoPay, one of\nRussia’s largest online payment-processing firms and a company that he and\nGusev cofounded.\n\nIn secret, he had deep ties to the cybercrime underworld, helping online\nmiscreants of all stripes obtain credit card processing for their shady\nendeavors, and taking a hefty cut of the action. Vrublevsky also is the\ncofounder and administrator of the popular spammer forum Crutop.nu and another\npivotal figure in the cyber wars that have made us into a spam nation—or in\nreality, a world of spam—today.\n\nBy 2010, I had spent more than a year investigating and reporting on\nallegations of corrupt business practices by Vrublevsky and his reputed ties\nto spammers working for the Rx-Promotion rogue pharmacy program, first as an\ninvestigative reporter for the Washington Post and then for my own\ncybersecurity news website, [KrebsOnSecurity.com](http://KrebsOnSecurity.com).\nBut as I dug deeper and deeper, I wanted to know more about the spam email and\ncybersecurity problem: who was driving it and how to solve it. It was clear\nothers did, too.\n\nPrior to the war of attrition between spam kingpins that this book will\nexplore, there was shockingly little public and reliable information available\nto answer the most basic questions facing the spam problem, such as:\n\n•Who is buying the stuff advertised in junk email, like Viagra, prescription\ndrugs, and even Gucci purses? And what drives people to purchase and ingest\npills pushed by these intrusive and unknown marketers?\n\n•Are these drugs real or ineffective—and possibly lethal—fakes?\n\n•Who is profiting from sending spam? How are the profits being divvied up, and\nwhere is the money going?\n\n•Why is the pharmaceutical industry—one of the richest and most influential\nbusinesses in the world—seemingly powerless to stop the wholesale theft and\nhijacking of its products, trademarks, and customers?\n\n•For that matter, why is it so easy to pay for these blatantly spam-advertised\nknockoffs with a credit card?\n\n•Do customers have their credit card accounts hacked or resold after buying\nfrom spammers? What if they don’t even buy from them? Are they still in\ndanger?\n\n•And what can consumers, policymakers, and law enforcement use to get control\nof the cybercrime epidemic?\n\nThese are some of the questions people asked when I told them I was writing a\nbook about spam. At the beginning, I could offer only my best guesses for\nanswers. Even as I sought advice from purported spam experts, I discovered\nthat some of the world’s top authorities on spam didn’t have a firm grip on\nthe answers either. Many offered canned responses that seemed to be based on a\nhandful of well-worn case studies, some of which were sponsored by major\npharmaceutical or security companies, or both.\n\nLeaked pharmacy spam databases that I was able to obtain from Rx-Promotion and\nGlavMed-SpamIt during the Pharma Wars changed all of that by providing a deep\ninsider look at almost every significant aspect of the world’s largest spam\norganizations. Perhaps ironically, the spammers themselves provided this\nglimpse into their shady doings that affect each of us every day.\n\nHackers loyal to Gusev and Vrublevsky leaked this information to certain law-\nenforcement officials and to me in an attempt to sabotage each other. Instead,\ntheir databases offered unprecedented insight into the day-to-day operations\nand profits of these secretive, international drug cartels, which comprise a\nloose affiliation of spammers, virus writers, shadowy suppliers, and shippers.\nThe information in these databases also forms the basis of my reporting for\nmany portions of this book.\n\nMore importantly—and alarmingly—this cache of documents also contained the\ndemographic, health, and financial information of millions of customers—mostly\nconsumers in the United States—who had purchased prescription medications from\nthe spam networks upon receiving a solicitation by junk email or after\nsearching for prescription drugs online.\n\nThe databases offered an unvarnished look at the hidden but burgeoning demand\nfor cheap prescription drugs, a demand that appears driven in large part by\nAmericans seeking more affordable and discreetly available medications.\n\nGiven the increasing menace of spam email and related cybersecurity assaults\nthat directly affect consumers and companies (like the major news story I\nbroke to the media in December 2013 about the Target credit-card database\nbreach—a cyberattack that compromised millions of Americans’ financial\ninformation and forced an even greater number of us to get new credit cards),\nyou may be wondering why governments, law-enforcement officials, and\ncorporations aren’t taking a stronger and more significant stance to stop the\ntidal wave of spam and cybercrime impacting us all.\n\nPart of the reason for the Internet community’s stunted response to the\nmalware and spam epidemic to date is that many policymakers and cybercrime\nexperts tend to dismiss spam as a nuisance problem that can be solved or at\nleast mitigated to a manageable degree by the proper mix of technology and law\nenforcement. For many of us, spam has become almost the punch line of a joke,\nthanks to its close association with male penile-enhancement pills and\nerectile dysfunction medications such as Viagra and Cialis. We assume that if\nwe don’t open the emails or don’t purchase anything from them, we aren’t\naffected.\n\nUnfortunately, that attitude underscores a popular yet fundamental\nmiscalculation about the threat that spam poses to every one of us: namely,\nthe sheer destructive power of the botnets and the misguided computer\nprogrammers who keep them going. Indeed, the botnets built and managed by\nmembers of SpamIt, Rx-Promotion, and other spam affiliate programs were not\nonly used for distributing spam. Web criminals routinely rent access to these\ncrime machines to mask their true location online, because botnets allow\nmiscreants to bounce their Internet traffic through a myriad of infected\nsystems that are largely untraceable.\n\nCrooks running these botnets also regularly use them to harvest usernames and\npasswords from host PCs, stealing everything from people’s online banking\ncredentials to digital keys that can unlock valuable corporate secrets at\ncompanies large and small. Indeed, the miscreants at the helm of some of the\nworld’s most active botnets already control thousands of zombie systems inside\nFortune 500 companies that allow attackers to spam people using these\ncorporations’ more powerful servers, and to siphon sensitive and proprietary\ndata from internal company systems.\n\nBotnets pose other serious threats. Frequently they are rented out as powerful\nhired muscle in high-stakes Internet extortion schemes known as distributed\ndenial of service or “DDoS” attacks. In such assaults, crooks demand tens of\nthousands of dollars in protection money from businesses. If business owners\nrefuse to pay up, the botnet masters will order their armies of infected PCs\nto pelt the targeted company’s website with so much junk Internet traffic that\nit can no longer accommodate legitimate visitors. The extorted business either\npays up or stays offline until the attackers relent (or, if the targeted\nbusiness can afford it, hires a legitimate anti-DDoS company to help deflect\nthe attacks).\n\nPolitically or ideologically motivated DDoS attacks are capable of unplugging\nentire nations and silencing critics or protesters of certain issues. In 2008,\na politically motivated, sustained DDoS attack against the ultra-wired former\nSoviet nation of Estonia knocked most government sites offline for several\ndays, interrupted electronic banking for several hours, briefly incapacitated\nthat country’s largest cellular network, and disrupted the national network\nthat Estonians rely on in the event of medical emergencies.\n\nSuch firepower has gained the attention and concern of the U.S. government and\nits military operations as well. Cyberattacks have been identified as a potent\nand current threat to today’s network-centric war-fighting machine. In a\nseminal speech at the White House in May 2009, President Obama declared the\ncyber threat to be one of the most serious economic and national security\nchallenges facing America today.\n\nDespite government concerns, the public policy response to all of the\norganizational and technological machinery that powers the spam epidemic has\nbeen lukewarm at best and, in some places, virtually nonexistent. Here is a\nthreat that is capable of disrupting entire countries’ infrastructure,\ndiluting vital communication networks, poisoning people with its spread of\ncounterfeit consumer products, and fueling the development of an entire\nillegal underground economy, yet governments around the world have done little\nto protect their citizens from these invasive cyber armies.\n\nMany lawmakers in the United States and elsewhere are using the cybercrime\nepidemic to lobby for changes to the laws that govern how police and federal\nauthorities can gather data on their citizens. But more stringent penalties\nagainst cybercrime have done little to deter attackers or the activities of\nfortune-seeking pill spammers and modern e-thieves. Most of the recently\nproposed and approved Internet security laws in the United States have focused\non vague initiatives to beef up the security of the nation’s critical\ninformation infrastructure—the computers and interconnected systems that run\neverything from manufacturing plants to water treatment facilities and the\npower grid.\n\nRecent legislative efforts in the United States aimed at combating cybercrime\nhave also met with stiff resistance from privacy advocates and the public at\nlarge. When the U.S. Congress tried to pass a law that would have forced ISPs\nto cease providing connectivity to websites that were deemed to have trampled\non trademarks by peddling pirated or counterfeit goods, lawmakers were\nconfronted with nothing short of a popular revolt from constituents opposed to\nthe idea. Most of that resistance was organized and executed in artfully\nplanned online demonstrations.\n\nMeanwhile, a handful of key arrests and disruptive actions against spam\nbotnets and top players in the cybercrime underground appear to have done more\nto destabilize the industry than any of the half-baked legislative proposals\nput forth so far. As numerous examples in this book illustrate, governments\naround the world can perhaps achieve the most impact on cybercrime not by\npassing new laws or increasing penalties for various cybercriminal offenses,\nbut by better enforcing existing laws and by creatively applying pressure on\nand incentivizing global corporations to address this problem in ways that\nsuit their own interests and extend the reach of domestic law-enforcement\nagencies.\n\nThis is not to say that the answer to combating spam and botnets rests only\nwith the governments of the world. On the contrary; as we will see later in\nthis book, some of the most effective actions against these dual scourges have\ncome from efforts by corporations to protect their own financial interests,\ncustomers, trademarks, and public image—and from consumers themselves.\n\nUltimately, spam and all of its attendant ills will diminish very little\nwithout a more concerted, cooperative push from some of the richest and most\npowerful interests in the world, including the pharmaceutical industry; the\ncredit card and banking sectors; lawmakers and law enforcers around the globe;\nand people like you and me, most of whom are the unsuspecting targets and\nvictims of these spammers and hackers every day. It’s time to do something\nabout this global epidemic, to protect our identities, our bank accounts, our\nfamilies, and our lives before it’s too late.\n\n* * *\n\n[1.](01_chapter01.xhtml#fnr1)It should be noted that Gusev has publicly denied\nsending spam and running SpamIt, though not to me directly in my interviews\nwith him.\n\n\nChapter 2\n\n## BULLETPROOF\n\nTo understand the threat that email spam poses for all of us, it’s crucial\nfirst to peer into the dark corners of the cyberworld and understand what’s\nlurking there. Kidnapping. Bribery. Extortion. Blackmail. Corruption. These\nwere among the business skills commonly employed by the men who built the\nearliest cybercrime havens—the virtual pirate coves of the Internet.\n\nThese web hosting businesses—mostly based in Russia and the former Soviet\nstates—were often referred to as “bulletproof networks” or “bulletproof\nhosting providers” because they had secured enough political and operational\nprotection through a variety of methods (some legal, some illegal) to make\nthem virtually untouchable by the law. Indeed, they had so much clout that\nthey could often stay online in the face of withering pressure from foreign\ngovernments and law-enforcement agencies to disconnect them and their\ncustomers, who were invariably trafficking unsavory or illicit goods and\nservices on the web.\n\nOne of the leaders, McColo Corp., was a master at this. Nikolai, the young\nentrepreneur whose violent death by car accident we witnessed at the outset of\n[Chapter 1](01_chapter01.xhtml), certainly didn’t invent the business of\nattracting and hosting cybercrime-based enterprises online. Rather, like\ninnovators in other fields, he stood on the shoulders of cybercriminal giants\nbefore him, refining a time-honored business model by focusing on efficiency:\ncutting out middlemen, slashing prices, and investing in more dependable,\nfaster networks.\n\nMost of all, McColo distinguished itself by earning a reputation as a\nbulletproof hosting provider that offered top-notch technical and customer\nsupport. These were qualities that early pioneers in the business tended to\noverlook, probably because they had so little competition.\n\nBut to understand how McColo came to dominate the cybercrime underground, it\nhelps to know how and why its predecessors failed. As it happens, the\nbulletproof hosting providers that laid the groundwork for young Nikolai’s\nbusiness also are closely intertwined with the early careers of the two\ncybercrime kingpins whose lengthy feud forms the basic story arc of this book.\nAnd one network above all paved the way for the rise of McColo, the Pharma\nWars, and many of the junk email and cybercrime practices that threaten us and\nour online security today.\n\nBy the middle of 2007, the Russian Business Network (RBN)—a shadowy web\nhosting conglomerate based in St. Petersburg, Russia—had cemented its\nreputation among security experts as the epicenter of cybercriminal activity\non the Internet. In case after case, when computer crime investigators\nfollowed the trail of money and evidence from sites selling child pornography\nor pirated software, web properties at RBN were somehow always involved. When\ncyber sleuths sought to shutter sites that were pumping out colonies of\ncomputer viruses and “phishing” scams that use email to impersonate banks and\nlure people into entering account passwords at fake bank sites, more often\nthan not, the offending site was a customer of RBN.\n\nRBN epitomized the early bulletproof hosting providers, virtual safe houses\nwhere web hosting customers could display and offer practically any online\ncontent—no matter how illegal or offensive—as long as they kept paying\nexorbitant hosting fees that were prone to increase without notice. A basic\nweb server at RBN commanded prices between six hundred and eight hundred U.S.\ndollars per month, more than ten times what most legitimate hosting providers\ncharged for regular customers at the time.\n\nThese fees didn’t just line the pockets of the bulletproof providers; they\nwere essential to those providers’ survival. For example, a share of the\nincome from those lofty fees trickled down from RBN’s ringleaders to local\nauthorities and corrupt politicians in the region, some of whom were all too\nready to look the other way when law-enforcement officials from other nations\ncame inquiring about sites promoting illegal activity that were hosted on\nRBN’s networks.\n\nDavid Bizeul, a French security researcher who compiled a massively in-depth\nanalysis of RBN during its heyday in mid-2007, said RBN had a dedicated team\nresponsible for fielding abuse complaints, but that this team only served to\nmake RBN appear more like a legitimate Internet service provider (ISP) than\nanything else.\n\n“RBN has an available abuse team—used to give it a respectable image—and this\nabuse team will ask you to provide a Russian judicial indictment in order to\nprocess” an abuse or takedown request, Bizeul wrote in 2007. “Of course, this\nindictment is very difficult to obtain. Isn’t it a paradise for fraudsters?”\n\nThe exact origins of the Russian Business Network are shrouded in mystery.\nPerhaps for that reason, many experts in the computer security industry have\nfor years ascribed most malicious Internet activity to the ringleaders behind\nRBN, whether or not that activity had any obvious connections to the infamous\nhosting network.\n\nStill, if RBN has become a kind of digital boogeyman for many, that reputation\nwas hard-earned. According to press reports and sources familiar with the\ncompany, RBN was born out of cybercriminals’ need for more stable and reliable\nweb hosting for a variety of their illegal businesses—most especially extreme\npornography and child porn. Indeed, RBN’s roots trace back to the child porn\nindustry and to organized crime groups based in Minsk, Belarus.\n\nAt the dawn of the new millennium, a bright, twenty-two-year-old Belarusian\nnamed Alexander Rubatsky was being groomed to follow in the footsteps of his\nfather—a well-respected lieutenant colonel in the Belarusian police force. But\nRubatsky was far more interested in and skilled at computers, and eventually\ndropped out of the police academy.\n\nVictor Chamkovsky, a Belarusian filmmaker and investigative journalist who\ndocumented Rubatsky’s early career, said Rubatsky’s talents made him an\nattractive acquisition by local organized crime groups who saw big money in\nprocessing payments for Internet businesses, particularly pornography.\nAccording to Chamkovsky, in 1995 Rubatsky started hanging out with Gennady\nLoginov, a young tough whose brother was the leader of a militant organized-\ncrime group in Minsk known as “The Village.” Rubatsky’s job was not to strong-\narm people, but to simply find databases to plunder and acquire credit card\naccounts that could be drained or sold for cash.\n\nIn Spring 2001, Rubatsky began looking for a real job and was hired as a\ncomputer specialist with CyberPlat, at the time Russia’s largest processor of\nonline payments. As part of his position, he was given the funds and authority\nto hire more than a dozen other programmers. His assignment: to assemble a\nteam that could build the next generation of CyberPlat’s payment platform.\n\nAs noted by the Belarusian newspaper BelGazeta, CyberPlat also paid Rubatsky\nto rigorously test its systems for security vulnerabilities that might expose\nit to data breaches. But the company would later allege that he abused that\naccess by downloading a copy of the company’s client database. Rubatsky told\nprosecutors that he grabbed the data merely so that he could demonstrate the\nsecurity weaknesses his team had found. But his employer wasn’t buying that\nexplanation. The local police raided the cabin where Rubatsky and his hackers\nworked, and carted off enough evidence to put him on trial for theft. The\nBelarusian courts ultimately sided with CyberPlat, sentencing Rubatsky to six\nmonths in jail. (That sentence was later suspended.)\n\nBut Rubatsky would exact his revenge. Before his trial ended, CyberPlat’s\ncustomer list was leaked to law-enforcement officials. Cybercrime\ninvestigators from the United States and other nations had long suspected that\nmost of the payments to sites selling child pornography were being processed\nthrough merchant accounts tied to CyberPlat and its Moscow-based partner Bank\nPlatina, and now the authorities had a smoking gun.\n\nBy mid-2002, CyberPlat found itself ensnared in an international scandal when\nit was reported by the Russian news publication Kommersant that among\nCyberPlat’s customers were dozens of websites selling access to child-porn\nimages and videos. CyberPlat fired 40 percent of its staff—including top\nmanagers—in the wake of the scandal.\n\nMeanwhile, Rubatsky was left to continue pursuing the extremely lucrative\nmarket of processing child-porn payments for shady sites that offered it. At\nthe same time, Rubatsky’s strongman Loginov was determined to beef up\noperational and physical security for the enterprise. Never again would local\npolice forces be able to so easily raid the hacker\nhut.[2](02_chapter02.xhtml#fn2)\n\nPrefiguring his later work as a pioneer in the bulletproof hosting business,\nRubatsky sought to secure local and physical protection so that he could\ncontinue to operate his business without interruption or interference. If the\nlocal police decided to conduct another raid, at least Rubatsky would see them\ncoming and have a chance to hide or destroy incriminating evidence of his\nbusiness.\n\nAccording to a documentary by Chamkovsky called Operation Consortium, and as\ndocumented in other Russian news sources, Loginov and his associates rigged\nthe cottage with a variety of security devices, including closed-circuit\ncameras and alarm systems. Loginov’s team also acquired firearms, police\nradios, and uniforms. They even received combat training under the tutelage of\na former officer from the Russian KGB—the secret police and intelligence\nagency of the Soviet Union.\n\nLoginov’s gang was reportedly subjected to a crash course in KGB field\nservice, including a battery of physical and psychological endurance tests, as\nwell as specialized instruction in a variety of medical and technical skills.\n“Initially, they even had to take [written] tests,” said Igor Parmon, a deputy\nin the Belarusian Ministry of Internal Affairs, in Chamkovsky’s documentary.\n“They were even punished for missing classes.”\n\nA 2004 story in the Belarusian Business News describes how Loginov’s group\nreacted when they learned that a local businessman named Evgeny “Pet”\nPetrovsky was building his own credit-card processing business catering to the\nchild porn industry—a company called Sunbill (later renamed BillCards). The\norganized crime gang decided to put their newfound combat training to work by\neliminating—or at least intimidating—the competition. Petrovsky’s alleged role\nin setting up card processing for child porn sites was also documented in 2004\nby the Computer Crime Research Center, a nonprofit organization based in\nOdessa, Ukraine, that gathers data on transnational cybercrime.\n\nPetrovsky was stopped in his car by a man posing as a local policeman, and\nwhen he stepped out of the car as directed, he was kidnapped by masked men.\nOnce they reached their safe house in the outskirts of Minsk, the abductors\ncontacted Petrovsky’s associates and demanded a million U.S. dollars for his\nsafe return. But no money would be forthcoming. When local authorities began\nto close in on their location, the assailants fled with Petrovsky to Moscow.\nBy November 2012, Russian and Belarusian authorities had located the Loginov\ngang’s hideout and arrested the kidnappers. They found Petrovsky alive and\nrelatively unharmed.[3](02_chapter02.xhtml#fn3)\n\nAccording to Chamkovsky, Rubatsky was intensely focused on hacking and\nplundering online stores of financial data, and was not aware of his comrades’\nparamilitary activities. But when Rubatsky got word that Loginov’s group had\nbeen rounded up by law enforcement for kidnapping and extortion, he fled\nBelarus for St. Petersburg, Russia.\n\nFrom a rented office space in downtown St. Petersburg, Rubatsky reportedly\nworked with contacts at Moscow’s Alfa Bank to set up an entirely new payment\nsystem called “Alfa-Pay.” The system was designed to process payments for\nchild pornography and to shield the business from disruption or prying eyes.\nAs described in a 2006 story in the Belarusian newspaper Evening Minsk, the\nbusiness relied on a network of holding companies that served as\nintermediaries for employees back in Belarus who handled everything from\nphotographing teenage and preteen models to the distribution of the content\nand the payment of commissions to resellers of the photographic content.\n\n“With Rubatsky’s help, a huge holding was developed, which encompassed\neverything from photo-shooting and pornography distribution to the\nadministrative work of a holding company, [including] regular payments,\nbilling, and commissions,” Chamkovsky wrote. “Rubatsky’s know-how on…sites\ndedicated to child pornography was in creating [a] cookie-cutter system that\ncould be easily cloned.”\n\nAll of this may have seemed like an issue isolated to Russia and Eastern\nEurope, where these shadowy cybercriminal companies are allowed to exist. But\nthe truth is that the vast majority of the business’s customers were actually\nAmericans who were willing to pay more than forty dollars per month for\nsubscription access to the child porn sites, known in the underground as\n“strawberry” and “lolita” sites (the latter being a literary reference to the\nnovel of the same name by Russian author Vladimir Nabokov). According to press\nreports on the operation, Rubatsky’s network of child porn sites attracted\nmore than 100,000 visitors per day and generated revenues of nearly $5 million\nper month.\n\nBut before long Alfa-Pay found itself at odds once again with Petrovsky’s\nBillCards payment-processing business. By this time, Petrovsky had allied\nhimself with Igor “Desp” Gusev, who was rumored to have been the administrator\nof a secret online forum called Darkmasters.com, which catered to webmasters\n(website owners) engaged in selling extremely hard-core porn, including child\npornography.[4](02_chapter02.xhtml#fn4)\n\nRubatsky’s Alfa-Pay and Petrovsky’s BillCards were soon vying to destroy one\nanother, said Pavel Vrublevsky, cofounder and owner of ChronoPay, the Russian\ncompany mentioned in [Chapter 1](01_chapter01.xhtml) that got its start in\n2003 processing payments for adult webmasters. (In 2003, Gusev would join\nVrublevsky as a fifty-fifty cofounder in ChronoPay, which would later eclipse\nCyberPlat as Russia’s largest processor of online payments.)\n\n“Alfa-Pay got in a huge fight with BillCards, and they both started launching\ncomputer attacks against one another, trying to start criminal cases against\neach other, and sending all kinds of incriminating information to mass media\nand all that crap,” Vrublevsky recalled in a 2010 interview that would eerily\nprefigure the turf battle then already underway between himself and Gusev over\ncornering the market for knockoff pharmaceuticals online. “As a result, both\nbusinesses fell apart, and it was a big scandal.”\n\nThat’s when Rubatsky decided it was time to go into another lucrative but less\ndangerous line of work: web hosting. According to Vrublevsky, the Belarusian\nset up a meeting with the men running Eltel, a local ISP whose networks\nconnected much of St. Petersburg to the rest of the public Internet.\n\nVrublevsky maintains that Eltel’s management had bought political protection\nfor their business from agents of the Russian Federal Security Service (FSB),\nthe successor to the Soviet Union’s KGB. This type of cover, known as krusha\nor “roof” in Russian, was considered necessary for any business capable of\ngenerating healthy profits—because such income made the business vulnerable to\ncriminal and governmental interference and even violence.\n\nAccording to Vadim Volkov, author of Violent Entrepreneurs: The Use of Force\nin the Making of Russian Capitalism, FSB officers are frequently embedded as\nemployees of Russian companies, ostensibly as a means to help them fight\nextortionists who might try to steal the company’s profits.\n\nVolkov writes that Russian law allows FSB agents, while remaining in service,\nto be “assigned to work at enterprises and organizations at the consent of\ntheir directors… This provision allowed thousands of acting security officers\nto hold positions in private companies and banks as ‘legal consultants,’ as\nthe position was modestly called. Using their ties with the state\norganizations and information resources of the FSB, they performed what has\nbecome known as ‘roof’ functions—protecting against extortion and cheating by\ncriminal groups and facilitating relations with the state bureaucracy. Expert\nestimates suggest that up to 20 percent of FSB officers are engaged in\ninformal ‘roof’ businesses.”\n\n“The Eltel guys were famous for being really crazy and hosting child\npornography and crap like this, because they had a good relationship with the\nlocal cops,” Vrublevsky said in a telephone interview. “But the ISPs upstream\nfrom Eltel were constantly blacklisting their sites, so [to get around that\nissue] Rubatsky came up with the idea of having a direct link to big [Internet\nbackbone providers] like Telia and Tiscali.”[5](02_chapter02.xhtml#fn5) With a\ndirect link, bulletproof hosting providers would no longer be at the mercy of\nsmaller, intermediary ISPs that could be bullied into pulling the plug on RBN\nat the slightest sign of interest from law enforcement.\n\nTo circumvent this obstacle, “this Rubatsky guy ended up spending a shitload\nof money so [Eltel] could have their own channel of Internet coming from\nabroad,” Vrublevsky recalled. “And they called it the ‘Russian Business\nNetwork,’ or RBN for short.”\n\nAccording to Vrublevsky, Rubatsky appointed as head of the RBN project a\nsmart, young technician named Eugene I. Sergeenko, a twenty-year-old hacker\nbetter known in the underground by his handle, “Flyman.”\n\nFlyman would soon become synonymous with both RBN and the global spam\nepidemic, as RBN emerged as the global epicenter of malicious cyberactivity,\nincluding everything from phishing schemes to the penis-enlargement spam that\nbombards each of us every day.\n\n♦ ♦ ♦\n\nBy 2007, RBN had evolved into a cybercriminal force to be feared. The rogue\nhosting provider had become a massive magnet for online criminal schemes of\nall kinds. Researchers in academia and at private Internet security firms had\nbeen sounding the alarm about RBN for more than a year, churning out countless\nreports about huge volumes of phishing scams, male enhancement spam, and sites\nhosting malicious software emanating from the troubled ISP and contaminating\nmillions of Internet-connected systems around the world. But most of these\nreports were fairly technical analyses that examined just one or two aspects\nof the multifarious badness emerging from RBN—such as a new malware\ninnovation, a botnet command center, or another orchard of malicious websites\nthat had sprung up in RBN’s backyard.\n\nIt occurred to me that nobody had centralized all of the disparate research on\nRBN or sought to pull it all together into a single report revealing all of\nthe malicious activity there. At the time, these various reports had gradually\nworn down the support infrastructure that kept RBN’s network online, so it\nseemed to me that a major exposé in a widely read publication might topple the\nentire enterprise once and for all.\n\nI’d recently carved out a cybercrime beat as a reporter at the Washington Post\nand was eager to centralize the intelligence on RBN in a report that I hoped\nmight bring broader attention to the size of the threat. I firmly believed\nthat the cybercrime community had made a major strategic blunder in\nconcentrating so much badness in one place. If somehow RBN was ostracized and\nshunned by the rest of the Internet community, many cybercriminal businesses\nwould be unplugged from the web.\n\nCybersecurity experts I spoke with about the idea said such an action could\nincrease the costs of these criminal operations and make it more difficult for\nthem to find a stable home. One possible end result would be much less spam\nfor everyday users and fewer sites pushing malicious software or peddling\nchild porn. To me, the positive implications were huge. Not only could this\ndecrease or possibly eradicate junk email and all of the viruses, malware, and\nother security problems that come with it, but it could also possibly decimate\nan illegal and shocking industry that harmed children for the perverse\npleasure of a small minority of adults.\n\nIn June 2007, I began badgering dozens of sources for quantifiable data about\nmalicious activity that persisted at RBN. Over the next four months, the\nreporting aspect of the story came together almost on its own, as facts\npouring in from different sources about the location of websites both\nmalicious and atrocious began to paint a truly frightening picture of this\nrogue Internet hosting firm and what it was doing to clog our networks with\ndestructive spam email.\n\nNearly identical damnations of RBN came in the form of incriminating data from\nsome of the most noted security firms in the industry, including Cisco, Dell\nSecureWorks, FireEye, HostExploit, Marshall/M86, the SANS Internet Storm\nCenter, Shadowserver, Sunbelt Software (now GFI), Symantec, Team Cymru, Trend\nMicro, and Verisign, to name just a few.\n\nKen Dunham, then director of rapid response for Verisign’s iDefense cyber\nintelligence unit, said his team examined all of the web properties hosted at\nRBN and couldn’t find a single redeemable quality there. “We went through and\ncorrelated all of their information, and we couldn’t find one good thing at\nRBN,” Dunham said. “We’ve seen virtual safe houses for criminal groups in the\npast, but virtually everything within this hosting provider has always been\nillicit or malicious.” In short, there was no redeeming reason for this\ncriminal ISP to remain online.\n\nPerhaps because of the mystery and aura of Russian organized crime that\nsurrounded RBN, convincing sources to speak openly and plainly about what they\nknew of the ISP’s operations was far more challenging. One source, an academic\nwho fed investigators at the Federal Bureau of Investigation daily dossiers on\nthe sale of child pornography and other criminal activity at RBN, said he was\nworried for his physical safety if he spoke out publicly on what he knew.\n\n“The Russian Mafia is behind RBN, and they have big guns and small morals,”\nthe academician explained. “I’d love to be an ‘expert’ for you, but I really\ndon’t want to get my family whacked.”\n\nThat was one of dozens of candid quotes I could never attribute, and I\ndesperately needed experts to state on the record what they knew about RBN in\norder to expose this malicious network that was affecting the lives of\nmillions of unsuspecting people. After much cajoling, I eventually convinced\nenough experts to speak the truth. On October 13, 2007, the Washington Post\nran the story “Shadowy Russian Firm Seen as Conduit for Cybercrime,” in the\nfront section of the paper and featured the piece prominently on their\nwebsite.\n\nNot long after that story, the Post also ran a pair of supporting pieces on\nits Security Fix blog, detailing the malicious activity at RBN and explicitly\ncalling out which ISPs were providing RBN connections to the rest of the\nInternet. The jig was up. Now that their names were out in the open, these\nproviders would need to justify taking money from RBN—an indefensible position\ngiven RBN’s horrid reputation as safe haven for any material, no matter how\nillegal or offensive.\n\nOver the next few weeks, tens of thousands of Internet addresses previously\nassigned to the Russian Business Network were gradually abandoned. The\ncybercrime enterprises that had once occupied these “cyber lots” vanished,\nscattering to new bulletproof hosting providers in Italy, China, Korea, and\nelsewhere. The result was that for a short time, while the spam bots continued\nblasting out junk advertisements and links to malware-laced sites, the sites\nadvertised in those emails sat unresponsive. Although on the surface this was\na hollow victory, for many in the security community it was a welcome shot\nacross the bow alerting the cybercrime underground that the online security\nindustry was finally fighting back.\n\nNot everyone was thrilled about this development. Whereas before RBN had been\na concentration of known bad hosters that ISPs could easily block or filter\nwith a handful of firewall instructions, such blocking became much harder once\nthe sites at RBN were dispersed to dozens of networks. Now, ISPs had to spread\ntheir security nets farther to ensure that malicious websites, botnets, and\nspammers couldn’t get through. But ISPs, government officials, and\ncorporations were finally starting to pay attention to this cybercrime\nunderworld spreading beneath their feet.\n\nThat was the tip of the iceberg. In August 2008—almost a year after RBN was\nscattered to the four winds—I wrote a series about cybercrime activity\nconcentrated a bit closer to home at a shadowy ISP called Atrivo. Like young\nNikolai’s McColo, it was a Northern California-based hosting provider that had\nalso ignored requests from law enforcement agencies and from the security\ncommunity to unplug abusive websites that had become synonymous with botnet-\nhosting and huge numbers of sites set up to foist malicious software. I relied\non the same evidence collected by some of the security firms that had gathered\ndata on RBN, and in particular a report from HostExploit, an organization of\ninternational respected Internet professionals dedicated to researching,\nexposing, and raising awareness about cybercrime.\n\nThat series, and growing attention from other media outlets and security\nexperts, led to Atrivo being gradually excluded from the Internet, as its\npartners in the ISP industry who provided connections to the larger Internet\nfor it and its cybercriminal users were publicly shamed into severing ties\nwith the company one by one over a period of approximately two weeks.\n\nOne of the significant fallouts of Atrivo’s shutdown was the hastened demise\nof the Storm worm, an infamous botnet that had infiltrated and compromised\nmillions of Americans’ PCs and “was once responsible for sending more than 20\npercent of all spam,” I explained on the Washington Post’s Security Fix blog\non October 17, 2008. Atrivo had hosted a number of the master servers for the\nStorm worm; the worm discharged its final blast of spam three days before\nAtrivo was forced off the Internet by its final remaining Internet provider.\n\nA week after Atrivo went dark, I heard from a trusted source who had contacts\nwith many unsavory individuals in the cybercrime underworld. My source said he\nhad a message to pass on from an unnamed cybercrook who’d been mildly\ninconvenienced and grudgingly impressed by the organized ostracism of Atrivo I\nhad started.\n\n“Tell Krebs ‘Nice job on Atrivo,’” the mysterious miscreant told my source.\n“But if he’s thinking about doing McColo next, he’s pushing his luck.”\n\nI wasn’t sure what to make of this communication, which seemed like an amused\nobservation backstopped by a veiled threat. But by the time my source relayed\nthat message, it was too late to turn back. I was already knee-deep in an\ninvestigation of McColo, the ISP company led by Nikolai “Kolya” McColo. It was\na logical progression, mainly because many of the miscreants and botmasters\nwho had parked their botnet and crimeware operations at Atrivo also had\nportions of their infrastructure hosted at McColo. And now that Atrivo was\nwiped off the Internet, McColo had become an even more critical bulletproof\nprovider for the underground cybercrime community.\n\nOn the afternoon of November 11, I sent several months’ worth of data\ndetailing McColo’s offenses to the company’s two ISP partners that connected\nit to the larger Internet: Global Crossing and Hurricane Electric, both of\nwhich had headquarters in the United States. The information was arranged in a\nmap that showed how the servers used to control all of the top five most\nactive spam botnets—Internet-connected programs responsible for sending most\nof the world’s junk email—were parked at just a handful of servers in McColo’s\nNorthern California hosting facility. I had a hunch that, once presented with\nthe record of malicious activity there, McColo’s Internet partners would sever\nbusiness ties with the hosting provider and effectively cripple it.\n\nHours later, I heard from a source who monitored global spam activity daily,\nand who knew I was working on a piece about McColo.\n\n“Krebs, what did you do?” the source asked with a praising laugh. “I’m hardly\nseeing any more spam, and it looks like McColo has been unplugged from the\nInternet!”\n\nI don’t recall saying thank you or good-bye—I only remember swearing loudly\nand slamming the receiver down to quickly dial several other sources on my\nmobile phone. All of them confirmed the same findings: McColo was gone, and\nnone of its Internet address space was reachable from anywhere on the World\nWide Web. Mission accomplished—for the time being.\n\nA call to Benny Ng, Hurricane Electric’s director of marketing, revealed the\nreason. The ISP had severed ties with McColo that afternoon.\n\n“We looked into it a bit, saw the size and scope of the problem you were\nreporting, and said ‘Holy cow!’” Ng said. “Within the hour we had terminated\nall of our connections to them.”\n\nWithin a few minutes of confirming the takedown, I wrote and published a blog\npost about the McColo outage—which quickly became one of the biggest\ncybercrime stories, in terms of immediate global impact, up until that\ndate—and then began working on a longer story about the incident that was\nintended for publication on the Washington Post’s site and possibly in the\ndead-tree edition (as the print version was affectionately known among us dot-\ncom reporters) the following day.\n\nI worked from my home office that evening and well into the morning, toiling\nover the follow-up piece until eventually falling asleep in my pajamas at the\ncomputer keyboard as I finished the story around dawn.\n\nThe piece was edited and published on washingtonpost.com later that morning,\nand for a brief time the story was featured “above the fold” as one of the\nmost popular on the site that day. That is, until a lawyer for\nwashingtonpost.com found it and went positively ballistic. Apparently, nobody\nhad asked the lawyers for their input, and now the attorneys were clamoring\nfor the story to be unpublished from the website until facts could be triple\nchecked and certain language about alleged illegal activities at McColo could\nbe toned down.\n\nEditors at the Washington Post and other major publications typically request\nthat a pending story be “lawyered” when it contains statements of fact or\nallegations that could lead to legal trouble down the road, particularly from\nthe parties named in the story who might wish to pursue libel charges. One\nwashingtonpost.com lawyer was extremely uncomfortable with any language that\neven hinted at illegal activity on the part of McColo’s owners, who had\nrepeatedly ignored requests for comment. (To give a sense of how shady the\ndealings at McColo were, the sole points of contact listed on its website were\nanonymous instant messenger accounts.) After all, there was no evidence that\nanyone associated with McColo had been charged with any crime, so why were we\nalleging it?\n\n(An important note: The story that ran that morning was full of links to\nsupporting evidence of illegal goings-on at McColo, as gathered by countless\nsecurity experts in the industry. Unfortunately, the washingtonpost.com lawyer\nwho objected to it being published initially viewed the piece on her mobile\nphone, which had stripped out all of the hyperlinks that readers could use to\nview voluminous third-party reports and evidence of said criminal activity. To\nthe attorney, the story appeared to be hurling all kinds of baseless and\npotentially libelous accusations at McColo, whose business at this point\nseemed all but ruined.)\n\nThe attorney demanded that the McColo story be pulled from the\nwashingtonpost.com website, and after a brief period of defiance, the website\nnews desk acquiesced without asking me whether the story was accurate or what\nsupporting evidence I had to back up my reporting. The piece was simply yanked\noff the site, with no explanation to the tens of thousands of readers who\nfound dead links and were eventually redirected back to my original blog post\nabout the takedown. My inbox quickly filled with emails from mystified readers\nwondering where the story had gone.\n\nFor nearly five excruciating hours, the follow-up to one of the most important\ncybercrime stories to date remained in editorial and legal limbo, as the\nlawyers hashed over the piece line by line, changing or deleting potentially\nobjectionable bits and pieces.\n\nThe piece was eventually republished later that evening, albeit in a shorter\nand much redacted form. But from that day forward, any story of mine that\ncontained even a whiff of information about alleged online criminal activity\nhad to be forwarded to at least one senior editor at washingtonpost.com and\noften run through a gamut of lawyers. Since I considered my beat to be\ncybercrime, this usually happened several times a week.\n\nAfter the McColo fiasco, investigative stories that took weeks and sometimes\nmonths to produce could sit just as long in the inboxes of higher-ups whose\napproval I had to get before the stories could be published. In some cases,\nsubsequent stories were placed on indefinite hold by washingtonpost.com\neditors, the lawyers, or both.\n\nOne of those pieces was an investigative story I’d spent six months reporting\nand writing, about a pattern of cybercrime activity that traced back to\nVrublevsky’s ChronoPay. At the time, the fastest growing and most lucrative\ncybercrime scheme worldwide was the spread of fake antivirus software. Also\nknown as “scareware,” fake AV uses misleading pop-up alerts and other ruses to\nfrighten unsuspecting Internet users into purchasing worthless security\nsoftware. Adding insult to injury, the bogus security programs often are\nbundled with malware that turns host machines into spam zombies.\n\nSecurity experts who had been closely tracking the scareware scourge told me\nthey’d found that ChronoPay was nearly always responsible for processing the\ncredit card payments for scareware scams, and that the company’s\nfounder—Russian Pavel Vrublevsky—appeared to be heavily and personally\ninvolved in engineering and profiting from these schemes.\n\nI knew very little about Vrublevsky until late 2008, when a Russian source\n(who will remain anonymous) urged me to look up ChronoPay’s incorporation\nrecords in the Netherlands, where ChronoPay was founded. Those records showed\nthat ChronoPay was created in 2003 as a fifty-fifty partnership between\nVrublevsky and Igor Gusev. The same sources that led me to the incorporation\ndata said that in 2005, the two men parted ways. Gusev would go off in 2006 to\nfound the GlavMed-SpamIt rogue online pharmacy partnership. Not to be outdone,\na year later Vrublevsky would cofound Rx-Promotion, a competing rogue Internet\npharmacy.\n\nI had no clue about Vrublevsky’s ties to Rx-Promotion at the time, or even who\nIgor Gusev was. What I did know was that ChronoPay had very recently been\nassociated with the Conficker worm, a computer contagion that remains one of\nthe most virulent and heavily scrutinized strains of malware ever unleashed.\nAn early version of the worm instructed millions of infected computers to\ndownload a rogue antivirus program from Trafficconverter.biz, an online\nbusiness that made tens of millions of dollars by paying scammers to foist\nfake antivirus software on PC users. And ChronoPay was the company responsible\nfor processing payments for TrafficConverter.\n\nIn March 2009, I turned in the first version of an exposé on ChronoPay’s\npivotal and lucrative role in the spread of fake antivirus software. The piece\nalso presented evidence indicating that Vrublevsky was the founder, owner, and\ncreator of Crutop.nu, the shadowy online forum that catered to the spammers\nand scammers who had attended McColo’s funeral.\n\nThe story cited published research from several esteemed security experts\nabout ChronoPay’s history. Nevertheless, it was held in editorial limbo for\nmonths, punted from one washingtonpost.com senior editor to another. The\neditors were convinced ChronoPay would sue the Washington Post, which was\nunderstandable. In our phone interview, Vrublevsky had promised his company\nwould do just that if we ran the story.\n\nThe same dithering delayed another big scoop related to the ChronoPay piece.\nWhen McColo went dark, much of the illegal activity that had made its home\nthere quickly shifted to another Northern California hosting provider, Triple\nFiber Networks, or 3FN as it was known in the underground. The same spam\nbotnet controllers that had called McColo their home for years had begun using\n3FN after McColo’s demise. A review of postings at the online forum Spamdot—a\nclosely guarded virtual den of thieves where most of the most successful\nRussian spammers gathered at the time—showed that 3FN’s owners actively picked\nup McColo’s stranded customers when the company’s operations were shuttered in\nNovember 2008.\n\nAt the time, 3FN also was the Internet’s largest host of sites that pushed\nfake antivirus software. The 3FN website was eerily similar to McColo’s.\nAgain, the only way to contact the company’s owners was through ICQ (“I seek\nyou”), an instant messaging protocol that for years was the de facto\ncommunications medium for many Russian hackers.\n\nI pressed for these stories to come to light. Having exposed the malicious\nactivity that eventually knocked RBN, Atrivo, and McColo offline, I believed\nthat the Post had an obligation to its readers—and to the wider world—to keep\nthe spotlight trained on those Internet providers that offered safe haven to a\nhuge swath of the cybercrime community. Bad press on these companies from\nmajor media would force more law-enforcement agencies into taking action\nagainst them and thus reducing the threat they posed both to Americans and\npeople all over the globe. But my editors were hardly anxious for a repeat of\nthe McColo story, even though it hadn’t resulted in any lawsuits or issues for\nthe Post.\n\nWhen I mentioned in an editorial meeting in early 2009 that 3FN had emerged as\nthe central focus of a U.S. law-enforcement investigation into cybercrime, it\nwas strongly suggested that we get confirmation of that fact from at least two\nsources, or wait for an on-the-record law-enforcement comment about the\ninvestigation or for proof of legal proceedings to be filed against the\nhosting provider before moving forward with any story alleging badness at 3FN.\nThe case documents had been sealed by a federal judge, and my law-enforcement\nsource was the only one I knew who had even heard of 3FN. The story was held.\n\nThen, on June 2, 2009, more than fifteen thousand websites hosted at 3FN were\nyanked offline after the U.S. Federal Trade Commission (FTC) convinced a\nNorthern California district court judge to have the company’s upstream\nInternet providers stop routing traffic for the provider. The FTC alleged that\n3FN operated “as a ‘rogue’ or ‘black hat’ Internet service provider that\nrecruited, knowingly hosted, and actively participated in the distribution of\nillegal, malicious, and harmful content,” including botnet control servers,\nchild pornography, and rogue antivirus products.\n\nThe FTC’s action provided the backstopping I needed to finally gather\nsufficient support to move ahead with my investigation into Vrublevsky,\nChronoPay, and their role in fostering the fake antivirus market that was\nplaguing millions of consumers and threatening their identities, finances, and\nsecurity. Crutop.nu also was hosted at 3FN and was even named in the FTC’s\naction. The FTC called Crutop a place “where criminals share techniques and\nstrategies with one another” and a Russian language website “that features a\nvariety of discussion forums that focus on making money from spam.” A review\nof multiple discussion threads at the Russian adult webmaster forum indicated\nthat Crutop’s more than eight thousand active members had been 3FN’s single\nlargest customer base.\n\nTellingly, directly after 3FN was taken down—but before washingtonpost.com ran\nthe story on ChronoPay’s ties to the rogue antivirus industry—Crutop.nu’s\nhomepage was changed to a lengthy screed about the FTC’s action against 3FN.\nThis would be my first introduction to Vrublevsky’s epic rants. The message\nread, in part:\n\nAnd in conclusion we would like to add, that while paragraph 1 of our rules\nhas never been taken seriously before and was written as a joke, but related\nto recent events we would like to know how it was possible that five (5!)\nreputable experts-agents (including NASA experts and Mr. Brian Krebs) from the\nUSA (where every tenth person speaks Russian, source: Wikipedia), could not\nfigure out that on Crutop.nu in the SPAM sub-forum, discussions have nothing\nto do with mail spam or other cybercrimes?\n\nThe story on Vrublevsky and ChronoPay’s key role in 3FN finally ran more than\nfour months after I turned it in. No lawsuit from him or ChronoPay followed.\nBut the editors at the Washington Post said they were still deeply concerned\nabout my focus on Internet bad guys. The Post higher-ups were nervous about my\nreporting on a crime-heavy subject in which the standard forms of documentary\nevidence don’t typically exist. Also, they took the position that my focus on\ncybercrime—as opposed to a broader beat such as consumer technology or\ntechnology policy—was too narrow, and that I was getting too close to my\nsources to remain objective.\n\nI shared their concerns—to a degree. No journalist wants to depend on a\nhandful of sources to the exclusion of others; doing so risks publishing\nstories that lack perspective and balance. But I knew the solution here was\nthat I merely needed more and better sources—particularly those actively\nengaged in the cybercrime community. I also was convinced that the 3FN story\nwas too important not to pursue, and that setting the story aside would be a\nwaste of a good opportunity to expose—and potentially stop—a great deal of\ncybercrime activity.\n\nAt a meeting in mid-2009, the washingtonpost.com editors explained that,\nalthough my Security Fix blog attracted a loyal and admirably large following\ngiven the niche subject, the angle of my reporting didn’t quite fit into the\nPost’s emerging strategy of being the go-to source for news “for and about\nWashington, DC.”\n\nThat turn of phrase encapsulated the new strategy that was the centerpiece of\na protracted and painful effort to merge the separate operations of the\nWashington Post newspaper with the newsroom of washingtonpost.com, mainly for\ncost reasons.\n\nThe Post leadership had concluded that one way to save money was to shift the\npaper and site’s news coverage so that it more closely focused on local events\nin the nation’s capital and on explaining to readers how the events in\nWashington, DC, affect the rest of the world. The company also opted to close\nsome of its major U.S. news bureaus and to rely more on wire services like the\nAssociated Press and Reuters for breaking stories.\n\nThe editors were hoping I could spend most of my time writing about technology\npolicy, specifically technology regulation and policy, or the future of\ntechnology innovation as it relates to policy. But I had no desire to shift\nthe focus of my reporting away from cybercrime. I’d covered the tech policy\nbeat for several years early in my career at the Post, and had found it\ntedious and stultifying.\n\nMoving back to tech policy would also mean abandoning my previous four years\ncultivating clueful and connected sources in both the security industry and\nthe cybercrime community. I was in the midst of a yearlong series about\nincreasingly costly and sophisticated cyberattacks being perpetrated every\nmonth against countless small to mid-sized organizations across the country.\nAfter all that careful research and investigation, I finally had a front-row\nseat that allowed me to peer into the day-to-day activities of large,\norganized cybercriminal gangs operating out of Eastern Europe.\n\nOver the course of several months, I was able to learn who these criminals\nwere, where they worked, what they did in their free time, and who they were\nattacking—often before the victims themselves knew they had been robbed of\nhundreds of thousands of dollars, sometimes millions. The bank accounts at\nmost small businesses and organizations are managed by regular men and women\nwho are no match for organized cybercrime gangs, and I desperately wanted to\ncontinue spreading the word about this increasingly common and costly form of\nonline robbery.\n\nMoreover, I was beginning to understand that ChronoPay and Vrublevsky were\nvery much the tip of the iceberg—that they were just the most visible figures\nin a largely Russian and Eastern European underground community whose members\nall seemed to know and rely upon one another.\n\nSo fourteen years after I joined the Washington Post, I was let go from the\ncompany with six months’ severance, just enough time to plot my next career\nmove. I remember feeling at the time that it was very important for me to hit\nthe ground running on a new job on January 1, 2010. What that new job was to\nbe, exactly, I wasn’t sure of, though.\n\nI discussed my termination with only a handful of family members and with two\ntrusted sources, but no one else. So I was baffled when, less than a month\nlater and well before my official termination date, I discovered a lengthy\ndiscussion thread on Crutop.nu titled “Krebs fired from the Washington Post,”\nin which members took turns celebrating and jeering at the news.\n\n“For those of you who don’t know—he is the author of Security Fix at WP, who\nloved to write about Atrivo, McColo, EstDomains, UkrTeleGroup, [and] 3FN, and\nhe is the one who helped shut them down,” wrote the Crutop member who posted\nthe thread. Other members greeted the news with cheers such as, “Thank you,\nSanta!” and “Santa got our letters!” Having something so personal and private\nexposed on a public forum run by some of the most active spammers that I’d\nbeen striving to expose was eerie and unnerving, but it also made me even more\ndetermined to continue my work.\n\nI had anonymously registered the domain name\n[KrebsOnSecurity.com](http://KrebsOnSecurity.com) just two weeks before that\nCrutop thread was posted, but hadn’t yet decided whether to pursue a\ntraditional position at another major news publication or to go it alone on a\nblog. After hearing from colleagues at other large media outlets who were\nbeing let go, forced to take unpaid leave, or reassigned to more advertising-\nfriendly beats, I was not anxious to jump back into a position at a major\nnewspaper or online publication. But the idea of going out on my own—and\nmaking a living at it—seemed daunting, even terrifying at times.\n\nAt the same time, a part of me was eager to succeed on my own terms and to\nbuild an audience based solely on my original reporting. When I read that\nCrutop thread, it struck me almost as a personal challenge and I decided to\ntake it on. In an encouraging development, I soon heard from Russian readers\nwho expressed disgust at that Crutop thread and were anxious to share\ndocuments that could prove the extent of ChronoPay’s involvement in the\ncybercriminal underground. I suspected, but couldn’t be sure at the time, that\nVrublevsky’s old business partner-turned-nemesis—Igor Gusev—was behind this\nruse, but for the moment I didn’t want to do anything to deter my sources from\nsharing what they knew.\n\n“Do not be mistaken,” one source pseudonymously named “Boris” warned in an\nemail that promised the delivery of massive amounts of incriminating evidence\nof wrongdoing at ChronoPay. “These guys, and probably Vrublevsky, will come at\nyou hard, and it may not be pretty.”\n\nBut Boris and others were true to their promises and their warnings. The\nanonymous threats started just days after a virtual treasure trove of\nincriminating ChronoPay emails and documents fell into my lap. Any last\nhesitation I’d had about striking out on my own disappeared. It was time to\nget to work.\n\n* * *\n\n[2.](02_chapter02.xhtml#fnr2)I was unable to track down Rubatsky, but\naccording to the Belarusian Telegraph Agency (the state-owned national news\nagency), Rubatsky is currently a fugitive who is wanted by Interpol, the\ninternational criminal police organization.\n\n[3.](02_chapter02.xhtml#fnr3)Loginov and several associates were later\nprosecuted and found guilty of kidnapping and other crimes. According to a\nreport in the Ecommerce Journal, Petrovsky is thought to be in hiding\nsomewhere in Ukraine.\n\n[4.](02_chapter02.xhtml#fnr4)In an email interview, Igor Gusev acknowledged\nthat someone using his unusual nickname “Desp” was listed as an administrator\non the homepage of Darkmasters.com, but denied that he himself was ever an\nadministrator of Darkmasters. Instead, Gusev said he had merely agreed to lend\nhis imprimatur on the site in exchange for money from the true\nadministrator—another adult webmaster who used the nickname “Master.”\nVrublevsky, on the other hand, insists this is “proof” that Gusev was closely\naligned with the Russian Business Network.\n\n[5.](02_chapter02.xhtml#fnr5)Now part of TeliaSonera, Telia was the dominant\nSwedish telecommunications company with operations throughout Europe and Asia.\nTiscali is an Italian telecommunications company that provides domestic\nservice but at one time offered services throughout Europe and Hong Kong.\n\n\nChapter 3\n\n## THE PHARMA WARS\n\nThe morning of May 14, 2010 began with a rambling, disturbing email message\nwaiting in my inbox. The anonymous writer had read my blog post about a public\nspeaking engagement on cybercrime that I’d just completed in upstate New York.\nThe message read:\n\nBrian,\n\nYou are a wonderful puzzle. Your wife apparently allows You to behave like a\nteenager. I would like to see You grow up.\n\nWe love You. But, Your wife is right. It’s time for You to put Your peculiar\ntalent in the hands of professionals. The last report about You driving around\nupstate New York prompts me to send You this final plea before…\n\nYour long suffering, but loving, wife should be empowered to make a contract\nwith a professional person, (who might be a female but Your docile wife will\neat her eyeballs on top of Your breakfast cereal before You come up from the\nbasement if she makes moves on You).\n\nSo, why am I writing? Well, it’s easy. I like what You do and many more would\nif they only knew about You. But, like many artists You think everyone sees\nwhat You see. We do not.\n\nTherefore, the next move is up to You. I would start with Your wife. I would\nask her what she thinks of this email.\n\nThen I would engage an attorney. You’ll need one when she falls “in love.”\n\nThe message was textbook Vrublevsky: Malevolent, rambling, graphic, and full\nof mangled metaphors. It was the kind of screed I frequently saw coming from\nVrublevsky’s alleged “RedEye” identity on Crutop.nu—the Russian adult\nwebmaster forum that he’d cofounded and that was an education center for\nspammers. As the U.S. Federal Trade Commission (FTC) described the forum in\nits takedown of hosting provider 3FN, Crutop “features a variety of discussion\nforums that focus on making money from spam.”\n\nVrublevsky had earned a name for himself early on in the business by creating\na network of adult websites that specialized in extreme and violent\npornography, mostly videos featuring rape, incest, and bestiality. His name\nand ChronoPay’s address are on the company registration records of “Red &\nPartners BV,” which was a company Vrublevsky formed and was the parent firm of\nhis adult webmaster affiliate program, according to legal documents obtained\nby this author from the government of the Netherlands. Also, as I noted in a\n2009 story in the Washington Post, the websites for both ChronoPay.com and Red\n& Partners (re-partners.biz) shared the same domain name servers and Google\nAnalytics code for tracking site visitors, though ChronoPay denied a\nconnection between the two. Many of the webmasters on Crutop were affiliates\nthat made money by reselling subscriptions to porn sites run by Vrublevsky and\nothers on the forum.\n\nBut aside from the strange and somewhat threatening language, the message held\nfew other clues to support my suspicion that Vrublevsky was the author. It was\njust a hunch, yet the timing was suspect.\n\nSix months earlier, I’d decided to go it alone and start my own\nsite—[KrebsOnSecurity.com](http://KrebsOnSecurity.com)—a daily news blog\ndedicated to investigative reporting on cybercrime to increase public\nawareness and action against it. The email arrived just two days after I’d\ntold Vrublevsky that I was preparing to publish a story based on cybercriminal\nallegations leveled against him by Ilya Ponomarev, a deputy of the Russian\nState Duma’s high-tech development subcommittee. Ponomarev had sent a letter\nto Russian investigators, echoing many of the allegations in my earlier\nreporting on ChronoPay and Vrublevsky for the Washington Post.\n\nPonomarev’s letter also included a new tidbit of information for me, which\noffered the first of many insights into the widespread corruption and\nbackwardness of Russian politics. Incredibly, Vrublevsky—who according to\nmultiple sources at this point ran one of the Internet’s most notorious\npharmaceutical spam programs, Rx-Promotion—had been selected as chairman of\nthe anti-spam working group of the Russian Ministry of Telecom and Mass\nCommunication, a body tapped by Russian President Dmitry Medvedev to advise\nthe government on new laws to curb junk email. Essentially, Ponomarev wanted\nVrublevsky gone.\n\nWhen I contacted him for comment on Ponomarev’s missive, Vrublevsky publicly\ndenied being associated with Rx-Promotion or spam and then accused me of\nhaving been bribed by his enemies into creating negative press about him. He\nonce again promised to sue me, and this time actually took steps to follow\nthrough on the threat. He had already begun the process by the time we spoke,\nbut as I’d find out, his attorney and executives at ChronoPay eventually\ntalked him out of it because he would have a slim chance of winning, the case\ncould drag on for years, and he and ChronoPay would be vulnerable to having\neven more of their business dragged into the light of day if the case ever\nwent to trial.\n\nHow did I find all of this out when Vrublevsky never said anything more than\nthreatening to sue me? At this point, dozens of leaked emails began showing up\nin my inbox; they were between Vrublevsky and a Russian-speaking lawyer he’d\nhired from the Washington, DC, law firm of Duane Morris LLP. The emails would\nlater show that to silence me, Vrublevsky had been fully prepared to pay more\nthan $100,000 to bring a defamation case against me for my stories about his\nrole in the rogue antivirus and pharmacy industries.\n\nThese internal emails were the first of many compromised materials (or\ncompromat, as they’re called in Russia) that I would receive over the course\nof a year from unnamed and anonymous hackers apparently bent on exposing\nChronoPay and Vrublevsky. When I first began to receive these\nmaterials—usually via a link to an archive at a free file-sharing site—I\nconsidered the possibility that someone had forged emails and documents to\nmake them appear stolen from ChronoPay. Eventually, however, the sheer volume,\ncomplexity, and interconnectedness of the records made it clear they were\nlegitimate.\n\nMonths later, Vrublevsky himself would admit this same thing to me in a phone\nconversation. Unknown hackers or ChronoPay insiders had leaked huge caches of\nhis firm’s internal correspondence—tens of thousands of emails and accounting\ndocuments—as well as hundreds of hours of phone conversations that Vrublevsky\nrecorded with others. The information painstakingly documented the breadth of\nChronoPay’s involvement in the rogue pharmacy and fake antivirus business\nendeavors. These required the creation of an elaborate network of shell\ncompanies and offshore bank accounts—all documented in well-organized\nMicrosoft Excel spreadsheets, and in some cases described in Vrublevsky’s own\nvoice.\n\nThis cache of purloined documents contained not only evidence of wrongdoing by\nChronoPay and its executives, but also intricate, sometimes lurid details\nabout some of the most powerful people in the cybercrime underground.\n\nIt took many months to read through all of the materials, but more importantly\nto discover the most significant emails and documents. Part of the difficulty\nwas that the ChronoPay employee email inboxes I’d been given offline access to\nwere, ironically enough, laden with spam messages themselves, causing plenty\nof false positives when I searched them for specific terms that might expose\nChronoPay’s involvement in establishing shell companies and affiliate\nprograms, and running spam operations. Also, almost all of the missives were\nwritten in Russian, and specific phrases or proper nouns often had multiple\npermutations of their Cyrillic and transliterated Russian equivalents, or\nshorthands that required individual searches for each, or both.\n\nThankfully, I’d begun learning the language four years earlier on my own. In\nmy work for the Washington Post, I had found myself spending an unusual amount\nof time on Russian-language underground forums that were not only hostile to\nWesterners, but which often chastised or banned members for the unforgivable\nsin of communicating in English. To overcome this obstacle, I checked out\nsixty hours’ worth of Russian language instruction on CD from my local\nlibrary. By 2008, I had finally mastered enough Russian to be able to read\nmost forums without the aid of an online translation service. For an\ninvestigative reporter like me, this was vital to ensure I didn’t misinterpret\nany of the information I was picking up there. Plus it made my research go a\nwhole lot faster.\n\nAs I trolled through the documents, I discovered hundreds of emails between\nVrublevsky and Stanislav Maltsev, a former investigator with the Russian\nMinistry of Internal Affairs. In 2007, Maltsev was responsible for\ninvestigating charges of illegal business activities levied against\nVrublevsky. But in short order, Vrublevsky had hired Maltsev as his head of\nsecurity, and the case against Vrublevsky quickly died on the\nvine.[6](03_chapter03.xhtml#fn6)\n\nIt also became clear that ChronoPay executives had tried in vain to isolate\nthe company’s “black” projects—the Rx-Promotion pharmacy spam program and its\nfake antivirus business, for example—from the company’s more legitimate client\nbase. The leaked ChronoPay emails show that in August 2010 cofounder Pavel\nVrublevsky authorized a payment of 37,350 Russian rubles (about $1,200) for a\nmultiuser license for an online project-development tracking and management\nservice called MegaPlan.\n\nChronoPay employees used their MegaPlan accounts to track payment processing\nissues, customer order volumes, and advertising partnerships for these black\nprograms. In a move straight out of the Quentin Tarantino film Reservoir Dogs,\nthe employees adopted curious aliases such as “Mr. Kink,” “Mr. Stranger,” “Mr.\nTemplar,” and “Ms. Gandalfine.”\n\nHowever, in a classic failure of operational security, many of these employees\nhad their MegaPlan messages and passwords automatically forwarded to their\nChronoPay employee email accounts, which ended up in the corpus of emails that\nwere leaked. An organizational chart featured on the ChronoPay MegaPlan\nhomepage showed that the former cop Maltsev (a.k.a. “Mr. Heppner”) had been\nappointed the deputy manager of Rx-Promotion, directly under the “big boss,”\nVrublevsky (a.k.a. RedEye).\n\nFinally, I had the key that I’d been looking for. The MegaPlan accounts\nprovided the single largest cache of information on the extent of ChronoPay’s\ninvolvement in fostering the development of markets for rogue antivirus\nsoftware, or “scareware.” These are malicious programs that use misleading\nsecurity prompts about nonexistent security threats on a victim’s PC, and then\nhijack the computer until the victim either figures out a way to remove the\nmalware or pays for a license to the bogus software.\n\nThese types of programs affect tens of millions of people around the world and\nare shockingly lucrative. Most PC users would be hard pressed to say they’ve\nnever encountered one of these messages, and it’s just the most visible sign\nthat your computer has been hijacked by a remote spammer or other stealthier\nmalware. (Whatever you do, don’t ever click these messages! Try to get the\nmalware removed immediately by an antivirus professional, or see the Epilogue\nfor tips on how to avoid making a bad situation like this worse.)\n\nThe leaked records show ChronoPay’s high-risk or “black projects” division\nworked diligently to stay on the cutting edge of the scareware industry. In\nMarch 2010, the company began processing payments for icpp-online.com, an\ninnovative scam site that stole victims’ money by bullying them into paying a\n“pretrial settlement” to cover a “copyright-holder fine.”\n\nAs security firm F-Secure noted at the time, victims of this scam were\ninformed that an “Antipiracy Foundation scanner” had found pirated movie and\nmusic files on the victim’s system, and that those who refused to pay $400 via\na credit card transaction could face jail time and huge fines. The scheme was\nbrilliant in its simplicity. Many people have, at some point, watched or\nlistened to pirated content, so there was no reason for them to distrust this\nmessage. As a result, thousands were swindled.\n\nHere’s the kicker: for many years, scareware was a problem only for PC users\nwho browsed the web with computers powered by Microsoft’s Windows operating\nsystem. But in May 2011, scareware purveyors began targeting users of Apple’s\nMac OS X operating system for the first time. No one was safe from spam and\nmalware attacks anymore.\n\nThe leaked ChronoPay internal documents would reveal the company’s hand in\nthis innovation as well. A few days after the first attacks surfaced,\nexperienced Mac users on Apple support forums began reporting that new strains\nof the Mac malware were directing users to pay for the software via a domain\ncalled mac-defence.com. Others spotted fake Mac security software coming from\nmacbookprotection.com. When I first looked at the registration records for\nthose domains, I was not surprised to find the distinct fingerprint of\nChronoPay.\n\nThe website registration records for both domains include the contact address\nof fc@mail-eye.com. The leaked ChronoPay documents show that ChronoPay owned\nthe mail-eye.com domain and had paid for the virtual servers in Germany that\nran it. The records also indicate that the fc@mail-eye.com address belonged to\nChronoPay’s financial controller, then an employee named Alexandra Volkova.\nOne of the smoking guns had been found, and it was time to let the public\nknow.\n\n♦ ♦ ♦\n\nAfter the Ponomarev story ran, I began hearing from Vrublevsky by phone at\nleast once a day, often for no apparent reason. The calls came from a\ndifferent mobile number almost every time. (When asked why his calls always\nappeared to come from a different Russian phone number, Vrublevsky\nnonchalantly replied that he currently had no fewer than nine mobile phones,\nand that this was a common tactic used by successful Russian businesses who\nwished to evade surveillance by meddlesome Russian government agents.)\n\nAt first, I thought he was being dramatic or overly paranoid; I would find out\nlater he was very much the target of Russian government surveillance. “Gusev\nput in his blog the name of an FSB guy working on the Vrublevsky case,” the\nChronoPay CEO told me in one phone conversation, referring to himself in the\nthird person. “They’ve been tapping my phone and know that I have ongoing\ncommunications with you.”\n\nI quickly discovered that this was a man who enjoyed the sound of his voice\nlike no one else I’d ever encountered. Despite everything I knew about the\nguy—and the fact that he was often extraordinarily crass and derisive, and\nfrequently outright insulting—I also found him to be disarmingly charming,\nfunny, and likeable. He was just as likely to make fun of himself as he was of\nothers, and he possessed a seemingly boundless supply of anecdotes about\nimportant Russian power brokers, politicians, and cybercrooks. Without\nprompting, Vrublevsky would excitedly segue from one colorful story to the\nother as if describing an elaborate soap opera, albeit one that never seemed\nto have a central plot or conclusion.\n\nMoscow is eight hours ahead of the time zone in Washington, DC (Eastern), and\nthat meant Vrublevsky would usually call me as his chauffeur was shuttling him\nfrom ChronoPay’s offices to his home. In short, Pavel was frequently ready to\nunwind and be chatty right when I was getting ready to buckle down and start\nmy workday. Most conversations ended with me hanging up on him after he\nrefused to take a hint that I had more to do than to listen to him blather for\nhours on end.\n\nInitially, I thought that the purpose of his phone conversations was to get me\nto publish something exonerating him of his wrongdoing, more and more of which\nI was discovering every day. In each of our conversations, Vrublevsky took\ngreat care to cast himself as an anti-cybercrime crusader determined to\ndestroy the spam industry and ensure the arrest and conviction of all\nspammers.\n\nVrublevsky constantly intimated that I hadn’t a clue about cybercrime, and\nthere was no way to fully understand the nuances of the subject without making\nat least a token visit to Russia. In one conversation, he offered to fly me to\nMoscow so I could see firsthand that he was in fact one of the good guys.\n\n“My proposition to you is to come to Moscow, and if you don’t have money… I\nrealize journalists are not such wealthy people in America… We’re happy to pay\nfor it,” Vrublevsky said in a phone conversation on May 8, 2010.\n\nWhen I politely declined his invitation, Vrublevsky laughed and said I was\nwrong to feel like I was being bribed or intimidated (which I did).\n\n“It’s quite funny that you think somehow when you fly to meet me in Moscow or\nChronoPay offices that you are in any possible danger from me for being\nmurdered,” Vrublevsky said, pinpointing exactly what I was thinking. “Come to\nMoscow and see for yourself. Take your notebook, come to my office. Sit in\nfront of me and look around. Because you’re getting information which, to be\nhonest, is not factual.” (I would eventually do exactly as Vrublevsky urged,\nas we will see in Chapter 9, “[Meeting in Moscow](09_chapter09.xhtml).”)\n\nAfter about a month of daily calls from Vrublevsky—sometimes twice a day—I\nrealized that he was feeding me semi-reliable information about other\ncybercrooks in the hope that I would be diverted into researching and writing\nabout them, instead of him.\n\nThe real trouble with these chat sessions—aside from their tendency to eat up\nhalf of my workday—was untangling the bits of truth and fact from Pavel’s\nmusings, paranoid conspiracy theories, and attempts to draw attention away\nfrom his own dealings. When I asked him point blank about my theory—that he\nwas trying to turn the spotlight away from himself by regaling me with\nelaborate tales about rival businessmen in the Russian underground—Pavel\nmomentarily dropped the phone as he burst out laughing for about a minute\nstraight.\n\n“You know, Brian, you surprise me sometimes. You really do. This is why I\nabsolutely fucking love you,” he said after picking up his mobile phone, still\nsnorting and having fun at my expense. “Why do I say this? It’s funny,\nsometimes I’m not really sure you are too bright. And then you go and say\nsomething like that. Dammit, Krebs, sometimes you’re a lot fucking smarter\nthan you sound.”\n\nBut Vrublevsky also could be mercurial, prone to wild mood swings and bouts of\nmumbling or shouting profanities. Or sometimes the voice on the other end of\nthe line sounded like a completely different person, the tone low and\ncomparatively serene. Often, this was late at night when his three children\nand wife, Vera, were already in bed and he’d perhaps had a few drinks or\nsomething else to take the edge off.\n\nIn one marathon phone conversation shortly after I’d informed Vrublevsky about\nreceiving the compromat, he was in one of his sullen moods and rather bluntly\noffered to pay me $30,000 to turn over all of the material that I’d been\ngiven. I’d told him about the leaked documents because I believed he already\nhad a good idea of what information had been taken. Clearly, he was more\ninterested in securing my future silence than in regaining control over the\ncompromat. I politely declined the monetary offer and told him I was flattered\nbut still planning to continue my investigations.\n\nI soon realized that Vrublevsky had another, far bigger target in mind on this\ncrusade to recapture ChronoPay’s positive image: Igor Gusev, his former\nbusiness partner in ChronoPay and now head of a pharmacy affiliate program\nthat competed directly with Vrublevsky’s Rx-Promotion. Vrublevsky was\nconvinced (and, I think, accurately) that Gusev or one of Gusev’s henchmen was\nresponsible for leaking ChronoPay’s internal emails and other incriminating\ndocuments.\n\nAround the same time that the first batch of ChronoPay compromat was leaked,\nAdam Drake—a source in the anti-spam community in whom I’d confided some of my\nstories about Vrublevsky’s strange phone calls—emailed to tell me about a\nbizarre message he’d just received. Drake’s mysterious correspondent, who used\nthe pseudonym “Despduck,” said he had access to the database for GlavMed and\nSpamIt, sister programs that were responsible for a huge percentage of the\nworld’s spam problem. The “Desp” portion of the nickname was a play on the\nmoniker chosen by Igor “Desp” Gusev, the man who cofounded ChronoPay with\nVrublevsky in 2003 and went off on his own two years later to start SpamIt and\nGlavMed.\n\nDrake wrote:\n\nBrian,\n\nRecently you posted about a Russian government investigation into the SpamIt\noperation (“Following the Money, Part\nII”—[krebsonsecurity.com/2010/05/following-the-money-part-\nii/](http://krebsonsecurity.com/2010/05/following-the-money-part-ii/)).\n\nI have a guy from Russia contacting me claiming to be a friend of a former\nmember of the SpamIt-GlavMed affiliate group. He has a lot of information I\nwant to share with you confidentially. I say this because I wanted your\nthoughts on it, and he makes claims about how some info for that story was\nhanded to you, which I wanted your thoughts on.\n\nHe also claims to have quite a bit of raw data related to some of their\ngathering places which—if it seems legit—I will hand over to law enforcement.\nI’ve been working with a task force which includes members of Interpol and the\nFBI since last year investigating that group, so I haven’t been able to post\nmuch publicly at all.\n\nIf any of this is not up your alley or within your range of interests, let me\nknow, but I thought it might be. This same group is likely also behind the\nrash of rogue “antivirus” crap that’s been making the rounds.\n\nHope you are otherwise well.\n\nI immediately recognized Vrublevsky’s hand in this ruse and asked Drake to\nforward a copy of the Despduck email. I could scarcely believe my eyes as I\nread the message, which looked as if someone had been taking dictation from\nVrublevsky while he was regaling whoever would listen with one of his\nexcitedly told, rambling stories. The letter went on for more than two\nthousand words and was full of elaborate theories of who was behind the\nattacks on ChronoPay, a company about which Despduck spoke positively\nglowingly.\n\nI told Drake about my hunch that he also was being hounded by Vrublevsky, and\nhe confided that a law-enforcement friend who was quite familiar with\nVrublevsky and had also seen the Despduck emails had independently come to the\nsame conclusion.\n\nThere was something else about Despduck’s letters that I couldn’t quite put my\nfinger on. A week later, I went back and looked at my previous email\ncorrespondence with Vrublevsky, and compared it to the emails from “Despduck”\nthat my anti-spam source was receiving. One commonality immediately jumped off\nof the screen in front of me. Both Despduck and Vrublevsky capitalized the\nletter y anytime they used the word “You” or “Your,” regardless of the word’s\nposition in a sentence or how many times it was used. That capitalization\npattern did not occur with any other words in the emails that shouldn’t have\nbeen capitalized.\n\nThen it occurred to me: What about that threatening “eyeballs” email I’d\nreceived just after calling Vrublevsky for a quote on the story about\nPonomarev’s allegations? Sure enough, I saw the same capitalization pattern\nthere. The pieces were starting to come together.\n\nBut why would Vrublevsky go to such pains to launch this multipronged campaign\nto simultaneously win me over and coerce me into cooperating with him? My\nanti-spam source provided the answer, sharing several emails sent by Despduck.\nThey showed that Vrublevsky believed I had accepted money from his pharma-spam\nrival Gusev in exchange for writing stories about Vrublevsky’s exploits.\nVrublevsky also seemed convinced that I was in league with shadowy figures\nbehind the Russian Business Network (RBN), the bulletproof hosting empire\ndetailed in the first half of [Chapter\n2](02_chapter02.xhtml).[7](03_chapter03.xhtml#fn7)\n\nDespduck wrote (again, with the Y capitalization in “You”):\n\n1.Brian Krebs, believe it or not, was actually paid by RBN guys (by GlavMed\nmostly) to publish his research. All of his info is actually based on the fact\nthat re-partners.biz had an office address of ChronoPay, which is bullshit, of\ncourse. Anyone can put any address anywhere.\n\n2.Then Ilya Ponomarev (NOT a leading politician in Russia) wrote a letter to\nthe cops in Russia trying to somehow fuck Vrublevsky based on Krebs info. A\nstupid attempt, probably just making it look like it can work to get more\nmoney from Desp. Obviously nothing happened because ChronoPay has an extremely\nstrong image and brand in Russia. ChronoPay will soon sue Krebs, and Ponomarev\nhas already changed his opinion and sent another letter to the cops explaining\nhe was not targeting Vrublevsky.\n\n3.All this happened because Vrublevsky has a position with the Russian\nGovernment in fighting spam, and what’s more important, in protecting Russian\nimage abroad. Spammers hate him for that. I’ll explain more when You have\nquestions.\n\nOnce again, Despduck spoke glowingly of Vrublevsky as a cybercrime fighter who\nwas being unjustly accused by the media and by his business rivals of\norchestrating the nefarious activity he claimed to be battling. I was now more\ncertain than ever that Despduck was Vrublevsky.\n\nOn July 12, 2010, an anonymous source with whom I’d be corresponding via email\nsent me another massive trove of compromat stolen from ChronoPay. My source,\nwho used only the name “Boris” in our email exchanges, said he was sharing the\ndata out of frustration with Russian authorities, who he said seemed to regard\nVrublevsky as hardly worth the trouble of shaking down for bribes, to say\nnothing of investigating.\n\nBrian,\n\nThis file contains full information about criminal activity of ChronoPay and\npersonally Pavel Vrublevsky on legalizing out-of-law money [sic]. We’ve tried\nall methods accessible in Russia, but the absolute corruption of the Russian\npolice brakes [sic] the criminal case and marks time. We hope you can\neffectively use this information in the struggle for the cleanliness of the\nInternet. The same file was transferred two weeks ago to the FBI.\n\nGood luck,\n\nBoris\n\nThe ChronoPay emails leaked by Boris—the “treasure trove of documents”\nreferenced at the conclusion of [Chapter 2](02_chapter02.xhtml)—show that\nVrublevsky hired a hacker named Nooder Tovreance to break into Gusev’s SpamIt\nand steal the organization’s payment and customer records. In one email\nexchange between the two, which begins April 8, 2010, and ends at the\nbeginning of June, Tovreance offered to sell the database to Vrublevsky for\n$20,000, but said that he needed to break the file transfers up into multiple\nsmaller chunks due to the size of the database.\n\nThe two ultimately settled on a price of $15,000, to be paid in WebMoney, a\nvirtual currency that is popular in Russia and Eastern Europe. The first\npayment of $7,500 was to be made to a WebMoney purse specified by Tovreance in\nexchange for half of the files, with the remaining amount payable upon\nVrublevsky’s receipt of the entire database. Follow-up emails indicate that\nVrublevsky paid the first $7,500, but welched on the second payment after\nreceiving the database as promised. When I interviewed Tovreance, he confirmed\nthat Vrublevsky had hired him to produce the GlavMed and SpamIt data, and that\nindeed Vrublevsky had stiffed him on half of the promised price.\n\n♦ ♦ ♦\n\nRoughly one week after miscreants leaked that ChronoPay compromat, Drake\ncalled with the news that Despduck had sent him a copy of the SpamIt and\nGlavMed database. By this time, I began to believe that just as Vrublevsky hid\nbehind his “Despduck” identity in leaking the GlavMed-SpamIt customer\ndatabase, Gusev was using the “Boris” identity to feed me the information\nstolen from ChronoPay.\n\nThe GlavMed-SpamIt database landed in my lap the day after I published on my\nblog the first breaking story about a new, exceedingly complex computer worm\nthat appeared to have been weaponized for espionage. That blog post was the\nfirst widely read story about a piece of malware of unprecedented\nsophistication that would become known as “Stuxnet”—a computer worm that\nexperts later discovered was a cyberweapon created by Israeli and U.S.\nintelligence agencies in a successful bid to delay Iran’s nuclear ambitions.\n\nBut I filed the Stuxnet post just as I was leaving for a week-long vacation\nwith my wife and mother in York, Maine, and I’d promised to give work a rest.\nWhile follow-up reporting on Stuxnet would take dozens of telephone\ninterviews, delving into the scoop that my anti-spam source was handing me\ncould be done without letting my family know I was back on the clock.\n\nDrake set up an account for me on his web server and placed a copy of the\nSpamIt archive there. The file contained almost ten gigabytes worth of data.\n(To put that into perspective, if the SpamIt database was compiled into\npaperback books three inches wide, it would take a bookshelf roughly the\nlength of a football field to hold them all.)\n\nI was already overwhelmed with gigabytes of fascinating internal material from\nChronoPay, and had to delete data from my Macbook’s hard drive to accommodate\nthe SpamIt archive. As I sat on the back deck of a coastal Maine vacation\nproperty with my laptop propped up on my knees, while listening to the roar of\nthe ocean surf, I began to see the enormity of the task before me. I would\nneed to make sense of raw intelligence from two of the largest sponsors of\nspam on the planet, in the process potentially incurring the wrath of the most\npowerful and vengeful cybercriminals on earth.\n\n* * *\n\n[6.](03_chapter03.xhtml#fnr6)Vrublevsky claimed the charges were trumped up\nand nothing more than a legal shakedown orchestrated by his enemies, but the\ncompany that was being “shaken down” operated a virtual currency he created to\nhelp his webmasters and spammers get paid without leaving an official money\ntrail through the Russian banking networks.\n\n[7.](03_chapter03.xhtml#fnr7)While Vrublevsky acted as if he had nothing to do\nwith RBN, the pharmacy spam websites and fake antivirus affiliate programs he\nran took full advantage of hosting arrangements managed under the RBN banner.\n\n\nChapter 4\n\n## MEET THE BUYERS\n\nThough my ultimate goal was to unmask the botmasters who were getting paid to\nsend most of the world’s junk email, I knew it would take months, possibly\nyears, of poring over the data coming in from the two competing rogue pharmacy\nprograms. What I had discovered so far were small pieces of criminal activity\nhere and there, so a lot more in-depth research and investigation would be\nrequired to build a watertight case against these guys and expose their\nmalicious activities. I decided to focus my immediate efforts on reaching the\npeople directly affected by these cybercriminals: customers who purchased and\ningested pills from spam ads.\n\nAlmost all of us have gotten pill spam or pharma spam at some point in our\nlives—those emails that show up in our inboxes, spam filters, and junk\nfolders, offering cheap prescription or enhancement drugs. It may be less than\nshocking that about 70 percent of the transactions made through rogue pharmacy\nwebsites advertised by Gusev’s SpamIt and Vrublevsky’s Rx-Promotion were for\nmale-enhancement drugs like Viagra and Cialis. Even GlavMed customers who did\nnot order drugs to treat erectile dysfunction (ED) usually received penis\npills anyway. So confident were these pharmacies in the power of their ED\nformularies that they routinely included two to four free samples of these\npills with every customer order.[8](04_chapter04.xhtml#fn8)\n\nFor those of us who would never dream of ordering from an unknown pharmacy,\nthis might seem like an obvious and unnecessary gamble. Why not just use an\nordinary pharmacy? Indeed, I was intensely curious to learn what motivated\npeople to engage in this apparently risky activity, and whether they were\nhappy with their purchases—or if they felt they’d gotten ripped off. I thought\nthat if I interviewed enough of these buyers and found that overall they did\nnot get what they expected, exposing this reaction could help reduce demand\nand eventually drive the spammers out of business.\n\nThanks to data leaks from both Rx-Promotion and GlavMed-SpamIt, I had the\nnames, phone numbers, addresses, and credit card numbers of more than a\nmillion people who had bought spamadvertised drugs. Some of those orders were\nfairly recent, so I was eager to interview buyers who might still have some of\nthe pills and could forward them to me for testing at a qualified lab to see\nwhat these consumers were really getting.\n\nI purposefully avoided calling customers who sought out and paid for knockoff\nViagra and Cialis, partly because I thought that those who had come to these\nfly-by-night pharmacies to purchase drugs for more serious ailments and\nconditions would have more interesting and sympathetic stories to tell that\nwould help me get to the heart of this issue: who was purchasing these drugs\nand why? But I’d be dishonest if I said my reporting wasn’t also influenced by\nan experience I had with an interviewee very early in the process of\ncontacting buyers.\n\nJust a few days after I began phoning people who had purchased medications\nfrom GlavMed, I dialed the phone number supplied by a male customer who’d\nordered Viagra. His wife answered instead. She broke down in tears when I\nexplained that her husband had purchased generic Cialis a few months prior.\nShe was not aware of this fact and said she couldn’t think of a reason on\nearth why he would have wanted it. After that mercifully short interview, I\ndecided to avoid calling any other customer who had purchased only erectile\ndysfunction drugs.\n\nOver two months, I called more than four hundred people who had purchased\npills from SpamIt. Most of those I reached either hung up on me or declined to\nbe interviewed. But I managed to interview at least forty-five buyers who\nordered everything from heart medication to antidepressants and pills to treat\nthyroid conditions. I began to get a clearer picture of who these people were,\nwhat their motivations were, and how their actions affect us all, even those\nof us who don’t open spam emails, let alone buy anything from them.\n\nMany people—particularly anti-spam activists—take an understandably dim view\nof consumers who buy items advertised in junk email. After all, the argument\ngoes, if people stopped buying from sites advertised via the spam that floods\nour inboxes every day, then the spam industry and many of its corresponding\nthreats to our identities and security would probably be greatly diminished.\nBut contrary to popular belief, most of the people buying from spam aren’t\nidiots or crazy. The majority appear to be technologically unsophisticated\npeople making rational (if potentially risky) choices based on one or a\ncombination of several primary motivations:\n\n•Price and Affordability: Those who bought drugs other than male enhancement\npills almost universally said they responded to prescription drug spam either\nbecause they had no health insurance, or because the same drugs available\nunder their health plans cost two to five times as much as the drugs offered\nvia these legitimate-looking Canadian pharmacy sites. (In reality, the\nspammers were just borrowing the good reputation of legitimate Canadian\npharmacies. As we’ll see in [Chapter 5](05_chapter05.xhtml), the drugs that\neach affiliate program shipped were manufactured mainly in India and China,\nand the websites selling the drugs were most often hosted on botted PCs that\nhad been hacked by the spammers for use in sending junk email.)\n\n•Confidentiality: The buyer wants to purchase specific drugs discreetly and\nquietly, either out of embarrassment or shyness, or because he or she feels\ncompelled to hide something from a spouse or loved one. Most of the customers\nI interviewed broke down into two camps here—those who were self-treating\nvenereal diseases, and those who were ordering impotence drugs to perform for\na lover or spouse. Sadly, the order history suggests that some of these buyers\nrepeatedly fit into both categories.\n\n•Convenience: Ordering drugs online without a prescription and having them\nshipped to your door is extremely convenient. In addition, a great many buyers\nI spoke with said they were merely purchasing drugs they had been previously\nprescribed for a similar or related ailment. In effect, these people were\nself-prescribing and didn’t see the need to pay for a doctor visit or to\nsubmit to the higher prices charged by their local pharmacies.\n\n•Recreation or Dependence: Buyers in this category purchased mainly drugs\nwhose use and sale have been restricted in the United States, usually because\nthe drugs have the potential for abuse. These were primarily painkillers such\nas generic oxycodone, hydrocodone, and tramadol; weight-loss drugs like\nphentermine (a powerful stimulant); and sleeping pills like Soma and Lunesta.\nPerhaps because of the addictiveness of some of these drugs, this class of\nbuyers tended to be the most loyal, profitable repeat customers.\n\n## Price\n\nSpamIt customers were motivated to purchase drugs from spam for a variety of\nreasons, but the number one reason I heard was affordability—particularly\namong customers who were purchasing medications taken to treat chronic\nconditions.\n\nIt is no accident that most SpamIt customers live in the United States, the\ncountry with the highest prescription drug prices in the world. Prices for\npharmaceuticals in the United States are substantially higher than those in\nCanada, India, the United Kingdom, and many other countries, in large part\nbecause those nations have enacted price controls on drugs. In 2012, the price\nof generic medications in the United States rose an average of 5.3 percent,\nwhile the cost of brand-name drugs increased by more than 25 percent,\naccording to a study by the Health Care Cost Institute.\n\nOther factors that have increased the cost of prescription drugs include: a\nspike in demand for these drugs over the last decade; intense marketing to\nconsumers and doctors of higher-priced brand-name drugs; drug manufacturers’\nattempts to recoup the substantial costs of research and development; and the\ncostly dice game that is the process of bringing a new drug to market in the\nUnited States. (According to a 2012 Forbes article, the cost for a\npharmaceutical company to get a new drug to market is now around $350\nmillion.)\n\nBut there’s more to it. In a landmark 2011 study on the economics of the rogue\nInternet pharmacy business, researchers at the University of California, San\nDiego (UCSD) figured out a way to view countless purchase records from online\npill shops tied to EvaPharmacy, another rogue pharmacy affiliate program that\ncompetes directly with the likes of Rx-Promotion and SpamIt. The researchers\nfound significant differences between the drug-selection habits of Americans\nand customers from Canada and Western Europe. The analysis divided the\nEvaPharmacy pills into two broad categories: lifestyle drugs—such as erectile\ndysfunction and human growth hormone pills—and non-lifestyle drugs, including\nthose used to treat disorders including anxiety, sinus infections, high blood\npressure, hair loss, cancer, and infertility.\n\nThe researchers discovered that U.S. customers selected non-lifestyle items 33\npercent of the time. In contrast, Canadian and Western European customers\nalmost always bought drugs in the lifestyle category—only 8 percent of the\nitems placed in their shopping carts were non-lifestyle items. In other words,\nmany more Americans were turning to these spam pharmacies for prescription\ndrugs to treat critical medical conditions, not to increase their comfort or\nenjoyment of life.\n\n“We surmise that this discrepancy may arise due to differences in health-care\nregimes; drugs easily justified to a physician may be fully covered under\nstate health plans in Canada and Western Europe, leaving an external market\nonly for lifestyle products,” the researchers wrote. “Conversely, a subset of\nuninsured or underinsured customers in the United States may view spam-\nadvertised, no-prescription-required pharmacies as a competitive market for\nmeeting their medical needs.”\n\nInterestingly, dozens of SpamIt customers I interviewed said the pills they\nreceived were indistinguishable from the same drugs they had purchased from\nlocal pharmacies, except that the pills they ordered online cost far less. In\nfact, many customers were so satisfied with their orders that they went back\nto the same site month after month.\n\nHenry Webb, a forty-two-year-old real estate agent from California, had been\nbuying from online pharmacies for nearly three years when I first called him,\nthough he said he had no idea who he was really buying from until I contacted\nhim. Webb battled depression for much of his adult life, until about ten years\nago when his doctor prescribed him Lexapro, a prescription antidepressant. For\nyears, Webb paid close to $500 for a ninety-day supply of the drug.\n\nAnd then one day he opened an unsolicited email that advertised Lexapro for\nalmost one-quarter of that price. He’s been ordering from a couple of\ndifferent “Canadian pharmacy” sites ever since, and said he has yet to have a\nnegative experience.\n\n“The pills look exactly like the kind I paid five hundred dollars for at the\ndrugstore—they’re in the same blister pack and everything,” Webb said. “The\nonly comment I have is that it’s sad we live in this country and have to look\noutside of the United States for affordable medicine.”\n\nContacted a few months after that initial interview, Webb said he quit\nordering online after he had bad experiences with some drugs that made him\nsick. Webb also experienced something that nearly all who purchase products\nadvertised in spam will deal with at some point: incessant phone calls from\naggressive online pharmacy merchants trying to refill his prescription or sell\nhim other drugs.\n\n“They won’t leave me alone and have been calling several times a day,” Webb\nsaid. “I can’t change my number because it’s attached to my business, but\nthese guys do very devious stuff like spoof the caller ID so it looks like\nthey’re calling from my local area. So I pick up, because I have to be\nreachable for my real estate clients.”\n\nExacerbating the pricing problem for consumers is the little-known but\nwidespread practice among the major pharmaceutical manufacturers of paying\ngeneric rivals to delay the introduction of lower-cost medicines. According to\nthe U.S. Federal Trade Commission (FTC), pharmaceutical companies struck an\nunprecedented number of these collusive deals in fiscal year 2010. The FTC\nfound that the number of these deals skyrocketed more than 60 percent, from 19\nin FY 2009 to 31 percent in FY 2010. Overall, the agreements reached in FY\n2010 involved twenty-two different brand-name pharmaceutical products with\ncombined annual U.S. sales of about $9.3 billion.\n\nCraig S., a now-retired life insurance salesman from North Carolina, knows\nfirsthand how it feels when a drugmaker or health insurer suddenly stops\noffering generics. Craig said his employer of twenty years previously offered\na health-care plan with generous drug coverage benefits. Then a year prior to\nour interview, his employer dropped the insurance provider and pushed all\nemployees into health-care savings accounts (HSAs), which his employer\ncontributed a mere thousand dollars annually. Craig’s doctor had long\nprescribed the name-brand drug Actos to help treat his type 2 diabetes, and\nCraig had been buying the generic version.\n\nBut he soon discovered that the generic version of Actos was not offered\nthrough the HSA program. Strangely enough, however, he was able to use his HSA\ncredit card to buy a ninety-day supply from the GlavMed pill shop for $178\nincluding shipping and handling.\n\n“The drug my doctor wants me to take is $212 per month, and I told him that’s\njust not going to happen,” Craig said. “It costs me now about a third of what\nit would if I bought the brand-name version each month through my health\nplan.”\n\nWhen asked whether he’s concerned about the quality, efficacy, and safety of\nthe drugs he’s purchasing from spammers, Craig said, “Not really.” He said he\nstill sees his doctor every ninety days, and that the drugs he’s been ordering\nfrom GlavMed appear to be keeping his diabetes in check.\n\nHis chief concern is that the pills he’s ordered may one day simply not arrive\nin the mail, noting that he had a close call once with an order that arrived a\nweek later than it should have. But for now, the people supplying his drugs\nover the Internet appear to be getting their act together on the shipping.\nCraig said that every few months, when his prescription is about three weeks\naway from running out, he’ll start getting phone calls from people with Indian\naccents, asking if he’s ready for refills.\n\n♦ ♦ ♦\n\nIllinois resident “Steve” suspected his girlfriend had been cheating on him,\nbut he didn’t fully accept the news until the day he received some jolting\nnews via text message.\n\n“I needed meds due to cheating girlfriend syndrome,” Steve explained\nsheepishly in our interview as to the reason for his purchase. “She texted me\none day and basically told me she had gonorrhea and that I should get checked\nout, too.”\n\nIt had been a tough month for Steve. Not only had his girlfriend slept with a\ncoworker, dumped him, and stuck him with a (mercifully treatable) venereal\ndisease, but his employer—an environmental testing firm—had just laid him off,\nand he had no health insurance.\n\n“I could have had COBRA insurance but that’s like three hundred to four\nhundred dollars a month,” Steve explained. “And when you’ve got no income,\nplus rent and a car payment and everything else, that’s not really an option.”\n\nHis ex-girlfriend helpfully texted the name of the drug her doctor had\nprescribed to clear it up—a full regimen of 500 milligram erythromycin\ntablets. So, Steve went online and searched for the drug and found exactly\nwhat he needed at a site claiming it was selling drugs from Canada. (The site\nSteve purchased from was actually hosted in China through GlavMed and the\ndrugs shipped from India.) Seven days and sixty dollars later, Steve had\nreceived the antibiotics and was on his way to a VD-free existence.\n\nDespite the circumstances that prompted his purchase, Steve said the overall\nexperience with GlavMed was a positive one, and that he would buy from them\nagain if he ever got another flare-up.\n\n“Would I do it again? Sure. Why pay a copay and seventy-five dollars for a\nprescription when I can get it online for a lot less bother? I mean, I could\nhave treated five people with [the number of pills] they sent me. So, for the\nprice you can’t beat what they’re offering.”\n\nAs the stories of these buyers show, a great many Americans turn to drugs\nmarketed via spam because the alternative is several times more expensive, or\nbecause their insurance doesn’t cover the drugs they’ve been prescribed. While\nSteve’s positive experience with pills ordered for a single use or regimen\nseems to be fairly common, repeat buyers purchasing pills to treat chronic\nconditions are likely to encounter a bad batch of pills sooner or later.\n\nAs we’ll see in [Chapter 5](05_chapter05.xhtml), this is because spam-\nadvertised pharmacies tend to get their cheap pills from dozens of different\nsources around the world, some of which appear to have little—if\nany—accountability for the safety and efficacy of their drugs. Inferior and\npoor-quality medications may only make the customer sick, as in Henry’s case.\nIn extreme cases, as we’ll see in [Chapter 5](05_chapter05.xhtml), substandard\npills may send the customer to the hospital—or worse yet, to the morgue.\n\n## Confidentiality\n\nA lawyer by profession, Washington, DC, resident “John” spent far too much\ntime behind his desk and was looking for a quick and easy way to bulk up his\nmuscles. After researching several online bodybuilding forums, he began taking\nsome legally questionable steroids from one of the sites recommended by the\nseasoned meatheads. A few months and a short regimen of gym workouts later,\nthe bulker pills had helped add several pounds of muscle to his lean frame.\n\nBut then one day in February 2010, John began to feel puffiness and\nsensitivity around his nipples. Worried that it may be a latent side effect\nfrom the bulker pills (and nervous about discussing his recent regimen of\nbulker pills with his doctor), John returned to the bodybuilder forums for\nadvice from his fellow meatheads.\n\nForum members told him he was suffering from a steroid-induced case of\ngynecomastia, the development of abnormally large mammary glands in males that\nresults in breast enlargement.\n\n“The medical shorthand for the condition is pronounced ‘guyno,’ but most of\nthe guys on the forums just call them ‘bitch tits,’” John said. “The guys were\ntelling me that if you don’t get it fixed with medication, then you need\nplastic surgery to fix your chest and I didn’t want to do that.”\n\nThe cure for John’s condition—according to his newfound friends on the\nforums—involved a regimen of additional drugs designed to counteract the\nhormones that cause guyno. Among them was a drug called “Femara,” which is\nmost often prescribed to treat postmenopausal early-stage breast cancer\npatients.\n\nJohn searched the web and ended up buying a two-week regimen of 2.5 milligram\nFemara pills for $136 from a GlavMed site called elitepharmacy.com. He waited\nthree weeks for the drugs, but they never arrived. So John canceled his order\nwith GlavMed and ordered them from another online pharmacy that was not\naffiliated with GlavMed. (John recollects that the two sites looked nearly\nidentical.) The original site apologized for the delay and credited his credit\ncard with the amount he’d paid.\n\nThe drugs that he received from the second site showed up in a manila envelope\naddressed from India, but the pills themselves were sealed in a blister pack\nwith the brand name Novartis seamlessly printed multiple times across the\nsilver foil on top of the pills.\n\nAccording to John, the pills looked like the real thing, and they reduced the\ntenderness and swelling in his nipples, effectively nipping his pouty man-\nboobs in the bud.\n\n“I was a little leery of the whole thing at first, but it worked,” John said.\n“I also thought I was wasting my time canceling my order. I sort of figured\nthis was a shady operation…but they refunded my money.”\n\nJohn’s experience highlights the lengths to which rogue pharma programs will\ngo to ensure customer satisfaction. The goal here is not necessarily to keep\nthe customer happy. Rather, the people running these operations will do next\nto anything to keep customers from initiating “chargebacks,” a process in\nwhich the customer reverses the charges, claiming fraud or some other misdeed\non the part of an online store. Merchants that receive too many chargebacks\npay much higher processing fees and may eventually be fined or have their\naccounts closed, or both.\n\nData from GlavMed’s customer database shows that the program had dozens of\ncustomer support personnel working round-the-clock via phone and online chat,\nresponding to customer concerns or questions about existing orders.\n\nVishnevsky, the spammer discussed in [Chapter 1](01_chapter01.xhtml) who\nworked with GlavMed-SpamIt to help bankroll the development of the Cutwail\nbotnet, said in an interview via instant message that people who buy from\npharma sites can always get their money back just by calling and lodging a\ncomplaint with the pharmacy program’s 800 number.\n\n“The bank will screw every merchant that has chargebacks [that are] more than\n1 percent of total sales,” Vishnevsky said. “So no one will risk to lose the\n[card processing account] by not returning money, and everyone who asks [the\npharmacy affiliate program’s customer service department] for money back will\nget it.”\n\n## Self-Prescribing\n\nKimberly from Virginia was a GlavMed buyer who self-prescribed but received a\nrefund after complaining she was unhappy with her purchase. She and her\nhusband were having trouble conceiving a child. He was frequently gone on long\nmilitary deployments, and she was anxious to get pregnant before her husband\nleft for another year-long stint abroad. A nurse by profession, Kimberly said\nshe’d decided to order the fertility drug Clomid online because she knew that\nit was what a fertility doctor would prescribe.\n\n“I basically knew how to use it and what I was supposed to do, and instead of\nhaving to pay a doctor tons of cash to explain something I already knew how to\ndo, I opted to do it myself,” Kimberly explained. “It’s not like I just\nordered from the first site that popped up. I looked around and saw one\nspecific site pointed to by so many other sites.”\n\nA few weeks later, a brown envelope arrived via post, with markings from India\non the package. The Clomid pills were in the familiar blister packaging, but\nshe noticed they were stamped with an expiration date that had already passed.\nShe insisted on a refund and received it without delay. Ironically, she\ndiscovered she was pregnant just a few days after receiving the refund—no\npills necessary.\n\nBut she says her inbox has been inundated with spam ever since she ordered the\ndrugs online, and she remains concerned that the people who run the online\npharmacy are going to push fraudulent charges through to her credit card.\n\n“They’ve spammed me a million times since then,” Kimberly said. “I know that\nobviously wasn’t the best idea for me to order these drugs online, but I was\ndesperate at the time. I’m really glad I didn’t take the medication. It\nprobably would have hurt the baby I already had inside of me.”\n\nVishnevsky confirmed that people are often inundated with spam after ordering\nfrom or responding to junk email offers. That’s because addresses of known\nbuyers are a valuable commodity frequently resold or simply stolen by other\nhackers and spammers. (Recall how Vishnevsky’s own list of two billion email\naddresses was left on McColo’s servers. That list was downloadable by anyone\nwho happened to discover the correct link needed to grab the file.)\n\nBut Vishnevsky said it’s a common misconception that ordering from online\npharmacy sites will result in credit card fraud. None of the spammers for\nSpamIt, GlavMed, or any other pharmacy spam program allow affiliates to view\ncustomer card data, he said, because they want to keep that information for\nthemselves.\n\n“Only administrators of [the] pharma program would see that, and they have no\nbenefit to getting fraud on [the] card, because [the] merchant would risk\nlosing [their card processing] account” as a result of increased chargebacks\nand fraud claims, he said.\n\n## Dependence and Addiction\n\nMost of the buyers I reached who fit into this category declined to be\ninterviewed. Also, all of them had ordered from sites run by affiliates\nworking for Vrublevsky’s Rx-Promotion, which had carved out a niche as one of\nthe few rogue pharmacy affiliate programs that marketed and sold painkillers,\nstimulants, and other substances whose distribution is heavily controlled by\nauthorities in the United States and elsewhere. (Records show that GlavMed\nalso offered controlled pills for the first two years of its existence, but it\nwas no longer selling controlleds when I began this project.)\n\nGoran was a forty-one-year-old former prisoner of war from Eastern Europe, now\nliving in the United States, who badly injured his back almost twenty years\nago. Doctors long ago stopped prescribing him hydrocodone, so he spends\nbetween $250 and $500 a month buying it off the Internet along with tramadol,\neven though doing so is a felony in his state. Records leaked from Rx-\nPromotion show that Goran made several purchases throughout 2010.\n\nGoran told me he’s been happy with his purchases so far, and that they work\nabout as well as the drugs prescribed by his doctor to keep the pain at bay.\nHe said the online drugs typically ship from Hong Kong and arrive in blister\npacks wrapped in a sealed ziplock bag.\n\nWithout the pain meds, he said, he’d be unable to manage his transportation\nbusiness. “In this country, if you don’t work, you know what you are?” he\nasked. “You’re homeless.”\n\nGoran may be taking the pills for legitimate back pain, but I suspected many\nothers were not. Interestingly, the GlavMed database shows telltale signs of\nabuse among customers who ordered controlled substances during the years that\nthe affiliate program was selling them. I shared the GlavMed customer data\nwith Gary Warner, director of research in computer forensics at the University\nof Alabama at Birmingham, who ran a series of queries on the database to see\nif any immediate patterns became clear.\n\n“What we found is that if you were a GlavMed customer who made more than five\norders, there was an 80 to 85 percent chance that you bought tramadol or\nSoma,” Warner said. “The question is, were they buying it for personal use or\nfor resale? These are pills that have a street value of about five dollars per\npill, which means that if you ordered a bottle of these pills through GlavMed\nand sold them one by one, you could have made about $1,300 profit per bottle.”\n\nThe UCSD researchers with whom I shared the Rx-Promotion sales data also found\nstrong indications that a major driver of revenue for that rogue pharmacy was\nrepeat customers. The team found that sales of painkillers and other drugs\nthat are highly restricted in the United States produced 48 percent of all\nrevenue for the Rx-Promotion program.\n\n“The fact that such drugs are over-represented in both Rx-Promotion (and, for\ndrugs like Soma and tramadol, in SpamIt) reinforces the hypothesis that abuse\nmay be a substantial driver for this component of demand,” the UCSD team wrote\nin a research paper on their findings.\n\nFor the most part, I was unable to learn firsthand from the people I\ninterviewed about the efficacy and safety of the drugs they received from\nGlavMed or Rx-Promotion sites. Nearly everyone I spoke with promised to mail a\npill or two from the packages they’d received, but only one interviewee\nactually followed through. That package contained both knockoff Viagra and\nanother drug that were in the same bag and got crushed together and badly\ncontaminated.\n\nSo while I’d gotten some good information on why people were ordering these\ndrugs and perpetuating the spam problem, I decided that to make sense of the\nGlavMed and Rx-Promotion affiliate and client data, I needed help from Warner\nand several other prominent academic researchers with the capability and\nfacilities to test these drugs. What I didn’t know at the time was that these\nresearchers had been trying to discover the same thing on their own, only to\nbe stymied by miles of red tape and the pharmaceutical industry itself. I was\nalso about to discover the much darker, more sinister consequences of these\nonline drug buyers’ choices.\n\n* * *\n\n[8.](04_chapter04.xhtml#fnr8)Again, while leaked ChronoPay emails show\notherwise, Vrublevsky denies co-owning Rx-Promotion, but admits that ChronoPay\ndid process payments for the pharmacy program. Gusev has publicly denied\nrunning SpamIt, but again, the evidence suggests otherwise.\n\n\nChapter 5\n\n## RUSSIAN ROULETTE\n\nLess than twenty-four hours after Christmas 2006, Marcia Bergeron succumbed to\npoisons mixed into several medications she had ordered from a supposedly\nCanadian pharmacy online. Her body was discovered by a neighbor, and more than\na hundred generic pills were found in her home, including a sedative, an anti-\nanxiety drug, and acetaminophen.\n\nBergeron, a fifty-seven-year-old resident of Quadra Island in British\nColumbia, Canada, had started losing her hair and experienced blurred vision\nin the days before her death. According to the coroner’s report, “Mrs.\nBergeron had been suffering from a range of symptoms. In emails to a friend,\nshe described symptoms of ongoing nausea, diarrhea, aching joints, and other\nissues. Her friends locally were aware she was losing her hair and having\nvision problems. In the days immediately prior to her death, she was extremely\nfatigued and sick.”\n\nAn autopsy report showed that Bergeron had been slowly poisoned by extremely\nhazardous chemicals included in the pills, which the Coroners Service of\nBritish Columbia said were ordered from an online pharmacy.\n\nToxicology tests indicated that many of the pills contained dangerously high\nlevels of heavy metals that had probably been used as filler or were trace\nelements from a contaminated production facility. Among the chemicals included\nin the pills were uranium and lead, both of which can be lethal or severely\ndamaging even in small doses.\n\nIt remains unclear which rogue Internet pharmacy program sponsored the site\nfrom which Bergeron ordered. Drugs purchased by GlavMed and other rogue\npharmacy partnerships are marketed as if they come from pharmacies in Canada,\nwhich is world-renowned for its affordable medications. But most of the drugs\nfrom GlavMed appear to have been shipped from a half-dozen pharmacies or\nsuppliers in India, a nation that is also now among the world’s largest\nsources of legitimate branded and generic medications. The rest seem to have\ncome from more than forty manufacturers and suppliers in China, India, and\nPakistan, some of whom appeared to resell legitimate, branded drugs at bargain\nbasement prices and some who didn’t. The one that Bergeron used clearly\ndidn’t.\n\nIndia has the brains, manpower, and infrastructure to manufacture huge\nquantities of pills each year, and it has fostered a booming, $10 billion-a-\nyear pharmaceutical industry even though the country has routinely denied the\npatents for many drugs made by Western drugmakers.\n\nAs Vikas Bajaj and Andrew Pollack wrote for the New York Times in March 2012,\nIndia’s conflict with Western drug companies over patents dates back to 1970,\nwhen the country stopped granting drug patents. It resumed granting them in\n2005 as part of an agreement with the World Trade Organization, but the\nagreement was not retroactive to medicines created before 1995.\n\nSince then, the Times notes, India has emerged as the world’s pharmacy and, in\nrecent decades, has been the largest provider of cheap, generic lifesaving\nmedicines in poor countries across the globe. Western drugmakers have charged\nthat by limiting drug patents in specific cases and fostering the development\nof inexpensive, generic knockoffs, the Indian government and the\npharmaceutical industry there are stifling innovation and reducing profits\nthat are essential to continued research and development on lifesaving drugs.\nThe Indian drug companies say their practices ensure that poorer nations\nmaintain affordable access to drugs for scourges like HIV and cancer.\n\nIndeed, in one high-profile legal showdown, the Indian drugmakers faced off\nagainst Swiss pharmaceutical giant Novartis in a legal battle over whether\nIndian firms could continue to produce generic copies of Gleevec, a drug that\nprovides effective treatment for some types of leukemia. As the New York Times\nnotes, Gleevec can cost as much as $70,000 per year, while Indian generic\nversions have sold for about $2,500 a year. In late March 2013, the Indian\nSupreme Court ruled that the patent that Novartis sought for Gleevec did not\nrepresent a true invention.\n\nThe problem is that India’s admirable, if self-serving fight to produce\naffordable generic drugs for the rest of the world does not address the safety\nand efficacy of these non-brand drugs. But to hear the U.S. pharmaceutical\nindustry tell it, any prescription drugs produced outside the so-called\n“approved supply chain” are counterfeit at least, probably substandard, and\nquite possibly harmful or lethal. Whether or not that’s always the case, the\nU.S. drugmakers are right about one thing: most drugs sold by rogue online\npharmaceutical companies are not produced in regulated facilities—and\ntherefore pose serious risks to anyone who decides to take them.\n\nThe statistics about the rogue pharmaceutical industry—and their implications\nfor the health of its customers—are truly terrifying. According to the World\nHealth Organization, approximately 8 percent of the bulk drugs imported into\nthe United States are counterfeit, unapproved, or substandard, and 10 percent\nof global pharmaceutical commerce—or $21 billion—involves counterfeit drugs. A\nstudy led by the International Journal of Clinical Practice (IJCP) published\nin 2012 puts the number at more than three times that amount. The IJCP study\nestimates that global sales of counterfeit medicines doubled in the five years\nbetween 2005 and 2010, and now exceed $75 billion. The Alliance for Safe\nOnline Pharmacies estimates that 30,000 to 40,000 active online drug sellers\noperate at any given time, and that only a fraction are legitimate.\n\nPharmaceutical giant Merck recently analyzed more than 2,500 Internet\npharmacies and found that more than 80 percent of those sites were selling\ntheir drugs without requiring a prescription. Online pharmacies run by\npharmacy affiliate networks like Rx-Promotion and GlavMed-SpamIt never asked\ncustomers to produce a prescription, although legitimate online pharmacies\nselling prescription drugs to Americans must by law require a prescription.\nWhat’s more, Merck discovered that nearly six hundred of those pharmacies were\nselling the drugs at a price below the lowest wholesale average price\navailable to any market anywhere, strongly indicating that the drugs were\ncounterfeit—and very possibly unsafe.\n\nMany people who bought from Rx-Promotion and SpamIt-affiliated online\npharmacies expressed surprise at receiving their pills in packages showing\nthat they were shipped directly from India and China. But according to a 2010\nreport from the U.S. Government Accountability Office (GAO), that’s where the\nvast majority of drugs you buy from your corner drugstore are also produced.\nThe GAO found that roughly 80 percent of the raw ingredients that go into all\npharmaceuticals—including those peddled by rogue online pharmacies, approved\nonline pharmacies, and even Main Street vendors like CVS and Walgreens—come\nfrom chemical factories based in India and China.\n\nThe problem isn’t that these drugs are produced outside North America for U.S.\nand Canadian consumers. The issue is that it’s unclear whether the suppliers\nthat rogue pharmacy operations like SpamIt and Rx-Promotion use are supplying\nbranded and generic medications to the supply chain for pills sold at\nlegitimate and approved pharmacies in the United States and abroad—and, more\nimportantly, whether the drugs they’re creating are safe or not.\n\nSpamIt pharmacies, for example, relied on pills bulk-shipped by at least forty\ndifferent suppliers, but the vast majority of the medications sold via their\nspamvertized sites came from a half-dozen drop shippers in India and Hong\nKong. According to information pieced together from the SpamIt affiliate\ndatabase and the Stupin online chats, the top suppliers for SpamIt included\nSai Balaji Enterprises and Hemant Pharma (doing business as “Chinmay\nOverseas”), both from Mumbai, India. Other top suppliers for SpamIt included\nTrans Atlantic Corp., based in Hong Kong, and Shri Kethlaji Traders in\nSumerpur, India.\n\nThe trouble is that the GlavMed-SpamIt order fulfillment system appears to\nhave selected suppliers and drop shippers automatically based on which one\nrecently bid the lowest for the class of drug the customer is seeking. The\nspam pharma companies have no idea whether these drugs are safe for consumer\nconsumption—or whether they’re even the real drugs or fake ones stuffed with\npotential poisons and toxins like what killed Marcia Bergeron.\n\nIn short, customers who order drugs from spam may be playing a dangerous game\nof Russian roulette.\n\nDigging deeper, I discovered that GlavMed kept scrupulous records of customer\nservice complaints and requests. Thousands of complaints from customers\nappeared in the leaked GlavMed database, yet relatively few of them pertained\nto the quality of the drugs that were delivered. Rather, most complaints were\nabout delays in receiving the ordered drugs or were lodged by customers who\nreceived the wrong medications or were unhappy with how the drugs were\npackaged.\n\nOne exception was a transaction made by Deborah G., a resident of the United\nKingdom. Deborah ordered weight-loss drugs and other items from pillaz.com—a\nsite advertised by a spammer working for Igor Gusev’s GlavMed affiliate\nprogram. According to the GlavMed customer complaint database, the pills that\nDeborah ordered sent her to the emergency room. The London resident described\nherself as a forty-three-year-old woman who weighed more than two hundred\npounds but who had no allergies or current medications. In 2010, she paid\n$437.39 (not including shipping) for a veritable medicine cabinet of\nprescription drugs, including:\n\n•One hundred eighty (20 milligram) tablets of the anti-obesity drug Acomplia.\n\n•Sixty doses of Xenical, a drug that blocks the absorption of fat in certain\nfoods.\n\n•A three-month supply of Hoodia, an organic weight-loss supplement.\n\n•Four tubes of acne-fighting tretinoin cream.\n\nNot long after ingesting her new pills, Deborah fell into a deep depression\nand had to be admitted to the hospital after she began to feel sick to her\nstomach. Suspecting that the tablets she’d received from her online order may\nhave been tainted, she brought the drugs to a lab to have them professionally\ntested.\n\n“On testing, they discovered they were completely fake,” Deborah said in her\nemailed complaint to GlavMed’s customer support team. According to Deborah,\nthe lab results revealed that some of the pills contained a variety of\ninactive and decidedly hostile ingredients, including poisons, cement, and\ntalcum powder.\n\nDeborah later lodged a threatening complaint at the site from which she’d\nordered.\n\n“I want ALL my money back. I will gladly post back the tablets, and no further\naction will be taken,” she wrote in a comment included in the SpamIt database.\n“However if I do not receive this I will face no other option than to go to\nthe police and all the customs authorities dealing with counterfeit drugs, and\ntrust me, I will get you prosecuted. I will expect a full refund for all your\npoisons immediately.”\n\nRecords show that the SpamIt-affiliated pharmacy site complied, posting a full\nrefund to Deborah’s credit card. Again, the last thing these rogue online\npharmacies want is to be pulled onto the radar of law-enforcement authorities\nor to have unsatisfied customers issue chargebacks, which could endanger the\nonline pharmacy’s ability to take credit cards (which would kill its business)\nand could cause it to incur heavy fines.\n\nGiven the quantity of fake pharmaceuticals that flood markets in North America\nand Europe each year—and the potential brand damage and profit losses wrought\nby rogue pharmacies—one would think the powerful and influential pharma\nindustry would use its might to show just how dangerous these drugs can be.\nIndeed, the story of Bergeron’s death is almost always recited in some form\nwhenever experts allied with the pharmaceutical industry talk about the need\nto eradicate rogue Internet pill shops.\n\nYet, neither the Food and Drug Administration (FDA) nor the giants of the\npharmaceutical industry appear to have taken concrete steps to fight back\nagainst these rogue online competitors, though it’d be easy to show whether\nthe drugs being offered through them contain harmful ingredients or at least\ndangerously low or high levels of the active ingredients compared to\nlegitimate versions of their pills.\n\nJohn Horton, president of LegitScript, a company that maintains a searchable\ndatabase of thousands of approved and “rogue” pharmacy websites, said the FDA\noccasionally publishes the results of chemical testing done against dietary\nsupplements and some prescription drugs bought from online pharmacies, but\nthat few comprehensive studies have been conducted.\n\n“It’s fair to say that there’s a dearth of testing,” said Horton, a White\nHouse aide on drug policy issues during the administration of President George\nW. Bush, from 2002 to 2007. “I think one of the problems you run into is that\nthese tests are expensive. Also, it’s difficult to scientifically study and\nanalyze the chemical composition of these drugs ordered from rogue pharmacies\nbecause those pharmacies constantly are switching suppliers.”\n\nAccording to LegitScript, there are more than 41,000 active Internet\npharmacies, yet only one-half of one percent of those (slightly more than 200)\nare approved and legitimate web pill shops. In other words, if you order from\none, you have more than a 99 percent chance of using an illegitimate,\nunapproved website. The company ranks pharmacies as legitimate if they meet a\nset of criteria, including registration with the U.S. Drug Enforcement Agency\nand possession of a legitimate license to dispense drugs. But most\nimportantly, the pill shop must ask for and receive a legitimate, doctor-\nordered prescription before shipping prescription drugs to Americans.\n\nTo make matters worse, Horton said many of the 40,000-plus rogue online\npharmacies rely on multiple suppliers, meaning that the quality and safety of\nthe drugs they ship can shift from day to day as prices in the wholesale and\ndrop-shipping markets fluctuate.\n\n“Most of these pharmacy affiliate programs don’t just have one supplier,”\nHorton said. “Some of the bigger ones have dozens. So, just because a given\ndrug from a specific pharmacy program tests as genuine one day doesn’t mean\nit’s going to be the same genuine drug the next time someone orders it.”\n\nBut Horton believes perhaps the single biggest reason neither the FDA nor the\npharmaceutical industry has put much effort into testing is that they’re\nworried that such tests may show that the drugs being sold by many so-called\nrogue pharmacies are by and large chemically indistinguishable from those sold\nby approved pharmacies.\n\n“Frankly it’s sort of a double-edged sword,” Horton said. “Let’s say you test\nRx-Promotion’s drugs and they turn out to be real, to be chemically equivalent\nto the stuff you’d get from your local pharmacy. Does it then follow that by\npublishing those results, you are almost implicitly endorsing the site that\nsold those drugs?”\n\nThus, most of the work of testing pills sold by rogue pharmacies has fallen to\nacademic researchers attempting to unearth data on the safety and efficacy of\nprescription medications ordered through spam. Stefan Savage, a professor in\nthe systems and networking group at the University of California, San Diego\n(UCSD) led a research team that spent many months in 2011 making more than\neight hundred test orders from pill shops advertised via junk email.\n\n“The prevailing wisdom was that these pharma shops took your money and ripped\noff your credit card, and you never got jack,” he said. “We wanted to know if\nyou ordered from these stores whether you actually got anything, and if so,\nwhere it came from, who did the payment processing, all that stuff.”\n\nSavage said the group was surprised to learn that the drugs they purchased and\ntested all seemed to have the right active ingredients in roughly the correct\namounts, but they weren’t able to test the drugs for contaminants that may\nhave introduced health risks for customers.\n\n“For legal reasons we can’t buy every drug, and we’re not equipped to test\neverything,” Savage said. “But in the drugs that we have tested, the right\nactive ingredient has appeared in the right amount. So it really seems like\nfrom the standpoint of the people in this business and their communications\nwith each other that they believe they’re selling an equivalent product” to\nwhat consumers would otherwise get at a local drugstore, he said.\n\nIn 2012, Savage and his fellow UCSD researchers, along with researchers at the\nInternational Computer Science Institute and George Mason University, examined\ncaches of data tracking the day-to-day finances of GlavMed, SpamIt, and Rx-\nPromotion. The result is perhaps the most detailed analysis yet of the\nbusiness case for the malicious software and spam epidemics that persist to\nthis day. They found that repeat customers are critical to making any rogue\npharmacy business profitable. Repeat orders constituted 27 percent of average\nprogram revenue for GlavMed and 38 percent of that revenue for SpamIt. For Rx-\nPromotion, revenue from repeat orders was as much as 23 percent of overall\nrevenue.\n\n“This says a number of things, and one is that a lot of people who bought from\nthese programs were satisfied,” Savage said, noting, however, that many of the\nrepeat customers were purchasing controlled and habit-forming prescription\ndrugs, including painkillers. “Maybe the drugs they bought had a great placebo\neffect, but my guess is these are satisfied customers and they came back\nbecause of that.”\n\n♦ ♦ ♦\n\nBy far the most important question about the pills pimped by the spam business\nis the efficacy and safety of the drugs. I interviewed hundreds of U.S.\nresidents who purchased prescription drugs from the pharmacy sites advertised\nthrough SpamIt, and received a panpoly of responses about the effectiveness of\nthese pills. But none of those I interviewed could tell me about the safety of\nthe drugs or their purity.\n\nFor that, I’d hoped to enlist the help of chemists and researchers. Gary\nWarner, director of research in computer forensics at the University of\nAlabama at Birmingham (UAB), had sought to conduct much of the same research,\nbut ran into bureaucratic hurdles left and right. So not long after receiving\na copy of the GlavMed-SpamIt data, I shared it with Warner. He, in turn, tried\nto get various pharmaceutical firms interested in using the data to open a\nbroader, well-funded investigation into these rogue online pharmacies. But his\nefforts were met with little success.\n\nThe sprawling campus of UAB is also known as “the University that Ate\nBirmingham,” and it’s not hard to see why. The city of Birmingham is home to\nfewer than a quarter-million residents, and about one in ten are students at\nthe university.\n\nOn the fourth floor of a nondescript brick building smack in the middle of the\ncampus is the UAB computer forensics lab, where Warner spends eight to ten\nhours a day with a mix of undergraduate, graduate, and PhD students who, like\nme, seem to be infected by a passion for going after Internet bad guys.\n\nWarner is standing in front of a floor-to-ceiling whiteboard that is covered\nwith equations related to a mathematical algorithm that the computer lab’s\ntwentysomething geeks are trying to work out. He is gesturing at rows of\ncomputer servers and Mac OS X systems that line either side of the climate-\ncontrolled and tightly secured room, which is used in part by university\nstudents laboring under a grant from the Defense Advanced Research Projects\nAgency (DARPA) to create and study malicious software in a lab environment.\n\nA complete and unabashed caffeine junkie, Warner is slurping from his third\ndiet Mountain Dew of the day. He’s talking excitedly about the dangers of\nordering from unlicensed Internet pharmacies, irrespective of whether the\npills themselves are real and chemically equivalent to pills that customers\nmight otherwise purchase from a local pharmacy.\n\nPart of the problem, Warner said, is that many unlicensed Internet pharmacies\nwill happily ship a variety of drugs whose use has been banned or highly\nrestricted in the United States because of the drugs’ tendency to induce\ndangerous side effects—without offering any warnings or instructions on using\nthe medications.\n\nFor example, pharmaceutical giant Roche decided to pull its anti-acne drug\nAccutane from the U.S. market after juries awarded millions of dollars in\ndamages to former Accutane users. The drug has been strongly linked to birth\ndefects among children born to women who took it while pregnant. As a result,\nthe U.S. FDA in 2005 ordered that Accutane only be sold to women who sign a\npledge saying they will submit to multiple pregnancy tests and practice at\nleast two forms of birth control while on it. But Accutane is still available\nthrough rogue spam pharmacies.\n\nThis is another example of the risks people take when buying from these rogue\npharmacies: they don’t get vital information on the serious health hazards\nthey could face in taking certain drugs in certain conditions or in\ncombination with other drugs. Legitimate pharmacies, on the other hand, do\ntheir best to ensure that their customers understand these risks before giving\nthem their prescriptions.\n\n“Many of these rogue pharmacies are still advertising a number of\ndiscontinued, banned, or very restricted drugs,” Warner said. “And they’re\ndefinitely not passing on warnings about how these drugs should be used, even\nwhen there are strong conditions that would normally be impressed on the\ncustomer when ordering these drugs from regular pharmacies.”\n\nThe most obvious example of a common risk introduced by pills dispensed from\nGlavMed and SpamIt pharmacies is the two to four free counterfeit Viagra or\nCialis pills that were shipped with every order. The pills were stuffed into\nall orders, even those in which the customer had purchased drugs such as\nnitrates that could produce a deadly cocktail when taken with erectile\ndysfunction (ED) medications. Physicians have long warned against taking ED\ndrugs in tandem with medicines designed to decrease high blood pressure,\nbecause doing so could lead to dangerously low blood pressure levels, a\ncondition that often precipitates a heart attack.\n\nThe UAB computer forensics lab is the ideal location for testing drugs bought\nthrough spam. One floor below Warner’s lair, Elizabeth Gardner, PhD, spends\nmuch of her time analyzing new “legal highs.” These are mind-altering\nsubstances created with synthetic versions of chemical compounds whose use and\ndistribution are restricted in the United States. Some of these legal highs\nare fairly benign, such as the “performance-boosting” pills sold at gas\nstations that hint at their supposed abilities to enhance a man’s stamina in\nthe bedroom.\n\n“Most of these are just lots of caffeine and wishful thinking,” Gardner quips.\n\nOther legal highs are far more serious and can have devastating—even\nhorrifying—side effects. Just prior to my visit to the UAB campus, police in\nMiami, Florida, responded to a call to a crime scene that was straight out of\na Hollywood zombie movie. Police officers were summoned to the area beneath a\nlocal highway overpass, where one man was reportedly assaulting another.\nArriving on the scene, officers shot and killed a thirty-one-year-old local\nman who was found gnawing the face off a homeless person in broad daylight.\nInvestigators later discovered that the assailant had been turned into a real-\nlife zombie after ingesting prodigious amounts of “bath salts,” a synthetic\nstimulant designed to produce effects similar to amphetamines and cocaine.\n\nOn a Thursday afternoon in mid-June 2012, Gardner is looking at the chemical\nanalysis of a local bath-salts sample. Bits of the drug are being fed into a\nlarge white box that resembles an oversized laserjet printer. The device is a\nmass spectrometer, a tool that this lab uses to search for and identify the\nactive ingredients found in various controlled substances. Almost noiselessly,\nit automates the fetching and analysis of tiny glass vials filled with\nchemical samples that are fed into the machine’s interior.\n\nThe machine produces data that are relayed to a nearby computer, which uses\nthe information to plot a line graph that shows several distinct upward\nspikes.\n\n“See these spikes here,” Gardner says, pointing at two especially tall peaks\nin the graph. “These are the chemical markers for mephedrone, which is the\nactive ingredient in these salts.”\n\nDespite our efforts, I was unable to get any of the online drug buyers to send\nme useful samples of the pills for testing in Gardner’s lab. Not that it would\nhave mattered: UAB couldn’t get legal cover to do it anyway.\n\nIncredibly, the UAB researchers have legal approval from federal regulators\nand law-enforcement agencies to test and handle highly controlled and illegal\nsubstances, such as cocaine, heroin, and a methamphetamine, but they had not\nyet received permission from the FDA and DEA to test pills ordered through\njunk email.\n\nPart of the problem is that Congress changed the law in 2008, when it enacted\nthe Ryan Haight Act, which makes it expressly illegal for anyone to order\nprescription drugs over the Internet without a prescription. In addition, even\nif an American has a valid prescription for a drug, it is illegal for him or\nher to order the drug from a pharmacy outside the United States and have it\nshipped back into the United States.\n\n“We’ve kind of gotten it taken care of,” Warner said. “We’ve got the\nmemorandums of understanding in place and got the post office boxes all set up\nand the top-level approval at the university. But we still have this one tiny\nlittle administrative hurdle to get over.” They still needed a green light\nfrom federal regulators.\n\nWarner even had a regional bank on board to provide his researchers with\nprepaid cards that could be used to covertly buy drugs from GlavMed-SpamIt and\nRx-Promotion.\n\n“The bank was willing to put up the money to help fund our operations, but we\nstill needed a government letterhead memo basically saying that no one was\ngoing to go to jail for this,” Warner said. The university was slated to\nreceive a grant from the FDA to conduct research on rogue pharmacies, but the\ngrant would come with serious strings attached.\n\n“They basically said that none of the money could be used to purchase drugs,\nand if any of the grant money is used to analyze drugs ordered from spam, then\nthe grant will be withdrawn,” Warner said. “What changed between when the FDA\ntentatively offered the grant and these conditions? Nobody can say. They just\nsaid, ‘It’s not legal for us to authorize you to buy drugs.’ So the FDA Office\nof Compliance had to go back and revise the grant to only evaluate the\nwebsites in the spam emails, and we were no longer allowed to purchase the\npills.”\n\nThis was not the first time Warner and UAB were frustrated in their attempts\nto test pills ordered through spam to conduct their research. Not long before\nI’d shared the GlavMed data with him, Warner had a meeting with executives and\nfraud investigators from Pfizer. The pharmaceutical giant indicated it was\ninterested in working with UAB on a study to analyze drugs purchased through\nrogue pharmacy affiliate programs. After all, counterfeit sales of its\nblockbuster drug—Viagra—accounted for more than 40 percent of the transactions\nfrom both Rx-Promotion and GlavMed.\n\nBut the funding for such a project would come with certain strings attached.\n“Pfizer said they wanted to work with us on this project as long as they had\nthe right to shut the thing down if it turned out the drugs were real,” Warner\nrecalled. “Microsoft was talking with us and Pfizer about whether UAB and\nMicrosoft could do something like a website such as pilldangers.org or\nsomething, and warn people of dangers of buying pills online. And my chemist\nsaid, ‘Well, what if the drugs are real?’”\n\n“In response, the Pfizer guy said, ‘Well, then we wouldn’t want to publish\nanything.’ I told them that we’re big on academic freedom and that we wouldn’t\nbe able to live with that condition,” Warner recalled. “I told him that we’d\nwant to be able to say, for example, ‘Okay, so in 25 percent of pharmacy\norders we got, we got the real thing.’ They said, ‘No, no, you can’t do that.\nWe only want you to publish about the fake pills.’”\n\nThen, after Warner had received a copy of the GlavMed data, he had a chance to\nchat with another Warner—Mark Warner—the director of intelligence for Pfizer\nand a twenty-one-year veteran of the FBI. UAB’s Warner said Pfizer’s Warner\ncalled to discuss possible collaboration on mining the GlavMed data for\ninformation that U.S. law-enforcement officials could then present to Russian\nofficials to help stop the tidal wave of spam affecting everyone.\n\n“I got off the phone with him before I understood exactly who he was, but this\nguy acted like an old-school, knuckle-dragger cop,” UAB’s Warner recalled of\nthe conversation. “He’s a New Yorker, so it kind of went like this:\n\n“‘Well, Mistah Wahrnah, just listen to me. I’ve been doin’ this a lot longer\nthan you. And here’s the way it’s gonna go: the Russians aren’t gonna do fuck\nall for us. What we need to do is find the spam affiliates who are in the\nUnited States and lock ’em up. Forget the Russians. We’re never going to touch\nthe Russians. The Russians are bulletproof. We can’t touch ’em. So let’s just\nfind the guys who are in the U.S., put them in jail, and move on.’”\n\nOn the one hand, Pfizer’s Warner had a point: according to most law-\nenforcement experts I interviewed for this book, there was almost no chance\nthat the Russians would do “fuck all” about it. For starters, hackers in\nRussia are generally left alone as long as they do not prey on the country’s\nown companies or citizens. But UAB’s Warner said he was taken aback by such a\nresponse. After all, more than 40 percent of GlavMed’s sales involved knockoff\nversions of Pfizer’s blockbuster drug Viagra, so it would be in the pharma\ncompany’s best interest to collaborate.\n\n“I just couldn’t believe the caveman mentality that this guy had,” Warner\nrecalled in a telephone interview. “I thought to myself, you know he may be a\ntwenty-one-year veteran of the FBI, but it doesn’t mean he knows jack about\ncybercrime. At the same time, counterfeit versions of his company’s big\nmoneymaker were by far the largest single drug that GlavMed sold. They’re the\nones in a perfect position to complain about pharmaceutical spam, but who\nknows? Maybe $100 million in counterfeit SpamIt and GlavMed profits is nothing\nto a company that makes tens of billions a year.”\n\nUAB’s Warner said he began to feel despondent about having so much information\non a massive criminal cybercrime conspiracy, while law enforcement seemed to\nhave so little interest in running with the data cache.\n\n“I had been participating in the FBI’s pharmaceutical fraud working group, and\nI was horribly disappointed because hardly any of the big pharma companies\ncame to the meetings,” Warner said. “At least in the meetings I attended,\nthere would be seven pharmaceutical companies at the table, and not a single\none of them I’d ever heard of. Roche wasn’t there, Bayer wasn’t there, Pfizer\nwasn’t there. Merck wasn’t there. AstraZenica might have been at one of the\nmeetings. But we couldn’t get anyone interested.”\n\nThat said, there may have been another reason that Pfizer was in no mood to\nhelp the FBI. Not long before Warner acquired the GlavMed-SpamIt data, the FBI\nwrapped up a criminal investigation into Pfizer for promoting off-label uses\nof its biggest selling drugs and for paying kickbacks to physicians to promote\nthem. The government alleged that Pfizer sales reps made misleading marketing\nclaims about uses for the firm’s drugs. For example, reps allegedly were urged\nto instruct physicians on staging conversations about prescribing Viagra for\nwomen who had difficulty reaching orgasm.\n\nPfizer denied the allegations but nevertheless agreed to a $2.3 billion\nsettlement, at that time the single largest fraud settlement ever collected by\nthe U.S. Justice Department. The settlement amount roughly equaled the\nrevenues that Pfizer brings in each year from sales of Viagra. It’s no wonder\nthe pharma giant didn’t want to draw the FBI into another investigation, even\nif this one was to the pharmaceutical giant’s benefit.\n\nFor its part, Pfizer has opted to pursue cases against spammers and\ncounterfeiters via civil lawsuits. Over the past five years, the company has\nspent millions on investigation and legal fees to go after purveyors of fake\nViagra and other drugs. (Pfizer declined repeated requests to be interviewed\nfor this book.)\n\nWarner was disappointed that he couldn’t get permission to test prescription\ndrugs purchased from Rx-Promotion and GlavMed-SpamIt. But he seemed genuinely\nhopeful that the customer databases from both rogue pharmacy operations would\nbe enough to help bring down some of the world’s biggest spammers and botnet\nmasters, nearly all of whom were working for one or both of these affiliate\nprograms and whose personal and financial data were sprinkled throughout each\naffiliate program’s leaked records.\n\nThe same anti-spam activist who had shared the GlavMed database with me said\nhe sent a copy of it to contacts at the FBI. And for several weeks at the end\nof 2010, multiple law-enforcement agencies fought to take the lead on the\ninvestigation. Ultimately, the inquiry was determined to be best pursued as a\ntrademark infringement matter and was turned over to a multi-agency task force\nof the U.S. Department of Homeland Security’s Immigration and Customs\nEnforcement (ICE) bureau.\n\nThat task force, known as the National Intellectual Property Rights\nCoordination Center (NIPR), draws on civil and criminal investigative\nresources from at least twenty separate agencies, including the FBI, Interpol,\nthe U.S. Postal Inspection Service, the National Aeronautics and Space\nAdministration (NASA), and the Royal Canadian Mounted Police.\n\nThe investigation at NIPR was part of a broader push by the Obama\nadministration to crack down on abuses of intellectual property rights online,\nincluding rogue pharmacy sales and the illegal trade in pirated movies, music,\nand software. Around that same time, administration officials were announcing\nthe results of Operation Pangea, an annual international law-enforcement push\nled by Interpol and aimed at disrupting pharmaceutical crime. The week-long\noperation led to the shuttering of at least 290 rogue online pharmacies; the\nseizure of nearly 11,000 packages containing more than a million pills; and\nthe arrest or investigation of at least 76 individuals connected with the\npharma stores.\n\nMany of the sites taken down in Operation Pangea were web storefronts\nadvertised by spammers working for Vrublevsky’s Rx-Promotion program. Just\nprior to the takedowns, the U.S. Food and Drug Administration sent a warning\nletter to Vrublevsky’s partner—Yuri “Hellman” Kabayenkov—stating that the\nagency had identified 294 websites that were selling addictive, highly\ncontrolled prescription drugs such as painkillers without a prescription. It\nseemed U.S. authorities were finally starting to take a stand.\n\nRx-Promotion essentially shrugged. According to Vrublevsky, hardly anyone in\nthe program noticed the takedowns, which ironically more or less equaled the\naverage number of sites that disappeared each week as a result of regular\ncleanup efforts from anti-spam groups and web hosting firms.\n\n“It was very funny to read the news and see that there was this huge,\ninternational operation that resulted in the closure of hundreds of illegal\npharmacies on the Internet,” Vrublevsky said. “And then you read spammer and\nhacker forums and see these guys asking each other, ‘Dude, did you feel that?’\nand, ‘Dude, did you notice that?’ It didn’t seem like anyone cared or really\nnoticed.”\n\nVrublevsky said that in the weeks prior to the operation, a group of U.S.\nfirms—mainly copyright holders in the entertainment industry—had called a\nmeeting with members of the Russian State Duma, the lower house of Russian\nparliament. That meeting was part of a campaign in Russia by the entertainment\nindustry to crack down on music and movie piracy. The campaign’s slogan was\nroughly translated, “Say No to a Thief!”\n\nThe leaked ChronoPay emails show that the company was quietly paying the\nsalary of at least one member of the Russian Association for Electronic\nCommunications (RAEC), an industry trade group. ChronoPay invoices indicate\nthat the company paid a “monthly fee for public relations advice”—16,666.66\neuros—to Dmitry Zakharov, then RAEC’s public relations director. (This was yet\nanother debt that Vrublevsky and ChronoPay would welch on. ChronoPay’s\ninternal email records are littered with emails from RAEC’s debt collectors,\nwho hounded ChronoPay officials to pay tens of thousands of euros in\ndelinquent “consulting” fees, without success.) I sought comment from Mr.\nZakharov about this apparent arrangement, but received no response. That was\nfrustrating and ironic, in part because Zakharov left RAEC in 2010 and is now\ndeputy director of the department of external communications for the Russian\ngovernment’s Ministry of Telecom and Mass Communications.\n\nIn a phone interview one month after Operation Pangea, Vrublevsky told me he\ncontacted the RAEC leaders to make fun of them for participating in the\ncopyright and trademark forum.\n\nUnsurprisingly, the copyright owners—particularly from the movie\nindustry—threatened RAEC members like Vkontakte (a Russian version of\nFacebook) and mail.ru (a webmail provider) that unless they removed all\nrights-infringing materials, law enforcement would get involved, Vrublevsky\nsaid. “I heard about this and called those RAEC dudes and said, ‘Hey, how much\nbrains do you need to have not to go to a meeting with rights holders called,\n‘Say No to a Thief’?”\n\nLater in 2010, RAEC sent an official letter addressed to Victoria Espinel, the\nObama administration’s intellectual property enforcement coordinator. The\nletter—which also was sent to top officials at Google, Microsoft, the National\nAssociation of Boards of Pharmacy, and LegitScript—offered the Russian hi-tech\nindustry’s help with anti-spam efforts and with future initiatives aimed at\nstamping out rogue Internet pharmacies.\n\nThe letter claimed that the economic loss in Russia caused by spam was $450\nmillion in 2009, and that as a result, Russia was hard at work crafting its\nown anti-spam laws. RAEC didn’t mention that the man who cofounded the rogue\nInternet pharmacy targeted in the American government’s recent Pangea effort\nwas also in charge of the Russian government committee responsible for\nrecommending ways to draw up those anti-spam laws.\n\nRAEC officials closed the letter by offering to host a closed-circuit\nvideoconference bridge with officials from the Obama administration and the\ntechnology industry, “during which we could discuss the available results of\nresearches, the current matters, the initiatives, and opportunities for joint\nactions dedicated to the stabilization of [the] situation in the area of\ncybercrime in general, and in relation to the pharmaceutical spam in\nparticular.”\n\nLegitScript President John Horton said his immediate reaction upon receiving a\ncopy of the letter was to contact the FDA and Espinel.\n\n“I said, ‘I’m sure you guys know about what’s going on with ChronoPay,’ and it\nturns out they did,” Horton said. “I also emailed Victoria [Espinel] and told\nher my informal suggestion was not to respond to the letter.”\n\nIn mid-August 2010, Andrew J. Klein, President Obama’s senior adviser for\nintellectual enforcement, invited leaders of the top Internet domain name\nregistrars and registries to attend a three-hour meeting at the White House to\ndiscuss voluntary ways to shutter websites selling counterfeit prescription\ndrugs.\n\nThe invitation was sent via email to dozens of executives and attorneys at\nsome of the world’s largest Internet companies, including Google, Microsoft,\nPayPal, Visa, and Yahoo! The recipients were invited to attend a meeting on\nSeptember 29 with senior White House and Cabinet officials, including Victoria\nEspinel.\n\n“The purpose of this meeting is to discuss illegal activity taking place over\nthe Internet generally and, more specifically, voluntary protocols to address\nthe illegal sale of counterfeit non-controlled prescription medications\nonline,” the invitation stated.\n\nMultiple people who attended the event called it more of an ambush than a\ncollaborative meeting of the minds to solve a tough problem, and said that\nEspinel essentially told attendees that they needed to work out a voluntary\napproach—or else.\n\n“She basically got a bunch of big brand holders in the room to say, ‘You guys\nneed to do something about this or something will be done to you,’” UCSD’s\nSavage said, recalling a conversation with an attendee.\n\nThough few knew about it at the time, one of the firms invited—Google—was\nalready under criminal investigation by the U.S. Justice Department for\nactively courting fake Canadian pharmacies—including many rogue Internet\npharmacies created by SpamIt and Rx-Promotion—to advertise drugs for\ndistribution in the United States.\n\nThe implications of this case were huge. One of the ways that affiliates for\nGlavMed promoted their pharmacy sites was by hacking websites. Affiliates\nwould insert dozens of links and even entire web pages into hacked sites that\nredirected visitors to sites peddling knockoff prescription drugs. The more\nhacked legitimate sites that affiliates had pointing to their pharmacy stores,\nthe greater their ranking would be in the major search engine results when\nconsumers searched for specific drug names. This process—known in the\nunderground as “black search engine optimization,” or “black SEO” for\nshort—was a major driver of pharmacy sales for affiliates of both Rx-Promotion\nand GlavMed-SpamIt.\n\nIt was bad enough that Google’s search results were constantly being gamed by\nspammers. For Google to also be taking money from unregulated and potentially\nspammer-affiliated online pharmacies was beyond the pale. According to the\nJustice Department, Google was aware as early as 2003 that Canadian pharmacies\nwere illegally shipping prescription drugs into the United States.\n\nGoogle would later settle criminal charges in connection with the case and\nagree to pay a whopping $500 million in fines. One of the largest forfeitures\never paid to the Justice Department, the fine was intended to represent the\ncompany’s advertising revenue from the Canadian pharmacies and the revenue the\npharmacies received from American customers buying controlled drugs.\n\nLess than two months after the White House meeting, Espinel stood at the\npodium in a press conference at the White House. Flanked by U.S. Attorney\nGeneral Eric Holder and then Department of Homeland Security Secretary Janet\nNapolitano, Espinel announced the creation of a new nonprofit entity to battle\nrogue Internet pharmacies.\n\n“A group of founding private-sector partners announced today that they will\nform a new nonprofit to work with each other and the U.S. government to rid\nthe Internet of illegal Internet pharmacies,” Espinel explained, naming the\nnonprofit members as American Express, eNom, GoDaddy, Google, MasterCard,\nMicrosoft, Network Solutions, Neustar, PayPal, Visa, and Yahoo.\n\n“This group of companies has taken an extraordinary and unprecedented step to\ncombat illegal online pharmacies,” Espinel told a packed press room and CNN\ncameras. “We believe this will have a rapid and dramatic effect on illegal\nonline pharmacies. This will change the rules of the road and make clear that\nlegitimate companies will not interact with criminal actors.”\n\nThere was only one problem with the whole announcement. Few at the companies\nnamed as members could remember having agreed to form such a nonprofit.\n\n“Prior to that news conference, the participants from those companies had a\nroundtable conference call to talk about it, but nobody went into that meeting\nplanning to agree to form that group,” Warner said. “The people I spoke to who\nwatched that announcement saying they’d agreed to form that group came out\nafterwards and were like, ‘We did?’”\n\nEighteen months after the creation of the nonprofit that was first announced\nby Espinel at the White House gathering, the group had yet to hold its first\nmeeting. At the same time, the NIPR case was being closed. The Pfizer security\nchief’s warning would turn out to be eerily prescient. According to sources\nfrom two separate federal law-enforcement agencies who asked not to be\nidentified because they were not authorized to speak on the record, the\ninvestigation into the core spammers and hackers employed by GlavMed and\nSpamIt was abandoned in part because most of the perpetrators were believed to\nbe in Russia and former Soviet nations, countries that were typically less\nthan cooperative with Western law-enforcement agencies seeking to apprehend\ncybercriminals within their borders.\n\nGiven the lack of interest by federal regulators in methodically testing drugs\nordered through these fly-by-night online pharmacies, it remains unclear\nwhether the bulk of these drugs contain adequate amounts of the active\ningredients without also mixing in harmful contaminants that could hurt or\neven kill people who ingest them.\n\nThis inaction appears to suit the pharmaceutical industry, which is wary of\ntesting and getting results that might indicate that the vast majority of the\nprescription drugs ordered through spam are far cheaper and no less safe than\nthe same pills ordered through a local pharmacy.\n\nUnfortunately, the lack of objective data about the safety and efficacy of\nspam-ordered prescription drugs does little to dampen demand, while continuing\nto expose consumers to a dangerous game of Russian roulette.\n\n\nChapter 6\n\n## PARTNER(KA)S IN (DIS)ORGANIZED CRIME\n\nThere’s a famous quote from Sun Tzu’s The Art of War that applies to my\nresearch and motivation for writing this book: “Know your enemy.” Indeed, with\nsome understanding of what motivates these spam pharmacies and their\ncustomers, it’s time to look at how spam operations actually work. The driving\nforce behind the success of programs like GlavMed and Rx-Promotion—and the\nengine that propels virtually every cybercriminal collaborative effort—is an\narrangement known in Russia as the partnerka—literally, a “partnership.”\nPartnerkas such as GlavMed and Rx-Promotion seek to match dodgy advertisers\nwith businesses that are willing to purchase the web traffic that can be\ngenerated through spam.\n\nMany legitimate businesses that are searching for more customers—principally\nsmall businesses based in Russia and Eastern Europe—will try to raise\nawareness of and demand for their products or services by hiring a spammer.\nWhile using hacked computers to send junk email is technically illegal in\nRussia, many legitimate businesses there remain unaware or unafraid of this\nprohibition.\n\nIndeed, as we’ll see in [Chapter 7](07_chapter07.xhtml), our “Virgil” in the\nspammer underworld—Cutwail botnet bankroller Igor Vishnevsky—got his start in\nspamming when his boss ordered him to figure out how to drive more traffic to\nhis heating company’s website.\n\nIn fact, when the Cutwail spam botnet is used to send spam to email addresses\nending in “.ru,” the messages very often include a Russian phone number where\nrecipients can inquire about ordering spam advertisements for their own\nproducts and services.\n\n“I’ve seen pretty much everything from e-cigarettes to office space to resorts\nadvertised in this way,” said Brett Stone-Gross, a University of California\nresearcher who has studied the Cutwail botnet’s operation for years.\n\nIn a typical spam partnerka, the individuals who run the operation—the\nsponsors—assume responsibility for coordinating and maintaining almost every\naspect of the business, from the web content to customer service, to\nnegotiating with suppliers and setting up the web servers and domain names\nneeded to advertise the product for sale.\n\nThe only role of the spammers (sometimes referred to as “adverts” or\n“traffers”) is to drive traffic to the websites where the goods advertised in\nthe spam are sold, and they can walk away from the deal at any time. Spammers\nare typically paid commissions that equal 30 to 35 percent of the total sales\ngenerated by their traffic. It’s a fairly lucrative business for them,\nprovided their traffic actually generates paying customers.\n\nThis dynamic of partnerka systems allows the sponsors to maintain a safe\ndistance (in theory, at least) from the more illicit aspects of the spam\nbusiness—which typically uses hacked PCs by the thousands to relay spam and to\nhost pharmacy websites. The adverts benefit from the arrangement by being able\nto quickly unplug their traffic from one partnerka program in favor of another\nthat may offer more attractive terms—such as higher commissions, better\ncustomer service, and greater product selection—that increase their likelihood\nof attracting customers through their spam. And there are multiple types of\npartnerships, including those that peddle replica watches, porn, knockoff\ndesigner handbags, and fake antivirus software as well as pharma spam. When\nspam emails show up in your inbox or get caught by your firewall, spam filter,\nor antivirus software, they’re likely from one of these partnerkas.\n\nTechnology and security experts like to talk about these partnerkas as\n“organized cybercrime.” But according to UCSD’s Stefan Savage, partnerka\nsystems are more accurately described as “disorganized crime”—that is, loosely\naffiliated networks of independent contractors, each of whom is essentially\nout to make a buck for himself and will only continue the partnership so long\nas it remains economically viable and competitive to do so.\n\n“It’s really a brilliant business model on both sides,” said Savage, who has\ncoauthored several long-term studies on various aspects of the partnerka\neconomy, from spam to botnets. “On the affiliate side you don’t need to learn\nabout all the stuff like payment processing and fulfillment; you just have to\nfigure out how to get traffic. Also, you have a great deal of flexibility—if\none partnership goes offline or has better rates, you can move to someone\nelse. So the partnerka model really offers incredible mobility to the\naffiliate, because they’re not tied to anything.”\n\nSavage said the partnerka programs themselves benefit from the arrangement by\nnot having to deal with the potential risks of being technically associated\nwith botnets and other inventive yet potentially harmful (and legally murky)\nways that their spammers may dream up to generate traffic.\n\n“It’s a win for the affiliate program because they don’t need to make a bet on\nwhat’s the best way to get traffic,” he said. “The affiliate program says,\n‘Most of these guys [the spammers] are going to get screwed, but I don’t care\nbecause I pay on a commission basis only. Someone is going to get this right,\nand when they do, I’ll make money off of it.’”\n\nAs a result of the partnerka dynamic, most spammers also have no allegiance to\nany one pharmacy partnerka program. For example, almost all top spammers for\nboth GlavMed and Rx-Promotion partnered with at least a half-dozen other\npharmacy partnerkas, including EvaPharmacy, Bulker.biz, Rx-Partners, and\nMailien. This dynamic presents perhaps the most frustrating problem of all for\nanti-spam crusaders trying to stem the flow of junk email. Much as squeezing\nan inflated balloon doesn’t make the balloon any smaller but instead merely\ndisplaces the air into new bulges, anti-spam campaigns that succeed in\nshuttering one partnerka or a major component of that operation often result\nin the most successful affiliates simply shifting their spam traffic to\ncompeting partnerkas.\n\nAs Dmitry Samosseiko, a security expert with SophosLabs Canada, noted in his\nseminal paper, “The Partnerka—What Is It, and Why Should You Care?”, all\npartnerkas are in strong competition with each other.\n\n“Allegiance is earned through more generous commission rates, shorter ‘hold’\nperiods, support for a wider range of payment systems, higher quality\npromotional material, better support, etc.,” Samosseiko wrote. Partnerkas\ntypically place a one- to two-week hold on paying affiliate commissions to\nhedge against the possibility of having to pay all affiliates at the same time\nand to ensure that affiliates do not receive commissions for sales later\nreversed by credit card processors.\n\nSamosseiko said partnerkas frequently use competitions and other gimmicks to\nattract more affiliates (spammers). “Many organize expensive parties for their\nmembers, send generous gifts for holidays, run lotteries where a top producer\nwins a luxury car, and the list goes on,” he wrote.\n\nThese incentives also drive up the amount of email spam we receive. For\nexample, in 2008, Stupin and Gusev—the founders and administrators of GlavMed\nand SpamIt—decided to sponsor a competition among their top spammers, with\nhefty cash prizes going to those adverts whose spam generated the greatest\nnumber of sales. Each participant was given a list with approximately 20,000\nemail addresses, and the contest began on July 4, 2008, Independence Day in\nthe United States.\n\nThe first three finishers were awarded prizes of $1,000 to $3,000, and were\nbestowed with “Master of Inbox” status on Spamdot.biz, an exclusive forum\nowned by the SpamIt administrators. (The winner of that competition, a hacker\nnicknamed “Engel,” was the Russian man allegedly behind the “Festi” spam\nbotnet, an extremely virulent and powerful spam-spewing machine, as detailed\nin [Chapter 7](07_chapter07.xhtml). Incidentally, Engel and his botnet would\neventually catapult Vrublevsky and himself toward a dangerous collision with\nthe law, as we’ll see in [Chapter 12](12_chapter12.xhtml).)\n\nIn their seminal paper, “PharmaLeaks: Understanding the Business of Online\nPharmaceutical Affiliate Programs,” researchers at the University of\nCalifornia, San Diego (UCSD), the International Computer Science Institute,\nand George Mason University examined caches of data tracking the day-to-day\nfinances of GlavMed, SpamIt, and Rx-Promotion, which collectively over a four-\nyear period processed more than $170 million worth of orders from customers\nseeking cheaper, more accessible, and more discreetly available drugs.\n\nThe result is perhaps the most detailed analysis yet of the business case for\nthe malicious software and spam epidemics that persist to this day. The\nresearchers concluded that spam—and all of its attendant ills—will remain a\nprevalent and pestilent problem because consumer demand for the products most\nfrequently advertised through junk email remains constant.\n\n“The market for spam-advertised drugs is not even close to being saturated,”\nsaid UCSD professor Stefan Savage. “The number of new customers these programs\ngot each day explains why people spam. Because sending spam to everyone on the\nplanet gets you new customers on an ongoing basis, so it’s not going away.”\n\nAffiliates understand this deeply, and like regional drug dealers who stake\nout huge swaths of online territory, they frequently squabble with one another\nout of jealousy or animosity, or in retribution for some perceived slight.\nThese virtual turf wars can quickly become quite ugly and expensive for all\ninvolved. This is especially true when disputes break out between competing\npartnerkas, because most of the top affiliates are big-time spammers with\nextremely powerful botnets at their disposal.\n\nSuch disputes also are expensive because of the opportunity costs involved.\nThe crippling attacks are carried out via botnets, by diverting resources that\nnormally are used to send spam so that they instead send junk Internet traffic\nuntil the targeted website is overwhelmed and can no longer accommodate\nlegitimate visitors (that is, potential buyers).\n\nIn their “PharmaLeaks” paper, the UCSD researchers discovered that just 10\npercent of the highest-earning affiliates accounted for 75 to 90 percent of\ntotal program revenue across all three affiliate programs.\n\n“Undermining the activities of just a handful of affiliates would have\nconsiderable effect on a program’s bottom line,” the researchers wrote.\n\nThe shadowy bosses at the head of various partnerka programs identified this\nweakness as an existential problem early on. To remedy it, the crime bosses\nsought to establish a virtual cartel for online pharmacy partnerkas that was\ndesigned to prevent inter-partnerka disputes, price wars, and affiliates\nstampeding from one pharmacy program to the next at a moment’s notice. The\npartnerka bosses believed that such a deal would reduce overhead costs and\nepisodic dips in overall spam volumes, and ultimately ensure a more consistent\nflow of junk email into inboxes everywhere.\n\nTo facilitate this, on September 4, 2007, Dmitry Stupin told his partner Igor\nGusev that he would like to see SpamIt and GlavMed enter into a pharmacy\ncartel with other partnerka programs. A week later, Gusev arranged a meeting\nto discuss the idea with Leonid Kuvayev, a convicted spammer who was\ncoadministrator of Rx-Partners, a competing pharmacy spam program.\n\nAround that same time, Pavel Vrublevsky was reportedly setting up his own\nrogue pharmacy operation—Rx-Promotion—in conjunction with a coworker and\nlongtime friend, Yuri “Hellman” Kabayenkov. Vrublevsky denies playing an\nactive role in Rx-Promotion, but according to emails leaked from ChronoPay,\nVrublevsky had a meeting with Rx-Partners’ Leo Kuvayev and Kuvayev’s\npartner—Vladislav Khokholkov—to discuss Rx-Promotion’s participation in the\nstill nascent cartel. In the leaked emails, Vrublevsky claims to have declined\nparticipating in the cartel, but said that Mailien, SpamIt, and another large\nprogram—EvaPharmacy—had agreed to set price controls on drugs and to cap\naffiliate commissions at 40 percent.\n\nChat logs that Russian investigators eventually seized from Stupin’s computer\nsuggest that the cartel worked assiduously to win over EvaPharmacy. Below is a\ntranscript of a chat between Stupin and representatives of Eva (also known as\n“Bulker.biz”). Their chat has been translated from Russian into English.\n\nSTUPIN: I don’t like the conditions we give to adverts. Some of them demand 45\npercent. We suffer from it because of low prices, plus some of them are asking\nto lower hold to one week. I want to straighten them up and pay more to myself\nthan to them ;) We do not offer less than two-week hold to anyone. Simply\nbecause of delays in payments from Shaman and the islands (off-shore), our\naccount balances are going down.[9](06_chapter06.xhtml#fn9) I am not asking\nyou about anything, just saying that you also can set a minimum hold to two\nweeks and then adverts will not have a choice, because we will offer similar\nconditions. I also think that it is going to be easier for you to pay with the\nhold time than without it, because if adverts raise production, you need to\nkeep too much cash in banks. In summary, my utopia is a cartel agreement to\nlower advert commissions to 30 to 35 percent, similar to the payoffs of\nWestern affiliation programs.\n\nBULKER.BIZ: We also have two weeks of hold. However, we do exclude our best\nadverts [from that restriction]. You forced a lot of our adverts to switch to\nyou by lowering your prices. Therefore, we have no other choice ;) To have an\nagreement is a great idea, yet for it to work, it needs to include Mailien and\nothers. Otherwise, spammers will continue to run to them. Surely, 45 percent\nis just outrageous! The partnerka earns three times less because of that!\n\nSTUPIN: Yes, and the only argument for asking for 45 percent, is that Eva pays\nthat much ;)\n\nBULKER.BIZ: Some people pay even 50 percent and are killing the market even\nmore. I also want to say that I know which advert you are talking about. He\ndoes not have a hold at all, but it does not mean that he costs us the entire\nbalance every day.\n\nSTUPIN: I know, he told me everything.\n\nBULKER.BIZ: Listen, we are willing to strike an agreement and to establish the\nsame conditions with adverts, but only after we test new suppliers and are\nable to lower our prices to match or to be close to yours, only when our\ncompetitive conditions are similar.\n\nAccording to Vishnevsky, who was active in the development of the Cutwail\nbotnet, the findings by the UCSD researchers show that about a handful of\naffiliates generating the bulk of the revenue for partnerka programs are\naccurate. Vishnevsky said very few affiliates who did not already own\nsignificant spamming resources could expect to make much money because of the\ncosts involved in creating those.\n\nThe most expensive part of any spamming operation is the process of procuring\nthe bots used to relay junk email. Almost without exception, the top-earning\naffiliates ran their own very large botnets, crime machines that they used to\nsend their own spam and that were rented out to other affiliates.\n\nVishnevsky said affiliates who rent botnet resources from other spammers\nfrequently do so by purchasing “installs,” or seeding a prearranged number of\nbots with an additional malicious program that sends spam for the affiliate.\nAffiliates who rent bots from fellow affiliates often will pay for those\nresources by simply diverting a share of their commissions on each sale from\nspam generated by the rented bots. Very often, Vishnevsky said, botmasters\nwould demand up to 50 percent of an affiliate customer’s commissions.\n\nBut a proper spam-spewing network consists of much more than just bots. If we\ncompare a spam network to a factory, the bots can be thought of as the\nmachinery responsible for assembling the component parts of the product for\nsale. And a spam botnet is only as effective as the software that directs the\nday-to-day activities of that machinery. Modern PCs are extremely powerful\nsystems, but they can quickly become overwhelmed if too many operations are\ndemanded of them simultaneously. Decent spam software distributes the workload\nacross thousands of infected machines, ensuring that individual PCs aren’t\nbeing overpowered by more work than they can handle.\n\nAt the same time, good spam software is responsible for keeping track of how\nmany emails were successfully delivered and how many recipients clicked\nthrough to the advertised site. The software also is expected to automatically\ndelete or “scrub” from spam lists any email addresses that are no longer\nactive or that refuse to accept incoming email. Spammers often “spoof” or fake\nthe address in the “From:” section of a junk email, and when spam messages are\nsent to inactive inboxes, the messages frequently bounce back not to the\nspammers but to the unwitting person whose email address was used to spoof the\nemail’s origin! (No doubt you may have been on the receiving end of one of\nthese from a friend, colleague, or relative whose email account was hacked or\nspoofed.) Emails that bounce like this prompt confused and concerned Internet\nusers to complain to their Internet or email providers, or both, which in turn\nmay enact more stringent measures to block such wayward messages in the\nfuture.\n\nFinally, an affiliate who doesn’t already have decent email lists will have to\nbuy them from someone else, if he cannot write his own program to continuously\nharvest new email addresses from random websites.\n\nAccording to Vishnevsky, an affiliate can expect to spend 20 to 30 percent of\nhis income on renting software and email lists.\n\n“It should not be surprising that most spammers do not make much money if they\nhave to rent all of these things,” he said.\n\nIt’s impossible to say how much organizations worldwide spend fighting junk\nemail sent by the likes of affiliates of Rx-Promotion, GlavMed, and SpamIt,\nbut it is almost certainly many, many times more than the profits eked out by\nthe administrators and founders of those programs.\n\nWhat’s mind-boggling is that when the UCSD researchers calculated the direct\nand indirect costs of these programs during an eleven-month period between May\n2009 and April 2010, they found that the net profit for these programs was\nabout 20 percent of gross revenue.\n\n“What’s fascinating about all this is that at the end of the day, we’re not\ntalking about all that much money,” said UCSD’s Savage. “These guys running\nthe pharma programs are not Donald Trumps, yet their activity is going to have\nreal and substantial financial impact on the day-to-day lives of tens of\nmillions of people. In other words, for these guys to make modest riches, we\nneed a multibillion-dollar security industry to deal with them.”\n\nSavage and his research team also had a chance to review many of the leaked\nchats between Gusev and his business partner Stupin, and said the\nconversations were replete with examples of how these guys were constantly\nlooking for ways to add value to their consumer offerings. Guys like the\nSpamIt administrators succeeded because they understood their core market:\nselling discreetly delivered and affordable products—from online porn to penis\npills—that many adults would be ashamed to buy otherwise.\n\nAt one point, the chats show that Stupin and Gusev considered using their spam\ninfrastructure to promote a far more questionable consumer product: penis-\nextending devices.\n\n“This is by far the funniest conversation in the whole collection,” Savage\nrecalled. “It’s basically Gusev fighting with Stupin over whether or not they\nshould add penis-extender devices to their online shops. Gusev is totally into\nthe idea. He’s like, ‘Yeah, Americans really want to add inches,’ but Stupin\nis unconvinced. And that’s the thing I try to explain to people [based on] all\nof our research into this bizarre underground economy.\n\n“The pharma and spam guys don’t fundamentally think of themselves as criminals\nat all. I think their mental model is that they’re selling a quality product\nto an audience that is demanding it. Yes, there may be some laws in their way,\nbut those laws are tools of a Western power structure and bourgeoise\nintellectual-property bullcrap, and it’s just The Man getting in the way of\ntheir marketplace.”\n\n♦ ♦ ♦\n\nIf Savage is correct—that partnerkas represent “disorganized cybercrime”—then\nthe role of creating and maintaining order from all of this criminal chaos\nfalls to the cybercrime forums. These are online communities where most\nspammers, scammers, and fraudsters meet, transact, earn, and maintain a\n“trustworthy” reputation in the underground.\n\nCybercrime forums serve a number of core purposes. For starters, they offer\nrelatively unknown and novice criminals an opportunity to establish a\nreputation as a trusted, reliable vendor or buyer of services. If these\nnewbies wish to construct a new cybercrime operation—such as a spam botnet—but\nlack the knowledge or resources to build up a particular component of that\nbusiness, they can simply purchase the missing components or information from\nother members. Or, they can turn to senior members and self-help tutorials on\nthese forums for pointers and questions.\n\nIn this way, crime forums almost universally help lower the barriers to entry\nfor would-be cybercriminals. Crime forums also offer crooks with disparate\nskills a place to market and test their services and wares, and in turn, to\nbuy ill-gotten goods and services from others.\n\nThere are forums dedicated to almost every major language and specialization\nof cybercrime, but most crime forums are either in Russian or English.\nLikewise, most are built upon a similar structure of a main homepage with\nlinks to sub-forums dedicated to a broad array of cybercrime specialties,\nincluding: spam; online banking fraud; bank account “cashout” schemes;\nmalicious software development; identity theft; credit card fraud; confidence\nscams; and black SEO, or techniques to fraudulently manipulate a site’s\nrankings in Google and other Internet search engines.\n\nEven forums dedicated to a specific form of cybercrime—such as spam—tend to\nmodel themselves on this same sub-forum structure. In 2011, researchers at the\nUniversity of California, Santa Barbara, and Ruhr-University Bochum in Germany\npublished an in-depth analysis of the Cutwail botnet, “The Underground Economy\nof Spam: A Botmaster’s Perspective of Coordinating Large-Scale Spam\nCampaigns.” In the course of their investigation, the researchers acquired the\nback-end database of the now-defunct crime forum Spamdot.biz, a closely\nguarded cybercrime community, and ultimately agreed to share the site’s\ncomplete information with me for research for this book. In 2007, Spamdot came\nunder the ownership of Igor Gusev and Dmitry Stupin, the coadministrators of\nthe sister pharmacy partnerkas GlavMed and SpamIt.\n\nIt was clear from this material that while Spamdot counted among its members\nsome of the world’s most established and successful spammers, it also included\ndozens of members whose primary specialty was offering ancillary cybercrime\nservices, from providing bulletproof web hosting and the mass registration of\ndomain names, to selling huge email spam lists and software to help spammers\n“scrub” their existing lists of dead addresses and those used by anti-spam\nactivists and security firms.\n\nThese activists frequently seed the Internet with dummy email addresses in the\nhopes that spammers will find and spam the addresses. Both vigilantes and\nsecurity firms then use the spam sent to these dummy addresses to collect\nsamples of the latest malicious software or phishing scams being distributed\nvia junk email. These help gauge the size and location of major spam botnets,\nand from there, these anti-spammers can generally improve the performance of\nspam filters. But since these activities eventually tend to cut into the\nprofitability and stability of any spamming operation, more experienced\nspammers recognize the long-term value in scrubbing their distribution lists\nof these decoy addresses. It’s a constant game of cat and mouse.\n\nSub-forums tend to be moderated by established cybercrooks who are proficient\nin their respective specialization. It is not unusual to see the same\ncybercriminal acting as the moderator of the same sub-forum across multiple,\ndistinct cybercrime forums. For example, an infamous Russian fraudster known\nas “Severa” acts or has acted as the moderator of the spam sub-forum on at\nleast four different major cybercrime forums, including Spamdot. As will be\nfurther described in Chapter 7 (“[Meet the Spammers](07_chapter07.xhtml)”),\nSevera is the author of some of the most prolific and “successful” spam\nbotnets that have ever been created. As a result, Severa knows virtually\neveryone of consequence in the spam industry and has a broad cross-section of\nknowledge about the topic that makes him ideally suited to moderate discussion\nforums dedicated to the subject.\n\nActors such as Severa are the living “glue” holding these cybercrime\ncommunities together. They possess a wealth of knowledge about their industry\nand are adept at connecting novices with more experienced members looking for\npartners or subcontractors. As such, core miscreants like Severa present\nattractive targets for law-enforcement officials, since taking them out can\noften destabilize the fraud ecosystem.\n\nMany crime forums—particularly new, fledgling forums—allow open registration,\naccepting all comers. But forums populated by some of the most experienced and\nconnected cybercrooks tend to erect various hurdles for new members designed\nto screen out useful and talented hackers from hangers-on or, worse, possible\nlaw-enforcement officials attempting to infiltrate and gather evidence of\nthese spammers’ illicit activities. To create these safeguards, most\nestablished crime forums require new applicants to list at least two existing\nand trusted forum members as references or “vouches,” signaling that one or\nmore existing members of the forum can vouch for the applicant’s skills and\nintegrity and have invited the novice to apply for membership.\n\nNew applicants generally also must proffer a nonrefundable deposit, usually in\nthe form of a digital currency such as WebMoney or bitcoins. Assuming the\napplicant’s references confirm that members know him and can vouch for his\nskills, the applicant is granted limited access to the forum, which he can\nthen use to introduce himself to the broader community, plead his case for\nmembership, and list any unique talents that his full membership would bring\nto the forum.\n\nExisting members may use this trial period to haze or verbally abuse the\napplicant, or to test his knowledge of programming, hacking, or skill sets\nrelated to his claimed area of interest or speciality. This weeds out the\nweakest novices. In the end, however, many forums are democratic, leaving the\napproval of an applicant’s permanent membership to a vote in which all\nestablished members may—but are not required to—participate.\n\nSo what’s the incentive to join these forums and why are they so popular among\nspammers? Much like a castle once provided its inhabitants with protection\nfrom marauding raiders and bandits, crime forums offer full members a modicum\nof protection (or at least cause of action) against getting ripped off.\nFraudsters are particularly vulnerable to being cheated out on their own\nbecause they lack the ability to report being victimized to local authorities.\nAfter all, the transactions in which they engage are in most cases illegal. To\ncombat any such “ripping” activity, forums enforce a strict code of ethics so\nthat members caught trying to cheat fellow members are quickly ostracized or\nbanned.\n\nFor starters, most established forums will offer an escrow service—a small\npercentage of the transaction cost—that will hold the buyer’s funds until he\nis satisfied that the seller upheld his part of the bargain. Legitimate and\nlongtime forum members tend to insist on the use of escrow for all\ntransactions, while cheapskates and less experienced members eschew this\noffering at their own risk.\n\nMuch like the online auction house eBay encouraging users to leave positive or\nnegative feedback based on the quality of the transactions they conduct with\nother members, a fraud forum member’s standing is governed in part by the\nnumber of reputation or “rep” points he has accrued during his time on the\nforum. Members can earn rep points simply by being regular, active\nparticipants in various forums’ discussion threads—essentially sharing their\nknowledge and experience on a range of computer crime topics. The rep points\nare awarded or subtracted by established forum members and moderators who have\nearned the right to bestow or revoke such status indicators.\n\nThis system is remarkably effective at regulating the criminal acts of these\ncrooks against each other. Aleksey Mikhaylov, a native Russian and information\nsecurity expert who has exhaustively reviewed the documents, chats, and other\nmaterial leaked from the Spamdot forum, said that the threat of a single\nnegative post on the forum prompts these guys to amicably resolve issues worth\ntens of thousands of dollars. Access to the forum and their “standing” there\npreoccupies all of them. Without the protection and accountability afforded by\nthese criminal havens, spammers, scammers, and other online ne’er-do-wells are\nat much greater risk of getting fleeced by their contemporaries.\n\nMembers judged by forum administrators as guilty of multiple or serious forum\nrule infractions may be assigned the rank of “deer,” or even the more serious\n“ripper” label. A deer marker usually is an indicator of a new member who has\nviolated the forum rules by accident, or because he isn’t yet familiar enough\nwith them. Forum members who earn a deer status tend to be considered clueless\nnewbies, their status alerting fellow forum members that dealing with them\nmight be more trouble than it’s worth.\n\nRippers are those who have been shown to have “ripped” someone off by failing\nto consummate a previously agreed-upon transaction—either by refusing to pay\nfor a service or good, or by neglecting to deliver on these as promised. The\naggrieved party must demonstrate to forum administrators that he or she was\nripped, typically by starting a discussion thread in a sub-forum called\n“blacklist.” Very often this means posting lengthy online chat records of a\nprevious conversation that document the alleged infraction. Interestingly,\nthese self-reported records can often present invaluable evidence and\nintelligence to undercover law-enforcement officials and security researchers\nwho frequently lurk on underground crime forums.\n\nAlthough the average crime forum has many members—sometimes tens of\nthousands—most of the more active forums exist to make money for the\nadministrators, the subforum leaders, and those selling turnkey services or\nsolutions to the rest of the community. The top sellers pay to have their\nsales threads made into “stickies” so that the sales pitches stay at the top\nof their respective sub-forums and are thus more likely to be to read by\npeople seeking help in those cybercrime specializations. Depending on the\nforum, these stickies are sold annually or monthly, and range in price from a\nhundred to thousands of dollars per month.\n\nOver the past few years, the number of new cybercrime forums has skyrocketed,\nillustrating a burgeoning demand for criminal services and a robust\ncompetition among them for customers. And while many new crime communities\ndisappear or fizzle out shortly after their creation, others are now more than\na decade old, suggesting that the cybercrime industry is quite mature, each\nmarketplace with its own unique means of self-policing, networking, and rapid\ninformation sharing.\n\nAttempts by anti-spam activists to shutter the more mature of these cybercrime\ncommunities—usually by applying pressure to their hosting providers or domain\nregistrars, or both—ultimately backfire. The forums simply transfer their\ndomains to another, more bulletproof and insulated hosting provider, often\nenacting more stringent security measures in the process that more carefully\nscreen new and existing members for signs of lurkers, law-enforcement\nofficials, and researchers.\n\nBut there’s hope: Some of the most successful efforts at tackling the spam and\nmalware epidemics have focused on identifying and apprehending the world’s top\nspammers and dismantling their crime machines, as we’ll see in the next\nchapter and in Chapter 11: [Takedown](11_chapter11.xhtml).\n\n* * *\n\n[9.](06_chapter06.xhtml#fnr9)The name “Shaman” in this chat conversation is a\nreference to the nickname of Nikolai Victorovich Illin, the forty-three-year-\nold computer whiz behind Gateline.net. Gateline was a credit card processor\nthat SpamIt, GlavMed, Rx-Promotion, and other partnerkas apparently prized for\nits ability to process MasterCard transactions. Stupin and Gusev considered\nShaman a key and equal partner in their business.\n\n\nChapter 7\n\n## MEET THE SPAMMERS\n\nIgor Vishnevsky wouldn’t have known where or how to get started in the\nspamming business had it not been for the connections he made spending\ncountless hours on several major cybercrime forums at the time. At nineteen\nyears old, he enrolled at a university in Moscow and had dreams of landing a\njob as a programmer at a legitimate company. But soon enough, the money dried\nup.\n\n“I studied three years, and then my parents stopped paying for my education\nbecause they didn’t have money,” Vishnevsky said in an interview.\n\nWhat little Vishnevsky knew of computers dated back to his time as a teenager,\nwhen his parents bought him a Sinclair ZX Spectrum, an early home computer\nthat was among the first mainstream home computers sold in Europe. In his\nearly years, Vishnevsky taught himself everything from BASIC to more complex\nassembly programming languages. Later, he acquired a second-hand PC and\nlearned PASCAL, a programming language designed to teach students how to\ndevise more complex software programs.\n\nThe clever young hacker was making between $200 and $300 per month creating\nporn websites as part of an affiliate program run by Vrublevsky’s Crutop.nu.\nBut that was hardly enough to live on in Moscow, so he took a job at a local\ncompany that sold heating and air-conditioning equipment and services. Little\ndid he know that would lead to spamming.\n\nOne day his boss asked for help in advertising the company’s services via some\nless-than-legitimate means.\n\n“One time, my boss ordered spam from someone and told me that it was cool and\nthat I should find out how to send spam myself,” Vishnevsky recalled. “Of\ncourse, I told him that spam was bad, blah, blah, blah, but he told me that we\nhad a lack of orders and I have to do that [in order to drum up more\nbusiness].”\n\nVishnevsky’s research for his boss into the spam industry led him to\nCarderplanet.com, which at the time was an extremely popular Russian language\ncybercrime forum. Carderplanet drew thousands of members from around the world\nwho traded knowledge and tips on everything from running spam botnets to\ncashing out hacked bank and credit card accounts.\n\nFounded in Ukraine in 2001, Carderplanet.com was the most brazen collection of\ncarders (crooks who traffic in stolen credit cards) hackers, and cyberthieves\nthe Internet had ever seen. As Joe Menn writes in his book, Fatal System\nError, there was virtually no enforcement of computer intrusion laws in\nUkraine, so the group felt secure enough to organize parties and to advertise\ntheir hacking services on the larger Internet. Carderplanet would come to be\nthe mold out of which nearly every future crime forum would be modeled, with\nsub-forums for every imaginable form of computer crime specialization.\n\nIt was on Carderplanet that Vishnevsky was introduced to Vardan Kushnir, a\nthirty-five-year-old notorious spammer who ran the American Language Center\n(ALC), a legitimate business in Moscow that taught English to Russian\nnationals. Kushnir offered to help get Vishnevsky started in spamming if he\nwould agree, in turn, to use some of his resources to send junk email\nadvertising the services of the ALC.\n\n“He offered me money enough to rent servers, and soon I was making four times\nas much as the climate company was paying,” Vishnevsky said. “But I continued\nto work there because I was not sure that spam was a stable source of money.\nWithin a couple of months I was already quite good with spam.”\n\nThrough spamming for his mentor Kushnir, Vishnevsky was introduced to Dmitry\n“Gugle” Nechvolod.\n\n“Gugle was Vardan’s friend, and he was always coming to him discussing\ndifferent shit,” Vishnevsky said. “At some point, I started to communicate\nwith [Gugle], too.”\n\nBut Vishnevsky’s real break came after his spamming mentor was suddenly and\nbrutally murdered. One morning, Kushnir’s mother found her son’s bloodied\ncorpse on her bathroom floor, his skull bashed in. As detailed in a 2007 story\nin Wired.com, Kushnir’s spam operation sent more than 25 million unsolicited\njunk messages each day, most of them pimping the ALC’s services and sent to\nRussian inboxes. According to Wired and Vishnevsky, Kushnir’s blatant and\nrepeated disregard for complaints about spam pimping the ALC may have been a\nprimary contributor to his murder.\n\nUndeterred by Kushnir’s gruesome death, Vishnevsky and Gugle pooled their\nresources and started their own spam business.\n\nBy October 2011, I decided there was enough information in the leaked SpamIt\nand Rx-Promotion data to begin identifying and profiling the world’s top\nspammers, and by extension those responsible for building and maintaining the\nlargest spam botnets. Buried within the gigabytes of internal ChronoPay\ndocuments was a Microsoft Excel spreadsheet innocuously titled “Registration\ndata” that would become the Rosetta Stone for identifying many of these\nmiscreants.\n\nWhen I compared the information in this spreadsheet with other earnings and\ncontact information I’d already gathered from the leaked SpamIt data, it was\nclear that for unknown reasons, someone at ChronoPay had compiled this list\nabout the most active spammers. Most of the spammers for both Rx-Promotion and\nSpamIt were paid via WebMoney, which, as mentioned, is a virtual currency like\nPayPal that is popular in Russia and Eastern Europe and widely used in the\nhacker underground.\n\nWebMoney accounts can be set up under pseudonyms or as merchant accounts, or\nthey can be formally attested. The latter two types of accounts require the\napplicant to show a copy of his passport at an authorized WebMoney location\nprior to obtaining attestation for that account. This account information is\nnot listed publicly by WebMoney, but it appears that a ChronoPay employee paid\nan insider at WebMoney to divulge the name and other contact information tied\nto each account used by top SpamIt affiliates. As it turns out, many of those\nindividuals also spammed for Rx-Promotion.\n\nOf the 163 WebMoney accounts listed in that spreadsheet, roughly one-third of\nthem were formally attested or were merchant accounts. The data included in\nthe spreadsheet showed the affiliate’s WebMoney ID, name, address, phone\nnumber, date of birth, email address, passport number, and the street address\nof the government office that issued the passport.\n\nMany of these WebMoney accounts had been set up years before their owners\nbegan spamming or participating in any cybercrime activity. But one in\nparticular caught my eye. Among the attested accounts detailed in the\nspreadsheet was a WebMoney purse created in January 2002 to a user who\nprovided the account alias “Software Seller.” This account was credited with\nmore than $175,000 for promoting pharmacy websites for SpamIt. That was where\nI would start.\n\n## Gugle\n\nIt took many weeks of digging through countless leaked chat records between\nthis user—who used the nickname “Gugle” on both ICQ instant message chat and\nas a nickname on Spamdot.biz—and the administrators of the SpamIt pharmacy\npartnerka. Ultimately, I was able to determine that this was the same\nindividual who ran the Cutwail botnet, easily the largest and most active spam\nbotnet at the time. (It remains quite active.)\n\nThe spreadsheet entry for the corresponding WebMoney ID next to the botmaster\nnamed Gugle listed a Dmitry Sergeyvich Nechvolod, born July 9, 1983, and\nliving in Moscow. When I saw Nechvolod’s information in that document,\nsomething in it reminded me of a conversation that I’d had with Vrublevsky\nearlier in the year. I didn’t realize the significance of that discussion at\nthe time, because I didn’t quite understand Gugle’s role then.\n\nIt was late 2010, and Vrublevsky had just called me and was excitedly relaying\nsome intelligence that he’d gleaned from his network of law-enforcement\ncontacts. He’d received word that cybercrime investigators with the U.S.\nNational Aeronautics and Space Administration (NASA) were coming to Moscow to\nmeet with Russian FSB agents. The NASA officials, who have guns and badges and\njust as much investigative authority as other U.S. law-enforcement agencies,\nwere coming to discuss cooperating with Russian authorities over an\ninvestigation into Nechvolod.\n\nBy that time, NASA investigators had connected the dots between Nechvolod and\nGugle, and had been building a criminal case against him for allegedly\ninfecting countless NASA computers with Cutwail malware.\n\n“The Americans came to Moscow trying to find the Cutwail owner, who goes by\nthe nickname ‘Gugle,’” Vrublevsky told me excitedly and proudly in a phone\ninterview, speaking of a man who was among the top spammers for both Rx-\nPromotion and SpamIt. “They got his nickname and even his real name correct,\nbut they were never able to catch him. Honestly, I think someone warned him.\nYou know, Brian, the corruption level in Russian law enforcement related to\ncybercrime is really quite high.”\n\nI’m still not sure why Vrublevsky told me all of this. Perhaps it was to brag\nthat he was so well-connected to Russian cyber law-enforcement officers that\nhe could help save one of Rx-Promotion’s best spammers from being delivered\ninto the arms of American federal agents. I believe Vrublevsky also wanted the\nNASA investigators to know he’d played them for fools. After all, these same\nNASA investigators had convinced the U.S. Federal Trade Commission to unplug\nthe bulletproof hosting provider 3FN, a disconnection that caused much trouble\nand expense for Vrublevsky and his network of extreme adult webmasters, and\nfake antivirus and spam peddlers.\n\nAccording to a source who helped work that investigation with NASA, Vrublevsky\nhad been given advance notice of the visit by corrupt FSB agents. Days before\nthe scheduled meeting between NASA and the FSB, Nechvolod fled Russia for\nUkraine.\n\n“Gugle and Pavel were business partners and friends,” said my law-enforcement\nsource at NASA, speaking on condition of anonymity because he was not\nauthorized to discuss the case. “It was Pavel who tipped off Gugle that [NASA]\nwas meeting with the FSB about Cutwail. Gugle is reportedly in Ukraine now,\nlying low.”\n\nAccording to the website of Russian software firm Digital Infinity Developers\nGroup, Nechvolod was part of a team of elite programmers that could be hired\nout for jobs at diginf.ru. The Diginf Team page on that site (now defunct)\nlisted Dmitry Nechvolod as an “administrator of UNIX-based systems,” an\n“administrator of Cisco routers,” and “a specialist in information security\nsoftware.” Between Nechvolod’s expertise and that of his team, it is clear\nfrom reviewing their résumés that this group of programmers could hack their\nway in or around virtually any communications or security system.\n\nNechvolod’s cadre maintained a core version of the Cutwail bot code and rented\nit out to other miscreants on underground forums, where the spamming system\nwas known as “0bulk Psyche Evolution.”\n\nIn many ways, Nechvolod is the poster child for the modern cybercriminal, a\nprofession not unlike drug dealing in that it generates a constant stream of\ncash. Those illicit funds need to be either laundered by investing in\nproperties or other hard assets, or spent. Nechvolod, like many of his peers,\npreferred to splurge on a lavish and fast lifestyle of fast cars, fast girls,\nnice clothes, and drugs, Vishnevsky said.\n\n“He always dressed very nice, and when he wrecked his $100,000 Lexus sedan, he\nwent and bought a brand-new BMW,” Vishnevsky said.\n\nBy 2008, Nechvolod’s spam business was booming. His Cutwail botnet had grown\nto more than 125,000 infected computers and was able to blast out 16 billion\nspam messages daily. Soon enough, his company’s growth forced him to find and\nhire several new programmers. To give you a sense of what he was looking for,\nbelow is an ad that he posted to Crutop.nu, seeking a talented programmer\nexperienced in building web applications.\n\nJob type: local office in Moscow (benefits package included), full-time (9\nhours per day, 5 days a week).\n\nREQUIREMENTS:\n\n• Excellent knowledge of Perl and PHP\n\n• Excellent knowledge of SQL\n\n• Knowledge of AJAX, JavaScript\n\n• The ability to quickly write scripts without bugs\n\n• At least 22 years of age\n\n• Responsibility\n\nThe salary for a probationary period $1.5K (1 month), after—$2K +.\n\nA full-time salary—with benefits—and opportunities for advancement. What\nenterprising young coder could ask for more? And while $23,500 a year would be\na very good salary for a junior programmer living in Moscow, it was an\nabsolute dream for coders from the countryside who could convince the boss to\nlet them telecommute. Nechvolod’s job offer is yet another illustration of how\ncybercrime businesses in some parts of the world are in direct competition\nwith many legitimate companies in the search for talented programmers.\n\n## Cosma\n\nThe records leaked from both GlavMed-SpamIt and Rx-Promotion show that one of\nboth partnerkas’ most successful spammers was a hacker who used a variety of\nnicknames, including “Cosma,” “Tarelka,” “Bird,” and “Adv1.” Cosma, as we’ll\ncall him here for simplicity’s sake, and all of his affiliated accounts with\nSpamIt earned more than $3 million in commissions over three years with the\npharmacy program.\n\nHis spam machine was the Rustock botnet, a malware strain that was first\nunleashed onto the Internet in 2006. The botnet’s name was derived from its\ninitial purpose: to help perpetrate a form of securities fraud known as “pump-\nand-dump” stock scams. In such schemes, fraudsters buy up a bunch of low-\npriced microcap stock (the prices usually vary from a fraction of a penny to a\nfew cents per share), blast out millions of spam emails touting the stock as a\nhot buy, and then dump their shares as soon as the share price ticks up from\nall the suckers buying into the scam.\n\nIn 2007, researchers began noticing that PCs infected with Rustock had started\nsending pharmacy spam in addition to pump-and-dump emails. Experts at Dell\nSecureWorks estimated around that time that Rustock had infected more than\n150,000 PCs and was capable of spewing as many as 30 billion spam messages per\nday.\n\nThe emergence of pharmacy spam from Rustock coincides with the time that Cosma\nsigned up as an affiliate with SpamIt. Those same three affiliate names that\nthe Rustock botmaster used with SpamIt—Cosma2k, Bird, and Adv1—also were\nregistered using the same ICQ account at Vrublevsky’s Rx-Promotion. Leaked\nChronoPay data shows that these three accounts collectively earned\napproximately $200,000 in commissions by promoting pharmacy websites for Rx-\nPromotion in 2010.\n\nIn several chats, Cosma muses on what he should do with tens of thousands of\ncompromised but otherwise idle PCs under his control. Throughout the\ndiscussions between Stupin and Cosma, it is clear Cosma had access to internal\nSpamIt resources that other spammers did not, and that he had at least some\nsay in the direction of the business.\n\nIn one conversation, dated October 14, 2008, Cosma tells Stupin that he’s\ndecided to dial back his public image a few notches after attracting unwanted\nattention from other crooks. Cosma tells Stupin he was mugged and held hostage\nby thugs who’d targeted him because of his late-model Porsche Cayenne, a sport\nutility vehicle that costs considerably more than $100,000 in Moscow. After\nbeing roughed up by his captors, Cosma relinquished the keys to his Porsche.\nCosma laments to Stupin that as a result of that incident, he decided to\nreplace his stolen Cayenne with a less flashy BMW 530xi.\n\nCosma left behind a number of clues about his real-life identity. He\nregistered with the SpamIt program using the email address ger-mes@ger-mes.ru.\nThat website disappeared in 2010, but a cached copy of the site shows that its\nhomepage previously featured some very interesting information. It included a\njob résumé for a Belarusian-educated programmer underneath a picture of a\nbrown-haired young man holding a mug. Above the image was the name “Sergeev,\nDmitri A.” At the very top of the page was a simple message: “I want to work\nin Google.” Beneath the résumé is the author’s email address, followed by the\nmessage, “Waiting for your job!”\n\nIf the thugs who stole Cosma’s Porsche had known who he was, they might have\nhanded him over to Microsoft. In July 2011, Microsoft offered a standing\n$250,000 reward for information leading to the arrest and conviction of the\nRustock botmaster. Cosma remains at large.\n\n## Severa\n\nCosma ran his stock spam business in tandem with that of another cybercrook, a\nhacker who uses the nickname “Severa.” This spammer was named as a defendant\nin an indictment handed down by a U.S. federal court in 2007 as a major\npartner of Alan Ralsky, an American spammer who was convicted in 2009 of\npaying Severa and other spammers to promote the pump-and-dump stock scams. But\nwhile Severa was indicted, he was never arrested, and his case is still\npending. Partially, this is because he appears to still be in Russia, a\ncountry that traditionally hasn’t extradited alleged cybercriminals to stand\ntrial in the United States or Europe.\n\nSevera’s spam machine was powered by a sophisticated computer worm known as\n“Waledac.” This contagion first surfaced in April 2008, but many experts\nbelieve that Waledac was merely an update to the Storm worm, the engine behind\na massive spam botnet that first surfaced in 2007.\n\nWaledac and Storm were major distributors of pharmaceutical and malware spam.\nAt its peak, Waledac was responsible for sending 1.5 billion junk emails per\nday. According to Microsoft, in one month alone approximately 651 million spam\nemails attributable to Waledac were directed to Hotmail accounts, including\noffers and scams related to online pharmacies, imitation goods, jobs, penny\nstocks, and more. The Storm worm botnet also sent billions of messages daily\nand infected an estimated one million computers worldwide.\n\nBoth Waledac and Storm were hugely innovative because they each included self-\ndefense mechanisms designed specifically to stymie security researchers who\nmight try to dismantle the crime machines. Traditional botnets are controlled\nby Internet servers that can be shuttered just like McColo or Atrivo. But\nWaledac and Storm sent updates and other instructions via a peer-to-peer\ncommunications system not unlike popular music and file-sharing services. The\nbeauty of this approach is that even if security researchers or law-\nenforcement officials manage to seize the botnet’s back-end control servers\nand clean up huge numbers of infected PCs, the botnets could respawn\nthemselves by relaying software updates from one infected PC to another.\n\nAccording to SpamIt records, Severa brought in revenues of $438,000 and earned\ncommissions of $145,000 sending spam advertising for rogue online pharmacy\nsites over a three-year period. He also was a moderator of Spamdot.biz.\n\nSevera made more money renting his botnet to other spammers. For $200, vetted\nusers could hire his botnet to send one million pieces of spam. Junk email\ncampaigns touting employment or “money mule” scams cost $300 per million, and\nphishing emails could be blasted out through Severa’s botnet for the bargain\nprice of $500 per million.\n\nThere is ample evidence in the leaked SpamIt chats that Severa controlled the\nWaledac spam botnet. On August 27, 2009, Severa sent a private message to a\nSpamdot.biz user named “IP-server.” Those communications show that the latter\nhad sold Severa access to so-called “bulletproof hosting” services that would\nstand up to repeated abuse claims from other Internet service providers\n(ISPs). The messages indicate that Severa transacted with IP-server to\npurchase dedicated servers used to control the operations of the Waledac\nbotnet.\n\nIn the private message, Severa wrote to IP-server (translated from Russian):\n“Hello, writing to your ICQ, you are not responding. One of the servers has\nbeen down for 5 hours. The one ending on .171. What’s the problem, is it\ncoming up or not, and when?” Severa then pasted an error message sent by the\nproblematic web server. IP-server must have resolved the outage, because the\nInternet address that Severa was complaining about—193.27.246.171—would be\nflagged a day later by malware analysts and tagged as a control server for the\nWaledac botnet.\n\nThe federal indictment lists Severa’s name as “Peter Severa,” but this last\nname may be a pseudonym. According to anti-spam activists at Spamhaus.org,\nSevera’s real name is Peter Levashov.[10](07_chapter07.xhtml#fn10)\n\nWhy should anyone care who Severa really is? Much like his close\nassociate—Cosma, the Rustock botmaster—Severa may also have a $250,000 bounty\non his head. The Conficker worm, a global contagion launched in 2009 that\nquickly spread to an estimated 9 to 15 million computers worldwide, prompted\nan unprecedented international response from security experts. This group of\nexperts, dubbed the “Conficker Cabal,” sought in vain to corral the spread of\nthe worm.\n\nBut despite infecting huge numbers of Microsoft Windows systems, Conficker was\nnever once used to send spam. In fact, the only thing that Conficker-infected\nsystems ever did was download and spread a new version of the Waledac botnet.\nLater that year, Microsoft announced it was offering a $250,000 reward for\ninformation leading to the arrest and conviction of the Conficker author(s).\nSome security experts believe this proves a link between Severa and Conficker.\n\nSevera and Cosma had met one another several times in their years together in\nthe stock spamming business, and they appear to have known each other\nintimately enough to be on a first-name basis. Included in the archived\nSpamdot.biz records that were leaked to me is a series of private messages\nexchanged between Cosma and Severa on May 25 and May 26, 2010. In it, Severa\nrefers to Cosma as “Dimas,” a familiar form of “Dmitri.” Likewise, Cosma\naddresses Severa as “Petka,” a common Russian diminutive of “Peter.”\n\nBoth Severa and Cosma remain free and quite active in the spam and malware\nscene. Severa is still the spam subforum administrator on several underground\nforums, pimping his spam services, remarkably under most of the same prices he\noffered them for in 2008. The spam botnets that Severa maintains continue to\ninundate inboxes with junk email promoting fly-by-night products and spreading\nmalicious software.\n\n## GeRa\n\nAccording to the leaked SpamIt data, the second most successful affiliate in\nthe program was a member nicknamed “GeRa.” Over a three-year period, GeRa’s\nadvertisements and those of his referrals resulted in at least 80,000 sales of\nknockoff pharmaceuticals, brought SpamIt revenues of in excess of $6 million,\nand earned him and his pals more than $2.7 million.\n\nA variety of data suggest that GeRa is the lead hacker behind Grum, a spam\nbotnet that could send more than 18 billion emails a day prior to its takedown\nin 2012.\n\nGeRa and Stupin chatted online by ICQ almost every day, usually because GeRa\nwas complaining that some portion of his spamming infrastructure wasn’t\nworking properly. In fact, Stupin would remark that GeRa was by far the most\nbothersome of all the program’s top spammers, telling a fellow SpamIt\nadministrator that “neither Docent [Mega-D botmaster] nor Cosma [Rustock\nbotmaster] can compare with him in terms of trouble with hosting providers.”\n\nSeveral of the leaked Stupin chats show GeRa pointing out issues with specific\nInternet addresses that would later be flagged as control servers for the Grum\nbotnet. For example, in a chat with Stupin on June 11, 2008, GeRa posts a link\nto the address 206.51.234.136. Then after checking the server, he proceeds to\ntell Stupin how many infected PCs were phoning home to that address at the\ntime. That same server has long been identified as a Grum botnet controller.\n\nBy this time, Grum had grown to such an established threat that it was named\nin the “Top Spam Botnets Exposed” paper released by Dell SecureWorks\nresearcher Joe Stewart. On April 13, 2008—just five days after Stewart’s\nanalysis was released—GeRa would post a link to it into a chat with Stupin,\nsaying “Haha, I am also on the list!”\n\nThe chats between GeRa and Stupin show that at some point GeRa defected from\nworking with SpamIt to spam for Rx-Promotion. Researchers from the University\nof California, San Diego (UCSD) who studied the leaked Rx-Promotion affiliate\ndata noted that all Rx-Promotion pharmacy sites included a “site_id” in their\nsource code, which uniquely identified the store for later assigning\nadvertising commissions. The researchers discovered that whenever Grum\nadvertised an Rx-Promotion site, this identifier was always the same: 1811.\nAccording to the leaked Rx-Promotion database, that affiliate ID belongs to a\nuser named “gera.”\n\n“It doesn’t prove that GeRa owned Grum,” said Stefan Savage, a professor in\nthe systems and networking group at UCSD and coauthor of the study. “But it\ndoes show that when Grum advertised for Rx-Promotion, it was for sites where\ncommissions were paid to someone whose nickname was ‘GeRa.’”\n\nAccording to payment records leaked from GlavMed and Rx-Promotion, GeRa\nreceived commission payments for all of those accounts to a WebMoney purse\nwith the ID number 112024718270. According to a source who has the ability to\nlook up identity information attached to WebMoney accounts, that purse was set\nup in 2006 by someone who walked into a WebMoney office in Moscow and\npresented a Russian passport. The name on the passport was that of a twenty-\nsix-year-old named Nikolai Alekseevich Kostogryz. (My attempts to contact\nKostogryz to confirm if GeRa was indeed him or if his identity had been stolen\nwere unsuccessful.)\n\nStupin’s chat records and GeRa’s private messages on Spamdot.biz reveal a\nbelligerent, argumentative hacker who seemed to be perpetually angry about\ngetting screwed over by someone. GeRa had a long-running feud with FTPFire, a\nSpamIt member that he referred to the program. In one of his conversations\nwith Stupin, GeRa stated that he wanted to find the guy and “take care” of him\nin “the Italian way.” He told Stupin that he had some police officers on his\npayroll and had asked them to locate FTPFire.\n\nGeRa also said he was robbed of $30,000 when a rogue antivirus partnerka he\nwas working with folded. That criminal outfit, called BakaSoftware, was in the\nscareware racket, inundating victims with increasingly alarmist warnings about\nsecurity threats and viruses on his or her PC. These warnings would continue\nuntil the victim either paid to license mostly useless security software or\nfigured out a way to remove the invasive program.[11](07_chapter07.xhtml#fn11)\n\nAlthough it is unclear if GeRa is still active in the spam scene, his\ncontribution to the junk email world lives on. The source code for his Grum\nbotnet has been sold to several other spammers who have apparently modified it\nfor their own purposes and are currently using it to blast junk email.\n\n## Engel\n\nFew botmasters were as angry and as vindictive as “Engel,” the nickname chosen\nby the convicted Russian spammer named Igor A. Artimovich, and his brother,\nDmitry. Engel allegedly maintained the Festi botnet and, for a time, spammed\nfor both Rx-Promotion and SpamIt. But in 2009, a series of incidents and\naltercations between himself and the SpamIt administrators would turn him\nforever against the SpamIt program and make him a close ally of Pavel\nVrublevsky. Ironically, that alliance would eventually lead to Vrublevsky’s\nand Rx-Promotion’s undoing.[12](07_chapter07.xhtml#fn12)\n\nFirst spotted in autumn 2009, Festi quickly became a potent threat on the\nbotnet scene. According to ESET, a Slovakian antivirus and security firm,\nFesti was at the time among the most powerful and active botnets for sending\nspam and for launching distributed denial of service (DDoS) attacks. A vocal\nand often combative member on the Spamdot.biz forum, Engel referred to his\nbotnet as “Topol Mailer.” That moniker was an oblique reference to the\nRussian-made intercontinental ballistic missile known as Topol-M, an apt\nnickname for a botnet that once delivered a third of all spam to inboxes\naround the globe, but principally to Americans.\n\nEngel’s profile on Spamdot.biz listed his email address as “support@id-\nsearch.org.” That domain is no longer online, but archive.org reveals that\nEngel used it as the home base for a bot whose sole purpose was to harvest\nemail addresses from billions of web pages. Engel claimed publicly that the\nbot was nothing more than a research project, but he bragged privately to\nSpamdot members that his search bot could scour hundreds of sites\nsimultaneously and quickly collect “hundreds of megabytes” of email lists.\n\nEarly in his work for SpamIt, Engel began to suspect that Gusev and Stupin\nwere “shaving” his commissions—essentially not paying him all of the money\nthat he was due from pharmaceutical sales at sites that he had promoted using\nspam sent from the Festi botnet. SpamIt’s Gusev and Stupin denied that they\nwere shaving commissions—and they were truthful in their denial—but private\nchats leaked by Stupin show this was only a half-truth.\n\nThose chats show that the Cutwail botmaster Gugle (Dmitry Nechvolod) had\nsomehow hijacked portions of Festi’s traffic and diverted the spam destined\nfor Engel’s pharmacy sites to his own pill shops. Gusev and Stupin were aware\nof this activity, but seemed unwilling to do much about it—mainly because they\nintensely disliked Engel and already suspected that he was too closely allied\nwith Vrublevsky.\n\nBy 2009, Engel became so embittered over continued allegations of being\nshortchanged on commissions that he began using the Spamdot.biz forum to\naggressively promote his own new pharmacy partnerka and forum—Spamplanet.net.\nIn short order, he succeeded in luring away several top botmasters, including\nCosma, the Rustock botmaster.\n\nGusev and Stupin decided this activity, combined with Engel’s increasingly\npublic and combative allegations of shaving, were unacceptable, and banned\nEngel from their forum. When the SpamIt administrators ignored Engel’s demands\nto re-enable his account, Engel used the Festi botnet to launch a long series\nof crushing DDoS attacks against SpamIt and its network of pill-shop sites,\ndecreasing revenue for everyone in the partnerka.\n\nThe spammers profiled in this chapter were in charge of building and\nmaintaining some of the world’s most powerful and disruptive spam botnets, and\nas a result are or were responsible for a huge chunk of the junk email sent\nglobally each day. Collectively, their spam botnets have infected tens of\nmillions of computers over the years, and gobbled up personal and financial\ndata from countless consumers in the process.\n\nIndividually, these junk email artists earned a few million dollars for their\nefforts, yet they’ve forced businesses and consumers to spend hundreds of\nmillions more shoring up digital defenses to fight their daily glut of\ncrimeware.\n\nBut these spammers were mere vassals and barons in charge of warring fiefdoms.\nThe real authors of this economic asymmetry—the kingpins who created the\npharmacy partnerkas—used the spammers like so many pawns in a high-stakes game\nof chess, a costly conflict that denizens of the digital underground would\nsoon dub the “Pharma Wars.”\n\n* * *\n\n[10.](07_chapter07.xhtml#fnr10)I contacted Severa using the instant messenger\naddress that he provides on multiple cybercrime forums on which he is a global\nmoderator for discussions about junk email and spam services. The person\nanswering messages on that address said he didn’t know any Severa, that he’d\nnever used botnets for mass mailing campaigns, and that he only conducted\nsmall, targeted email campaigns for clients.\n\n[11.](07_chapter07.xhtml#fnr11)It’s worth noting that BakaSoftware’s core\ncredit-card processor was ChronoPay.\n\n[12.](07_chapter07.xhtml#fnr12)According to the New York Times in 2013,\nArtimovich does not deny going by the nickname Engel, but he does deny using\nbotnets or sending spam, and says he was only hired by ChronoPay to help the\ncompany build an antivirus product.\n\n\nChapter 8\n\n## OLD FRIENDS,  \nBITTER ENEMIES\n\nIn early summer 2008, SpamIt co-owner Igor “Desp” Gusev, then twenty-seven,\nwas vacationing with his young wife and infant daughter in Marbella, on the\npicturesque coast of southern Spain. He’d just been offered a job as a civil\nservant in Russia, as an aide to an official at the Russian government’s\nMinistry of Economic Development, but he was ambivalent about leaving Spain\nand accepting the position.\n\nAt that time, SpamIt and GlavMed had emerged as the largest rogue Internet\npharmacy program on the planet and had attracted nearly all of the world’s top\nspammers. Both programs had just reached what would be the peak of their\nearning power and were bringing in almost $6 million in revenue each month.\n\nDespite the success of his spam venture, Gusev was thinking strongly about\ntaking the government job and leaving his life as a cybercrime boss far\nbehind. The subject hadn’t come up yet with his business partner, Dmitry\nStupin, but Gusev had to break the news at some point. The two had built\nGlavMed and SpamIt from nothing into a thriving business, but lately\nbitterness had arisen between them. Gusev was anxious for a more meaningful,\nlegitimate, and stable life with his family. Stupin, meanwhile, was growing\nincreasingly resentful that Gusev was constantly traveling and leaving him to\nwrangle with the day-to-day challenges of running a business that relied\nprincipally on criminals.\n\nThe following exchange, from a chat log between Gusev and Stupin recorded in\nsummer 2008 and translated into English by native Russian speaker Aleksey\nMikhaylov, illustrates the simmering resentment that Stupin felt at being left\nbehind. It also includes a theme that ran through many of their conversations:\nStupin was forever dreaming up new ways to make money, while Gusev seemed to\nyearn for a more respectable—if also more routine way of life.\n\nGUSEV: I like it in Spain very much :) However, all the fun is shadowed by the\nfuture “job”; we’ll see what kind of shithole this is.\n\nSTUPIN: What kind of “job”? What are you talking about?\n\nGUSEV: I am going to join the Ministry of Economic Development as an assistant\nto the vice minister.\n\nSTUPIN: Hmm…have you finally decided to do it? If you think thoroughly, and\ninvest your time and efforts into what we already have, we can raise profits\nup to two to three times, which translates to several extra millions of\ndollars per year just for you.\n\nGUSEV: Surely, if your goal is to make money :) It’s too long to explain in\nwriting. Let’s have lunch in Moscow sometime and I will explain to you why I\nwant to take this job. However, here is short version: it is not the main\nthing to make money in our country. The most important thing is to retain it,\nmultiply it, to ensure that nobody is going to seize it. Our main source of\nincome now is a semi-legal business. If they want to bring us down, they will\ndo it as easy as 1–2–3. It’s not going to be easy to escape from it, even with\nthe two or three political connections I have now. The main goal is not to\nlose what we already have and not allow us to be brought down.\n\nSTUPIN: When it comes to not losing—simply buy real estate abroad. It is more\n“mobile” than you think. If the shit hits the fan, we can maintain everything\nwith the efforts of four to five people. Everyone else—they are only for\nbusiness development.\n\nGUSEV: I am not talking about money. This is about business itself. If you and\nI get into trouble, all this “mobility” will disappear. Therefore, I want to\nmake it so that it would not be easy to cause problems for you and me. You\nhave to admit that the business is not going to sustain itself without you and\nme. Andrey, Margo, Sashka, Stratos will not be able to do it by themselves.\n\nSTUPIN: I have a feeling lately that I am talking to a wall. Am I getting on\nyour nerves?\n\nGUSEV: No, why do you think so?\n\nSTUPIN: Your behavior is different. There is no more communication.\n\nGUSEV: It is not too different for me. I write something and do not get any\nreplies. You just write “okay” from time to time :)\n\nSTUPIN: I do not consider you a “worker” anymore, a person to work with. I\nconstantly communicate with Andrey and Sashka, and I discuss everything with\nthem. You are either absent, or you are doing nothing (as it appears to me).\nIt does not get on my nerves or irritate me. I just no longer consider you a\nperson I need to or can work with.\n\nGUSEV: As far as the job, you have had full authority for a long time. It is\nmore efficient this way.\n\nSTUPIN: It is more convenient for me not to communicate with you much, because\notherwise I start wondering why we need you at all. It is going to be better\nif you start doing something, or else I will continue to discuss stuff with\nyou less and less.\n\nGUSEV: You know, thanks for being frank with me, but I have not given you an\nopportunity to rise to a partner from a simple programmer just so that in the\nfuture you’d tell me that I was no longer necessary. You would have been a\nlead developer in some major company with the salary of five to seven\nthousand, and you would not have been able to buy your house in Turkey if we\ndid not meet together at that time, and if I had not have allowed you to\nmanage the company. Think about it at your leisure. Money blinds people and\ngives false feelings of total power.\n\nSTUPIN: Did I say that you’ve become unnecessary? That was your own thought.\nIf you had thought a bit further, you’d understand that I was the reason that\neverything was working so reliably and so thoroughly, only because of my\nbecoming the person you allowed me to become.\n\nGUSEV: Let’s talk tonight. I will cool off a little.\n\nSTUPIN: No problem. I have no issues.\n\nBut this feud would have to wait while a more pressing concern came to the\nfore. While Gusev was still in southern Spain, he received a flood of urgent\nmessages from a friend named Alexey, a hacker upon whom he relied for\nintelligence about law-enforcement interest in spammer activity.\n\nLEHA: Hey. Are you there? I’ve been looking for you.\n\nGUSEV: Sorry, have been in Spain with the family.\n\nLEHA: There is something bad that you need to know. Just listen to what I have\nto say, and then draw your own conclusions.\n\nLeha explained that a few nights prior, he ran into Yuri “Hellman” Kabayenkov,\nVrublevsky’s fifty-fifty partner in Rx-Promotion. As happened more often than\nnot, Kabayenkov was drunk, and on this night in particular Leha heard him\nbragging about his role in bribing the local police into opening a criminal\ninvestigation into Gusev’s business.\n\nLEHA: So I happened to run into drunken Hellman last week. And either just to\nbrag, or just because he’s a stupid moron, he spilled his guts. He asked,\n“Have you stayed in touch with Desp (Gusev)?” This was definitely a loaded\nquestion. I immediately said, “Why do you ask?”\n\nHellman hinted that “right-thinking people” would start thinking about\ndistancing themselves from Gusev, and that he himself had seen the paperwork\nfor the case, which specified that Gusev was to be accused of money\nlaundering.\n\nGUSEV: What are they trying to pin on me?\n\nLEHA: The article in the criminal code that deals with legalization of\nproceeds from crime. I’m not sure whether the criminal case actually exists\nyet or not, I’m just relaying what I heard. I myself am shocked by such stupid\nbehavior. Obviously, Pasha [Pavel Vrublevsky] was the one who initiated this,\nbut the fact that Hellman got himself into this is especially ridiculous.\n\nGUSEV: Thanks, Leha. You warned me in time.\n\nLEHA: Hellman wanted to buy a car. If you remember, he bragged about this at\nmy birthday party… But at some point he said that he had to delay the\npurchase, because he needed lots of money for something. And now, while he’s\ndrunk, he let it spill exactly what he needed the money for.\n\nGUSEV: Do you by any chance know the prosecutor’s office that is in charge of\nthe case?\n\nLEHA: I have no idea which prosecutor’s office or who initiated the case. I’m\nnot even sure the case exists. I didn’t see it.\n\nGUSEV: But what reason does Hellman have to pay for my criminal case? What did\nI do to him?\n\nLEHA: It’s total nonsense. I have no idea what reason he might have. I asked\nhim and his response was, “But why not?” Pasha [referring to Vrublevsky] is a\nfucking asshole. To do this kind of bullshit is way too much.\n\nGUSEV: The funny thing is, he still owes me money.\n\nLEHA: So much bragging. He says that police colonels and generals are working\nfor him on these things. Hellman has also picked up on this crap. Says that he\nhas everything under control.\n\nGUSEV: If you can try to find out which prosecutor’s office is handling the\ncase, it will make finding it a lot easier.\n\nLEHA: I have a very fucking bad feeling about this, Igor. Do you have any way\nto solve this problem?\n\nGUSEV: I will start working on this now. I’m not 100 percent sure, but I will\nask some very serious people for help. As you know, a 100 percent guarantee of\nsolving all problems is not given even by God.\n\nAnd so began the Pharma Wars, a long-running, public, and ultimately very\ncostly grudge match between the proprietors of the world’s largest pharmacy\npartnerkas then—a feud that would forever change the course of the spam\nindustry. The investigation that Vrublevsky and Hellman allegedly purchased\nagainst Gusev and his business would set in motion a damaging series of events\nthat would find the two men competing to see who could spend more money\nbribing officials to help ruin the other.\n\nAnd they would both succeed.\n\nGusev believes that Vrublevsky and Hellman paid for the criminal case against\nhim because they suspected him of being responsible for a recent financial\ncatastrophe that wiped out more than $7 million in funds belonging to one of\ntheir businesses. The lost money was being held in escrow for some of Russia’s\nmost accomplished hackers, and the resulting fallout from the money’s\ndisappearance quickly made RedEye (Vrublevsky) a persona non grata among adult\nwebmasters and spammers alike.\n\nIn a telephone interview, Gusev said the trouble with Vrublevsky started\nshortly after the latter was the victim of a corporate raid that led to the\nlooting of millions of dollars that Vrublevsky reportedly owed to Russian\nadult webmasters. Many Western readers are no doubt familiar with the concept\nof a conventional corporate raid—also known as a hostile takeover—which\ninvolves buying a sizeable interest in a company and then using the resulting\nvoting rights to enact changes such as replacing top executives or liquidating\nthe company.\n\nIn Russia, however, the hostile takeover is all too frequently a violent\nevent, and can just as often happen via bribed judges or politicians as at the\npoint of a gun. According to Knowledge@Wharton, a publication from the Wharton\nbusiness school, a staggering 70,000 Russian companies each year become\ntargets of raider attacks.\n\n“In the mid-1990s, reports of AK-47 wielding masked men storming the\nheadquarters of up-and-coming companies, seizing assets, and forcing owners to\nsign a variety of property transfer documents were all too common,” wrote the\nfive members of the 2010 class of Wharton’s Lauder Institute who authored the\narticle.\n\n“Since the [Russian] financial default of 1999, however, tactics of raiders\nand their agents have become much more sophisticated. These days, the most\ncommon scenario involves an interested party placing an order with a raiding\nteam for the takeover of a target company. Raiders typically start by\nacquiring a minority share in the target firm and using this share to initiate\nfrivolous lawsuits against the target. The raiders then use a complex game of\nlegal arbitrage to compromise the company’s operations and drastically devalue\nits stock. These actions result in possible bankruptcy and almost certain\ntakeover by the raider.”\n\nThe business entity targeted in the raid against Vrublevsky was Fethard\nFinance, a now-defunct virtual currency system of which Vrublevsky was a\nmajority shareholder. Through a legal entity he founded called “Red &\nPartners,” Vrublevsky developed a network of extreme porn sites. The online\nforum that Vrublevsky (a.k.a. “RedEye”)[13](08_chapter08.xhtml#fn13)\nfounded—Crutop.nu—was the perfect spot for marketing the Red & Partners sites\nto Russian adult webmasters, who could earn commissions for selling monthly\nmemberships to the sites. (Recall that our “Virgil” in this spammer\nnetherworld—Vishnevsky—earned a tidy living as a young man advertising Crutop-\naffiliate websites.) When these webmaster affiliates got paid, they were\ncompensated not in dollars or Russian rubles, but in credits with Fethard’s\nvirtual currency, which quickly caught on as an accepted form of payment for\ngoods and services in the Russian cyber underground.\n\nFethard and Vrublevsky’s porn empire seemed to be humming along nicely until\nSeptember 2007, when Vrublevsky—or rather the Crutop administrator\nRedEye—broke the news to more than eight thousand Russian adult webmasters who\nhad money tied up with the virtual currency: Fethard had been the latest\nvictim of a corporate raid and was flat broke.\n\nAccording to Gusev, the brains behind the raid was Mikhail Zhilenkov, the\nhusband of Maria Okulova, the granddaughter of the first president of Russia,\nBoris Yeltsin. Interestingly, Okulova’s father, Valery Okulov, is the former\nCEO of Aeroflot—Russia’s largest airline, and a company that would soon\nradically change the direction of Vrublevsky’s life.\n\n“In 2007, the Fethard system had two main shareholders: Pavel and Zhilenkov,\nwho is a well-known raider and has some good connections in police and\n[Russian FSB],” Gusev recalled in a phone interview. Indeed, Alexander\nKhinshtein, a journalist for the Russian news magazine Moskovsky Komsomolets,\nhas detailed the exploits of RostInvest, a Zhilenkov investment firm\nimplicated in a number of raider scandals throughout the latter half of the\nlast decade.\n\nGusev believes Vrublevsky’s lust for power and the desire to be associated\nwith anyone who had it blinded his former business partner to what lay ahead.\nZhilenkov used his sway as a 50 percent shareholder in the company to take\ncontrol of the day-to-day management of Fethard. And that gave Zhilenkov\ndirect access to all the Fethard affiliate accounts.\n\nOn September 12, 2007, Vrublevsky was sucker-punched twice. The first blow was\nlearning that virtually all of the funds in the Fethard accounts had been\ndrained and funneled to various banks offshore. The second was discovering\nthat Russian police had opened a criminal investigation into him and Fethard,\ncalling it an illegal banking system.\n\n“Pavel either didn’t see or didn’t worry about that side of Zhilenkov, because\nhe was strutting around like a turkey cock and boasting about getting such a\nbigwig as his new partner, and all of the connections and power it would bring\nhim,” Gusev said in an interview with this author.\n\nThe raid against Fethard was an important event because Vrublevsky became\nconvinced it was orchestrated by Gusev. (Gusev vehemently denies he had\nanything to do with it—a claim I’ve come to believe.) Determined to strike\nback at his perceived aggressor, Vrublevsky began scheming with the\naforementioned cofounder of Rx-Promotion—Yuri “Hellman” Kabayenkov—to get a\ncriminal investigation into Gusev started.\n\n“Zhilenkov was the originator of this case,” Gusev said. “It was a warning\nfrom Zhilenkov to Pavel not to try to get the money back. Zhilenkov made it\nvery clear that if Pavel intended to try to get the money back that was stolen\nfrom Fethard, he will have even more problems, and the criminal case would\nmove forward. But all along, Pavel has wrongly suspected that I was somehow\ninvolved in this.”\n\nIt’s not hard to see why. In many ways, Gusev and Vrublevsky could not be more\ndifferent. Gusev is thoughtful, erudite, deliberate, self-deprecating, and\nmiserly. In contrast, Vrublevsky is vulgar, impulsive, loquacious, self-\naggrandizing, and a spendthrift. Gusev is a self-described “golden boy” who\ngrew up in a wealthy family—his grandfather was a minister of construction and\nbuilding in the former Soviet Union—and he received a classical education at\none of Russia’s top schools. Vrublevsky, who looks at least ten years older\nthan his real age—in his midthirties—had a bit less sheltered upbringing and\nwas tossed out of several schools as a young man.\n\nGusev said he got his start in the Internet industry in 1998, when a local\nbusinessman hired him to create a website for a sports memorabilia business.\nGusev learned as much as he could about HTML and web programming, and earned\ntwo hundred dollars for his efforts. Not long after that, he decided he could\nmake much more money in the porn business, so he hired a programmer to help\nhim make software that collects lists of top porn sites used in so-called\n“circle jerk” operations.\n\n“CJs, as they’re called, are a kind of system in which different sites hosting\nmany porn images redirect viewers who click on an image from one site to\nanother,” Gusev said. “The idea behind the CJ is that you are redirected so\nmany times that finally you are so tired of looking for the content that you\nactually click on one of the sponsor ads and purchase a subscription. It is a\nsystem designed to wear people down, and it worked quite well, at least for a\nwhile. But I can tell you this much: this was a trick first tried in the\nUnited States. It was not invented in Russia!”\n\nGusev and Vrublevsky first met as a consequence of their common links to\npornography of the rather extreme variety. In 1998, Gusev was administrator of\na Russian online forum that catered to webmasters who marketed films and\nimages involving bestiality and sex with farm animals. Vrublevsky’s market,\nwhich he served through his Red & Partners holding company, were those who\nenjoyed viewing violent pornography, mainly pictures and short films depicting\nrape or other forms of forced sex, incest, and\nsodomy.[14](08_chapter08.xhtml#fn14)\n\nGusev was able to profit from the business because he owned a credit-card\nbilling firm called Digital Internet Billing, or “DiBill” for short. The\nbilling firm relied on connections to the Dutch banking system, where,\naccording to Gusev, a sizeable portion of the market for his company’s product\nhappily resided.\n\nOne day, Gusev received an instant message from Vrublevsky, asking to meet and\nto discuss combining their efforts and creating a consolidated payment\nprocessing company to service the booming porn industry that had sprouted up\nvirtually overnight with the broad adoption of the commercial Internet in the\nWest.\n\n“We spoke several times in Moscow, and he was seeming so enthusiastic and so\nmotivated about this new business, ChronoPay, and he offered me to join him,”\nGusev said. “I thought for this time it could be a very good step in my\ncareer. I wish I had been a bit smarter and refused his proposal.”\n\nIn 2003, they made it official. Red & Partners teamed up with Gusev’s firm\nDPNet to form a new corporation in the Netherlands, and ChronoPay was born.\nAmong the investors was Vladimir Tsastsin, the chief executive of an Estonian\nInternet domain name registrar called EstDomains. Tsastsin and Vrublevsky\nwould become fast friends, and for the next five years, Tsastsin’s EstDomains\nwould become the most popular domain registrar among Russian webmasters\n(particularly those pushing spam and malware).[15](08_chapter08.xhtml#fn15)\n\nFor a short while, Gusev and Vrublevsky worked side by side in the same\noffice. But after less than a year, both men were bickering constantly about\nthe direction that the firm should take. After a protracted disagreement over\nwho should be allowed to buy Gusev’s shares in ChronoPay, Gusev sold DPNet to\na Russian businessman named Leonid Mikhailovich Terekhov and went off to start\nwork on establishing GlavMed and SpamIt.\n\n“We were sitting in one office just opposite each other, and I guess because\nof this we should be considered some kind of friends or business partners,”\nGusev said in a 2011 interview. “But it worked only for [the] first five or\nsix months. After that, we started having some problems communicating with\neach other. The problem was that I wasn’t supporting his decisions and he\nwasn’t supporting my decisions.”\n\nMeanwhile, something strange was brewing at ChronoPay. The company had begun\nto attract legitimate businesses—not just porn sites, but brand-name companies\nin Russia that were eager to help customers find alternative ways to pay for\ntheir goods. Few working-class Russians used or even had credit cards at the\ntime, and while there was a growing desire for ecommerce, surprisingly few\ncompanies doing business in Russia were willing and able to help consumers use\ntheir bank accounts to pay for things online.\n\nBy 2006, ChronoPay had attracted as clients a number of Russia’s top brands,\nincluding Russian mobile providers MTS and Skylink, and even more Western-\noriented nonprofit organizations, such as the World Wildlife Fund. Millions of\nRussians could suddenly pay their heating or telephone bills online, or\npurchase concert and airline tickets, all via ChronoPay.\n\nIn securing these bigger, legitimate clients, Vrublevsky may have been\nensuring that black and gray businesses would have sustained access to banking\nsystems that would be willing to process riskier transactions, such as online\npharmacy purchases and credit card transactions related to extortionist sales\nof rogue antivirus software, Gusev said.\n\n“The main reason ChronoPay was so successful for so long in all of these gray\nand black businesses is that they have had a pool of white clients whose\nbusiness was covering up these gray and black dealings,” Gusev said. “They\nwere using that to win better processing rates from the [acquiring banks],\nbecause they would say, ‘We’ll bring you millions of dollars in transactions\nfrom some of the largest Russian companies, and all you have to do is help us\nprocess these other things.’”\n\nStefan Savage, the University of California, San Diego professor who made\nhundreds of legal drug purchases through pharmacies run by GlavMed, Rx-\nPromotion, and dozens of other partnerkas said ChronoPay wasn’t really a\ncredit card processor, but rather a marketer and reseller of payment services\n(known in the business as a payment service provider or PSP).\n\n“They didn’t have their own bank relationships, but they worked with other\ncompanies that had that relationship. They had lots of deals with other people\nto help get money through,” Savage said. “They were representing on behalf of\nclients, fake clients who were selling drugs via different banks, and they\nwould round-robin their Rx-Promotion business through front companies that\nthey created. And later, when the banks would figure out what was going on,\nChronoPay would deny all knowledge of what its front companies were doing.”\n\nIn other words, ChronoPay and Vrublevsky were instrumental in establishing the\norganizational, legal, and technical cover that spammers needed to be able to\naccept credit card numbers for the pills they were pimping. ChronoPay and\nVrublevsky also used these same obfuscation techniques to hide their integral\nrole in the processing of tens of millions of dollars in credit card payments\nfrom Americans and Europeans who were victimized by scareware scams. As we’ll\nsee in Chapter 9: [Meeting in Moscow](09_chapter09.xhtml), Vrublevsky claims\nthat his relation to scareware scams was merely as an advisor who helped these\noperations set up the front companies and payment systems to help make the\nwhole operation appear aboveboard to the credit card companies.\n\nAccording to Savage, the service that ChronoPay provided is known in the\nindustry as “factoring.” The company would take multiple clients, load them up\nwith credit card processing, and then map their transactions into accounts on\nbehalf of shell companies that they had, companies that they’d represented to\nthe banks as being the true customer. And then Vrublevsky and other ChronoPay\nemployees involved would simply pay these clients out of their own pockets.\n\nIn short, dodgy organizations turned to ChronoPay primarily when they had few\nother options.\n\n“They were willing to take on and manage all of these really shady customers\nthat were not going to be taken as customers by anyone else,” Savage said.\n“There were lots of games being played with several banking partners, and\nChronoPay was very good at playing these games.”\n\nThose partnerships—principally with financial institutions in the former\nSoviet republics of Azerbaijan, Georgia, and Latvia—were the primary\ncontributor to ChronoPay’s dominance in processing transactions for rogue\nInternet pharmacies and scareware scams behind the company’s legitimate front.\nThankfully for Vrublevsky and Gusev, this activity was largely eclipsed for a\nwhile by the much higher volumes of transactions coming from comparatively\nlegitimate Russian companies.\n\n“ChronoPay is a unique company from one point of view, because it is famous in\nRussia for [its association with] big-name brands in that country,” Gusev said\nin a 2010 interview. “But everyone knows who is the owner of the company and\nwhat he did before this company and what he does right now.”\n\n♦ ♦ ♦\n\nTwo years after Vrublevsky and Gusev parted ways as cofounders of ChronoPay,\nGusev had become successful in his own right. GlavMed and SpamIt were pulling\nin millions of dollars a month and employing some of the smartest computer\nprogrammers that Moscow had to offer.\n\nNot to be outdone by his rival, in 2007, Vrublevsky and Hellman would launch\nRx-Promotion, seeking to lure away many of the top spammers from SpamIt. Rx-\nPromotion was entering an already crowded field including some two dozen other\nrogue pharmacy partnerkas. But from the start, Rx-Promotion would have an\nadvantage over its competitors. It would specialize in offering highly\nrestricted and addictive prescription medications—such as hydrocodone and\nValium—to any and all customers, regardless of whether the customers had a\ndoctor-approved prescription.\n\nGusev said GlavMed initially offered controlled medications as well, but that\nit decided early on that the market for these pills was too volatile and\nrisky.\n\n“When GlavMed started operations in 2006, there were some controlled\nsubstances, but we didn’t understand what we were getting into then,” Gusev\nsaid. “A couple of years later, we made some strategic decisions not to have\nany connection to controlleds. After all, there is not serious damage for\nhealth if you are selling Viagra. But controlleds…if you selling these over\nthe Internet, you are most often selling to drug-addicted people. And\nhonestly, I don’t want to be some kind of drug dealer.”\n\nGusev’s timeline doesn’t quite match up to the records leaked from SpamIt and\nGlavMed, which show that these two partnerkas continued to sell some\ncontrolled prescription drugs until at least mid-2009.\n\n♦ ♦ ♦\n\nAll indications suggest that—despite Vrublevsky’s early warning of the\npolitical and legal machinations set against him—Gusev underestimated his\nformer partner’s resolve, or else could not find properly connected allies in\nRussia’s political and legal apparatus to derail the slowly building criminal\ncase targeting him and his businesses. For one thing, Gusev did not start\ntaking precautions to outflank Vrublevsky until the beginning of 2010, when he\nfinally accepted that he was under investigation by Russian FSB agents, and\nthat investigators were seeking to paint him as “Spammer #1 in Russia.”\n\nThe case against Gusev coincided with a push by Russia’s then-President Dmitry\nMedvedev to attract foreign investment for “Skolkovo.” The project was an\nambitious technology park being built outside Moscow that is intended to serve\nas a Russian version of Silicon Valley, America’s biggest incubator of high-\ntech innovation. The Skolkovo project gained momentum in March 2010, after\nInternet hardware maker Cisco Systems Inc. pledged $1 billion to the project,\nand Silicon Valley venture capital firm Bessemer Venture Partners promised\ninvestments worth $20 million over two years.\n\nBut Medvedev and other leaders knew that if they were going to succeed in\nattracting more investment from Western nations, they would need to tidy up\nRussia’s reputation for being lax in pursuing cybercriminals within its\nborders. Gusev was the perfect sacrificial goat to start with. He was to be\nthe first high-profile cybercrime target of the National Anti-Corruption\nCommittee, a body aimed at helping state agencies and ministries cleanse\nthemselves of corrupt officials who often turned a blind eye to crime in\nexchange for bribes or “donations.”\n\nAs if to validate the anti-corruption committee’s choice, Gusev’s first\nresponse to counter the criminal case being aggressively waged against him was\nto attempt to bribe public officials into delaying his case, feeding him\ndetails about its progress, and running interference on his behalf.\n\nOn January 9, 2010, Gusev reached out to GlavMed-SpamIt coadministrator Dmitry\nStupin, via online chat to discuss options for avoiding or delaying his\nprosecution. Gusev told Stupin that he might be able to purchase protection\nfrom the charges by funneling money to key Russian politicians who have\ninfluence over investigators.\n\nSpecifically, Gusev suggested purchasing a sponsorship of the Volleyball\nFederation of Russia. The price tag for this is an official sponsorship fee of\n10 million rubles (about $350,000), plus $150,000 in cash. The official head\nof the federation, Nikolai Patrushev, is a powerful man in Russian law\nenforcement. Patrushev was director of the Russian FSB, the successor\norganization to the KGB, from 1999 to 2008. He has been secretary of the\nSecurity Council of Russia since 2008.\n\nAccording to Gusev, it is typical for Russian sport leagues and charities to\nbe used as vehicles for funneling money into the pockets of policymakers.\n\n“In Russia, sports is not really a business. It’s a way of getting business\nsettled,” Gusev said in a telephone interview. “I have one friend who is a\npretty famous hockey player. One time he told me that in [the] hockey league,\nthere are only two teams who might earn something, while the other teams have\nonly losses. Sport in Russia is some kind of…from one point of view one can\nmeet some new faces and start some relationship for the future, and from other\npoint of view you can get some kind of protection. That’s because all\nleagues—basketball, football, hockey, whatever—all have persons from the\ngovernment who are somehow controlling them.”\n\nThe phenomenon Gusev describes is well documented. One example comes from a\nbook by Lennart Dahlgren, former head of the Russian division of Swedish\nfurniture maker IKEA. In Despite Absurdity: How I Conquered Russia While It\nConquered Me, Dahlgren writes of having to pay bribes of 30 million rubles ($1\nmillion) to Russian charities that helped funnel money to bureaucrats and top\nofficials.\n\nIn May 2011, Gusev told me in a telephone interview that he was a paid sponsor\nof the Russian volleyball league, hoping to persuade someone to stop the\ncriminal case against him. Gusev was convinced, and other leaked documents\nappear to confirm his suspicions, that law-enforcement interest in his\nactivities was paid for by Pavel Vrublevsky, his former business partner\nturned competitor.\n\nIndeed, in late 2010, Vrublevsky secured a sponsorship of the Russian\nBasketball Federation for ChronoPay. The basketball federation is headed by\nSergei Ivanov, a former KGB officer who was tapped by Russian President\nVladimir Putin as deputy prime minister of Russia. In fact, ChronoPay used\nties to Ivanov as an advertisement for its success and power. In a series of\nphotographs of ChronoPay executives on the company’s blog is a picture of\nVrublevsky and Ivanov standing in the front row at a basketball game cheering\non their team, both men in business suits and smiling broadly.\n\nIt remains unclear how much Vrublevsky had to pay to secure that sponsorship,\nbut several clues suggest it was more than $1 million. A story in a March 2011\nprint edition of the Russian daily Kommersant stated that the basketball\nfederation’s budget was increased to approximately $6 million due to\ncontributions from sponsors—ChronoPay, Russian investment group VTB, and\nRussian automaker Sollers. In that article, Ivanov is quoted as saying that\nVTB contributed more than half of the budget, and that the other half was\ncontributed by ChronoPay and Sollers.\n\n“If Pavel wants me to be named the World’s Number One Spammer, he pay lots of\nmoney to get that name for me, but you know I never tried to do any research\nto find out who actually was the number one spammer,” Gusev said. He was\nreferring to a then-just-released paper by the UCSD researchers, who found\nthat spammers working for Rx-Promotion blasted out more than twice the amount\nof spam of any other program, including SpamIt.\n\n“I thought it should be the owners of the largest botnets, and I thought most\nof them were working with SpamIt,” Gusev said. “But this research shows that\n25 percent of spam was for Rx-Promotion sites. It’s very difficult for Pavel,\neven with all this information and money and influence, to persuade people\nthat the bigger problem is not with him.”\n\nChat records from late January 2010 show that Gusev and Stupin sent initial\n“donations” of $210,000 and $115,000 from their company, Despmedia, to the\nVolleyball federation. In another online chat a month later, Gusev tells\nStupin that their total expenses for bribes sent to Russian law-enforcement\nofficials exceed $400,000.\n\nIn a conversation dated February 19, 2010, Gusev reports that he just paid\n$20,000—$5,000 to a middleman and $15,000 to someone from the Prosecutor\nGeneral’s Office, the law-enforcement body that was investigating him—for\ninformation and for “delaying” his case. In the same chat log, Gusev says that\nhe has found someone—a very able man, a lawyer and reshalshik (problem-\nsolver)—who can provide a “complete set of services” to deal with the “RedEye\nproblem.”\n\nGusev secured promises from this man that a donation in the proper amount\nwould virtually ensure the incarceration of Vrublevsky and the destruction of\nhis various shady businesses. But the price tag for this assurance was\nsteep—$1.5 million.\n\nGusev says he has met a reshalshik and asks Stupin for advice on how to deal\nwith the guy in addition to the $1.5 million. This fixer’s price is that Gusev\nand Stupin must agree to help an old, mutual acquaintance start a competing\nrogue Internet pharmacy program.\n\n“I found a person who is willing to help me in this situation with RedEye,”\nGusev writes. “This guy has a proven scheme, because he is a very strong\nlawyer. A real fixer-upper. For his service, along with very large sum of\nmoney, he is asking for something in return—he is asking to help his friend—a\nvery famous webmaster, who faced a similar problem to the one we are facing,\nand who was saved by that person. This ‘friend’ is not doing anything right\nnow. This lawyer is asking us to help him with establishing an online pharmacy\nprogram. I am not happy about the idea of creating more competition, but out\nof all the people I talked to, only this guy offered a structured solution to\nthe problem, giving us hope.”\n\nGusev then goes on to talk about the volleyball federation sponsorship, which\nis code for funneling money to corrupt FSB agents to run interference. He\nsays: “People from the volleyball association can and will cover us, using\ntheir FSB connections, but they can do very little with the Prosecutor’s\nOffice. They can only prolong the legal proceedings. They will also not be\nable to prosecute Red. The person who we are asked to help is my old\nacquaintance—Pet—the owner of лолного [this is a colloquial term—pronounced\n“loll-nah-vah”—referring to Lolita or child porn sites]—which handles billing\nthrough billcards.” Gusev is almost certainly talking here about Evgeny “Pet”\nPetrovsky, the Belarusian owner of the Sunbill/BillCards payment processing\nfirm who was kidnapped by Loginov’s gang in [Chapter 2](02_chapter02.xhtml).\n\nAfter Gusev breaks the news that this fixer-upper lawyer is charging $1.5\nmillion plus a personal favor, Stupin exclaimed, “Oh, my god! What does he\npromise for that?”\n\n“He promises that Red would remain in prison and would not be able to buy his\nway out,” Gusev answered. “Plus, he is going to lose a large portion of his\nbusiness and will be left with no money to fight the war.”\n\nIn a telephone interview in mid-2011, Gusev explained his actions thusly: “All\nthat I wanted was to speak with someone from FSB [who] was making this [case]\nfor Pavel, and to persuade them to stop all this conflict before it’s too\nlate,” he said. “Unfortunately, this didn’t help me very much.”\n\nIn summer 2010, tens of thousands of emails and internal documents would be\nleaked from ChronoPay by unknown insiders or attackers who had hacked into the\ncompany’s network—offering countless examples of the sort of activity that\nVrublevsky had denied orchestrating for years.\n\nWhen I asked Gusev whether he’d been responsible for the incident, he denied\nit, but then allowed that his involvement was a logical assumption, given the\nwar of attrition that had earlier caught him flat-footed.\n\n“Pavel has one year of advantage on me because I wasn’t really expecting that\nhe would make all these things public about me and our business,” Gusev said.\n“Now, I am some kind of cybercriminal, and he is some kind of cybercriminal.\nThe most logical decision is for us to solve this quietly, but he wants to\nharm me so desperately that he is making decisions without understanding the\nconsequences.”\n\nConvinced that Gusev had been behind the leak of ChronoPay documents and\nemails, Vrublevsky paid a local hacker to break into and leak the SpamIt and\nGlavMed customer database.\n\nThe following chat log is dated August 28, 2010, just days after SpamIt’s\ninternal database found its way to U.S. law-enforcement agencies. In this\nconversation, Stupin and Gusev discuss whether to close SpamIt.\n\nGUSEV: It looks like I am in deep shit. Red gave our database to Americans.\n\nSTUPIN: To which Americans?\n\nGUSEV: I can’t tell exactly, yet. Probably to FBI or Secret Service. Have you\nread on Krebs’s blog about the meeting at the White House regarding illegal\npharmacy problems on the Internet?\n\nSTUPIN: No.\n\nGUSEV: krebsonsecurity.com/2010/08/white-house-calls-meeting-on-rogue-online-\npharmacies\n\nSTUPIN: Maybe you return back to Russia?\n\nGUSEV: I am planning to do that. I am really worried now.\n\nGUSEV: Do you think “closing down” will help? Just realize: they have our\nENTIRE database… There are 900,000 records. What are we going to do with\nthose? For conviction and 5-year jail time, it is only necessary to prove 1\ntransaction! What is the worst? They combine the sentences and it is possible\nto get 5 life sentences.\n\nGUSEV: I also think we need to shut the operations down, because it’s an\nabsolute disaster!\n\nGUSEV: Regarding closing down—I think we need to shut down SpamIt first. In a\nmonth or 1/2 month—GlavMed.\n\nGusev and Stupin would close SpamIt.com in late September 2010, replacing the\nSpamdot.biz homepage with the following message to affiliates:\n\nBecause of the numerous negative events that happened last year and the risen\nattention to our affiliate program, we’ve decided to stop accepting the\ntraffic starting 1.10.2010 [October 1, 2010]. We find the decision the most\nappropriate in this situation. It provides avoiding the sudden work stop which\nleads to the program collapse and not paying your profit.\n\nIn our case the whole profit will be paid normally. All possible frauds are\nexcluded. Please transfer your traffic to other affiliate programs by\n1.10.2010.\n\nThank you for your cooperation! We appreciate your trust very much!\n\nImmediately after SpamIt’s closure, the volume of junk email sent worldwide\ndropped noticeably—20 to 40 percent, depending on estimates—as spammers\nemployed by the program sought to move their traffic to other partnerships\nthat might pay for their services. Experts who tracked the top spam botnets\nused to promote SpamIt’s “Canadian” pharmacy sites quickly noticed that most\nof the major botnets—including Grum, Rustock, and Cutwail—essentially were\nparked in neutral for several weeks as the botmasters tried to figure out new\nways to earn a living from their crime machines.\n\nThanks to a New York Times story that—according to the leaked ChronoPay\nemails—was sourced in part by outreach from the public relations staff of the\nRussian Association of Electronic Communications (RAEC), Gusev had become the\nworld’s biggest spammer, even though Gusev claims that he was never a spammer\nin the conventional sense. By the time Moscow police searched his apartment,\nGusev had already fled Russia with his wife and young daughter, reportedly\nheaded for Spain.\n\nBut Gusev wasn’t going to go down without a fight. In November, he launched\nredeye-blog.com, a website that he used to publicly catalog Vrublevsky’s\ncolorful past, even hiring a native English speaker to translate the blog for\nWestern audiences. It didn’t take long for Vrublevsky’s many enemies to follow\nsuit, airing RedEye’s dirty laundry by posting comments on the blog. Hundreds\nof adult webmasters with long memories of Vrublevsky’s wrongs against them\nbegan using the blog to chronicle the millions of dollars Vrublevsky still\nowed them from the Fethard disaster.\n\n“Moscow is a good place to stay when you have money and good friends who can\nhelp you with your problems,” Gusev said in a phone interview in November\n2010. “I’m trying to ruin his ChronoPay because if he will not have money, he\nwill hopefully stop all these things.”\n\nNot long after that interview with Gusev, Vrublevsky finally acknowledged that\nthe Pharma Wars, as many were calling their feud, had progressed beyond the\npoint of return. Rather, Vrublevsky said wryly, neither side appeared to be\ndeterred by “mutual assured destruction.” Here he was referring to a doctrine\nof military strategy in which both sides in a nuclear arms race are\ndiscouraged from launching a first strike based on the certainty that the\naggressor’s action will trigger an equivalent response.\n\n“The problem is that Gusev is not trying to hit me with his weapons, but he is\ntrying to scare me,” Vrublevsky said in one of his many phone calls to this\nauthor. “His claim that he is staying abroad forever—this all is bullshit\ntargeted to his webmasters, and of course it all sounds like a James Bond\nstory, but nobody hides like this. In reality, Gusev is waiting for me to call\nhim up and say, ‘Okay, man, let’s stop this war.’ But there’s nothing in that\nChronoPay compromat that can make me stop or is able to save him now. It’s\njust a way he thinks he’ll be able to blackmail me every few months, and\nnothing else.”\n\nMeanwhile, consumers all over the world were enjoying a brief reprieve from\nthe barrage of spam email and the malware it carried with it that threatened\nto infect their computers and steal their identities. The spam email empire\nteetered on the brink of collapse. When asked whether he was worried that his\nefforts to embarrass and inconvenience Vrublevsky might further damage an\nindustry that he’d helped to build and that had made him quite wealthy, Gusev\ntold me it was a risk he had to take.\n\n“At least we will both lose lots of time, power, and money, and no one will be\na winner here,” Gusev said, speaking by phone from an undisclosed location\nabroad. “I am still making some reports to continue this conflict with only\none reason. Because if I stop now, in one or two years Pavel will find the\npossibility to hit me again on something else, and I don’t want to [allow] him\nthat.”\n\nI believed Gusev when he told me facts about his life, his business, and his\nconflict with Pavel. He may not have always told me the whole truth, but I had\nlittle reason to doubt his version of events. In contrast, Vrublevsky often\nlied to me or stretched the truth well beyond believability in our interviews.\nEven so, he’d promised to be more forthcoming if I met him on his own turf,\nand I was anxious to hear his side of the story. It was time to renew my\npassport.\n\n* * *\n\n[13.](08_chapter08.xhtml#fnr13)Note that Vrublevsky denies being RedEye, and\nspeaks of RedEye always as “Mr. RedEye,” which is a bit of a joke. Gusev’s\nblog about Pavel is called redeye-blog.com.\n\n[14.](08_chapter08.xhtml#fnr14)Vrublevsky denies even being associated with\nthe parent company that owns all these sites, even though incorporation\nrecords put it at the same address in the Netherlands that ChronoPay used in\nits registration documents. What’s more, the Red & Partners website was for\nmany months hosted on Internet address space assigned to ChronoPay by European\nInternet address authorities.\n\n[15.](08_chapter08.xhtml#fnr15)Tsastsin dismissed as “rubbish” claims that\nEstDomains was courting spammers and malware purveyors. Nevertheless, his\ncompany’s business would later be stripped of its ability to issue new domain\nnames by Internet regulators, after a report in the Washington Post exposed\nthat he had been convicted in Estonia of conspiracy to commit credit-card\nfraud, money laundering, and forgery, among other offenses. EstDomains ceased\nto exist after that incident, but Tsastsin and six other associates allegedly\ncontinued their illegal schemes. In 2011, he was arrested by Estonian\nauthorities in an international law-enforcement operation aimed at dismantling\nthe DNSChanger Trojan. This huge botnet had infected more than four million\nPCs worldwide with malware that hijacked search results, shut down security\nsoftware, and earned Tsastsin and his business partners more than $14 million.\nTsastsin and his colleagues were charged with wire fraud and money laundering,\nbut in late 2013, they were acquitted by an Estonian court. As of this\nwriting, the men are awaiting extradition from Estonia to stand trial in the\nUnited States on cyberfraud charges.\n\n\nChapter 9\n\n## MEETING IN MOSCOW\n\nThe frozen Moscow River crunched and groaned as it churned beneath the twin\nengines propelling our sleek, modern icebreaker cruise ship at a steady clip.\nOn the far shore, the formidable and beautiful edifice of the Kremlin towered\nover the frosted black water. An open door behind me flooded the bracing night\nair with the cacophony of pulsing Russian pop music, clinking glasses, and the\ndin of flatware on plates.\n\nFebruary is hardly the warmest month for a trip to Russia, but a press tour\ninvitation in 2011 from Russian security firm Kaspersky Lab proved too timely\nto pass up. I wanted to surprise Vrublevsky—and I wasn’t sure he’d be a free\nman much longer—so I jumped at the invitation.\n\nI’d been studying the Russian language and culture—and its seedy underbelly of\ncybercrime—for more than five years, and visiting the country had long been a\ndream of mine. But I let few people know that I was going to visit and told no\none my real reason for making the trip: to meet Pavel Vrublevsky in Moscow,\nand tentatively Igor Gusev on a side trip to Europe (which I never followed\nthrough with). I had an idea at the time that their feud would make an\ninteresting story, and I was anxious to meet each man face to face.\n\nI had wanted to meet the infamous cybercrooks then because I believed this\nmight be my one chance to interview them in person without prison guards\npresent. I was preparing to run a series of articles documenting the Pharma\nWars between Gusev and Vrublevsky, because between the two of them, they were\nresponsible for probably 75 percent of the spam on the planet. I was certain\nneither man would want to talk to me much after that series started.\n\n“Brian! Come, the performance is starting,” bellowed a broadly grinning and\nwaving Eugene Kaspersky, barely audible over the ship’s powerful turbines and\nthe crackling river ice. Following him through the door leading from the stern\nof the boat into the main hall, I nearly crashed into a troupe of young men in\nbaby blue jumpsuits turning cartwheels and performing a traditional Russian\nfolk dance on the wooden dance floor between the bar and the dinner tables.\n\nThe icebreaker cruise with Kaspersky took place the day before I was to depart\nfrom Moscow. After dinner was served, Kaspersky and I each enjoyed glasses of\nice cold Russian vodka, and he began telling me about his cryptography work\nfor a former Soviet institute in the 1980s that was sponsored by the Russian\nMinistry of Defense and the KGB (then the Russian equivalent of the U.S.\nFederal Bureau of Investigation).\n\nIt also emerged that we both got interested in computer security after getting\nhacked. Eugene became obsessed with viruses after finding malware on his\ncomputer in 1991. I started learning all I could about computers and Internet\nsecurity a decade later, when my home network was overrun by the “li0n worm,”\na contagion unleashed by a now-famous Chinese hacker that locked me out of my\nsystems and trashed several servers.\n\nAs I watched the dancers careen from one corner of the ship to the other, my\nthoughts wandered back to the day I’d arrived in Moscow and immediately sought\nan audience with Vrublevsky. I hadn’t slept a wink since my meeting with the\nnotorious cybercrime figure, and I kept replaying the day’s events in my head.\n\nMy flight to Moscow was routed through John F. Kennedy International Airport\nin New York, where I ran into Paul Roberts, a security journalist and analyst\nwho had recently begun working for Kaspersky. Roberts was joining the press\ntour as well.\n\nI had never been to Russia, but as we approached Sheremetyevo International\nAirport, I could see that Moscow was up to that point exactly how I’d pictured\nit: overcast, cold, snowy, and windy.\n\nWaiting for the plane to touch down, I was suddenly struck by how little I had\nactually done to prepare for my trip, and for the first time, I was a bit\nscared. Prior to my departure, a family member who’d been in the foreign\nservice had given me some unsolicited advice on ways to ensure my safety while\nin Moscow. Much of his wisdom was common sense, such as “arrange all meetings\nin public spaces,” “travel nowhere alone,” and “avoid getting into cars with\nunfamiliar people.” Nevertheless, I was stunned at how soon after arriving in\nMoscow I would be forced to ignore all of that advice.\n\nRoberts and I were supposed to have a car waiting at the airport to take us to\nour hotel, but high winds had delayed the departure of our flight from New\nYork. When we arrived in Russia, the hired car was nowhere to be found.\n\nAs we stepped out of the main terminal and onto the slushy sidewalk, we were\nimmediately pegged as Americans and accosted by perhaps a half-dozen men\noffering us “cheap” cab rides from the airport. Unfortunately, our hotel was\nabout thirty kilometers from the airport, and the trip would be anything but\ncheap.\n\nVery soon after we walked out of the terminal, I began to feel queasy, enough\nso that I thought for sure I was going to lose my breakfast all over the\ncabbies who were constantly in my face and having trouble taking “no” for an\nanswer. I retreated to a snow-covered metal bench to catch my breath and\nsteady myself. The cabbies seemed to sense that they might regret getting too\nclose and mercifully left me alone for a couple of minutes. Presently, Roberts\nambled in my direction after scouting the length of the airport curb for any\nsigns of our prearranged pickup.\n\n“I’m not really crazy about the idea either, but it looks like we may have to\nhire one of these guys,” he said, squinting through the driving snowfall.\n\nFive minutes later, we were crammed into the back of a black, compact Russian-\nmade automobile, racing through the soggy streets and swerving around the\nslower traffic crowding onto Leningradskoye Shosse, the main highway from the\nairport into central Moscow. I took this opportunity to try out my prepaid\nwireless Internet service. Because I rarely use unsecured public Wi-Fi and was\neven less interested in doing so in Moscow, I wanted to avoid being at the\nmercy of coffee shop or hotel wireless services while in Moscow. So I had\narranged to purchase Internet access in advance via a company called XCom\nGlobal. The company’s service will ship you a USB dongle just prior to your\ndeparture, which in theory should allow you to have 3G wireless Internet\naccess more or less anywhere in the city of your choosing.\n\nAs I plugged the dongle into my Macbook in the back of the cab, however, I was\ndismayed to find that it was impossible to keep a signal for more than a few\nseconds at a time. I thought perhaps this was because we were hurtling down\nthe highway at 120 kilometers per hour, but I later found the service was just\nas unreliable when seated at a coffee shop near our hotel smack in the middle\nof downtown Moscow. What few plans I had made in advance of my trip were\nrapidly falling apart.\n\nForty-five minutes and the equivalent of $170 later, Roberts and I exited the\ncab and checked in to the Marriott Grand Hotel on Tverskaya Street, the broad\ncommercial thoroughfare that runs from Red Square through central Moscow. At\nthe front desk, an attractive young woman behind the counter requested my\npassport. When I produced the passport, she took it, curtly told me I could\ncome by and pick it up later in the day, and then disappeared into a back\noffice.\n\nI didn’t much care for the idea of relinquishing my passport, but I also\ndidn’t have many other options. My unease soon turned to dread. I had been\nthere all of five hours when I was alarmed by a Google news alert that I’d set\nup to monitor Internet postings that featured my name. The alert linked to a\nbrief message posted to the Russian blogging service LiveJournal that\nbroadcast my precise location. The posting read: “American cybersecurity\nblogger Brian Krebs is now in Russia, staying at the Moscow Marriott Grand.”\n\nI ran upstairs and bolted the door to my spacious hotel room, immediately\nbeginning to wonder if I had made a huge miscalculation in coming to Russia.\nEventually, I convinced myself otherwise, reminding myself that this interview\nwas crucial to wrap up all the work I had been doing to expose these spammers.\nWithin a few hours I finally got up enough nerve to call Vrublevsky. When I\ntried the third cell phone number I had for him, Vrublevsky answered.\n\n“Duuuuuuuudddde!” he bellowed into the phone. “It’s 7 a.m. where you are. Who\ndied?”\n\nI informed Vrublevsky that I was in fact in his time zone, and that we should\nmeet as soon as possible. After another long “Duuuuuuuuddde!” Vrublevsky\npromised to send a car if I would wait in the hotel lobby. He told me he’d be\nsending along with the driver his receptionist, named Vera. He proceeded to\ndescribe Vera as this grossly overweight, unattractive older lady but, hey,\nshe spoke English and knew how to deal with Westerners, so she was coming, he\nsaid.\n\nFifteen minutes later, I was seated in the lobby, nervously waiting for Vera\nand watching incoming guests as they stomped off snow and trudged through the\nhotel’s revolving door. Sitting there nursing a cup of hot tea, I found it\ndifficult to avoid staring at a gorgeous, slender, dark-haired young woman\nstanding nervously just beside the door, clad in skin-tight jeans and a puffy\nwhite coat. After a while of unsuccessfully trying not to look in her\ndirection, I had trouble ignoring the fact that she was also trying not to\nstare at me.\n\nAfter about five minutes of this dance, the young woman came over and asked if\nmy name was Brian. I was momentarily alarmed (I knew next to no one in Moscow\nat this point) until she told me her name was Vera, and I suddenly remembered\nwith a smile why I could trust almost nothing of what comes out of\nVrublevsky’s mouth.\n\nThe joke continued when, after enduring about twenty minutes of creeping\nMoscow rush-hour traffic to travel a couple of miles, we arrived at\nChronoPay’s offices and I ran into the same girl clad in different clothes. It\nturns out that Vera has a twin sister who also works at the company.\n\nVrublevsky was feeling especially punchy that evening, and he was clearly\nexcited by my surprise visit. True to form, almost immediately upon my arrival\nhe launched into an elaborate tale. Apparently, someone had arranged a police\nraid on the Rx-Promotion Gold Party, a gathering held four nights earlier at\nMoscow’s Golden Palace. The normally boozy and bawdy event is thrown for all\nRx-Promotion affiliates—those several hundred individuals who pimp Rx-\nPromotion pharmacy sites. The top affiliate was to win an actual one-kilogram\nbar of gold, while other leading pill-pushers would win iPads and iPhones.\n\nUnfortunately for the Rx-Promotion affiliates, the party was broken up when\nseveral busloads of men in ski masks and machine guns stormed the party and\nbegan interrogating the revelers. Vrublevsky claims the men were sent on\nbehalf of the drug enforcement authorities, but according to several of those\nin attendance who posted on various Russian forums about the experience, the\npolice appear to have used the raid as a pretense to match Rx-Promotion\naffiliates’ online identities to real faces and names. I privately decide that\nVrublevsky’s version of the story is unlikely, but I’m unwilling to interrupt\nhis narration in case it offends him and he decides to show me the door—or\nworse.\n\nVrublevsky never showed at his own party. As he explains it, the day before\nthe gathering his wife inexplicably pleaded with him to go on an emergency\nvacation to the Maldives. What’s more, someone had the presence of mind to\ntake down all Rx-Promotion logos from the rented party space hours before the\npolice arrived.\n\n“The whole Russian Internet knew there was supposed to be an Rx-Promotion\nparty in Moscow, and obviously everyone would expect logotypes of Rx-\nPromotion,” Vrublevsky tells me, chain-smoking Marlboros in his company’s\ncramped boardroom, which features an enormous, outdated map of the world\nflanked by swords and a giant red Soviet-era flag.\n\n“And for some reason,” he continued, speaking about himself in the third\nperson, “everyone expected Mr. Vrublevsky would show up there. Obviously, Mr.\nVrublevsky would probably not be able to control every motherfucker with a\ncell-phone camera around. And for that reason, Mr. Vrublevsky decided not to\nbe there. At the same time, someone else decided to remove all of the Rx-\nPromotion logos around.\n\n“Mr. Vrublevsky flies to the Maldives to have a one-week vacation. He then\ngets a phone call that there are five buses of special forces from Russian DEA\ngoing to that party, closing down Golden Palace and two nearby cafes, just for\nthe reason that there are too many special forces and dogs and cameras.\nGetting in there just to find out some very stupid shit: there is no Mr.\nVrublevsky, no logotype, absolutely nothing to shoot on their video.”\n\nThe story about how police raided the Rx-Promotion party to dig up dirt on its\nfounders and affiliates was certainly amusing, but it appears to have simply\nbeen one of nine such casino raids and nearly one hundred “gambling den” raids\nthat were conducted in 2011 by a new antigambling sheriff of Moscow, Anatoly\nAndreev.\n\nAfter relating this seemingly random anecdote to me, Vrublevsky asks Vera to\nbring us some coffee and we make some small talk about the Moscow traffic and\nabout the man stomping above us, shoveling huge mounds of snow off the\nbuilding’s roof. I ask Vrublevsky a bit about his family, and he says with a\nknowing smile and a sardonic laugh that his father worked for many years as a\nresearcher at Nycomed, a large European pharmaceutical company.\n\nI ask him about the origin of the sword that flanks the Soviet flag standing\nbehind my chair. Vrublevsky tells me a long story about how it was presented\nto him by the leader of the capital of Dagestan, whom he describes as a close\npersonal friend. He doesn’t tell me the guy’s name, only that he was—at least\nat one time—mayor of Makhachkala. According to the Moscow Times, that person\nis likely Said Amirov, a four-time mayor who is said to have survived more\nthan fifteen assassination attempts and is paralyzed from the waist down.\nAlso, according to a February 2014 story in the Moscow Times, Amirov is\ncurrently on trial after being charged in 2013 with illegal arms trafficking,\nso it’s pretty funny that he gave Vrublevsky a sword.\n\n“It turns out that the main dude I was with there, his uncle was the mayor of\n[Dagestan’s capital city] Makhachkala,” Vrublevsky recalled. “This mayor guy\nis the most blown-up guy in the world. This mayor dude has been blown up like\nthirteen fucking times. They didn’t kill him—he’s in a wheelchair. But once\nthe local terrorist groups blew up a whole neighborhood just to try to kill\nhim. Not just one building, but the whole neighborhood.”\n\nVrublevsky dodges direct questions about why he was in the turbulent\nmountainous Russian republic, a mostly Muslim region that borders Georgia and\nthe breakaway regions of Chechnya. But it is likely that Vrublevsky passed\nthrough the region on a side trip from Baku, Azerbaijan. The leaked ChronoPay\nemails show that executives visited Baku on several occasions to keep up\nrelations with Bank Standard, an Azerbaijani financial institution that\nprocessed huge volumes of payments for ChronoPay’s rogue antivirus programs\nand Rx-Promotion’s pharmacy sites.\n\nI change the subject and ask Vrublevsky if he’d discovered who was responsible\nfor leaking ChronoPay’s internal documents.\n\nHe responds, “The leak was done from within the company, from within the IT\ndepartment. They realized they were going to get caught stealing money. So,\nfirst they disrupted [the] internal accounting system, which made this\ncompromat useless for law enforcement, because we simply don’t have any\naccounting database. It was destroyed before [the] compromat went out.”\n\nI push a manila folder full of printed emails across the table toward\nVrublevsky. “Well, whoever it was also sent about 30,000 internal ChronoPay\nemails. This was part of the original package they had sent me of ChronoPay\nemail from the beginning of 2009 through the middle of 2010.”\n\nVrublevsky lazily leafs through a few of the pages, shrugs, and then shoves\nthe folder back across the table. “I’m not surprised at all.”\n\nI’m not deterred by his vagueness. “It’s a pretty rich collection of\ndocuments. You might find it interesting. There is a lot of damning stuff in\nthere, and none of it too flattering about you or ChronoPay. But I guess\nyou’ve already seen most of those emails.”\n\n“Could be. There are a lot of ‘buts’ there.”\n\nI persist. “Buts or no, the documents show me that you haven’t been truthful\nwith me at all, Pavel.”\n\n“Oh? On what?” he asks vaguely.\n\n“On a lot of things. For starters, remember the first story I wrote about\nChronoPay? The rogue antivirus piece back in 2009? You said you didn’t have\nanything to do with that industry.”\n\n“Yeah, so what’s the story?”\n\n“You tell me! As far as I can tell, the story is that you guys set up an\nentire cybercrime industry and paid for the domains and processing for it.”\n\n“Yeah, so what? I’ve told you about this before: this is what all processors\ndo, and nobody is able to disclose this to you for a very simple reason. It\nviolates Visa and MasterCard rules. Visa and MasterCard know everyone is doing\nthis, but by rules it’s illegal. When you register merchant IDs, this is part\nof the service you provide. Plus you do customer support which is related to\nthat.”\n\nFinishing his coffee and lighting another cigarette, Vrublevsky refers to my\n2009 Washington Post story that drew multiple connections between him and\nChronoPay and the rogue antivirus industry.\n\nI couldn’t believe my ears; Vrublevsky had admitted that many of the companies\nwhich ChronoPay claimed to represent as clients were in fact set up and run by\nChronoPay employees.\n\n“Here’s your mistake. By the time which correlates with your story, we did not\nknow too much about spyware. But that company which you tracked was not used\nfor spyware only. It was used for a bunch of shit. You can go and dig into\nWirecard and Visa Iceland and you’ll find the same shit. The reason is when\nyou open a merchant ID, you need to register it to a company, and that company\nshould have a rock-solid look from [the] outside, like a legitimate website,\net cetera. So most payment service providers, you basically register the\ncompanies yourself and monitor it from the inside.”\n\nI counter, “You also never told me that ChronoPay was the processor for Rx-\nPromotion…”\n\n“No, you’re right. I didn’t.”\n\n“But it’s true, isn’t it?”\n\n“Yes. Well, it used to be, anyway.”[16](09_chapter09.xhtml#fn16)\n\nI was floored. “What do you mean? Not anymore? As of when?”\n\n“My friend, if I was able to tell you that, I would be fucking happy to.”\n\n“That’s it? What’s the deal there, Pavel? You know I’ve come a long way at\ngreat personal risk to interview you here in person. It’s really not nice to\nbe like this.” I knew I was running a risk in challenging him but I needed\nanswers.\n\nLaughing again, he answers, “We dropped them as a client. It’s quite simple.”\n\n“Rx-Promotion? When?”\n\n“September of 2010. So I have had…a half-fucking-year to do nice legitimate\nbusiness decisions.”\n\nVrublevsky makes a call and, speaking in Russian to Vera, asks her to bring us\nsome more coffee.\n\nI press on. “The people who released the documents about your company have a\nlot of information about your operations.”\n\n“They used to steal money from within here, obviously they do. But they’re not\ngoing to get anywhere with this.”\n\n“Why not?”\n\n“You see, compromat is not enough to fuck someone. You also need to have the\npossibility to prove something, and to do that, you need to know how it works.\nThe people who released this information made a lot of mistakes. I spread\ninformation around quite carefully. You can see basically who was the one\nspreading the information, not from the information itself, but the\ninformation that surrounds it. You know what they don’t know. You can figure\nout quite simply who was doing this based on what he knows and what he\ndoesn’t.”\n\nBeautiful Vera, nervously smiling at us both and somehow sensing the\nconversation has turned more intense, steps gingerly into the conference room,\nsets cups of coffee before us both, and quickly leaves. I’m baffled by\nVrublevsky’s response, but I don’t want to interrupt him. “Okay,” I said. “Go\non.”\n\n“Brian, there is one other thing not related to this exactly, a thing that\nsurprises me.”\n\n“What’s that, Pavel?”\n\n“When it comes to me…why is it again that you expect me to be truthful? Please\nremind me.”\n\nI was a bit taken aback by how he cleverly turned the conversation back on me.\n“Call me old-fashioned. I guess when I ask a direct question, I expect an\nhonest answer.”\n\n“Ahahaha. A lot of people expect that. But coming back to the subject, I don’t\nsee Rx-Promotion or much of this other shit in the compromat to be much of a\nproblem. And I’ll tell you why: I really don’t violate too many laws.”\n\nAt this comment, I laugh so hard and so involuntarily that the coffee I just\nsipped almost comes spraying out my nose. It is all I can do to keep the\ncoffee from spilling all over my suit and the boardroom table. We both share a\nnice laugh that helps defuse the tension.\n\nNevertheless, I could see that this was not going to be a fruitful line of\ninquiry. So I tried changing tack and pulled some printed ChronoPay emails out\nof my briefcase.\n\n“I want to get your reaction to this ChronoPay internal email sent by\nChronoPay’s chief of security, Vladimir Stepkov, dated March 16, 2010 with the\nsubject, ‘Rx-promotion2 total earnings.’ It appears to describe your co-\nownership of Rx-Promotion with Yuri ‘Hellman’ Kabayenkov. It reads: ‘Men, our\nbeloved Kisilev gave the data on the cost of tech support. Pavel and Hellman\ndivide all in half, and…’”\n\nInterrupting my recitation, Vrublevsky is clearly annoyed and no longer\nsmiling. “Whoa, whoa, Brian, whoa, wait! I have no fucking idea what’s going\non here! I can’t really get too much into discussions between other people and\nme. So if you drop the scary questions shit, please, perhaps it’s better to\nmove into normal talk.”\n\nI remain silent for a few minutes. Vrublevsky continues, smirking again and\nlighting another Marlboro before the one he was just smoking has been\nextinguished. I decide an awkward silence may prompt him to divulge more. But\nhe isn’t having any of it.\n\n“I’m not going to get deep into this Rx-Promotion shit, and you’re not going\nto figure out much of this for yourself. Same goes for spyware. I’m doing much\nbetter research when it comes to Gusev. Like the cops say, the best way to\nfind out is when a person says it himself. This is not something I want to\ntalk about. But I made you promises before to give you truthful answers to\nsome questions. Not of course on all of them, but some.”\n\n“I see. Well, just do me a favor, will you? Just let me know when you want to\nstart doing that.”\n\nWe talked for more than three hours, and my additional direct questions\nelicited equally evasive and nonsensical responses from Vrublevsky. Exhausted,\nI finally packed up my things and thanked him for making time for me. On the\nway out, Vrublevsky showed me around the building that ChronoPay’s offices\nwere housed in, which according to him was an edifice of historic value.\n\nAs we descended the stairs to the parking garage, he pointed out a door\ndirectly one floor below the entrance to ChronoPay’s office. On the door was a\nsign that read, “Russian Association of Electronic Communications.” RAEC is a\nlobbying firm whose principal organizer, according to leaked ChronoPay\ndocuments, was being paid a monthly salary by ChronoPay. This was the same\nRAEC that had taken the lead in the campaign to organize Western media\ncoverage of the criminal charges against Gusev as the “#1 spammer in Russia.”\n\nI left Russia two days later, after declining two more invitations from\nVrublevsky to meet. Our meeting had annoyed and unnerved me. I had spent the\nprevious eight months listening to him lie to me over the phone about various\ntopics, but to see him do it so flagrantly and openly to my face was\naggravating and left me extremely uneasy around him.\n\nI didn’t expect much from Vrublevsky, so I wasn’t terribly surprised when he\nstonewalled me at our interview. He did, however, confirm several important\npieces of information. ChronoPay was deeply involved in not only processing\npayments for fake antivirus companies and the pharmacy affiliate partnerka Rx-\nPromotion, but it was primarily responsible for creating and fostering these\nenterprises.\n\nVrublevsky’s overconfidence in his claim that he really doesn’t break too many\nlaws turned out to be misplaced. Four months after our visit, Russian federal\ninvestigators issued an arrest warrant for him in connection with a massive\ncyberattack on ChronoPay’s top competitor, a Russian payment processing\ncompany called Assist. Vrublevsky was later arrested, tried, found guilty, and\nsentenced to a two-and-a-half-year stint in a Russian penal colony. In May\n2014, barely a year into his sentence, he was inexplicably released from\nprison.\n\nDespite my disappointment over my visit with Vrublevsky, it did help me piece\ntogether a more complete picture of this fraud ecosystem—and that had always\nbeen my goal. At this point, I’d interviewed dozens of buyers who helped to\nperpetuate the spam problem, and I’d tracked down some of the world’s most\nnotorious spammers. It was time to press forward and dive into the trenches\nwith the spam fighters on the front lines of this incessant, borderless war.\n\n* * *\n\n[16.](09_chapter09.xhtml#fnr16)Finally, we were getting somewhere.\nVrublevsky’s admission that his company was in fact closely involved in\nworking with Rx-Promotion confirmed what was obvious from looking at several\nyears’ worth of leaked ChronoPay emails and spreadsheets. In one of our\nmarathon phone conversations prior to my visiting him in Moscow, Vrublevsky\neffectively acknowledged that the leaked documents and emails were legitimate\nwhen he grudgingly admitted to me that it would have been hard for even the\nRussian FSB to have faked as many documents as were leaked in the ChronoPay\nbreach.\n\n\nChapter 10\n\n## THE ANTIS\n\nFew subjects so predictably rile the spam and cybercrime community as much as\ndiscussions about “antis”—the underground’s derisive term for anti-spam\nvigilantes who act alone or in concert with other antis to hobble or take down\nthe large-scale junk email operations plaguing us. The leaked online chats\nbetween Stupin and hundreds of bulk emailers who worked for SpamIt reveal that\nwhen affiliates weren’t busy spamming, they were using their bot armies to\nbludgeon someone or something offline that threatened to kill their criminal\noperations. Very often, rival spammers would turn their digital armaments on\none another. But their favorite targets were antis, whom the spammers\nperceived as a real and present threat to their business models—and rightfully\nso.\n\nBy the third quarter of 2013, nearly 70 percent of all email sent daily was\nunsolicited bulk email relayed via spam botnets. To give you a sense of how\nmassive the spam problem is, miscreants like those working for SpamIt and\nother spam partnerkas were sending an estimated 85 billion junk messages every\nday. According to InternetWorldStats.com, almost 2.4 billion people were using\nthe Internet by April 2012, which means that spammers were sending\napproximately 35 junk emails for every Internet user each day.\n\nSome of the anti-spam tactics came from independent activists, such as members\nof InboxRevenge.com, a forum dedicated to exposing spammers by reporting spam\ndomains to registrars and calling attention to spam-friendly bulletproof\nhosting providers. One of the most active InboxRevenge members was Adam Drake,\nthe same anti-spam activist to whom Vrublevsky initially leaked the SpamIt\ndatabase to undermine his archrival Gusev.\n\nIronically, in order to take down the spammers, Drake and his merry band of\nvigilantes had to use their adversaries’ own techniques. They built a series\nof automated tools designed to place phony orders for drugs at dozens of spam-\nadvertised websites simultaneously. These order-stuffing programs would place\nrapid-fire orders for pills using fake identities and made-up credit card\ndetails. The idea was to flood the spam partnerkas’ databases with so much\njunk that they would be forced to manually verify each order. In some cases,\nthe order-stuffing programs slowed the pill websites to a crawl, blocking\ninterested buyers from making purchases.\n\n“We sent on average 20,000 to 30,000 ‘orders’ to their spamvertized domains\nevery day,” Drake recalled of the initiative they began in 2007. In response,\nthe spam partnerkas built increasingly sophisticated fraud detection systems\nthat behaved much like the spam filters they detested, but for bogus orders.\nThose systems “scored” each order on the likelihood that it was fake by\nlooking for a combination of qualities about an order that flagged it as high\nrisk. In the process, Drake said, the spammers ended up declining or canceling\na great many orders from legitimate buyers. “Clearly we cost them some money.”\n\nIndeed, SpamIt and GlavMed’s order-checking system routinely red-flagged\npurchases that were even mildly suspect. A review of the customer order record\nleaked from those sister partnerkas shows that thousands of orders were held\nor denied based on the slightest whiff of a fake order. For example, many\norders were declined for the following reason, which accompanied thousands of\norders in the SpamIt customer service system:\n\n“This order is slightly riskier because the phone number supplied by the user\nis not located within the zip code of the billing address for the credit\ncard.”\n\nAccording to Vishnevsky—our “Virgil” in the spammer underworld and the guy who\nhelped to bankroll the development of the Cutwail spam botnet—the anti-fraud\nmeasures also served to keep in check spam affiliates who tried to generate\nfake sales and commissions using stolen credit cards. Such fraud activity\nwould not only result in commissions for phony sales, but would ultimately\nbring unwanted attention to the partnerka’s credit card processing systems,\nwhich would incur hefty fines if the number of credit card chargebacks\nexceeded a certain threshold (usually 1 percent of overall sales).\n\nSpamIt administrators also took elaborate steps to ensure that anti-spam\ngroups and activists could not easily take down the pharmacy websites being\nadvertised via spam. The SpamIt folks used hacked PCs to help obfuscate the\nreal location of the pill-shop sites, employing a circuitous method known as\n“fast-flux” hosting. This method, the virtual equivalent of the classic\nstreet-corner scam known as “three-card monte,” involves rapidly changing the\nlocations of the website so that no one site is used long enough to be\nisolated and shut down.\n\nUnder a fast-flux setup, the customer clicking a link in a spam email might\nreach a different site or Internet address if he or she clicked the link again\na few seconds later. Potential customers of these pill shops would not notice\nanything different, except perhaps a short delay.\n\nSpamIt’s curators also kept a close eye out for fraud investigators from\nMasterCard, Visa, and the major pharmaceutical firms. The SpamIt database\nshows that they routinely added these Internet addresses and email addresses\nto a database of customers that were blocked from placing orders on the\npharmacy sites.\n\nBotmasters like Gugle and Cosma worked diligently to ensure maximum inbox\ndeliverability of their emails and were constantly changing their approaches\nto evade new protections being added to anti-spam software and hardware. This\nglut of spam became so overwhelming that many network security professionals\nin charge of defending corporate networks were forced to supplement their\nhardware and software-based anti-spam tools with spam “blacklists” (also\ncalled “blocklists”).\n\nAt its most basic, a spam blacklist is a record of Internet address ranges\nthat are most frequently seen as sources of spam. Generally, Internet\naddresses on blacklists fall into one of two categories: they are at networks\nand Internet service providers (ISPs) that have earned a reputation for\nturning a blind eye to spammers on their networks—like Atrivo and McColo\nCorp.—or they are individual malware-infected, spam-spewing “zombie” PCs.\n\nThe most widely used blacklists were run by ad-hoc and secretive organizations\nwith funny names, like Spamhaus, SURBL, and URIBL (the BL in these acronyms\nstand for “blacklist”). Companies trying to block spam for tens of thousands\nof employees routinely incorporate these blacklists into spam filters,\nblocking the delivery of email sent from any of the listed Internet addresses.\nNot infrequently, innocent, non-spamming networks would get lumped into these\nblacklists along with the bad actors. But most organizations were all too\nwilling to accept that some legitimate email would not get through if it meant\nbeing able to stem the surging daily tide of junk messages.\n\nFor its part, the spam community was less than amused by these self-appointed\nguardians of the inbox, and maintained that antis had no right to decide which\nemails Internet users should and should not be able to receive. In 2011, a\ncopy of Spamdot.biz, an extremely secretive forum frequented by most of the\nworld’s top spammers, was made available to several law-enforcement agencies\nand this author. The forum postings show that as far back as 2005, spammers\nbegan organizing and executing large-scale Internet attacks aimed at punishing\nand intimidating anti-spam activists.\n\nAmong the most destructive and blistering of such campaigns was one of the\nlargest cyberattacks in the history of the Internet waged against a remarkably\neffective anti-spam start-up called Blue Security Inc. The company had devised\nan elegant approach to stopping spam destined for more than half a million\nusers of its Blue Frog software. The program would simply fire off a reply to\nthe sender’s network, asking the spammer to stop delivering junk email to its\nusers.\n\nBut because those sorts of requests tended to go ignored, Blue Security took\nthem to the next level. It bombarded the spammers with requests from all\n522,000 of its customers at the same time. That led to a flood of Internet\ntraffic so heavy that it disrupted the spammers’ ability to send emails to\nother recipients—a crippling effect that caused a handful of known spammers to\ncomply with the requests.\n\nBut after a short while, key members of the spam underground declared they’d\nhad enough and said it was time for Blue Security to be wiped off the face of\nthe Internet. According to a lengthy discussion thread on Spamdot.biz, at\nleast a dozen top spammers spent weeks and more than $15,000 marshaling their\nforces for an all-out surprise attack on Blue Security’s customers.\n\nSpamdot members had discovered that the Blue Frog software contained a\ncritical weakness: spammers who wished to comply with Blue Frog removal\nrequests were given a free tool that allowed them to clean their lists of Blue\nFrog user email addresses. While Blue Security took pains to encrypt the user\nemail addresses included in that tool, it was easy for spammers to identify\nwhich email addresses on their spam distribution lists belonged to Blue Frog\nusers. All the spammer needed to do was compare their unaltered spam email\nlists with those scrubbed by Blue Security’s tool. The addresses that were\nmissing from the spammer’s scrubbed distribution lists were all Blue Security\nusers.\n\nThe assault on Blue Security began with a threatening email sent to most of\nthe 522,000 Blue Frog users. The message below was pasted for review and later\nedited by several Spamdot forum members before being emailed to the Blue Frog\ncommunity:\n\nYou are being emailed because you are a user of Blue Security’s well-known\nsoftware “Blue Frog.”\n\nToday, the Blue Security database became known to the worst spammers\nworldwide. Within 48 hours, the database will be published on the Internet,\nand your email address will be open to them all. After this, you will see the\nspam sent to your mailbox increase 10 to 20 fold.\n\nBlue Security was illegally attacking email marketers, and doing so with your\nhelp. Many websites have been targeted and hit, including non-spam sites. Blue\nSecurity’s software has been fully analyzed and contains an abundance of\nmalicious code. This includes: ability to send mass mail to users; the ability\nto attack websites with distributed denial of service attacks (DDoS); the\nability to open hidden doors on any machine on which it is running; and a\nhidden auto-update code function, which can install anything on your computer\nand open it up to anyone.\n\nBlue Security lists a USA address as their place of business, whereas their\nmain office is in Tel Aviv. Blue Security is run by a few Russian-born Jews,\nwho have previously been spamming themselves. When all is said and done, they\nwill be able to run, hide, and change their identities, leaving you to take\nthe fall. YOU CANNOT PARTICIPATE IN ILLEGAL ACTIVITIES and expect to get away\nwith it. This email ensures that you are well aware of the situation. Soon,\nyou will be found guilty of computer crimes such as DDoS attacking of\nwebsites, conspiracy, and sending mass unsolicited bulk email messages for\neverything from Viagra to porn, as long as you continue to run Blue Frog.\n\nThey do not take money for downloading their software, they do not take money\nfor removing emails from their lists, and they have no visible revenue stream.\nWhat they DO have is 500,000 computers sitting there awaiting their next\ncommand. What are they doing now?\n\n1.Using your computer to send spam?\n\n2.Using your computer to attack competitor websites?\n\n3.Phishing through your files for your identity and banking information?\n\nIf you think you can merely change your email address and be safe while still\nrunning Blue Frog, you are in for a big surprise. This is just the beginning…\n\nAn unusually active member of the Spamdot forum, a user who adopted the\nnickname “BoT,” laid out a devious plan for an attack on Blue Security that\nwould turn the company’s own anti-spam service against its users. The strategy\nwas simple and elegant. The spammers would register dozens of domain names,\nall of which would redirect visitors back to a single website that the\nspammers controlled. Then, the miscreants would spam Blue Security’s entire\nuser base, and sit back and wait for the inevitable wave of Unsubscribe\nrequests to come in. When the removal requests started flowing back to that\nsingle website, the spammers would simply change the site’s settings so that\nall incoming traffic got redirected to Blue Security’s homepage, effectively\ncausing the company’s own anti-spam technology to attack itself.\n\n“This way they either get screwed in the ass by their own weapon or get abuse\ncomplaints,” BoT explained in a Spamdot forum posting just prior to the\nattack. “Even better, would be to redirect the traffic to the websites of CNN,\nBBC, Reuters, and such, and those sites will start writing that the Internet\nis turned into a battle because of the ‘blue froglings.’”\n\nOn May 1, 2006, the spam community unleashed a series of increasingly\namplified attacks on Blue Security’s Internet servers, immediately blocking\nlegitimate users from visiting the company’s site. Blue Security hadn’t yet\nbeen made aware that it was being targeted, but company officials knew\ncustomers were having difficulties reaching the firm’s website. At some point,\nthe decision was made to redirect traffic destined for its unreachable\nhomepage to a company blog, which included a message to Blue Frog users\nacknowledging the problem.\n\nBlue Security’s blog was hosted at a blogging service run by Six Apart Ltd., a\nSan Francisco-based company that runs millions of websites through its TypePad\nservice. (Six Apart would later be bought by Russian blogging giant\nLiveJournal.ru.) The result of this redirection meant that Six Apart’s blog\nservice then received the brunt of the attack, and that thousands of web logs\nhosted there also went down. The denial-of-service assault also shut down\noperations for roughly twelve hours at Tucows Inc., a Toronto-based Internet\nservices company that helped manage Blue Security’s site. Tucows CEO Elliot\nNoss called the attack “by far the largest the company had ever seen,” and\nsaid that only a handful of companies have the infrastructure in place to\nwithstand such an assault, much less a more powerful one.\n\n“This attack really was like trying to take out a mosquito with an atomic\nbomb,” Noss said.\n\nNot long after that, Blue Security CEO Eran Reshef received an email from one\nof the spammers who had previously agreed to stop spamming Blue Security’s\nusers—telling him how to get in touch with the person in charge of the attack.\n\nThe message provided a link to a pharmacy website that was being promoted by\nspammers at the time and instructed Reshef to view the HTML source of the\npage. Within it, he would find an ICQ number. ICQ, or I-Seek-You, is an\ninstant message technology that was immensely popular in the cybercrime\ncommunity at the time.\n\nBlue Security’s team downloaded a copy of the pharmacy site homepage and then\nopened it in an HTML editor to make sure it was not booby-trapped with\nmalicious code. They then located the hidden message: “preved, stuchis v asku\n299650295,” or “hello, add ICQ #299650295.”\n\nSoon after Reshef sent a chat request to that ICQ number, someone using the\nname “Pharmamaster” replied. Pharmamaster was taunting and not at all\ninterested in bargaining.\n\nTue May 02 16:30:57 2006\n\n[16:02] BLUESECURITY: Do you want to discuss now a friendly resolution to the\ncurrent situation? We are aware of your concerns, but as I told you before,\nand unlike what you think, we don’t want to affect your business. We are not a\ncommon anti-spam company.\n\n[16:07] PHARMAMASTER: You started with me and my people and my staff, so you\nshall get hurt first and feel who we are. And when I’m sure you got the point\nof who we are, then we can talk. Bluesecurity.com is down now but how about we\nkeep all your systems down for a few months?\n\nReshef declined to be interviewed about the specifics of the attack. But a\nsource who helped the company respond to the onslaught said Reshef also\nreceived threats against his family.\n\n“The level of the attack was so bad that I remember being in a meeting with\nEran and the other guys,” said the source, speaking on the condition of\nanonymity. “The other stuff that was going on was a personal attack where Eran\nwas getting pictures of his children at a playground sent to him—pictures he’d\nnever seen before.”\n\nThe attacks continued for more than two weeks, with increasing intensity. At\none point, the attackers began emailing Blue Security employees, saying that\nthey had 70 percent of the Blue Frog email user base and offering $50,000 for\nthe remaining 30 percent to any employee willing to turn over the company’s\ninternal data.\n\nOn May 14, the management of Blue Security met with the FBI to discuss their\noptions, but this was more a formality than anything. Two days later, Reshef\nand Blue Security would wave the white flag. The Washington Post ran a front-\npage story by this author on May 17, observing that the company had\nacknowledged defeat. Blue Security had received more than $4 million in\nventure capital funding, but its benefactors had decided it was time to throw\nin the towel.\n\nThat story quoted Todd Underwood, then chief of operations and security for\nRenesys Corp., a company that monitors Internet connectivity. Underwood called\nthe attack “unsurprising but sad.”\n\n“When the company’s founders first approached the broader anti-spam community\nand asked them what they thought of Blue Security’s business model, everyone\nsaid this was a terrible idea and that they would eventually cause a lot of\ncollateral damage,” Underwood said. “But it’s also extremely unfortunate,\nbecause it shows how much the spammers are winning this battle.”\n\nThe individuals responsible for organizing the attack on Blue Security appear\nto have been the principals at one of the largest pharmacy partnerkas at the\ntime. Many of the plans laid out on Spamdot.biz for attacking Blue Security\nwere shaped and encouraged by a heavyweight Spamdot.biz user who had adopted\nthe nickname “Mr. Green.” According to Spamhaus, Mr. Green was the alias used\nby a Russian named Vlad Khokholkov, a Moscow native who allegedly partnered\nwith notorious spammer Leo Kuvayev.\n\nThe attack on Blue Security was a shot across the bow of anti-spammers\neverywhere. At the time, close to 90 percent of all email was junk\nadvertisements, and Blue Security had tapped into a visceral sense of\nfrustration among email users who were fed up with the daily deluge. But the\ntop Spamdot members were running pharmacy partnerkas that were pulling in\nmillions of dollars each month, and they viewed Blue Security as the vanguard\nof a new breed of anti-spam activity that posed a potent threat to the\ncontinued success of their money-making machines. They weren’t willing to be\nsidelined, whatever the cost.\n\nSpamhaus believes Kuvayev and Khokholkov ran the pharmacy affiliate programs\nMailien and Rx-Partners. This is backed up by the leaked instant message chats\nfrom SpamIt administrator Dmitry Stupin. In a 2008 conversation between Stupin\nand “Joop”—the nickname used by a Russian who was one of GlavMed’s top\nearners—the two are discussing a rival affiliate program called “Affiliate\nConnection.”\n\n“If it’s no secret, do you know Leonid Kuvayev and Vlad Khokholkov (Mr.\nGreen)?” When Stupin hesitated in answering, Joop apologized and changed the\nsubject. “I am taking my question back. Something is wrong with my head. I\nforgot that their partnerka [was] Rx-Partners/Stimulcash.”\n\nKuvayev, a Russian national, was convicted of violating U.S. anti-spam laws in\nMassachusetts in 2003 and ordered to pay $37 million for blasting botnet spam\nthat touted counterfeit copies of Microsoft Windows and other name-brand\nsoftware. He reportedly fled the country after that, avoiding jail time. But\nat some point after his conviction, Kuvayev returned to Russia.\n\nUltimately, however, Microsoft got the last laugh. The software giant paid\nconsultants at Russian computer forensics company Group-IB to monitor\nKuvayev’s activities and to share the information with Russian law-enforcement\nagencies.\n\nIn 2011, Kuvayev was arrested on child molestation charges. He is now in a\nRussian prison. Police raided Kuvayev’s home after receiving a tip that he was\nhaving sex with underage girls. In his residence, they found hours of\nvideotaped footage showing him abusing girls—some as young as fourteen years\nold—lured from a nearby Moscow orphanage. In 2012, Kuvayev was tried and\nconvicted of child molestation, and he is currently serving a twenty-year\nprison sentence (recently reduced to ten years according to MKRU, a Russian\nweekly periodical).\n\nReached via email, Khokholkov denied being involved in the attack on Blue\nSecurity. Exactly who was responsible for orchestrating the attack remains\nunclear, but the leaked SpamIt chats and forum discussions clearly show that\nVlad and Leo worked as partners, and that Kuvayev’s spam gang was heavily\ninvolved.\n\nNot long after the attack on Blue Security, Mr. Green asked Spamdot forum\nadministrators to delete all of his postings and account information. But some\nof his forum messages survived as quoted text in forum conversations between\nother Spamdot members. They indicate that Mr. Green was working closely on the\nattack with a self-professed Satanist who used the nickname “Zliden,” and the\nemail address “domains@locu.st.” According to Spamhaus, this was the last\nknown email address of Leo Kuvayev.\n\nKuvayev is widely considered one of the most blatant and unrepentant spammers\nthat ever worked the business. But like other masters of bulk email, he took\ncare to separate his various online identities from his offline existence,\nswitching email addresses and nicknames and deleting old posts every so often\nto elude digital-crimes investigators and anti-spam activists.\n\nEven so, Kuvayev’s experience (and that of his contemporaries like Cosma and\nNechvolod) shows that while the Internet may occasionally lose track of online\nidentities, anti-spam and Internet security activists have far longer memories\nand are willing to go to great lengths to bring spammers to justice.\n\n## Spamhaus DDoS\n\nThe denizens of Spamdot.biz also planned and executed several powerful attacks\nagainst Spamhaus, as well as against the widely used spam blacklists\nmaintained by URIBL and SURBL. In a message to fellow members in October 2008,\nSpamdot administrator “Ika” posted a note on the forum to update the group’s\nprogress in collecting funds from spammers to launch a lengthy distributed\ndenial-of-service (DDoS) attack against the websites of all three blacklist\nproviders.\n\nThe message read, in part:\n\nDear Sirs,\n\nWe have collected more than $3,000 in the fund, of which portions will be\nallocated to the first four days of DDoS against URIBL and Spamhaus. We also\nbought $1,000 worth of bot installs at the rate of $25 for 1,000 bots.\n\nCurrent DDoS targets: 1) Infrastructure lists.uribl.com/ 2) Home businesses of\n[Spamhaus founder Steve] Linford—www.uxn.com and www.ultradesign.com/net where\nthe Spamhaus backup database is kept. 3) Both faces of Spamhaus.org.\n\nA representative from the online pharmacy partnerka Affiliate Connection said\nthat his spammers could pool together several million hacked PCs for use in a\nmassive attack on Spamhaus. But he noted that the opportunity costs from an\nassault like that would be high, because anti-abuse companies would quickly\nidentify and blacklist all further communications (including future money-\nmaking spam) from the spam zombies. What’s more, the Affiliate Connection\nleader said, URIBL and SURBL had recently purchased denial-of-service\nprotection services from a leading anti-DDoS provider.\n\nThe SpamIt administrators responded that these factors were hardly enough to\ndeter their plans.\n\n“Well, then, if they are sitting on strong anti-DDoS channels, we will have to\nact strongly and decisively to fill their pipes,” Ika declared. “They will\nhave to account for huge traffic volumes and it will become a real problem for\nthem. It will be expensive, but I think that some of the affiliates can\nallocate a few hundred bucks a day on it.”\n\nWeeks later, the Spamdot.biz thread on plans for attacking Spamhaus had\ngenerated pages of talk but little action. Disgusted with his colleagues,\nGeRa—the SpamIt and Rx-Promotion affiliate who operated the Grum spam\nbotnet—challenged other spammers to step up and make sacrifices for the good\nof the industry.\n\nI appeal to the largest spammers, you guys doing $50,000 to $200,000 in\ncommissions per month, will you not be able to find $3,000 to solve this\nproblem?\n\nDocent, the curator of the Mega-D spam botnet, responded that he and his team\nwere ready to lend funding to support a sustained attack on Spamhaus. But soon\nthe discussion stalled on the question of who was going to take responsibility\nfor directing and organizing the attack.\n\nTo complicate matters, not everyone on the spam forum was in favor of\nattacking Spamhaus and the other blacklist providers. Severa, the botmaster\nwho built and operated the Waledac and Storm spam botnets, was more\nphilosophical, observing that “Spamhaus is only a part of [a] huge evolution\nprocess,” and that spam filters actually helped to separate the novice\nspammers from the pros and discourage inexperienced, would-be spammers from\ntaking up the craft.\n\n“Guys, we CAN’T live without anti-spam filters anymore,” Severa reasoned in a\nreply on the Spamdot discussion. By advocating for the continued, widespread\nuse of spam filters, Severa’s comments must have sounded almost heretical to\nmany of his colleagues. But this spam kingpin in all likelihood correctly\nidentified inexperienced spammers as a plague on the industry and a drain on\nhis profits. If spam filters mainly succeeded at keeping the ankle-biters at\nbay, then so be it.\n\n“Really, it stops newbies and lamers. Imagine, if all filters were turned off\nnow. Would you earn money? NO! It would just kill email as communication\nservice, nothing more. So, Spamhaus is not good or bad; Spamhaus is just\nSpamhaus.”\n\nSpamdot member “Swank” said he agreed with Severa’s general statement, but\nthat Spamhaus nevertheless needed to be humbled.\n\n“Severa, you make a great point and you are exactly right,” Swank wrote.\n“Having anti-spam filters and more is good for technology and the Internet\nbecause both sides—spammers and anti-spam folks—are always adapting and\nchanging things around to get past each other’s latest. The end result is\ntechnology is constantly improving, which like you said also keeps the\nprofessionals going and the newbies out of the business. That being said,\nstupid companies like Spamhaus are not fair to the mailers who are compliant.\nSpamhaus is abusing their powers to take out ANYONE who is an email marketer,\nregardless of whether or not the person is compliant or not. Spamhaus hates\nall email marketers. That crap is absolute bullshit and is not fair to anyone.\nSpamhaus needs to realize they are not untouchable and they will soon realize\nthis.”\n\nIn October 2008, GeRa announced to Spamdot members that he was releasing an\nautomated attack tool that his programmers had built to help the community\nparticipate in a massive attack on Spamhaus. The tool, which he called Anti-\nHaus v. 1.0, was distributed to major botnet owners who in turn installed the\nprogram on tens of thousands of hacked PCs that they controlled and that were\nalready relaying spam.\n\nA representative from Spamhaus who gave his name only as “Barry” said the\norganization doesn’t recall this particular October 2008 attack, noting that\nSpamhaus has lost track of how many massive attacks it has been hit with over\nthe years.\n\nIn March 2013, Spamhaus came under an attack that it would not soon forget. In\nfact, some experts called it the largest concerted cyberattack that the\nInternet had ever witnessed. A group of bulletproof hosting providers united\nunder the “Stophaus” banner decided to attack the anti-spam provider. Stophaus\nformed an online forum to coordinate the assault after Spamhaus listed one\nbulletproof hosting provider in particular on its block list: a network known\nalternatively as CB3ROB, a.k.a. “Cyberbunker” because it operated from a\nheavily fortified NATO bunker in the Netherlands.\n\nAttackers allied with Stophaus launched a nine-day digital siege that hurled\nas many as 300 billion bits of data per second at the organization’s website.\nAs the New York Times described it, the data “fire hose” directed at Spamhaus\ndidn’t just swamp the anti-spam provider; the deluge spilled over onto\nneighboring networks, causing what the organization’s content distribution\nnetwork CloudFlare estimated to be hundreds of millions of people to\nexperience delays and error messages across the web.\n\nWhen the attackers allied with Stophaus decided that they were not going to be\nable to bring down CloudFlare, which Spamhaus had hired to protect it from\nDDoS assaults, they began pelting the “peering points” at which Internet\nnetworks exchange traffic, including Internet exchanges in London, Amsterdam,\nFrankfurt, and Hong Kong.\n\nThe New York Times reported that authorities in Spain later arrested Sven Olaf\nKamphuis, a thirty-five-year-old Dutch man thought to be responsible for\ncoordinating the unprecedented attack on Spamhaus. According to Spamhaus and\nmedia reports, Kamphuis made claims about being his own independent country in\nthe Republic of Cyberbunker. The Guardian reported that Kamphuis was\nextradited to the Netherlands, but there is no indication that he is being\nprosecuted for crimes there. Kamphuis denies being involved in the attack and\nsaid he was merely acting as a press contact for CB3ROB/Cyberbunker.\n\nThe Stophaus assault was the loudest and latest reminder that such weapons of\nmass disruption are readily and freely available today to any person or\norganization that chooses to wield them. The attack that hit Spamhaus—known as\na DNS reflection and amplification attack—leveraged unmanaged domain name\nsystem (DNS) servers on the web to create huge traffic floods intended to\nintimidate and silence targets.\n\nTo understand the significance of this, here’s a bit of background. DNS\nservers act as the white pages of the Internet, transforming or “resolving”\nhuman-friendly domain names like example.com into numeric network addresses\nused by computers. Typically, DNS servers only provide services to machines\nwithin a trusted domain, in this case example.com. But DNS reflection attacks\nrely on consumer and business Internet routers that are configured to accept\nqueries from anywhere on the web. Attackers can send spoofed DNS queries to\nthese so-called “open recursive” DNS servers, forging the request so that it\nappears to come from the target’s network. That way, when the DNS servers\nrespond, they reply to the spoofed (target) address.\n\nThe amplification part of the attack takes advantage of the ability to craft\nDNS queries so that the responses are much bigger than the requests. They do\nthis by leveraging an extension to the DNS standard that enables large DNS\nmessages. For example, an attacker could compose a DNS request of less than\n100 bytes, prompting a response that is sixty to seventy times as large. This\namplification effect is especially pronounced if the perpetrators query dozens\nof DNS servers with these spoofed requests simultaneously.\n\nThe good news is that Internet and security experts have long understood how\nto block these extraordinarily powerful attacks. “Indeed, a number of computer\nsecurity specialists pointed out that the attacks would have been impossible\nif the world’s major Internet firms simply checked that outgoing data packets\ntruly were being sent by their customers, rather than botnets,” wrote John\nMarkoff and Nicole Perlroth of the New York Times.\n\nThe bad news is that little has changed since these ultra-powerful attacks\nfirst surfaced more than a decade ago, said Rodney Joffe, senior vice\npresident and senior technologist at Neustar, a security company that also\nhelps clients weather huge online attacks. Joffe estimates that there are\napproximately 25 million misconfigured or antiquated home and business routers\nthat can be abused in these digital sieges. Most of these are home routers\nsupplied by ISPs or misconfigured business routers, but a great many of the\ndevices are at ISPs in developing countries or at Internet providers that see\nno economic upside to spending money for the greater good of the Internet.\n\n“In almost all cases, it’s an option that’s configurable by the ISP, but you\nhave to get the ISP to do it,” Joffe said. “Many of these ISPs are on very\nthin margins and have no interest in going through the process of protecting\ntheir end users—or the rest of the Internet’s users, for that matter.”\n\nAnd therein lies the problem. Not long ago, if a spammer or hacker wanted to\nlaunch a massive Internet attack, he had to assemble a huge botnet that\nincluded legions of hacked PCs. These days, such an attacker need not build\nsuch a huge bot army. Armed with just a few hundred bot-infected PCs, Joffe\nsaid, attackers today can take down nearly any target on the Internet, thanks\nto the millions of misconfigured Internet routers that are ready to be\nconscripted into the attack at a moment’s notice.\n\n“If the bad guys launch an attack, they might start off by abusing 20,000 of\nthese misconfigured servers, and if the target is still up and online, they’ll\nincrease it to 50,000,” Joffe said. “In most cases, they only need to go to\n100,000 to take the bigger sites offline, but there are 25 million of these\navailable.”\n\n\nChapter 11\n\n## TAKEDOWN\n\nNine months after my icebreaker cruise on the Russian trip to meet Vrublevsky,\nI found myself again gazing out at the starry night sky, standing on the deck\nof another large ship in a foreign country. This time, it was on the upper\ndeck of an aging cruise liner that was docked at the harbor in downtown\nRotterdam.\n\nOn the other side of the frosted porthole windows, a big band was jamming at a\nreception for attendees of the GovCert cybersecurity conference, where I had\ndelivered a presentation earlier that day on the turf war between Gusev and\nVrublevsky. The evening was bracingly frigid and blustery, and I was waiting\nthere to be introduced to investigators from the Russian Federal Security\nService (FSB). Several FSB agents who attended the conference told our Dutch\nhosts that they wanted to meet me, but only in a private setting.\n\nMy hands had grown so cold that I could no longer hold on to my beer glass,\nwhich was glazing with ice. I set the glass down on the ledge, and at the same\ntime heard the thick steel door swing open behind me, squeaking loudly on its\nhinges. Stepping out into the night air, a woman from the conference\napproached, formally presented the three men following behind her, and then\nhurried back inside to the warmth of the reception.\n\nA middle-aged stocky fellow introduced as the senior FSB officer spoke in\nRussian, while a younger gentleman translated into English between drags on a\nMarlboro. They asked, did I know anything about a company in Moscow called\n“Onelia”? I said no, asked them to spell it for me, and inquired as to why\nthey were interested in this firm. The top FSB official said they believed the\ncompany was heavily involved in processing payments for a variety of organized\ncybercriminal enterprises.\n\nLater that evening, back at my hotel room, I searched online for details about\nthe company but came up dry. I considered asking some of my best sources in\nRussia what they knew about Onelia. But a voice inside my head warned that the\nFSB agents may have been hoping I’d do just that. They would be able to divine\nwho my sources were when those individuals began making inquiries about a\nmysterious (and probably fictitious) firm called Onelia.\n\nMy paranoia got the best of me, and I shelved the information. That is, until\nseveral months later, when I discovered that Onelia (turns out it is more\ncommonly spelled Oneliya) was the name of the limited liability company behind\nGateline.net, the credit card processor that processed tens of thousands of\ncustomer transactions for SpamIt and Rx-Promotion.\n\nGateline.net states that the company’s services are used by firms across a\nvariety of industries, including those in tourism, airline tickets, mobile\nphones, and virtual currencies. But according to payment and affiliate records\nleaked from both SpamIt and Rx-Promotion, Gateline also used to process most\nof the rogue pharmacy site purchases promoted by spammers working for the two\nprograms.\n\nThe connection between Gateline and the spam programs is supported by chat\nlogs seized in 2011 by Russian investigators who were looking into SpamIt.\nThose logs show hundreds of conversations between SpamIt co-owner Dmitry\n“SaintD” Stupin and a Gateline administrator, Nikolai Victorovich Illin, who\nused the nickname “Shaman” (shaman@gateline.net) and was referred to as\n“Nikolai,” or the diminutive form, “Kolya.” The logs show more than 205\nconversations between Shaman and Stupin from 2007 to 2010.\n\nThe leaked Stupin chats suggest that Shaman held enormous sway over the day-\nto-day operations of SpamIt. The pharmacy spam sponsor had great difficulty\noffering buyers the ability to pay by MasterCard, mainly because MasterCard\nseems to have been far more vigilant than Visa about policing the use of its\nservices by rogue online pharmacies. The payment records of SpamIt indicate\nthat Shaman received a sizable cut (about 8 percent) from all sales processed\nby the SpamIt pharmacies, and that he sometimes earned tens of thousands of\ndollars per week for his services.\n\nIn the following chat between Shaman and Stupin, recorded November 23, 2009,\nShaman chastises Stupin for not being more aware of transactions that they\nbelieved were from undercover buys made by MasterCard fraud investigators. At\nthe beginning of the chat, Shaman posts a link to a story about the criminal\ncase opened by Russian investigators into SpamIt and Stupin’s copartner, Igor\nGusev.\n\nSHAMAN: www.runewsweek.ru/country/31283/\n\nSTUPIN: Yep, yep.\n\nSHAMAN: I’d suggest you not to advertise (PR) banks too much.\n\nSTUPIN: We need it the least.\n\nSHAMAN: Otherwise, the entire business will go down. There has been something\nlike that already.\n\nSTUPIN: Igor is trying to remove those posts.\n\nSHAMAN: Okay. What’s the deal with information wars? We have to stop this\nthing somehow. You’ll destroy the whole business.\n\nSTUPIN: We will??? There has been not a single post from us. Igor is removing\nthem all the time. We are not doing anything else.\n\nSHAMAN: Stop responding to him in forum posts and RedEye will calm down.\n\nSTUPIN: I will ask Igor whether he has been responding. If he has—I will ask\nhim to stop doing it.\n\nSHAMAN: [Pointing out an email address that apparently belonged to a\nMasterCard fraud investigator] Kill this asshole—he is MasterCard’s officer\n[employee]. He made a purchase. www.iacva.org/PDF/William%20Hanlin.pdf\n\nSHAMAN: Be more attentive with the batch. Kill these as well: Charles Wilson,\nStephen Carpenter, Fredric Manger, Sandro Racheli…\n\nSHAMAN: What’s going on with you?\n\nSTUPIN: Our programmers are checking what’s happened. This should not be\nhappening.\n\nWhen I met with the FSB officers, the noose was already beginning to tighten\naround Vrublevsky, and Gusev had long ago closed SpamIt and effectively\nscuttled GlavMed. Now, it appeared that the FSB was taking aim at the\nfinancial infrastructure that served both competing pharmacy partnerkas, as\nwell as other rogue online pharmacy programs.\n\nVrublevsky and Gusev’s Pharma Wars were extremely costly for the spam\nindustry, and their internecine war cost everyone in their business plenty.\nThe two are now widely reviled on cybercrime forums for costing spammers tens\nof millions of dollars in profits, and for focusing attention from law-\nenforcement officials and security experts on individual spammers.\n\n“These two fuckers killed the spam business,” Vishnevsky said in a May 2012\ninterview. “It was never super profitable for most guys; maybe five to ten\nguys earned really good money with spam. But after Pavel and Gusev started\ntheir war, everyone started thinking that every spammer is a millionaire and\nstarted hunting for spam and spammers.”\n\nVishnevsky complained that as the revenues from his spam business dwindled, he\nwas forced to take a second legitimate or “white” job to supplement his\n“black” deeds. He still sells his spam software to numerous other spammers,\nbut he also now serves as a system administrator of a local company in Moscow,\nessentially being paid to defend against some of the threats he is helping to\ndeploy with his spam business.\n\nBut his spam business is definitely way down since the golden years of pre-and\npost-McColo. It’s not that spamming somehow became a more dangerous activity\nin Russia. Rather, Vishnevsky is having trouble attracting and retaining\ntalented programmers to help maintain his spam business. Legitimate high-tech\nand well-paying programming jobs are increasingly available to talented coders\nin Moscow, and many of his longtime employees have been hired away to\nlegitimate jobs in Moscow’s young but promising tech sector.\n\n“Many representatives of the underground can’t find good coders now, because\ntheir salaries in Moscow are much more than you can earn with spam,”\nVishnevsky said. “This business went to shit when Pasha [Vrublevsky] got\nbusted. If Pasha and Gusev [had] not start[ed] that stupid war, everyone would\nbe much happier.”\n\nVishnevsky’s criticism may be harsh, but it is hardly an exaggeration. The\nspam industry has indeed taken a huge hit in the past few years. Prior to\nSpamIt’s closure in October 2010, the volume of spam sent worldwide each day\nhovered at around 5.5 billion messages. Since SpamIt’s closure, however, the\nvolume of global spam sent daily has been in marked decline. According to\nSymantec, by March 2011, spam levels had fallen to just over one billion junk\nmessages per day, and the total has hovered at or very close to that\ndiminished level ever since.\n\nSpam remains a major problem, but it has moved much farther underground, and\nthe major players seem to be quite a bit more circumspect in their activities.\nOf course, the turf war between Gusev and Vrublevsky was only one (albeit\nconsiderable) contributor to the decline of the spam economy. If the spam\nindustry has become less attractive for would-be cybercriminals, that may have\nsomething to do with a series of targeted takedowns against major spam botnets\nover the past several years.\n\nHere are a few other notable takedowns that targeted botnet operators and\ntheir crime machines:\n\n•In May 2009, the Federal Trade Commission convinced a court to force Internet\nproviders to stop routing traffic for 3FN, a hosting provider in Northern\nCalifornia that had been identified by investigators and the FTC as a major\nsource of harmful content online. Vrublevsky’s forum Crutop.nu was hosted\nthere and forced to find a new home after 3FN’s closure.\n\n•In November 2009, FireEye, a Milpitas, Calif.-based security firm, led a\ncoordinated effort to take down the Mega-D botnet. A year later, Mega-D’s\nalleged proprietor—twenty-four-year-old Oleg “Docent” Nikolaenko—was arrested\nin Las Vegas. He pleaded guilty to spreading malicious software to protected\ncomputers in 2013 and was sentenced to time served, plus three years’\nprobation. (Nikolaenko had already served twenty-seven months in custody\nrelated to his trial prior to his conviction.)\n\n•In January 2010, employees at the Internet infrastructure firm Neustar seized\ncontrol over the Lethic spam botnet, a spam-spewing crime machine made up of\nmore than 200,000 infected PCs.\n\n•In February 2010, Microsoft unveiled what would be the first in a series of\ncourt-assisted takedowns of major spam botnets. The first target was Severa’s\nWaledac spam botnet, which at the time was blasting billions of spam emails\ndaily through a network of more than 60,000 hacked computers. In that effort,\nMicrosoft convinced a U.S. federal court to grant the software giant legal\nownership of 277 Internet domains that the Waledac botmaster was using to\ncontrol his spam empire.\n\n•In October 2010, Armenian authorities arrested twenty-seven-year-old Russian\nGeorgiy Avanesov in tandem with a coordinated takedown of the Bredolab botnet,\na spam engine that had hijacked millions of PCs since its debut in 2009. At\nthe height of Bredolab’s operation, experts say the botnet was blasting more\nthan three billion messages each day. Investigators alleged that Avanesov made\nmore than $130,000 per month renting his botnet out to other spammers.\nAccording to a BBC report, Avanesov was later convicted of computer sabotage\nand sentenced to four years in an Armenian prison. SpamIt records indicate he\nhad multiple affiliate profiles generating income for him from that pharmacy\nprogram.\n\n•In March 2011, Microsoft went after Rustock, launching a legal sneak attack\nthrough the U.S court system to seize control over the domains being used to\ncontrol Cosma’s spam engine. At the time, Rustock was running on an estimated\n815,000 computers and was blasting huge volumes of junk email daily. Microsoft\nhad help in the case from Pfizer, the drugmaker whose products and trademarks\nwere most heavily abused by the spammers.\n\n•In July 2011, Microsoft announced it was offering a $250,000 reward for\ninformation leading to the arrest and conviction of the Rustock botmaster.\nInterestingly, while Spamdot.biz closed its doors after Gusev was named the\nWorld’s Number One Spammer by Russian law-enforcement officials in October\n2010, the spam forum didn’t go away. It merely changed its name and location.\nNot long after Microsoft offered its reward, Cosma—the Rustock curator (having\nchanged his nickname by then to “Tarelka,” or “plate” in Russian)—could be\nseen on the new forum asking for advice on how to obtain a new passport under\nan assumed name.\n\n•In July 2012, FireEye and Spamhaus went after the Grum botnet, which had\nemerged as one of the top three most active spam machines, sending 18 billion\nmessages per day. Their collaborative takedown briefly shrank global spam\nvolumes, but the source code for Grum subsequently fell into the hands of\nseveral other miscreants, prompting its revival. Grum remains active today.\n\n•In July 2013, Microsoft and the FBI announced a joint operation that took\ndown more than 1,400 distinct botnets that were using Citadel malware to\ncontrol infected PCs. Citadel was primarily used by crime groups engaged in\nemptying bank accounts through online heists.\n\n•In December 2013, Microsoft worked with the FBI again and with authorities in\nEurope to disrupt the ZeroAccess botnet. ZeroAccess was often bundled with\nother threats (including spam bots and fake antivirus software), but the\nbotnet mainly was designed to hijack search engine results on infected PCs and\nto redirect people to websites that fraudulently charged businesses for online\nadvertising clicks.\n\n•In June 2014, the FBI in conjunction with multiple international law\nenforcement partners and private security firms took down the “Gameover Zeus”\nbotnet, a collection of more than one million hacked computers. The FBI also\nnamed a Russian man—thirty-one-year-old Evgeniy Mikhailovich Bogachev—as the\nmastermind behind the operation and the principal author of the botnet.\nAccording to the U.S. Justice Department, the Gameover botnet was used to\nsteal more than $100 million from victimized businesses. The botnet was also a\nmajor platform for deploying costly online extortion attacks against\nindividual computer users.\n\nBut it wasn’t only the spam industry that was temporarily trashed by the war\nbetween Gusev and Vrublevsky. ChronoPay was deeply involved in processing\npayments for partnerkas that pushed rogue antivirus products, and when\nVrublevsky became the subject of a criminal investigation in 2011, his\nprocessing networks fell apart. Overnight, the rogue antivirus affiliate\nnetworks ground to a halt because they had lost their connection to the credit\ncard networks. Vrublevsky was arrested at the end of May 2011 on unrelated\ncharges, and by August 2011, computer security giant McAfee noticed a 60\npercent decline in users reporting problems with fake antivirus programs.\n\n## Downing Domains and Scrubbing Search\n\nAnother front in the war on spam has targeted the pharmacy websites advertised\nvia junk email. Typically, spammers have sought out domain name registrars who\nturn a blind eye to spammers registering hundreds or even thousands of domains\nper month for use in pharmacy spam campaigns. For many years, some of the\nlargest players in the website name industry brushed aside requests by the\nanti-spam groups to de-register domains that were clearly registered to\nbenefit from spam activity.\n\nJohn Horton, a former deputy in the White House Office of Drug Control Policy\nand now president of LegitScript, an Internet pharmacy verification service,\nhas tracked the rogue pharmacy domains for years. Horton said that for quite\nsome time, most registrars argued that it wasn’t their job to inspect how\ntheir customers were using their domains.\n\nThat situation began to change in late 2008, when EstDomains—a Estonian domain\nregistrar that had emerged as a clear favorite of spammers and Internet\nscammers alike—had its accreditation revoked by the Internet Corporation for\nAssigned Names and Numbers (ICANN), the nonprofit entity that oversees the\ndomain name registration industry. ICANN took action after a Washington Post\nstory by this author observed that EstDomain’s CEO—Estonian businessman\nVladimir Tsastsin—had been previously convicted of money laundering, forgery,\nand credit card fraud.\n\nICANN acted after my Washington Post story called attention to a little-known\nclause in the contracts that domain name registrars like EstDomains had signed\nwith ICANN, which stated that registrars were not allowed to appoint\nprincipals who had criminal backgrounds. As mentioned in [Chapter\n8](08_chapter08.xhtml), Tsastsin was an early, major investor in ChronoPay,\nand in 2011 was arrested in Estonia along with six other men accused of\nrunning an enormous botnet that spanned more than four million machines\nworldwide.\n\nHorton said the EstDomains incident spooked many in the domain registration\nbusiness. One of EstDomains’ closest partners was an Indian registrar called\nDirecti, which was grappling with its own deluge of abuse complaints about\nspammers using its service.\n\n“Three to four years ago, nobody was suspending domain names engaged in rogue\nInternet pharmacy activity unless you could also clearly show that those\ndomains were benefiting from spam activity,” Horton said. “Directi was one of\nthe first registrars that said, if we know websites are selling prescription\ndrugs without a prescription, and [those drugs are] being shipped into another\ncountry in violation of that country’s laws, we will take action to suspend\nthe domain. After that, we saw GoDaddy and eNom and a few others do the same\nthing. If you look at registrars by market share, roughly 60 to 70 percent of\n[the] registrar market now does act [to suspend domains] on the basis of those\nallegations.”\n\nIf the Internet community wasn’t aware of the financial risks of getting too\ndeeply enmeshed in the web of fake pharma sites, they got that message loud\nand clear in August 2011, when the U.S. Justice Department announced that\nGoogle had agreed to pay a $500 million fine to settle a criminal\ninvestigation that it allowed supposed Canadian pharmacies—including many\nrogue Internet pharmacies—to advertise drugs for distribution in the United\nStates. The $500 million figure was intended to represent the company’s\nadvertising revenue from the Canadian pharmacies and the revenue the\npharmacies received from American customers buying controlled drugs.\n\n## Visa Crackdown\n\nProbably the most lasting impact on the spam economy over the past two years\nhas come from research published by a ragtag group of academic researchers who\nmapped out the money-laundering networks relied upon by nearly all pharmacy\npartnerkas. More importantly, the researchers were able to use their findings\nto browbeat top commercial brands into pressuring Visa to take action against\nthe financial institutions that enable this activity.\n\nBy early 2010, the rogue pharmacy programs and fake antivirus peddlers were\nbeing infiltrated by a stealth band of white-hat researchers, university\nprofessors, and grad students who hoped to show that following the money could\nmake it much harder for these businesses to obtain credit card processing.\nOver several months, these researchers made hundreds of “test buys” at\nwebsites from forty different shady businesses hawking knockoff prescription\ndrugs, counterfeit software, and fake antivirus products. The researchers—from\nGeorge Mason University, the International Computer Science Institute, and the\nUniversity of California, San Diego (UCSD)—posed as buyers for these products.\n\nThe academic team believed that if they could locate and bring public\nattention to the financial institutions that were profiting from this trade,\nthe industry as a whole would suffer. The reason is that although selling\nknockoff prescription drugs over the Internet is not illegal per se, it is\nillegal for foreign entities to ship prescription drugs into the United\nStates. Such activity violates Visa and MasterCard card processing rules and\ncan bring hefty fines.\n\nAs noted in [Chapter 5](05_chapter05.xhtml), UCSD professor Stefan Savage and\nhis team had a mountain of work to do just in gathering ground-truth data\nabout the pharmaceutical spam economy.\n\n“When we started this, we wanted to figure out the whole value chain for the\nspam economy,” Savage said. “One big part of it was the back-end processing\nand banks, which no one was looking at.”\n\nSavage said that initially the University of California, Berkeley was none too\ninterested in their research. The sticky ethical and legal issues of\nessentially violating federal law to conduct otherwise harmless research made\nthe project a tough sell. The school and the researchers struck a bargain.\nThey would only purchase generic drugs that were available in the United\nStates over the counter and without a prescription, such as the abortion drug\nRU-486.\n\nIt turned out that the toughest part of their research was finding a reliable\nway to pay for their test orders. If they ordered the drugs with the same\ncredit card over and over, the pharmacy partnerkas would cancel the\ntransactions and flag the card number as suspicious. They settled on prepaid\ngift cards, since these payment instruments allowed their purchases to be\nanonymous. But it wasn’t enough to be able to purchase the drugs with the\nprepaid cards. The team needed to coax the card issuers into divulging the\nnames of the banks and merchant account numbers used to process the\ntransactions.\n\n“We found [that using] gift cards was the easiest thing because we could put a\nfake name in them or whatever,” Savage said. “But with a lot of these gift\ncards, if you wanted to find out transaction information, you needed to call\nsome customer support center. And even some of these fairly big prepaid cards\nhad only a few customer service people. And they would quickly get suspicious\nbecause if you did a lot of buys, you ended up talking to the same people all\nthe time.”\n\nSavage and the other researchers soon discovered the perfect prepaid network,\nalthough he declined to name it so as not to ruin similar ongoing and future\nresearch efforts. He would only say that it is a prepaid card issued by a\nfairly large grocery-store chain in the United States.\n\n“So we asked another group that was exploring this, and they told us about a\ngift card from a grocery-store chain. [UCSD graduate student] Chris Kanich\nshows up at one of these grocery stores with like $5,000 in cash and buys a\nboatload of these grocery-store prepaids. They didn’t bat an eyelash,” Savage\nsaid. “We’ve still got a stack of them somewhere. But that really was a hard\nthing to get past the university: that we were going to take all this money\nand turn it into these untraceable payment instruments, and of course trust us\nthat we’re not just going to go off on some Brazilian vacations or something.”\n\nWith the university’s blessing and a stack of prepaids the size of several\ndecks of playing cards, the researchers set off buying knockoff drugs from\nsites that were being advertised via spam. The grocery store’s prepaid network\nworked like a charm at all of the online pill shops, and everything seemed to\nbe humming along nicely. That is, until Uncle Sam decided that the largely\nunregulated and burgeoning market for prepaid cards was rife for abuse by\nmoney launderers.\n\n“Everything was going fine until Congress decided to help the world with this\nCredit CARD Act of 2009,” Savage said, referring to a law that went into\neffect in 2010 and included multiple restrictions on how credit card companies\ncan charge consumers. “The U.S. Treasury Department’s Financial Crimes\nEnforcement Network (FinCEN) had always been very concerned about gift cards\nfrom the standpoint of volume to untraceable money, because they totally\nrocked and were great for money laundering. I swear, if you had a suitcase\nfull of these, you could move many millions of dollars and it would be a\nhelluva lot lighter than several million bucks.”\n\nSomehow, the prepaid industry had escaped the “know your customer” regulations\nthat govern all U.S. financial institutions. These rules require banks to take\nspecific steps to profile customer activity for signs of money laundering,\nsuspicious transactions, and terrorist financing. After passage of the Credit\nCARD Act, however, prepaid networks fell under those same rules.\n\n“These cards were all reloadable, and you could just set the name on the cards\nto whatever you wanted, because there were essentially no ‘know your customer’\nrules for prepaid networks,” Savage said. “All of a sudden these networks\nneeded to have anti-money-laundering protections on international\ntransactions. The short-term impact of that was everyone in this industry\nbasically said, ‘Okay, no more international transactions with prepaids,’\nwhich instantly made my $5,000 in prepaid cards a useless pile of crap.”\n\nSavage said he was discouraged and ready to give up at that point, but one of\nhis graduate students—Chris Kanich—was undeterred. It was close to the end of\nNovember 2011.\n\n“That son of a bitch totally ignored me and started cold-calling credit card\nissuers. He just called them and said, ‘Hi, my name is Chris Kanich and we’re\ndoing this pharmacy spam research and we need a financial product that can do\nX, Y, and Z.’ He called like fifty banks until he found this little bank in\nthe Midwest. The person he talked to was receptive and said the CEO of the\nbank was really interested in cybersecurity. So they cut us a special deal,\nand after that, it became way easier.”\n\nThe research team became intimately familiar with the various schemes that\ndifferent rogue pharmacy networks used to weed out suspicious transactions.\nThe rogue pharmacy networks were extremely wary of any fraud that might drive\nup their transaction rates or get them shut down, so they tended to rely on\nmany layers of anti-fraud measures. For example, they used geo-location\nservices to check if the buyer’s Internet address showed that he was from a\ngeographic location that was in the same town as the billing address on the\ncredit card.\n\n“Over time, we learned that each transaction was awarded a fraud score based\non a number of criteria, and any transactions that went above a certain fraud\nscore were just never put through by the merchant processors,” Savage said.\n“We learned that having an email address at a public webmail provider\nincreased your fraud score. We learned over time that you needed to have a\nname that had a real physical address and a working phone number because they\nwould often call you back to verify the order.”\n\nEarly in their bogus buying spree, the researchers got found out. They were\ntrying to conduct at least one undercover purchase every month from each of\nmore than two dozen online pharmacy partnerka programs, so that they could\nkeep track of the acquiring banks that were processing the transactions.\nLittle did they know that most of the partnerkas were using the same financial\ninstitutions—a handful of banks in Azerbaijan, Latvia, Cyprus, and Turkey.\n\n“We tried to keep a low profile and put in one order per program per month,\nbut since we didn’t know they were all getting processing from the same place,\nwe were doing like thirty-five orders per month from the same people,” Savage\nsaid. “At one point Chris Kanich [still a coresearcher but by then an\nassistant professor at University of Illinois at Chicago] gets this call from\ncustomer service people from one of the partnerkas, and he’s having to think\non his feet because they wanted to know why so many people at his address were\nordering Zyrtec, which is an anti-allergy drug. And he basically made up some\nstory, saying he lived in a college dormitory, and that he and all of his\nroommates had allergies because they were all allergic to cats and one of the\nguys had a cat. So, over time, we all learned how to do this fake ordering.”\n\n## Spamlytics, Microsoft, and Napalm\n\nFollowing the money trail revealed an astounding fact: 95 percent of the\ncredit card transactions for the spam-advertised drugs and herbal remedies\nthat the researchers purchased were handled by just three financial firms—one\nin Azerbaijan, one in Denmark, and another in Nevis, in the West Indies. Many\nAmericans probably would be hard-pressed to find these places on a map, let\nalone recall conducting business with a company in those areas. And yet, a\nhuge percentage of the credit card processing for the spam industry flowed\nthrough financial institutions in these regions. Anti-spam experts wanted to\nknow why banks couldn’t spot this odd concentration of dodgy banking activity\nand put a stop to it.\n\nThe researchers published their findings in a paper, “Click Trajectories: End-\nto-End Analysis of the Spam Value Chain,” which described their “spamalytics”\nmethod for targeting the central weakness in any spam operation—its reliance\non credit card processing for the goods advertised in junk messages.\n\nSavage said that five days after the New York Times wrote about their paper,\nthe researchers received a phone call from the White House. On the line was\nVictoria Espinel, the Obama administration’s intellectual property enforcement\ncoordinator.\n\n“She was having this come-to-Jesus meeting with the domain name registrars,\nbig-name brands, and Google, saying, ‘Hey, we should all be doing something\nabout this spam problem.’ In our paper, we said there were basically two ways\nof doing this: you can go bilaterally against the [pharmacy] merchant banks,\nbut that’s slow. Or you could try to shut it off at the credit card issuing\nside, because these pharma networks were mostly all Western money. That was in\nretrospect a stupid idea, because when we talked to issuing banks here in the\nUnited States, they said, ‘Hey, our customers aren’t complaining, and we’re\nnot in the business of policing what our customers do that appears to be legal\nin the transaction records.’”\n\nEspinel connected Savage and his team with the International Anti-\nCounterfeiting Coalition, a nonprofit group created to help corporate brands\ntackle commercial piracy and trademark abuse cases. The IACC was putting\ntogether an online portal where any brand holder could sign up and report\nabuse of their trademarks directly to MasterCard and Visa, which would\ninvestigate the claim and ultimately levy fines against any banks processing\ntransactions tied to that claim.\n\nThe IACC relied on contracts that all banks sign as a prerequisite to doing\nbusiness with the credit card associations, which stipulate that all product\nsales must be legal not only in the jurisdiction where the merchant bank\nresides, but also in the home country of the customer. And since shipping\nprescription drugs to consumers from outside of the United States violates\nU.S. law, any claim reported to Visa or MasterCard via the IACC by an affected\nbrand holder effectively caused fines to rain down on banks that were\nprocessing payments for the pharmacy partnerkas.\n\n“These stipulations were always in the contracts, but for some reason people\nweren’t paying attention to this,” Savage said. “It turns out that the people\nwho really give a rat’s ass about the spam problem are the brand holders,\nbecause they’re the ones whose products, copyrights, and trademarks are being\ncounterfeited and violated. And the beauty of this approach is it’s not a\nlegal issue with criminal law. This is entirely a contract issue. In fact,\nthere is no law enforcement involved in this process at all. It’s just about\ngetting Visa and MasterCard to enforce their own contract rules.”\n\nIronically, it was not the pharmaceutical companies that stepped forward to\nuse the IACC’s cudgel against the pharmacy spammers but Microsoft. The same\nnetworks blasting spam to pimp online pharmacies were also being used to\npromote sites peddling counterfeit copies of Microsoft’s Windows operating\nsystem, and Microsoft saw a golden opportunity in the IACC to make it much\nmore expensive for counterfeiters to process credit card payments for knockoff\ncopies of Windows.\n\n“Microsoft decided they were going to go in whole hog. They were really\ncommitted,” Savage said. “The idea was, as the lead guy over there said, ‘a\nspecial Thanksgiving present.’ They were going to simultaneously go after\nevery bank being used in this program, all of the registrars registering\ndomains, and all of the hosting companies, and then in a short time take down\neverything. And then go to Google and Bing and get [the spammers] out of\nsearch results too. There was a moment when they just dropped the bomb on the\nentire industry. And there is this transition going on in the underground\nwhere everyone is saying, ‘Hey, we’re having a little bit of trouble.’”\n\nSavage said one major software vendor in particular went after affiliate\nprograms that were selling its products. Affiliate programs that trade in\npirated “OEM” or “original equipment manufacturer” software are those that\nprincipally traffic in high-dollar titles, including Microsoft Windows and\nAdobe products. It seems likely that Adobe was the vendor in question here,\ngiven the reaction on the OEM affiliate forums.\n\n“This vendor went after everything. They did it so quickly—and not only for\ntheir own products—that it all but shut down the entire OEM ecosystem,” Savage\nsaid. “A couple of [OEM affiliate programs] survived by getting rid of that\ncompany’s brand, but in the beginning, when people had no clue what was going\non, it shut down the entire business for everyone.”\n\nContracts between the banks and Visa and MasterCard stipulate that merchants\nare prohibited from selling goods and services that are illegal in the country\nwhere those goods or services are being purchased or used, or both. The credit\ncard associations have a standard process for accepting complaints about such\ntransactions, in which they warn the online merchant’s bank (including a\nnotice of potential fines for noncompliance). After a complaint about such\nactivity, the merchant’s bank conducts its investigation and may choose to\ncontest the issue if they believe the complaint is in error. But if the bank\ndecides not to challenge the complaint, then they will need to take action to\nprevent similar future transactions, or else face an escalating series of\nfines from the card associations.\n\nThe researchers noticed that in case after case, merchant accounts that had\nbeen used in fraudulent activity for an extended time before the researchers\nfiled a complaint with the IACC generally stopped being used within one month\nafter a complaint was lodged.\n\nSavage said the data suggests that the private sector can have a major impact\non cybercrime merely by going after the funding for these operations.\n\n“It doesn’t require a judge, a law-enforcement officer, or even much in the\nway of sophisticated security capabilities. If you can purchase a product,\nthen there’s a record of it and that record points back to the merchant\naccount getting the money,” Savage said. “Visa and MasterCard frown on sales\nof illegal purchases made on their networks and will act appropriately on\ncomplaints from brand holders based on undercover purchases.”\n\nAt approximately the same time that the researchers were submitting their\nfindings to the IACC, Visa was enacting a series of changes to their operating\nregulations that seem designed to specifically target online pharmacies and\nsellers of counterfeit goods. First, sales of goods categorized as\npharmaceutical-related were for the first time explicitly classified as “high\nrisk” (along with gambling and various kinds of direct marketing services),\nand acquirers issuing new contracts for high-risk ecommerce merchants required\nsignificantly more due diligence (including $100 million in equity capital and\ngood standing in risk management programs).\n\nAlso, the new documents explicitly call out examples of illegal transactions\nincluding “unlawful sale of prescription drugs” and “sale of counterfeit or\ntrademark-infringing products or services,” among others. Finally, these\nchanges include more aggressive fine schedules for noncompliance.\n\nSome of the best evidence of the success of the test-buy strategy comes\ndirectly from the folks operating the affiliate programs that reward spammers\nand miscreants for promoting fake antivirus and pirated software and dodgy\npill sites. In June 2012, a leader of one popular pharmacy affiliate program\nposted a lengthy message to gofuckbiz.com, a Russian language forum that\ncaters to a variety of such affiliate programs. In that discussion thread,\nwhich is now more than 250 pages in length, the affiliate program manager\nexplains to a number of mystified forum members why the pharmacy programs have\nhad so much trouble maintaining reliable credit card processing.\n\nIn May 2011, Visa initiated a new program, the so-called “Global Brand\nProtection Program.” How this would turn out for banks and merchants no one\nknew at the time, so at the time nothing much changed—everything kept working\nas before. After several months, Visa begins to act, and beginning in November\n2011, fines of $25,000 USD on every domain containing brands Viagra, Cialis,\nand/or Levitra or other copyrighted medications began raining down on\nmerchants.\n\nThe manager continued:\n\nAll affiliate programs have come under fire. Today, all sizable affiliate\nprograms have paid more than hundreds of thousands in fines under this\nprogram. Banks also come under fire, and although in most cases they can cover\ntheir financial losses at the expense of merchants—provided their turnover is\nsufficient—Visa’s audits, reputation risks, and other hassles complicate their\nwork. That is why some banks have completely refused to do business, some have\ngreatly reduced the volume of “pharma” payments, [and] some have “overinsured”\nthemselves in one way or another, leading to practically zero approval rates.\nSome (banks) continue to work, but today their number is very limited.\n\nAnother affiliate of a rogue pharmacy program put the situation in far less\ndelicate terms, observing:\n\nRight now most affiliate programs have a mass of declines, cancels, and\npendings, and it doesn’t depend much on the program IMHO, there is a general\nsad picture, fucking Visa is burning us with napalm.\n\nAfter getting scorched by Visa’s fines, many pill-shop processors have begun\nintentionally “miscoding” their pharmacy transactions, said Savage. The credit\ncard companies require all transactions to be tagged with a transaction code\nthat identifies the type of good or service being purchased. There are\nthousands of such codes (pharma is 5192, for example), and the contracts that\nmerchants must sign with the card associations give the latter the power to\nlevy huge fines against merchants that miscode high-risk transactions as\nlower-risk activity.\n\n“At this point, most of the remaining pharmacy partnerkas start[ed] getting\ndesperate, doing crazy things like laundering their transactions through\nparking garages and random banks in the United States,” Savage said. “The\nmiscoding was great because [initially] for most of the counterfeit stuff, we\nas researchers couldn’t complain about it to Visa because we had no standing\nwith Visa. We couldn’t just say, ‘Hey, here’s a Pfizer product that’s getting\nripped off. Visa, you should do something about that.’ Only the brand holder\ncan actually take action.\n\n“But on this miscoding stuff, anyone can report anything. If we find that one\nof these pharma shops is using a U.S. bank and miscoding their transactions,\nwe can often just call the bank and say, ‘Hey, did you know this is going on?’\nAnd most times, they’ll say, ‘Thank you very much,’ because they can get big\nfines for processing these miscoded transactions. And so if you tell them,\nthey get to shut it down without Visa finding out and fining them.”\n\nDamon McCoy, assistant professor at George Mason University’s computer science\ndepartment, said many pharmacy, scareware, and OEM software affiliate programs\nhave responded to the payment system crackdowns by putting burdensome security\nmeasures in place to screen out test buys. For example, some rogue pharmacy\nprograms—such as RxPayouts—began requiring buyers to send scans or faxes of\ntheir driver’s licenses and physical credit cards. Others have decided only to\nprocess payments for existing customers.\n\nBut both security measures can be self-defeating, for customers and affiliates\nalike. The researchers note that RxPayouts’ photo ID requirement for new\ncustomers (enacted in January 2012) caused an uproar among affiliates.\nAccording to the researchers, one affiliate wrote in response, “This new rule\nis killing me, my conversion rate for new customers [has] dropped to [zero].\nAs soon as my new customers find out they have to fax their customer service a\nphoto ID, they cancel their order.”\n\nMcCoy said the new requirements also serve to insulate affiliate programs from\nanother potential source of headache and trouble: rogue affiliates who join\nthe program merely to reap the commissions for orders placed with stolen\ncredit cards.\n\n“Originally, the affiliate programs were doing this to defend against the\ncarders, and in the past if there was a chargeback for a purchase, the\naffiliate program ate that chargeback cost,” McCoy said. “Now, if a chargeback\ncomes through, they’ll take that charge out of the affiliate’s subsequent\nearnings.”\n\nThe researchers observed that pharmacy affiliate programs also have responded\nrecently by replacing brand-name drugs with their generic equivalents (for\nexample, sildenafil citrate instead of Viagra, tadalafil instead of Cialis,\nand so on). The operators of these programs argue to their affiliates that\nsuch actions will eliminate the brand and trademark issues and thus undermine\nthe ability of brand holders to shut down both individual sites and the\nassociated merchant accounts.\n\nWhether this last step will allow banks that cater to such businesses to\ncontinue to do so undisturbed by the credit card networks remains to be seen,\naccording to the program affiliate manager quoted above, who posted the\nfollowing on gofuckbiz.com.\n\n“What this will lead to in the end, time will tell. Either everyone will stop\nusing well-known brand names, which are so well known to buyers, and will\nstart using the Indian generic names or names of active ingredients, or\neveryone will continue to compete in this mad race of who will outsmart whom.”\n\n\nChapter 12\n\n## ENDGAME\n\nIn June 2011, Vrublevsky made his second unscheduled trip to the Maldives that\nyear. This time, he fled Moscow because he got word that prosecutors there\nwere preparing to levy criminal charges against him in connection with a July\n2010 cyberattack on Aeroflot’s ticketing systems.\n\nInvestigators had already arrested Igor and Dmitry Artimovich, brothers who\nallegedly co-built and operated the Festi botnet. Both brothers deny operating\na botnet or sending spam, and claim that the Russian police planted evidence\non their computers. Russian prosecutors had obtained a signed confession from\nIgor stating that Vrublevsky had hired him to attack Assist, Aeroflot’s\npayment processor. At the time of the attack, ChronoPay was among several\ncompanies bidding for a lucrative contract to process payments for Aeroflot,\nand prosecutors alleged that the attack was designed to ensure that Assist\nwould not maintain the contract. Ironically, a month after the attack,\nAeroflot awarded the contract to neither company, but instead to Alfa Bank,\nthe largest private bank in Russia.\n\nRussian authorities reminded Pavel that he could also be picked up by American\nor other national authorities while in the Maldives, and so he voluntarily\nreturned to Moscow.\n\nUpon his arrival, Vrublevsky was arrested and sent to Lefortovo, a high-\nsecurity, fortress-like prison built in Moscow in 1881. The prison earned its\ninfamy during the Cold War, when it was used by the Russian KGB to isolate and\ninterrogate political prisoners. In 1994, control over Lefortovo was\ntransferred to the Russian police, and later it was handed to the FSB, the\nsuccessor agency to the KGB.\n\nIn prison, Vrublevsky admitted to ordering the attack on Assist, but later\nrecanted that statement. Nevertheless, his lawyer—ChronoPay employee Stanislav\nMaltsev, the same former Russian policeman who was once in charge of\ninvestigating allegations of illegal business activities by Vrublevsky—argued\nthat his client should be able to remain free pending his trial. The court\ndenied that request and ordered Vrublevsky to be held in Lefortovo for six\nmonths, the maximum pretrial time allowed by law for the offenses alleged\nagainst him.\n\n“The main risk of letting him out is not that he will run, but that he will do\nsome negative thing to witnesses and try to persuade them not to give or\ntestify to any information about him,” Gusev said in a phone interview.\n\nThis is a bold statement for a man whose leaked chat logs show that he and\nStupin paid $1.5 million to bring a criminal prosecution against Vrublevsky\nand $50,000 to start the case against Igor and Dmitry Artimovich, the brothers\nwho—sharing the nickname “Engel”—allegedly used their Festi botnet to spam for\nRx-Promotion and to occasionally launch crippling attacks against online sites\n(including the Aeroflot DDoS that got Vrublevsky thrown in prison).\n\nThe following is from a leaked chat, allegedly between Gusev and Stupin, dated\nSeptember 26, 2010. The two men had already decided to close SpamIt and were\nconsidering whether to do the same with GlavMed. Vrublevsky is referred to\nhere as “Paul” (the Western equivalent of “Pavel”).\n\nGUSEV: To my mind, you do not fully understand what’s been going on for the\nlast year. Paul has a plan to either throw me into jail or end me. His\nintentions are totally clear. There are only two choices: 1—Do nothing, and\npay nothing to nobody, and at the end either go to jail or keep hiding until\nall the resources are exhausted; 2—Do the same thing as he is doing, with the\nsame goal.\n\nGusev tells Stupin that “any war costs money, resources, and nerve cells. You\ncannot go to war little by little, you either fight to the end or do not start\nit at all. Engel is going to harm us all the time… If there is any potential\nopportunity to take him out of the game, we have to use such an opportunity.\n$50K is very little compared to the losses we’ve had because of his DDoS\nattacks and compar[ed] to future losses if he is going to DDoS us again.”\n\nGusev tells Stupin that if he won’t put up his share of the $50,000 bribe to\nbring a criminal investigation against the Artimovich brothers, Gusev will be\nforced to assume greater control over the pharmacy partnerka. Stupin\nultimately acquiesces, but says he wants to go on record stating that he\nthinks it’s a bad idea.\n\nThe chats also show that around this same time, Gusev visited the Russian FSB\nand was enticed into working with them and giving information on big players\nwithin the rogue pharmacy industry.\n\n“They have tons of info, and a very good understanding of how everything works\nand where money comes in and comes out,” Gusev told Stupin in January 2010.\nThe FSB, he said, “definitely has information on the money movement of the\nwallets. In summary: If they want to put me in prison, they will. They also\nasked about you. For now they wanted me to work for them and give them info on\nothers. They promised all kinds of benefits from working with them.”\n\nInterestingly, the leaked chat logs between Gusev and Stupin were obtained by\nFSB investigators who had detained Stupin and made a forensic copy of his hard\ndrive. Somehow, Engel—perhaps via the bribes paid by Vrublevsky—obtained a\ncopy of these logs and leaked them to several sources, including this author.\n\nConversations from those chat logs have been featured prominently throughout\nthis book, but one of the most telling and honest conversations comes in a\ndiscussion thread on the Russian adult webmaster forum master-x.com. That\nconversation thread is full of comments from spammers who were sidelined from\nthe business or lost money because of the Pharma Wars between Gusev and\nVrublevsky. It currently spans more than one hundred pages.\n\nThe epic master-x.com discussion starts out with nearly everyone using\nnicknames and generally trying to hide their real-life identities, but about\nhalfway through the thread Gusev starts to make references to himself that\nclearly identify him as the author. In this conversation, Gusev becomes\nuncharacteristically very emotional and launches into a series of increasingly\nhostile tirades directed at Artimovich.\n\nGusev says that Russian webmasters understood that the Pharma Wars between\nhimself and Vrublevsky were just a contest to see who had more money and\nconnections. Gusev also warns Artimovich that Vrublevsky is likely to turn his\nanger on him when he gets out of prison. (By admitting Vrublevsky hired him to\nDDoS Assist, Artimovich essentially sealed Pavel’s fate.)\n\nKeep in mind that Pasha is a very vile man. And he has such a long memory! You\nsee, the fact that I was doing better than him after leaving ChronoPay had\ncaused him a severe butt hurt of 7 years!!! He could not sleep, was in a lot\nof pain over this! That’s what envy is. It destroys one slowly but surely. Now\nimagine his psychological state after he finishes his prison term. Hungry,\nangry, abandoned by all butt-kissers, without any business, and worst of\nall—with a clear realization that he could not put me in jail after all. I\nthink that Pasha’s psyche will not be able to withstand such pressure. And\nsince he will not be able to reach me, he will focus on you and your brother.\n\nAnd then Gusev says he may actually exact his revenge on Artimovich before\nVrublevsky does.\n\nBut this is all musing about a possible future. Speaking of the present, I\nthink I will get to you beforehand anyway. I warned you before that if you try\nto get my family involved in this conflict, the consequences would be very\nharsh. I will personally find you, tear your head off, and swap it with your\nass—most likely no one will see a difference.\n\n♦ ♦ ♦\n\nOn Dec. 23, 2012, Russian prosecutors freed Vrublevsky from Lefortovo Prison,\njust three days before his birthday. Vrublevsky’s release was hardly an act of\nmercy. Under Russian law, six months was the maximum time that prosecutors\ncould hold him pending trial.\n\nWithin hours of returning to his Moscow home, Vrublevsky was tweeting and\nblogging about his triumphant release. He also wasted little time in calling\nthis author, mainly to gripe about his treatment and living conditions in the\nfamed prison. In a lengthy phone conversation, Vrublevsky lamented the\npresence of and constant utterances from numerous Muslim inmates who were held\nin captivity in his corner of Lefortovo.\n\n“I didn’t even have hot water or a fucking window, and the light was on\ntwenty-four hours a day,” Vrublevsky recalled. “This is the most strict prison\nin Russia, and half of the prison is there for some kind of Muslim terrorism.\nI was blocked from communication with my family for three months…no phone\ncalls, visits, nothing. Just this ‘Allah, Akbar!’ crap five times a day!”\n\nVrublevsky’s lawyer forbade him from discussing his case, but as always he had\nan amusing story to share about his situation. When prisoners of Lefortovo are\nto be released, they’re ceremoniously informed by the more senior convicts of\na solemn tradition whereby the freed captive is supposed to later burn the\nclothes he had on when he was released. Fearing it might be welcoming more bad\nluck not to observe this tradition, Vrublevsky invited some friends over to\nhis house the day after his release to torch the clothes he was wearing when\nhe was admitted and expunged from Lefortovo.\n\n“Imagine this picture: It is gray, ugly weather, we are behind the house,\nstanding there with my clothes that I came out of the prison with,” Pavel\nrecalled, barely able to stop laughing. “Standing there having a cigarette in\nfront of the fire, having a funeral for the clothes. It’s like a real\nHollywood-type movie, minus the dramatic music at this moment. Serious things\nare being said, like, ‘Dude, don’t go back there, blah, blah.’ All of a\nsudden, my wife runs out of the house screaming: ‘Pavel, you’re burning the\nwrong shoes!’ Turns out, I burned my expensive Yamamoto shoes, not the ones I\nwore home from prison!”\n\nDuring his imprisonment, Vrublevsky signed a full confession stating that he\nmasterminded the attack on Assist, Aeroflot’s credit card processor.\nVrublevsky’s confession stated that he had instructed a ChronoPay\nemployee—Maksim Permyakov, an information security specialist for the\ncompany—to deposit $20,000 in WebMoney payments into a purse owned by Igor A.\nArtimovich, the alleged Festi spam botmaster and a former employee of Sun\nMicrosystems in Russia. Indeed, a lengthy email thread in the cache of\nmessages leaked from ChronoPay details this exchange precisely.\n\nArrested by investigators with the Russian Federal Security Service (FSB),\nArtimovich signed a similar confession stating that he’d been hired by\nChronoPay to use Festi in an attack on Assist. The FSB also arrested\nArtimovich’s brother, Dmitry, a freelance programmer.\n\nAll four men—Vrublevsky, Permyakov, and the Artimovich brothers—were charged\nwith violating two articles of the Russian criminal code: Article 272, which\ncovers “illegal access to computer information,” and Article 273, which\nprohibits the use and distribution of malicious computer programs. Both\narticles provide for imprisonment for between three and seven years.\n\nBut in September 2012, the court hearing the case refused to consider charges\nbrought under the latter statute, stating that the statute of limitations for\ncharging the defendants with using and distributing malicious computer\nprograms had expired.\n\nAll but one of the accused—Permyakov—would recant their jailhouse confessions\nprior to the start of their trial, claiming they were under intense\npsychological pressure from investigators at the time. Artimovich says police\neven beat him up.\n\nPermyakov, however, ultimately admitted to his role in the scheme and agreed\nto assist prosecutors in their investigation. For many who followed the trial\nclosely, this was not much of a surprise. Prior to joining ChronoPay,\nPermyakov himself was an official with the Russian FSB.\n\nPermyakov may well have also been the source of the leaked ChronoPay emails\nand documents. In his many rants and musings about the source of the breach,\nVrublevsky remained adamant in his belief that the ChronoPay compromat was not\nstolen by hackers but instead leaked by someone in the company’s information\ntechnology department. Interestingly, while nearly all of the top ChronoPay\nemployees saw years’ worth of their company email communications leaked as a\nresult of that breach, Permyakov’s inbox was conspicuously absent from that\narchive.\n\nIn any case, it’s perhaps fitting that the trial of Vrublevsky and his co-\nconspirators would unfold as a stellar example of the very corruption that the\nformer ChronoPay CEO had schemed for so long to work to his commercial\nadvantage.\n\nAeroflot claimed that its ability to accept plane reservations via its website\nand credit card processing facilities was sidelined for nearly a week by the\nDDoS attack from Festi, and that the attack cost the company at least 146\nmillion Russian rubles (approximately $5 million). But as noted by Russian\nnews media outlet Novaya Gazeta, which covered the Vrublevsky case perhaps\nmore closely and skeptically than any other news organization, the judge in\nthe case cited the monetary damages in her ruling even though an arbitration\ncourt refused to acknowledge the figures and denied Aeroflot’s lawsuit to\nrecover property damage claims in connection with the attack. Rather, the\narbitration panel pointed out that most customers who could not purchase\nairline tickets online simply made their reservations through third-party\nbooking services or else bought them by visiting Aeroflot ticket counters.\n\nToward the end of his trial—in June 2013, Vrublevsky was arrested and\nimprisoned yet again, allegedly for trying to intimidate a witness for the\nprosecution. The prosecutors charged that Vrublevsky called one of the\nwitnesses—a woman named Nikita Evseeva—and that he had offered money in\nexchange for her silence. But according to Novaya Gazeta and other Russian\npublications, the truth was that Evseeva’s signature had been forged on a\ndocument stating that she had viewed and confirmed the sanctity of evidence\nthat the prosecution intended to present at trial.\n\nVrublevsky’s lawyers argued that they’d discovered Evseeva was in fact a\nfriend or girlfriend of the law-enforcement officer who had investigated the\nDDoS attack for the prosecution. Vrublevsky, his attorneys claimed, had\ncontacted Evseeva to convince her to state in court that her signature had\nbeen forged by investigators, and to offer her money so that she could make\nthe trip to be present at his trial.\n\nVrublevsky’s attorneys were almost certainly correct in their assertion that\nthe signature was forged, according to Aleksey Mikhaylov, an information\nsecurity expert and Moscow native now living in New York City, who has\nfollowed the case religiously since its inception and has devoured news\nreports in the Russian press online and the occasional report in Western news\npublications. He explains the importance of the forged signature and the role\nof the witness in this case.\n\n“Basically, the FSB investigators falsified some evidence, and unfortunately\nthis is not uncommon in Russia,” Mikhaylov said. “In the Russian criminal\ntrials, there is a term called panitoi, and this is someone who is supposed to\nbe an outside person—someone who has no interest in or connection to the case,\nlike in America where random people are called to jury duty—who is taken into\nthe room where the evidence is handled, and he or she is supposed to be\nwitness that everything is okay for the prosecution’s handling of evidence. In\nthis case, the witness was supposed to verify that certain evidence gathered\nfrom Artimovich was not compromised. It’s supposed to be a completely random\nperson, but the fact that the witness in this case was a good friend, if not\ngirlfriend, of an investigator in the case is very suspect.”\n\nNevertheless, the court ignored the evidence presented by the defense and\nupheld the decision to imprison Vrublevsky for witness tampering.\n\nFor his part, Igor Artimovich gave an interview with the New York Times prior\nto his imprisonment stating that he was not responsible for Festi, and that\nhis involvement with ChronoPay stemmed from a project within the company that\nhad sought to develop a ChronoPay-branded antivirus product.\n\nThis may seem like a ridiculous and outlandish claim for a company that had\nbeen so instrumental in fostering the development and prosperity of the rogue\nantivirus industry—a business that sought to extort money from victims by\nplanting malicious software on users’ systems and then pitching the sale of a\nworthless security product supposedly designed to remove the infection that it\ncaused.\n\nBut there appears to be a kernel of truth to Artimovich’s claims. When I\nvisited Vrublesky in Moscow in February 2011, he told me of plans to launch a\nChronoPay-branded anti-malware solution codenamed ChronoPay Antivirus. I\nrecall that we both shared an awkward laugh about this at the time, but among\nthe many documents leaked from ChronoPay are technical papers referencing the\ndevelopment of different antivirus software modules. The documents suggest\nthat the company had hired programmers to reverse engineer the free version of\nthe commercial anti-malware product Malwarebytes.\n\nBy the end of July 2013, the court had reached a verdict. All four of the\naccused were found guilty. Vrublevsky and the Artimovich brothers each were\nsentenced to two-and-a-half years in a penal colony. Permyakov received a\nslightly lesser sentence of two years because he assisted prosecutors in their\ninvestigation.\n\nMikhaylov said that he strongly believes that nearly everything that happened\nwith Vrublevsky in connection with his criminal case—the inception,\ninvestigation, prosecution, trial, and ultimate conviction—had very little to\ndo with the execution of justice the way Westerners understand it, but it has\neverything to do with his old business partner Gusev, and more specifically to\nbribes that Gusev paid the Russian FSB.\n\nHe notes that the Russian criminal code and the legal framework are not\nparticularly well-suited for prosecuting many high-tech crimes.\n\n“Many years ago, when the issue of hacking and cybercrime first surfaced, the\ngovernment introduced a law that says it’s illegal to gain unauthorized access\nto a computer system. And in this case, the prosecution argued that by\nattacking Assist [Aeroflot’s credit card processor], the hackers basically\ngained unauthorized access to Aeroflot because they were able to switch off\nits credit card processing and website,” Mikhaylov said.\n\n“You cannot look at this and say it is logical or makes sense from a legal\nperspective. The prosecution had to work with what they had to work with.\nThat’s why they charged him with this thing even though in any normal court\nwould have rejected it out of hand for any number of reasons. The prosecution\ndid produce some of the evidence linking him to the Artimovich brothers. But\nit does seem that a lot of this evidence was either falsified, or due process\nwasn’t followed in the case.”\n\nMikhaylov noted that Aeroflot is 51 percent owned by the Russian government,\nand that the attack on this state asset was a source of shame and aggravation\nfor many political powers-that-be in the country.\n\n“The practice of businesses using corrupt law enforcement in Russia to fight\neach other and steal market share is very common,” he said. “But when one\nparty is willing to pay big amounts of money or there are political folks\ninvolved, all due process goes out the window immediately. In those\ncircumstances, political connections and financial matters dictate the outcome\nof the case.”\n\nMikhaylov said he believes Vrublevsky drastically underestimated the\nseriousness and potency of the case that his enemies had laid against him.\n\n“When he initially got out of prison pending his trial, he tried to win the\ncase on the merits, which was a big mistake and very naïve of him,” Mikhaylov\nsaid. “Maybe he felt there was some financial support behind the scenes,\nbecause of his previous bribes to corrupt law enforcement. Unfortunately for\nhim, Gusev eventually found a much stronger weapon to use in this conflict and\ngained the upper hand. [Providing] $1.5 million in a single payment is a\nserious effort on his part, even by Russian corruption standards. I seriously\ndoubt Vrublevsky spent that much, even taking into account his past efforts on\nresolving the Fethard conundrum and hiring Maltsev as his security chief\nafterwards. Gusev won the war, or at least the battle, by upping the ante\nconsiderably. I’m sure that now Vrublevsky would gladly pay twice as much to\nget out, but it’s a lot more difficult to negotiate from his current\nposition.”\n\nMikhaylov predicted that Vrublevsky would not end up serving that much time in\nthe penal colony, or if he does serve his full term, the high-profile nature\nof his imprisonment may serve to insulate him while he’s there.\n\n“Pasha is rich guy, or at least he used to be rich guy. He had a house in the\nmost affluent neighborhood outside of Moscow. He still owns a major share in\nChronoPay. If I was him, I would sell everything to get out. In Russia it’s\nrelatively doable, unless you have FSB working against you. They are ruling\nthe country. If someone in FSB took $1.5 million from Gusev, there is probably\nno way they will accept money from Pasha. But there is another thing that\nworks for Vrublevsky. His case got a lot of attention, which means maybe he\nwill be watched over by the prison’s administration. There are hundreds of\narticles on him and this case. My guess is the prison and the Russian\ngovernment doesn’t want a public figure like him to get raped and cut in\nprison. That’s bad publicity.”\n\nMikhaylov is quick to note that he’s no apologist for Vrublevsky, who he views\nas the inevitable target of karmic justice.\n\n“At the very least, it produced something positive. Pavel was held accountable\nfor a very tiny fraction of his crimes,” Mikhaylov said. “His trial was\nobviously a fraud, and due process was not followed. But Pasha will get out of\nprison very angry, probably in a year or so. He will be looking for blood, and\nwho knows? Maybe a few years down the road, Gusev will share the same fate.”\n\nMany of Mikhaylov’s predictions have come true on several levels. It’s not\nclear whether Vrublevsky paid for the privilege, but in June 2014—less than a\nyear into his two-and-a-half-year prison sentence—he was released without any\npublic explanation (as far as I could determine through extensive research)\nand allowed to return home to his family in Moscow.\n\nLocal Russian newspapers suggested that he’d been sprung from jail because his\ngovernment needed him. In response to U.S. sanctions against Russia for\nfunding and organizing pro-Russian separatists who were causing unrest and\narmed conflict in Ukraine, Visa and MasterCard in March 2014 stopped servicing\npayments for clients of at least two top Russian banks. Russian President\nVladimir Putin responded by signing into law a bill that required the creation\nof a homegrown, cashless national payments system to route around the credit\ncard companies. The law also imposed stiff new requirements on international\npayments providers operating in Russia.\n\nIn a telephone interview shortly after his release, Vrublevsky told me that\nhis lawyers had strictly forbidden him from discussing his case. He said he\nhad no idea why he was released early, but that he didn’t think it had\nanything to do with the national payments system.\n\n“It was probably because I’ve been a good fireman,” Vrublevsky said,\nexplaining that for the last five months that he was in prison he had\nvolunteered to work as a fireman for the remote village that surrounded the\npenal colony—a former coal mining area in the Ryazan Oblast region of Russia\napproximately 200 kilometers southeast of Moscow.\n\n“I’ve seen things and places that people shouldn’t see, but I’ve seen some\nfunny stuff as well,” Vrublevsky said in response to questions about his\nprison sentence. “I get out and people are asking me about the national\npayments system, and I’m sitting there saying, ‘Man, are you joking? I can\npretty much tell you about how to feed cows with fireman water, but I don’t\nknow anything about the latest changes in the federal law’!”\n\nVrublevsky remains the principal shareholder in ChronoPay, a company he is\nlooking to sell as soon as he can. When I asked whether he was concerned that\nhis recent scandal and incarceration might hinder that effort, Vrublevsky\nintimated that whatever didn’t kill him and his company would only make them\nboth stronger.\n\n“Do you think that BMW is a good car? This is a company that was making\nengines for German airplanes in World War II. So there’s your answer. When\nsomeone is making a good product—and ChronoPay is a good product—all these\nother things are secondary.”\n\nGusev remains in exile from Russia, where he is currently wanted on criminal\ncharges of running an illegal business in GlavMed and SpamIt. Vrublevsky said\nhe believes Gusev is hiding with his family somewhere in Spain or in Turkey,\nbut that could not be independently confirmed. In any case, wherever Gusev is\ntoday, it’s unlikely he’ll be traveling anytime soon. In a 2011 interview, he\nsaid he was worried that the international organization of police\nagencies—Interpol—might post a notice for his arrest, should he decide to\ncross European borders.\n\n“I’m expecting that very soon I could be in the Interpol database,” Gusev\nsaid. “I’m already in the database of Russian police, so I’m not able to come\nto Russia, unfortunately. I’m sure Pavel is doing all he can to have my name\nput on the list of Interpol, and it could be very dangerous for me to go by\nplane or some kind of border transport.”\n\nKimberly Zenz, a cybercrime expert with the Reston, Virginia-based firm\nVerisign iDefense, has tracked the feud for years. She said she believes\nVrublevsky was the aggressor, and that he was brought down by an enormous ego\nand an overabundance of misplaced confidence.\n\n“He loves the attention, and cybercriminals should not love attention,” Zenz\nsaid. “But this way, he gets to very publicly be the big boss and get respect\nfor his role in the underground community.”\n\nBut according to Zenz, other factors worked to undermine Vrublevsky’s spam and\nrogue antivirus empire.\n\n“He really was on the wrong side of history,” Zenz said. “At one point, people\ncomplained that Russia never cared about cybercrime. And I think Pavel\nmisunderstood how far he could go and what he could attack. The part of his\npersonality that made him grow ChronoPay the way he did was the same part that\nmade him overstep his bounds and attack Assist, and think that he could take\non Gusev and that there would be no problem with either.”\n\nStefan Savage, the UCSD professor, said Vrublevsky seemed obsessed with always\ncoming up with some newer and greater blackhat scheme.\n\n“You have to see it in that light to understand how he could have this\nlegitimate company and then still want to pump it full of pharma and fake\nantivirus and all this other stuff,” Savage said. “He clearly felt driven to\nbe the big man. And certainly, if you look at the interactions between him and\nother people at ChronoPay—and the fact that he would constantly show up at\nVisa security and fraud conferences in Europe—it’s clear he sees himself as\nthis larger-than-life figure. He didn’t need to do all this to have a good\nstandard of living. He could have been totally legit, although he might have\ndone what he did to support a certain lifestyle. But I also suspect part of it\nas well was he had a certain social circle of people in this cybercrime space\nthat he was trying to impress.”\n\nBut while the Pharma Wars may be temporarily over, the global threat from spam\nis stronger than ever. The demise of many large spam affiliate programs like\nSpamIt and Rx-Promotion coincided with a marked and more malevolent shift in\nthe way cybercrime is monetized. For starters, the work done by Savage,\nMicrosoft, and the brand holders who worked with the International Anti-\nCounterfeiting Coalition (IACC) to make it far more expensive for partnerka\nprograms to obtain credit card processing effectively killed off much of the\nrogue antivirus or scareware industry that ChronoPay had so carefully\nnurtured. But in its place, a far more insidious threat has taken hold:\nransomware.\n\nMuch like scareware, ransomware is most often distributed via hacked or\nmalicious sites that exploit browser vulnerabilities. Typically, these scams\nimpersonate the Department of Homeland Security or the FBI (or the equivalent\nfederal investigative authority in the victim’s country) and try to frighten\npeople into paying fines to avoid prosecution for supposedly downloading child\npornography and pirated content.\n\nRansomware locks the victim’s PC until he either pays the ransom or finds a\nway to remove the malware. Increasingly, ransomware attacks encrypt all of the\nfiles on the victim’s PC, holding them for ransom until victims pay up.\nVictims are instructed to pay the ransom by purchasing a prepaid debit card or\ncash voucher, sold at convenience stores or retail outlets the world over.\nVictims are then told to send the attackers the voucher code or card number\nthat allows the bad guys to redeem the information for cash.\n\n“I don’t think it’s an accident that we’ve seen ransomware rise as it’s become\nharder for these partnerka programs to find a continuous supply of banks to\nhelp them process cards for scareware payments,” Savage said. “You have a\nbunch of people who are used to making good money for whom fake antivirus\nsoftware and scareware have become problematic and for whom pharma is not\nreally an option. There’s a void in the ecosystem where people can make money.\nIt’s not at all an accident that these ransomware schemes essentially are\nbypassing traditional payment schemes.”\n\nThe past few years have also witnessed a noticeable change in the ways that\nbotmasters are using the resources at their disposal. By August 2013, the\nproportion of email that is spam had dropped to 67 percent, according to\nKaspersky Lab, a Russian antivirus and security firm. But to supplement a\ndecline in revenue from commercial email missives, many miscreants\nincreasingly are hiring out their botnets to send malicious software that\nposes a far more serious threat to consumers, especially those of us who never\nopen spam or junk emails, let alone buy anything from them.\n\nOne excellent example of this is the Rustock botnet, which started off in 2007\npromoting pump-and-dump stock scams. For years, it was among the world’s top\npromoters of pharmacy sites, but over the past few years, the miscreants at\nthe helm of Rustock have dedicated more of their spamming resources to\nblasting malware wrapped in a thousand disguises, from phony missives from\nFedEx and UPS, to bogus audit alerts from the U.S. Internal Revenue Service.\nIn most cases, this password-stealing malicious software is aimed at small- to\nmid-sized businesses in the United States and Europe, with the goal of\ninfecting the computer of the person in charge of the organization’s finances.\nArmed with that person’s username and password to the organization’s bank\naccount, the fraudsters will push through fraudulent bank transfers from that\nvictim’s account to accounts that they control.\n\nIndeed, according to University of Alabama at Birmingham’s Gary Warner,\nmalware sent via Cutwail spam is among the leading causes of corporate account\ntakeovers. This increasingly common cybercrime scourge affects thousands of\nsmall businesses each year, often resulting in hundreds of thousands of\ndollars in losses for individual victim organizations.\n\nAnother notable shift is that cybercrime entrepreneurs who run their own\nbotnets increasingly are seeking to extract more value from each infected\nsystem, carefully harvesting every nugget of personal data (for example,\npasswords, software license keys, and social media accounts) that they can\nfrom the compromised systems of unsuspecting users, all of which can be resold\nin the cyber underground, Savage said. What’s more, there are now more\ncybercrime bazaars than ever to help botmasters offload this data. In other\nwords, it’s very possible that a cybercriminal right now is selling your\npersonal information to someone else and making a pretty penny off it.\n\n“Much like the Inuit Eskimos made sure to use every piece of the whale, we’re\nseeing an evolution now where botmasters are carefully mining infected systems\nand monetizing the data they can find,” Savage said. “The mantra these days\nseems to be, ‘Why leave any unused resources on the table’?”\n\nWhile some are using ransomware and data harvesting, Savage said, many other\nformer affiliates and managers of failed scareware, pharma, and pirated\nsoftware partnerkas are casting about for the next big thing.\n\n“It’s a period of innovation, and people clearly are looking around for\nanother sweet spot that’s as good as pharma, which made more money more\nreliably than anything else out there,” he said. “A few affiliate programs are\ntrying to peddle pirated e-books and movies; others are getting into\n[advertising] payday loans. There are now tons of programs that will write\nterm papers for students. That seems to be a big thing now.”\n\nThe other factor weighing on the spam industry, Savage says, is that many\naffiliates have found more success advertising websites using so-called “black\nSEO” techniques to manipulate search engine rankings for their sites. He notes\nthat the biggest earner by far across thousands of GlavMed pharmacy affiliates\nwas a black SEO expert who used the nickname “Webplanet.” This enterprising\nyoung hacker appears to have earned all of his money by gaming the search\nengines.\n\n“There are a lot of games being played now doing [advertising fraud] or black\nSEO,” Savage said. “For now, a lot of these guys are becoming more diversified\nand are in kind of a regrouping period. And the subset of people doing well\nwith pharma spam are either retrenching or saying, ‘Yeah, we’ll have to accept\nlower profits or find another niche.’”\n\nSavage says he expects that online pharma as an industry will be dead two to\nthree years from now.\n\n“There will be some small affiliate programs, but I doubt there will be any\nbig affiliate programs like Rx-Promotion or GlavMed,” Savage said. “It just\ndraws too much attention and pressure from the card systems like Visa and\nMasterCard.”\n\nSavage’s comments eerily echo the words I heard from Igor Gusev in our last\ninterview in mid-2011.\n\n“It’s very strange that some people need to have done so much expensive\nresearch to understand that [the] weakest part of this business is card\nprocessing,” Gusev said. “They need to put pressure on the card processors\nwhich are monsters [that] only regulate [under] very negative public pressure.\nI think it would be a very powerful strike, and online pharma would be dead\nwithin two years if they could somehow switch off the merchants who [are]\nconnected to online pharma.”\n\nGusev, too, was wondering what the next big partnerka will be after pharmacy\nprograms die off.\n\n“I think that the next big thing will be connected to video, audio, and maybe\nsocial networking,” he said. “It will be some kind of service like what Google\nand Apple are trying to do now with sharing and having all your MP3s and\nvideos uploaded to a web service so you can access it from anywhere. The only\nquestion is what kind of model they will use to do billing for that, and how\npeople will pay for it.”\n\nGusev said he was considering going into the consulting business, advising\nonline affiliate programs on how to navigate the choppy waters inhabited by\nthe shady credit card processors and dodgy banks that support those\nindustries.\n\n“Honestly, I am looking into this business,” Gusev said. “From one point of\nview, it’s pretty risky because I want to stay as far as possible away from\ndoing stuff which could lead to another criminal case. But from another point\nof view, I can earn some money just to make some consultations with merchants\nsuch as this, if the merchants agreed to pay some percentage for my expertise,\nbecause the banks are the vital thing to all of this stuff.”\n\nMost readers of this book probably have never ordered anything advertised in\nunsolicited junk email or ingested prescription drugs of uncertain origin that\nwere ordered online. But there are a myriad ways that even the wariest\nInternet users still end up supporting spammers, scam artists, and organized\ncyberthieves. And almost all of those ways invariably stem from one cause:\napathy.\n\nWhether we go online using a device powered by Microsoft Windows, Mac OS X,\nLinux, or Android, each of us has a role to play in combatting or contributing\nto online fraud. As such, we are all either part of the problem or the\nsolution. There is no in-between anymore. Today’s online threats take full\nadvantage of people who fall behind on security updates, or those who wantonly\nopen unbidden email attachments and click on random links in email or on\nFacebook and Twitter that seem legitimate. For more information on what all of\nus can do to fight spam and malware—and better protect ourselves online—check\nout the Epilogue that directly follows this chapter.\n\n\n## Epilogue\n\n## A SPAM-FREE WORLD: HOW YOU CAN PROTECT YOURSELF FROM CYBERCRIME\n\nMany of us have had the experience of receiving a spammy email from a friend\nor loved one, only to have a frantic follow-up note arrive a few minutes later\nfrom that person stating that his or her email account was hacked and warning\nus not to open or respond to any of the messages sent by the intruder. To be\nsure, this is an alarming situation for many users. But the scarier truth is\nthat if your inbox (or your phone, tablet, Twitter or Instagram account,\nanything really) gets hijacked by modern cyberthieves, spewing spam is about\nthe most innocuous thing that can happen to it.\n\nThe true value of your email account to crooks is not merely in its ability to\npump spam or even forward malicious software and viruses to your entire\ncontact list. Depending on what you do with your account and how long you’ve\nhad it, your inbox could be worth far more than you imagine.\n\nFor example, sign up with any service online, and it will almost certainly\nrequire you to supply an email address. In nearly all cases, the person who is\nin control of that address can reset the password of any associated services\nor accounts—merely by requesting a password reset email. Got your retirement\nfund, bank account, or insurance plan tied to that inbox? An attacker in\ncontrol of your email account—either via phishing you or installing malware on\nyour system—can simply visit the websites that manage those accounts, request\na password reset, click a link in an email, and change your passwords (and\nthey will start with your email password)!\n\nEven if the person who hijacks your inbox doesn’t have the time or inclination\nto seize control over all of your associated accounts, he likely knows that\nthose accounts have a resale value in the cybercrime underground. How much are\nthese associated accounts worth? There isn’t exactly a central exchange for\nhacked accounts in the underground, but recent price lists posted by several\nne’er-do-wells who traffic in nonfinancial compromised accounts offer some\ninsights.\n\nSeveral bad guys in the underground will sell purloined usernames and\npasswords for working accounts at overstock.com, dell.com, and walmart.com,\nall for two dollars each, for example. Other sellers peddle accounts at\nfedex.com and ups.com for five dollars a pop, and Apple iTunes accounts\nstarting at eight dollars. Accounts that come with credentials to the email\naddresses tied to each site can fetch a dollar or two more.\n\nSome crime shops go even lower with their prices for hacked accounts, charging\nas little as three dollars for active accounts at dell.com, overstock.com,\nwalmart.com, tesco.com, bestbuy.com, and target.com, to name just a few. This\nmay sound like peanuts and hardly worth the bother, but remember that the bad\nguys engaged in this activity very often run large botnets, meaning they can\ngather this information from hundreds or thousands of hacked computers\nsimultaneously.\n\nEven if your email isn’t tied to online merchants, it is probably connected to\nother accounts you care about. Hacked email accounts are not only used to\nblast junk messages. They are harvested for the email addresses of your\ncontacts, who can then be inundated with malware, spam, and phishing attacks.\nThose same contacts may even receive a message claiming you are stranded and\npenniless in some foreign country, and asking them to wire money somewhere.\nTrust me, countless people actually follow through on these fake pleas for\nhelp and wire money straight into the pockets of these cyberthieves.\n\nIf you’ve purchased software, it’s likely that the license keys to those\nsoftware titles are stored somewhere in your email messages. Do you use online\nor “cloud” file storage services like Dropbox, Google Drive, or Microsoft\nSkyDrive to back up or store your pictures, files, and music? The key to\nunlocking access to those files also lies in your inbox.\n\nAnd worst of all, if your webmail account gets hacked and was used as the\nbackup account to receive password reset emails for one of your other\naccounts, guess what? Attackers can now seize both accounts.\n\nHopefully, it’s clear by now that keeping thieves out of your inbox is worth\nmaking the effort to take a few precautions. Fortunately, some simple tips and\nactions can help you maintain control over your email account—as well as lock\ndown the system you use to access that account.\n\nUntil recently, some of the web’s largest providers of online services offered\nlittle security beyond requiring you to enter a username and password.\nIncreasingly, however, the larger providers have moved to enabling multifactor\nauthentication to help users avoid account compromises. Gmail.com,\nHotmail/Live.com, and Yahoo.com> all now offer multistep authentication that\nusers can and should use to further secure their accounts. These typically\ninvolve the sending of a numeric code via text message or smartphone app that\nneeds to be entered along with your username and password. The code is sent\nand requested any time a suspicious login is detected—such as a login attempt\nfrom a computer or Internet address not normally associated with your account.\n\nDropbox, Facebook, and Twitter offer additional account security options\nbeyond merely encouraging users to pick strong passwords. To check if your\nemail or social network or other communications provider allows you to\nsupplement your account security with two-factor authentication, check out the\nwebsite twofactorauth.org. If your provider is listed with a check mark, click\nthe icon under the “Docs” column next to that provider for a link to\ninstructions on how to configure and enable this feature.\n\n## Password Madness\n\nEnabling two-factor authentication is a good way to increase your account’s\nsecurity, but if you’re relying on crummy passwords to begin with, you’re\nstill dangerously exposed. Plus, not every important service or site offers\ntwo-factor protections yet. Hardly anybody likes passwords—they can be such a\npain to remember sometimes—but unfortunately we are stuck with them until we\ncome up with stronger, more hacker-proof methods of securing our\ninformation.[17](epilog.xhtml#fn17) Here are a few tips for creating strong\npasswords. Take a moment to review these tips and tools, and consider\nstrengthening some of your passwords if they fall short.\n\nIf you’re like me—and really detest passwords but recognize that life is too\nshort to try to remember hundreds of them—it may be a good idea to consider a\npassword manager. These are computer programs or online services that can help\nusers not only pick and use much stronger passwords, but better safeguard them\nas well. They do so by using strong encryption to store your passwords.\n\nIf you want help picking strong passwords but don’t trust that you can\nremember such cryptic and lengthy ones as “#$DG3dcLqziI%&*wp,” then good news:\npassword manager programs are built to do that for you. Nearly all of them\nhook into your browser and handle the retrieval and insertion of your\npasswords when you visit a site at which you’ve previously asked the program\nto remember your password. All you have to do is create and remember a single,\nstrong “master password” that you’ll be asked for when you visit one of these\nsites.\n\nSome of the more popular password management tools include KeyPass, Password\nSafe, and RoboForm. LastPass is another excellent option that works entirely\nonline. (It does not require special software to be installed on your\ncomputer, so you can access your passwords no matter which machine you’re\non—including your smartphone.)\n\nIf you prefer to pick and manage your own passwords—or if you just need a\nreally good one to use as your master password in a password manager\nprogram—here a few tips for avoiding crummy passwords:\n\n•Create unique passwords that use a combination of words, numbers, symbols,\nand both upper- and lower-case letters.\n\n•Do not use your network username as your password.\n\n•Don’t use easily guessed passwords, such as “password” or “user.”\n\n•Do not choose passwords based upon details that may not be as confidential as\nyou’d expect, such as your birthday, your Social Security or phone number, or\nnames of family members or pets or anything else you post about on social\nmedia. (The bad guys use Facebook, Twitter, and Instagram too!)\n\n•Do not use words that can be found in the dictionary. Password-cracking tools\nfreely available online often come with dictionary lists that will try\nthousands of common names and passwords. If you must use dictionary words, try\nadding a numeral to them, as well as punctuation at the beginning or end of\nthe word (or both!).\n\n•Avoid using simple adjacent keyboard combinations. For example, “qwerty” and\n“asdzxc” and “123456” are horrible passwords that are trivial to crack.\n\n•Some of the easiest-to-remember passwords aren’t words at all but collections\nof words that form a phrase or sentence, perhaps the opening sentence to your\nfavorite novel or the opening line to a good joke. Complexity is nice, but\nlength is key. Picking an alphanumeric password that was eight to ten\ncharacters in length used to be a pretty good practice. These days, it’s\nincreasingly affordable for hackers and spammers to build extremely powerful\nand fast password-cracking tools that can try tens of millions of possible\npassword combinations per second. Just remember that each character you add to\na password or passphrase makes it an order of magnitude harder to attack via\nbrute-force methods like this.\n\n•Avoid using the same password at multiple websites. It’s generally safe to\nreuse the same password at sites that do not store sensitive information about\nyou (like a news website or discussion forum), provided you don’t use this\nsame password at sites that are sensitive.\n\n•Never use the password you’ve picked for your email account at any online\nsite. If you do, and an ecommerce site you are registered at gets hacked,\nthere’s a good chance someone will be reading your email soon.\n\n•Whatever you do, don’t store your list of passwords on your computer in plain\ntext. That’s like handing your identity over to cybercriminals if your\ncomputer gets hacked. My views on the advisability of keeping a written list\nof your passwords have evolved over time. I tend to agree with security expert\nBruce Schneier when he advises users not to worry about writing down passwords\nand having someone stumble across them in real life. Just make sure you don’t\nstore the information in plain sight. The most secure method for remembering\nyour passwords is to create a list of every website for which you have a\npassword and next to each one write your login name and a clue that has\nmeaning only for you. If you forget your password, most websites will email it\nto you (assuming you can remember which email address you signed up with).\n\n## Keep Up to Date\n\nAll of the account security tools in the world won’t prevent your inbox or\nFacebook account from being hijacked if your computer gets compromised by\npassword-stealing malware. While having antivirus software and a firewall on\nyour system can help ward off threats, these are far from panaceas, and\ntoday’s cyberthreats are being built to evade detection by these, especially\nin that critical first twelve-to twenty-four-hour period after which the\nmalware is blasted out via spam and social networking site links.\n\nIt’s important to understand that a key tenet of securing any system is the\nconcept of “defense in depth,” or having multiple layers of security and not\ndepending too much on any one approach or technology to block all attacks. And\nguess which layer is the most important one of all? You!\n\nMemorize and practice Krebs’s “Three Rules for Online Safety,” and you will\ndrastically reduce the chances of handing over your computer or mobile device\nto the bad guys. In short:\n\n•Rule 1: “If you didn’t go looking for it, don’t install it.” A great many\nonline threats rely on tricking the user into taking some action—whether it be\nclicking an email link or attachment, or installing a custom browser plug-in\nor application. Typically, these attacks take the form of scareware or fake\nantivirus pop-ups that try to frighten people into installing a security\nscanner. Other popular scams direct you to a video but then insist that you\nneed to install a special “codec,” video player, or app to view the content.\nOnly install software, software updates, or browser add-ons if you went\nlooking for them in the first place. And before you install anything, it’s a\ngood idea to grab the software directly from the source. Sites like\nMajorGeeks.com and Download.com claim to screen programs that they offer for\ndownload. But just as you wouldn’t buy a product online without doing some\nbasic research about its quality and performance—and ensuring it’s the actual\nproduct you want—take a few minutes to search for and read comments and\nreviews left by other users of that software to be certain you’re not signing\nup for more than you bargained. Also, avoid directly responding to email\nalerts that (appear to) come from Facebook, LinkedIn, Twitter, your bank, or\nsome other site that holds your personal information. Instead, visit these\nsites using a web browser bookmark and manage your online social networks that\nway. Fatfingering a single character in a web address can lead to hostile\nsites set up to take advantage of typos.\n\n•Rule 2: “If you installed it, update it!” Yes, keeping the operating system\ncurrent with the latest patches (from Microsoft, Apple, or Google, for\nexample) is important, but maintaining a secure computer also requires care\nand feeding for the applications that run on top of the operating system. Bad\nguys are constantly attacking flaws in widely installed software products,\nsuch as Java, Adobe PDF Reader, Flash, and QuickTime. The vendors that make\nthese products ship updates to fix security bugs several times a year, so it’s\nimportant to update to the latest versions of these products as soon as\npossible. Some of these products may alert users to new updates, but these\nnotices often come days or weeks after patches are released. A wonderful\nresource for anyone feeling update fatigue is Secunia’s Personal Software\nInspector, a free tool that periodically scans for and alerts users to\noutdated security software. The latest version also can be set to update such\nproducts automatically. FileHippo also has a nice, free update checker.\n\n•Rule 3: “If you no longer need it, remove it!” Clutter is the nemesis of a\nspeedy computer. Unfortunately, many computer makers ship machines with gobs\nof bloatware that most customers never use even once. On top of the direct-\nfrom-manufacturer junk software, the average user tends to install dozens of\nprograms and add-ons over the course of months and years. In the aggregate,\nthese items can take their toll on the performance of your computer. Many\nprograms add themselves to the list of items that start up whenever the\ncomputer is rebooted, which can make restarting the computer a bit like\nwatching paint dry. It takes forever. And remember, the more programs you have\ninstalled, the more time you have to spend keeping them up to date with the\nlatest security patches.\n\nI hope you find these tips useful and timely. For more information about how\nto stay safe online—including news about the latest threats, criminal schemes,\nand software bugs being leveraged by the spammers and scam artists online,\ncheck out my website, [KrebsOnSecurity.com](http://KrebsOnSecurity.com). While\nyou’re there, drop me a note and let me know what you thought of this book,\nusing the contact form at\n[www.KrebsOnSecurity.com/about](http://www.KrebsOnSecurity.com/about).\n\n* * *\n\n[17.](epilog.xhtml#fnr17)It’s important to note that improved security and\nidentification methods are in the works for certain digital technology and\ndevices. Many banks in Europe, for example, put chips in their credit cards,\nwhich make the cards more difficult and costly to use for fraud. This is\nslowly being introduced in the United States as well. Another recent security\nmeasure worth noting is the addition of fingerprint ID technology on some\nphones and laptops as an option to lock or unlock them. And doubtless more is\non the way.\n\n\n## ACKNOWLEDGMENTS\n\nWriters tend to be a solitary lot, but they seldom produce enjoyable works\nwith the length and complexity of a book without a great deal of assistance\nand patience from friends and colleagues.\n\nSpam Nation would not have been possible without the help of several native\nRussian speakers who spent countless hours with me teasing out the\nconversations and links between various real-life characters profiled in this\nbook. In particular, I would like to thank Alek Geldenberg, Aleksey Mikhaylov,\nand Maxim Suhanov for their tireless work in translating documents, emails,\nand chat logs, and in generally helping me connect the dots.\n\nFor their knowledge of the hacker underground and the denizens therein, my\nsincere gratitude goes out to Lawrence Baldwin, Adam Drake, Alex Holden, Lance\nJames, Jon O, and Kimberly Zens.\n\nFor helping me to extract patterns and meaning from epic truckloads of data, I\nam especially grateful to Damon McCoy, Stefan Savage, Brett Stone-Gross, Gary\nWarner (and their armies of grad students).\n\nJoe Menn and Misha Glenny were there with encouragement and sage advice\nexactly when I needed it. Had it not been for the hours-long chat with Roland\nDobbins in Snowmageddon 2009, I might not have had the courage to strike out\non my own as an independent journalist. Thanks of an unspecified nature go\nalso to J.B. Snyder, a great guy who always does just what he says he’s going\nto do.\n\nI owe more than I care to acknowledge for my continued physical and online\nsafety to several folks. Chris Barton has kept me and my site online and out\nof trouble—even in the face of often withering attacks. Group-IB and Kaspersky\nLab were instrumental in watching my back in Moscow. Various unnamed law\nenforcement officials have been helpful here in the States; thank you all.\n\nLast but not least, I would like to thank the regular readers of my\nsite—[KrebsOnSecurity.com](http://KrebsOnSecurity.com)—for their\nencouragement, support, and inspiration these past five years. I could not\nhave done this without you.\n\n\n## SOURCES\n\n## Chapter 1: Parasite\n\nA November 2008 blog entry by ThreatExpert (now owned by Symantec) was helpful\nwith the research on the car race that killed Kolya McColo, as well as a day-\nof-the-accident news report from the Russian publication Rossiyskaya Gazeta\n(ng.ru). I also relied on posts to the Crutop.nu forum, as well as leaked\ninstant message chats between Stupin and Igor Gusev, talking about who was\ngoing to attend or was at McColo’s funeral. As for information about Dmitry\n“Gugle” Nechvolod, I relied on instant message interviews with Igor\nVishnevsky.\n\n## Chapter 2: Bulletproof\n\nMuch of the background information on RBN came from Russian and Belarusian\nnews sources, including compromat.ru and Transitions Online, and Victor\nChamkovsky’s documentary, Operation Consortium, the text of which is still\navailable online via\nweb.archive.org/web/20120112081516/http:/www.detektiv.by/komputer. The\nconnection between Alexander Rubatsky and RBN also was supported by a letter\nto the Russian government by Russian Duma lawmaker Ilya Ponomarev. The section\non Petrovsky’s abduction was supported by news sources and reports including\nthe Ecommerce Journal (web.archive.org/web/20120611001710/http://m.ecommerce-\njournal.com/articles/hild_adult_in_internet_what_are_the_roots) and the\nBelarusian electronic newspaper, Diary. The section about Russian\ncommunication provider Eltel’s role in RBN was supported by a 2009 story in\nRussian Newsweek. Eltel appears to have since been purchased by Beeline, one\nof Russia’s larger mobile firms.\n\n## Chapter 3: The Pharma Wars\n\nData to back up statements about Vrublevsky’s apparent connection to Red &\nPartners was first published in a July 31, 2009 Washington Post article called\n“Following the Money: Rogue-Antivirus Software,”\n(voices.washingtonpost.com/securityfix/2009/07/following_the_money_trail_of_r.html).\nI revisited that story in a May 2010 post on\n[KrebsOnSecurity.com](http://KrebsOnSecurity.com), titled “Following the\nMoney, Part II,” ([krebsonsecurity.com/2010/05/following-the-money-part-\nii/](http://krebsonsecurity.com/2010/05/following-the-money-part-ii/)).\n\nThe public documents obtained from the Netherlands Chamber of Commerce that\nconcern Red & Partners, and show how Igor Gusev (DPNet) and Pavel Vrublevsky\n(Red & Partners) cofounded ChronoPay back in 2003 and became fifty-fifty\nshareholders can be viewed online here: [krebsonsecurity.com/wp-\ncontent/uploads/2011/02/CP20051.pdf](http://krebsonsecurity.com/wp-\ncontent/uploads/2011/02/CP20051.pdf). (Note: This is a Dutch document that was\npublicly released.)\n\nSome of the information that makes up this chapter is difficult to source\nprecisely. For example, while it is assumed that Gusev or hackers closely\nallied with him obtained and released publicly several years’ worth of emails,\nspreadsheets, and recorded phone calls from ChronoPay, I was not able to\nconfirm this. As stated in this chapter, the information was shared\nanonymously by a source who used the alias “Boris.” However, ChronoPay’s CEO\nVrublevsky did confirm that the documents in question were in fact stolen from\nChronoPay. The data regarding GlavMed and SpamIt—including four years of ICQ\nchat records between GlavMed-SpamIt administrator Dmitry Stupin and his\ncoworkers and employees (spammers) was paid for and released to this author\nand to U.S. authorities by Vrublevsky.\n\n## Chapter 4: Meet the Buyers\n\nThis chapter relied almost entirely on interviews with people who purchased\ndrugs from GlavMed-SpamIt and Rx-Promotion. It also featured quotes and\nperspectives from online interviews with Igor Vishnevsky, the self-described\nspammer who acknowledged funding and reselling the Cutwail spam botnet. I also\nrelied on information from government sources, including the FDA\n(www.fda.gov/ICECI/EnforcementActions/WarningLetters/ucm229010.htm).\n\n## Chapter 5: Russian Roulette\n\nFor the opening story about the death of Marcia Bergeron, I relied on a 2007\npiece in the Vancouver Sun. For additional background on the Bergeron story, I\nobtained a copy of Bergeron’s coroner report from authorities in British\nColumbia.\n\nSeveral facts in this chapter refer to or cite stories in the New York Times.\nThe section that details how the anti-acne drug Accutane came under new safety\nrules by the Food and Drug Administration drew information from an August 2005\nstory by Gardiner Harris. An April 2013 story by the New York Times’ Harris\nand Katie Thomas helped with the research on the role of Indian pharmacies\nproducing the anti-leukemia drug Gleevec at drastically lower prices than\nWestern pharmaceutical companies.\n\nA CNN story by David Goldman was the source for information about the $500\nmillion settlement Google struck with the U.S. Justice Department over\nillegally allowing online Canadian pharmacies to advertise drugs to U.S.\nconsumers. A discussion of the $2.3 billion settlement Pfizer agreed to with\nthe Justice Department drew information from a Wall Street Journal article by\nRon Winslow.\n\nThis chapter refers to an incident that had been reported recently in the news\nwhen I visited the University of Alabama at Birmingham—the case of the so-\ncalled “causeway cannibal” who reportedly chewed the face of a homeless man\nafter allegedly ingesting bath salts. At the time, UAB’s lab was testing the\nchemical composition of a substance that authorities suspected was bath salts.\nBut as CNN and other news outlets later reported, follow-up toxicology tests\non the suspect shot by police found not bath salts but marijuana.\n\nThis chapter also references a study by Merck. That study was never officially\npublished; the references are in fact to online intelligence that Merck\ngathered between 2009 and 2010 and shared at the author’s request.\n\nThe section that references a letter from the FDA to Vrublevsky’s alleged\npartner in Rx-Promotion refers to a letter dated October 8, 2010, and\naddressed to one “Jorge Smark” at the email address hellmanh@gmail.com. See\nwww.fda.gov/ICECI/EnforcementActions/WarningLetters/ucm229010.htm.\n\n## Chapter 6: Partner(ka)s in (Dis)Organized Crime\n\nThe inspiration for this chapter came principally from the seminal paper on\npartnerka programs “The Partnerka—What Is It, and Why Should You Care,” by\nDmitry Samosseiko of SophosLabs Canada. This chapter also relies heavily on\ndata gathered by researchers at the University of California, San Diego, the\nInternational Computer Science Institute, and George Mason University.\n\n## Chapter 7: Meet the Spammers\n\nA section that details the rise of self-described spammer Igor Vishnevsky\nreferenced an August 2006 article in Wired, “The Sleazy Life and Nasty Death\nof Russia’s Spam King,” by Brett Forrest, in which Vishnevsky himself also is\ninterviewed. Some of the information about Vishnevsky’s botnet—Cutwail, a.k.a.\n“0bulk Psyche Evolution”—comes from a March 2011 paper released at the fourth\nUSENIX symposium by security researchers Brett Stone-Gross, Thorsten Holz,\nGianluca Stringhini, and Giovanni Vigna, and titled “The Underground Economy\nof Spam: A Botmaster’s Perspective of Coordinating Large-Scale Spam\nCampaigns.”\n\nSome of the information about infamous spammer Peter Severa’s connection to\nconvicted spammer Alan Ralsky comes from a forty-page indictment that the\nJustice Department lodged against Ralsky in its prosecution. Raw data about\nthe spam-sending power of the major spam botnets drew principally from reports\npublished by Dell SecureWorks and by M86 Security.\n\n## Chapter 8: Old Friends, Bitter Enemies\n\nA discussion about raider attacks on Russian businesses references an April\n20, 2009 paper by Brenden Carbonell, Dimitry Foux, Vera Krimnus, Ed Ma, and\nLisa Safyan of the 2010 class of Wharton School’s Lauder Institute, University\nof Pennsylvania, entitled “Hostile Takeovers: Russian Style” (see\nknowledge.wharton.upenn.edu/article/hostile-takeovers-russian-style/). The\nsegment on Skolkovo, a technology park outside Moscow that Russian leaders\nenvisioned as a Silicon Valley in the East, drew on a March 2012 story by\nIngrid Lunden at TechCrunch. This chapter also benefited from an October 2010\nstory in the New York Times, “E-Mail Spam Falls after Russian Crackdown.”\n\n## Chapter 9: Meeting in Moscow\n\nA section explaining the likely reason that Russian police raided the Rx-\nPromotion party alludes to a series of police raids on Moscow gambling dens,\nwhich were documented colorfully in February 2011 articles in Russian news\noutlets Svobodanews, RIA Novosti, and Rossiyskaya Gazeta (rg.ru).\n\nIn the beginning of my interview with Vrublevsky, he makes an indirect\nreference to Said Amirov, the four-time mayor of the capitol city of Dagestan.\nFor background on Amirov’s arrest and ongoing trial for alleged weapons\ntrafficking, I relied on stories in the Moscow Times and Business FM Radio.\n\n## Chapter 10: The Antis\n\nInformation about the percentage of email that was spam in the latter half of\n2013 comes from statistics published by Kaspersky Lab, in a November 2013\nposting on its securelist.com blog. The story about the attack on Blue\nSecurity draws on my reporting of the incident at the Washington Post. A\nsection on the March 2013 attacks on Spamhaus references New York Times\nstories in March and April about Sven Olaf Kamphuis.\n\n## Chapter 11: Takedown\n\nA March 2013 story in the Milwaukee Journal Sentinel was the source of\ninformation about the guilty plea deal of convicted spammer Oleg Nikolaenko.\nOther references to botnet and spammer takedowns in this chapter draw on my\nown reporting published about these events at\n[KrebsOnSecurity.com](http://KrebsOnSecurity.com).\n\n## Chapter 12: Endgame\n\nThe beginning of this chapter includes information from a September 2013 New\nYork Times article on Igor A. Artimovich, “Online Attack Leads to Peek into\nSpam Den.” Russian news outlets Vedemosti, Novaya Gazeta, and RIA Novosti were\nindispensable for their accounts of Vrublevsky’s convoluted trial.\n\nAccording to multiple Russian news outlets, Maksim Permyakov was the only one\nof the four charged in connection with Vrublevsky’s trial who admitted his\nrole in the scheme, which was hiring the Artimovich brothers at Vrublevsky’s\nrequest to launch a DDoS attack against Assist (a company that was competing\ndirectly with Vrublevsky’s firm for a lucrative credit card processing\ncontract with Russia’s largest airline).\n\n\n## ABOUT THE AUTHOR\n\n![image](../images/back02_001.jpg)\n\n© KRISTOF CLERIX\n\nBrian Krebs is the editor of\n[KrebsOnSecurity.com](http://KrebsOnSecurity.com), a daily blog dedicated to\nin-depth cybersecurity news and investigation. For the third year running,\n[KrebsOnSecurity.com](http://KrebsOnSecurity.com) was voted the Blog That Best\nRepresents the Security Industry by judges at the 2013 RSA Conference, the\nworld’s largest computer security gathering. KrebsOnSecurity also won the Most\nEducational Security Blog award in 2013 and 2014, and in 2013 Krebs was\npresented with the Security Bloggers Hall of Fame award, alongside security\nexpert Bruce Schneier.\n\nFrom 1995 to 2009, Krebs was a reporter for the Washington Post, where he\ncovered Internet security, technology policy, cybercrime, and privacy issues\nfor the newspaper and the website. His stories and investigations have also\nappeared in Popular Mechanics, Wired.com, the Guardian, the Sydney Morning\nHerald, and many other publications. Krebs is a 1994 graduate of George Mason\nUniversity, where he earned a bachelor of arts in international relations.\n\n\nThank you for purchasing this eBook.\n\nAt Sourcebooks we believe one thing:\n\nBOOKS CHANGE LIVES.\n\nWe would love to invite you to receive exclusive rewards. Sign up now for VIP\nsavings, bonus content, early access to new ideas we're developing, and sneak\npeeks at our hottest titles!\n\nHappy reading!\n\n[SIGN UP NOW!](http://tiny.cc/9781402295621)\n\n\nThank you for reading!\n\nAt Sourcebooks we are always working on something new and exciting, and we\ndon’t want you to miss out.\n\nSo sign up now to receive exclusive offers, bonus content, and always be the\nfirst to get the scoop on what’s new!\n\n[SIGN UP NOW!](http://tiny.cc/9781402295621)\n\n",
    "book_id": "spam_nation",
    "book_title": "Spam Nation",
    "book_author": "Brian Krebs",
    "topic_id": "cybersecurity_history",
    "topic_label": "history",
    "chunk_index": 1
  },
  {
    "chunk_full": "![Cover for The Fifth Domain](../images/9780525561972_cover.jpg)\n\n\n![Book title, The Fifth Domain, Subtitle, Defending Our Country, Our\nCompanies, and Ourselves in the Age of Cyber Threats, author, Richard A.\nClarke, imprint, Penguin Press](../images/9780525561972_title_page.jpg)\n\n\nPENGUIN PRESS\n\nAn imprint of Penguin Random House LLC\n\n[penguinrandomhouse.com](http://www.penguinrandomhouse.com)\n\nCopyright © 2019 by Richard A. Clarke and Robert K. Knake\n\nPenguin supports copyright. Copyright fuels creativity, encourages diverse\nvoices, promotes free speech, and creates a vibrant culture. Thank you for\nbuying an authorized edition of this book and for complying with copyright\nlaws by not reproducing, scanning, or distributing any part of it in any form\nwithout permission. You are supporting writers and allowing Penguin to\ncontinue to publish books for every reader.\n\nLibrary of Congress Cataloging-in-Publication Data\n\nNames: Clarke, Richard A. (Richard Alan), 1951– author. | Knake, Robert K., author.\n\nTitle: The Fifth Domain: Defending Our Country, Our Companies, and Ourselves\nin the Age of Cyber Threats / Richard A. Clarke and Robert K. Knake.\n\nDescription: New York: Penguin Press, 2019. | Includes bibliographical references and index.\n\nIdentifiers: LCCN 2019012065 (print) | LCCN 2019016384 (ebook) | ISBN 9780525561972 (ebook) | ISBN 9780525561965 (hardcover)\n\nSubjects: LCSH: Cyberterrorism—United States. | Computer security—United States. | Computer networks—Security measures—United States. | Corporations—Security measures—United States. | National security—United States.\n\nClassification: LCC HV6773.2 (ebook) | LCC HV6773.2 .C585 2019 (print) | DDC 363.325—dc23\n\nLC record available at <https://lccn.loc.gov/2019012065>\n\nWhile the authors have made every effort to provide accurate internet\naddresses and other contact information at the time of publication, neither\nthe publisher nor the authors assume any responsibility for errors or for\nchanges that occur after publication. Further, the publisher does not have any\ncontrol over and does not assume any responsibility for author or third-party\nwebsites or their content.\n\nVersion_1\n\n\nTo the late Michael A. Sheehan:\n\nSoldier, Diplomat, Patriot, Iconoclast, Friend\n\n—RICHARD A. CLARKE\n\nTo my son, William, whose deep interest in the causes of war is driven by his\neven deeper desire for peace.\n\n—ROBERT K. KNAKE\n\n\n# Contents\n\n[Title Page](02_Title_Page.xhtml)\n\n[Copyright](03_Copyright.xhtml)\n\n[Dedication](04_Dedication.xhtml)\n\n[PART I](06_Part_I_The_Twenty-Yea.xhtml)\n\n[THE TWENTY-YEAR WAR](06_Part_I_The_Twenty-Yea.xhtml)\n\n[1\\. The Back of the Beast](07_Chapter_1_The_Back_of.xhtml)\n\n[2\\. EternalBlue, Eternal War](08_Chapter_2_Eternalblue.xhtml)\n\n[PART II](09_Part_II_The_Corporate.xhtml)\n\n[THE CORPORATE FRONTLINE](09_Part_II_The_Corporate.xhtml)\n\n[3\\. Two Kinds of Companies?](10_Chapter_3_Two_Kinds_o.xhtml)\n\n[4\\. The Kill Chain](11_Chapter_4_The_Kill_Ch.xhtml)\n\n[5\\. The Tech Stack](12_Chapter_5_The_Tech_St.xhtml)\n\n[6\\. Cyber Resilience: The Best Bad Idea We’ve\nGot](13_Chapter_6_Cyber_Resil.xhtml)\n\n[PART III](14_Part_III_The_Governme.xhtml)\n\n[THE GOVERNMENT’S SUPPORTING ROLE](14_Part_III_The_Governme.xhtml)\n\n[7\\. Nudges and Shoves](15_Chapter_7_Nudges_and_.xhtml)\n\n[8\\. Is It Really You?](16_Chapter_8_Is_It_Reall.xhtml)\n\n[9\\. Fixing the People Problem](17_Chapter_9_Fixing_the_.xhtml)\n\n[10\\. Power Grids and Power Plays](18_Chapter_10_Power_Grid.xhtml)\n\n[11\\. Securing the Feds](19_Chapter_11_Securing_t.xhtml)\n\n[PART IV](20_Part_IV_Warriors_Dipl.xhtml)\n\n[WARRIORS, DIPLOMATS, AND CANDIDATES](20_Part_IV_Warriors_Dipl.xhtml)\n\n[12\\. The Military, Domains, and Dominance](21_Chapter_12_The_Milita.xhtml)\n\n[13\\. A Schengen Accord for the Internet](22_Chapter_13_A_Schengen.xhtml)\n\n[14\\. Democracy’s Shield](23_Chapter_14_Democracy_.xhtml)\n\n[PART V](24_Part_V_The_near_Futur.xhtml)\n\n[THE (NEAR) FUTURE IN CYBERSPACE](24_Part_V_The_near_Futur.xhtml)\n\n[15\\. Real and Artificial Intelligence](25_Chapter_15_Real_and_A.xhtml)\n\n[16\\. A Quantum of Solace for Security](26_Chapter_16_A_Quantum_.xhtml)\n\n[17\\. 5G and IoT](27_Chapter_17_5g_and_Iot.xhtml)\n\n[PART VI](28_Part_VI_You_and_the_W.xhtml)\n\n[YOU AND THE WAY AHEAD](28_Part_VI_You_and_the_W.xhtml)\n\n[18\\. Derisking Ourselves](29_Chapter_18_Derisking_.xhtml)\n\n[19\\. Everything Done but the Coding](30_Chapter_19_Everything.xhtml)\n\n[Glossary](31_Glossary.xhtml)\n\n[Acknowledgments and Disclosures](32_Acknowledgments_and_D.xhtml)\n\n[Notes](33_Notes.xhtml)\n\n[Index](34_Index.xhtml)\n\n[About the Authors](35_About_the_Authors.xhtml)\n\n\n# PART I\n\n# THE TWENTY-YEAR WAR\n\n\n## Chapter 1\n\n## THE BACK OF THE BEAST\n\nThe future is already here; it’s just not very evenly distributed.\n\n—WILLIAM GIBSON\n\nSitting in the back of the Beast, the armored vehicle custom made for the\nPresident of the United States, Bill Clinton wanted to talk about his cousin\nfrom Hope, Arkansas. He didn’t want to talk about the major speech he was\nabout to give at the National Academy of Sciences. It was January 1999, and\nClinton had just proposed budget initiatives to combat emerging threats,\nincluding those in the cyber domain. Few people then saw cyber threats as a\nmajor problem. But he did. Dick Clarke sat next to him with a PowerPoint deck\nand an annotated version of the speech, but the President was channeling his\nBubba persona, telling a story about Arkansas, and not to be stopped.\n\nWhen the Beast pulled into the underground parking at the academy, Clinton\nfinally turned to the business at hand. “I read the speech. It’s okay.” That\nmeant it wasn’t.\n\n“But really, isn’t what we want to say something like this: Throughout history\nthere is a competition between offensive and defensive technologies and a gap\nbetween their development. A guy in a cave carves a rock and attaches it to a\nstick and creates a spear, and then someone needs to defend against that, so\nthey get some animal hides and make a shield. Later on, people defend towns\nwith walls and then some guy invents battering rams and catapults. But there\nis time between when an offensive weapon is created and when the defensive\ncounter to it comes along.” A Secret Service agent standing next to the\nvehicle opened the heavy door of the Beast. You cannot really open it from\ninside.\n\nThe President kept going, warming to his theme. “And right now, the problem is\nthat the new offensive technologies have taken to the field and they now have\nthe advantage over the things that we have to defend against them. So, what we\nhave to do is invest in new technologies that will give the defense the\nadvantage again, or at least even out the playing field. Have I got it right?”\n\nClarke looked at the President, bemused, reminded again about the\npreternatural ability he had to make the complex comprehensible. Clarke put\naway his copy of the draft speech and the PowerPoint deck, sighed, and said,\n“Yeah, Mr. President, you should say that today.” And he did.\n\nNineteen years and three months later, Clinton said the same thing verbatim in\nanswering a question about his cyber-oriented novel while sitting on stage in\nWashington’s Warner Theatre. It was still true. In the intervening twenty\nyears, hundreds of billions of dollars in public and private investment in\ncybersecurity research, development, and deployment had not fundamentally\nchanged the advantage. It remains a case of what military theorists call\noffensive advantage or offensive preference.\n\n### Offensive Preference in Cyberspace\n\nAny scenario between adversaries is a balance between offense and defense.\nWhen the offense has the advantage because of some combination of\ntechnological superiority or cost, military theorists write, there will be\nconflict. When the reverse is true, when it costs more to attack, or when the\nchances of an attack defeating the defenses is low, greater stability will\nprevail. We think these generalities apply now to the ongoing hostilities\nbetween hackers and corporations, to the current covert espionage done by\nnation-states, and to the potential for a future nation-state-on-nation-state\ncyber war. Today, as for the last twenty-five years, the conventional wisdom\nin the fields of computer science, information technology, and networking is\nthat there is an enormous offensive preference. That might not have been a big\ndeal to most people, except that in the last twenty-five years, we have also\nmade almost everything dependent upon computer networks. In fact, because the\noffense is thought to have the advantage right now, in a crisis situation of\npossible conventional warfare, there is likely to be an inclination to go\nfirst with a cyberattack.\n\nThis book is about how the balance between offense and defense is changing and\nhow the rate of change can be increased to set us on the path to stability. We\nthink it is possible to reduce the risks posed by offensive cyber technologies\nand actors, and to increase peacetime stability for corporations and crisis\nstability for nations.\n\nAs we write this in 2019, we see a pattern of malicious activity in cyberspace\nthat suggests we are already engaged in a low-grade, simmering cyber conflict\nwith Russia, China, and Iran. We also are beginning to turn a corner on this\nproblem. Estimates put worldwide cybersecurity spending at $114 billion in\n2018. Venture capital investment in cybersecurity technology is up, topping $5\nbillion in 2018 alone. More than three thousand new technology firms have\nsprung up, backed by ample venture capital, to develop new solutions. Cyber\ninsurance was long a fringe product. Today, the market is (finally) growing\nand thriving, with almost $2 billion in premiums written in 2017.\n\nLong-standing problems created by government, such as barriers to information\nsharing, have been solved and companies are actually beginning to organize\ncommunities not only to share information, but also to provide mutual aid\nduring crises. One chief information security officer (CISO) at a major bank\nwe spoke with thinks that in five years his bank will largely be immune to\ncyberattacks as it upgrades from legacy systems that are inherently insecure\nto systems that are secure by design. Many leaders in Silicon Valley, where\noptimism is never in short supply, would tend to agree.\n\nToday, if you are a small-business owner, you can conduct most of your work\nonline and do so with the support of cloud service providers that have\ndedicated thousands of people and billions of dollars to protecting your data.\nAutomation and artificial intelligence have the potential to erase much of the\nattacker’s advantage. Yet, at the same time, attackers are looking at how they\ncan use these tools as well. Quantum computing could provide both impossible-\nto-break protection for data and the ability to crack all current forms of\nencryption. Blockchain, which many technologists think could lead to\nfundamentally more secure protection of data, has for the time being found its\nbiggest use in cryptocurrency, a technology that is decidedly giving an\nadvantage to attackers by allowing criminals to move their ill-gotten gains\naround anonymously. These technology trends could shift the balance in either\ndirection. It is up to us to determine which way the scales will tip.\n\nThe Pentagon has long identified four primary domains of conflict: land, sea,\nair, and space. In recent years, cyberspace has come to be known as the “fifth\ndomain.” Unlike the others, cyberspace is man-made. It can therefore be\nchanged by man. It is a positive attribute of cyberspace that once a weapon\nhas been used and discovered it can be blocked. That is the equivalent of\nchanging the atmosphere so that bombs can no longer fall.\n\nWe have been working together on the cyber problem for fifteen years. We both\nconsult for major corporations, cybersecurity companies, and venture-capital\nand private-equity firms. We have both been adjunct faculty members teaching\ngraduate students about cybersecurity. And, for our sins, we have both spent\ntime in government agencies, Dick Clarke in the Defense Department and State\nDepartment, Rob Knake in Homeland Security. The best parts of our government\nexperiences, however, were in the White House, on the National Security\nCouncil staff. Dick served on the George H. W. Bush (41), Bill Clinton (42),\nand George W. Bush (43) staffs. Rob served on the Obama staff (44).\n\nWhile in the White House, we both had the opportunity to author decision\ndocuments (executive orders, presidential directives) on cybersecurity. Dick\nalso drafted the first national strategy on cybersecurity that any nation ever\npublished. So, yes, you can blame us in part for some of the mess, but we\nthink we also have some unique perspectives. Between us we have spent more\nthan four decades closely following the evolution of the cyber threat and the\ngovernment and corporate response. Ten years ago, when we wrote the book\n_Cyber War: The Next Threat to National Security and What to Do About It,_ our\ngoal was to raise the alarm. We knew the seriousness with which cyber threats\nwere taken in Washington, but didn’t see the same level of concern in the\nprivate sector. Unfortunately, much of what we wrote about cyber threats\nturned out to be right, but things have also changed a lot since then,\nincluding our prescriptions.\n\nWhen we wrote _Cyber War,_ Silicon Valley, still stuck in its “Don’t Be Evil”\nphase, wouldn’t accept that its inventions had the potential to cause real\nharm. Our intention was to scare government and corporate leaders into\naddressing the threat before the prospect of cyber war turned into a real\ncyber war. In the intervening decade, far too little has happened to respond\nto the threat, while many of our predictions on the emergence of war in\ncyberspace have regrettably come to be true. Yet cybersecurity remains a\nsolvable problem, one far less difficult to address than a host of others,\nlike climate change, that we face today.\n\nWe have full faith that, in time, we will find workable solutions to the\nproblems that plague cyberspace today through an ugly and disruptive process\nof trial and error. Eventually, businesses will come around to recognizing the\nvalue they get from being globally connected and will start investing\nappropriately to secure that value. Eventually, governments will figure out\ntheir roles and begin to help the private sector help itself.\n\nBut unless we are smart and proactive, we will solve the challenges we face in\ncyberspace only after multiple crises. After cyberattacks cause blackouts in\nthe United States, we will make the necessary investments to prevent them.\nAfter train derailments, ship collisions, or airplane crashes caused by\nmalicious actors operating in cyberspace kill people, we will build systems\nthat have near-zero tolerance for failures caused by hackers.\n\nThe danger is that, after events like these, we won’t just do the hard work of\nmaking our systems resilient to cyberattacks. Blood will need to be answered\nwith blood. We think it safe to conclude that the next major war the United\nStates enters will be provoked by a cyberattack. That provocation may be\naccidental. It may be intentional. But the United States does not have a good\nrecord of turning the other cheek. And so as we think about what needs to be\ndone to improve cybersecurity, our fundamental goal is to achieve cyber peace\nso that we do not end up embroiled in more devastating and costly wars in the\nreal world.\n\nOur collective understanding of these problems as a community of practitioners\nhas grown immensely in recent years. We now have a clear view of the many\nproblems that make cyberspace an attractive domain for war-fighters, and of\nhow we could make it less attractive. As we developed the concept for this\nbook, we kept coming back to the realization that the specter of cyber warfare\ndoes not overshadow all the good things that are made possible by the\ninternet. The speed and connectivity that enable cyber warfare also enable\nemail, social media, Amazon Prime, and massive multiplayer games. While some\nmight question whether these applications represent positive outcomes for\nsociety, this global network has allowed collaboration and communication that\nwas undreamed of a few decades ago and has been the driving force behind\nmassive increases in productivity and wealth creation.\n\nBy some estimates, the digital economy, separate and apart from the\ntraditional economy, is growing at three times the rate of the rest of the\neconomy. But as the global consulting firm McKinsey points out, it’s\nincreasingly difficult to separate the digital economy from the rest, as every\ncompany today is wired up. McKinsey estimates that fully 98 percent of the\neconomy is being impacted by digitization. It is no coincidence then that the\ncompanies thriving today are the ones that have taken cybersecurity seriously.\nIn 2018, we saw the first real hits to companies’ bottom lines from\ncyberattacks. The NotPetya malware took billions from companies operating in\nUkraine, Europe, and the United States, leading many to report the losses on\ntheir quarterly and annual filings with the Securities and Exchange\nCommission. Yet some, if not most, multinational corporations operating in\nUkraine either were not impacted, were minimally impacted, or had some really\ngood lawyers who argued the losses did not need to be reported (more on that\nlater).\n\nCompanies such as Microsoft, Apple, and Google, all companies that at one time\nsaw concerns over cyber threats as overhyped, now have religion and are\ninvesting in cybersecurity with the zealotry of the converted. They view\ncybersecurity as a competitive advantage in a market where consumers are\nincreasingly wary of doing business online. Large banks such as Citi, Bank of\nAmerica, and JPMorgan Chase also view cybersecurity as a competitive\ndifferentiator for both consumer and commercial clients.\n\nThe near daily press reports of new incidents and the constant stream of\nnotifications that your personal information has been stolen have created the\nimpression that cyberspace is hopelessly insecure. Yet hiding in plain sight\nare many examples of companies with big targets on their backs that have been\nable to constantly defeat even the best nation-state offensive teams year in\nand year out. While these companies have massive security teams and budgets in\nthe hundreds of millions of dollars, their innovations, many borrowed from the\nmilitary, are slowly making their way to the wider market.\n\nThe offensive advantage in cyberspace is slowly shifting as the defense closes\nthe gap by taking advantage of new technologies, becomes better organized, and\nbegins to understand the value of what is at stake. Accelerating that shift is\none of the central requirements for achieving something more like peace and\nless like war in cyberspace.\n\nCyber warfare must become both more difficult and costlier to carry out. Cyber\ncriminals, who act as proxies for nation-states as well as cause significant\nharm with their moneymaking schemes, must have their numbers culled. The\nbarriers to entry for engaging in malicious activity in cyberspace have been\ngoing down steadily, year over year. They must be brought back up.\n\nMany who have looked at the specter of cyber war have called for drastic\naction. “Reinvent the internet” to make it more secure is an often-heard\nrefrain, but no one has yet come up with a plan for how to do that without\ncausing more economic and social harm than the bad actors could do on their\nworst days. Even sillier are the calls for a “cyber Manhattan Project” or\n“cyber moon shot.” These demands for a massive national effort always lack the\nsame thing: a clear goal.\n\nThe Manhattan Project of the 1940s took developing theories of physics, as\nlaid out in a succinct letter from Albert Einstein to President Franklin\nRoosevelt, and set out an engineering challenge to translate them into an\natomic weapon. Kennedy’s goal of the “moon shot” was even clearer: get to the\nmoon. Cyber war has no such neat solution, because achieving peace in\ncyberspace is not a question of solving an engineering problem or reaching a\nspecific location.\n\nSome of the challenges blocking the way to cyber peace are technical, but\nmost, at their heart, are economic. With the right package of economic\nincentives, the technical problems can be solved. So, while this book will\ndive into the 1s and 0s to explain the challenge, most of the solutions will\nbe about how to make markets and governments work in the interest of promoting\nsecurity. Above all, our guiding principle is to avoid solutions that would\ncause more disruption than the problems they are meant to solve. In\ncyberspace, this appears to be an easy trap.\n\nThe worst example of this tendency came at the end of the Obama\nadministration, when officials at the Department of Justice proposed that\ncompanies should weaken encryption to make digital information readily\naccessible to law enforcement and also, therefore, to criminals. They failed,\nbut many similar ideas are still being put on the table. When things go wrong\nin cyberspace, such ideas are likely to be introduced and reintroduced and\nwill eventually be implemented if we do not, as a community, develop\ncompelling alternatives.\n\nAbove all, as we seek solutions in this space, we are looking for rapid\nevolution, not revolution. We think there are enough companies that have\nfigured out how to manage the threat that the challenge now is to create the\nright package of incentives to spread these models and to innovate faster than\nattackers can. As the cyberpunk author William Gibson said, “The future is\nalready here; it’s just not very evenly distributed.” In a sense, therefore,\nthe task at hand is to figure out how to more evenly distribute a secure cyber\nfuture.\n\n### A Different Threat, a Different Model\n\nAs we looked for solutions to problems that have long plagued cyberspace, what\nhas not changed is our fundamental premise that cybersecurity is a shared\nresponsibility between government and the private sector, with the onus for\nprotecting computer systems falling on the owners and operators of those\nsystems. Dick first made the concept of a “public-private partnership” for\ncybersecurity official U.S. policy with Presidential Decision Directive 63\n(PDD 63, for those in the know) in 1998. That directive also put in place many\nof the building blocks for realizing this vision that we still rely on today,\nsuch as information sharing and analysis centers (ISACs). Since then, across\nthe Bush, Obama, and Trump administrations, specific policies have been\nrescinded and rewritten, but the overall thrust of U.S. cyber policy has\nremained largely unchanged. This degree of continuity across twenty years and\nfour presidential administrations would be remarkable in any other area of\npublic policy. At a time when Republicans and Democrats are sharply divided\nover climate change, immigration policy, and tax policy (to name a few), it is\neven more remarkable.\n\nSince the Clinton administration, our cyber strategy has changed very little\ndespite many attempts to come up with a different one. Thus, when we consider\nhow to secure privately owned and operated networks, we return to the basic\nidea that the companies that own and operate the internet and the things that\nare connected to it, be they multinational media companies, providers of\nessential services, or the makers of the tiniest IoT devices, will be\nresponsible for protecting themselves. They will do it through network\ndefense, not offense.\n\nGovernment’s role will be limited, to support the private victims of\ncyberattacks with law enforcement, information sharing, diplomacy, and, in the\nrare cases where it is both feasible and in the national security interest,\nmilitary force. Government will also play a role in helping the private sector\nhelp itself, through nudges to encourage investment and cooperation in\ncybersecurity; through research, training, convening; and, ultimately, through\nregulation.\n\nDespite twenty years of continuity on this policy, this division of\nresponsibility is often derided in corporate America. Many CEOs are\nincredulous that they are responsible for defending their companies against\nforeign adversaries of the United States. “That’s what I pay taxes for,”\nechoes out of every boardroom. Leaders in national security often have the\nsame view, believing that it is the responsibility of the U.S. military to\ndefend the nation in cyberspace. They want to equate cyberattacks to nuclear\nmissiles, and argue that it must be the government’s role to stop these\nattacks.\n\nThe idea that government should find some magic way to make this problem go\naway and let us go about our business online is compelling to many. It’s also\ndeeply flawed. The cyber domain is fundamentally different from the air\ndomain, as are the threats that lurk within it. Making cybersecurity the\nmilitary’s responsibility would require rearchitecting the internet to give\ndefense agencies the necessary choke points to try to filter out hostile\nthreats. Doing so would require also granting them unlimited access to the\ncontent of traffic, a spy’s dream and a privacy advocate’s nightmare. Such an\napproach would likely still fail, and fail while incurring massive costs with\ntremendous societal disruption.\n\nWhen cyberattacks do occur, every CEO would like to view it as a national\nsecurity crisis, shift responsibility to government, and have the military\n“fire off the missiles.” The desire to counterpunch is understandable, but\nfoolhardy. Thus far, the U.S. government has shown remarkable restraint,\navoiding engaging in reckless counterstrikes that would broaden conflicts.\nWhether that restraint will hold we do not know, but we are fairly certain\nthat the utility of such strikes will be low.\n\nAttribution (determining who is behind an attack) is a recurring challenge in\nresponding to such attacks. Advanced threat actors have learned how to keep\ntheir computer systems hidden and are able to quickly replace any lost\nresources with other, likely stolen, computing resources, or make it appear as\nif another group altogether were responsible for an attack. Thus,\ncounteroffense is at best like firing a cruise missile into an empty tent, and\nat worst like firing a cruise missile into a civilian apartment complex. And\nof course, along with relying more on the military, we must also take a dim\nview of vigilantism in cyberspace, and hope that we will soon see the\nDepartment of Justice indict someone for so-called hacking back.\n\nLate in the Obama administration, the government finally got out of the\nbusiness of operating the last government-managed portion of internet\ninfrastructure, the Domain Name System. With that function now firmly\nimplanted in the private, nonprofit Internet Corporation for Assigned Names\nand Numbers (ICANN), the federal government has finally completed the\ninternet’s thirty-year transition from a science experiment at DARPA (the\nDefense Department’s Advanced Research Projects Agency) to a wholly commercial\nventure. We spent thirty years getting the government out of operating the\ninternet; we would not want security to be the reason we let the government\nback in.\n\nWhat that leaves us with is the approach we have advocated all along: building\nsystems so that most attacks cause no harm, and that allow us to respond to\nand recover from attacks that do succeed, with minimal to no disruption. We\nhave adopted a different way to talk about this concept: cyber resilience. We\nalso have ideas to share on how it can be implemented.\n\n### Cyber Resilience\n\nThe best strategies can be summed up with a single word. In the Cold War, we\nhad two such strategies: containment and deterrence. George Kennan’s famous\n“long telegram” took a few thousand words to spell out the strategy of\ncontainment, of keeping the Soviet sphere of influence limited. Thousands of\npapers and books would ultimately be written on deterrence in the nuclear era\n(and rewritten for the cyber era), but those single-word strategies clued\neveryone in to the basic ideas. Once set out in the 1940s, they held for\nalmost fifty years with very little variation as times and presidential\nadministrations changed.\n\nThroughout this book, we will come back many times to the theme of working to\nshift the advantage from the attacker to the defender. This effort should be\nthe overall goal of our national policy, and that of like-minded countries and\ncompanies. It’s the right idea, but the language of offense-defense theory too\nreadily suggests that cybersecurity is just another problem, such as terrorism\nor nuclear threats, that the military will deal with.\n\nThe reality of the internet as we know and love it today does not lend itself\ncompletely to traditional national security approaches. One of the guiding\nlessons we kept in mind while writing this book was the need to look for\nsolutions by analogy that were not drawn from the world of warfare. This may\nseem rich, coming from the guys whose last book was titled _Cyber War,_ but we\nbelieve that if the goal we want to achieve is cyber peace, then we should be\nlooking at solutions to problems outside the fifth domain or any of the other\nfour. If we try to find allegories in the Barbary pirates, or the battle of\nFallujah, or the response to 9/11, we will no doubt find them, but they will\nlead us to one type of solution. Instead, throughout this book we have looked\nto other areas of study, such as ecology, public health, emergency management,\nand even psychology. As we have done that, one central theme continued to\nemerge: resilience. At the corporate level, many leaders are recognizing that\ntheir enterprise cybersecurity strategies need to be built around resilience.\nThey must try to prevent every incident they can, but respond and recover\nrapidly when prevention fails. In his book _Digital Resilience_ , RedSeal CEO\nRay Rothrock identifies the concept of resilience as “a winning strategy in a\nlosing war,” arguing that the threat from cyber actors has made resilience\n“table stakes for any enterprise interested in survival.” Yet while the\ncorporate world is starting to embrace resilience, many in Washington provide\nonly lip service to the concept. Programs and budgets suggest cyber policy is\nstuck in a war-fighting mentality.\n\nIf you do a keyword search on cybersecurity strategies from the last few\nadministrations, you will no doubt find the word “resilience” buried somewhere\nin the document. But the idea has never been embraced as the central goal of\nour strategy. It has always been an ill-defined and vague concept. Ultimately,\nwhat we want is to be able to ignore cyberattacks, to be able to slough them\noff and continue on with our business rather than being forced to escalate.\nBecause we insist on finding Cold War parallels, the cyber community often\ntalks about this concept as “deterrence by denial,” the idea that we want to\nmake our defenses so good that adversaries will not even try to attack, and if\nthey do attack, it won’t be of consequence. We’d propose a slight shift. We\nwant to make our defenses so good, and our architectures so strong, that we do\nnot care about whether we are being attacked most of the time because the\nattacks have no serious effects.\n\nCyber resilience must be built upon, rather than be seen as a replacement for\nsound security fundamentals. When confidentiality, integrity, and availability\nare compromised, resilience is about the ability to rapidly respond, return to\na good state, manage bad outcomes, and learn from the incident so that future\nincidents are less likely. Here, it is important to note that thinking of\n“resilience” as the ability to recover to a previous state or to bounce back\nis too limiting. For resilience to be a useful concept in the field of\ncybersecurity, it requires that the concept fully embody the idea of returning\nstronger or better than before.\n\nIn the field of psychology, where the concept of resilience has been more\nfully developed than in any of the other fields that use the term, there is a\nbuilt-in acknowledgment that resilience is not about returning to a previous\nstate after an individual experiences trauma, but about adapting to that\ntrauma. After the death of a spouse or parent or a child, after the loss of a\nlimb or the trauma of war, overcoming these experiences does not mean\nforgetting them or getting back to the way you were before the experience. No\none could.\n\nApplying this psychological reality to the physical world, Judith Rodin, a\npsychologist by training and the former head of the Rockefeller Foundation,\nformulates a definition that works equally well for coping with cyber threats\nas it does for, say, building resilient cities. Rodin defines resilience as\nthe capacity of any “entity . . . to prepare for disruptions, to recover from\nshocks and stresses, and to adapt and grow from a disruptive experience.” We\nthink that definition transfers aptly to the cyber world.\n\nIn the next chapter, we provide a reminder of the threat and the damage that\ncan be done. Then we look at corporations and the progress some of them are\nmaking at safeguarding their networks. We examine the potential for improved\npublic-private partnerships and the role of regulation. We ask what the\ngovernment and the military should do, and we examine the role of the\ninternational community. Because cyberspace is ever changing, we then discuss\nthe new technologies and what they could mean for the offense-defense\nstruggle. Finally, we have some suggestions about what you should do at home\nto secure your corner of cyberspace.\n\nThroughout the book, we will try to show that we have a choice to make about\nthe future we want in cyberspace. In the chapters that follow, we will sketch\nout why raising the alarm on cyber threats is warranted, and will lay out a\nplan for how the worst outcomes can be avoided. There are two futures we can\nchoose from. It is up to us to decide which one we want cyberspace to become.\n\n\n## Chapter 2\n\n## ETERNALBLUE, ETERNAL WAR\n\nThe Russian military launched the most destructive and costly cyberattack in\nhistory. . . . This was also a reckless and indiscriminate cyberattack that\nwill be met with international consequences.\n\n—STATEMENT FROM THE PRESS SECRETARY OF THE WHITE HOUSE, FEBRUARY 2018\n\nLorina Nash rushed her mother to the emergency room at Lister Hospital in\nStevenage, England. The doctors said they needed tests to diagnose the\nproblem. They gave Nash’s mother a blood test, but then the computers crashed\nand they could not complete the analysis. The doctors put the sample in the\nhands of a courier and sent him on a three-hour trip to a clinic whose\ncomputers were still working. Lorina and her mom waited in what became a\nlargely empty ER, as most patients were sent away.\n\nAmbulances racing to Essex Hospital were redirected elsewhere, as the Accident\nand Emergency department there had also stopped accepting patients. At North\nHampshire Hospital, the CT and X-ray machines froze. Colchester Hospital\ncanceled twenty-five operations. At Chesterfield Royal Hospital the problem\nwas the reverse: without functioning computers, patients could not be released\nand had to spend another night in the hospital. It was May 12, 2017, and the\nBritish National Health Service had been hit by a ransomware cyberattack that\nwas shutting down businesses all over Europe and North America, locking down\ncomputers and demanding payment in Bitcoin to unlock them.\n\nThe attack tool used became known as WannaCry, and seven months later the\nAustralian, British, and American governments identified the culprit as one of\nthe North Korean government’s hacking groups, sometimes called the Lazarus\nGroup by Western analysts. While WannaCry captured the media’s attention in\nthe United States and many other countries, the events in May were only a\nprelude to a much more devastating attack a month later by another state\nactor. Indeed, what was to come was the most devastating single cyberattack in\nhistory, so far costing companies more than $20 billion and, more importantly,\nshutting down key infrastructure.\n\nWhile WannaCry got the public’s attention, corporate and government IT\nsecurity professionals had already been aware of the growing risk of\nransomware. A year earlier, a virus known as Petya (named after a Soviet\nweapon in a James Bond movie) had demonstrated significant success in\nattacking Windows-based systems and then spreading encryption throughout the\ninfected network. Analysis of Petya by U.S. cybersecurity firms later revealed\nthat it employed an attack technique based on the National Security Agency’s\nEternalBlue weapon.\n\nThen in late June 2017, malware resembling Petya spread with unprecedented\nspeed around the world, attacking Microsoft servers and then jumping to all\nconnected devices on the affected corporate networks. In major companies\nseemingly selected at random, and at their facilities in scores of nations,\ncomputer screens froze and flashed messages demanding payment. It looked like\nransomware again. It wasn’t.\n\nOnce analysts realized it was not the Petya attack again, they creatively\nlabeled the new attack NotPetya. What cybersecurity experts quickly surmised\nwas that the demand for ransom was fake, a diversion. The attacking software\nwas actually what was known as a wiper, which erased all software on the\ninfected devices. Any device connected on an infected network would be wiped:\ndesktops, laptops, data storage servers, routers, IP phones, mobile phones,\ntablets, printers.\n\nOperations at major global corporations suddenly ground to a halt. At the\npharmaceutical firm Merck, which made more than $40 billion in revenue in 2017\nand employed more than sixty thousand workers, production lines froze.\nDistribution of vaccinations, oncology drugs, and hundreds of other\npharmaceuticals stopped. Later, the company would claim the damages cost them\nalmost $900 million.\n\nMaersk, a container ship and port giant, suddenly could not operate the cranes\nthat move millions of shipping containers at its megaports around the world,\nincluding New York and New Jersey, Los Angeles, and Rotterdam. Moreover, it\nhad no idea where any given container was, what was in any container, or where\nany container was supposed to go. Later, the company would publicly own up to\n$300 million in damages, but a company insider told us that when opportunity\ncosts were accounted for, the true loss was triple that number.\n\nHundreds of corporations, some in almost every sector, were frozen, including\nthe logistics firm TNT Express (a subsidiary of FedEx), Mondelēz, the snack\ncompany, and the DLA Piper law firm. If there had been any doubt that a\ncyberattack could be global in an instant, that it could disable physical\nsystems, or that it could affect the machinery that keeps the global economy\nmoving, that doubt evaporated on June 27, 2017. Was it cyber war?\n\n### A Cyber War by Any Other Name\n\nWhether NotPetya was an act of cyber war depends, of course, on your\ndefinition. Upon examination, NotPetya was an operation run by a military\nunit, specifically the Main Directorate of the General Staff of the Russian\nFederation’s military, often called the GRU or Russian military intelligence.\n(In the funny-name-game world of cyber wonks, the GRU’s hacking team is also\nknown as Fancy Bear.)\n\nThe Russian military did not, we suspect, intend to indiscriminately attack\nglobal corporations. What it had intended was a crippling attack on Ukraine on\nthe eve of its national holiday, Constitution Day. The GRU had figured out a\ntruly creative attack vector, a channel that could be used to spread an\nattack.\n\nWhat the GRU had noticed was that almost every company and government ministry\nin Ukraine used the same accounting software. Think of the prevalence of\nQuickBooks in the United States and you will get the picture. Only in Ukraine,\nthe equivalent software was known as M.E.Doc, from the Ukrainian software\ncompany the Linkos Group. Like every other similar application, the M.E.Doc\nprogram was periodically updated. Updates were pushed out to licensed users\nfrom a server at Linkos. The updates were digitally signed by Linkos and\nrecognized by users’ firewalls, thus allowing the M.E.Doc updates to pass\nfreely into corporate networks.\n\nSo the GRU hacked into Linkos and planted a little something extra in the next\nupdate to M.E.Doc: an attack package that exploited a known vulnerability in\nMicrosoft server software, combined with a password-hacking tool and\ninstructions to spread to any connected device on the network, wiping them of\nall software.\n\nThe GRU attack worked almost flawlessly, destroying about 10 percent of all\ndevices in Ukraine, including some in every government ministry, more than\ntwenty financial institutions, and at least four hospitals. _Almost_\nflawlessly. What the GRU had apparently not recognized (or maybe they did) was\nthat global companies operating in Ukraine would also be hit, and from their\nUkrainian offices the attack would spread over virtual private networks (VPNs)\nand rented corporate fiber connections back to corporate headquarters in\nEngland, Denmark, the United States, and elsewhere.\n\nThis kind of mistaken collateral damage is not unique to NotPetya or to the\nGRU. The software used in the so-called Stuxnet attack on the Iranian nuclear\nenrichment plant reportedly carried out by the United States in 2010 somehow\ngot out into the world, even though the Natanz plant was not connected to the\ninternet or any other network. Stuxnet quickly spread around the globe, was\ncaptured by cybersecurity teams in many countries, and was decompiled, with\nparts of it later reused in new attack tools.\n\nStuxnet, however, did not damage anything outside of Natanz, because it was\nwritten in a way that the only thing it could hurt was the Iranian nuclear\nenrichment processor. Nonetheless, the fact that the software spread way\nbeyond its target was reportedly one of the motivations for President Obama’s\nsubsequent directive, Presidential Policy Directive 20, which allegedly\nrestricted further offensive use of cyber tools without his personal approval.\n(President Trump is reported to have removed those restrictions in 2018.)\n\nStuxnet revealed to the world, or at least to anyone who cared enough to\nbother to grab a copy, one of the most sophisticated attack tools ever,\ncontaining more than fifty thousand lines of computer code including numerous\ntricks never used before (so-called zero-day exploits). NotPetya revealed not\na thing about Russian GRU attack tools. It exposed nothing of theirs because\nit was not their tool. It was America’s.\n\n### Using Our Weapons Against Us\n\nAn obscure, important, and contentious debate among cybersecurity experts\nconcerns whether it’s the responsibility of the U.S. government to tell\nsoftware developers (say, Microsoft) when NSA hackers find a mistake in the\ncompany’s code that would permit someone to do something new and malicious,\nsuch as hack in and copy customer data, steal money, or wipe out all the\nsoftware on a network. In the parlance of U.S. government cyber-policy makers,\nthis debate is called the “equities issue” because it involves balancing the\ninterests of intelligence agencies trying to attack with the concerns of\ngovernment departments such as Treasury and Homeland Security that have an\ninterest in more secure corporate networks.\n\nIf the government tells the software developer, then the company issues a\n“patch” that can fix the problem. If the government does not tell them, then\nit can hack into interesting foreign networks using the vulnerability in order\nto learn things to protect the country. (The government creates an “exploit,”\na hacking tool that takes advantage of the poorly written computer code.)\n\nAfter Edward Snowden stole sensitive NSA information and gave it to WikiLeaks\n(and the Russians), Obama appointed a five-man group to investigate and make\nrecommendations. Dick Clarke was one of the group that became known as the\nFive Guys, after the Washington hamburger chain.\n\nThe Five Guys’ recommendations were all made public, every single word of\nthem, by the Obama White House. One of those recommendations was that when the\nNSA finds a hole in widely used software, it should tell the manufacturer,\nwith rare exceptions. Those exceptions would be approved at a high level in\nthe government and should be valid for only a finite period. The Obama\nadministration accepted that recommendation.\n\nMicrosoft has charged that the NSA knew about a big problem with Microsoft’s\nserver software for five years and did not tell them. Instead, the NSA\ndeveloped an attack tool, or zero-day exploit, and called it EternalBlue.\nPresumably, the NSA used EternalBlue to get into foreign networks. Only in\nMarch 2017 did Microsoft, having just been informed of its software’s\ndeficiencies by the U.S. government, issue a patch for the problem.\n\nAs is always the case when a software company issues a patch, not every one of\nits users gets the message or believes the warning that it is a critical patch\nthat has to be installed right away. So, despite the patch, the North Korean\nauthors of WannaCry were successful in using the vulnerability two months\nlater, in May 2017, and the Russian GRU used it again, in combination with\nother tricks, in creating the June 2017 NotPetya disaster.\n\nThose devastating attacks would almost certainly have been avoided if the U.S.\ngovernment had told Microsoft years earlier. At least, that is what Microsoft\nsaid publicly after it figured out what happened.\n\nWhy did the government finally tell Microsoft? Our guess, and it is just that,\nis that by March 2016 the government had figured out that Russia had stolen\nthe U.S. attack kit, knew about the zero day, and was using it or was about to\nuse it.\n\nIt is possible that the Russian GRU stole the zero-day attack tool from the\nUnited States in 2016, or perhaps even as early as 2013. We do know that\nanother contractor assigned to the NSA, Harold Martin, was apparently walking\nout of NSA facilities with highly classified papers and software on a regular\nbasis, according to the charges brought against him by the Justice Department\nafter the FBI arrested him in 2016.\n\nMartin used antivirus software to defend his personal home computer;\nspecifically, he used Kaspersky Anti-Virus. Kaspersky, which is widely used\naround the world, is made in Russia. According to press reports, the Russian\nGRU gained access to Kaspersky’s Moscow headquarters and then used the\nmillions of Kaspersky Anti-Virus packages installed on computers around the\nworld to search for documents with certain keywords. (Kaspersky denies that\nthis is what happened.)\n\nMaybe the GRU learned those keywords, which may have been Top Secret\nExceptionally Controlled Information code names, from the Edward Snowden\ntreasure trove. In any event, one possibility is that, using a backdoor in\nKaspersky Anti-Virus on Harold Martin’s home computer, the Russian GRU found a\nton of NSA attack tools, perhaps including the EternalBlue exploit.\n\nNow, how would anybody know that the Russian GRU did that? Well, it just could\nbe that Israel’s military intelligence Unit 8200 was sitting inside\nKaspersky’s network watching it all go down. The Israelis would have told the\nNSA pretty quickly if that happened. It is also possible that the Russian GRU\nhacked a secret server outside of the NSA that was used to store attack tools,\na so-called staging server, in the autumn of 2013. Maybe that was how they got\nthe NSA’s crown jewels.\n\nHowever they got them, they got them. We know that because they posted them\nonline for all the world to see, and use, in the summer of 2016. Posing as the\nfictional hacker group known as the Shadow Brokers, the Russian GRU started to\ndole out the NSA’s attack tools publicly. It’s true that they did not call\nthem the NSA’s tools, opting instead to call them property of the “Equation\nGroup,” but the NSA PowerPoint slides were kind of a giveaway as to who the\nEquation Group really was. The Shadow Brokers went on to offer to sell some of\nthe Equation Group’s better tricks. The tricks all seemed to date from 2013,\nwhich may give credence to the staging server attack as the source of the\nNSA’s attack tools.\n\nThe NSA is not the only U.S. government organization engaged in cyberattacks.\nThe Pentagon’s Cyber Command is too, as is the CIA. We know a lot more about\nwhat the CIA does now because, like the NSA, it also had a major theft and\npublic exposure of its cyber secrets. In the case of the CIA, however, there\nis little doubt about how the secrets were taken or by whom.\n\nJoshua Schulte, a CIA employee, was arrested by the FBI in August 2017 and\ncharged with passing over eight thousand pages of highly classified\ninformation to Julian Assange, who subsequently posted them publicly on the\nWikiLeaks website. Assange, an Australian who had taken refuge in Ecuador’s\nLondon embassy, has been accused by numerous American authorities of acting in\ncooperation with Russian intelligence.\n\nThe CIA documents were called Vault 7 by WikiLeaks, and they too revealed\nnumerous zero-day exploits of widely used software, including products of\nApple, Microsoft, and Samsung (e.g., allegedly a tool to listen to rooms in\nwhich Samsung televisions were installed, even when the television appeared to\nbe turned off). When the documents became public, Microsoft president Brad\nSmith complained that no one in the U.S. government had told them about the\nvulnerabilities.\n\nAt least one other U.S.-based company had, however, been noticing some of the\nalleged Vault 7 exploits. For at least six years, cybersecurity company\nSymantec had been reporting on attacks by a group it named Longhorn. Attack\ntechniques used by Longhorn in more than sixteen countries reportedly match\nalmost exactly in technical detail some of what was revealed in the Vault 7\ndocuments. If that is true, then the CIA might have been exploiting flaws in\nU.S.-manufactured software for years without telling the companies involved.\n\nWikiLeaks, which is not the most credible source of impartial information,\nalleged that the Vault 7 documents showed the existence of a CIA program code-\nnamed UMBRAGE. This program supposedly involved the CIA using attack tools\nthat it had stolen from other governments in order to leave a misleading trail\nand cause investigators to believe attacks done by the CIA were, in fact, done\nby others.\n\nBy 2018, the outing of one another’s cyber tools and personnel was picking up\nspeed. An anonymous group calling itself Intrusion Truth began to regularly\ndisclose the hacks, tools, and people involved in Chinese hacking groups known\nas APT 3 and APT 10. It is not yet generally agreed upon among the cyber-\nexpert community who Intrusion Truth is, but it is clear that they are\nrevealing the secret activity of the Chinese government.\n\nWhat does all of this tell us? First, stealing one another’s attack tools may\nbe more widely practiced than was previously thought, and may be done by at\nleast a few nations.\n\nA second obvious observation from these incidents is that the security of U.S.\ncyberattack units is still miserably poor years after a frustrated President\nissued an Executive Order (EO 13587) and other instructions to fix it. Most of\nthe theft of U.S. attack tools could have been prevented by simple physical\nsecurity procedures.\n\nThird, we should not conclude that the Russian GRU _has_ to steal U.S. attack\ntools. They have plenty of good ones they have developed themselves. Their\nmotive in stealing and publicly releasing the U.S. cyber arsenal is to\nembarrass the United States, make it seem like America is the world’s most\nproblematic hacker, and allow nations (including our friends and allies) to go\nback and identify U.S. intelligence operations against them (thereby creating\ndistrust among allies).\n\nFinally, there is obviously a great deal of hostile activity by the militaries\nof various nations going on in cyberspace. All of this might not constitute\nwar according to the traditional definition, but it is fairly clear by now\nthat the United States and its allies have been regularly attacked by the\nRussian military using cyber weapons. The Russian military has not only used\ncyber weapons to collect intelligence, but has also deployed cyber weapons to\ndamage, disrupt, and destroy physical objects in the real world, beyond the\nrealm of 1s and 0s. And the Russians are not the only ones. To quote the\nBritish Foreign Office, the Russians are simply the most “reckless and\nindiscriminate.”\n\nRussia’s GRU successfully penetrated the Pentagon’s classified intranet, as\nwell as the State Department and White House systems. According to the United\nKingdom’s National Cybersecurity Center in October 2018, the GRU has engaged\nin a sustained campaign of low-level cyber war for several years, going back\nat least to its 2007 attack on Estonia and its 2008 attack on the nation of\nGeorgia.\n\nAccording to the U.K., the GRU, operating under the false flag name of\nSandworm, attacked the Ukrainian power grid in 2015 and again in 2016.\nOperating under the false flag name of Cyber Caliphate (sounds like an Arab\nterrorist group, right?), it shut down a French television network, TV5Monde.\nIt attempted to interfere through cyberattacks in the investigations of the\nRussian assassination attempt in Bristol, England, Russian doping of Olympic\nathletes, and the Russian downing of Malaysia Airlines Flight 17.\n\nFamously, the Russian GRU penetrated the Democratic National Committee (which\nadmittedly required little skill) as one part of a multifaceted campaign to\naffect the outcome of the U.S. presidential election. And of course, there was\nthe most damaging cyberattack in history to date, NotPetya, about which the\nWhite House issued a rare public statement of attribution regarding a\ncyberattack.\n\nIn one operation in the Netherlands, GRU hackers were arrested in the parking\nlot of the international organization that investigates chemical weapons use,\nattempting to hack into the wi-fi. According to Dutch police, the Russian\nmilitary personnel were in possession of taxi receipts from GRU headquarters\nto Moscow airport, thus proving that business expenses are the bane of every\norganization, even cyber-war units.\n\nWhether or not you call all of that activity cyber war, it is objectively a\nlot of damage being done by a military organization. Much of it fits the\ndefinition we suggested in _Cyber War_ in 2010 (damage, disruption, and\ndestruction of physical objects caused by a nation-state-created cyberattack).\nBack then there were commentators and critics who thought such predictions\nwere hyperbolic. By now, however, it seems generally accepted that this kind\nof warfare can happen. Indeed, U.S. Director of National Intelligence Dan\nCoats publicly stated that the Russian government had penetrated the control\nsystems of some U.S. electric power companies, that we were in a period\nsimilar to the months before 9/11, and that “the warning lights are blinking\nred.”\n\nThe Russian GRU’s teams such as Unit 26165 and Unit 74455 are not the only\nmilitary organizations running around cyberspace breaking things. The Chinese\nPeople’s Liberation Army (PLA) teams such as Unit 61398 and Unit 61486 have\npenetrated thousands of networks in the United States and tens of thousands\naround the world. Although President Obama and President Xi signed an\nagreement to limit cyberattacks on each other for commercial purposes (about\nwhich more later), Chinese penetrations of U.S. organizations continue.\n\nSimilarly, North Korea’s Bureau 121 and Unit 180 have helped to finance the\ndevelopment of missiles and nuclear weapons with their criminal theft\nactivities around the world, including against the SWIFT international\nfinancial transfer system. North Korea has also attacked infrastructure and\nbusinesses in South Korea, including banks and television networks. The global\nattack that was WannaCry demonstrated the havoc that the North Koreans can\nwreak.\n\nIran’s military, through its Revolutionary Guard Command (IRGC) and its\nMinistry of Intelligence, have also been damaging and disrupting in\ncyberspace. For weeks in 2012 the online banking systems of the eight largest\nU.S. banks were shut down by an Iranian attack, which the Justice Department\nlater charged was directed by the IRGC. Iran penetrated the U.S. Navy Marine\nCorps Intranet and defied U.S. efforts to evict them for more than two years.\nIranian units took control of networks running systems as diverse as a water\nsystem dam in New York State and the Sands Casino in Las Vegas.\n\nIran’s destructive efforts also include the 2012 attack on the Saudi oil\ncompany Aramco, which wiped software off thousands of machines, and the 2017\npenetration of the Triconex safety-instrumented system of a petrochemical\nplant in Saudi Arabia, an attack apparently intended to prevent alarms going\noff during a planned lethal chemical leak in the future.\n\nAnd then there is the United States, where in September 2018 the President\ndevolved authority to conduct cyberattacks to the Department of Defense and\ninstructed the military to “defend forward” to disrupt other nations’ cyber\nactivities. We will discuss that more in chapter 12.\n\n### Naming Cyber Warriors\n\nOne way in which the U.S. government has decided to respond to these\ncyberattacks by foreign militaries has been to “name and shame.” At the risk\nof compromising what are called sources and methods, U.S. intelligence\nagencies have permitted Justice Department lawyers to name, show photographs\nof, and issue arrest warrants for individuals in foreign military cyber units\ninvolved in attacks inside the United States. This U.S. tactic is intended to\ndemonstrate the extent of the problem, to give the appearance of doing\nsomething about it, and in rare instances to make it possible to arrest and\ninterrogate the military personnel involved. We found no U.S. government or\nformer U.S. government official who thought it would deter further attacks.\n\nAmong those military personnel indicted in U.S. courts is Park Jin Hyok of the\nNorth Korean Reconnaissance General Bureau. From the People’s Liberation Army,\nHuang Zhenyu was publicly accused and an arrest order was issued for him,\namong others. GRU officer Dmitriy Sergeyevich Badin is among a host of Russian\nmilitary officials now sought by international law-enforcement agencies on a\nwarrant from the United States. Ehsan Mohammadi is among the Iranians named by\nthe U.S. Justice Department as having hacked American organizations on behalf\nof the Iranian government.\n\nThough it has historically been challenging to apprehend foreign hackers\nbecause of their ability to conduct cyber operations from their own soil, some\nof the named military hackers have actually been arrested. Yanjun Xu of the\nPLA was arrested on a trip to Belgium. Alexei Morenets of the GRU was picked\nup by Dutch counterintelligence police in that parking lot in the Netherlands.\n\nWe have to leave it to your imagination how the United States knows the true\nnames of these and many other foreign cyber military officers, how it obtained\ntheir pictures, and how it knows that they were involved in specific attacks.\nWhile you ponder that, keep in mind that the important thing here is that\nthese are foreign military officers charged with attacking things in the\nUnited States.\n\n### Instability in Cyberspace Risks Escalation\n\nAll of this activity by Russia, China, North Korea, Iran, and, yes, the United\nStates is suggestive of a dangerous pattern of crisis instability. Most\nsignificant hacking used to be done by non-state actors, individuals, or\nclubs. Now, major attacks are usually the work of some nation’s military.\n\nNations are regularly using their militaries not only to steal secrets, but to\ndamage, disrupt, and destroy sensitive systems inside potential enemy nations.\nSuch operations could easily lead to escalation into broader war,\nintentionally or unintentionally. The U.S. military, for example, has said\nthat it reserves the right to respond to cyberattacks with any weapon in its\narsenal.\n\nTo be clear, the recent and current levels, pace, and scope of disruptive\nactivity in cyberspace by the military units of several nations is\nunprecedented, dangerous, and unsustainable in “peacetime.” It cannot continue\nlike this. Either we control and deescalate tensions, or conditions will cease\nto have any resemblance to peacetime.\n\nIf we do not take concerted steps to reduce the risk of cyber war, if we do\nnot engage in a multifaceted program to bring us closer to cyber peace, we\nrisk highly destructive cyberattacks that could cripple modern societies and\nescalate into the kind of Great Power conflict we have not seen in more than\nseventy-five years. Thus, we need to make it a major national priority to find\nways of defeating nation-state hackers. Some companies may already know how.\n\nThere are two lessons we could draw from the NotPetya attack on Ukraine. The\nfirst is that nation-state military and intelligence organizations are already\ntaking down major global companies such as Maersk and Merck with cyberattacks.\nThe second lesson, however, is the dog that did not bark. There were other\nU.S. and global companies in Ukraine during the NotPetya attack, companies\nsuch as Hyatt Hotels, Abbott Laboratories, Boeing, DowDupont, Eli Lilly,\nJohnson & Johnson, Cargill, Pfizer, Delta Air Lines, and John Deere. They do\nnot appear to have been significantly damaged by NotPetya. We turn to what\nkeeps some companies comparatively more secure in the next section.\n\n\n# PART II\n\n# THE CORPORATE FRONTLINE\n\n\n## Chapter 3\n\n## TWO KINDS OF COMPANIES?\n\nIf we have data, let’s look at data. If all we have are opinions, let’s go\nwith mine.\n\n—JIM BARKSDALE, FORMER CEO, NETSCAPE\n\nThere are two kinds of companies: those that have been hacked and know it; and\nthose that have been hacked and don’t.” It’s become a staple of keynotes at\nsecurity conferences, the CISO version of the aristocrats joke. Everyone has a\nvariation of the line, but its originator is Dmitri Alperovitch. Now the chief\ntechnology officer and cofounder of CrowdStrike, Alperovitch raised the alarm\nabout nation-state threats when he was at McAfee, one of the largest antivirus\ncompanies. Alperovitch wrote some of the earliest reports on Chinese and\nRussian intrusion sets, uncovering the widespread penetration into American\ncompanies by foreign groups. Now, Alperovitch is no longer so sure that\nadvanced persistent threat, or APT, actors are unstoppable.\n\nWhen the Obama administration concluded its protracted negotiations with\nChina’s President Xi over economic espionage in 2015, the Chinese premier\npledged to bring an end to the targeting of U.S. companies by his government’s\nspy agencies. Very quickly, CrowdStrike observed that China’s cyber spies had\nnot changed their ways. But instead of reporting that the Chinese had stolen\ndata, CrowdStrike made clear that they had detected the attacks and thwarted\nthem. “Seven of the companies are firms in the Technology or Pharmaceuticals\nsectors, where the primary benefit of the intrusions seems clearly aligned to\nfacilitate theft of intellectual property and trade secrets, rather than to\nconduct traditional national-security-related intelligence collection which\nthe Cyber agreement does not prohibit,” Alperovitch wrote on the company blog.\n\nIt was an important contribution to the debate at the time on the\neffectiveness of the agreement. It was also a bit of a humble-brag.\nAlperovitch and his cofounder George Kurtz did not shy away from the fact that\nthey had handled the onslaught from China’s most advanced offensive groups.\nWhen we asked Alperovitch whether he stood by his “two kinds of companies”\nline, he had a short answer: no.\n\nOf course, Alperovitch is selling something. In June 2018, CrowdStrike\nannounced it had raised another $200 million at a $3 billion valuation. The\ncompany will likely go public by the end of 2019. So what Alperovitch is\nselling, companies are buying. And what he is selling is a platform for rapid\ndetection and containment as well as follow-on incident response services.\nIt’s tempting to joke that Alperovitch is now saying that there are three\nkinds of companies: those that have been hacked and know it; those that have\nbeen hacked and don’t know it; and those that buy CrowdStrike. That would be\nunfair to Alperovitch, who sees his company as only one piece of a much larger\nsolution, and one with many noble competitors, including Dragos, Cylance,\nFireEye, and others in the field.\n\nAlperovitch should be happy. Business is booming at CrowdStrike. Yet he is\nfrustrated. What frustrates him isn’t that his technology can’t find a market.\nIt clearly has. He’s frustrated because he believes more companies that could\nbe secure are not. He has strong evidence that companies following a model of\nrapid detection and containment are able to stifle adversaries, keeping them\nfrom achieving their goals. Those goals may be to steal intellectual property\nor commit fraud or hold a company’s computers for ransom, but they are not, he\npoints out, simply to gain access to the network. That is only one step in a\nlong chain of events that adversaries need to string together to achieve their\ngoal (something we will explore more fully in chapter 4). And doing that\nagainst a prepared and determined company is harder than many might think.\n\n### Is the Offense Really That Easy?\n\n“I just don’t buy that offense has an advantage,” says Dave Aitel. Aitel\nshould know. For his entire career, starting at age eighteen at the NSA, he\nhas been on the offense. After six years at the NSA he joined the legendary\ncybersecurity firm @stake, and then went on to found Immunity, a company that\nbuilds hacking tools for penetration testers and government clients. He sold\nit to the cybersecurity and data center firm Cyxtera in 2018 for an\nundisclosed sum.\n\nWhen Aitel worked at the NSA he was one of the last breed of full-spectrum\nhackers, meaning that he developed exploits, deployed them, and ran them\nagainst nation-states’ most sophisticated targets. He had a habit of working\nodd hours, coming in after everyone had left and working until the morning.\nOne time, Aitel got caught up in whatever he was doing and forgot to leave\nbefore the rest of the workforce arrived. A disgruntled General Michael\nHayden, then the NSA director, arrived to find Aitel’s car parked in his\nreserved spot.\n\nAitel possesses many fine qualities, but humility is not one of them. So the\nfact that he does not exhibit the typical hacker bravado should cause a moment\nof pause. “For the nation-state offense,” he says, “you put such a premium on\nnot getting caught that you really don’t have a huge advantage.” The work he\nhas done throughout his career is painstaking and deliberate. While signals\nmay pass between computers at light speed, for the attacker, moving from\nreconnaissance through to achieving his objective can take months. And today,\nthe attacker’s job has only gotten harder.\n\nWhen he began his career, the only threats that security tools could detect\nwere those they had seen before and knew were bad. These “blacklist”\ntechnologies, like legacy antivirus programs, would scan files against\nsignatures of known bad files and block them. Avoiding these technologies\ncould be as simple as making a single change to the file so that it no longer\nmatched the bad file.\n\nNow, Aitel is worried that the superweapons of his craft are increasingly\ngetting discovered. As we’ve seen, a zero day is a vulnerability that is not\nknown to defenders and therefore has yet to be patched. Aitel, from an\noffensive perspective, is concerned that security firms are actually finding\nzero day attacks with increasing regularity, to the point that detection of\nzero days is becoming commoditized. “Microsoft’s Advanced Threat Detection,\nCrowdStrike, Kaspersky, the new FireEye stuff, all that stuff actually works\nand that is a huge change,” Aitel says. Thinking from an attacker’s\nperspective, he is not happy about it.\n\nIt’s getting harder to find vulnerabilities in new systems and even harder to\nexploit them. Modern trusted systems can actually be trusted. Your iPhone, a\nubiquitous commercial device, is far better defended than a state-of-the-art\nsystem from Aitel’s early days on the offense. Even the latest version of the\nlong-maligned Microsoft Windows operating system is pretty secure.\n\nBetter detection and less accessible targets mean that by default, in Aitel’s\nview, defenders now have the advantage. Of course, many companies forgo that\nadvantage by underinvesting in IT in the first place and failing to continue\nto invest in keeping it secure. “The offense works super hard and they have a\nmission and they have metrics and they know when they win and they lose,” says\nAitel, whereas many companies on the defensive simply don’t value protecting\ntheir assets as much as the offense values stealing them (or destroying them).\n\nNow at a company that makes money defending systems, Aitel wonders how his old\nemployer is going to be able to continue to meet mission demands for\nintelligence as security gets better. “Offensively,” he says, “we aren’t\nplanning for the future.” He has been a significant opponent of Obama-era\nrules requiring the intelligence community to disclose vulnerabilities in\nwhat’s known as the Vulnerabilities Equities Process (the VEP). “The theory of\nthe VEP is that you don’t need a huge stockpile of vulnerabilities. But\nimagine if every zero day you used only worked twice. That’s the world we are\nmoving to.” For Aitel and his former employer, that is a tough world to live\nin. For the rest of us, it may mean that we have already started to erode the\noffensive advantage.\n\nWhen we wrote _Cyber War_ in 2009, we quoted a senior intelligence official\nwho told us point-blank that his teams at the NSA carried out an undisclosed\nnumber of missions every month and never got caught. That was then. Only\nmonths after _Cyber War_ was published, the cybersecurity community, and soon\nafter the general public, began to learn about Stuxnet, the highly\nsophisticated malware attack on Iran’s nuclear centrifuges. Like Stuxnet,\nother campaigns and malware groups have also been solidly pinned to the NSA.\nIn the case of Longhorn, not only had the group been caught in the act, but\nSymantec had traced its campaign across forty targets in fifteen countries.\nWhat many suspected was seemingly confirmed in stolen U.S. government files\nreleased by WikiLeaks. Thus, if in a ten-year period the best in the business\nwithin Fort Meade and the CIA have gone from acting with impunity in\ncyberspace to getting caught with near ironclad attribution, it suggests to us\nthat the offensive advantage has eroded and will continue to.\n\nAs we’ve noted, NotPetya was a devastating attack to FedEx, DLA Piper,\nMondelēz, Maersk, and Merck, among others, but many international businesses\nactive in Ukraine either were not hit or maintained operations through the\nattack and were not forced to disclose any losses. Ukraine is a global center\nfor outsourced IT operations. Samsung, Oracle, Boeing, Ericsson, and Siemens,\nto name a few, have research and development centers in Ukraine. Microsoft,\nwhose exchange server was the vector of the attack, has offices there. And yet\nthese companies continued to hum along despite attacks that crippled other\ncompanies doing business there. The CISO of one U.S.-based global company told\nus how his team not only stopped NotPetya from spreading beyond their Kiev\nfacility, they quickly identified its origin and shared that information with\nother companies. How did they do it? “Simple. We patched when we were told to\nand we segment our network.”\n\nThis is not to say that cyber defense is easy or cheap. Indeed, the cost of\ndefense is still many times the cost of offense. Those who disagree with that\nlook at the likely cost of designing the Stuxnet weapon used by the United\nStates to attack the Natanz facility in Iran. We concede, without knowing the\ndetails of that classified program, that it was probably ridiculously\nexpensive to execute that attack. The goals of most hackers, however, are more\nlimited and far more easily and inexpensively achieved.\n\nIf a hacker’s goal is to steal information, hold a company’s data hostage for\npayment (ransomware), permanently delete all the software from the devices on\na network (wiper), or flood a network to the point where it cannot operate (a\ndistributed denial-of-service attack, or DDoS), the cost of such an attack\nagainst a poorly defended network is shockingly low. Indeed, there are\nwebsites on the so-called dark web where hackers sell those attack tools.\nRemote access tools (RATs) can sell for as little as five hundred dollars. A\nkit to engage in ransomware could be available for a thousand dollars. These\ntools will likely not get you into the network of Bank of America or Citibank,\nbut most networks are less well defended than they are. When public\nannouncements are made by software companies or cyber-defense experts about\nthe need for specific steps to block newly discovered attack techniques, most\ncompanies do not rush out and patch their vulnerabilities. It is just too\ncostly, too demanding. Thus, attack kits based on vulnerabilities that have\nbeen known for years still work on many targets.\n\nSo imagine that you are trying to find a way into a network to steal\ninformation or money. You could try all the existing hacking tools for a few\nthousand dollars. Probably that would not work on a smart firm that has fixed\nall the known vulnerabilities. As the attacker, perhaps you move on to employ\na zero-day hacking tool developed or bought for a few hundred thousand\ndollars. Let’s say five hundred thousand. Now, you might get in.\n\nOn the defensive side, a bank is spending a thousand times the cost of the\nhalf-million-dollar attack tool. Each major U.S. bank spends more than half a\nbillion dollars on cyber defense every year. Arrayed against the cyber-\ncriminal gang’s hacker-tool-development team, there are more than several\nhundred bank and contractor employees defending the network. The attackers are\nusing one piece of software, maybe with several embedded tool kits to help\nfind and extract data they seek. The bank is using upwards of five or six\ndozen different, layered software tools developed by almost as many different\ncybersecurity vendors to detect and prevent the attack.\n\nImagine this contest as an ancient battlefield. Then, there might have been\nequally sized and equipped armies on either side of the field, each with a\nhundred thousand troops, cavalry and catapults, spears and shields. When they\nclashed, thousands on both sides would die. Today in cyberspace there would be\na small professional team with one or two attack tools on one side of the\nfield against many times that number of defenders with dozens of variations of\nshields and nets on the defensive side. The defenders will usually not attack,\nbecause they can’t. If they are corporations, by law they are not allowed to.\n\nIf the attackers fail, they do not die, they move on to the next victim, and\nthey keep going until they get in somewhere and steal data, take money, or\nstop the company from working. Like a hockey goalie, cyber defenders can lose\nthe game if one puck gets by them. Instead of there being the thirty shots on\ngoal in a two-hour hockey game, there are hundreds of thousands of attempted\nshots on a major corporate or government network every day.\n\nAnd if somehow the defenders figuratively rip off the attacker’s helmets and\nsee their faces, even identify who the attackers are, often nothing happens.\nToday, the sophisticated attackers are well masked, but if they are\nidentified, they often have little to fear because they are operating remotely\nfrom a country that will not cooperate with law-enforcement requests from the\nUnited States or Western European countries. This contributes to the\n“cybersecurity is hopeless” outlook that we so desperately need to combat.\n\nUltimately, a bank isn’t spending half a billion dollars to keep out one\nattacker. It’s spending half a billion dollars to protect many trillions of\nassets from more than two hundred advanced persistent threat groups. By one\nestimate, there are seventy-seven Chinese APT groups alone. And, more\nimportantly, getting into the network isn’t the goal. Getting information out\nor transferring funds or destroying computer resources is, and the companies\nthat are good at cyber defense are amassing an impressive record of denying\neven the best cyber adversaries these outcomes.\n\n### What the Data Says\n\nIt’s a somewhat odd predicament that in a field based on 1s and 0s, data is\noften hard to come by. Most companies that have been hacked don’t have to\ndisclose it. And, as Alperovitch points out, many don’t even know it. What’s\nmore, companies that have a solid basis for believing they have succeeded in\nthwarting their adversaries don’t exactly want to stand up and shout it. No\nCISO wants to invite the wrath of hacking groups who might just pursue them\nfor showing hubris (the things some groups do just for the “lulz,” or laughs\nin hackerspeak, are mind boggling). But some sectors of the economy are forced\nto disclose breaches of sensitive information. And when that sensitive\ninformation appears on the dark web, law enforcement often comes knocking.\nThat means that an ostrichlike approach of sticking your head in the sand when\ndanger approaches, not looking for data thieves, and hoping no one knows you\nwere attacked won’t always work.\n\nIf you have been paying any attention to cybersecurity news over the last five\nyears, you might conclude that every major health-care provider was hit by a\nChinese attack and lost their subscriber database. When health-care providers\nlose data on the people in their health plans, they are required to notify\ntheir customers and report to the Department of Health and Human Services. In\nturn, HHS helpfully reports it on their website.\n\nTodd Inskeep, a longtime fixture in the cybersecurity community, decided to\ndig through the reports to find out what they showed. Now a consultant at Booz\nAllen Hamilton, Inskeep is often called in to be an interim CISO at companies\nafter they have been hacked and have fired their full-time CISO. Inskeep is\nfirmly convinced that most breaches are preventable. Oftentimes, the mistakes\ncompanies make that let attackers in are painfully obvious, at least after the\nfact. But many in the community will contend that if attackers are thwarted on\none attack path, they will simply find another and eventually win. Inskeep\nthinks the data tells a different story.\n\nWhen Inskeep and other researchers at Booz Allen looked at that data, what\nthey found suggests that many of the largest health-insurance companies have\ndone a pretty good job at keeping their customer data safe. While Anthem, the\nsecond-largest health insurer in the country, lost all of its subscriber data\nin 2015, some 78 million records, over the last five years the companies in\nthe number one and number three positions in the market did not. Those\ncompanies, United Health and Aetna, respectively, lost a total of 12,000\nrecords to cyber incidents. United Health, in fact, lost zero (though the\ncompany did report a small number of losses of files that had gone missing).\nFour of the remaining top ten health-care companies also reported zero losses\nto cyber theft. The three companies that round out the top ten reported a\ntotal of 37,000 lost records out of the 28 million records those companies\nhold.\n\nIs it possible that these companies had major losses that neither they, nor\nlaw enforcement, nor the cybersecurity ecosystem discovered? Maybe. Is it\npossible that they simply weren’t targeted? Unlikely. A health-care record\nfetches a pretty high premium on the dark web because it lets criminals commit\ninsurance fraud, a highly lucrative enterprise. And so, the more likely answer\nis that these companies, motivated by a financial incentive not to have fraud\ncommitted against them using the information they store, have actually been\nable to manage the threat. And given the scrutiny health care has received and\nthe intelligence assets placed against discovering Chinese intrusions, it is\nalso unlikely that these companies were hit by state actors that managed to\nkeep their thievery from being discovered.\n\nWe reached out to several of these companies to gain their perspective on the\nissue. Jim Routh, the longtime chief security officer at Aetna (now part of\nCVS Health, where he retains the same role), agreed to talk. Like most people\nin the field, Routh understandably does not want to incur the wrath of the\ncyber gods by proclaiming that his company hasn’t been hacked, but he does\nagree that it is a reasonable conclusion one could draw based on the available\ndata.\n\nThere is an old saw in cybersecurity that being in the field is like being\nchased by a bear. You don’t need to outrun the bear, you just need to outrun\nthe other companies in the field (so that the bear will eat them). Aetna’s\napproach to outrunning the bear (proverbial or Russian) is to focus on\ninnovation. Routh has one of the best records among CISOs and is constantly\ninnovating to keep it. Aetna goes well beyond the requirements passed down to\nit by government agencies or its customers, rapidly creating controls that are\nnot part of regulatory requirements or even part of voluntary frameworks. They\ntrack threat actors, study their tactics, techniques, and procedures, and work\nto understand the criminal ecosystem that supports them.\n\nWhile Aetna has a pretty good record, Routh isn’t about to give up and go home\nif an APT actor gets past him. Routh’s goal is to achieve resilience, that is,\nto keep a security incident from undoing his company, halting production, or\nundoing its reputation. “Resiliency isn’t about avoiding a breach, it’s about\npreventing bad outcomes,” Routh says. Yet so far, he seems to have avoided a\nbreach.\n\nTo do that, Routh and his team are constantly changing the attack surface and\nmodifying the environment so that even if attackers get in they can never be\nsure of their footing on the network and can never rest, knowing that they\nwill be able to maintain access. Aetna deploys upwards of six hundred\ndifferent controls, and changes which ones are deployed every day. They have\nthree hundred machine-learning models running across nine platforms to control\ntheir security. They do red teaming (attacking their own network to test for\nsecurity problems) every quarter. Authorization decisions on Aetna’s network\nare made by a centralized machine-learning program that takes into account\nsixty different attributes before granting access. If it all sounds\ncomplicated, it is. “I teach a class for our auditors on how to test the\nmathematical efficacy of our controls,” Routh says. “When I talk about\ncontinuous, behavioral-based authentication, regulators think it is voodoo.”\n\nOf course, it’s not voodoo. And it’s not luck. And of course, Aetna isn’t the\nonly company that is doing it. Beyond the health-care industry, it’s possible\nto find many other examples of companies for which there is no public\ninformation to suggest that they have been breached. That may mean that they\nhave pretty solid security programs, but it also may mean that they have even\nbetter lawyers. Under U.S. federal laws, only health-care records currently\nhave a mandate that losses be disclosed to the individual record holders and\nmade public. Disclosure of other types of personal data are required by laws\nin all fifty states, but these laws are limited to credit cards, Social\nSecurity numbers, and other personally identifiable information.\n\nLarge swaths of malicious activity are never disclosed or counted, from simple\naccount compromise to the theft of intellectual property that undergirds our\neconomy. That’s because such disclosures are required for public companies\nonly if they are judged (by the company) to be a “material risk” under vague\nguidelines issued by the Securities and Exchange Commission. In our analysis\nof public information on cybersecurity incidents, we found that less than a\nmajority of the companies that make up the _Fortune_ 500 had reported any\nsignificant cybersecurity incidents in the last decade. That means that the\nmajority of the companies with the biggest bull’s-eyes on their backs have\neither succeeded in keeping the adversaries at bay or convinced their lawyers\nthat whatever was taken did not merit a disclosure.\n\nFor a small number of companies on that list, we have full faith that they\nhave invested sufficiently and smartly to manage the risk and protect their\nmost valuable assets. For others, we know for a fact that they have lost their\ncrown jewels. Unfortunately, that knowledge is protected by classification\nrules that prevent us from publicly naming companies that the U.S.\nintelligence community has identified as victims of China’s multiyear effort\nto steal our nation’s most valuable secrets.\n\nIt is difficult to square the fact that in 2013 (the last year numbers were\nreleased) the FBI and other federal agencies made more than three thousand\nnotifications to U.S. companies that they had been breached with the\nrelatively small number that have copped to it publicly. Keith Alexander, the\nformer director of the NSA and the first commander of Cyber Command, has\ncalled China’s intellectual property theft “the greatest transfer of wealth in\nhistory.” While we agree with that assessment, looking at the data on\ncompanies that have actually disclosed when they have been hacked does not add\nup to an honest picture of the losses we have sustained.\n\nGiven this reality, any list of companies that have been hacked is going to be\nimperfect, and identifying companies that haven’t is even more difficult. Yet\nwe think there is solid evidence that some companies are effectively managing\nongoing campaigns carried out by the most advanced and persistent actors.\nBattling those actors takes advanced skills and equal persistence on the part\nof defenders. It requires using threat intelligence and tracking actors inside\nnetworks. It requires building out a cooperative community to create a global\ndetection grid of adversary behavior. But most companies aren’t being attacked\nby APT actors. For large swaths of the economy, “good enough” cybersecurity is\na relatively straightforward proposition.\n\n### Getting the Basics Right\n\nJames Mickens is one of the funnier people ever to work in cybersecurity. A\ncomputer scientist by training, Mickens did a stint publishing off-the-wall\ncommentary on cybersecurity issues until leaving Microsoft for a teaching\nposition at Harvard. Describing himself as “like a petty, sarcastic version of\nNeil deGrasse Tyson,” Mickens explained the universe of computer science to\nhis readers. In one of his pieces that has become part of the folklore of\ncybersecurity, “This World of Ours,” Mickens explains how to think about cyber\nthreats. “Basically, you are either dealing with Mossad or not-Mossad,” writes\nMickens, referring to Israel’s much vaunted intelligence agency. “If your\nadversary is not-Mossad, then you’ll probably be fine if you pick a good\npassword and don’t respond to emails from ChEaPestPAiNPi11s@virus-\nbasket.biz.ru.” If it is Mossad, on the other hand, Mickens would like you to\nunderstand that “YOU’RE GONNA DIE AND THERE’S NOTHING THAT YOU CAN DO ABOUT\nIT,” because if Mossad or another APT actor is coming after you, they aren’t\ngoing to stop until they get what they want.\n\nOn both ends, Mickens is exaggerating for effect, but, as with much satire,\nthere is a kernel of truth. In chapter 18, we will talk about what individuals\nneed to do to protect themselves online: it is a bit more involved than just\nusing a good password, but it is possible. On the other end of the spectrum,\nwe will discuss in chapter 4 what companies that are consistently defeating\neven the most advanced adversaries are doing. We maintain it is possible. In\nthe middle, of course, between practicing good personal cyber hygiene and\nthreat hunting for adversaries inside your network, is where most companies\nneed to be.\n\nIn 2011, the Obama administration put out a broad legislative proposal to\nregulate cybersecurity in critical sectors. After Congress refused to pass it,\nthanks to lobbying by an implacable U.S. Chamber of Commerce, the White House\ncyber team began to think about how they could nudge companies to invest more,\nand more intelligently, in cybersecurity without requiring them to do so. The\nidea was simple. If you can’t regulate, the next best thing is for government\nto simply put out voluntary standards and urge companies to meet them. And so\nthe National Institute of Standards and Technology (NIST, pronounced like\n“mist”) Cybersecurity Framework was born.\n\nThe framework takes the immensely complicated task of securing an enterprise\nand breaks it down into manageable chunks. Everything a company needs to do to\nprotect itself fits into one of five core “functions”: Identify, Protect,\nDetect, Respond, and Recover. These functions provide a basic lexicon that\neveryone in the company from the board to the coding team can understand. Each\nfunction is further broken down into categories that cover high-level\nactivities such as asset management in the Identify function; data security in\nthe Protect function; continuous security monitoring in the Detect function;\nbreach planning in the Respond function; and communications in the Recover\nfunction.\n\nEach category is broken further into subcategories that specify a desired\noutcome. For instance, under the Identify function, the first subcategory\nunder Asset Management is “Physical devices and systems within the\norganization are inventoried.” The subcategories are then referenced against\nexisting standards documents such as the Center for Internet Security’s\nCritical Security Controls, or NIST’s own technical guides, known as the 800\nseries of special publications.\n\nCritics of the framework will, somewhat justifiably, note that its list of\nfive functions, twenty-two categories, and ninety-one subcategories, which\ntie, in turn, to hundreds of detailed technical controls, doesn’t provide a\nready starting point for companies that do not know where to begin. The team\nthat developed it at NIST would argue that companies need to understand their\nown risk and risk appetite, and then develop their own security profile by\nselecting what security controls are appropriate for their desired level of\nrisk. One thing NIST has made clear is that the framework was never meant to\nbe a checklist. But for those companies that are looking for a simple list,\nthere is good data to point the way.\n\nEvery year Verizon’s cybersecurity division puts out its Data Breach\nInvestigations Report, the VDBIR in acronymland. The VDBIR brings a much-\nneeded dose of data to the opinion-driven, everybody-is-an-expert world we\nlive in. When Inskeep looked at last year’s report, some basic facts jumped\nout at him. He saw clearly that most attacks involved weak or stolen\npasswords—81 percent, according to the VDBIR. So he put strong passwords or,\nbetter yet, multifactor authentication at the top of a list of five things\nmost companies should do. If guessing a password or finding a stolen password\nwouldn’t get an adversary in, the data suggested to Inskeep that attackers\nnext went to spear phishing.\n\nSymantec’s Internet Security Threat Report concluded that 71 percent of\norganized groups, the really advanced nation-state and hacker-for-hire groups,\nrelied on email to initiate their attacks. Data in the VDBIR agreed, showing\nthat 66 percent of malware was delivered in email attachments. So Inskeep\nlooked at how to address that. He proposed two controls: one set of technical\ncontrols like email filtering, and one set of controls focused on employee\ntraining.\n\nKnowing that adversaries would not give up and take their hacking skills\nelsewhere if he blocked credential theft and spear phishing, Inskeep next\nlooked to protect systems that could be remotely exploited. Instead of trying\nto protect everything, he thinks companies need to focus on where adversaries\nwill go to gain access if they are thwarted on the two most common pathways.\nLocking down, monitoring, and patching vulnerabilities in internet-facing\nsystems would pay real dividends.\n\nFinally, if you can’t keep an adversary out of your systems, you want to keep\nthem from moving across your network. Inskeep found convincing data from\nCrowdStrike that showed that most adversaries used known vulnerabilities to\nallow them to move laterally within a network. Finding these vulnerabilities\nand patching them should, therefore, be a priority. So he made it fifth on his\nlist.\n\nWill doing these things stop Mossad or, more importantly, the Russians and the\nChinese? No. There is a reason the acronym APT has caught on to describe them.\nAdvanced persistent threats are, if anything, persistent. But it will\ncertainly make their job harder. No group is going to waste a zero-day exploit\nif they can use Metasploit, an open-source penetration-testing tool, to gain\naccess to your network. Forcing them to burn a zero day is in the interests of\nboth individual companies and the defense community at large because it\nincreases the cost of the attack.\n\nDenying the easy attacks means there will be fewer attacks overall. If newbie\ncriminal hackers can’t gain a foothold by successfully carrying out easy\nattacks, they may never develop advanced skills. This kind of basic cyber\nhygiene isn’t necessarily easy or cheap, and it doesn’t mean that companies\nwon’t need to invest in detecting and response, but it will cut down on the\nnumber of adversaries that can make it into company networks and will increase\nthe work factor for those that do. But fundamentally shifting the balance\ntoward defenders requires finding technical and other innovations that give\ndefenders a decisive advantage.\n\nIn the next chapter, we look at how the best companies in the industry combat\nthe threats that good cyber hygiene will never be able to stop.\n\n\n## Chapter 4\n\n## THE KILL CHAIN\n\nIf some animals are good at hunting and others are suitable for hunting, then\nthe gods must clearly smile on hunting.\n\n—ARISTOTLE\n\nPossibly the greatest innovation in cybersecurity over the last decade wasn’t\na technology but a white paper. “Intelligence-Driven Computer Network Defense\nInformed by Analysis of Adversary Campaigns and Intrusion Kill Chains” was\nwritten by Eric Hutchins, Michael Cloppert, and Rohan Amin, a group of\nresearchers at Lockheed Martin, the large defense industrial base (DIB)\ncompany. The paper was released in 2011 with little fanfare at an obscure\nconference, the International Conference on Information Warfare. “This wasn’t\nBlack Hat or RSA,” says Amin, now the CISO at JPMorgan Chase. “We had no idea\nthat it would take off the way it did.” But take off it did, launching\nnumerous imitators and dozens of companies, which have built technologies to\nhelp their customers find, fix, and finish adversaries inside their networks.\n\nWe sat down with Amin in his office at JPMorgan headquarters in a skyscraper\nhigh above Park Avenue. The building was remodeled in 2011 to give it a West\nCoast, tech-friendly feel, complete with coffee bars (two), coworking desks\n(many), meeting and phone pods, as well as LEED certification for responsible\nenvironmental construction. If the image of someone who works at JPMorgan\nconjures up a Brooks Brothers suit and a Hermès tie, you would be disappointed\nto find that jeans outnumbered slacks by two to one. The reality for JPMorgan,\nlike every other global bank headquartered in Midtown or in the Financial\nDistrict, is that the venerable old bank is now a tech company that lends and\ninvests money. That means they need an office environment that will attract\nthe tech talent like Amin that the bank needs and have had to slacken the\ndress code accordingly.\n\nFive years into his stint at JPMorgan, Amin already outlasted most CISOs in\nthe field. Of course, Amin is far younger than most of his peers, part of a\nnew breed of CISOs who, unlike an older generation that came into\ncybersecurity through IT, law, the military, or law enforcement, have spent\ntheir entire careers in the field.\n\nAmin began working at Lockheed in 2002, right after graduating from the\nUniversity of Pennsylvania with a BS in computer and telecommunications\nengineering and an MS in telecommunications and networking. Working at\nLockheed, a company that’s consistently under threat from the most skilled\nnation-state actors, gave him early exposure to what we now call advanced\npersistent threats. “In the early 2000s, people were still in the ‘worms and\nviruses’ state of mind, automated threats that were indiscriminate,” says\nAmin. “But we were seeing focused adversaries with hands on keyboards, a\nperson whose job it is to steal our info.”\n\nA few years in, Amin and others on Lockheed Martin’s computer incident\nresponse team (CIRT) began to develop the kill-chain process. “We were seeing\na whole bunch of Chinese intrusion sets targeting the DIB and we were tired of\nthis victim mentality, woe-is-us, nothing-we-can-do, defeatist attitude.”\nBuilt into that victim mentality was the idea that the attackers had the\nadvantage. Amin and his team were looking for a way to flip that around.\n\nAmin and his colleagues took inspiration from the Air Force, which coined the\nterm “kill chain” to break down the process from locating a target to putting\na bomb on it: find, fix, track, target, engage, assess. In applying the\nconcept to cybersecurity, the Lockheed CIRT wanted to disrupt the\neffectiveness and efficiency of their adversaries in cyberspace. “We also were\nexposed to thinking from JIEDDO,” says Amin, referring to the Joint Improvised\nExplosive Device Defeat Organization, a mid-2000s effort to deal with the\nthreat from roadside bombs in Iraq and Afghanistan.\n\nIn building out the kill chain, the Lockheed team began with the same phases\nthat JIEDDO used to break down the stages of a terrorist’s building, placing,\nand detonating a roadside bomb: reconnaissance, weaponization, and delivery,\neverything “left of boom.” They replaced “detonation” (the boom) with\n“exploitation,” the stage where an attacker gains initial access, having\ndefeated perimeter security protections.\n\nStages of the kill chain\n\n![](../images/Art01_Final.jpg)\n\nMany cyber practitioners would see the failure to stop exploitation as a\nvictory for the attackers, but the Lockheed team viewed it as the point at\nwhich the attackers were on their home terrain. To the right of exploitation,\nthey capture three more phases: installation, command and control (C2 in the\ndiagram above), and actions on objectives, the things an adversary needed to\ndo to actually get what they wanted, whether that was to steal intellectual\nproperty or to destroy the network.\n\nThe paper the Lockheed team wrote turns the idea that offense has the\nadvantage over defenders on its head. What the writers suggested was that\nattackers needed to string together an intricate series of events to achieve\ntheir objective. Defenders, on the other hand, only had to detect and stop\nthem at any one of several possible stages. This kind of thinking proved to be\nrevolutionary.\n\nToday, it’s hard to avoid the kill-chain concept in cybersecurity. “I often\nsit in on tech pitches, and at least half the time the pitches reference the\nkill-chain model,” says Amin. “Usually, they have not done their homework and\nhave no idea I cowrote the paper they are citing.”\n\n### Breaking the Links in the Chain\n\nThinking like an attacker is the oldest advice in cybersecurity. Yet few of\nthe good people who work in cyber defense seem capable of doing it. If you\nthink like an adversary, it quickly becomes clear that there is a lot more\nwork involved in going after a well-defended target than it would seem. And\nwhile there are now many different models of the kill chain under different\nnames, such as the “attacker life cycle,” to avoid copyright infringement\nagainst Lockheed, the basic model is largely the same. And it always starts\nwith reconnaissance.\n\nIf you are going to hack Lockheed Martin or any other firm, you had first\nbetter do some research. This initial reconnaissance might involve using a\nnetwork scanner to look for vulnerabilities, but it probably begins with a few\ntools that everyone reading this book already used today: Google and LinkedIn.\nAttackers are going to find out everything they can about the company. Where\nare its offices? Who are its employees? How is it organized? What software do\nthey use? What systems do they run?\n\nIf defenders make it hard to conduct reconnaissance on the company by limiting\ninformation about who its employees are and what systems they operate,\nadversaries may give up and move on to other targets. If corporations plant\nfalse information, say fake employees on LinkedIn with profiles that point to\ntechnologies they do not use and fake email addresses for contacting them,\ncompanies can detect the reconnaissance in the early stages by noticing\nattempts to access those systems or contact those nonexistent employees.\n\nAfter reconnaissance, an adversary needs to weaponize what they have learned,\ntaking information about the company in question and putting together a plan\nto gain access to it. That might involve looking for a known vulnerability in\na hardware or software system at the company and then buying or building\nmalware to exploit the vulnerability. Weaponization is hard to counter\ndirectly, but the next stage, delivery, is not.\n\nMost sophisticated attacks today rely on spear phishing, sending an email to a\nspecific and unwitting employee at the company, with malware attached inside a\npdf or other document. Sometimes the email provides a link to a website, where\nthe malware will automatically download. If the attack is unsophisticated and\nreuses malware known to antivirus companies, a simple matching of the payload\nto fingerprints of known malware can block it.\n\nIf the attack tool is new or changed in any way, companies such as FireEye can\n“detonate” the attempted spear phishing by quarantining the suspicious email\nand then automatically clicking on each pdf or link and seeing what happens.\nIf the attachment proves harmful, the system will block it. Other companies\nwill do the same thing for web links by seeing what they download when they\nconnect to the link and determining if it is malicious. Still others will rate\nthe website in the link for trustworthiness and will prevent employees from\nconnecting to untrustworthy sites.\n\nThese systems are, of course, imperfect, and sophisticated adversaries will\ntest their payloads against these defense tools before using them against\nhigh-value targets. That’s why companies that have adopted the kill-chain\nmodel haven’t given up on training their employees as a line of defense.\n\nThere is a cartoon that has circulated in the IT security community for years.\nIt shows a boxing ring. The emcee for the match, gesturing toward a formidable\nstack of computing equipment in one corner, announces that “In this corner, we\nhave firewalls, encryption, and antivirus software, etc. And in this corner,\nwe have Dave!” In the opposite corner is an overweight, slovenly, middle-aged\nman with a silly grin and a T-shirt that says HUMAN ERROR. Poor Dave\nrepresents that one guy in every organization who just can’t resist a clever\n(or not so clever) hook in a phishing email. Dave finds the offer for a free\nvacation or the policy report from a D.C. think tank he has never heard of\njust too tempting to resist.\n\nSince the cartoon first appeared in 2014, the tech stack in the right-hand\ncorner has evolved considerably. Today, the buzzwords it would hit would\ninclude “machine learning,” “advanced AI,” and “virtual detonation chambers,”\nbut Dave is largely the same. There is no training Dave. No matter how many\nPowerPoint slides you make them click through or security-awareness videos\nthey watch, the Daves of the world will always click. But there is training\nthat works for most other employees.\n\nCompanies that have made their employees a strong line of defense have done so\nby targeting their own staff with simulated attacks. They send emails trying\nto trick the staff into clicking on links or opening documents from sources\nthat look like what an attacker might use. If they fall for it, instead of\ngetting the document they wanted to read or the website they wanted to reach,\nthey get a “You got phished!” message. Their company’s security team and,\nusually, their manager also get notified. If they do that too often, there may\nbe consequences such as a day of unpaid leave. Once bitten, twice shy.\n\nOf course, there is still the problem of Dave. If one thousand employees\nresist clicking on the phishing email but Dave still does, the attacker has\nfound their way in. To combat this problem, companies have realized they need\nnot just to train their employees to spot spear phishing, but also to use\ntheir employees as a detection system. Let’s say Dave clicks on an email that\nis also sent to his coworkers, and someone else recognizes it as spear\nphishing. Companies such as Cofense offer a button that can be embedded into\ntheir clients’ email, so the staff recipient can click to report phishing.\n\nSome recipients of the spear-phishing email may have been in a meeting when\nthe email arrived in their in-box. Others may have seen the email and thought\nit was uninteresting. But a few vigilant employees may have seen it, decided\nit was a phishing attempt, and sent it off to the IT department, or clicked\nthat Cofense button. If the company is lucky and Dave has not clicked on it\nyet, they may be able to delete the message to him before he sees it or they\nmay place it in quarantine to be examined later.\n\nSometimes the spear-phishing email is so good that even the best-trained\nemployee in the world would click on it. The attacker may have really done his\nhomework and found out a supplier the company uses. They may have compromised\nthat supplier’s less-well-defended network and gotten into their email system.\nThe spear-phishing email might then not come from an unknown or spoofed email\naddress. It might have come from someone that poor Dave is emailing with all\nthe time. It might even come wrapped inside a document that they were\nexpecting their supplier to send, like a monthly bill. No amount of user\ntraining is going to stop that. But compromising Dave’s computer doesn’t mean\nthat the offense has won. In the traditional kill-chain model, they haven’t\neven gotten halfway in.\n\nOnce poor unsuspecting Dave has clicked on the pdf, the malware hidden in the\nbackground will try to take over his computer. It will attempt to implant\nitself deep in the operating system. But defenders can both prevent the\ninstallation or, if it fails, detect it. Sandboxing techniques, such as\nsoftware that quarantines suspicious messages, can be used to keep the malware\nisolated, so it cannot gain control of the system. Endpoint protection\napplications from companies like Cylance block any activity that their models\ndeem to be suspicious. Endpoint detection and response, from companies such as\nCrowdStrike, installed on Dave’s system will watch for anomalous behavior that\nmay indicate it has been compromised.\n\nThese companies’ products seek to block the adversary as it exploits\nvulnerabilities in an attempt to execute code on Dave’s system, install\nmalware, communicate back with its controller, and move across the network,\nthe next steps in the kill chain. At the most advanced companies, teams of\nhighly skilled individuals are looking for these whispers of ghosts lurking in\ntheir machines.\n\n### The Hunters\n\nThe concept of threat hunting is fundamental to the kill-chain model. While\neach step in the kill chain provides an independent opportunity to detect the\nadversary activity, companies that are looking inside their systems for\nevidence of an intrusion not only have the ability to detect it, but also to\nstop it. That is why companies are working to break up the steps of the kill\nchain into many more.\n\nThe MITRE Corporation isn’t a large company compared to other defense\ncontractors, but it is an important one. MITRE is a nonprofit that manages\ngovernment-funded research-and-development centers. Because of that, it might\nbe working to employ artificial intelligence to detect the early signs of\ndisease outbreak for the CDC, or it might be figuring out how to make the\nwings of a drone into solar collectors, to allow them to fly indefinitely.\nCompetitors on the global stage, be they foreign corporations or foreign\ngovernments, want the intellectual property and state secrets that MITRE is\ndetermined to guard closely.\n\nIn 2009, the MITRE Corporation had its first significant breach. Gary Gagnon\nwas its CISO. While many CISOs would have called in an incident response firm\nand started updating their résumés, Gagnon is not your typical CISO. Against\nhis initial instincts, he green-lit an audacious idea from his incident\nresponse team, who argued that instead of trying to get the adversary out of\nthe network quickly, they needed to keep the adversary inside their network,\nto try to understand their intent and interests. They proposed firewalling off\nthe intruder to limit what information he could access, and then doing their\nown man-in-the-middle attack to compromise his command and control and learn\nhis tactics and techniques.\n\n“I’ve been on the job for three months, and I’m like, ‘Holy shit, you’ve got\nto be kidding me.’” But Gagnon saw the value in the intelligence he could\ncollect. “So, I said I will do this once, but I will never do it again.” But\nhe did do it again. In fact, he did it more than two thousand times.\n\nThat first incident made Gagnon realize that the attacks his company was\nsuffering were not opportunistic, but rather well planned. “The mind-set of\nmost defenders is that it is random rather than a planned objective that can\nbe understood. Most companies believe that the aggressors are not targeting\nthem.” But they are, and Gagnon now had the data to know it with confidence.\n\nGagnon thinks about cyber adversaries in terms of uncertainty. Attackers\nbreaking into his network knew that the information they wanted was at MITRE,\nbut they didn’t know where to find it on the network. The attacker’s job was\nto drive down that uncertainty by gaining a foothold on the network and then\nmapping it and moving laterally across it until he could find and extract the\ndata he wanted. Gagnon’s approach was to reintroduce uncertainty. To do that,\nhe began a multiyear deception campaign to trick the adversary into wasting\ntime and revealing his tools and techniques while Gagnon’s threat-hunting team\nwatched.\n\n“In the world of deception, all deception is good,” says Gagnon. And that’s\nwhy he is not shy about discussing MITRE’s deception campaign. “The fact that\nwe are communicating to the public that we use deception as a tool starts\nreintroducing uncertainty. If an adversary gets in our network, how do they\nknow if they defeated our controls or if we let them in? If they exfil data,\nhow do they know whether it is real or whether we planted it?”\n\nGagnon and MITRE went all in on deception, building out what they called their\n“fun house”: a “house of mirrors where we can let the adversary play.” By\n2010, they had a fully replicated model of all of MITRE’s infrastructure. They\ncaptured the data they collected on adversary activities and transformed them\ninto indicators to feed their sensors, but they also developed Collaborative\nResearch into Threats (CRIT), a database that captures a wide range of\nadversary activity. Around 2014, the folks at Fort Meade suggested that MITRE\nstudy what they had learned and see how it could be used to inform the\ndefense.\n\nGagnon’s team created a chart that exploded the traditional concept of the\nkill chain. Instead of the standard seven steps (three to the left of\nexploitation and three to the right) the chart his team showed Gagnon depicted\nan expanded version that broke out the three steps to the right of exploit\ninto nine distinct steps matched with the behavioral characteristics that\ncould be used to detect the adversary at each stage. It was an epiphany for\nGagnon.\n\n“I already knew that I didn’t want to play the cybersecurity game at the\nexploitation phase. That’s vulnerability of the day,” explains Gagnon. “I’m\nnot worried about the compromise. What I worry about is what happens after the\ncompromise.”\n\nBreaking down the right of exploit into nine steps that were based on five\nyears of observing how adversaries actually acted showed Gagnon something\nsurprising: attackers did not change the tools or tactics they used once they\ngot inside the network, right of exploit. In many cases, attack groups were\nutilizing common tools that they have sometimes used for years. What that\nmeant is that defenders were making it all too easy to operate inside their\ntargeted network, yet this was the piece of cyberspace that defenders could\nactually control. Defenders could shift the balance in their favor\nconsiderably if they could figure out how to detect and disrupt adversaries on\nwhat was tantamount to home turf.\n\nGagnon immediately publicly released the chart. “I wanted to build a community\naround adversarial behavior right of exploit. It was now a tractable problem\nfor me. It went from ‘I don’t know what is happening’ to ‘There are now nine\nobjectives the adversary is trying to achieve.’” Gagnon’s team also identified\nwhat tools the adversaries were using against them and where there were gaps\nin their detection capabilities. “That became an investment framework for us.”\nGagnon went shopping for new endpoint products that could fill these gaps. He\ndubbed the chart the ATT&CK Matrix, for adversarial tactics, techniques, and\ncommon knowledge.\n\nSince 2014, the ATT&CK Matrix has continually evolved. Today, ATT&CK breaks\ndown the steps an adversary needs to take within the network to eleven\nseparate stages, so that threat hunters can look for signals that might\nindicate privilege escalation, in which adversaries try to gain administrative\nrights, or lateral movement, in which adversaries attempt to move across the\nnetwork from their initial point of access. MITRE has further broken down each\nstep in the chain into more than two hundred tactics to look for. Building on\nthe kill-chain model in this way shows just how difficult the adversaries’ job\ncan be if the threat hunters are looking for them.\n\n### Collective Defense\n\nThe ATT&CK framework is ultimately an attempt to create collective defense\namong companies threatened by advanced adversaries. As such, it is an evolved\nexample of the most dreaded phrase in cybersecurity: “information sharing.”\nInformation sharing often feels like the dead horse in cybersecurity that\ncontinues to be beaten well past the point where anyone could get any further\nuse out of the concept. But in reality, information sharing has been the focus\nof cybersecurity policy for twenty years because it is both so important and\nso hard to get right.\n\nWe discussed the value that a single corporation got by pooling the insights\nof its employees on what might be a spear-phishing email. Now, imagine the\nvalue that corporation could get if it shared those insights with its peer\ncompanies and in return received insights from those companies’ employees?\nThat might really put the hurt on these companies’ common adversaries. Why?\nBecause if the companies are not sharing this information, the adversary is\nfree to use the same email message, from the same account, with the same\npayload, delivered using the same URL, exploiting the same vulnerability, and\ncommunicating back to the same command-and-control infrastructure, across\nmultiple different companies.\n\nIf one company discovered it, no big deal; one thousand others would not. But\nif these companies are sharing information among themselves, and a discovery\nof the attack by one means that every company will know about it, the attacker\nwill need to be much more careful and selective. The attacking group might\nneed to develop separate attack patterns for every target. That would be a lot\nof work.\n\nBy sharing the spear-phishing email, or malware, or any other indicators of\ncompromise, defenders are hugely increasing the workload of the attacker. When\nthe kill-chain methodology is combined with information sharing across every\nstage, the attacker’s advantage can almost totally be erased. Of course,\nsharing this kind of information is difficult and it can be hard to justify\nagainst the many priorities within an enterprise’s cybersecurity organization.\nAfter all, sharing a piece of malware with other companies in your sector\ndoesn’t directly benefit you. It benefits you only if, in return, the\ncompanies you share with also share with you. Some have described this as a\ntragedy of the cyber commons. Fixing the problem by incentivizing information\nsharing has been the focus of over a decade of government policy and dozens of\nacademic and think-tank papers.\n\nWhen PDD 63 called for the creation of the first information sharing and\nanalysis centers to be created by the private sector, Dick Clarke hoped that\nthe private sector would be able to muster the resources to build just one\ncenter. Since then, more than a dozen industry-level organizations have sprung\nup. The most successful of these is the Financial Services Information Sharing\nand Analysis Center (FS-ISAC). Encompassing almost all of the financial\nservices industry in North America (and therefore most of the world), the FS-\nISAC has addressed the sharing problem by creating tiers of membership. At\neach higher tier, newer, better, higher-quality information is shared among\nthe members on that level. The trick is that you get it only if you can give\nin kind. The largest, most sophisticated members of the financial services\nindustry formed the Financial Systemic Analysis & Resilience Center (FSARC), a\nseparately chartered organization that works directly with the federal\ngovernment to share intelligence.\n\nFor its part, MITRE has helped to stand up a series of regional information\nsharing and analysis organizations, nonprofit groups that pull together\ncompanies in the same geographic area to encourage them to build information-\nsharing processes. These efforts have enjoyed some success, but have also led\nmany smaller, less sophisticated companies to the conclusion that they cannot\nundertake the time and effort of sharing information on their own.\n\nHere is where vendors like CrowdStrike have stepped back into the picture.\nInstead of needing to set up a process to share a piece of malware discovered\nby CrowdStrike on one of your computers, why not have CrowdStrike do it for\nyou? Better yet, why not have CrowdStrike pull that discovery back to its\ncloud and share it with all its customers so they can block it before they are\never even infected? This is the concept behind CrowdStrike’s intelligence-\nsharing offerings and those of its competitors.\n\nMany of these competitors want to go one step further. Cybersecurity often\ndraws in the civically minded. A large portion of professionals in the field\ngot their start in military, government, or law enforcement. For them, “the\nmission” never changes, no matter whom they are working for. It remains always\nto stop the bad guys. And so, even when an economist might argue that it is\nnot in the rational interest of a security-tool vendor to share information\nwith other tool vendors, they do.\n\nRick Howard is a 1982 graduate of West Point whose last job in the Army was to\nlead its computer emergency response team. The chief security officer of Palo\nAlto Networks, Howard works for the kind of company that might argue it could\ndo it all for its customers. Palo Alto offers a full range of network and\ndevice-security tools that are some of the best in the business. But instead\nof making the case that all you need is Palo Alto’s suite of products, Howard\npushed his company and its competitors not just to share information among\ntheir customers, but also to share it with one another.\n\nHoward persuaded his then CEO, Mark McLaughlin, also a civic-minded West Point\ngraduate, to start the Cyber Threat Alliance (CTA). Together with Symantec,\nMcAfee, and Fortinet, Palo Alto agreed that under the CTA banner, these\ncompanies would each agree to share the new threats they discovered with one\nanother. What is more, this would be no soft agreement. Membership would\nrequire sharing a thousand unique pieces of malware a day. The requirement was\nso high that only serious players could join. It had an effect that Howard\nintended. Rather than selectively choosing what to share each day, many of\nthese companies chose to automatically share everything they found. Howard’s\ngoal was simple. He wanted to make it so that an adversary could only use a\npiece of malware or another element of attack infrastructure once before it\nwas discovered and shared globally. In short, he wanted to achieve herd\nimmunity.\n\nToday, CTA members are sharing about four million indicators a month. “Seventy\npercent of those indicators come with some kind of context around them,” says\nNeil Jenkins, CTA’s chief analytic officer. “It’s not just a file hash and an\nIP address, it’s context about what industry is being targeted, what country\nis this being seen in, what attack framework or TTP [tactics, techniques, and\nprocedures] is it using.” And all that information is getting shared with\nevery vendor that is a member. “If that information is getting shared and put\ninto our products, we can protect thousands of companies and millions of\nindividuals.”\n\nThe idea (and execution) was so compelling that the Obama administration’s\nlong-serving cybersecurity coordinator (and Rob Knake’s long-suffering White\nHouse boss), Michael Daniel, decided to become the organization’s director\nwhen he left office. In Daniel’s view, there was nothing else he could do\noutside of government that would have the impact that realizing the Cyber\nThreat Alliance vision would. Since taking over, Daniel has added another\ndozen members, including major players in the space, such as Cisco, Sophos,\nand Rapid 7. While he has yet to pull in CrowdStrike or many of the other\nendpoint vendors who view their intelligence as a competitive advantage, he\nkeeps trying. Many of those companies’ customers (including the federal\ngovernment) are placing pressure on them to join for the simple reason that\nthe best endpoint detection system in the world isn’t likely to be as good as\nthe ten next best combined.\n\n\n## Chapter 5\n\n## THE TECH STACK\n\nSoftware was not built to be used, it was built to be bought by someone at the\ntop.\n\n—STEPHEN O’GRADY, FOUNDER, REDMONK\n\nIn the movie _Amadeus,_ a young Wolfgang Mozart asks the emperor how he liked\na new piece of music that the prodigy had just played for him. “Too many\nnotes,” the emperor replied. In Mozart’s case, however, the many notes were\nall tied together in movements that together formed a coherent symphony\nconceived by one individual and then played on almost a hundred instruments,\neach chiming in at the right time for an overall intended effect. We are far\nfrom achieving that level of orchestration in cybersecurity. The whole of the\ncybersecurity technology landscape adds up to less than the sum of its parts.\n\nSilicon Valley is seldom accused of lacking ambition, but in the case of\nsecurity, few pitches that promise to revolutionize anything in cybersecurity\nmake it to a live meeting with investors. Instead, venture-capital firms have\nchased relatively quick wins from marginally improving existing cybersecurity\nproducts. The “10x” improvement that Google looks for in its venture\ninvestments has not been achieved even by Google, whose new cybersecurity\nplatform, Chronicle, looks altogether undifferentiated. Instead, Silicon\nValley and venture-capital firms around the country have funded thousands of\ncybersecurity companies with massive overlap in capabilities that are targeted\nto a small set of buyers in the financial sector.\n\nThe large financial institutions spend huge amounts on scores of these\nproducts, both to placate regulators and to protect their assets from cyber\ncriminals. All these tools are, however, a nightmare for most large\nenterprises to integrate and manage, and impossible for smaller companies to\ntry. For every new regulatory requirement or emergent threat there is a new\ntool that someone wants to sell them.\n\nYou will never know how popular you are or how many friends you have until you\nbecome a CISO at a large-cap financial institution. Then your best friend from\nhigh school whom you haven’t spoken to in twenty years will show up at your\noffice with a new business card. He’s doing business development for a new\ncybersecurity tool he just has to show you. A lot of the time, the tool might\nactually address a threat or close a regulatory requirement. So you decide to\nbuy it and add it to all the other security technology in your tech stack. The\nproblem is you then need to manage and run it.\n\nOne consulting firm we have worked with is doing brisk business helping\nclients come up with strategies to eliminate tools. They are often able to\nshow customers that there are features in other products they already have\nthat could replace one or more of their stand-alone products. Mostly, though,\nthey work with clients to sort out which tools they really need and can\nactually use, on the theory that a small handful of managed tools will be more\neffective than a large number of unmonitored machines that go _bing!_ Their\nrecord was reducing eighty-plus tools down to eight. That may be the right\napproach for some companies, but for those who are in a constant battle\nagainst advanced threat actors, new tools are constantly needed to combat new\nthreats, protect new classes of assets, and generally stay one step ahead.\n\nA utility company we know is in the process of a massive technology rebuild.\nThey began with the largest set of security requirements they could come up\nwith, drawn from the NIST 800 series of technical guides (and many they\ndefined themselves that aren’t yet captured in the technical docs), some 614\ncontrols in all. They then began looking for tools that implement multiple\ncontrols. In the end, they ended up with 114 different tools. Sixty-seven are\none-offs. The other 47 are designated as primary, meaning that they cover\nmultiple controls. Six programs tie it all together, analyzing data across\nmultiple tools using behavioral analytics. Few companies have the resources or\npatience for this kind of multiyear, multimillion-dollar integration effort.\n\nThe problem may be best illustrated by looking at what it takes to secure a\nsimple desktop or laptop computer, what the security community calls endpoints\nor hosts. Gartner, the IT advisory firm, tracks twenty-two different\ncategories of endpoint technologies, everything from legacy antivirus to\nvirtual private network software. At a dinner Dick Clarke had with leading\ncorporate CISOs in 2018, he asked how many different tools they were deploying\nonly to endpoints. The low was six. The high was thirty-two, the median in the\nhigh teens. This many tools bog down systems and causes problems with\ncompatibility. Many security programs are now being given a budget not for how\nmuch they can spend, but for the percentage of memory and processing power\nthey are allowed to take up.\n\nYou might think that the obvious answer would be for customers who need to\nintegrate all these tools to start demanding that vendors check off multiple\nboxes on their requirements list. You’d be right. That is what Sounil Yu has\nbeen trying to get industry to do.\n\n### The Cyber Defense Matrix\n\nSounil Yu works for a large financial institution, the identity of which is\none of the worst-kept secrets in cybersecurity. He spends his days looking for\nnew technologies that can help his bank do cybersecurity better, faster, and\ncheaper. The bank has a security budget on the order of $400 million per year.\nYu’s job is to figure out how that gets spent.\n\nEvery start-up that wants to pitch a cybersecurity product to his employer\ngoes through him: thousands of solutions, each one claimed by their inventors\nto be unique. Lots of jargon, little differentiation. To help himself sort\nthrough the mess, Yu began to organize technologies pitched to him into what\nhe dubbed the Cyber Defense Matrix. The matrix tries to capture everything\nthat a cybersecurity program needs to do at a high level. Yu pivoted off the\nNIST Cybersecurity Framework’s five functions: Identify, Protect, Detect,\nRespond, and Recover (what he calls “Things that I do”). He put those across\nthe top of his matrix. Down the side, he wrote out the five common asset\nclasses: Devices, Apps, Networks, Data, and Users (what he calls “Things that\nI care about”). He then started to fill in the matrix with technologies.\n\nWhen he was finished, it showed heavy concentrations of technologies in areas\nlike device protection, but huge blanks on the matrix for anything to do with\nrecovery. Few products covered more than one space on the grid, and finer-\ngrain analysis would show that no product could do everything necessary within\na single square (despite claims made by their marketing department). When he\ntook the analysis beyond the traditional company IT network and looked at\ntools for monitoring the security of employee devices or supplier networks,\nmost of the grid was blank. None of this made sense. By some estimates there\nare more than three thousand security product companies. If three thousand\ncompanies were building security products, why were they clustered so closely\ntogether and not filling out his matrix? Moreover, how would companies other\nthan the five or so largest banks ever amass the resources and patience to\nintegrate and manage this mess?\n\nYu quickly concluded that what the market needed was platforms. All these\ntools did one of four things: sensing, sense making, decision making, and\nacting. Many of them did all those things (or tried to do all of those things)\nin a single, neat package. That approach created two main problems. First, it\nmeant that every tool that required sensing needed its own sensor and every\ntool that would take an action needed its own actuator. Second, it meant that\nwhen it was sense making, it was making sense of only the data it collected\nfrom its own sensors. Sensors and actuators need to be deployed to networks,\ndevices, and applications, and thus need to be managed. They are hard to get\ndeployed and difficult to maintain, but the real value of these products was\nin the data analytics and artificial intelligence that made sense of the data\nand could decide what to do about it. So Yu made a pitch to decouple the\nsecurity stack.\n\nHis epiphany was that a sensing and actuating platform could do the bidding of\nmultiple analytics and orchestration tools. At a conference sponsored by the\nendpoint vendor Tanium in 2016, he made the case that vendors like Tanium\ncould provide the platform for sensing and actuating for any number of\nanalytics or orchestration tools. Companies such as McAfee, Cylance, and\nCrowdStrike could pull the data they needed from the Tanium sensor and then\nsend actions to the Tanium actuator based on their analysis. Tanium could\nprovide antivirus software “powered by” McAfee or Trend Micro, or insider\nthreat detection “powered by” Exabeam. Tanium did not bite.\n\nLike almost every other company in the field, Tanium wants to be “the\nplatform,” a do-it-all, single-vendor product, not “a platform” that other\nvendors would use. Tanium raised another $200 million last fall at a valuation\nof $6.5 billion, to bring its total raise to $800 million. The trouble is that\neven $800 million in venture funding is not enough to build out all the\ncapabilities on Sounil’s matrix.\n\n### Venture Tourism and Thin Peanut Butter\n\nIf anyone can be blamed for this state of affairs it is Silicon Valley. And if\nwe reserve a special place in cybersecurity hell for the enablers of vice,\nthen Sand Hill Road should burn. The tech start-up battle cry of “Move fast\nand break things,” originally coined by Facebook CEO Mark Zuckerberg, has been\npushed by the venture capitalists of the Valley in an effort to build large,\nmonolithic monopolies at the expense of consumers, regulations, ethics, and\ncybersecurity. And move fast and break things they did, from the now\nantiquated concept of stable employment to a free press to U.S. elections.\n\nAll the while, the push to get products out the door and fix security later\nhas led us to our current predicament. The idea of building in security, i.e.,\nmaking products secure from the start rather than bolting security on after\nproducts are built, has long been championed by the security community. It\nnever made sense to the “visionaries” in Silicon Valley, but when the\nprevailing winds of tech euphoria started to slacken as the breaches piled up,\nthe venture-capital world became interested. It was like a fire department\nthat both sets the fires and charges to put them out. Billions have gone to\ncybersecurity companies. Billions will continue to flow. Yet we remain far\nfrom a high level of cybersecurity. A significant part of the problem is the\nventure-capital model we have in this country for funding cybersecurity\nresearch and development.\n\nIn an attempt to understand how we reached this point, we sought out Bob\nAckerman. In some ways Ackerman hasn’t gone very far. He started out studying\ncomputer science at the University of San Francisco and now he sits a few\nmiles away in an office on the Embarcadero almost under the Bay Bridge. In\nother ways, however, he has traveled the history of cybersecurity and is\nhelping to shape its future.\n\nFrom his early days working with UNIX and the pioneering BSD operating system\nto designing what a mobile phone/computer would look like at the technology\ncompany InfoGear years before the iPhone materialized, Ackerman went on to\nform his own ecosystem for venture investment in cybersecurity. Today that\nsystem includes DataTribe, AllegisCyber, and Founders Equity. The three firms\ntogether and his many successful investments in the field have earned Bob the\nnickname Mr. Cyber on Silicon Valley’s venture-capital row.\n\nDataTribe, based in Baltimore (near the NSA) and San Francisco, is Ackerman’s\nvehicle to identify unmet needs in the cybersecurity product market and then\nto create teams, do research, and start companies to meet those needs. “I’m\nnot an investor,” Bob explained. “I build companies.” In doing this seed and\nA-round investing, he draws heavily upon recently retired NSA staff.\n\nAllegis is his vehicle for later-stage investment in cyber companies, B- and\nC-round money. Founders Equity is “for the ones that got away,” a fund to buy\nstock in privately held cyber companies from early-stage employees looking for\nsome cash before the companies go public.\n\nCybersecurity, along with other IT and biotech in general, attracts venture-\ncapital (VC) money like bears to honey. Indeed, most applied cybersecurity\nresearch is funded by VC investors hoping to back the next unicorn on its run\nfrom start-up to billion-dollar valuation on the stock market. Although\nAckerman is the quintessential cyber-VC guy, he sees some real downsides to\nthe fact that investor money has flooded into the field.\n\n“Visionary sheep” is what Ackerman calls the many venture-capital firms that\nthink they must invest in cybersecurity start-ups. “The problem is most of\nthem know nothing about cybersecurity, they just want ‘a cyber’ in their\nportfolio,” he told us. “They’re doing venture tourism” in the world of\ncybersecurity. “There are really only about a half dozen venture-capital firms\nwho understand the field, the technology.”\n\nThe result of this financial tourism is overinvestment and too many VC\ncompanies mindlessly following their competitors’ activities, Ackerman\ncontends. “It totally disrupts the economics of innovation.”\n\nStaffing those firms with the limited supply of cybersecurity experts and\nsoftware engineers has, in the words of Ackerman, “spread the peanut butter\ntoo thin” on too many pieces of bread. It also makes it difficult for the\ncorporate buyer to sort through a sea of look-alike, sound-alike firms\ncompeting for the attention and dollars of chief information security\nofficers.\n\nMany of the three thousand cybersecurity companies “are a feature, not a\nfirm,” he said. They solve one narrow problem and really should be part of a\nplatform company offering a mutually supporting mesh of integrated security\nproducts. In a rational world, many of the start-ups would be folded into\nlarger companies, but the desire of VC investors to force their firm to\nsomeday become a billion-dollar unicorn prevents such needed consolidation.\nThus, while VC funding was a way to have private-sector money fund research\nand development in cybersecurity, it has now become an impediment to efficient\nmarket forces. Luckily, if the cyber-products industry can’t solve the\nproblem, there is hope that the IT-products industry, with some gentle\nencouragement, just might.\n\n### Building Security In\n\nSounil Yu’s presentation at the 2017 RSA, the annual corporate cybersecurity\nconference held in San Francisco’s Moscone Center, was titled “Solving\nCybersecurity in the Next Five Years.” He took a poll at the start to ask how\nmany people thought it was possible. Only a handful of the hundred-plus\nattendees raised their hand. Undeterred, Yu made his pitch. What he meant by\n“solving” wasn’t that cybersecurity problems would go away, but that they\nwould be manageable, that the situation was improving, and that companies\nwould achieve resilience in the cyber realm.\n\nThere is a concept borrowed from the military called the OODA loop, for\nobserve, orient, decide, act. It was meant to help military leaders at the\nfield level figure out what to do when bullets are flying and grand strategy\nhas been tossed out the window. At each stage of the kill chain, the attacker\nis going through the OODA loop, figuring out where he is, where he needs to\ngo, and how to get there. In order to defeat the adversary, Yu argues that\ndefenders need to “get inside” the attacker’s OODA loop, to respond faster and\nmore nimbly.\n\nRight now, though, security is well outside the attacker’s OODA loop. It may\ntake an attacker a day to infiltrate a system and two hundred days for the\nsecurity team to find it. Security is slow. It introduces delay and approvals.\nThe true cost of security isn’t just or even mainly that it sucks down a\ndecent percentage of the IT budget, but that it slows down businesses from\nmaking money. What’s faster than the attacker’s OODA loop? The business cycle,\nthe pace that companies want to move at when unencumbered by security.\n\nAgain, pivoting off the NIST Cybersecurity Framework, Yu provides a history\nlesson in cybersecurity. In the 1980s, as information technology became\naffordable to the corporate world, enterprises started incorporating it into\nevery facet of their business. As IT got spread around the corporation, it\nbecame hard for companies to know what assets they had and how to manage them.\nSecurity was largely in the form of asset-management programs. Yu therefore\nlabels the 80s the “identify” decade.\n\nThen came the 1990s, when viruses and worms started to emerge, and we\nintroduced measures to “protect” our IT assets. That’s when we got antivirus\nsoftware and firewalls, secure configuration and vulnerability management. (Yu\nnotes that when consultants say that their clients’ security programs are\nliterally stuck in the 1990s, that is what they mean: relying on antivirus and\nfirewalls and hoping for the best.)\n\nIn the 2000s, we saw that attackers were able to bypass antivirus, firewalls,\nand other protective controls, and we needed a way to detect when that\noccurred. Thus were born technologies such as intrusion detection systems\n(IDS) and security information and event management (SIEM), which helped\norganizations home in on unusual activities detected in their logs. Security\norganizations shifted to include threat management programs and started\nbuilding security operations centers staffed with personnel to continuously\nmonitor and act upon alerts created by these detection systems.\n\nFinally, to bring us to today, we are in the age of response. We realized that\nour detection systems were far from perfect; our analysts were overwhelmed by\nfalse positive alerts. We are instructed to “assume the breach,” hunt for\nthreats, and try to contain them. In this current age, we see the emergence of\nincident response capabilities, which manifest largely as a capability\ndelivered through people with some technology to assist. We also see the\nemergence of hunt teams to seek out intrusions. Security organizations become\nmore integrated into the overall risk-management programs so that the wide\nrange of security issues can be properly prioritized among competing demands\nfor personnel and resources.\n\nBy now, you should see where this is going. If the 1980s were the Identify\ndecade, the 1990s were the Protect decade, the 2000s were the Detect decade,\nand the 2010s were the Respond decade, then the 2020s will be (drumroll,\nplease . . .) the RECOVER DECADE! But instead of thinking of recovery as a\nlong, drawn-out process of rebuilding after an incident, Yu thinks that\nrecovery really means resilience, the rapid adaptation to emerging threats by\nsystems that can fail safe. He sees a series of technologies that are coming\nonline to make enterprises more resilient: content distribution networks like\nAkamai, Docker containers that allow applications to be spun up and spun down\nsecurely, serverless architectures, immutable infrastructure, and, of course,\nthe cloud. None of these things are security tools, but all of them help\nbusinesses make changes to their IT environments quickly when problems arise.\n\nYu quotes Ryan McGeehan, who ran incident response at Facebook, as saying,\n“Larger swaths of risk are quickly being eliminated at newer companies, at\nearlier and earlier stages. And usually not because security was the goal.”\nThese technologies nullify attacker persistence on infrastructure by\nrebuilding it frequently, shifting some measure of advantage from the\noffensive to the defensive side. They provide visibility and make anomalies\neasier to detect by providing rich data on the state of security. In short,\nthese technologies are being designed with security built in.\n\nWhile Yu notes that since the 1980s, security and IT have been diverging and\nCISOs and CIOs are increasingly reporting to different leaders (and at one\nanother’s throats), he sees trends such as DevOps, bring your own device, and\nthe ever-present specter of shadow IT bringing them back together. DevOps,\nshort for “development and operations,” shortens the software development life\ncycle by bringing the development team and the operations team in closer\nalignment so they can rapidly push out new versions of software. The fact that\nemployees tend to prefer to carry around one device and not two has forced\nmost companies to allow work to be done on personal devices. Shadow IT, the\ninformation technology systems that workers use to get jobs done that are not\nprovided by or sanctioned by the company’s IT department, has long been\nconsidered a problem in traditional security organizations. But some companies\nare starting to embrace these trends despite the apprehension of their\nsecurity teams. If carried out with security in mind, they are finding, doing\nso has security benefits.\n\nYu argues that by embracing trends in technology rather than fighting against\nthem, security can harness the speed of modern businesses as a weapon to be\nwielded against malicious cyber actors. With DevOps, companies may be\nreleasing updated versions of their software dozens of times a day. That means\nthat when bugs are discovered, they can be fixed immediately. It also means\nthat bugs may be eliminated in rewrites before an attacker can identify and\nexploit them. The concept of chaos engineering pioneered at Netflix has\ncorporations running a constant stream of experiments to test the resilience\nof their systems. Bring-your-own-device policies can let companies bring their\nemployees’ personal phones and computers under protection, rather than\nallowing devices to be used for some work purposes but well outside employers’\ncontrol. Shadow IT is usually a sign that existing and approved technologies\nare too slow for business.\n\nBy embracing the speed of business, Yu believes that security will in fact be\nable to get inside the attacker’s OODA loop. Simply put, business moves faster\nthan the attacker. The new resilient designs that enable businesses to move\nthat quickly are largely being built in the cloud.\n\n### Cloudy with a Chance of Security\n\nThere is a bumper sticker that is ubiquitous on the back of laptops at hacking\nconventions like Black Hat and DEF CON. With a wink and a nod, it reads: MY\nOTHER COMPUTER IS . . . YOURS. Stealing computing resources from universities,\ncorporations, and individuals used to be common practice, even among the “gray\nhat” hacking world that was more interested in research and less in criminal\nprofit. While cyber criminals still use stolen computer resources for mining\ncryptocurrencies and for carrying out DDoS attacks, when they need real\ncomputing power or to hide their tracks, they turn to the same company that\nyou do for your socks and kitchen supplies: Amazon.\n\nWith a stolen credit card or a compromised account, criminals can spin up a\nvirtual server on Amazon as easily as you can buy an ebook. According to data\nfrom Spamhaus, a nonprofit corporation that tracks online spam propagation,\nAmazon is one of the worst sources of all kinds of malicious cyber activity.\nOut of its data centers spew many of the ads for CheapPills and Ponzi schemes\nthat clog up your junk mail folder. Amazon’s servers host many of the domains\nthat cyber criminals try to get you to click on.\n\nOf course, Jeff Bezos isn’t relying on spam or botnets to make his billions.\nAs with the internet itself, the cloud has turned out to be a neutral medium,\na mirror that reflects the intentions, good or bad, of those who are using it.\nSo, like email or the World Wide Web, the cloud quickly has become vital to\nboth legitimate businesses and the cyber-criminal underworld. Like every\nSilicon Valley start-up, criminals are making the most of cheap or free\ncomputing power. While the cloud has made it easier and cheaper for cyber\ncriminals to do what they do, it has also made it immeasurably easier for\ncompanies that do not have thousands of people and security budgets with nine\ndigits to implement best-of-breed protections online.\n\nThere are, of course, trade-offs. Larry Zelvin, a senior security executive at\nBMO Bank and a former senior White House and DHS official, worries that the\ncloud could be what ball bearings were to the German war effort in World War\nII, the single point of failure that when successfully targeted destroys the\nwhole economy. When Rob Joyce, then head of Tailored Access Operations (TAO)\nat the NSA, gave a talk at the 2016 USENIX Security Symposium about how to\ndefeat an APT actor, he cautioned against throwing everything into the cloud\nand hoping for the best. “You need to remember that ‘the cloud’ is just a\nfancy way of saying somebody else’s computer.”\n\nFor some companies or government agencies, that will mean they will never\ntrust what is going on beneath the hypervisor that creates the virtual\ncomputing environment in which their applications live, and they will choose\nto build their own. For most companies, owning your own servers doesn’t reduce\nrisk. It increases it.\n\nEd Amoroso, AT&T’s longtime chief security officer, now an independent\nconsultant, cautions against trying to replicate the security practices of the\nselect few companies with these capabilities. “The _Fortune_ 50—the companies\nthat have five hundred to seven hundred people on their security team—when\nthey say they aren’t moving to cloud or they are going to build their own,\nwhat it ignores is that ninety-nine percent of the businesses and\norganizations out there bear no resemblance in any way to these large banks.”\nThe obvious question a company asks, he says, in making the decision to move\nto the cloud is, “Are we better than Amazon?” Ninety-nine times out of a\nhundred, the answer is going to be no.\n\nFor the rest of us, the cloud has the potential to bring the same kinds of\nsecurity programs we discussed in chapter 4 to small businesses and even\nindividual users. If you can’t afford to spend hundreds of millions on your\ncybersecurity or hire a thousand people to guard your IT system, the second-\nbest thing is to outsource the security of your computing infrastructure to\ncompanies that do.\n\nLike the banks, Amazon, Google, and Microsoft all have security budgets that\ndwarf the GDP of Palau. They have global security operations centers working\ntwenty-four hours a day, three hundred sixty-five days a year, working in\neight-hour shifts that follow the sun around the world. In stages, each\ncompany has gotten religion on security, recognizing that their business\nmodels were predicated on being able to provide a security environment that\nwas as good as, if not better than, the security environment in a traditional\nIT shop.\n\nEarly adopters of cloud services complained that using cloud services left\nthem blind. They no longer knew anything about the state of security on the\ncomputers that ran their most critical operations. So Amazon, Google,\nMicrosoft, and others began to make the data available. Now, businesses can\nget an instant, real-time snapshot of the state of their security and can use\ncloud computing power to analyze the data provided. Cloud providers are also\nbeing clear where their responsibility for security ends and where their\ncustomers’ begins.\n\nAll major cloud services will provide their customers raw computing power.\n“Elastic” computing, which can shrink or expand based on demand, is what makes\nmany regard Amazon as the leader in the space. Instead of a company building\nits own data center or stuffing servers into its closet, Amazon builds and\nmaintains the computing environment and leases it to the company on a metered\nrate. It has proven the perfect solution for start-ups that need\ninfrastructure on which they can build their own applications.\n\nThis type of cloud computing is known as infrastructure as a service (IAAS).\nAmazon and other leaders have also started to sell platform-as-a-service\nofferings that provide the coding environments on which to build applications.\nFar and away the best way to rapidly increase security is to move from local\ncomputing to software as a service (SaaS).\n\nSalesforce, one of the early successful SaaS providers, never sold its\ncustomer relationship management platform as a software package you could\ninstall on your own computer. In fact, early on, Marc Benioff and his team\nmade up company T-shirts that had a big no-smoking-style circle and slash\nsymbol (think _Ghostbusters_) over the word “software.” The only way to use\nSalesforce was (and is) to use a web browser to access it. The software sits\nsafely on Salesforce’s servers. It can’t be downloaded by cyber criminals to\nlook for vulnerabilities. When Salesforce discovers a problem, there is no\ndelay between when the patch is ready and when it is installed. Malicious\nactors have no window through which to attack the weakened software.\n\nThe New York Cyber Task Force has repeatedly called out cloud computing as one\nof the best ways for the defender to gain leverage over the attacker. Amoroso,\na member of the task force, identified a series of advantages that cloud\ntechnologies have over traditional IT environments. First, they offer greater\nautomation: tasks like securely configuring devices are done automatically for\nyou in the cloud. Second, cloud technologies are “self-tailoring,” meaning\nthat once services are selected, they automatically work together without\nneeding to patch cables together or install software. Third, they have “self-\nhealing characteristics,” meaning that when things go wrong, cloud\ntechnologies will automatically switch over to back up infrastructure.\n\nCloud providers all offer different levels and different approaches to\nsecurity. Google largely bakes security into its offering. Its security\nfeatures can be adjusted, but come with Google Cloud offerings. Microsoft\nprovides basic features, but offers additional security monitoring on a per-\nuser basis for its SaaS offerings like Office 365, a popular suite for email\nand word-processing applications. Amazon provides a solid baseline by\nmonitoring its own infrastructure and providing data on the state of that\ninfrastructure to users, but allows third parties to sell security as a bolt-\non to its core offerings in its marketplace. Google is so confident in its\nsecurity capabilities that, instead of arguing that it shouldn’t be expected\nto be able to stop government intelligence organizations, it is actively\nworking to protect its customers from them and will notify individual Google\naccount holders if they are being targeted by an APT actor.\n\nThe danger with cloud computing is that it is concentrating risk in the hands\nof a few players that now have a near monopoly. Almost all SaaS providers\nstart out building their services on top of Amazon Web Services or Microsoft\nAzure and many stay that way. Netflix, now in a heated rivalry with Amazon\nPrime for eyeballs in the streaming wars, uses Amazon, as do other giants of\nthe internet age such as Airbnb. Dropbox, the online file storage company,\nuntil a few years ago was also an Amazon customer.\n\nWhat this concentration of risk means is that a problem at Amazon (or\nMicrosoft or Google) could be a problem for everyone. Researchers discovered\nflaws in the chips relied on for most computers built in the last twenty\nyears. These vulnerabilities, dubbed Spectre and Meltdown, would allow an\nadversary to access data being processed by a vulnerable computer chip even if\nthe software being run was fundamentally secure. Because the cloud is\n“multitenant,” meaning that multiple companies or users are running on the\nsame hardware, there is the potential that an adversary who could compromise a\nvulnerability like this could access multiple sets of data at once.\n\nWhile patches have been issued and workarounds put in place to keep cloud\nassets secure, the underlying concern remains. Attackers have found\nvulnerabilities that allow them, once they have gained access to a virtual\nmachine at a cloud provider, to break out of that virtual machine in what is\nknown as a VM escape attack. Researchers at CrowdStrike uncovered the high-\nprofile VENOM vulnerability (virtualized environment neglected operations\nmanipulation). The vulnerability was found in a popular open-source\nvirtualization package used by almost all cloud providers. Luckily, the\nvulnerability was discovered in a security review, not through adversary\nactivity, and users of the vulnerable software package were quick to put\npatches in place.\n\nSince the VENOM vulnerability was discovered, a new layer of protection has\nbeen put in place for most applications that run in the cloud: containers.\nJust what they sound like, containers run on top of virtual machines and keep\napplications running in the cloud from interacting with other applications\nrunning in the same virtual machine. Thus, a vulnerability in one piece of\nsoftware running inside a container would not let an attacker gain access to\ndata in another. Instead of installing lots of software in system libraries\nthroughout a computer, containers like Docker or Kubernetes keep all the files\nfor the software to execute within the container.\n\nFor advanced threat actors, compromising the security of a cloud provider to\nget to your data may be something they are more than willing and able to do.\nThus, the cloud may not be the right solution for all applications. The U.S.\ngovernment, while taking a “cloud-first” approach in the Obama administration,\nhas been noticeably slow to make the transition, instead consolidating its own\ndata centers. Where it has made a big push on the cloud (i.e., inside the\nintelligence community), it hired Amazon to build out and run cloud\ninfrastructure that only it could use. The reality is that for most purposes,\nthe security bang for the buck you get by moving to the cloud is well worth\naccepting the residual risk. After all, being able to walk into your own data\ncenter and see that there are thousands of lights blinking back at you and\nthat no one has stolen your servers provides no guarantee that there is not a\nteam of APT actors silently riffling through them.\n\n### To Code Is to Err\n\nWhen we spoke to Ed Amoroso a decade ago for _Cyber War,_ we asked him what he\nwould focus on if he were made “Cyber Czar for a day.” He had a one-word\nanswer: software. Poorly written software was then and is now ultimately\nresponsible for many of the ills that plague cyberspace. Amoroso said that if\nhe were in that position, he would direct government R&D to focus on reducing\nerror rates in software and to develop tools to make it more secure. In _Cyber\nWar_ we lamented that DARPA, whose predecessor organization had funded the\ndevelopment of the early internet, didn’t seem too interested in securing its\ninvention. That began to change shortly after we published _Cyber War,_ thanks\nin part to Mudge Zatko.\n\nWhen Dick got tasked with figuring out a national strategy for cybersecurity\nin the late 1990s, he asked colleagues at the FBI who some of the good-guy\nhackers were that he should talk to that could explain to him all the bad\nthings happening in cyberspace. That led to a meeting at John Harvard’s\nBrewery in Cambridge with members of the hacker think tank the L0pht. Mudge\nZatko was the de facto leader of the L0pht.\n\nWith Dick’s prompting, Zatko and other members of the L0pht team were asked to\ntestify before the Senate, where they stated in matter-of-fact terms that they\ncould take down the entire internet in thirty minutes, referencing abuse of\nthe Border Gateway Protocol (BGP), which is used to route internet traffic\nbetween communications carriers and is still in use, vulnerable, and being\nexploited today.\n\nZatko, with long brown hair, sitting in the middle of the long table, flanked\non either side by his fellow hackers, looked much like Jesus at the Last\nSupper. A decade later, his flowing locks had given way to a serious, D.C.\nprofessional haircut. The famed hacker looked like many other government\nfunctionaries in his official portrait, with a tight, square-knotted tie,\nstanding with a straight back in front of an American flag.\n\nWhen Zatko got to DARPA he doled out some of the funding he had to efforts to\nsecure code. Zatko came from a background of breaking and exploiting software\nand systems. In thinking about the problem of cybersecurity, he identified\nthat many of the defensive software solutions being offered were actually\nadding to the problem rather than reducing it. Taking a sample of almost\n10,000 pieces of malware collected from the late 1980s to 2008, he showed that\nthe average number of lines of code in malware stayed consistent at a\nrelatively tight 125 lines.\n\nMeanwhile, security software such as a unified threat management platform now\nencompassed more than 10 million lines. In a case of the cobbler’s son having\nno shoes, the code in security tools appeared to introduce new vulnerabilities\nat a far higher rate than other classes of software. Put another way, the\nsecurity software was easier to exploit than the nonsecurity software.\n\nLooking at the vulnerabilities added to DoD’s watch list, which tracks\nexisting vulnerabilities in the armed-forces-deployed computer systems, over a\nmonthlong period in the summer of 2010, Zatko identified that six of the\nseventeen vulnerabilities tracked that month were in the security software the\nDoD had deployed. He showed that over longer periods, the percentage of\nvulnerabilities in security products would change from a low of 18 percent to\na high of 44 percent. As if attackers didn’t have an asymmetric advantage on\ntheir side to begin with, the DoD (and commercial industry) were introducing\nmore risk and vulnerability than they were removing by deploying modern\ndefensive security software.\n\nAlthough coding has improved in recent years, it used to be a rule of thumb\nthat there would be at least one to ten errors in every thousand lines of\ncode. Zatko found that in some specific cases, such as NASA’s code hygiene for\nmission critical space systems, that rate had been cut to between one and\nfive. But given that Windows 10 has approximately 50 million lines of code, it\nis easy to understand how there could be a lot of lines that could spawn\nvulnerabilities.\n\nAfter repeatedly getting complaints about how easily hackers and researchers,\nsuch as the L0pht, were finding errors in Windows, Steve Lipner at Microsoft\ndeveloped a system called secure development life cycle (SDLC) to check code\nbefore publishing it. It became an informal industry standard and it did\nimprove things a little. Companies also sprung up to vet code. We worked with\none called Veracode, out of Bedford, Massachusetts. Parts of some large\nenterprises such as Boeing and Wells Fargo told their software vendors that\nthey would not buy their software unless it had been checked by Veracode. IBM,\nWhiteHat, Black Duck, and other companies offer similar and related services.\n\nDevelopers, the people who actually write the code for bosses who wanted it\ndone yesterday, found SDLC and third-party vetting a cumbersome process that\nslowed them down. There was all that waiting around to get the results of your\ncoding, then the time for fixing your mistakes. In the new, fast-paced world\nof DevOps, new code could be requested by a manager one day and go live on the\nnetwork within twenty-four to seventy-two hours. There was no time for\nsecurity review. Veracode’s answer for that in 2017 was something called\nGreenlight, a software package that figuratively looked over the code-writer’s\nshoulder as they were writing. It warned them immediately when they had failed\nto do something properly. There was no waiting for days. Other companies\nfollowed suit with similar real-time code vetting.\n\nStill, however, there were errors. Not everyone had their code vetted for\nsecurity, and the code reviews don’t always find all of the issues. Even if\nsecurity bugs were found, the developing company still had to decide whether\nthey would actually change the code and what the cost would be to thoroughly\ntest and vet the changes to ensure they didn’t break things for their\ncustomers. Others who had vetted code would sometimes have to change it later\nto add a feature, and they would forgo security checks of the modified code.\nTo err is human.\n\nSo maybe the solution is to take the human out of the loop on code\ndevelopment. Google, with its AutoML program, was using artificial\nintelligence in 2018 to write code for neural networks, i.e., AI to write AI.\nDevelopers Fan Long and Martin Rinard at MIT experimented in 2015 with machine\nlearning not just to spot errors in code, but to fix them on the spot by\nhaving the AI write a patch. Meanwhile, at Rice University in Houston in 2018,\nSwarat Chaudhuri and colleagues were sketching. Actually, they were using a\ntype of AI they call “sketch learning,” which uses neural networks to\nrecognize patterns and judge intent behind a question. Their goal was to have\nAI that could guess what kind of code you wanted or needed based upon your\nbrief description. The AI would then put together Java code to respond to your\nrequest, drawing on what it had learned by looking at previously written Java\ncode in the large GitHub depository of code. The Rice project, called Bayou,\nwas funded by the Defense Department and Google. Microsoft was also funding\nwork at Cambridge University in 2018 in which AI was attempting to determine\nhuman intent and then finding or generating the appropriate code. That\nproject, called DeepCoder, is designed to grow from developing a snippet of a\nfew lines for a minor component of a program to gradually tackling larger\ntasks.\n\nAll of this work is still early days of what we believe is the future of\nsecure coding, indeed the future of all code writing. Machine learning,\nespecially if it were ever to be powered by a quantum computer, could\neventually examine vast amounts of existing code and learn enough from that\nprocess to write large-form programming on its own. That is a huge step from\nwhat is going on today with AI writing APIs or snippets of programs, but we\ncan see the path to that outcome.\n\nWhile this sounds exciting and promising, there are still significant issues\nto overcome. For instance, just because a computer can write code doesn’t mean\nit will be secure code. AI/ML is notorious for “unknowingly” incorporating\nbiases based on their models. Think of facial recognition scanners that are\ntrained only on Caucasian faces and then become really good at identifying\ndifferent white men, but think all other races are the same (this actually\nhappens). To this end, the biggest promise is “proven” code. That is code that\nis mathematically proven to be constrained in its execution.\n\nFormal proofs are well known in mathematics, but only beginning to be applied\nat meaningful scale to software. Coq, OCaml, and other proof languages are\ngaining traction. According to Dan Guido at Trail of Bits, the state of the\nart for formally proven “safe” systems is up to about fifty thousand lines of\ncode. That is large enough for microkernels, which are often found in embedded\nsystems, but a long way off from the multimillion lines of code in modern\noperating systems and even individual applications. Yet it’s a start. By\nformally defining and verifying modular components of code, these pieces of\ncode may be used as trusted building blocks, providing strong footing for less\nsecure software running on top of them.\n\nMeanwhile, as we wait for our AI overlords to start writing better code, Zatko\nand his wife, the data scientist Sarah Zatko, have started rating today’s\nsoftware for how well it is constructed. At the request of the White House in\n2015, they set up the Cyber Independent Testing Lab to automate the process of\nrating software quality to, in his words, “quantify the resilience of software\nagainst future exploitation.” They hope to give consumers the ability to\ncompare products and distinguish those that are built with security in mind\nfrom those where security is, at best, an afterthought, and to pressure\ndevelopers to harden their products. By doing so, they would take away the\nlow-hanging fruit from attackers, upping the skill and time necessary to\ndiscover vulnerable products.\n\n### The Pieces Are There\n\nBuried in the three thousand cybersecurity vendors are many of the solutions\nneeded to stop most malicious actors from doing significant damage. Using the\ncloud and security as a service can help simplify some things. The pieces that\nare still missing seem to be coming or could be developed in the next three\nyears or so. Some of those missing pieces include software to write software\n(error-free) and advances in orchestration that can truly bring all security\ndevices together to orchestrate all defensive software. We need a solution to\nthe seeming paradox that there are both too few and too many security products\non the market. There is still a lot of white space on Yu’s Cyber Defense\nMatrix, but there are also too many narrow feature set solutions to specific\ncyber risks, offered by such an incredibly large number of vendors that even\ngiant corporations have a hard time sorting through the technologies,\nselecting best in breed, and integrating them.\n\nLarge corporations, the federal government (still the single largest buyer of\ncybersecurity products), and the VCs could do four things to make it easier\nfor their people trying to defend networks to maximize the benefit of the\nexisting solutions. First, VCs should require new companies to make clear\nwhere they add value in the existing cybersecurity landscape. Every\npresentation should include a slide in each pitch deck requesting funding that\nplaces the new technology in the Cyber Defense Matrix. Buyers of technology\nshould not take meetings with companies that can’t explain where they fit in.\nGoing a step further, product companies should rigorously track which controls\nand regulatory standards they meet or help meet and, where there are no\ndefined control sets for what they do, define them.\n\nSecond, buyers should refuse to purchase technologies that are not designed to\nbe open and plug-and-play compatible. While there are some open-source efforts\nthat may get to Yu’s vision of commodity sensors and actuators, the industry\nneeds to adopt this as the model for how technology gets deployed. We also\nthink that for the midmarket buyer, investors should look at consolidating\ncompanies that can offer full suites of capabilities tailored to specific\nmarkets (think a baby Symantec for health care).\n\nThird, buyers should place pressure on security product makers to up their\ngame in secure coding. If an independent testing lab rates a security product\nas failing to meet basic standards of code hygiene, it should not have a\nmarket. Buyers should insist on security being built into the design of new\nIT-enabled products, rather than letting them be rushed to market only then to\nbe hacked and later modified for security.\n\nFourth, we need to move away from product evaluations done in labs and soft-\nfeature comparison to cooperatively sharing data on product successes and\nfailures. Malcolm Harkins of Cylance has suggested that we need a process for\npublicly sharing data when security products fail to detect incidents, the\nsame way we learn that a faulty sensor was responsible for an aviation\nincident. If Cylance or CrowdStrike or another endpoint detection platform\nfailed to detect a compromise in an incident, that attribution of failure\nshould be made known.\n\nThus, we are left believing that technology itself is not what is lacking to\nrectify the offense-defense imbalance. It is leadership thinking holistically\nabout the nature of the cybersecurity challenge and looking for systemic\nsolutions, cooperation among large enterprises facing similar risks, and an\nawareness in corporate and governmental leadership that cybersecurity is\nexpensive, essential to the operation of any major entity, and demanding of a\ncontinuous and creative whole-company approach. More than anything else, it\nrequires a drastic shift away from the attitude that security is hopeless and\nthat adversaries win as soon as they gain a foothold in your network.\n\n\n## Chapter 6\n\n## CYBER RESILIENCE: THE BEST BAD IDEA WE’VE GOT\n\nThere are only bad options. It’s about finding the best one.\n\n—BEN AFFLECK AS TONY MENDEZ IN _ARGO_\n\nThe attacks started out small. The first wave of distributed denial-of-service\n(DDoS) attacks, at the end of 2011, was just probing and planning, stress\ntesting the capabilities of the world’s largest financial institutions. Over\nthe next nine months, the attacks would occur only sporadically, a day here\nand there, but in September 2012 the frequency and severity of the attacks\nwent up. The websites of U.S. banks such as JPMorgan and Bank of America were\nflooded with traffic on an unprecedented scale, and, oddly, at predictable\nintervals, Tuesday through Thursday from 10:00 A.M. to 2:00 P.M., New York\ntime, as if someone was trying to send a message.\n\nMedia outlets, with the help of unnamed officials in the Obama administration,\nquickly pointed to Iran as the culprit, believing the attacks were a response\nto the Stuxnet malware that had disrupted Iran’s nuclear enrichment program\nseveral years earlier. Phones began to ring throughout the White House West\nWing. At every level from CEO down to CISO, the banks wanted the government to\ndo something to stop the attacks.\n\nThe Obama administration selected a limited response. Rather than escalate\ntensions with Iran by striking back in cyberspace or sending a carrier group\nthrough the Strait of Hormuz, the administration chose to treat the attacks\nlike any other mildly disruptive internet activity. The Department of Homeland\nSecurity coordinated remediation, sending information on the attacking IP\naddresses to ISPs and hosting providers so they could notify the owners of\ninfected accounts to get them to delete the malware and slow the attacks. The\nState Department issued démarches to foreign governments to request their\nassistance in shutting down the attacks. No proverbial missiles were fired in\ncyberspace. The banks were not happy.\n\nNot liking the response they got, the banks took their case to _The Wall\nStreet Journal_. “We’d like them to act,” declared one unnamed bank official.\nBut act how? What this and other unnamed bank officials wanted the government\nto do was to either “block the attacks” or “take down the network of computers\nmounting them.” As simple as these options sound, for both technical and legal\nreasons, the U.S. government did neither.\n\nWhile the DDoS attacks against the banks were allegedly carried out by Iran,\nthe malicious traffic did not stream out of servers located in Tabriz,\nIsfahan, and Tehran, which would have allowed for both easy attribution and\nblocking at national borders. Instead, the attackers commandeered computers\nall over the world, most of them in the United States. Using malware that\nhomed in on vulnerabilities in popular blogging platforms, the attackers had\ngained access to large numbers of accounts on servers at hosting providers,\ncompanies such as GoDaddy or HostGator, and then used their powerful\nprocessors and high bandwidth to generate and deliver attack traffic to the\nbanks.\n\nIn order to “block” this traffic, the U.S. government would have had to be\nsitting in between the attacking computers and the target computers. While\nblocking the attacks sounds appealing, the reality is that the United States\nhas open borders in cyberspace. No agency of the federal government sits at\nthe internet exchange points, where the undersea cables come up onto land, to\ninspect each packet of internet traffic. Without such a capability, the U.S.\ngovernment is simply not positioned to block malicious traffic to protect\nbanks or any other companies. Nor should we want such a system to be built.\nWhile China has a Great Firewall, a vast system of traffic inspection and\ninterception deployed at the borders of China’s internet and throughout the\ncountry, calling the system a firewall suggests, erroneously, that it has\nvalue for cybersecurity when it is in fact a tool for censorship and\nsurveillance. Similarly, a Great Firewall of the United States would be an\nineffective tool for cybersecurity, but a very useful tool for domestic spying\nand censorship, something we as Americans should be concerned about giving to\nour government.\n\nTaking down the botnet through more aggressive means was also not practical.\nDirecting the U.S. military to knock the attacking computers off the network\nwould have meant launching a military operation against targets both in third-\nparty countries such as Germany, Canada, and France, as well as in the United\nStates. It is difficult to fathom the implications of the U.S. government\ntaking such an action (there are still likely lawyers in the bowels of the\nEisenhower Executive Office Building sorting through this). Foreign\ngovernments could reasonably label the activity as an act of war. American\ncompanies and individuals would rightly view it as an unreasonable invasion of\ntheir privacy without due process.\n\nThe attacks continued until May 2013. In the end, the banks were able to keep\ntheir websites up by investing in their information technology infrastructure\nso they had the capacity to service the legitimate requests of customers and\nfilter out or respond to the malicious requests. DDoS mitigation companies\nsuch as Akamai and Cloudflare signed a lot of contracts. While CEOs continued\nto demand that the government make the problem go away, many of their chief\ninformation security officers quietly thanked their friends in government for\nnot doing anything. The attacks got them the money they needed to make\nsecurity investments that were long overdue. In that year’s filings with the\nSecurities and Exchange Commission, not one of the banks listed the attacks as\nhaving a material impact on their business, despite having previously called\nfor the United States to treat them as acts of war.\n\nIf the U.S. government had chosen a more aggressive response, the\nramifications could have been far-reaching. A tit-for-tat escalation with Iran\nwould likely have prevented the nuclear deal achieved two years later. On\ncybersecurity, a stronger response would have settled the question of who is\nresponsible for protecting the private sector in cyberspace in favor of making\nit a government responsibility. That determination would have had far-reaching\nconsequences for the future of the internet.\n\nOver the last thirty years, the U.S. government has worked to get out of the\nbusiness of running the internet, turning over operation of the backbone to\ncommercial providers in 1995. The final piece of transitioning the operation\nof the internet to the private sector took place in the fall of 2015, when the\nCommerce Department ended its contract for the operation of the internet root\nservers, the systems that allow the translation of domain names like\ngoodharbor.net to the 1s and 0s that computers understand. As a nation, we\nshould be hesitant about inviting the government back onto the network.\n\n### A Different Domain, A Different Strategy\n\nPretty much as soon as computers were invented, those who invented them saw\nthe dangers of their misuse. And not long after that, all those involved\nrecognized that protecting computers from malicious actors was going to look\ndifferent from other national security missions. In other domains, national\nsecurity is primarily, if not exclusively, the responsibility of government.\nPrivate companies may build weapons and Americans have variously been asked to\nplant victory gardens, build bomb shelters, and say something when they see\nsomething, but otherwise citizens have had limited roles in confronting\nnational security threats. After 9/11, more than anything else President Bush\njust wanted average Americans to “keep shopping and traveling.” Cybersecurity\nis altogether different. Cyberspace is a largely privately owned domain and it\nis fundamentally about the exchange of information, much of which is meant to\nbe private. Thus, government’s role and the private sector’s role were\ninevitably going to look very different from how they did in other domains.\n\nAs the United States was just beginning to recognize a host of new threats in\nthe post–Cold War era, President Clinton asked Robert Marsh, a retired Air\nForce general, to lead a study on what to do to secure critical\ninfrastructure, including cyber threats. That study, released in 1997, called\nfor the development of a public-private partnership. “Because the\ninfrastructures are mainly privately owned and operated,” Marsh wrote, “we\nconcluded that critical infrastructure assurance is a shared responsibility of\nthe public and private sectors.” Dick Clarke and his team at the NSC reviewed\nthe report and drafted Presidential Decision Directive 63 (PDD 63) in the\nspring of 1998. That document set out the basics of how the United States\nwould approach cybersecurity for the next twenty years.\n\nLike every presidential policy document issued on cybersecurity since, PDD 63\noutlined how a partnership between industry and government to manage cyber and\nother threats to critical infrastructure would work. It called for the\ncreation of the first information sharing and analysis center and set up an\nanalogous organization in government. Each successive administration has\nmodified or added to the policy. President Bush rescinded PDD 63, replacing it\nwith Homeland Security Policy Directive 7 (HSPD 7), and then expanded\ncybersecurity policy with a host of other directives and strategies. When a\nbipartisan group chaired by Jim Lewis at the Center for Strategic and\nInternational Studies made recommendations on cybersecurity for the next\nPresident in the lead-up to the 2008 election, their basic advice was simple:\n“Do not start over.” Once President Obama came into office, he ordered a\nsixty-day review of cybersecurity policy, which largely concluded that the new\nadministration should build on, not replace, what Bush had done. The public-\nprivate partnership needed to be “enhanced” and “evolved,” but would remain\nthe cornerstone of the nation’s cybersecurity efforts. And to the surprise of\nmany in the field, President Trump has also continued to build on his\npredecessors’ work, even going so far as to positively cite Obama-era policies\nand programs in his own executive orders and strategies.\n\nOver twenty years later, the idea of “public-private partnership” and “shared\nresponsibility” are often met with a collective groan from those in the\nindustry. The phrases are soft and well worn, recited in every politician’s\nkeynote address at cyber conventions and packed into the press releases that\naccompany every new policy announcement. As the scope and scale of cyber\nincidents have grown, if we have learned anything it is that government’s role\nin protecting private companies from even the worst nation-state actors is and\nwill remain limited. Part of the struggle with this approach, however, has\nbeen an unwillingness to fully accept its implications. The concepts of\npartnership and shared responsibility have remained fuzzy. Government\nstrategies tend to avoid spelling out precisely how responsibilities will be\nshared because government officials have a hard time telling American citizens\nthat, when it comes to cybersecurity, the buck does not actually stop in\nWashington.\n\nYet, as national-level incidents occur, those divisions of responsibility have\ngrown clearer. Whatever policy documents say (or don’t say), the fundamental\nresponsibility for the protection of the nation’s networked systems falls on\nthe private-sector owners and operators of those systems, with the government\nin a supporting role. In short, private companies must protect themselves. The\ngovernment may provide assistance, but its responsibilities are to do the\nthings that only the government can do, such as investigate crimes, collect\nintelligence, and wage war. Companies are responsible for fending off denial-\nof-service attacks and filtering out malicious traffic. The government will\narrest criminals and level sanctions.\n\nMany on the political right have criticized this approach, arguing that\ncybersecurity is part of national security, the government’s most basic\nresponsibility. It should not be left to market forces or private interests,\nthey argue. Moreover, they say private companies, in the business of making\nmoney, are not properly incentivized to take on this responsibility. They pay\ntaxes to fund national defense and should not be left to protect themselves\nfrom foreign criminals and nation-state actors who wish to do the United\nStates harm. These arguments all seemingly have merit, but they do not lead to\na workable solution for the nation’s cybersecurity. That’s because all of\nthese ideas would be cures worse than the disease. They would destroy more\nvalue than they would protect.\n\nWith all the talk of cyber threats, it is easy to forget that the benefits of\ninternet connectivity are far greater than the risks that come with it. In\ndeveloping an approach to cybersecurity, it is important to stay focused on\npreserving and extending the internet as a platform for increased efficiency,\neconomic transactions, and the exchange of ideas. Any workable approach must\naddress problems in ways that increase the value derived from the network. As\nappealing as it may seem on the surface to have the government step in and\ntake cybersecurity out of the boardroom and off the balance sheet, the costs\nand consequences of an expanded government role would be far worse.\n\n### Can the Private Sector Bear the Cost?\n\nIn the summer of 2014, JPMorgan Chase was hacked. Jamie Dimon, CEO of the Wall\nStreet bank, went on the offensive in the media, defending the company’s\ninvestment in cybersecurity and pledging more. With unusual candor, Dimon\npublicly shared the fact that his company spent more than $250 million a year\non cybersecurity. By any measure, this is a larger number, but the denominator\nis important. JPMorgan is the largest bank in the United States. Its assets\ntotal more than $2.5 trillion. In 2017, income exceeded $24 billion, on\nrevenue of almost $100 billion. How much is too much to protect these assets?\n\nIn judging whether a company is spending enough on cybersecurity, an often-\nused metric is the percentage of spending on information technology compared\nto how much is spent to protect this enterprise. Modern banks, after all, tend\nto look like IT companies on the inside. No other industry has embraced the\nmany digital revolutions with the rapidity of the financial industry. JPMorgan\nspends $10 billion per year on technology and employs fifty thousand\ntechnologists, one in every five of its employees. By comparison, Facebook’s\ntotal number of employees is thirty-five thousand. Google, sixty-one thousand.\n\nTo protect their investment, JPMorgan spends $600 million per year. On a\ndollar-for-dollar basis, JPMorgan spends about 6 percent of its IT budget on\nIT security. Within the field of IT security, that is in the average range. A\ncompany building capability could easily spend more than that in any given\nyear, as could a company with critical assets targeted by advanced actors, as\nJPMorgan clearly is.\n\nIs it too much? Many pundits and politicians have begun to ask at what point,\ngiven the security risks, the internet has caused more problems than it has\nsolved. Simple math suggests that when the cost of securing a network exceeds\nthe value derived from being on that network, it no longer makes business\nsense to be online. We are far from that point.\n\nIn recognition of the cyber threat his company faces, Dimon said that he would\nlikely double the amount that JPMorgan spends on cybersecurity. While spending\nat this level would put the company squarely in the middle of the pack on\nexpenditure, smart investments could allow a company working at the scale of\nJPMorgan to spend less. Poor decisions could require more. Even at half a\nbillion dollars of spending, the investment is worth it because of the\nincredible value unlocked by networked technology. Thus, we return to the\nidea, so seemingly unfair, that the private sector can afford to pick up the\ncost of protecting itself and that government should, unlike in every other\ndomain, take a supporting role.\n\n### The Home Depot Model\n\nWhile many in government may wish to assign primary cybersecurity\nresponsibility to the private sector, actual national strategy is vague when\nit comes to the details of which side is doing what. Many in the cybersecurity\ncommunity (including both of us) gave the Trump administration a certain\namount of credit for building on the work of previous administrations in the\nNational Cyber Strategy released in 2018. As if on cue, the strategy\ncompletely dodged the question of where government’s role ends and the private\nsector’s begins. Instead of clarifying roles and responsibilities, the\nstrategy stipulates that “the Administration will clarify the roles and\nresponsibilities of Federal agencies and the expectations on the private\nsector related to cybersecurity risk management and incident response” at a\nlater date.\n\nWhile the Obama administration never released a formal strategy that spelled\nout the President’s approach to cybersecurity, it did ultimately get more\nprecise about what private companies could expect from government and vice\nversa. The best articulation was in a 2013 speech by Michael Daniel, then the\nPresident’s cybersecurity coordinator, who made clear at the RSA cybersecurity\nconference that private companies are responsible for their own network\ndefense. The government will provide support and do the things that only\ngovernment can do. As Daniel explained, there is a broad spectrum of\nactivities the federal government might take in response to a significant\ncyber incident:\n\n  * DHS, with the support of FBI, NSA, and other agencies, might intensify information sharing efforts and provide technical assistance to companies that are victims of an attack;\n\n  * The State Department might use diplomatic channels to call upon countries to stop this activity;\n\n  * Using other tools, federal law enforcement may investigate, attribute, arrest, and prosecute perpetrators;\n\n  * The FBI or the Secret Service could work through the courts and companies to stop U.S. infrastructure from being used in the attack;\n\n  * The Department of Homeland Security might coordinate with foreign governments to get infrastructure participating in the attack shut down;\n\n  * The executive branch might issue financial sanctions or visa restrictions against foreign hackers involved in efforts to disrupt our networks and critical infrastructure;\n\n  * And if warranted by a cyber incident’s effects, the President might call on the U.S. military to take action.\n\nDaniel’s scenarios can be boiled down into a short list of potential actions\nthat the government could take, including sharing information on threats,\nproviding technical assistance, using diplomatic tools, investigating the\ncrime, using legal action to stop the attack, issuing economic sanctions, and,\non a very bad day, using military force inside or outside cyberspace. None of\nthese response options look like what Daniel framed as the government “riding\nin on a white horse” in response to an incident. The government’s strategy is\nbasically taking a cue from Home Depot: You can do it. We can help. Private\ncompanies remain fundamentally responsible for protecting their own assets and\nsystems.\n\n### The Dangerous Allure of a National Protection System\n\nKeith Alexander is not convinced by this line of reasoning. He is unequivocal\nin his belief that private companies protecting themselves from nation-state\nthreats is not working. Now the CEO of the venture-backed cybersecurity start-\nup IronNet, he works in a suburban office park not far from Fort Meade. The\ncompany’s motto is “The mission continues.” General Alexander is not the only\nperson at the company to come out of the U.S. intelligence community, and it\nis clear that he still thinks about cybersecurity questions in terms of U.S.\nnational security and not shareholder value (likely to the chagrin of his VC\nbackers). “I flipped through this before you arrived,” he told us, dropping a\npocket copy of the Constitution on the table. “It still says that the purpose\nof the Union is to provide for the common defense. There is no parenthetical\nthat says ‘except in cyberspace.’”\n\nAlexander has been making the case that we should no more expect U.S.\ncompanies to defend themselves from Russian cyberattacks than we should from\nRussian nuclear bombers. Writing in the _Financial Times_ with Jamil Jaffer,\nhe notes: “In no other context do we rely on private-sector actors to defend\nthemselves against national-level threats. After all,” he continues, “we don’t\nexpect Walmart or Tesco to put surface-to-air missiles on top of their\nwarehouses to defend against Russian bombers. Yet when it comes to\ncyberattacks, we demand exactly that from JPMorgan and Barclays.”\n\nIt’s a compelling but somewhat flawed argument. Cyberattacks, as disruptive as\nthey are, are not Russian bombers carrying nuclear warheads. Cyberspace is\nalso an altogether different domain than the air through which nuclear bombs\nfall and missiles fly. If we could change the fabric of air to prevent bombs\nfrom falling, or after one bomb has fallen block all others like it, those\nwould be preferable options to either placing missiles on the roofs of Walmart\nor creating a potentially world-ending nuclear deterrence strategy (it was\ncalled MAD for a reason). Moreover, distinguishing between criminal attackers\nand foreign nation-state groups is becoming increasingly difficult, as some\ncriminal groups are every bit as sophisticated as the best nation-state groups\ntoday and are often hired by foreign governments.\n\nBy now, it should be clear to anyone that the Department of Defense is not\nmagically protected from cyber threats. If there are classified capabilities\nthat the Pentagon won’t share with the private sector, nobody should be too\nupset because they don’t appear to work very well. Moreover, the DoD, like the\nbig banks, is benefiting from the large infusion of new technologies from the\nprivate sector. Sharkseer, the Pentagon’s cutting-edge new intrusion detection\nprogram, is in fact an amalgamation of many dozens of different commercially\navailable products. To be clear, Alexander is not calling for government to\ntake over defense. Ultimately, what Alexander seems to be calling for is a\ntighter coupling of industry and government so that intelligence can be shared\nand collective action can be taken. We wholly agree with and endorse that\napproach.\n\nWhile Alexander isn’t actually arguing for a fundamental shift in\nresponsibility, others have. Alan Charles Raul, the former vice chairman of\nthe Privacy and Civil Liberties Oversight Board, makes the case in _The Wall\nStreet Journal_ that “Cyber defense is a government responsibility.” Raul\ndraws an analogy to the creation of the U.S. Navy in response to the threat of\nthe Barbary pirates in 1794, arguing that government similarly has\nresponsibility today, when commerce is threatened by “digital Barbary\npirates.” Raul argues that “Congress and the President must immediately order\nthe Department of Homeland Security, FBI, and Secret Service—and the State\nDepartment—to protect American commerce from attacks, as the Navy and Marines\nprotected U.S. maritime trade off the coast of Tripoli 200 years ago.”\n\nRaul is dismissive of the approach of government partnering with the private\nsector and sharing information, and against a regulatory approach. He falls\nback on the notion of having government inspect internet traffic. He suggests\nthat the federal government should make Einstein, a program run by the\nDepartment of Homeland Security to protect federal agencies, available more\nbroadly.\n\nAs the spate of breaches at federal agencies from the Office of Personnel\nManagement to the State Department indicate, Einstein is no panacea. While the\nname “Einstein” may suggest that it is somehow smarter than other network\ndefense tools, details on the program’s function and operations, as revealed\nin a series of privacy impact assessments that are publicly available, make\nclear the program is simply a combination of commercially available tools that\nmonitor where internet traffic is coming from and going to, detect intrusions,\nand block them using known signatures of malicious activity. The advantage\nthis program has is that it can use classified signatures, thuspossibly\nbringing knowledge of adversary capability and intention derived from\nintelligence collection.\n\nThe idea that government should create a national system to protect the\nprivate sector and that this system should make use of the capabilities of the\nNational Security Agency is not a new one. In fact, the program that houses\nthe Einstein system at DHS suggests a grander scale than simply protecting\nfederal agencies. It is called the National Cybersecurity Protection System.\nIn the Bush administration, most of the focus of the Comprehensive National\nCybersecurity Initiative in 2008 was on the idea of using intelligence to\nprovide an advantage to network defenders. That approach met with limited\nsuccess. If companies want these signatures, they can have them today. In\n2013, President Obama signed an executive order creating a program called\nEnhanced Cybersecurity Services that gives this classified information to\ncommercial service providers to protect their customers. Five years later,\nuptake rates have been low.\n\nOther countries may yet try to make this approach succeed. In countries that\ndo not value privacy and freedom of expression, concerns over the government’s\nability to read communications at will are not an obstacle. In countries where\nprivate companies hold less sway, slower, less reliable internet\ncommunications are less of a concern (though they will no doubt have an impact\non economic competitiveness and foreign investment). Yet for one last reason,\nrelying on this approach is likely to be a mistake: it won’t work.\n\nAs the speed and volume of network traffic increases, the ability to\nmeaningfully inspect it at the internet’s choke points goes down. The\nincreasing ubiquity of encryption makes the task all but impossible, as the\ncontent of traffic is not readily available for scanning. This technical\nreality has put the British government in the ironic position of calling for\ntraffic to move unencrypted, an act that would be counterproductive from a\ncybersecurity perspective.\n\nWhile governments talk about creating national perimeters in cyberspace to\nsecure their nations, as we have noted, industry is moving in the other\ndirection. Perimeter approaches at the company network level (let alone the\nnational level) were declared dead long ago. As we discussed earlier, cutting-\nedge companies in cybersecurity today are doing three things: looking at\ntraffic moving _within_ company networks for signs of malicious activity;\ndetecting malicious activity on individual computers (endpoint detection); and\nmaking product purchases and architecture decisions to favor the defender.\nInitial judgments about whether a packet contains malicious content must be\nmade in the context of the company or organization being targeted, something\nno government agency anywhere in the world is equipped to do. If what is\nrequired to achieve cybersecurity is to monitor internal company traffic, to\nplace software on each individual computer, and to make smart architecture\ndecisions, what role is there for government in this business?\n\n### The Glassiest House\n\nEven before he became national security adviser, John Bolton wanted to blow\nthings up in cyberspace. Always a hawk, Bolton, in what should have been his\ntwilight years, ramped up his rhetoric. In the month before his surprise\nascendance to the White House, Bolton argued forcibly that the United States\nneeded to go on the offensive against Russian, Chinese, and Iranian cyber\nunits. Nobody paid much attention until after Bolton was tapped, when Corey\nBennett, an enterprising reporter at _Politico_ , dug up Bolton’s speeches and\nop-eds and asked the cyber cognoscenti for comment. Once in office, Bolton\nquickly demolished the Iran nuclear deal and tried to derail negotiations with\nNorth Korea with a predictable call for unconditional surrender prior to\nbeginning negotiations. Bolton likes conflict. Having called for the United\nStates to get muscular in cyberspace, he then set about systematically\ndismantling the cyber office at the National Security Council. He sent the\nwell-respected cyber coordinator Rob Joyce back to the NSA.\n\nUltimately, though, weak coordination (or no coordination) at the White House\ncould give Cyber Command a freer hand. Instead of huddling in the Situation\nRoom or meeting via teleconference to organize a whole-government approach to\nan unfolding crisis in cyberspace, now the Pentagon can simply let the\nproverbial missiles fly. Of course, as it turns out, few people in the\nPentagon are thrilled to be unshackled. That’s because no one with any\nknowledge of how cyber offense is conducted thinks that “counter cyber” or\n“defending forward” works very well. The community also worries about the very\nreal potential for blowback.\n\nIn theory, counter-cyber activity might work like this. An Iranian hacking\nunit sipping a Red Bull in a nondescript office complex outside Tehran\nattempts to gain access to an electric utility in New Jersey. Maybe they are\nconducting reconnaissance so they can black out the Northeast in a future\nconflict. Maybe they want to steal the schematics for a new interchange and\nshare them with the utility planners in greater Tehran. Maybe it was Tuesday,\nthey were bored, and their scans turned up an insecure system. Whatever the\nreason, they start hammering away on the log-in for a web server at the\nutility. Perhaps the NSA picks up on this activity in its routine collection.\nPerhaps the utility notices the failed log-in attempts. Either way, the\nIranians have carried out an attack on the United States and it is time to\nfight fire with fire.\n\nOf course, the Iranian hackers didn’t attempt to connect directly from their\ncomputers to the New Jersey utility. Instead, they hid their tracks through a\nseries of hop points. These might be compromised computers in homes and small\nbusinesses. They might have used a commercial or consumer-grade virtual\nprivate network or one of the many censorship circumvention tools designed to\nallow people behind national firewalls to roam the web freely. Or, if they\nwere hip to the latest trends in the cyber-criminal underworld, they might\nhave used a stolen credit-card number bought for fifty cents on the dark web\nto set up an Amazon Web Services account and purchased all the computing power\nthey needed. Chances are, they used several of these techniques to create a\nstring of hop points.\n\nWhat that means for the counteroffense team at Fort Meade (or, in some darker\nfantasies, at the utility) is that hitting the Iranians back just became\npretty complicated. At the very least, the last hop point used to access the\nutility’s server was in the United States. Chances are high that several were.\nThat creates a jurisdictional nightmare that the courts will need to sort out.\nWarrants will need to be issued. The FBI will need to be brought in.\nCertainly, it forestalls the idea of destroying that computer. Before the\ntrail leads to Tehran, it probably winds its way through servers in at least\none other country (after all, Iran does not do much business with the United\nStates). Maybe it leads to computers in our once and future allies Germany and\nFrance. Maybe it leads to a server in our sometimes adversary China. Either\nway, following that trail comes with a boatload of geopolitical risks.\nDropping a “cyber bomb” on those servers is not a viable response, at least in\nthe near term.\n\nIf the legal and diplomatic questions can be worked out, maybe, just maybe,\nthe counter-cyber team can follow it all the way to the laptop resting on the\nknees of the Iranian hacker. Now what? Time is short. He’s about to shut down\nthe virtual machine he is working in and reboot. Should the counter-cyber team\nbrick his device? That will teach him! Oh wait, he’s got a dozen different\ncomputers he works on. Hmmm, you say, maybe we need to ratchet things up.\nLet’s see whether we can take out the power in all of Tehran. That would\ncreate deterrence!\n\nWhile the counter-cyber team is preparing to black out Tehran, its colleagues\non the other side of the wall at Fort Meade have been busy. They think the\nright thing to do is to maintain persistence on the Iranian hackers’ device\nand gather intelligence. After all, destroying a six-hundred-dollar laptop\nwill not hurt the Iranians too much and taking down the power grid in Tehran\nfor a single attempt to gain access to a server in New Jersey would not\nactually be proportional. Better to know what the Iranians are doing than to\ndo virtually nothing to stop them and, in so doing, go blind. The utility in\nNew Jersey might have made a different decision, of course. If unshackled from\nthe laws that prohibit hacking back, it might very well have decided it needed\nto do something punitive. Private companies escalating in the cyber arena\ncreate the likelihood that they will start a war that the United States\nmilitary will need to finish.\n\nRecognizing both that current law prohibits any form of private-sector\nactivity on a company’s own network and that companies have a legitimate\ngripe, Congress has tried to craft a law. A proposed law, the Active Cyber\nDefense Certainty Act, is, in fact, quite sensible, to the point that it makes\nsuch operations totally unworkable. Under the proposed act, companies wouldn’t\nbe allowed to do anything destructive or retaliatory, but they could “hack\nback” to establish attribution and find out what was taken. Before a company\nwent off its own network, it would need to notify the FBI’s National Cyber\nInvestigative Joint Task Force. The company would have to share what type of\nbreach occurred, who the company would combat with its active defense measure,\nhow it is preserving evidence for further investigation, and what steps it is\ntaking to minimize harm to third parties. All that would give it a “defense”\nagainst charges of violating the Computer Fraud and Abuse Act, but not\nimmunity from it. In the circumstances where intelligence collection or\ntactical or retaliatory action is called for, it is likely a better idea for\ncompanies to rapidly pass off information on the incident to government and to\nhave government take those actions when it is in the national security\ninterest. There are limits to the value of offense and dangers in overrelying\non it.\n\nMichael Sulmeyer, a senior cybersecurity policy official at the Pentagon in\nthe Obama era, has a neat way of summing up the problem with looking to\noffense as the solution to the cybersecurity dilemma. On the speaker’s circuit\nwhile at Harvard’s Belfer Center, he would break down the problem in a\nstraightforward manner. “We all know the old saying ‘Those who live in glass\nhouses shouldn’t throw stones.’ Well,” he would continue, “let’s just assume\nthat in cyberspace the U.S. government has the best stones, the sharpest, the\nshiniest stones, really great stones. But let’s also recognize that we live in\nthe glassiest house. So sharpest stones, glassiest house. Will we really care\nthat we can send our supersharp, awesome stones through somebody else’s window\nwhen they can throw a cinder block through our glass house?” Usually, that\nended the desire of anyone in the audience to argue that hitting back in\ncyberspace should be a major part of the solution.\n\n### Gaining Leverage\n\nMany historians have tried to come up with theories to predict why wars begin,\nbut perhaps the one with the greatest explanatory power is offense-defense\ntheory. In his classic _The Causes of War,_ Stephen Van Evera of MIT offers\nconvincing evidence that the question of whether offense actually has an\nadvantage over defense is not as important as whether aggressors believe that\nthey have an advantage. On the eve of World War I, combatants widely believed\nthat the ability to move troops around rapidly on rail gave an advantage to\nthe offense, not realizing the reality of the trench warfare to come, where\ndefending machine-gun nests would cut down advancing troops by the millions.\nAllan Friedman and Peter Singer argue that the belief in a first-strike\nadvantage is as misguided today in cyberspace as it was on the eve of the\nFirst World War.\n\nAs they point out, significant attacks require high levels of expertise and\nmay require months if not years of planning. The outcomes may be difficult to\nachieve, hard to predict, and possibly unknowable. And, of course, there is\nsome small risk that you will be caught and arrested or at least kept from\never traveling outside the authoritarian states that give you shelter.\nThinking along these lines, shifting the advantage decisively to the defender\nwill require increasing the work factor for the attacker; increasing the skill\nlevel necessary so that it is harder to gain a foothold, as it were, in the\ncyber-criminal world; increasing the uncertainty around success; and\ndecreasing the rewards and increasing the risks of engaging in cyberattacks.\nWhen a group of Wall Street security executives thought about how to achieve\nthese outcomes, they realized they needed to borrow an idea from the\nmoneymakers on the trading floors: leverage.\n\nFor over a generation, the center for cybersecurity policy has been\nWashington, D.C. That makes sense for most policy issues because Washington\nis, after all, the seat of government. And so, when the people who write task\nforce reports on various topics assemble, they usually do so at a D.C.-based\nthink tank like the Brookings Institution or the Center for Strategic and\nInternational Studies. Cybersecurity, as we are learning, is different. If the\nmain responsibility for cybersecurity falls to the private sector, then\nfiguring out a path forward might better be done in the seat of business, not\ngovernment. Thus, the New York Cyber Task Force was born.\n\nPhil Venables and Greg Rattray are both longtime fixtures in cybersecurity\npolicy circles. Venables, a computer scientist by training, has spent his\ncareer in security at banks and has been at Goldman Sachs for close to twenty\nyears. Rattray, a political scientist by training, is a retired Air Force\ncolonel who had a hand in many if not most of the early efforts to combat\ncyber threats at the Pentagon and at the White House. Rattray is now a senior\nexecutive at JPMorgan. To the problem of cybersecurity, Venables brings a deep\nunderstanding of what it takes to protect an enterprise in cyberspace;\nRattray, who has, among other things, advised ICANN on security, thinks about\nsecurity from the perspective of the internet as a war-fighting domain and a\nglobal ecosystem. Together with the dean of the School of International and\nPolicy Affairs at Columbia, Merit Janow, they conceived of the task force. To\nrun it, they could think of only one person.\n\nWe meet with Jason Healey in his office at Columbia University in the\nMorningside Heights neighborhood of Manhattan. It’s on the thirteenth floor\nand his office number is 1337. Asked whether he got that office and number\nassigned to him at random, Healey is somewhat coy. If you invert “1337” it\nlooks somewhat like the word “LEET,” hackerspeak for someone who is “elite.”\nHealey, who is quick to say that he is not a hacker, is certainly elite in the\nfield of cyber policy. His office is filled with well-worn copies of every\nbook ever written on cyber warfare. On the back of the office door is hung a\nspeaker hoodie from Black Hat, and there are about fifty lanyards with speaker\nbadges from DEF CON, RSA, and other top cybersecurity conferences.\n\nHealey has spent his whole career in the cyber domain. He went to the Air\nForce Academy intending to be a fighter pilot, but realized pretty quickly\nthat he didn’t have the eyes or reflexes to fly in combat. He turned down his\npilot training slot and went into intel, where he got his last choice for\ntraining, in Signals Intelligence. That turned out to be a good thing because\nU.S. Air Force Signals Intelligence was at the leading edge on cybersecurity\nin the 1990s. His early exposure had come from the Morris Worm, the Cuckoo’s\nEgg, and the Solar Sunrise incident. (Healey is steeped in this history and\nhas written _A Fierce Domain,_ the definitive book on these incidents.) Hired\nby Venables at Goldman to be its first computer emergency response team (CERT)\ncoordinator in 2001, Healey became immersed in defense of the corporate world.\nRattray, then director for cyber threats in the defense directorate on the\nNational Security Council staff, recruited Healey to be his counterpart on the\nHomeland Security Council. After his two-year stint was up, Healey returned to\nthe private sector, working again for Venables at Goldman and then later with\nRattray at a consulting firm. For a brief stint at the Atlantic Council he\nworked with neither of them, but once at Columbia he was again with the two\npeople who had done the most to shape his career.\n\nHealey’s academic focus at the Atlantic Council had been on how to get defense\nbetter than offense. Venables had, in the corporate world, been looking at the\nsame problem. His obsession was how to improve security by, in his words,\n“decreasing the cost of control” within the enterprise. How can you automate,\ntake the user out of security, create efficiency, and keep resources for what\nmatters? Coming from a national security perspective, Rattray took a broader\nview of the entire ecosystem. Healey remembers Rattray asking questions in the\n1990s that no one else in the military did, such as “What is the failure mode\nof the internet?”\n\nLooking at a chart from _The Economist_ on the most effective ways to combat\nclimate change, Healey thought what was needed was a similar list for\ncybersecurity. He sent out an email asking colleagues for examples of what had\nmade the biggest difference in helping defenders regain the advantage in\ncyberspace. Once the task force started its work, he continued to drill down\non the list, eventually producing about 115 innovations in technology, policy,\nlaw, and operations that would have shaved off some of the attacker’s\nadvantage. Policy changes such as safe-harbor provisions for sharing cyber-\nthreat data among competitors despite antitrust concerns made the list, as did\ntechnical innovations such as the growing ubiquity of encryption and hardened\noperating systems.\n\nStepping back from a fold-out chart of the list taped to the wall in his\noffice, Healey is still stunned by all the white space where other solutions\nshould be. “In this field, we all know that the defense operates at a\ndisadvantage. What’s remarkable,” he continues, “is how long we have known\nit.” Healey quotes Lieutenant Colonel Roger Schell from memory. Schell, when\nhe was at the NSA, developed the Rainbow manuals that guided early cyber-\ndefense operations. “Few if any contemporary security controls can stop a\ndedicated team from accessing information sought.” Schell wrote that in 1979.\n“Nineteen seventy-nine!” Healey yells. “We have known this for forty years and\nhaven’t been able to do anything about it. . . . I used to say that the cyber\ndefense was the Chicago Cubs of the internet, but now nobody has as long a\nlosing streak as we do.”\n\nYet, as we have noted, there are signs that the attacker’s advantage is\neroding. What we need to do now is collectively make investments that will\nfurther erode that advantage. The members of the New York Cyber Task Force\nconcluded that leverage should be the cornerstone of our national strategy,\nthat the collective efforts of public- and private-sector partners needed to\nbe focused on those factors that could most dramatically shift the advantage\nfrom the attacker to the defender. While we view the concept of leverage as a\nkey component of cyber strategy, it is a means to an end, not the end itself\n(the end being resilience). Still, the recommendations that the task force\nmade provide a road map for building resilience. On the corporate level, they\nrecommend (as we do) improving governance, embracing the cloud, investing in\nsecure software, and automating as much cyber hygiene as possible. For\ngovernment, they want agencies to focus on aligning market forces to promote\nsecurity by harmonizing regulation, promoting transparency, and creating\nincentives for cybersecurity, such as federally backstopped insurance and\nfunding for research and collaborations that the market will not fund. Of\ncourse, all of this is easier said than done.\n\n### Only Bad Options\n\nIn the movie _Argo,_ Ben Affleck as CIA operative Tony Mendez leads a mission\nto smuggle six State Department employees out of Iran after the fall of the\nembassy in 1979. Mendez came up with a plan to disguise the employees as a\nCanadian film crew filming a fake _Star Wars_ knockoff. In the movie, based on\na true story, we watch Affleck pitch the idea to Philip Baker Hall as CIA\nDirector Stansfield Turner and Bob Gunton as Secretary of State Cyrus Vance.\nBoth government officials are shown to be skeptical. After running through the\nother escape plans that the agency considered and rejected, Affleck levels\nwith his superiors: “There are only bad options. It’s about finding the best\none.” Hall as Turner deadpans, “You don’t have a better bad idea than this?”\nBryan Cranston, playing Tony Mendez’s fictionalized boss, delivers the closing\nargument: “This is the best bad idea we have, sir—by far.” With that, the\nmission is approved.\n\nWhile a fictional account, the approval process as depicted in the movie rings\ntrue to many people working policy in Washington. There are never any good\noptions. If there were, we would not need the apparatus we have developed for\nmanaging the national security of the United States. Instead, it is always\nabout finding “the best bad idea.” All national security decisions are about\nmaking trade-offs, nowhere more so than in cybersecurity, where every policy\nchoice has the potential to impact our economic prosperity and our most\ncherished values of freedom of speech, freedom of expression, and the right to\nbe free from unwarranted search and seizure.\n\nCyber resilience, prioritizing network defense and making the private sector\nbear the costs of absorbing these attacks is, at first blush, an unappealing\nprospect to most CEOs. After all, as General Alexander points out, the first\nresponsibility of the federal government is to provide for the common defense.\nYet every time policy makers unpack how government could take on this\nresponsibility, private-sector enthusiasm quickly begins to fade because of\nthe unintended consequences of government involvement. On cybersecurity, there\nare only bad options. Private responsibility for network defense with\ngovernment support is the least bad one. To get private companies to build\ntheir own resilience (and therefore the resilience of the nation and of\ncyberspace), a series of mechanisms is necessary. Sometimes corporations need\na little nudge. And sometimes they need a big shove.\n\n\n# PART III\n\n# THE GOVERNMENT’S SUPPORTING ROLE\n\n\n## Chapter 7\n\n## NUDGES AND SHOVES\n\n## The Government in Corporate Cyberspace\n\nAs they commit to this activity, the Federal Government can and will help\nthem, in the spirit of a true public-private partnership. The Government will\nnot dictate solutions and will eschew regulation.\n\n—NATIONAL PLAN FOR INFORMATION SYSTEMS PROTECTION, THE WHITE HOUSE, 2000\n\nBy the start of the Obama administration, it was clear to many in government\nand on the Hill that market forces alone were not driving the private sector\nto protect the nation’s vital systems against sophisticated criminal groups\nand foreign nations. So, with support from Democrats in the Senate, in May of\n2011, the White House delivered to Congress a comprehensive legislative\nproposal that would have granted the Department of Homeland Security authority\nto regulate critical infrastructure for cybersecurity, from oil and gas\ncompanies to stadiums.\n\nIndustry was not supportive. The U.S. Chamber of Commerce quickly made it its\nmission to kill the bill and succeeded, arguing that with the economy still\nfragile after the financial crisis a few years earlier, regulating\ncybersecurity would hurt one of the few sectors of the economy that was\nthriving: information technology. They espoused the mistaken view that\ncybersecurity regulation would stifle innovation and was a jobs killer. In\ncase the message wasn’t clear, the Chamber of Commerce hung giant banners\nbetween the pillars of its headquarters, which faced the White House across\nLafayette Square, that spelled out J-O-B-S. The idea alienated many of the\ntech executives who had donated both money and technical talent to elect the\nPresident. As the legislative proposal failed to gain support on the Hill, by\nthe summer of 2012 the administration quietly began to plot a different\napproach.\n\nAt that time, cybersecurity nominally fell under John Brennan, the deputy\nnational security adviser for Counterterrorism and Homeland Security (and\nlater CIA director). Brennan, by his own admission, mostly focused on the\nfirst half of his title, the administration’s Catholic conscience on the\ntargeted killing of terrorists. He delegated most of the Homeland Security\nmission on a day-to-day basis to his deputy, Heidi Avery. Avery is not a\nhousehold name by any measure. A career intelligence official, she managed to\ncoordinate the Obama administration’s response to Deepwater Horizon and a\nseries of major natural disasters without raising her profile above a single\nblog post. And so, in her stealthy way, so as not to undermine what was now a\nlong-shot effort to get the legislative package through Congress, Avery\nquietly assembled a small team to see which elements of the legislative\nproposal the President could accomplish through executive action.\n\nExecutive orders allow the President to direct agencies to take actions that\nalign with existing laws. The CSIS commission report, “Securing Cyberspace for\nthe 44th Presidency,” had suggested that the President draw on existing\nregulatory authority, such as the EPA has over water systems or DHS has over\nchemical plants, to regulate for cybersecurity. Avery asked staffers in the\nNSC cyber office to pursue this strategy. They didn’t expect that the idea of\nregulating for cybersecurity would meet resistance within the administration.\n\nAny regulation issued by a federal agency gets reviewed by the small but\npowerful Office of Information and Regulatory Affairs. OIRA is housed inside\nthe Office of Management and Budget in the ugly, 1960s-era New Executive\nOffice Building, directly north of the Eisenhower Executive Office Building\nthat houses the NSC staff. Pennsylvania Avenue was seemingly a dividing line,\nwith the national security team on one side advocating regulation and the\nChamber of Commerce and OMB on the other, dead set against it.\n\nWhen the NSC team went to meet with OIRA to get them on board with the idea of\nissuing an executive order to expand regulation on cybersecurity, the response\nthat they got was lukewarm.\n\nJasmeet Seehra, a career official and experienced Washington hand, was\nsurprised that, after failing to get a bill passed because it had been labeled\na job killer, the President would sign on to using his authority to\nunilaterally expand regulation. Unemployment was still hovering around 8\npercent. “I know it’s none of my business,” the career official said, “but you\nguys remember it’s an election year, right?” Instead, she suggested, might\nthey think about a “nudge”? No one in the room had any idea what she was\ntalking about. She pulled out a copy of a book called _Nudge: Improving\nDecisions About Health, Wealth, and Happiness,_ and suggested they do some\nreading. The book was coauthored by her boss, Cass Sunstein.\n\nSunstein, a Democrat, was not necessarily a fan of regulation. A former\ncolleague of President Obama’s at the University of Chicago Law School,\nSunstein had advocated for simple but not always popular ideas, such as\nsubjecting regulation to cost-benefit analysis. With the economist Richard\nThaler, Sunstein had written _Nudge,_ arguing that government may be more\neffective when it shapes voluntary action rather than when it sets mandatory\nrequirements. On his first date with his future wife and former UN ambassador\nSamantha Power, he told her his dream job was to run OIRA and implement these\nideas.\n\nThe nudge the NSC team came up with was the NIST Cybersecurity Framework,\ndiscussed in chapter 3. It was meant to spur voluntary efforts by private-\nsector companies to defend their own infrastructure and, most agree, was\nlargely effective at doing that. The National Strategy for Trusted Identities\nin Cyberspace, which we will discuss in chapter 8, was a nudge to get industry\nto solve the long-standing problems that keep things like health records from\nbeing brought online and make it burdensome to carry out certain financial\ntransactions. Urging industries to create their own mutual information sharing\nand analysis organizations was also a nudge.\n\nAll of these nudges contributed to some corporations improving their\ncybersecurity, and there are many more nudges that government should consider,\nbut to get companies to perform critical roles in our economy to the level of\ndefense that is now possible, they may need to be pushed a bit harder. Let’s\ncall it a shove. We think it’s time to reopen the regulation debate and to\nthink anew about how the government should be interacting with the private\nsector to further erode the offense’s remaining advantages.\n\nEvan Wolff is one of the leading cybersecurity attorneys in Washington. What\nthat means is that by day he helps his clients respond to cyber incidents,\nincluding directing investigations and advising on notifications under state,\nfederal, and international requirements. By night, as a former MITRE data\nscientist and Global Fellow at the Wilson Center, he thinks and writes about\nhow his clients can mitigate the threat of cyber incidents in the first place,\nincluding what can be done to build an effective collective defense. From\nexperience, Wolff recognizes that only rarely would the teams behind security\nincidents stop at nothing to reach their targets. In fact, the forensics\nusually shows that the basic blocking and tackling of cybersecurity was not\ndone, making it easy for the attacker. Fundamentally, what Wolff sees as\nmissing isn’t any one or group of security controls, it’s an economic model\nthat would force companies to take on the full societal cost of poor\ncybersecurity, along with better coordination with federal and industry\npartners. In the language of economics, we need to make companies “internalize\nthe externalities” of protecting data, protecting networks, and establishing\nsecure communications, says Wolff. “Until we internalize those externalities,”\nhe believes, “we aren’t going to begin to get the industry part of the\ncollective defense down.”\n\nContrary to the current political dogma, regulation doesn’t kill innovation,\nit can create it. When markets are not valuing what we as a society want them\nto value, regulation can create whole new markets. The common refrain from\nindustry is that regulation can’t possibly move fast enough to keep up with\ninnovation. We can find many examples where twenty-year-old security standards\nare still applicable and still have yet to be broadly implemented. We also see\na growing reluctance to use digital products and services by consumers and\nbusinesses because of security risks.\n\nThe tide seems to be turning on this issue. Twenty years ago, when President\nClinton released the first national strategy on cybersecurity, it “eschewed”\nregulation. Three years after that, the Bush strategy took largely the same\nstance. The Obama administration, as we’ve seen, pulled a regulatory proposal\nafter the Chamber of Commerce went on a jihad to stop it. And yet, as the\nlosses start to mount in cyberspace, the Trump administration’s cyber strategy\nwas silent on the topic of regulation. Surprisingly, the Department of\nHomeland Security’s 2018 cybersecurity strategy actually said it would use its\nregulatory authority: “DHS must, therefore, smartly leverage its regulatory\nauthorities in tailored ways, and engage with other agencies to ensure that\ntheir policies and efforts are informed by cybersecurity risks and aligned to\nnational objectives to address critical cybersecurity gaps.”\n\nSmartly leveraging existing regulatory authorities in tailored ways is exactly\nwhat government should be doing. What doomed the Obama legislative proposal to\nfailure was a bid to centralize all regulation of cybersecurity at the\nDepartment of Homeland Security, instead of taking the sector-by-sector\napproach advocated by the bipartisan group behind the CSIS commission. In that\napproach, DHS would regulate only the sectors it already has responsibility\nfor, such as the chemical, pipeline, and maritime industries, leaving other\nsector-specific agencies that understand their industries to regulate them.\n\nAlthough Clinton, Bush, and Obama eschewed, rejected, or declined to establish\na federal cybersecurity regulatory regime, there is a mountain of\ncybersecurity regulation created by federal agencies. Banks, nuclear power\nplants, self-driving cars, hospitals, insurance companies, defense\ncontractors, passenger aircraft, chemical plants, and dozens of other private-\nsector entities are all subject to cybersecurity regulation by a nearly\nindecipherable stream of agencies including the FTC, FAA, DHS, DoD, FERC, DOE,\nHHS, DOT, OCC, and on and on. Variation in federal regulations should be a\nresult of conscious policy choices, not the incremental accretion of rules\nwritten at different times with little central guidance. It is time to step\nback and assess which of these agencies and regulations have been effective.\n\nWhat we would like to see is either a comprehensive law passed by Congress or\nan executive order issued by a President. Where regulations are purposefully\ndifferent to address specific industries, that is the intelligent, nuanced\napproach. When regulations differ because regulators have not consulted with\none another, that is mismanagement. Eating up greater and greater percentages\nof security spending with duplicative regulatory compliances is in nobody’s\ninterest. For companies with multiple regulators, a streamlined process for\nverifying compliance, not just for eliminating duplicate requirements, is\nnecessary. The financial sector has been developing a good model for how to\ncoordinate oversight with the Federal Financial Institutions Examination\nCouncil.\n\nThe law or order would establish basic cybersecurity regulatory principles and\nbest practices for federal regulators, as well as just enumerating what\nregulations exist. Among the best practices could be guidelines for such\npolicy issues as accountability, audits, incident reporting, government\ninformation sharing, bug bounties, identity and access management, third-party\ncode security reviews, continuous monitoring, public notifications, supply\nchain security, and personnel certifications. Above all else, though, the key\nprinciple that needs to be followed is that regulations need to be outcome-\nbased, by telling regulated entities what they need to achieve, not how to do\nit.\n\nIn other areas, we have done this before. After 9/11, when experts worried\nabout other ways that terrorists could use our infrastructure against us as\nweapons, as al-Qaeda had done with airplanes, many people focused on the\nchemical industry. Massive volumes of highly toxic chemicals were stored all\nover the country, often in close proximity to population centers. Through the\nChemical Facility Anti-Terrorism Standards (CFATS), the Department of Homeland\nSecurity worked in partnership with industry to develop a program that\nfundamentally reduced the risk to the American people. It did not mandate that\nfacilities relocate or switch to safer production methods, but it had the\neffect of causing companies to make those decisions. If by necessity you must\nstore toxic chemicals in downtown Boston, then the program mandated that you\nimplement security at such a level as to thwart an attack on the facility by\ntrained terrorists. Instead of hiring paramilitary forces and hardening their\ncomplexes, most companies chose (wisely) to relocate or switch processes.\n\nIn the nuclear reactor domain, outcome-based security is achieved through the\nuse of a design basis threat (DBT). While the details of what makes up the DBT\nused by the Nuclear Regulatory Commission are classified, the basic idea is\nthat nuclear facilities need to be able to detect and delay an adversary\ncomposed of a certain number of actors with a certain type of skills bearing a\ncertain set of weapons and tools. Replicating this model would be\nstraightforward for cybersecurity, where red teaming is a well-established\npractice. One effective regulatory approach might be for government agencies\nto certify the capabilities of red teams and then for those red teams to\nconduct tests of companies.\n\nOne of the best examples of how to do outcome-based regulation is already\nbeing intelligently applied to combating cyber threats. Regulation E of the\nElectronic Funds Transfer Act requires that banks reimburse consumers for\nfraud losses. Contrary to popular belief, it’s not that your checking account\nis insured by the Federal Deposit Insurance Corporation that keeps you from\nbeing liable for fraudulent charges. Instead, the banks must accept those\ncosts. Originally established when check fraud was the dominant way criminals\ntook money out of the financial system, the rule works equally well now that\nthreats have mostly morphed into online account compromise.\n\nWe think, as a basis, mandatory breach disclosure is a start. In some version\nof a truth and reconciliation commission process, companies should be required\nto disclose all losses of intellectual property going back ten years. Moving\nforward, the Securities and Exchange Commission should establish a process to\nadjudicate public disclosures in a timely manner so that investors are made\naware when the intellectual property they are banking on may be used by\nforeign competitors.\n\nBreach disclosure alone has not had the hoped-for effect of preventing\npersonally identifiable information (PII) from being stolen. Equifax, after\ndisclosing the largest data breach in U.S. history in 2017, recovered its\nstock price in less than a year. We think it is necessary that the fines for\nlosing PII be significant enough to make companies think twice about storing\nthat data.\n\nThe Ponemon Institute, a cybersecurity think tank, puts the cost of a data\nbreach at $141 per lost record. Those costs, incurred through disclosure,\nclass-action lawsuits, state-level fines, and improved security, have not been\nsufficient to get companies to make the necessary changes in operations and\ninvestments to prevent such losses. If, instead, companies knew with certainty\nthat they would be paying, say, $1,000 for every record they lost, that would\nbegin to align incentives.\n\nThe prospect of high fines may still mean that many companies will simply\nchoose to take their chances and accept that if they are breached they will\nlose it all. Trying to force companies with bad cybersecurity out of business\nshould not be the goal. Nonetheless, we think companies should have to prove\nthat they have the resources to pay those fines.\n\nCongress should steal an idea from environmental policy by requiring companies\nthat store PII to purchase bonds that would cover the full societal costs of\nthe loss. Oil tankers operating in U.S. waters must have a Certificate of\nFinancial Responsibility issued by the U.S. Coast Guard National Pollution\nFunds Center showing that the vessel’s owner has the financial resources to\ncover the cost of cleaning up a spill.\n\nSuch massive policies mean that the underwriters are going to want near\ncertainty that they will never be paid out. Thus, we now have double-hulled\nships and other improvements that have made spills such as the _Exxon Valdez_\na thing of the past. If we treat data like oil spills and require companies to\ncover the full societal costs of losing data, the market will do the rest by\nensuring that spills of data become exceedingly rare.\n\nThese diverse regulatory models could be applied differently depending on the\nsector and the harm that government is trying to prevent. We are certain,\nhowever, that the blanket conclusion that regulation is anathema to innovation\nis wrong, that voluntary collaboration can be enhanced by a regulatory\nbaseline, and that a lack of security is holding us back from fully benefiting\nfrom the digital revolution.\n\n### If Washington Won’t Regulate, States Will\n\nWhile successive federal administrations have shied away from coherent and\ncoordinated cyber regulations, while various federal agencies and departments\nhave developed their own regulations covering the cybersecurity of specific\nindustries, while Congress has remained largely in gridlock on cyber\nregulations, state governments have acted.\n\nCalifornia has required since 2012 that businesses have cybersecurity\nprograms, and in 2016 its attorney general, Kamala Harris, concluded that\nfailing to implement the Center for Internet Security’s Critical Security\nControls “constitutes a lack of reasonable security.” (The CIS recommends\ntwenty specific areas for controls.) In September 2018, Governor Jerry Brown\nsigned SB-327, requiring that by January 1, 2020, manufacturers of devices\nsold in California must implement “reasonable” security features. Given that\nCalifornia’s economy is the fifth largest in the world, that will mean that\nmost device makers will be compelled to comply with the new law.\n\nNot to be outdone, other states have pursued cyber regulations. Ohio enacted\nlegislation in 2018 that provides protection for businesses against tort suits\nfollowing a successful cyberattack that obtained personally identifiable\ninformation if the corporation had a cybersecurity program based on the CIS\nCritical Security Controls and the NIST Cybersecurity Framework (so-called\nsafe harbor). New York’s Department of Financial Services (DFS) Regulation 500\nhas since 2017 applied to foreign banks, state-chartered banks, insurance\ncompanies, and other financial entities, requiring a cybersecurity program, a\nqualified chief information security officer, multifactor authentication,\nencryption, application security, supply-chain vendor review, asset inventory,\nand continuous monitoring or annual penetration tests. It also recommends the\nNIST Cybersecurity Framework and requires an executive to sign off for the\nefficacy of the company’s cybersecurity plan.\n\nSome of these state regulations are commendable ways of guiding recalcitrant\ncorporations to the minimum essential steps to protect themselves, their\ncustomers, and the general health of the cyberspace on which we all rely.\nUnfortunately, many of the laws vary significantly on important issues such as\nwhen there is a legal requirement to notify the customer or the government\nabout a possible hack. The multiplicity of varying state regulations combined\nwith the numerous federal rules does provide corporations and their lobbyists\nwith grounds for complaint that it is all just too hard and expensive to\ntrack, understand, and implement.\n\nIf ever there was an example of interstate commerce it is the modern\ncorporation’s information technology network. With the exception of small\nbusinesses, corporate cyber activity is almost always multistate, involving\ndistributed offices, data centers, IT vendors, and customers. Thus, there is a\ngood case for creating superseding and uniform federal regulation. There are\nonly two problems: Congress, which is hyperpartisan and concerned about\ncommittee jurisdictional fiefdoms within each house; and the lobbying groups\nsuch as the U.S. Chamber of Commerce, which blindly and in a knee-jerk manner\noppose any new cyber regulation with the erroneous mantra about stifling\ninnovation.\n\nUntil the Congress and the lobbyists can begin to act in the national\ninterest, there is the risk that any new uniform federal regulations they\nmight pass would actually water down some state laws and be less effective.\nThus, we may, for now, be better off with progressive states such as\nCalifornia and New York writing rules that end up being de facto national\nstandards because most major companies fall under their jurisdiction.\n\n### Getting Some Backbone\n\nWe have been arguing in this book that corporations can now achieve a fairly\nhigh level of cybersecurity if they spend enough, deploy state-of-the-art IT\nand cyber solutions, and adopt the right policies and procedures. Even the\npower grid, government agencies, and the military could achieve enhanced\nsecurity. However, in the unlikely event that all of that happened, we would\nstill have a problem.\n\nA foreign nation-state could still cause a high degree of chaos by attacking\nthe backbone of the internet itself, rendering it useless or at the very least\nonly sporadically available. Without the internet, few other pieces of the\neconomy would work. The three remaining problems are, naturally, described by\nthree acronyms: DDoS, DNS, and BGP.\n\nIn the attacks against the banks, the Iranians used a distributed denial-of-\nservice attack. In the more recent attacks, variants of the Mirai bot used\nthousands of surveillance cameras as platforms to flood the Domain Name System\n(DNS) and disrupted large parts of the internet. A worse DDoS can easily be\nimagined and executed, effectively knocking off-line key infrastructure by\nflooding internet connections. At a certain level of flood, the companies that\nspecialize in stopping DDoS attacks, such as Akamai and Cloudflare, will be\noverwhelmed.\n\nIf, as in the case of the Mirai bot, the flood is directed at specific DNS-\nrelated IP addresses and at certain companies that specialize in outsourcing\nDomain Name System look-up services, then that key part of the internet\nbackbone will not work and it will be impossible for some users to find their\nway to web pages, for some email to reach its intended recipient, or for some\nof the countless networked devices in our homes and offices to function. Mirai\nwas a relatively small attack compared to what could happen.\n\nWhile the DNS tells your email message or the server supporting your browser\nwhere to go on the internet (or on your corporate intranet) to find the\naddress you are looking for, there is a completely different system used by\nthe internet service providers who own and operate the big fiber-optic pipes\nthat are the backbone of the internet. That system, the one that tells Verizon\nor AT&T how to route a message to get to a server that is not on their own\nnetwork, is called BGP (it means Border Gateway Protocol, but just say BGP\nlike everyone else). BGP is still the biggest security flaw in the internet,\neven twenty years after Mudge Zatko testified that he and the other members of\nthe L0pht could take it down in thirty minutes.\n\nThink of the BGP as like the Waze app. It tells internet traffic what the\nroute is to get from where it is to where it wants to go. If you get onto the\ninternet by connecting to Verizon in the United States and you want to read a\nweb page of the Australian Football League that is on a server in Australia\nthat connects to the internet by using the local ISP Telstra, Verizon will\nconsult the BGP tables. There they will find the routing to the football club.\nIt may be from Verizon to AT&T to Telstra.\n\nThe problem is that essentially any internet service provider in the world can\ncontribute to the BGP. So, what if China Telecom posted on the BGP table that\nthe Aussie football server was actually on their network? Then your computer\nwould connect to China Telecom while looking for Australia. And that is what\nhas been happening.\n\nAccording to Chris Demchak of the U.S. Naval War College and Yuval Shavitt of\nTel Aviv University, China Telecom has been messing around with the BGP\ntables. For instance, in February 2016 and for six months after, all traffic\nfrom Canada to South Korea was misrouted through China. In October 2016, some\ntraffic from the United States to Italy went through China. In April 2017, the\npathway from Norway to Japan was altered to go through China. In July 2017, it\nwas the connection from Italy to Thailand. You get the picture.\n\nWhile traffic is going through China, that traffic (emails, for example) can\nbe copied or sent into a black hole. The Chinese are not alone. Russia and\nother countries have also been regularly redirecting internet traffic that was\nnot supposed to go through them. Iran has been grabbing traffic for secure\nmessaging apps such as Signal. While such messages are encrypted, the “To” and\n“From” metadata could be interesting to the Iranian secret police.\n\nChina Telecom’s attempts to redirect traffic through China is greatly aided by\nthe fact that it operates eight internet points of presence (PoPs) inside the\nUnited States and has its own West Coast fiber running from Hillsboro, Oregon,\nto Morro Bay, California. Needless to say, AT&T does not have PoPs in China,\nnor cables running from Shanghai to Dalian. China would never agree to that,\nbecause in a crisis the United States could really throw the Chinese internet\ninto chaos by playing with the BGP tables and grabbing their traffic.\n\nWhatever you think about the potentially beneficial or pernicious effects of\ncybersecurity regulation of U.S. companies, the very backbone of the internet,\nmade up of the long-haul fiber-optic cables and the routing systems, should be\nsecured so bad guys trying to mess around with the DNS and BGP routing systems\nwould have a harder time. The way that could be done would be for the Federal\nCommunications Commission (FCC) to regulate this internet backbone, the DNS,\nand the BGP systems to require some basic security functionality. They refuse\nto, once again, out of an ideological antipathy toward regulation thinly\nguised as a fear that regulation would impede innovation.\n\n### Cyber Insurance—A Moneymaker\n\nDo you chew Trident or Dentyne gum? Do you like Philadelphia Cream Cheese and\nsometimes put it on Ritz crackers? When no one is looking, do you eat all of\nthe Oreo cookies in the roll? Or when you have a cough, do you pop in a Hall’s\nlozenge? Then you already know some of the products of a big, multinational\nfood company you’ve probably never heard of: Mondelēz. Production of all of\nthose necessities of life came to a crashing halt because of the NotPetya\nattack we discussed in chapter 2. Mondelēz, however, had insurance and,\ntherefore, assumed that it had transferred its risk and that its claim to\ncover some of its $100 million in losses would be honored. Not so fast.\n\nZurich, the big Swiss insurance company, refused to pay out. The Swiss said\nthat NotPetya was an act of war, an attack carried out by the Russian military\nand, therefore, excluded from the insurance policy. Thus, the debate about\nwhat is and what is not cyber war has gone into a courthouse and the future\nrole of cyber insurance may be decided over who pays for the losses on the day\nthe Oreos stopped.\n\nThe outcome in the case is important because many corporations rely on\ninsurance as part of their overall risk strategy. Moreover, cyber insurance\ncould play an even bigger role if it were combined in some creative ways with\nregulation, as we will discuss later. The last ten years have seen a\nburgeoning of the cyber risk insurance market. Corporations and even city\ngovernments have attempted to transfer risk to insurance companies by buying\nup new cyber insurance policies. There was a lot of hope among cybersecurity\nexperts that this trend could be a way of nudging corporations into improving\ntheir security by linking insurance coverage to some meaningful security\nmeasures. Alas, that has not happened. Instead, a lot of insurance companies\nhave a newfound source of profit and that income has actually worked against\nmeaningful security improvements.\n\nAt first, staid old insurance companies were fearful of covering cyber risk.\nThey put riders in the existing casualty and loss policies that exempted\ndamage from cyberattack. They did so because there was no actuarial data: no\nreliable record of how often attacks occur, what losses from the attacks\ntypically amount to, or how attackers actually execute their breaches. To\ninsurance companies used to being able to predict with more than 90 percent\naccuracy when you will get into a car crash and how much it will cost them,\ncyber was a scary place, a terra incognita.\n\nGradually, however, some companies dipped a toe, not five or ten toes, in the\nwater. They covered a few kinds of costs and only up to fairly low dollar\namounts. They would pay for a cyber incident response team, maybe for the cost\nof giving customers some relatively useless credit monitoring service\npostbreach. Maybe they would pay out on some legal costs and cover some\nbusiness continuity losses. What the insurance policies would not cover were\nthe two most expensive effects of cyber breaches: reputational damage and\nintellectual property theft. If China steals your research-and-development\nsecrets, you are on your own.\n\nMost of the carriers began to require some assurance from their clients that\nthe insured party had taken some minimal cybersecurity measures. What they\nalmost never did, however, was to bother to check on whether the corporations\nwere actually doing what they claimed to be doing. As one insurance company\nofficial told us, “We can always check after they file a claim and if they\nweren’t living up to the minimum practices they said they were, we can just\ndeny the claim.”\n\nInsurance companies could, of course, require continuous monitoring software\nto report on a company’s state of security and compliance in real time. Doing\nthis would be the cyber insurance equivalent of the Progressive automobile\ninsurance policies that involve installing driver behavior monitors in cars.\nWhy wouldn’t insurance companies want that kind of information? Money.\n\nAfter years now of selling limited cyber coverage, most insurance companies\nhave found that doing so is profitable. While they do not sell anywhere near\nas much cyber insurance as life, casualty, home, or auto insurance, they keep\na much higher percentage of the premiums they collect when they sell cyber\ninsurance. The payouts to the insured are a smaller percentage of the revenue\nthan in most other forms of insurance. So why rock the boat when you are\nmaking money?\n\nMost insurance, somewhat oddly, is not regulated at the federal level. Health-\ncare insurance is, of course, or was until the Trump administration made a\nhash of the Affordable Care Act. Almost all other kinds of insurance are\nsupervised by insurance commissioners in the fifty states. Some states elect\ntheir insurance commissioners, as in California. In others, governors appoint\nthem. In New York, the Department of Financial Services doubles as the\ninsurance regulator.\n\nWhat worries some of the state insurance commissioners we have talked with is\nthe prospect of the often-discussed “cyber Pearl Harbor” or the “cyber 9/11.”\nWhat they mean by that is there could be a large-scale, catastrophic cyber\nevent that would not be covered by one of the many outs and exclusions the\ninsurance companies have put in their policies. The commissioners worry that a\nmajor cyber event could cause companies to pay out so much that they might\nbecome insolvent and unable to continue to pay out for other damages. Thus,\nthe commissioners are beginning to think about a new law similar to the\nTerrorism Risk Insurance Act, TRIA.\n\nEnacted after 9/11, TRIA provides a partial federal-government financial\nbackstop to the insurance industry in the event of a major terrorist attack\nthat exceeds the financial ability of the insurance industry to respond to\nclaims. A “Cyber War Risk Insurance Act” is one example of a possible useful\nnew regulation. It could provide a partial federal financial backstop to the\nindustry in case of a national cyber event. It would also be an opportunity to\ncreate some meaningful compliance standards for insured entities.\n\nWe would suggest that corporations would be eligible for such CWRIA-backed\ninsurance only if they had installed such features as an approved continuous\nmonitoring system to perform asset discovery, assess the state of critical\npatches, and conduct vulnerability assessments. Companies that went out of\ncompliance for more than thirty consecutive days would lose coverage until\nthey remedied their deficiencies. Now that would not be a federal mandate, but\nit would be one hell of a nudge, maybe even a shove.\n\n### Comey Versus Cook\n\nThe employees were looking forward to the holiday party, but then one of them,\nassisted by his wife, started shooting everybody. It was December 2, 2015, in\nSan Bernardino, California. Syed Farook and his wife, Tashfeen Malik, killed\nfourteen and wounded twenty-two, before being chased and killed by local\npolice. The FBI was immediately called in to lead the investigation.\n\nBy February, the FBI was saying publicly that it could not open one of the\niPhones used by the terrorists. The devices were set so that after a few\nfailed attempts to open them with a PIN, the phones would wipe all data. FBI\nDirector James Comey called upon Apple to develop software that could be used\nto bypass the PIN and unlock the devices. Apple CEO Tim Cook, correctly in our\nview, refused, saying that Apple could not be compelled to weaken the security\nof its own products. Comey took Cook to court.\n\nThe backstory was that Comey had been campaigning inside the Obama\nadministration for new legislation that would require companies that make\nencryption software to build in ways that the government could decrypt the\ncode. It was an idea that had gone down in flames twenty years earlier, when\nCongress rejected a proposal for a so-called Clipper chip that would permit a\ncourt to unlock encryption upon petition by the government. After months of\nlobbying inside the administration, Comey had lost. The Obama administration\nwould not undercut encryption. Then San Bernardino happened, and Comey saw his\nchance to get a court to give him what the White House would not.\n\nHow could anyone possibly deny the FBI’s request to help it in an ongoing\ninvestigation of such a heinous terrorist attack? Comey and his supporters at\nthe Justice Department claimed they were not seeking a legal precedent, they\nwere just worried about this one case. There were, however, hundreds of other\niPhones involved in other cases that the FBI or local police could not open.\nWhat happened next tells you a lot about the value of encryption to\ncybersecurity. Far from supporting Comey and the FBI, former high-level\nnational security officials came out of the woodwork to support Apple,\nincluding former CIA and NSA directors. We were part of that chorus. What we\nwere all saying was that encryption is essential to secure private-sector\nnetworks and databases. If Apple created a way to break the encryption on its\ndevices, malicious actors would find a way to use it too.\n\nIn a heated debate at the RSA security conference in 2016, Dick Clarke\nasserted that the government was looking to create a bad precedent and that,\nin fact, it already had classified means to open the phone. All that the FBI\nneeded to do was to “drive up the Baltimore-Washington Parkway to Fort Meade,”\nthe home of the NSA. John Carlin, then the assistant attorney general for\nnational security, strenuously denied it was about precedent and asserted that\nthere was no existing method of opening the device available to the\ngovernment. Comey told the same story in congressional hearings.\n\nThen, while Comey’s case against Cook worked its way through the courts, the\nFBI announced that it had opened the iPhones with the help of an Israeli\nsecurity firm. The court case ceased. Much later, the Justice Department\nInspector General reviewed what had happened and concluded that while Comey\nand Carlin were denying that the government could open the iPhones, the FBI\nactually had the capability all along. The IG declined to investigate whether\nComey had knowingly misled Congress or, alternatively, that no one in the FBI\nhad bothered to tell their leader that he was wrong as he went around the\nCapitol for weeks saying no capability existed. The latter possibility seems\nunlikely.\n\nThe takeaway from this tempest in a Capitol teacup is that even national\nsecurity officials, or maybe especially national security officials, think\nthat encryption is a sine qua non for corporate cybersecurity, but do not\nthink government should have a role in it. Many national security officials\nwere even willing to break ranks with the FBI to stress this point. Of course,\nno discussion of the virtues of encrypting everything would be complete these\ndays without mentioning that a lot of companies are having their networks\nencrypted involuntarily and not by the government.\n\n### Calling for a Ransomed Friend\n\n“I have a friend whose company just got hit. All of their data got encrypted.\nDo you think they should pay the ransom?”\n\nWe have had more than a few calls like that. We usually say that the answer is\nprobably yes, you should pay, unless you have multiple, reliable, backup\ndatabases. Then our callers often respond, “Okay, then do you know where I can\nbuy some Bitcoin?”\n\nIn 2017 and 2018, there was a near pandemic of ransomware in North America and\nEurope. According to the Royal Canadian Mounted Police, sixteen hundred\nransomware attacks were occurring each day in Canada in 2015. By the fall of\n2016, the attacks almost doubled. As we said, a pandemic.\n\nHackers could easily buy attack kits that would find vulnerabilities that\nallowed them to go from publicly facing web pages or email servers into an\nentire corporate network. There they could deploy something else easily\nprocured on the dark web: software that finds and encrypts all data stored on\na network, including emails, Word and Excel documents, Salesforce, Oracle, SAP\nfiles, everything. Then comes the ransom offer.\n\nWant the key to unlock everything we encrypted? Then send us one hundred\nthousand dollars’ worth of Bitcoin. Although Bitcoin was supposed to be a safe\nway of doing business because it involved a publicly viewable blockchain\nrecord, it has actually turned out to be easy to use it to hide money flows.\nBitcoin is the coin of the realm when it comes to ransomware, allegedly very\ndifficult to trace.\n\nFaramarz Savandi and Mohammad Mansouri knew how to do it. The two Iranians\nwrote their own version of ransomware software and it became known as the\nSamSam kit. The two men hit about two hundred networks in the United States\nover two years and collected more than $6 million in Bitcoin. The damage that\ntheir ransomware did to networks was estimated at $30 million. Among their\nvictims were numerous hospitals and medical facilities (MedStar Georgetown,\nKansas Heart Hospital, Hollywood Presbyterian, LabCorps), and city governments\nand agencies (Atlanta, Newark, the Port of San Diego).\n\nIn Atlanta, Mayor Keisha Bottoms declined to pay the fifty-thousand-dollar\ndemand. Most of her city’s services, including some police functions, were\ndown for a week. One estimate put the cost of coming back online at $17\nmillion. The two Iranians were also active in attacking networks in Canada and\nthe United Kingdom. They remain at large and are believed to be living well in\nTehran. There are numerous others in many countries engaged in the same\nprofitable trade, which has been estimated to have produced more than a\nbillion dollars in revenue in the last few years from thousands of ransoms\naround the world performed by dozens of attack groups.\n\nSo, back to our caller. Why do we often tell them to pay up? There is honor\namong thieves, and if you pay, you usually get back to business pretty\nquickly. If the ransomware thieves did not free up your network when you paid\nup, then word would get around and no one would pay. After all, they have\ntheir reputation to maintain. You can, however, get around them sometimes.\n\nIt’s all about how good your backup is and how long you can afford to have\nyour network down. If you back up your data every day, you may well have\nbacked up the malicious software that later infected your network. Hackers are\nwaiting a week or so after they get on your network before activating their\nencryption software. By so doing, they get in your backup. If you simply mount\nyour backup after your data is involuntarily encrypted, it will just happen\nagain, only this time you will have lost your backup as well.\n\nThe solution is to keep multiple backups of varying ages, to keep the backups\nsegregated into discrete modules so that everything is not in one master file,\nand to keep so-called golden disks, the clean originals of key applications,\nweb pages, etc. Then you can experiment with gradually restoring your network,\nassuming your corporation can be off-line for forty-eight or seventy-two\nhours. If you can’t be, you may have to pay up. As we have been saying for\nyears, cybercrime pays, at least if you are willing to live in Tehran or\nsomeplace similar and never use your ill-gotten gains to vacation somewhere\nnice that has an extradition treaty with the United States.\n\nAndy Ozment, a former White House and Homeland Security official, has\nprovocatively proposed that ransomware may be one of the more useful\nregulatory mechanisms we’ve got, essentially imposing fines on companies that\nhave not invested in basic cybersecurity. It is a compelling argument, but we\nthink it is time to remove the incentive for cyber criminals to use ransomware\nby having a government law or regulation that bans paying the ransom or\ninstitutes a fine in addition to whatever ransom is paid.\n\nRansomware is funneling billions of dollars to the underground economy. As DEF\nCON cofounder Jeff Moss has pointed out, even if most of those billions of\ndollars go to buying Maseratis and leather jackets in Moscow suburbs, the\nremaining millions are going to buying more and better capabilities, expanding\nteams, and attracting more criminal groups to the business. We need to stop\nfunding the development of our adversaries.\n\nIn the next three chapters we will look at how smart government intervention\nin the markets could solve the problem of identity theft and the workforce\ncrisis, and secure the power grid. We will also look at how the government can\ndo a better job of regulating its own security.\n\n\n## Chapter 8\n\n## IS IT REALLY YOU?\n\nTell me who are you? (Who are you? Who, who, who, who?)\n\n’Cause I really want to know (Who are you? Who, who, who, who?)\n\n—PETE TOWNSHEND\n\nThere is no doubt that over time, people are going to rely less and less on\npasswords,” the CEO of Microsoft told the crowd assembled at RSA.\n\nWith that, Microsoft announced that it was working with the cybersecurity firm\nRSA to roll out its SecurID technology on the Windows platform. Internally,\nMicrosoft was moving to a “smart-card system” and testing a “biometric ID-\ncard” that would allow facial, iris, and retina recognition as a means to\ngrant access to computing resources.\n\nOf course, this was all in 2004. Bill Gates was still Microsoft’s CEO. To his\ncredit, and contrary to legend, he never suggested that passwords would go the\nway of the dodo, only that we would rely on them less. What Gates was\nproposing then was two-factor authentication, or even multifactor\nauthentication: your password and a card with some sort of biometric data on\nit. You would type in your password, stick in your card, and the computer\nwould read the biometric data and match it with the biometrics you were\npresenting (your fingerprint, iris, etc.).\n\nThe obstacles were numerous. Many people did not like giving up their\nbiometrics. The reader devices were unreliable. Users lost their cards a lot.\nImplementation was expensive. And in the end, users still had to remember a\npassword.\n\nAnd so the password did not die. It procreated. Today there are some ninety\nbillion passwords in use around the globe, and that number is growing. By\ncorporate policy and with enough prodding from the tech media, people are\ncreating more, not fewer passwords. Password-manager applications, such as\nDashlane, 1Password, and LastPass, make it relatively easy to create and\nremember unique and difficult-to-break passwords. Application-specific\npasswords are automatically generated in the background by many applications,\nand the primary form of authentication for the growing number of smart devices\nis still the password.\n\nWhen Gates made his speech in 2004, the available alternatives to passwords\nwere awkward. They introduced friction into the user experience and did not\nalways work. Requiring the same card to access a building and to use a\ncomputer caused problems when people forgot to take them out of their\ncomputers when they left the office to go to the bathroom or the cafeteria,\nsomething no amount of scolding could fix.\n\nAt about the same time, the federal government made a similar move. President\nBush signed Homeland Security Presidential Directive 12 in August 2004, which\ncalled for federal government agencies to issue smart cards for both physical\naccess (opening doors and getting through security) and logical access\n(gaining access to computers). The directive gave agencies a generous fourteen\nmonths to implement the program. A decade later, data reported to Congress\nshowed that only 62 percent of federal employees had been issued and were\nusing the smart-card technology. Redoubling efforts after the breach at the\nOffice of Personnel Management, federal agencies finally hit the target of 85\npercent coverage in the fiscal year that began in October 2016.\n\nThe governments’ misfire on implementation did not inspire the private sector\nto move to smart cards for password replacement or augmentation. Simply put,\nthese technologies were too hard to implement and too difficult to use. A few\nyears after Gates’s 2004 speech, however, a new technology emerged that people\nalmost never are without because they almost never put it down: the\nsmartphone.\n\n### I (Am My) Phone\n\nThe first iPhone hit the market on June 29, 2007. The first Android phones\nwould come out a little over a year later. These devices would quickly address\nmany of the problems that people had with other tools used for multifactor\nauthentication. They could be used to receive text messages containing\nsecondary security codes. When fingerprint readers started to become widely\nadopted by smartphone makers around 2013, smartphones could then be used to\nmeet the trifecta for multifactor authentication: 1) something you have (the\nsmartphone itself, registered to you); 2) something you know (still the good\nold password or a one-time number sent to your phone); and 3) something you\nare (a fingerprint or, now, your face with the integration of facial\nrecognition software). Companies such as Okta and Duo, now darlings of Wall\nStreet for their successful IPOs, make implementing and using multifactor\nauthentication on smartphones for multisite single sign-on relatively simple.\n\nYet, for all these technical advances, adoption has been slow and may even be\nstalled out. Although Microsoft makes two-factor authentication freely\navailable to its customers, an independent survey recently reported that only\n20 percent of subscribers to Microsoft’s Office 365 suite of productivity\napplications are using any form of multifactor authentication. Surveys of\nother platforms have found similar results. As we have noted, upwards of 80\npercent of data breaches still involve weak or stolen passwords.\n\nWhile the most sophisticated adversaries are not going to give up and go home\nif they run into a second authentication factor, many lower-level criminals\nclearly would be forced to move on to other, softer targets. While multifactor\nauthentication may be costly to implement and add friction to the user\nexperience, it is even more annoying to adversaries. There is likely no other\ntechnical solution that would do as much to frustrate attackers, increase the\nskill level necessary to carry out attacks, or slow down attackers. Yet no\namount of imploring seems to move the needle on multifactor authentication.\n\nThe problem of passwords won’t go away until some combination of two things\nhappen: multifactor authentication without a password is forced on companies\nand their customers, or multifactor authentication becomes something that\ntakes place seamlessly in the background. On the first front, we are starting\nto see more companies make the push. Banks, which are financially responsible\nshould cyber criminals drain your bank account, have all the incentive they\nnow need to require the use of two-factor authentication. Many are adopting\n“push” models that don’t require users to do anything to set up two-factor\nauthentication. Banks validate your phone number in the background and then\nsend a text message with a one-time code you must enter to log in to your\naccount.\n\nOf course, there are multiple ways criminals can capture a text message and\nuse it to log in to an account, from compromising the underlying SS7 telephone\nnetwork to compromising the phones or computers that receive the text\nmessages. So, what Google, Duo, ThreatMetrix, and the Department of Defense\nare each separately working on is taking multifactor authentication well\nbeyond three factors.\n\nUsing advanced analytics, these efforts can take dozens or even hundreds of\nfactors to make decisions about granting an individual access to computing\nresources. As these technologies come to fruition, getting access to your\naccounts may only involve tapping on an app or clicking on a log-in button\nwhile data analytics go to work in the background to check whether the device\nyou are using is the same one you used last time, whether your location makes\nsense, whether your typing speed as you shift from uppercase to lowercase is\nconsistent with the pattern established on you over time, and a host of other\nfactors.\n\nMoreover, authentication is becoming something of a sliding scale instead of a\nsimple yes-no, binary decision. Once you are allowed inside a network and\nusing your account, behavior out of pattern will get flagged and you will then\nbe asked for additional verification. If, for instance, you are not in the\nhabit of transferring money to Poland, you may get a prompt to enter a\npassword or a call might even be placed to your phone with a live human\noperator, who may ask you questions, such as about your prior use of your\naccount.\n\nAll these measures are likely to make the password, as Bill Gates predicted,\nless central to the authentication process. And there may even be some hope\nfor a passwordless future. Jim Routh at Aetna is in the process of eliminating\npasswords for his twenty-million-plus subscribers using Trusona, a\npasswordless authentication app. That just leaves one huge problem: validating\nthe true identity of the account owner.\n\n### Identify Yourself\n\nPeople who work on identity management like to draw distinctions among\n“authentication,” “authorization,” and “identification.” The solutions Bill\nGates talked about in 2004, smart cards and tokens, are authorization\nsolutions that give or deny access to restricted accounts and computer\nresources. Okta, Duo, and other multifactor solutions are also authorization\nsolutions. They are asking, is the individual (or device) requesting\npermission to access this system presenting the required information and\nexecuting the required actions? If so, they grant access. If not, they don’t.\nWhat they do not do is affirm that you are, in fact, you.\n\nValidating that your email address is assigned to you is not something that\nOkta does. That’s the responsibility of the HR department, and for that they\nrequire you to bring in your passport and driver’s license. Your bank may\nrequire you to do the same when you open an account, or answer challenge\nquestions online based on information that credit bureaus have collected about\nyou. These are what is known as “identity-proofing” events, where you prove\nthat you are in fact you, establishing a unique identity.\n\nThe problem is that these events are one-offs for individual accounts. There\nis, as of yet, no way to assert your identity (and keep anyone else from\nasserting your identity) across the internet. And that is what allows for a\nhost of ills, from Social Security and insurance fraud to fake social media\naccounts that manipulate elections. If multifactor authentication would\nfrustrate adversaries in carrying out attacks, making it harder to steal\nidentities and therefore benefit from cybercrime, it could take away the\nmotivation in the first place.\n\nWe already have the means to use a single identity across multiple internet\nplatforms, what is called federated identity. Facebook, Google, and others\nhave used the fact that almost everyone has an account at one, the other, or\nboth to insert themselves into the authorization process for a host of sites\n(“Sign in with Google” buttons seem to be almost everywhere). But neither\nGoogle nor Facebook actually know who you are, so their ability to\nauthenticate you as _you_ is only as strong as the information you provided to\nthem when you registered your accounts. While both companies are making some\nattempts to validate new accounts by checking names against provided phone\nnumbers and then texting those phone numbers, criminals have proven adept at\nbeating these systems. Burner phones make it all too easy for criminals to\nhide their identity.\n\nThe lack of an ability to prove who you are on the internet is a long-\nrecognized but seemingly intractable problem. When identity proofing is needed\nonline, almost all websites rely on the tried-and-failed method of validating\nhistorical information about you. With your address, your phone number, your\ndate of birth, and your Social Security number, you can file your tax return.\nSo can anyone else with that information, leading to almost six hundred\nthousand cases of fraud in 2017.\n\nThe same goes for insurance fraud, new account fraud, and a host of other\ncybercrimes that deprive the government of tax revenue, drive up the price of\ninsurance, and cost the economy billions. Despite these losses, it’s a problem\nthat the market just cannot seem to fix. That is where, typically, government\nshould step in.\n\n### Getting Identity Unstuck\n\nOne of the first initiatives launched by the Obama administration to address\nour cyber insecurities was the National Strategy for Trusted Identities in\nCyberspace (NSTIC). As the administration’s first senior director for\ncybersecurity, Sameer Bhalotra spearheaded the effort. He was joined by Jeremy\nGrant, who ran the NSTIC program office from its inception in 2011 until he\nleft in 2015.\n\nOftentimes, government bureaucrats are charged with a failure of imagination\nand with a lack of ambition. Those charges do not apply to the team that put\ntogether the NSTIC strategy. The document is visionary. It literally contains\nlittle vignettes to get you to “Envision It!” in which Mary, or another\nfictitious person, uses her new online credential to do the kinds of\ntransactions we can’t easily do today online, such as close a mortgage. Always\nwary of government overreach, particularly on issues of individual privacy,\nthe Obama team did not propose the obvious answer of a government-issued ID\ncard with a digital chip. Anyone who remembers the fight over REAL ID, a Bush\nadministration effort to get states to issue secure driver’s licenses, should\nbe able to imagine why. Americans have a reflexive distrust of federal\nrequirements for identification. Nothing is more un-American than restricting\nmovement, as the Soviets did with their ubiquitous requests for “Papers,\nplease.”\n\nInstead of going with a national ID card, the NSTIC team took a market-based\napproach that would give consumers choices about whom they used to obtain a\ntrusted digital identity for use online. The strategy envisioned a host of\npotential providers, companies that ranged from banks to ISPs to independent\nidentity providers. Despite a solid strategy, there were two problems that the\nNSTIC team could not solve: initial validation of users through an in-person\nproofing event and getting companies to pay to use the new identities.\n\nThe NSTIC team tried to sell the Postal Service on doing the identity\nproofing. There are 4,800 post offices throughout the country that already\nprocess passport applications, including the necessary in-person proofing.\nBhalotra met with the Postmaster General and tried to sell him on the idea. He\nthought it was a no-brainer, because the post office is already performing\nthis service for passports and is desperate to find new sources of revenue\ngiven the decline in traditional mail brought about by the digital economy. He\nfigured this was an easy sell. It wasn’t. The prospects were too remote and\nthe mission too far from the core Postal Service mission of delivering the\nmail.\n\nThe second challenge was getting anyone to adopt the use of the new secure\nidentities and mandate that their employees or customers use them. Bhalotra\nthought that the banks would be natural allies as they already need to\nauthenticate customers for account opening and spend tremendous amounts\nbattling fraud. It was a hard sell there as well. He tried to stimulate demand\nby getting federal agencies to be the early adopters. Unfortunately, he got no\ntakers from the IRS, State, DHS, or HHS, the major agencies that interact with\ncitizens in ways that require identity proofing. Going direct to consumers\nalso was a nonstarter, because no one in the venture-capital community thought\npeople wanted to pay for this service.\n\nNone of this, of course, means the approach was wrong. Particularly in\ngovernment, there is no force more powerful than an idea whose time has come.\nIn 2011, the technologies were insufficiently mature and the need for the\nsolution was less apparent. In 2019, when almost every American has been made\na victim of identity theft, it is well past time to put in place the solutions\nthat the NSTIC developed and piloted.\n\nFor his part, Jeremy Grant has not given up. Now a member of the technology\nconsulting team at a law firm, he is actively pursuing many of the concepts he\nhelped to develop in government from his position in the private sector. Grant\nhas helped bring together JPMorgan, Bank of America, Wells Fargo, and\nCitibank, among others, to form the Better Identity Coalition. Their idea is\nto create a public-public-private partnership building on the states’\ndivisions of motor vehicles (DMV) driver’s-license databases and the Social\nSecurity Administration’s files.\n\nThe banks recognize that the DMVs do a pretty good job of in-person interviews\nand requiring multiple forms of proof of identity. True, there are counterfeit\ndriver’s licenses, but when you check DMV databases, you can usually tell that\nthe license was never issued by the DMV. Social Security, for all of the\nfaults associated with its number and card system, is pretty good at\nregistering when someone dies, as is the Department of Veterans Affairs.\nBecause a common criminal technique is to assume the identity of someone who\nhas passed away, access to death records would help identify fraudulent\nidentity activity.\n\nOne problem, however, is that most state DMV agencies do not have the highest\nlevel of cybersecurity on their own networks. If criminals and intelligence\nofficers can hack into the DMV database and alter it, using the DMV as a\nsource of verification may not be a good idea. Thus, the banks are seeking\nfederal grants to help the states improve their cybersecurity. Until that\nhappens, the DMVs may not be the solution. At best, they are a surrogate for a\nnational ID card system, something that has proven politically unpalatable on\nboth the right and left in the United States for decades. Yet we have been\nable to find workable solutions that address privacy and civil-liberties\nconcerns while improving identity with a simple concept: letting people opt\nin.\n\nNobody has to fly, but it does make work and personal travel a lot easier.\nAfter 9/11, it got harder. Americans wanted to be sure that the other people\non the plane with them were trustworthy, not terrorists. So there was not a\nlot of complaining when the government stepped in and put federal employees at\nthe airports, asking to see your identification. Not any identification would\ndo. It had to be a government-issued document that was hard to counterfeit.\nState governments were told what security standards they had to incorporate\ninto their driver’s licenses, and after some grumbling, they almost all\ncomplied.\n\nThis system, however, created long lines. So two innovations occurred, one\npublic and one a public-private partnership. The TSA created TSA PreCheck for\npeople who were willing to fill out forms, go through a background check, have\ntheir biometrics registered, be photographed, and be entered into a federal\ndatabase. TSA also authorized a private company, CLEAR, to manage a parallel\nsystem of authenticating travelers with a combination of your boarding pass,\nan iris scan or fingerprints, and a picture of you.\n\nWhen you use CLEAR, you engage in multifactor authentication. You have used\nthings you know to get the boarding pass. Then that boarding pass becomes\nthings you have. Finally, your biometrics and photograph are things you are.\nNo one has forced you to use CLEAR. In fact, you had to pay for it. A similar\nincentive system exists with E-ZPass toll-paying devices on cars.\n\nAmericans have accepted these systems, which can serve as valuable models for\nincentivizing the implementation of stronger authentication systems in other\nindustries. We can use similar principles in creating secure online\nidentities. We can use a certain degree of government compulsion. We can\npartner with private-sector companies. People who choose not to participate in\noptional additional background checks and identification would still be\nserved, but they would be subject to more examination and given slower\nservice.\n\n### A New Authentication Proposal: ReallyU\n\nBuilding on the lessons from NSTIC and how identity is handled in other\nindustries, we propose a new authentication system to ensure a higher degree\nof identity protection and replace outdated identifiers like Social Security\nnumbers. Because it would require a combination of nudges and shoves, ReallyU\nwould have to be authorized by Congress. Yes, Republicans and Democrats would\nhave to play nicely together, at least on this one law.\n\nThe law would authorize private companies that met certain standards to issue\nReallyU identities for use in online interactions with both the government and\ncorporations. On an opt-in basis, you could choose from any number of approved\ncompanies to serve as your identity service provider. You would then go\nthrough an identity-proofing process that included being interviewed on-site,\npresenting valid government identification, giving biometric data, and being\nphotographed. You could also provide an email address, mobile phone number,\nand credit card or other banking information if you chose to do so.\n\nThen, the ReallyU provider would do a background check to verify that you are\nwho you say you are. In that process, they would have access to some\ngovernment databases. Maybe your provider would be Google (they know\neverything about you anyway); maybe Apple (if they make your phone); maybe\nVerizon (or whoever your costly cell provider is); maybe Mastercard or Visa\nthrough your bank (you get the idea). These providers would then be paid each\ntime they validated your identity to a third party to, say, open a bank\naccount or access your IRS record.\n\nEach ReallyU provider could create their own federated identity network, much\nlike Mastercard and Visa have created their own parallel payment networks that\ninclude a heavy dose of identity checking. Government agencies should be made\nby law to accept any one of the approved federated identity networks for\nonline transactions. Companies doing online commerce could choose which\nReallyU providers they wanted to honor.\n\nSomething along these lines would give us a system of online identification\nthat would not be the equivalent of a national ID card because it would not be\nmanaged by the federal government and it would be voluntary, not required.\nBeyond a light touch of regulation, the government’s main role would be to\nhelp create the market by making federal agencies that require proof of\nidentity accept it and provide various kinds of preferential service to\nReallyU members.\n\nOnce you had a ReallyU identity, you could use it to identify yourself to any\ncompany or government agency that was part of the federated network. The\ngovernment agencies involved would include the IRS, Social Security, Medicare,\nVeterans Affairs, and federal employee retirement systems. They could also\ncontinue to accept their previously existing systems.\n\nIf you used the ReallyU system, each company and government agency could\ninterrogate a federated database to learn about you when you logged in to use\nit. They could then require you to prove your identity in any number of\ndifferent ways, based on a variety of two-factor or multifactor systems,\nincluding face identification (via a smartphone or camera on your laptop),\nfingerprint, iris scan, or one-time message sent to your mobile phone or\nemail. In the background, the system would be checking your location, the\ndevice you were using, and other observables, the same way ThreatMetrix does\nnow for many banks and other financial institutions.\n\nAs a consumer, you could switch identity providers whenever you want. You\nmight pick based on security or reputation or a preexisting relationship. You\nmight opt to pay for the service and gain more control or choose a service\nthat is free (and possibly ad-supported), though we think a better answer is a\nsmall per-transaction fee charged to the companies that are requesting an\nidentity-proofing or authentication event. The process for changing providers\nmight need some degree of government regulation, as was necessary to create\nthe phone-number porting system we use today. A light-touch regulatory\napproach run out of somewhere like the Commerce Department (not a national\nsecurity agency) would set the right tone.\n\nWhat would happen to the Social Security number? We could keep it, but only as\nan identifier, like your name, not as proof of anything. As former DHS cyber\nofficial Phil Reitinger tweeted, “An SSN is a fine identifier and an awful\nauthenticator.” The assumption that you, and only you, know your Social\nSecurity number is no longer a tenable proposition. Every SSN has probably\nalready been compromised.\n\nSo, what do we need the Congress to agree on for all of this to work? We have\na short list.\n\nFirst, Congress needs to direct the U.S. Postal Service and the TSA to offer\nin-person identity-proofing services, no matter how reluctant the current\nPostmaster General is. Just as the USPS has competitors in FedEx and UPS, this\naction won’t give government a monopoly but should stimulate competition. The\nlaw should require the Postal Service to partner with private companies to\nissue and manage the IDs, the IT/tech part of the solution. That is what the\nprivate sector, particularly Silicon Valley tech firms and their VC partners,\nare good at. What they are not good at, managing brick-and-mortar buildings\nwhere identity proofing is done by actual people, is what the USPS already\ndoes.\n\nSecond, Congress needs to direct the Commerce Department’s standards office,\nNIST, to develop whatever standards they think are necessary for the seamless\ntransfer of identity-proofing data and credential exchange, beyond, if\nnecessary, existing standards.\n\nThird, Congress needs to mandate that key agencies, including the IRS, accept\nthe ReallyU system. (No more e-filing a tax return by answering challenge\nquestions about your last tax return.)\n\nAs we have sought to make clear, what we propose is not a novel concept. It\nbuilds on ideas and programs that others have developed. We believe we are at\na point at which the technology is sufficiently developed and the benefits are\nnow clear. Identity masquerading is necessary for both financial theft by\ncyber criminals and all sorts of malicious activity inside government and\ncorporate networks by foreign intelligence and military hackers. The theft of\npersonally identifiable information (PII) is one of the most common\ncybercrimes, and costs companies billions of dollars to prevent. We can\ngreatly reduce all of that by adopting a voluntary system of federated,\nmultifactor identification for online activities. Most criminal uses of PII\nwould no longer work to access credit cards or other financial activities,\nthus greatly reducing the incentive to steal it.\n\nWhile all of this would require a new law and some federal standards and\nsupport, it would not be a government ID system. It would be an identity\nsystem used by companies and individuals who want to protect their identities\nwhile benefiting from the digital economy. It is more analogous to our current\ncredit-card system. All of this could be done today with existing\ntechnologies, piecing together bits from here and there that have already been\nproven to work. We just need leadership, will, and people of good faith\nplaying nicely together, including Congress for a quick minute or two.\n\n\n## Chapter 9\n\n## FIXING THE PEOPLE PROBLEM\n\nA burglar, a spy, a fugitive, a delinquent, a hacker, and a piano teacher . .\n. and these are the good guys.\n\n_—_ TAGLINE FROM _SNEAKERS_ (1992 FILM)\n\nFrank DiGiovanni is no cyber warrior. He is a real warrior. An ex–fighter\npilot in the Air Force, he now works in the Navy as a civilian. The walls of\nhis Pentagon office are adorned with the memorabilia collected over a lifetime\ndefending the country: military decorations, photos of the teams he has been\non, tactical knives, and innumerable challenge coins given out by military\nunits in appreciation of his service. DiGiovanni has served as the director of\nForce Training in the Office of the Assistant Secretary of Defense for\nReadiness, as well as the assistant deputy chief of Naval Operations for\nManpower, Personnel, Training and Education, and he is now the Deputy Director\nfor Expeditionary Warfare. In all these roles, DiGiovanni has been charged\nwith thinking about how the U.S. military trains to fight in cyberspace. He\nhas come to some brutal conclusions about a field that many would agree is\nbroken.\n\n### Breaking Through the Hype\n\nThe cybersecurity community is beset with hand-wringing about the field’s\nworkforce crisis. To match every story about the cyber-expert gap, there is\none about new programs to combat it. “The cybersecurity workforce is an\nindustrial crisis!” declares Brian NeSmith, the CEO of a well-respected\nmanaged security service provider. And indeed, there certainly are a series of\nproblems that we need to solve to get the workforce the nation requires. The\nfirst one, though, is to put an end to the hype. Breathless headlines declare\nworkforce shortages of a million or more people. NeSmith quotes an often-used\nfigure of 3.5 million unfilled positions by 2021, but the denominator is\nimportant. That figure is global, for the entire planet of 195 countries and\n7.6 billion people.\n\nThere’s an unholy trinity of forces that have an interest in hyping the\ncrisis. The first are companies that don’t like the high salaries that\ncybersecurity professionals demand. Attracting more people to the field,\ncreating a slack in demand, and driving down costs would be of interest. Every\ntime the issue of immigration reform comes up in Congress, the tech companies,\nin the hopes of expanding the H-1B visa program for technical workers, cite\nthe cybersecurity workforce crisis as one of the main drivers.\n\nThe second player in this trinity is the cybersecurity industry itself, which\ndoes not necessarily want more workers in the field. They want their customers\nto buy more products and services from them, including managed security\nservices that will outsource the work, automation of workflow, and AI that\nwill replace the workers. The message is effective: You can’t hire the people\nyou need. Spend your way out.\n\nThe last group pushing the workforce crisis are the security training programs\nspringing up at every university and community college and competing against\nprivate training programs. All have a vested interest in making the problem\nseem out of hand, but what do the numbers really say?\n\n### The Cyber Census\n\nWhen the good folks at NIST got tasked to help solve the cybersecurity\nworkforce crisis, one of the first things they did was to get an accurate\ncount of the existing workforce and the open jobs, down to a level of detail\nthat would be useful. Then NIST created an online census of the cybersecurity\nworkforce and job openings called Cyberseek, which brings real numbers to the\nworkforce problem. What the numbers show is a far more nuanced story than what\nthe tech companies, the toolmakers, and the training programs might have you\nbelieve.\n\nNIST calculates the total cyber workforce in the United States at 768,096\npeople, and it identified 301,873 job openings in a one-year period. NIST then\nhelpfully calculated that for every 2.5 people employed in cybersecurity,\nthere is one additional opening. Nationally, across all career fields, there\nare 6.5 people for every one opening, so the cybersecurity talent market is\nmost definitely tight. Where things get interesting is the data on\ncertifications. NIST took the job postings and pulled out the certifications\nthe postings requested. Then NIST compared them with the number of members of\nthe workforce who have those certifications. What these numbers suggest is\nthat the training programs endeavoring to get people into the field are\nsolving the wrong problem.\n\nBoth of us regularly receive emails or are approached at conferences by people\ntrying to break into the field. Many times, these individuals have no idea\nwhere to begin and are more interested in the policy aspects of cybersecurity.\nWe generally give them the same advice. First, gain a technical grounding.\nLearn to work from the command line in Linux, learn the programming language\nPython, then take a penetration testing course. Increasingly, the people we\ntalk to have taken several courses and obtained a series of entry-level\ncertifications. They are applying to dozens of jobs. They are never getting a\ncallback.\n\nThe reason for that appears to be that the demand is not at the entry level.\nThe market wants more midcareer, experienced professionals. Looking at the\ndata bears this out, as does talking to hiring managers. At any given company,\nthe person in charge of cybersecurity first has to fight for money. When they\nget money, they have to fight for head count. Companies are often willing to\nspend big dollars on cybersecurity, but will fight to keep their teams as\nsmall as possible or even smaller than possible. If a director of security can\nstaff up, the last thing they want to do is hire someone new to the field whom\nthey will have to train for a year or two before getting any value out of\nthem.\n\nThe data from Cyberseek bears this out: 167,776 people hold the CompTIA\nSecurity+ certification, an entry-level certification, against only 33,529 job\nopenings that require it, for a ratio of 5 holders for every opening. If there\nare 6.5 workers for every opening in the overall economy, entry-level cyber\nisn’t in much higher demand than, say, retail workers.\n\nGo further up the stack and the ratios start to shift dramatically in the\nother direction. Global Information Assurance Certification (GIAC) programs\ntend toward higher-level skills, with a historical connection to the NSA.\nThere are 45,527 GIAC holders and 33,239 openings that request some of the\nGIAC certifications. It’s safe to assume that almost all of these GIAC holders\nalready have jobs. For certified information systems security professionals\n(CISSP), certified information system auditors (CISA), and certified\ninformation security managers (CISM), there are more job openings than there\nare people with those certifications. Interestingly, for those who believe the\nskill shortage is only technical, auditors (CISA) and managers (CISM) are the\ntwo most in demand.\n\nIf the real shortage in the cybersecurity workforce is not at the entry level\nbut at the level of experienced professionals, it is a much harder problem to\nsolve. Pulling thousands of new people to the field, in many cases paying high\ntuition costs, will likely lead to a lot of people spending money on basic\ntraining and not being able to get jobs if new career pathways aren’t created.\n\n### The Cyber Workforce Market Failure\n\nIt is tempting to conclude that the cyber workforce problem will solve itself\nover time. After all, to move from an entry-level information-security analyst\nwith a CompTIA Security+ certification to a CISO takes years. As more and more\ncore societal functions go online and as companies either go out of business\nor make the leap to digital-first organizations, the scary headlines probably\nhave some truth to them: the workforce gap is still growing and market forces\nalone are not fixing it. In almost all cases, we think that when markets fail,\ngovernments need to intervene. While sometimes government intervention means\ngood, old-fashioned regulation, in this case there is probably no way to\nregulate our way out of the crisis. While cybersecurity is a twenty-first-\ncentury problem, we can look to two unlikely historical episodes for lessons:\ntwentieth-century military challenges and the guilds of the Middle Ages.\n\nWhen DiGiovanni got the task of figuring out how the military could train more\n(and more effective) cyber warriors, he first looked at how current military\ntraining programs in the field worked.\n\nHe came to a stark conclusion: the Department of Defense did not know who they\nwere looking for and how to train a cyber warrior. “We were repurposing people\nfrom the comms community and the intel community rather than taking people who\nwere born into the cyber community,” says DiGiovanni. “The military services\nwere taking the easy way out by repurposing troops in similar areas rather\nthan saying, what do I need to do this job, what are the attributes of the\npeople who can do it, and what do I need to do to train them?”\n\nAs to identifying the people with the capability to become, in his words,\nefficacious cyber warriors, DiGiovanni quickly concluded that the basic\nmilitary aptitude tests were missing the mark. “The tests we are giving people\nthat simply measure intelligence are missing a big part of what it takes to be\nsuccessful.”\n\nDiGiovanni identified a series of core attributes he was looking for, based on\ninterviews he conducted with those who were successful in the field at doing\nthe work he needed to train his recruits to do, i.e., hard-core hackers. He\ntalked to dozens of them. He now knew he was looking for people who had the\nability to be self-taught, who learned better on their own than in classrooms.\nHe was looking for people who became easily obsessed and would dig deep into a\nnew subject (“It could be anything—coffee, brewing beer, cars—they just need\nto be passionately curious”), people who had the tenacity to work forever, to\nbe the kind of people who will never give up on a problem until they have\nsolved it.\n\nThey also had to be “prestige seeking.” They could be “breakers” in one sense\nof the term “hacker,” or “builders” in another sense of the same term, but\nthey had to want to do things that others could not. They also had to be\nprocess oriented, creative but within constraints. Finally, they had to\nexhibit that most hackerlike trait, a willingness to constantly challenge the\nstatus quo, something the military’s culture does not exactly encourage.\n\nDiGiovanni looked for candidates who fit these attributes within the military\nand the Pentagon’s civilian workforce. When he found them, he did not stick\nthem in a standard classroom. He does not believe that most real-world skills\nare best learned by sitting in a chair, reading a book, listening to a\nlecture, and taking exams. For cybersecurity, he thinks these old-school\nlearning models are hopeless, and yet it is how the U.S. military still trains\nmost of its recruits to serve in cybersecurity missions. It’s also how most\nuniversities are approaching the problem. DiGiovanni, on the other hand, is a\nproponent of experiential and guided “autodidactic” learning. What that means\nis that he thinks cybersecurity is best learned by doing and is mostly about\nworking on your own with some gentle guidance.\n\nIt may be that the best way to learn cybersecurity is to beat your head\nagainst a computer monitor for a decade in your parents’ basement, but the\nnation can’t wait that long. Thus, finding a way to identify students with the\nright innate abilities and then to move them swiftly along through a hands-on\nlearning program may be a far better approach. With that insight, DiGiovanni\ncreated the Cyber Operations Academy Course. His first step was to hire a\nbunch of ex-NSA TAO guys.\n\nTAO, for Tailored Access Operations, is the NSA’s legendary elite hacking\nteam. They carry out focused operations against the world’s most hardened\ntargets (other nation-states). They are the very definition of an advanced\npersistent threat and they hire their fair share of computer prodigies right\nout of high school and recruit heavily from the University of Maryland, MIT,\nand Stanford, with a compelling pitch: Come break into live computer systems\nlegally, in the service of your country.\n\nDiGiovanni came across a small company, Point3 Security, founded by an ex-TAO\noperator named Evan Dornbush and other ex-government colleagues, that was\nstruggling to get its new endpoint system to the market. He gave them a simple\npitch: Design me a course, and sit in the lab as a resource for students. Give\nthem hints when they are stuck, but otherwise feel free to code away on your\nsecurity application. And so they did, developing a series of progressively\nharder challenges for students to work on. There were no multiple-choice\ntests, no lectures.\n\nWhen students got stuck, they could go to the instructors, who would mostly\ngive them a simple piece of advice: “Google it.” They left coding manuals and\ntrade publications around the lab as a resource as well, but the most valuable\nresource typically was other students in the class. The first year of the\nclass was rough. Many of the students, drawn from across the DoD, military,\nand civilian workforces, dropped out and returned to their previous\nassignments. Some got the bug for cybersecurity and gained enough knowledge\nthat they now have thriving careers in the military, federal government, and,\nin some cases, the private sector. What really made the program successful was\nthat the Pentagon provided jobs for those who succeeded.\n\nFor their part, the Point3 guys did get their endpoint detection technology,\nOdile, finished and on the market. They’ve white-labeled it to a few vendors\nand are happy with what they built. Most of their time is now spent\ncommercializing the course they built for the Pentagon. They created Escalate,\na series of progressively more difficult challenges that students can take\nonline. The first three are free. Beyond that, students, or the companies they\nwork for, pay three thousand dollars a year for access to the program. As with\nthe in-person course, mentors are available when students get stuck.\n\nDornbush, both as a trainer and a hiring manager, has seen the value of the\napproach that DiGiovanni pitched him. Point3 is rapidly expanding and he has a\nlot of slots to fill. “People come with all their certificates like CISSP,”\nsays Dornbush. He gives them a challenge on Escalate and they sit there having\nno idea how to analyze the piece of malware he has dropped on them. They know\nwhat malware analysis is and probably aced all the questions on the CISSP\nabout it, but they don’t know how to do it. “You want me to hire you to be a\nmalware analyst; I gave you a piece of malware and you can’t analyze it?”\n\nPoint3 is, of course, not the only company with an online offering like this.\nImmersive Labs, a U.K. company, is taking a similar approach and has multiple\ncustomers at the large financial institutions. It’s a better and cheaper\napproach than in-person classes and can be used to assess the competence of\ncurrent workforces, as well as provide them with additional training. This is\nprobably not an approach that can, in a short period, turn out all of the\nhighly skilled professionals the market is demanding. For that, students\ntaking these type of courses evenings and weekends also need the opportunity\nto work on real-world problems by day.\n\nHere is where the approach that the military took to new technical fields in\nthe twentieth century is instructive. When Admiral Hyman Rickover created the\nnuclear Navy, he recognized that the program would never succeed unless he\ncould guarantee that there would be no nuclear incidents as a result. Being a\ncontrol freak, Rickover personally selected every officer who joined his\nprogram and decided that the Navy would train all its nuclear engineers in-\nhouse.\n\nTo this day, having an undergraduate degree or even a PhD in nuclear\nengineering would not help you get into the Navy’s nuclear training program.\nThe only prerequisite for officers is to have taken calculus. Enlisted\npersonnel are chosen based on how well they do on the Armed Services\nVocational Aptitude Battery, which measures capabilities, not specialized\nknowledge. Similarly, taking private flying lessons is neither a requirement\nnor an advantage to becoming a military aviator.\n\nFor both aviation and the nuclear Navy, the military very quickly grew a large\nand capable workforce. That workforce, in turn, provided these trained\nindividuals to the civilian workforce once they completed their service\nrequirements. Go to any nuclear plant or talk to any civilian pilot and there\nis a good chance you will find someone who first received training and\nexperience in the military. As DiGiovanni points out, when World War II began\nin Europe in 1939, the Army Air Corps could field only 1,500 aircraft. By\n1944, the successor Army Air Forces had 80,000 aircraft and 2.5 million men\nand women under service. At the end of the war, as many of the pilots left\nservice, the burgeoning civilian aviation market gobbled them up.\n\nToday, U.S. Cyber Command has about eight thousand personnel. If there are\nover three hundred thousand job openings, U.S. military personnel leaving the\nservices are far from being a main source of talent to fill that gap. Cyber\nCommand doubtless needs to grow, but if we continue down a path where the\nprivate sector is responsible for its own security, there will never be enough\nskilled veterans for the civilian workforce. Instead, the approach of\n“recruit, train, deploy, and retrain” needs to be adopted by both the civilian\ngovernment and the private sector.\n\nMany in the Pentagon and civilian agencies will lament that as soon as they\ntrain up someone, the private sector will swoop in as fast as possible to hire\nthem. Bobbie Stempfley, a former leader at the Department of Homeland\nSecurity’s Office of Cybersecurity and Communications, has often quipped that\nif the government is so bad at cybersecurity, then why did they constantly\npoach her staff? Yet instead of lamenting this churn, we should encourage it.\nThere may be no better or more direct way for the government to support the\nprivate sector than by recruiting and training a cybersecurity workforce that\nprivate companies will eagerly hire. Creating this program in a civilian\ngovernment agency like DHS would likely draw a different and possibly larger\npool of candidates who are not inclined toward military service. After\ncompleting training, participants would have a multiyear obligation of service\nto pay back the costs, though private-sector employers should be allowed to\nbuy them out of those obligations.\n\n### Cyber Guilds\n\nReplicating a similar program in the private sector may be more difficult.\nTraining new personnel from scratch is typically not something shareholders\nwill find in their interest. To illustrate, let’s draw up a composite\ncharacter from real people we know. She’s the CISO of a midmarket company. The\ncompany does $3 billion a year in business. It has eight thousand employees.\nShe reports to the CIO, who oversees a one-hundred-person IT department. Three\nyears ago she was the director of IT security and had no one reporting to her.\nNow, as CISO, she has two direct reports. Her board and CEO are all over\ncybersecurity and have upped her budget every year for the last three years.\nShe can buy just about any tool she wants. What she can’t do is hire anyone.\n\nHer CFO is tightly controlling head count. Employees are expensive. Employees\nintroduce liability. Hiring a handful of junior people and training them is a\nnonstarter. If she gets approval for another person, she wants a “ninja” or a\n“wizard,” someone in the middle of their career who has experience across all\nthe areas of cyber operations. A junior person would gain valuable experience\nworking on the problems this company has, and could apply what they learn in\nan online program like Escalate at night each day (or by day each night, as\nthey will probably get stuck on the graveyard shift). Here is where the guilds\nof yesteryear come in.\n\nLearning by doing is, of course, not a new idea. Training programs in the form\nof hands-on apprenticeships were formalized in the Middle Ages, but they have\nlargely fallen out of favor in the United States except in a few specialized\ntrades (plumbing, carpenters, and electricians often still hire and train\napprentices). When a presidentially appointed commission looked at the\nworkforce problem at the end of the Obama administration, it concluded that\nthe next President should create a national cybersecurity apprenticeship\nprogram with the goal of training fifty thousand new cybersecurity\npractitioners by 2020. The Trump administration has not moved this initiative\nforward.\n\nLuckily, some of the private-sector leaders President Obama appointed to the\ntask force have realized that the program need not be led by the government.\nAjay Banga, the CEO of Mastercard, pushed leadership at Microsoft and Workday\nto join him in establishing the Cybersecurity Talent Initiative. Under the\nprogram, students who pursue a cybersecurity-related undergraduate or advanced\ndegree will then do a two-year tour of duty in full-time cybersecurity roles\nat federal agencies such as the DoD, FBI, CIA, DHS, Treasury, and the Small\nBusiness Administration. They will then transition to positions with\nparticipating corporate sponsors. At the end of the program, the corporate\nsponsors will pay off outstanding student loan debt up to seventy-five\nthousand dollars. More than forty-five universities have committed to the\nprogram, from Harvard and MIT to a series of historically black colleges and\nuniversities. The founding partners committed to taking on a minimum of five\nprogram participants per year.\n\nOf course, if only the founding companies join and only make their initial\ncommitments to hire five a year, the initiative won’t do much to close the\nworkforce gap. Alex Niejelow, senior vice president at Mastercard (and a\nformer White House colleague of Rob Knake’s), who helped shape the initiative\nwith Banga, hopes the program will grow rapidly. “We have three massive\ntechnology-enabled companies that are leading this initiative. We expect the\nrest of the market will follow,” says Niejelow. “Every company is facing this\ncrisis.”\n\nWe applaud private sector efforts like this, but ultimately believe that\ngovernment is likely to need to do two things. First, it needs to nudge the\nmarket away from requiring undergraduate degrees to get into the field and\ninstead create pathways for professionals later in their careers. Today, many\nif not most of the best people we know working in even the most technical\nareas of cybersecurity do not have undergraduate degrees in computer science.\nIf the national security of the United States requires college freshmen to\nmake good decisions about their career prospects, we are likely doomed. Thus,\nwe think an intensive boot-camp program like what DiGiovanni pioneered is\nlikely a better pathway into the field than emphasizing formal education.\nSecond, government may need to subsidize private companies to provide\napprenticeships, as the federal government alone is not likely to be able to\nprovide enough meaningful initial positions.\n\nOf course, risk is inherent to the approach that we have outlined. We might\ntrain hundreds of thousands of people in cybersecurity only to have them\nreplaced by robots. Artificial intelligence is making gains in automating some\nof the entry-level tasks that Tier 1 analysts do, like being “the eyes on the\nglass” in the Security Operations Center (SOC). Indeed, it’s possible that in\na decade or two, the cybersecurity workforce may actually shrink. Given that\nApple, Google, and Amazon have invested billions of dollars in digital home\nassistants that still can’t compose a grocery list, we think the point at\nwhich trained cybersecurity professionals are going to be looking for jobs is\npretty far off.\n\n\n## Chapter 10\n\n## POWER GRIDS AND POWER PLAYS\n\nThis is the largest blackout in U.S. history. If that is not a signal that we\nhave got a problem that needs to be fixed, I don’t know what is.\n\n—JENNIFER GRANHOLM, THEN GOVERNOR OF MICHIGAN, _AMERICAN MORNING_ , CNN,\nAUGUST 18, 2003\n\nNew York is down.” It was 2003 and many people were still jumpy from the 9/11\nattack that had occurred less than two years earlier. Just before 5:00 P.M. on\nAugust 14, a frantic news producer found ABC News’s Ted Koppel in a corridor\nand told him that the ABC television network had lost contact with the\nmothership, Network Control in Manhattan. “We’re running the entire national\nnetwork from here in Washington now.” ABC had automatically instituted its\ndisaster recovery plan and devolved control to D.C. “You have to go on,” the\nproducer told Ted. “Now. Live.”\n\nAlthough most Washingtonians had fled the city in the annual August evacuation\nto the beach, Ted Koppel was still there. For more than twenty years, Koppel\nhad done a network television newsmagazine show, _Nightline._ Weekday nights\nthe show went on the air at 11:30 P.M. East Coast time, but he taped much of\nit during the afternoon at ABC News’s Washington bureau. He had just completed\ntaping that night’s show. It would never be seen.\n\nThe producer told Koppel there had been a major power blackout. New York was\nin the dark and so were Cleveland, Pittsburgh, and a huge swath of the\nNortheast. With little more information than that, Koppel sat on a stool in\nfront of a camera and tried to explain to the rest of the country what was\ngoing on. The problem was, he didn’t know. No one did. Koppel was vamping,\nbut, being a pro at live television, he exuded calm to an anxious audience.\n\nDick Clarke, then an ABC News “talking head,” had also been in the D.C. bureau\nwhen control of the national network shifted to the little building on a side\nstreet in downtown Washington. The front desk guard stopped him from leaving\nthe building and redirected him to the studio. In a few minutes, he was\nsitting next to Koppel explaining to the audience how there were three\nisolated electric power grids (known as Interconnects) in the United States:\nEast, West, and, well, Texas, and within them there were subregions, such as\nthe mid-Atlantic area, known as PJM (the Pennsylvania–New Jersey–Maryland\narea). “It looks like the folks at PJM acted just in time to unplug us,\notherwise Washington would have gone down too,” Dick suggested.\n\n“But there is no way that this could have been terrorism, right, Dick?” Koppel\nasked, seeking to further assure people.\n\nDick paused. He knew more than he could say publicly about the fragility of\nthe power grid in the face of a cyberattack. As the nation’s first Cyber Czar,\nhe had pushed for meaningful cybersecurity regulation of power generation and\ndistribution companies. The electric power lobby had pushed back hard and,\nlargely, won. Nonetheless, President George W. Bush’s 2003 National Strategy\nto Secure Cyberspace that Dick had released six months before the blackout had\nstressed the need to increase protection of the power grid cyber controls.\n\nAnswering Koppel within the first hour of the blackout, Dick suggested that\nthere was no way to know just then if the grid had been attacked, but it was\npossible, he insisted, for malicious activity to bring down the grid. Koppel\ndownplayed the idea.\n\n### If a Tree Fell in a Forest\n\nA U.S.–Canadian investigation completed a year later placed the blame on a\ntree. To be fair, it had been a really big tree, in Ohio, and it had fallen on\na sagging, overloaded transmission line. Buried in the study was an\nobservation that an internet worm running rampant that day may have slowed\ndown the control network, possibly contributing to the cascading failures that\ntripped circuits providing power to 50 million people. Still, no one wanted to\nsay that the power grid could be brought down by malicious internet activity.\nIn retrospect, the 2003 disaster was not a cyber incident, but what Dick and\nothers knew then was that such a catastrophe could be caused by a cyberattack.\n\nA dozen years later, Ted Koppel was convinced too. He wrote a book called\n_Lights Out,_ about the threat of a cyberattack plunging the nation into\ndarkness not for hours, but for months. Koppel wrote that cyberattacks could\ncause large transformers and generators to become so damaged that they would\nbe irreparable, and he noted that there are few spares lying around. It takes\nmonths, and electric power, to make new ones.\n\nEven in 2015, however, some critics found _Lights Out_ to be hyperbolic,\nexaggerated, or alarmist. By then, however, there should have been less doubt.\nIn 2007, a generator was attacked and destroyed from the internet in a\ncontrolled experiment at Idaho National Laboratory. In 2015, Russian hackers\nplunged much of Ukraine into darkness by taking remote control of a power grid\ncontrol room, making the controls reflect normal activity, and then opening\nbreakers throughout the subgrid. A year later, they did it again, although to\nanother part of Ukraine.\n\nBy then film, television, and thriller writers had totally accepted the idea\nof hackers taking down the grid. It was the premise of Bruce Willis’s _Live\nFree or_ _Die Hard_ , and the television series _Madam Secretary_ showed an\nAmerican President retaliating against Russia by plunging Moscow into darkness\nin winter. (By 2017, the idea of the President ever standing up to Russia\nseemed more fictional than any cyberattack on the grid.)\n\n### Is Self-Regulation Enough?\n\nThe electric power industry, however, continued to deny that there was much of\na problem. The industry’s self-regulatory body, the North American Electric\nReliability Council (NERC), was satisfied that its rules for critical\ninfrastructure protection (known to all in the business as “nerk sip”) were\nadequate to protect the grid from hackers. The government’s regulatory body,\nthe Federal Energy Regulatory Commission (FERC), tended to defer to the\nindustry. (By 2019, however, FERC was more assertive and fined Duke Energy ten\nmillion dollars for cybersecurity lapses.)\n\nIndeed, so powerful were the industry’s lobbyists that only part of the grid\nwas subject to any federal regulation at all. FERC has its oversight limited\nto the “bulk” power system. Even then, the industry group managed to exempt 90\npercent of the grid by declaring it “low impact” or noncritical.\n\nThe “last few miles” distribution systems are beyond the reach of the federal\ngovernment regulators. State governments, which have shown little interest or\nability in regulating the cybersecurity of power grids, have legal authority\nover it. Power companies have noted that the state governments, which do\nregulate the price for electric power, are really reluctant to authorize\nincreases in electric rates. So really, you see, there is no way that the\ncompanies could come up with the money to pay for more extensive cybersecurity\neven if they wanted to, or so they say.\n\nThe FERC, however, did require power grid companies to report cyber incidents\non the parts of the grid for which it has authority. In 2015 and 2016, no one\ndid. That strained the credulity of even the FERC and the NERC, both of which\nbegan a process in 2018 to lower the threshold of incident reporting. FERC\neven suggested the radical notion (one commentator called it a “sea change”)\nthat portable devices that connect to the grid, such as laptops and tablets,\nshould meet cybersecurity standards. FERC’s newfound courage, however, may\nhave been both too little and too late.\n\nBy the fall of 2017, the Department of Homeland Security was quietly informing\npower grid companies that there was good reason to believe that potential\nadversary nations were attempting to penetrate the controls of the U.S. power\ngrid. For some on the receiving end of that information, it was hardly news.\nSome companies had been monitoring attempts to penetrate their networks for\nyears. Others, however, seemed as if they would rather not know. They\ncontinued to repeat the mantra that they were “nerk sip” compliant, that their\ncontrols were not connected to the internet, that they could not afford to do\nanything more, and that it was really the government’s job to save them from\nforeign armies.\n\n### Blinking Red Lights\n\nIn the summer of 2018, by which time most of the nation had accepted the fact\nthat Russia had actually meddled in the 2016 election and was hacking into\nanything it could in the United States, the head of the U.S. intelligence\ncommunity publicly warned that the power grid had in fact already been\nsuccessfully penetrated by Russia. DHS’s chief of industrial control system\nanalysis, Jonathan Homer, specified, “They [the Russian group Dragonfly] have\nhad access to the button, but they haven’t pushed it.” Dan Coats, the Director\nof National Intelligence and a former Republican Senator, described the\nRussian attacks on the U.S. electrical grid as being so severe that,\nfiguratively, “the warning lights are blinking red.”\n\nIn background briefings that followed Coats’s statement, government officials\nexplained that the Russians had “jumped the air gap,” which the power grid\ncompanies contended they had created between their internet-connected systems\nand the actual controls of the power networks. In point of fact, few companies\nhad actually isolated their controls. There was almost always a path from the\ninternet to the company’s intranet, and another path from there to the grid\ncontrols. The connections among and between the company’s internal networks\nwere usually segmented by firewalls, but firewalls seldom stop sophisticated\nhackers.\n\nBy 2019, Coats and the heads of all seventeen U.S. intelligence agencies were\ngetting more explicit. In their annual threat assessment to Congress, the\nagency heads wrote that Russia had the ability to disrupt the U.S. power grid\nand that China had the capability to disrupt the U.S. natural gas pipeline\nsystem (upon which much of the power grid relies). These were not theoretical\ncapabilities, the agencies made clear. These were swords of Damocles hanging\nabove America, swords that could be dropped at any time.\n\nRussia’s hackers had allegedly gone after the companies that supply parts to\nor do maintenance on the grid control side of the air gap. By compromising\nthose systems, the attackers could gain the log-in credentials of people\nauthorized to have access to the control network. Often that access would be\nremote, over virtual private networks (VPNs) running on top of the internet.\nThe Russians could then plug into the grid’s control. Then they could move\ninto the systems that display the state of the grid on big monitors in control\nrooms and send instructions to the thousands of devices in the field.\n\nIf all of that sounds a little familiar to you, maybe you read speculation\nabout how the United States had attacked the Iranian controls for the nuclear\ncentrifuges at Natanz. The Iranians had basked confidently in the assurance\nthat their control network was also “air gapped” from the internet. Not\nsatisfied with the security provided by firewalls, the Iranians had sought to\nprotect the plant from U.S. or Israeli cyberattack by having no internet\nconnection anywhere in the complex. The United States attacked, according to\nsome experts, by infiltrating the Stuxnet software into devices brought into\nthe building by contractors, perhaps on laptops or printers.\n\nThus, the United States now faced the specter that people in American power\ncontrol rooms could someday look up at “the big board,” the giant monitors on\nthe wall, and see everything blinking green for good, while the reality was\nthat the system was malfunctioning.\n\nEven if you had known for years that it could happen, having the head of U.S.\nintelligence say that it had taken place was enough to cause shock and high\nlevels of concern in much of official Washington. President Trump, however,\ndid not talk publicly about the Russian presence inside the U.S. power grid\ncontrols. He could barely admit they had tried to influence his election, and\nthat only on alternate days. Thus, there was no presidential directive, no\nten-point action plan, no public threat to Moscow whatsoever.\n\nLeft on their own to devise a reaction, the Washington policy chattering\nclasses suggested a variety of approaches to the problem of having a potential\nadversary possess the ability to throw much of the nation back into a\nnineteenth-century preelectric age, only worse, because this time we would be\nwithout manual devices. Keith Alexander suggested that it was the military’s\njob to defend the grid. He did not say how it would do that. Some commentators\nsuggested that improved information sharing by the government would help the\ncompanies do a better job finding the Russians on their networks.\n\nTaking a page from Special Counsel Robert Mueller’s playbook, others proposed\nthat the United States should indict the individual Russian military and\nintelligence officers who had done the hacks. In addition, maybe we could\nseize their assets in the United States and ask Interpol to issue\ninternational arrest warrants for them.\n\nThe more robust-sounding responses came from those who believed in deterrence.\nIf we were in the Russian power grid controls, then maybe we could scare the\nRussians into inaction, they said. Just like the U.S. President on that _Madam\nSecretary_ episode _,_ we could throw Moscow into wintry darkness if they\ntried to shut off the power in Washington, or mess with the Eastern\nInterconnect (everything east of the Mississippi, including Ontario).\n\nAll of those reactions struck us as pathetic and, were this not a serious\nbusiness that could lead to death and war, even laughable. Russia doesn’t care\nif we sanction their intelligence officers, and none of them have assets in\nthe United States anyway. They do not travel abroad under their real names,\nand they are never going to be caught because of an Interpol notice. Russia\nwill not be deterred by the threat of the United States turning off their\nlights. If they are going to attack us, they will already have calculated that\nit will result in some risks and costs. Moreover, will you really feel better\nas you freeze on a dark night, eating cold tuna fish from a can and figuring\nout how to break into an ATM, knowing that your Russian counterpart is also in\nthe dark? At least _they_ have plenty of vodka.\n\nThe reason the Russians are in the controls of the U.S. power grid is because\nit is easy to be, and very useful to be. Whether or not they could actually\nbring the country to its knees without firing a shot, no one knows. And that\nis the point.\n\nWe have to admit that it’s a hard problem. The power grid is a crazy quilt of\nhundreds of disparate electric power companies of very different sizes and\ncompetencies. Each company has tens of thousands, if not hundreds of\nthousands, of devices connected to it, many of them sitting out in the open,\nunguarded.\n\nWe got here by ignoring the warnings that have been issued by government\nexperts for almost twenty-five years that the power grid was becoming\nvulnerable to cyberattacks. Those warnings were ignored because such an attack\nhad never happened before, what Dick, in the 2017 book _Warnings_ , called the\nInitial Occurrence Syndrome bias.\n\nTaking the warnings seriously would have been an inconvenience to grid owners\nand operators. It would also have meant spending money, which would have had\nthe effect of raising electricity rates and/or lowering company profits.\n\nMoreover, because self-regulation usually results in minimal regulation,\nreally addressing the problem would have meant having serious, mandatory\ngovernment regulations and compulsory compliance enforcement. Business leaders\ntend to resist any government regulation. They resist new regulation of any\nkind like white blood cells attacking a disease. “How would government know\nwhat to do? They can’t even protect their own networks.”\n\nWe have placed the national security task of creating cybersecurity for most\nof the power grid into the hands of fifty state-level electric-rate-setting\nregulators, some of whom just might be subject to the blandishments of big\nutility companies and their lobbyists.\n\n### Five Not-So-Easy Pieces\n\nThe more important question which you are now asking yourself is, How do we\nget out of this mess? Well, we begin by admitting we have a problem, a big\none. There is no need here to once again paint the picture of what could\nhappen. By now, you can imagine it. If we have a big problem, it may require a\nwillingness to engage in bold solutions. Half measures are not recommended. We\nhave tried that already and they have failed. So . . .\n\n**First** , put someone in charge and give them real authority. We suggest\nthat this someone be a senior official in Homeland Security. If you feel\nbetter with someone from the Energy Department, fine. If you think the\nmilitary should do it, read chapter 12 on the military and realize that they\nare busy enough trying to defend themselves.\n\nReal authority means federal-level mandatory and compulsory regulatory\ndirective capability, unencumbered by prolonged legal review processes. It\nmeans authority over the cybersecurity of every aspect of the power grid: big\npower companies, little cooperatives, bulk power, generation, distribution,\nand last-mile access. It means the authority to raise rates and to direct\nspending. Did someone tell you security was cheap? Would you rather buy\neveryone an emergency generator and months of fuel?\n\n**Second** , launch a major program using the best private-sector threat\nhunter firms to find and remove foreign implants, backdoors, and remote access\nto the industrial control systems (ICS) and supervisory control and data\nacquisition systems (SCADA) on the grid. This will not be easy. Ask the U.S.\nNavy how easy it was to get the Iranians out of their network (and by the way,\nthe Russians are better).\n\n**Third** , put in place that combination of state-of-the-art cybersecurity\nbest practices that have achieved success in America’s most secure\ncorporations. Private-sector expert panels can design the essential set of\ncontrols, but they are likely to include permanent threat hunting software and\nteams, continuous monitoring applications, privileged access management\ncontrols, microsegmentation, endpoint detection, remediation systems, limited\nremote access, and vendor/supply-chain controls. Private, third-party teams,\nincentivized to find vulnerabilities, must then be used on a near constant\nbasis to monitor compliance. A pattern of noncompliance would result in severe\nfines, or forfeiture of the property.\n\n**Fourth** , prepare better for the worst. We also need to be discussing how\nto maintain society once the grid goes down for a long time. There needs to be\na contingency plan that helps to mitigate the most severe effects of such a\nworst-case scenario.\n\nIt may not be possible to stop the lights from going out from an attack that\nessentially flips breakers, but it should be possible to put better controls\non transformers and generators to prevent a hacker from overriding their\nlimits and causing physical destruction. In the event that fails, there should\nbe replacement systems stockpiled, or many more generators on standby than are\ncurrently used day to day. Those spares should not, however, be used on peak\ndays. They would be dedicated to respond to hostile attack situations to bring\nthe grid back up in isolated subgrids.\n\n**Fifth** , you want to hack into the Russian power grid’s controls and\npublicly threaten them with retaliation? Sure, okay, but we may already have\ntried that, and if so, it has not deterred them. Maybe we could say we are\nserious this time. And maybe deterrence will work, and maybe we can secure the\nexisting grid with retrofits, but it would be nice to have a plan B in case\ndeterrence fails and we cannot get all of the power companies to secure their\nnetworks.\n\nWe don’t really have a plan B today, and that contributes to crisis\ninstability. There is probably greater uncertainty on our part about what\ndestruction they can do to us than there is uncertainty on their part about\nthat same question. As Dr. Strangelove might have said, “Vee need to close the\nuncertainty gap.” We can do that by stepping up our cyber defenses on the\npower grid and causing the Russians and others to be uncertain what the effect\nwould be if they tried a major attack.\n\nWhat would a plan B look like? It would be a secure, segmented, diverse-source\nmicrogrid (SSDM) program, with some microgrids completely federally funded and\nsome built with incentives from the federal government. To build a bipartisan\ncoalition for the program, it would be justified by both national security and\nclimate change concerns. What we are suggesting for a plan B is:\n\n  * Thousands of heterogeneous sources of electricity generation and storage that would not be tied to any of the three big national Interconnects, or even the regional subnetworks\n\n  * Power generation facilities that would have guaranteed access to fuel, with on-site or near-site storage, or would use alternative fuels\n\n  * Alternative fuel sources that would include hydrogen cells, wind, solar, hydrothermal, and new-design compact nuclear reactors\n\n  * New innovative methods of storing power at every building, such as new high-capacity battery packs, or pumped-storage hydroelectricity\n\n  * Microdistribution networks that would carry the power on new lines, ideally underground, to key facilities that must have continuous power, including military bases, hospitals, and national-level infrastructure\n\n  * The location of power generators on the premises of critical facilities, such as military bases, to the greatest extent possible.\n\nOur SSDM proposal is at once evolutionary and revolutionary. The evolutionary\naspects include the construction of large alternative-energy plants. There\nalready are large solar and wind plants built by the private sector. Hydrogen\nfuel-cell plants are being built, including a 20-megawatt generator we were\nbriefed on that would use an abandoned factory in New Britain, Connecticut.\n\nThe DoD has already built large-scale solar and geothermal plants on its\nbases, such as a 16-megawatt solar plant at Davis-Monthan Air Force Base\noutside Tucson, a 14-megawatt solar plant at Nellis Air Force Base outside Las\nVegas, and a 170-megawatt geothermal plant at China Lake Naval Air Weapons\nStation in California.\n\nThe revolutionary parts of the SSDM proposal are threefold. First, it would be\nthe building of a new, second national power grid on a crash basis as a major\ngovernment initiative, with significant private-sector involvement. Second,\nthe new grid would not be interconnected, but would instead consist of\nthousands of energy sources intended only for specific facilities. Not being\ninterconnected, or connected in any way to the internet, it could not be taken\nout by a single or even a handful of cyberattacks. Third, and most important,\nperhaps, it would be designed with cybersecurity in mind, rather than as a\ngrudgingly added retrofit and afterthought.\n\nYes, it would be expensive, but think of it as a weapons system. Without a\nsystem like SSDM, the nation will be defenseless against a nation-state actor,\nsomebody like the Russian GRU, engaging in a cyberattack that would\ntechnologically revert us to the nineteenth century, but without all the\nequipment that people in the nineteenth century had to deal with life in a\nsociety without electricity.\n\nWe spent $201 billion to fund the DoD Missile Defense Agency between 1985 and\n2017. In 2018 alone, Congress approved $11.5 billion for missile defense. Yet\nno defense expert we talked to thinks that the United States could stop a\nRussian missile attack on America. By saturating the defenses with multiple,\nsimultaneous launches and scattering decoys, Russia or China could easily\ndefeat the missile defense system. Nonetheless, we spend because we just don’t\nlike the idea of Russia or some other nation being able to attack our\nterritory and knock the legs out from under our society and economy. Now,\nremember earlier in the chapter when we quoted the Director of National\nIntelligence saying the Russians were hacking into the controls of our power\ngrid?\n\nWe’ve spent enough time between us in the Executive Office of the President to\nknow how that game is played, so we have a pay-for. If you don’t care for\nours, get your own. Ours is the Air Force program to replace the Minuteman\nintercontinental ballistic missile (ICBM). They are planning to spend upwards\nof $140 billion to do that, and you just know there will be a cost overrun. We\ndo not need to have ICBMs, land-based nuclear missiles sitting in holes on\nfarms in Wyoming with about four hundred nuclear warheads. They are a relic of\nan age when we thought seriously about engaging in the kind of thermonuclear\nwar that would kill off the population, all of it. For that purpose, we also\nhave five times as many nuclear warheads on missiles on submarines. There are\nalso bombers and cruise missiles.\n\nWhich kind of Russian attack is more likely: one that crashes our power grid\n(the power grid they have already penetrated) and causes our society to\neffectively cease functioning for months, or one that uses nuclear weapons and\nrisks our nuclear retaliation and the end of all human life? Don’t struggle\nwith the answer. It was a rhetorical question.\n\nWe are not saying abandon all efforts to secure the existing grid. We are\nsaying that probably won’t work too well and we need a plan B, soon. A plan B\nthat gives us another grid that the Russians could only have low confidence in\ndamaging significantly, a second grid that would keep some of our most\nessential systems able to operate even if the Russians take down our\nInterconnects.\n\nSome of you may be thinking that the government should not be regulating\ncybersecurity because it can’t even secure itself. You would be half right, as\nwe see next.\n\n\n## Chapter 11\n\n## SECURING THE FEDS\n\nAgencies do not understand and do not have the resources to combat the current\nthreat environment.\n\n—WHITE HOUSE OFFICE OF MANAGEMENT AND BUDGET, “FEDERAL CYBERSECURITY RISK\nDETERMINATION REPORT AND ACTION PLAN,” MAY 2018\n\nShit, it’s snowing,” the lanky, blond guy said aloud, looking out from the\nlobby of the Business School. Overhearing him, a friendly, white-haired\nprofessor standing nearby asked, “Is that a problem for you?” The professor,\nCorey Schou, was one of the founders of cybersecurity education in America.\n“It snows a lot here. After all,” he said, “it is Idaho.”\n\n“I know, but it’s hard to practice pole-vaulting in the snow,” the student,\nConnor Pate, explained. Pate was a senior at Idaho State, recruited from his\nReno, Nevada, high school because he was among the top pole-vaulters in the\ncountry. Unable to practice that day, he accepted Professor Schou’s offer to\ntour the cyber lab. The professor recalls liking a student who was mad because\nhe could not train. He was also impressed by the undergrad’s knowledge of game\ntheory, something they discussed on the lab tour.\n\nA week later Connor Pate was filling out an application to join CyberCorps, a\nlittle-known federal scholarship program that has been helping to provide\ncyber-defense personnel for the U.S. government for almost two decades. The\nnext year Pate was in the MBA program at Idaho State, specializing in\ncybersecurity as a member of CyberCorps and paying no tuition.\n\nHe did, however, have mandatory Saturday classes and had to be part of a team\ncreating a cyber range on which to practice attacking and defending, staff a\nsecurity operations center, participate in a multiuniversity cyber\ncompetition, and provide an oral defense of a written thesis. All of that and\nmore were in addition to the core work required for the MBA. “At Idaho State,”\nPate told us, “CyberCorps is elite and tough.” Professor Schou admits, “We\nallow only about a dozen students at a time, combining both years of the two-\nyear program here.”\n\nCyberCorps is a Scholarship for Service program funded by the National Science\nFoundation, administered by the infamous Office of Personnel Management, and\nadvised by the NSA and DHS. Created by President Clinton in 1999, the program\nfirst existed at only a handful of schools, including from the start Cory\nSchou and Idaho State. Now it offers full scholarships at more than seventy\nundergraduate colleges, graduate schools, and, recently, community colleges.\n\nWhen CyberCorps was created, its originators, chiefly Janet Reno and Dick\nClarke, were not very hopeful that it would be a long-term solution to the\nhuman resources needs of federal cybersecurity offices. At least, however, it\nwould give the government some highly trained people for a few years at a\ntime, introduce the latest state of the art to other federal cyber employees,\nand increase the number of people in the nation’s overall cyber-skilled\nworkforce. The results have been better than expected, in part because many of\nthe faculty involved, people like Corey Schou, instilled a sense of public\nservice in their students.\n\nSchou had been teaching cybersecurity for almost fifteen years before\nCyberCorps came into existence, as well as helping the government to create\nsecurity standards for its national security–related networks. He had been a\nleader in national efforts to create certification requirements for\ncybersecurity professionals. It was only natural that he would help to create\nthe first standards for colleges to qualify as CyberCorps’s National Centers\nof Academic Excellence in Cyber Education. He was also on the first panel of\nacademic experts to determine which schools actually made it. (He recused\nhimself when it came to Idaho State, but his school became one of the original\nseven approved for the program.)\n\nThe leaders in cyber education in America in 1999 were not the universities\nthat you might have assumed would be pioneers in the field, like MIT or\nStanford. Places such as Idaho State and Tulsa University were among the early\nleaders and the best at producing cybersecurity practitioners at the\nundergraduate and graduate levels. Meanwhile, MIT was still handing out SM\ndegrees in computer science without requiring a recipient to take even a\nsingle semester-long course in cybersecurity.\n\nEach one of the National Centers of Academic Excellence in Cyber Education can\norganize a unique program, but the curriculum and faculty must meet the\nnational standards. Cory Schou’s program is not in the computer science\ndepartment. It’s in the business school, because Schou thinks cybersecurity\nexperts need to understand risk management and how cyber decisions fit into\noverall business decisions. When admitting students to the elite program,\nSchou looks for diverse backgrounds, not computer jockeys. He limits his two-\nyear program to a few students at a time to “create Bentleys, not Cadillacs.”\n\nNot only do the CyberCorps students get free tuition for two years, they are\nalso paid thirty-five thousand dollars a year for room, board, books, and\nequipment. In return, they promise one year of service in a government\nagency’s cybersecurity office (federal, state, local, or tribal government\nagencies qualify) for every year of scholarship, up to two years.\n\nThe government also pays to fly the CyberCorps students to Washington, D.C.,\nusually twice. One time they go to a job fair to land a summer intern\nassignment. Connor Pate found a summer internship at NASA’s Glenn Research\nCenter in Ohio. The second year they go back to the fair looking for an entry\njob. There is no lack of openings. The starting salary, however, is usually a\nlittle shy of sixty thousand dollars. In many cities in America, the starting\nsalary in a corporation for someone with the same skills would be at least\ntwenty-five thousand dollars higher.\n\n“But then, I don’t have any student loan debt,” Connor Pate told us. “And I am\ngetting to learn so much more than I ever would have in an entry-level job in\nsome company.” Pate landed a position in 2018 as a civilian cybersecurity\nexpert in the U.S. Army and is working his way through a two-year series of\nassignments around the Army, from operations to research to procurement.\n\nWill he stay on as a government employee defending a federal network after his\ntwo-year obligation is up? Right now his answer is: “Definitely. It was weird\nat first going to work at a fort, like Fort Belvoir, or hearing artillery\ngoing off and shaking my building up at Aberdeen [Aberdeen Proving Ground, an\nArmy research center],” Pate recalled. “But you get to work with some amazing\npeople on really cutting-edge problems. The Army is always under a cyberattack\nand they are doing and spending a lot to defend themselves.” He hopes the\npromotions will come quickly so that his government salary doesn’t fall\nfurther behind what he could be making in the private sector.\n\nThe motivating quality of public service, the great challenge, and, in some\nagencies, the resources available have been enough to keep many of the\nCyberCorps graduates in federal service after their two-year obligation. Some,\nlike Idaho State alum Steve Hernandez, have moved rapidly up into leadership\npositions. Hernandez moved over in 2017 from Health and Human Services to be\nthe chief information security officer at the U.S. Department of Education.\nAnother Idaho State alum, Alma Cole, was the CISO at Customs and Border\nProtection (CBP) in 2018.\n\nEven with the CyberCorps Scholarship for Service program, it is still\ndifficult for the government, and some other organizations, to beat the\ncompetition from corporations offering bigger salaries, signing bonuses, and\nother perks. Often, those recruited by the private-sector companies end up\nworking for the federal government, but in ways that prove to be more costly\nand create less institutional memory or loyalty. That happens because the\ngovernment uses contractor corporations such as Booz Allen Hamilton, ManTech,\nand General Dynamics to provide “butts in seats,” corporate employees sitting\nin government buildings doing what you might have assumed a government\nemployee would be doing.\n\nThe contractors are not incentivized to create secure networks. If they do,\nthey may work themselves out of jobs. They also have few real disincentives\nfor failing to secure a network. Few federal contractors ever pay penalties or\nhave their contracts canceled because they have failed to secure an agency’s\nnetwork.\n\nContract employees have no loyalty to the federal agency they are assigned to\nand are often moved around from one agency to another. Butts in seats do not\noften get to understand the culture or mission of an agency. For-profit\ncorporate employees have also proven to be a security risk in the handling of\nsensitive, classified information. While it is true that the cost of the\nactual butt-in-seat staffer may be in the same range as the current all-in\ncost of a federal employee, the compensation of the corporate leaders of\nfederal contract firms is often three, four, five, or six times higher than\nthat of the Senior Executive Service (SES) federal employees who hire their\nfirms.\n\nWhat has prevented the federal government from having its own large, strong\ncadre of cybersecurity personnel is the overly rigid civil service system.\nThat system makes it difficult for government employers to dismiss employees\nwhen they are dissatisfied with their performance or when the job for which\nthey were needed is completed. The rules have been there since the late\nnineteenth century to prevent political parties from firing professional\nemployees and replacing them with partisan supporters. In the twenty-first\ncentury that is still a concern, especially given Trump’s treatment of career\nofficials. The rules do, however, need to be modified to suit the new nature\nof work and the new needs of government.\n\nAs 2018 came to an end, Congress agreed on something. It came as a shock to\ncynics who thought the partisan gridlock had made a bipartisan approach to any\nsubject impossible. What the two parties and the two houses of Congress agreed\nupon was cybersecurity, or at least a new agency to deal with it. The\nCybersecurity and Infrastructure Security Agency (CISA) was authorized to come\ninto existence within the Department of Homeland Security, on a par with other\nagencies in the department such as the Secret Service, Coast Guard, and\nFederal Emergency Management Agency (FEMA).\n\nActually, CISA is really just a reorganization of things that were already in\nDHS and not an increase of resources, but the new agency’s mandate is to help\nthe other civilian federal departments and agencies protect their cyberspace.\nCISA is also to work with the private sector to encourage and assist\ncorporations and other organizations. While not the proverbial silver bullet,\nthe creation of CISA was a good step. Many other steps are needed to secure\nthe federal departments and key agencies such as the National Weather Service,\nthe Centers for Disease Control and Prevention, the Food and Drug\nAdministration, and other civil service organizations that keep us safe and\nhealthy.\n\nThere are scores of ideas about how to improve federal department and agency\ncybersecurity, suggested in numerous task forces and review commissions. Given\nhow difficult it is to get anything done in a time of hyperpartisan politics\nin Congress, we think that starting with a small number of nonpartisan ideas\nis more practical than trying to solve all of the government’s IT security\nproblems at once. Therefore, we propose just two additional steps for\nconsideration: creating a professional cadre of federal cybersecurity officers\nand centralizing some federal IT operations.\n\nFirst, the professional cadre: Today CyberCorps is a program to fund college\nstudy, recruit entry-level employees, and help place them in their first jobs\nin the departments. We would like to see it become more than just an entry-\nlevel system, but rather a government-wide cadre of highly skilled employees\nwho could be deployed in federal agencies and departments as needed. In our\nvision they would all belong to a central organization such as DHS’s new\nagency, CISA.\n\nCyberCorps could centrally hire cyber experts at all levels of skill, provide\nthem specialized training beyond what they learned in school or on the job,\ncreate a continuing education program, establish grades or ranks requiring\nadvanced certification and experience, compensate them differently from the\nrest of the federal civil service, reward them with significant incentive\nbonuses, and be able to dismiss them more easily. CyberCorps could then\nallocate personnel to departments and agencies for shorter- or longer-term\nassignments, while retaining central personnel management authority.\n\nCyberCorps officers could also work in state and local governments and some\ncritical infrastructure corporations on limited project-based assignments.\nOver time, the chief information security officers of the departments and\nagencies would be selected from and by CyberCorps.\n\nThis professional cadre of federal IT security experts would have ranks from\nentry level to a Senior Cyber Service, modeled on the Senior Foreign Service\n(at the State Department), the Senior Intelligence Service (at the CIA), and\nthe Senior Executive Service elsewhere in government. These existing Senior\nService ranks are now the equivalent of general and admiral ranks in the\nmilitary. To advance through the ranks of the Senior Cyber Service,\nprofessionals would have to continually qualify with work experience, tests,\nand continuing education programs similar to the National War College (a\nprerequisite for becoming an Army general or Navy admiral). Homeland would, in\nour plan, run a National Cyber College for members of the Senior Cyber\nService.\n\nThe civil service laws would have to be changed to allow the creation of that\nkind of expanded CyberCorps. In addition, the current Scholarship for Service\nprogram might have to be changed, to recruit, train, and place more cyber\nexperts in the new federal service. Specifically, the existing scholarship\nprogram might need expanded funding for more scholarships, faculty training,\nequipment such as cyber ranges for realistic training, paid internships,\nhiring bonuses, and moving expenses.\n\nCyberCorps may also be one place where some of the security clearance problems\nassociated with hiring into the federal government could be addressed. Your\ntwo authors have both taught graduate courses at a couple of universities and\nhave noticed that all too often our students have to hang around for many\nmonths after graduation before starting work in the federal government. They\nwait with no pay for their security clearances to be completed. For our Idaho\nState cyber scholar Connor Pate, it took nine months from the time he\ngraduated with his MBA and a federal job offer to when he could start work and\nbe paid. Connor waited. Others do not. They take that attractive private-\nsector offer. CyberCorps could begin the clearance process for students as\nsoon as they joined up, while in school. The Corps could also give them a\nstarting job that would not require a top-secret clearance while they were\nwaiting for a full vetting to be completed.\n\nIt’s good that the military has its Cyber Command to defend military networks.\nThe other half of the federal government, however, needs its cyber defenders\ntoo. We need a new CyberCorps.\n\n### Learning from State Governments: Not Everyone Can Do IT\n\nWe would also centralize IT service in the civilian agencies of the federal\ngovernment. People like to justify the existence of fifty state governments in\nthis country with the phrase “the states are laboratories for innovation.” The\nsystem of fifty fiefdoms also gives you a better-than-even chance of living in\na state that has poor education and health systems, but we digress. One thing\nthat several states have done successfully and that could serve as a model for\nthe federal government is to create information technology departments. We\nhave had the pleasure, as unpaid advisers, to work with the IT departments in\nboth New York and Virginia.\n\nThe idea is simple enough. No state agency (or in the case of Virginia, no\ncommonwealth agency, because “commonwealth” just sounds classier) or\ndepartment is likely to have the ability to recruit enough quality IT\nprofessionals to run the agency’s own network effectively and securely.\nMoreover, the leadership of, let’s say, the Fish and Game Department is\nprobably not really likely to be a great set of supervisors for a bunch of\ncomputer geeks running the agency’s network. Nothing against Fish and Game\npeople, you understand.\n\nThe solution is to make all, repeat all, IT functions into services that state\nagencies buy from the one state agency that specializes in computer science,\nnetwork management, data storage, and, oh yeah, cybersecurity. Rather than\njust issuing cybersecurity guidelines and rules and hoping that the other\nagencies think the rules are important enough to spend money implementing, the\nIT department is responsible for securing everything.\n\nThe statewide IT departments often contract out to one or more IT services\ncompanies, which actually run parts of the network day to day. The IT\ndepartment specifies the deliverables, the standards, the security features\nthat will appear in the contract. The state employees in the IT department do\ncontract monitoring, oversight, and quality control. Expecting each of forty\nor fifty separate state-level agencies and departments to be able to do that\nkind of contract management is unrealistic. Many states have figured that out\nand have centralized IT.\n\nWhy don’t we take the results of this successful experiment in “the\nlaboratories” that are the state governments and try it out at the federal\nlevel? Today, there are scores of independent federal departments and\nagencies, each with the authority to decide whether they are going to run\ntheir own IT network or let some other department do it. If they do run their\nown, and they almost all do, they must live up to security standards issued by\nthe White House’s Office of Management and Budget in association with Homeland\nSecurity. Most departments and agencies, however, get away with flouting the\nsecurity standards.\n\nYou can’t really blame a Cabinet secretary for wanting to spend money on, say,\na shiny new embassy complex in London, rather than a state-of-the-art endpoint\ndetection and response (EDR) software application. After all, you can cut a\nribbon and throw a hell of a party at a big new embassy. Besides, what\ndiplomat even knows what an EDR is anyway?\n\nThe Government Accountability Office (GAO) gives the federal departments and\nagencies grades, but there is no real cost to the people who run the\ndepartments if they get a bad grade. The Secretary of State, for example, is\nnot held back and denied promotion to the next grade. So, of course, most of\nthe departments and agencies do poorly in the cybersecurity grading and\ncontinue to underfund security. If there is no cost for poor performance in\nthings that agency leaders do not want to do and do not really understand,\nthen there will always be poor performance. Although usually there is no cost\nfor failure or mediocrity in federal cybersecurity, there are exceptions.\n\nThe GAO doesn’t usually give out F grades, but for all practical purposes,\nKatherine Archuleta got an F and flunked out. Yet in a way, it wasn’t really\nher fault. Nonetheless, we are still kind of mad about the whole thing. Both\nof your authors held top-secret and “code-word” security clearances. Before\nthe government deemed we were worthy, it spent hundreds of thousands of\ndollars vetting us. Security investigators went around the country talking to\nour high school teachers, college roommates, drinking buddies, coworkers,\nlandlords, and cranky neighbors asking them to tell embarrassing stories and\nprovide derogatory information about us. Somehow, nonetheless, we both got\nclearances.\n\nAll of those interviews, along with bank and tax records, medical files,\ncollege transcripts, credit scores, and other documents, went into the\ndatabases at the Office of Personnel Management (OPM). Then the Chinese\nPeople’s Liberation Army downloaded it all and sent it to Beijing. Almost a\nyear after the OPM figured that out (because somebody told them), they sent us\nnotices telling us that they had a little problem. The OPM suggested we click\non a link to get free credit-score monitoring. Neither one of us was terribly\ninclined to click on a link, especially one suggested by the OPM. Talk about a\nprivacy breach. Do we still sound bitter?\n\nWell, Katherine Archuleta was the head of the OPM at the time, and after a lot\nof other bitter people demanded it, she was forced to resign. It was a rare\noccurrence of executive accountability in government. From her perspective,\nthough, was she really supposed to win a fight with the Chinese army? She was\na teacher from Denver, who had become a school administrator and then a\npolitical activist. We are sure that when the Obama White House people offered\nher the OPM job, no one said there might be a cyber battle with a foreign\narmy. She thought she was just going to run the federal government’s highest-\nlevel human resources (HR) office. That would have been challenge enough for\nanyone.\n\nIn the great tradition of the government closing the barn door after the\nChinese have run off with all the horses, when the smoke cleared, the job of\nhandling all that sensitive security background investigation material was\ngiven to the Pentagon. It’s a common punt in Washington to make the military\ndo something hard. Of course, as we know and will discuss later, the military\nare not exactly stellar examples of secure network operators either.\n\nWhat we think makes more sense than asking all the little agencies like the\nOPM to defend against the Chinese army is to create a federal IT Services\nAgency (sure, call it ITSA) to own and operate the computer networks of all\ncivilian agencies. The DoD and the intelligence community could keep control\nof their networks, not because they are perfect at cybersecurity but because\nthey would use all their influence to kill any proposal to take away part of\ntheir empires.\n\nThere could also be a few exceptions granted to some civilian agencies, of\ncourse, like the state police who have an exception in Virginia. Maybe there\nwould be an exception for the Energy Department’s programs for managing\nnuclear bombs, okay, but almost every other civilian agency ought to be using\na series of federal networks and cloud services run by our proposed ITSA.\n\nThere have been baby steps in this direction. Departments and agencies can now\nask some bigger department to run their network for them, but few do. Maybe\nit’s a prestige thing for everyone to run their own network, similar to the\nstatus requirement that seems to force every Cabinet secretary to have their\nown security personnel and black Chevy Suburban with blinking blue lights.\n(Are there really that many people who want to kill the head of the\nEnvironmental Protection Agency or the Department of Education? Probably not,\nbut having that security detail cuts down on the commuting time in traffic and\nthey also get you really good tables at D.C. restaurants and walk you around\nTSA lines.)\n\nThe Obama administration did create new titles for people in the White House,\nsuch as chief information officer and chief technology officer. After seven\nyears, President Obama even got around to appointing a federal chief\ninformation security officer when there were less than four months left in his\npresidential term. What we have in mind is something more ambitious.\n\nCivilian federal departments and agencies would specify their IT needs and\nthen buy them from a federal IT Services Agency. That agency would only\ndeliver the services with high levels of security designed and built in by the\nCyberCorps experts over in DHS’s new CISA. As the state governments do now,\nthe IT agency could contract out to private IT services companies to provide\nsupport, but the IT agency and CISA would specify the requirements and the\nstandards and then ensure they are met.\n\nBy forcing most civilian federal agencies and departments to buy IT as a\nservice from one federal agency, there could be cost efficiencies, higher\nstandards, better management, and continuous modernization. Some may object\nthat security is better achieved by diversity. Actually, that is not true when\nthe diversity results in a lot of nonsecure networks. Moreover, an IT services\nagency could design in diversity, redundancy, and a heterogeneous system that\nwould increase the complexity for an attacker and make recovery easier.\n\nHow would we pay for ITSA? It would not need to cost more than we now spend.\nIn fact, it would undoubtedly cost less by achieving economies of scale and\nother efficiencies. Each department and agency would pay for IT as a service\nfrom their existing budgets. ITSA would be phased in over several years, but\neventually it would own all the hardware, software, clouds, networks, and\nsecurity systems used by civilian federal agencies. We would be more secure.\n\n### Continue the Bipartisanship: Two Simple Suggestions\n\nBuilding on the creation of CISA in 2018, we would be delighted if Congress\nwould in 2019 or 2020 go on to make all of the cybersecurity staff in the\ncivilian federal agencies and departments members of a new, expanded\nCyberCorps, and thus employees of CISA. CyberCorps would be led by the top\nfederal CISO, who would also be the head of CISA. It would be a professional\ncadre, with ranks, cross-departmental assignments, continuing education, and\ntesting. The top-level members of the Corps would constitute a Senior Cyber\nService.\n\nITSA would provide software and networks as a service to federal agencies, and\nCISA, through its new version of CyberCorps, would make the security decisions\nand run the cybersecurity operations for the civilian federal agencies. Not\neverybody can manage IT or achieve adequate cybersecurity. We should stop\npretending that every federal agency can.\n\n\n# PART IV\n\n# WARRIORS, DIPLOMATS, AND CANDIDATES\n\n\n## Chapter 12\n\n## THE MILITARY, DOMAINS, AND DOMINANCE\n\nAfter land, sea, air and space, warfare has entered the fifth domain:\ncyberspace.\n\n—MATT MURPHY, _THE ECONOMIST_ , JULY 1, 2010\n\nPatrick Shanahan is the man who manages the giant corporation that is the\nPentagon. In that building and in U.S. military units around the world, the\nformer Boeing executive, known in the airplane company as “Mr. Fix-it,” was in\n2018 known as DEPSECDEF, the Deputy Secretary of Defense, until he became\nActing Secretary late in 2018. In May 2018, he announced the Trump\nadministration’s intentions toward the fifth domain: “The Department of\nDefense will ensure our military is ready to fight and win against any\nadversary, dominating the cyber domain.”\n\nDominate the domain, that is how the Pentagon thinks about cyberspace. Four\nmonths after Shanahan offered that simple guidance, the Defense Department\nelaborated in the 2018 DoD Cyber Strategy:\n\n> The Department must take action in cyberspace during day-to-day competition\n> to preserve U.S. military advantages and to defend U.S. interests. Our focus\n> will be on the States that can pose strategic threats to U.S. prosperity and\n> security, particularly China and Russia. . . . We will defend forward to\n> disrupt or halt malicious cyber activity at its source, including activity\n> that falls below the level of armed conflict.\n\nThat statement followed the release a few days earlier of the White House’s\nNational Cyber Strategy (the first since that rather good one issued in 2003),\nand National Security Presidential Memorandum (NSPM) 13, a classified\ndirective that devolved decision making on cyber operations to the Pentagon.\n(President Obama had reined in cyber operations in the wake of Stuxnet by\nissuing PPD 20, which reportedly required the President to approve significant\ncyber-offensive actions.)\n\nCritics of the new Pentagon plan to dominate the domain predicted that it made\nconflict in cyberspace more likely by suggesting that the U.S. military would\nbe taking action on a daily basis to disrupt cyber activity without an armed\nconflict serving as justification for doing so. Pentagon officials countered\nthat the strategy simply recognized the reality that there is already a daily\ncompetition in cyberspace with Russia, China, and others, even in the absence\nof a declared war. By engaging more vigorously against Russian and Chinese\ncyber units, the Pentagon believes it can eventually create stability in\ncyberspace.\n\n### Defense or Domination?\n\nCan an organization designed for war contribute to the lowering of tensions\nand a reduction in the likelihood of conflict? That is the question this\nchapter addresses. More specifically, we ask: How can the U.S. military\ncontribute to limiting or preventing cyber war? How can the military reduce\nthe possibility of crisis instability and rapid escalation of fighting? Some\nof what it needs to do may seem counterintuitive. It needs to get better at\ncyber war, both defensive and offensive.\n\nThe nuclear forces of the United States and the Soviet Union (later Russia)\nhelped to prevent those two countries from engaging in direct military\nconflict for more than seven decades. The mere existence of those nuclear\nweapons did not prevent the third world war. It was the way in which those\nweapons were combined with diplomacy, strategy, and arms control.\n\nDespite leaders calling for the elimination of nuclear weapons for decades,\nthe arms continue to exist in the thousands. So too, however, does a form of\nglobal peace. It is a peace filled with tensions, competitions, and low-level\nconflict that may not seem like a desirable condition. Yet compared to the\nworld wars of the twentieth century, the way in which arms control, strategy,\nand diplomacy were combined to prevent global conflict was a success. Now that\nlong absence of global war among superpowers is threatened by the emergence of\na new kind of weapon in a new domain, cyberspace.\n\nMishandled, cyber weapons could trigger a larger conflict of the kind we have\nsuccessfully struggled to avoid. Indeed, the current level of U.S. cyber-\ndefensive and cyber-offensive capabilities combined with those of potential\nopponents is creating a situation of high risk, of instability. America’s weak\ncyber defenses may invite a potential adversary to engage in cyberattacks, and\nAmerica’s response to that may spin tensions out of control into a wider war.\n\nThus far, military strategists and diplomats have failed to develop the\ncombination of weapons, policies, and arms-control measures to deal with the\nthreat to global stability created by cyber weapons. In this and the next\nchapter, we suggest the ways they might do so. This chapter addresses what the\nmilitary should do to contribute to cyber stability, or cyber peace.\n\nPentagon officials had traditionally talked in terms of four domains, or\nspheres of potential combat: ground, sea, air, and outer space. Over a decade\nago, with the advent of U.S. Cyber Command, defense officials added a fifth\ndomain of potential combat to their list: cyberspace. U.S. Cyber Command is a\njoint organization, meaning it is composed of Army, Navy, Air Force, and\nMarine components. Their mission, in the language of the Pentagon, is to\nachieve dominance in that domain.\n\nDominance in cyberspace is not, according to the Pentagon, something that\noccurs only in a war. If U.S. cyber capabilities, both offensive and\ndefensive, are obviously adequate and, indeed, superior to any threat,\ndominance can occur in peacetime. That, at least, is the theory and the goal\nthe U.S. military has set out for itself. So far, the U.S. has not achieved\ndominance in the fifth domain. Indeed, it is far from it, and that, arguably,\nincreases instability. Instability can lead to war.\n\nHow, specifically, can the U.S. military lower tensions, avoid crisis\ninstability, and deter or prevent a major cyber war? In the most basic terms,\nwe think the U.S. military should be capable of defending itself so well in\ncyberspace that it could perform its conventional (or, in the extreme case,\nnuclear) military operations without significant degradation from\ncyberattacks, and thereby deter enemy activity. It should combine that\ndefensive cyber capability with the ability to achieve rapid dominance over an\nenemy, in part by using cyber weapons in the early stages of conflict to limit\nand bring a quick end to fighting.\n\n### The Pentagon’s To-Do List\n\nWhile that all sounds good as a goal, it has proven difficult to achieve. The\nPentagon’s 2018 strategy has five stated objectives (see endnote on [this\npage](33_Notes.xhtml#XEndnotePhraseInText117)). We would slightly reformulate\nthem into five distinct missions: 1) defending the military’s own networks; 2)\nprotecting the corporations that make our weapons and that form the defense\nindustrial base (DIB); 3) ensuring the integrity of U.S. weapons once they are\ndeployed; 4) guarding the private-sector infrastructure that the military\nneeds to do its job; and 5) being ready to go on the offensive to degrade\npotential enemies’ militaries in part through cyber operations.\n\nHow is the U.S. military doing at those five missions today? We have found in\nour teaching and in our consulting that often the best way to drive home a\nmessage is to have people envision and “live” a near-future situation that\ntests them and their systems. This technique is similar to a new boss asking\nhis organization, “How well would we really do today if this happened?” The\n“this” for our purposes is a political-military crisis leading to a regional\nwar. The best way to think about how the DoD and Cyber Command are doing at\ncybersecurity is to ask how they would do if excrement hit that ceiling fan\nright now.\n\nBorrowing a phrase from the military, we call these imagined scenario\ndevelopments tabletop exercises (TTXs). We have run these learning simulations\nfor graduate students, corporate CEOs, and for U.S. national security Cabinet\nmembers. Let’s answer the question about how well the U.S. military is doing\non its five primary cyber missions by envisioning a near-term political-\nmilitary crisis.\n\n### Envision the Near Future\n\nPerhaps the most likely international crisis that might erupt this year or\nnext is a conflict between Iran and Israel. What follows is a scenario of how\nsuch a crisis could evolve and our assessment of how the U.S. military’s\ncurrent cyber capabilities might perform.\n\n> TEL AVIV, 10 NOVEMBER 2019\n>\n> The air-raid sirens sounded at 0200. Israelis awoke and ran to bomb shelters\n> throughout the country. The hundreds of rockets and missiles that hit the\n> country were launched from hidden sites in both Lebanon and Syria. The\n> strikes hit air bases, Ben Gurion Airport, the Defense Ministry complex in\n> Tel Aviv, electric power stations, and the ports of Haifa and Ashdod.\n> Although Israel’s antimissile defenses intercepted scores of incoming\n> warheads, because of the high number of simultaneous attacks, many rockets\n> and missiles got through to their targets. The damage was significant.\n>\n> The attack launched by Iran and its allied militias in Lebanon and Syria\n> were themselves retaliation for a large-scale Israeli airstrike on pro-\n> Iranian forces in Syria three days earlier. A second wave of rockets and\n> missiles hit Israel at 0400. The Israeli Air Force reported to the Defense\n> Minister that it was having difficulty launching fighters to hunt down the\n> mobile missile launchers. Damage levels at some air bases were critical,\n> with squadrons of F-16s incapacitated. Drones launched from Lebanon and\n> Syria had dived into Israeli missile defense radars, blinding some of the\n> Arrow, Iron Dome, and Patriot antimissile batteries.\n>\n> As dawn rose over Jerusalem, the Israeli Prime Minister called the U.S.\n> President. Reluctantly, he asked for immediate U.S. assistance.\n> Specifically, he asked for an airlift of critical weapons and key components\n> to replace some of the inventory that had been destroyed. He also requested\n> that U.S. Navy antimissile destroyers be deployed off Israel’s coast to\n> augment the nation’s overwhelmed defenses, and U.S. F-35 fighter-bombers be\n> deployed for joint strikes on the mobile rocket and missile launchers. The\n> President agreed immediately and directed the Pentagon to assist. He also\n> ordered a cyberattack on the missile launchers and their command-and-control\n> system, including mobile missile launchers in Iran that had not yet been\n> used to attack Israel.\n>\n> Within an hour of the Prime Minister’s call, two U.S. Navy Aegis destroyers\n> near Spain swung about and moved at flank speed east through the\n> Mediterranean. At Defense Logistics Agency (DLA) supply depots throughout\n> the eastern seaboard of the United States, train cars were filled with\n> pallets and prepared to move cargo to U.S. air bases. C-17 aircraft were\n> being readied for a massive airlift reminiscent of the U.S. operation to\n> support Israel in the 1973 Arab-Israeli War. The long protective arm of the\n> United States was once again getting ready to reach out to shield a\n> beleaguered Israel that had surprisingly found itself overwhelmed.\n>\n> WASHINGTON, 12 NOVEMBER 2019\n>\n> The President was furious. His wrath was like an energy wave flowing down\n> the video-conference line from the White House Situation Room to the\n> Pentagon’s National Military Command Center. Rockets and missiles continued\n> to pound Israel. The Chairman of the Joint Chiefs of Staff had just told the\n> President over the video link that the two Aegis destroyers were still\n> disabled, their propulsion systems off-line and damaged. Tugs were en route\n> to tow them to port in Italy. Norfolk Southern Railroad derailments in\n> Virginia and South Carolina were still preventing trains with critical\n> cargoes from reaching air bases. Power blackouts in the mid-Atlantic states\n> had plunged McGuire Air Force Base in New Jersey and Dover Air Force Base in\n> Delaware into darkness. Back-up generators at the bases did not work. The\n> DLA reported that its attempts at mounting backup databases had failed,\n> following the wiper attack on its inventory supply system.\n>\n> A few U.S. Air Force F-35s had landed in Israel, but on their first combat\n> sorties from Ramat David Air Force Base, all four U.S. aircraft had\n> sustained radar system failures and returned to base, landing amid a hail of\n> incoming missiles. In Huntsville, Alabama, the Raytheon Corporation was\n> assessing the damage from an explosion and fire that had engulfed its\n> Patriot missile production line. It was unable to ship spare parts. On the\n> offensive side, U.S. Cyber Command reported that it believed it could\n> penetrate and disrupt the missile force in Iran in a week to ten days. It\n> had never studied how to penetrate the Iranian-controlled launchers in Syria\n> and Lebanon. That would take longer.\n>\n> It had been fifty-five critical hours since the President had ordered the\n> Pentagon to help Israel and almost no assistance had arrived. Turning red in\n> the face and sputtering at the large flat-screen showing the Pentagon\n> leadership, the President demanded to know why.\n>\n> From another screen on the wall of the Situation Room teleconference\n> facility, the Director of National Intelligence spoke up, filling the\n> silence coming from the Defense Department. “Sir, we assess that Iran has\n> launched cyberattacks to degrade our operations in support of Israel.”\n> Sitting next to the President in the Situation Room, the National Security\n> Adviser mumbled, “No shit, Sherlock.”\n>\n> “Well,” the President said, turning on his adviser, “what do _you_ suggest\n> we do now?”\n>\n> “It’s very clear, Mr. President. Iran has stymied our assistance to Israel\n> with cyberattacks. We must now escalate. Commence conventional attacks on\n> Iran. B-2 bombers and the aircraft carriers must strike them tonight.”\n>\n> Without a moment’s thought, the President turned to the Secretary of\n> Defense. “Do it. Begin bombing Iran.”\n\nIncredible fiction? We think not. We believe that were there a “kinetic,” or\nconventional, war today in which U.S. forces were opposed by Iran, Russia,\nChina, or even to some extent North Korea, the Defense Department would be\nhampered in the execution of its operations and largely unable to conduct\nsignificant offensive cyber operations against enemy military targets.\n\nIn this scenario, the United States faced off against Iran and lost, at least\nin the first round. In the real world, Iran does have significant offensive\ncyber capabilities. The barrier to entry to having a meaningful cyber-war\noffensive force is low. Countries that could never defeat the United States in\na purely conventional military battle can pose significant asymmetric risks to\nus in cyberspace. To see why we make that claim, let’s look at each of the\nfive cyber missions we think the Pentagon should undertake and see what a mid-\ntier power like Iran could do to us.\n\nIn our scenario, the DoD failed in its first cyber mission, to protect its own\nnetwork. Hackers penetrated the Defense Logistics Agency’s unclassified\nnetwork and erased all software, including the contents of a backup file,\nusing a wiper hack that turns computers into useless pieces of metal by\neliminating all of the data on them. In the real world, Iran did penetrate the\nU.S. Navy’s unclassified computer network in 2013 and was able to remain there\nfor years even after its presence was discovered, despite intense efforts to\neject the Iranian presence. Iran has also successfully used wiper hacks,\nincluding an attack against the world’s largest oil company, Saudi Aramco.\n\nCybersecurity experts have been warning companies that hackers are placing\nransomware in database backups, so that when network operators attempt to\nactivate their business continuity systems, they will find that the backup is\ninoperable too. Those same techniques could be used for a wiper program, which\nwould activate on the backup database once that system was used, destroying\nall files, operating systems, and applications on a network.\n\nIt is not just the DoD’s unclassified networks that are at risk. Russia was\nable in 2008 to gain access to the Pentagon’s secret-level SIPRNet system.\nNorth Korea succeeded in 2016 in stealing from a classified network the\nU.S.–South Korean combined operations plan to attack the North and kill its\nleadership.\n\nAmerican military officials operate today on the assumption that their\nunclassified and secret-level systems have been compromised and may not be\navailable to them or be reliable in a crisis. They hope that the top-secret-\nlevel Joint Worldwide Intelligence Communications System (JWICS) network is\nsecure, but know that it is a high-priority target of many nations’ hackers.\n\nAs we noted in chapter 2, even the National Security Agency, which is part of\nthe Defense Department, has been unable to protect its own network. Its top-\nsecret files have been stolen by and from employees of NSA contractors such as\nBooz Allen Hamilton. If the NSA, the home of U.S. government cybersecurity\nexpertise, has its information systems compromised, it is highly likely that\nthe same or worse is happening elsewhere in the DoD.\n\nIn our scenario, the DoD was also unable to perform its cyber mission of\nprotecting its own weapons systems. The engines of the two disabled U.S. Navy\nantimissile destroyers became casualties as a result of a cyberattack on the\nships’ propulsion system controls.\n\nThe reality may actually be worse than our scenario. In October 2018, the\nGovernment Accountability Office issued a scathing report on the cybersecurity\nof U.S. weapons systems, claiming that an enemy could easily hack into and\ndisable (or take control of) many of the country’s newest weapons. Although a\ndistinguished Defense Science Board review panel had sounded a loud alarm\nabout this precise problem in 2013, five years later the GAO concluded that\nthe “DoD is in the early stage of trying to understand how to apply cyber-\nsecurity to weapon systems.” Note that the conclusion was not that the DoD was\nin the early stage of fixing the problem, but in the early stage of “trying to\nunderstand how to . . .”\n\nIn the scenario, U.S. Navy ships were hacked. In the real world, too, U.S.\nNavy ships are completely networked. The General Electric gas turbine systems\non Aegis destroyers are well known and similar to engines used in civilian\nsystems. Could a nation-state get into a ship’s system and give disabling\norders to a key system? The Navy thinks so. It reported that its new USS\n_Freedom_ -class combatants are vulnerable to hacking.\n\nIn 2018, classified data about highly sensitive Navy programs was stolen from\na contractor who worked for the Naval Undersea Warfare Center in Rhode Island.\nSeparately, a Navy technician was discovered to be a criminal hacker. There is\nwidespread belief in the Pentagon that the repeated collisions of U.S. Navy\ndestroyers in the Pacific in 2017 were a result of cyberattacks, although the\nDoD officially denies it. The Navy still uses the outdated and insecure\nWindows XP operating system throughout the force.\n\nIn our scenario, protection of the DIB was also a problem. A key corporate\nfacility, a Raytheon plant that makes parts for antimissile systems, caught\nfire and blew up, preventing shipment of components to Israel. We have no\nreason to believe that this specific facility or company is any less secure,\nor any more secure, than other parts of the DIB, but we do know that defense\ncontractors have regularly been hacked by foreign adversaries.\n\nAmong the weapons systems compromised are the Extended Area Protection and\nSurvivability System (EAPS), a system designed to counter rocket, artillery,\nand mortar fire in flight, and the Patriot, THAAD, and Aegis antimissile\nsystems. Also hacked were databases containing data on the F-35 fighter-\nbomber. And these are just the systems listed in one report by the Defense\nScience Board, a group of outside advisers to the Pentagon.\n\nWhen foreign adversaries are able to hack into computer networks at private-\nsector corporations making things for the Defense Department, the risk is\nthreefold. They can steal the weapon designs, potentially allowing them to\nreproduce similar weapons. That is what most of the hacking of the DIB\ncompanies has been used for to date. They could, however, once inside a\ncorporate network, covertly place code in the operating systems of the\nweapons, allowing them to take control of the weapons if and when they\nencounter them in combat. Finally, hackers could do things to the controls of\na factory, product line, or support systems to sabotage facility operations.\n\nThe fourth cyber mission some people think the DoD ought to be doing is to\nprotect other corporations, not those making weapons, but those supplying the\nDoD itself with essential services such as electricity or rail transportation.\nWe said “some people” in the last sentence because the exact role the Pentagon\nshould have in defending critical infrastructure companies is a bit\ncontroversial. In our scenario, there were electric power blackouts in New\nJersey and Delaware, forcing the key airlift bases at Dover and McGuire onto\nfrequently unreliable backup generators. Trains in our fictional scenario\nbringing spare parts and weapons to air bases and maritime ports were\nderailed, preventing much of the needed resupply to Israel.\n\nIn the real world today, the DoD would fail to protect those power grids and\nrail-control systems because it has no legal authority to do so and, thus, no\nprogram at work to secure the off-base civilian systems on which the bases\ndepend. The responsibility to assist corporations providing “critical\ninfrastructure” such as electric power and rail is that of DHS. While DHS does\nshare information with some critical infrastructure companies, it does not act\nto monitor or to defend their information networks. Russia, meanwhile, has\nreportedly been able to penetrate U.S. power grid control systems, as we\ndiscussed in chapter 10.\n\nIran, the potential enemy in our scenario, has already successfully attacked\nthe U.S. financial sector infrastructure in 2011 and 2012, using a simple but\npowerful DDoS attack, a type of flood technique, to overwhelm the publicly\nfacing networks of the largest U.S. banks.\n\nThe division of labor between the DoD and DHS frustrates some in the Defense\nDepartment who believe that DHS and the corporations involved will never be\nable to do enough to secure the critical infrastructure upon which the\nPentagon, and the country as a whole, depend. One of the many problems with\nmaking the DoD responsible for defending critical infrastructure, however, is\ndeciding where to draw the line. DHS defines seventeen industries as part of\n“critical infrastructure,” including even the retail sector (e.g., Walmart,\nCostco, Home Depot).\n\nNot only does the DoD not have the authority to defend such networks, it is\nnot entirely clear that many of the corporations involved want the military\npoking around their networks. One of the critical infrastructure corporations\nmost often targeted is the megabank JPMorgan Chase. When some of its\ncybersecurity personnel began discussing the possibility of a pilot program\ninvolving the DoD protecting its network, our sources informed us that CEO\nJamie Dimon and other top bank officials quickly shut down the idea.\n\nFinally, we posited that the fifth mission of the U.S. military in cyberspace\nshould be to have the ability to attack enemy military systems using cyber\ntechniques. Most observers take for granted that Cyber Command can at least do\nthat well. The truth has been otherwise. Bureaucratic and legal impediments\nhave prevented America’s cyber warriors from being a real offensive threat for\nalmost all of Cyber Command’s first decade of existence.\n\nIn our scenario, the President, upon request of the Israeli Prime Minister,\nordered cyberattacks on the command-and-control systems supporting the Iranian\nmissile launchers, the similar systems of the Iranian-backed Hezbollah\nmilitia, and on the missiles themselves. Cyber Command responded that it might\nbe able to have some initial capability to do that in two weeks’ time. Of\ncourse, by then Iran and its militia allies could have emptied their missile\ninventories onto Israel. Were we unfair to Cyber Command’s offensive\ncapabilities in this simulation? We think not.\n\n### Surprise: Cyber Comm Wasn’t Offensive Enough\n\nTen years ago, we argued in the book _Cyber War_ that the U.S. military seemed\nto be too fixated on developing offensive cyber capabilities and\ninsufficiently focused on defense. As is often the case in Washington, the\npendulum then swung to the opposite extreme. For most of the second decade of\nthe century, Cyber Command did what we had advised (no doubt it was\ncoincidence and not because they were actually aware of and agreed with what\nwe had written). They focused on defense, but they did so to an excessive\ndegree, forgoing much of what was needed to be in a position to launch a major\noffensive operation if called upon to do so by the President. Although U.S.\nintelligence agencies were conducting covert operations in cyberspace, the\nU.S. military was, to our admitted surprise, insufficiently offensive in its\ncyber war preparations. Although preparations can themselves be destabilizing,\nit is also true that if a potential enemy knows that you have little offensive\ncapability, then deterrence is diminished.\n\nGetting inside a potential adversary’s military command-and-control systems,\nor its weapons systems, is not something that can be achieved within days of a\nPresident ordering it to happen. It can take months or even years to mount\ncovert programs to penetrate such systems. Once access has been achieved, it\nis then a difficult operation to maintain an undetected presence capable of\nbeing activated remotely upon command. Even an adversary’s simple software\nupdate can completely destroy a backdoor that took years to develop.\n\nDespite the fact that the terrorist group ISIS was the major adversary with\nwhich the U.S. military was engaged in combat in the Obama administration, few\nif any cyberattacks had been mounted against them. Toward the end of the\nadministration, Secretary of Defense Ash Carter directed Cyber Command to\nmount Operation Glowing Symphony to “drop virtual bombs” on ISIS. Later,\nSecretary Carter testified to Congress that he was “largely disappointed” in\nthat operation’s ability to degrade the terrorist group.\n\nSecretary Carter was not the only one in the Obama administration to have been\ndisappointed by cyberattacks. Obama himself was, as were many of his top\nadvisers. They were disappointed with the first major U.S. cyber-war attack,\nthe now infamous Stuxnet program. Officially known as Operation Olympic Games\nin the intelligence community, the operation seemed at first to have been a\nmarvel of both covert action and cyber intrusion. (The attack is now the\nsubject of many books and even a movie, _Zero Days_ , directed by Alex\nGibney.) Upon further examination, however, it had failed on several important\ncriteria.\n\nThe attack was supposed to remain covert. The Stuxnet attack software was\ndiscovered by the Iranians. How it worked was supposed to remain secret.\nEuropean and American cyber experts decompiled it and publicly discussed its\ndesign. The attack was supposed to be limited to the plant. The attack\nsoftware got out of Natanz and took on a life of its own, exploring the world,\nand was captured and copied by cyber criminals and other nation-states\nthroughout its journey. The covert cyber assault was supposed to do\nsignificant damage to the enrichment program. Although it did cause eight\nhundred centrifuges to be repaired or replaced, Iran then built twenty\nthousand centrifuges. Finally, the fact that the United States was the first\n(or among the first) nation to destroy infrastructure with a cyberattack was\nnever supposed to be known.\n\nAs we’ve seen, after the Stuxnet experience, some would say “fiasco,” Obama\nissued orders that prevented any further major covert operations without his\npersonal approval. It had a somewhat chilling effect. In a White House\ndominated by lawyers, an interagency debate arose about which U.S. government\nagencies could do what in the realm of offensive cyberattacks. Pentagon, CIA,\nand Justice Department lawyers engaged in what some policy makers saw as\nTalmudic sophistry. Stripping away the mystery and jargon, let’s try to\nunderstand the debate.\n\nThe military’s Cyber Command had not done the Stuxnet attack. The CIA and the\nNSA did. They did so under the authority of Title 50 of the U.S. Code, the set\nof laws that govern the U.S. intelligence community. Under those laws, U.S.\nintelligence agencies can covertly collect information abroad. They can also\ntake actions to damage or destroy things abroad, even in peacetime, when the\nPresident issues a specific “finding” that it is in the national security\ninterest of the United States to do so. The issuance of a finding is a highly\nsecret, ritualistic, arcane, and usually time-consuming process involving\nthousands of hours of government lawyers’ time, including time spent in\nconsultation with a select bipartisan group of Members of Congress. Even once\na finding is issued, every time a significant action is about to be undertaken\npursuant to the authorization, the process is repeated to issue a Memorandum\nof Notification (MoN) about that new action.\n\nDespite their off-putting experience with the outcome of Stuxnet, the Obama\nadministration apparently did not give up on the idea of using cyber weapons\nagainst Iran. As the so-called P5+1 talks with Iran about nuclear weapons\ndragged on, the Obama administration reportedly authorized a contingency plan,\ncode-named Nitro Zeus, to destroy or damage key parts of Iran’s infrastructure\nif the talks failed. That cyberattack allegedly would have been an\naccompaniment to a conventional attack and would have been, at least in part,\nimplemented under military authority. In general, however, Cyber Command was\nnot authorized to go after enemy weapons systems.\n\nCyber Command and the military in general are covered by a different section\nof law than that which was used to authorize Stuxnet. The military is\nauthorized by Title 10 of the U.S. Code. Lawyers in the Obama administration\nargued that the military could not violate international boundaries by\npenetrating other nations’ computer networks in peacetime for the purpose of\ncausing damage or destruction without a specific order from the President (or\nthe Secretary of Defense). Military intelligence units could collect\ninformation about other nations’ systems, but that would be under the\nintelligence authorities, and could not be conducted with the intent to\ndestroy things. Some in the military wanted to “prepare the battlefield” by\nlacing the weapons systems of possible future enemies with “logic bombs” that\ncould be triggered to destroy the enemy network or weapon in a conflict. They\nwere not given that authority until 2018.\n\nThus, Cyber Command and its component military units spent almost all of its\ntime since its inception trying to fend off other nations that were trying to\ninfiltrate our military networks and weapons. Given how many such attacks were\ngoing on and how successful they were, spending most of the time on defense\nwas likely the right thing to do, but having little or no offensive cyber\ncapability against enemy militaries created a weakness.\n\nIn the 2018 Department of Defense Cyber Strategy, Secretary of Defense James\nMattis had ordered Cyber Command to “defend forward” by joining with the\nintelligence community in attempting to identify potential enemy cyber\nsystems, penetrate them, and in some cases, stop incoming attacks. What some\nU.S. war-fighters wanted, however, was more. If they were ever ordered to bomb\nRussia or China, for example, they wanted to be able to make the “enemy” air\ndefense radars show no incoming U.S. attack. They wanted the opponents’ air\ndefense missiles to blow up on the launchpad when they were fired against U.S.\naircraft. (Media reporting suggests that U.S. intelligence may have penetrated\nboth Iranian and North Korean ballistic missile tests and caused several of\nthem to blow up on the launchpad. Apparently, however, the North Koreans later\ndeveloped missiles that did not include that particular feature.) The U.S.\nwar-fighters wanted to send erroneous commands on the other nations’ military\ncommunication systems. After all, they argued, that was what Russia and China\nwere apparently trying to do to us and, for all we know, they may be in\nposition to do that right now. We were not, at least not as much as most\nobservers assumed, and it was in part because of the arcane legal battles.\n\nThe fiscal year 2019 National Defense Authorization Act (NDAA), known as the\nJohn McCain Act, added language to make clear that the military, specifically\nCyber Command and its regional and service components (such as Army Cyber\nCommand), may take measures in peacetime against potential adversaries’\nsystems, so that they will be able to degrade their military operations\nquickly in the event of combat, defining such actions as “traditional military\nactivity.”\n\nDespite the controversy about the open-ended law that Congress passed after\n9/11, the Authorization for Use of Military Force (AUMF), the McCain Act also\npreauthorizes the use of military force. Although little noticed publicly, the\nlaw gave the Secretary of Defense and Cyber Command specific authority to\nengage in cyberattacks against four nations (Russia, China, Iran, and North\nKorea) if any of those countries are found to be “conducting an active,\nsystematic, and ongoing campaign of attacks against the Government or people\nof the United States in cyberspace, including attempting to influence American\nelections and democratic political processes.” Cyber Command is also\nspecifically authorized to share information with private-sector companies,\nincluding those in social media.\n\nTrump then signed National Security Presidential Memorandum 13, a directive\nseen by many as taking off the leash that has held back the U.S. military from\n“preparation of the battlefield.” That authority was described in the NDAA as\nfalling within the ambit of “traditional military activities,” but what it\nauthorizes is anything but traditional. Following the Congressional action,\nthe White House delegated day-to-day cyberattack decision-making authority to\nthe Department of Defense.\n\nHaving U.S. military units penetrating potential enemy weapons in peacetime is\nseen by some observers as destabilizing. The argument is that such U.S. action\nmight lead to peacetime “attacks” by both sides, or all sides, that could\naccidentally cause a highly destructive incident and lead to an escalatory\nprocess and open combat among the world’s great militaries. That concern has\nmerit, and even if the White House has devolved authority to the Pentagon,\nthere is a real need for interagency review (including White House staff) of\nplanned DoD cyber operations to prevent miscalculation. One way of reducing\nthe likelihood of general war may be to enhance uncertainty.\n\nTraditionally, military strategists argue for greater certainty in political-\nmilitary affairs. Certainty equals stability, they contend. That was, and is,\nthe case with the prospect of major nuclear war. The certainty of mutual\ndestruction creates deterrence. We have been taught that for the last fifty\nyears. With cyber war, however, uncertainty may deter significant military\naction.\n\nFor uncertainty to promote deterrence in the context of cyber war, a potential\nenemy needs to be uncertain of two things. First, the potential enemy must be\nuncertain about how well its own conventional weapons will work. Second, the\npotential enemy must be uncertain about how well our cyber defenses will work.\nCreating those two kinds of uncertainty will increase U.S. security and\ndeterrence.\n\nIf potential enemy leaders think there is a real possibility that their\nconventional weapons will malfunction because we have hacked them and that the\nU.S. military would quickly overwhelm them, they may be deterred from\ninitiating hostilities. Similarly, potential enemy leaders must be made to\ndisbelieve their own military and intelligence commanders’ claims that they\ncan defeat the U.S. military and badly damage U.S. infrastructure through\ncyberattacks. Cyber Command could contribute greatly to creating those two\nkinds of uncertainty. It has not.\n\nThe blame does not belong on Cyber Command. The U.S. government as a whole has\nlacked a clear strategy, adequate funding, the needed laws and regulations,\nand, most important, the organizational structure and leadership to create the\ncombination of defensive and offensive capabilities required to increase cyber\nstability and to deter cyber war.\n\nAs we discussed earlier in this chapter, key U.S. government networks have\nalready been penetrated. The networks of companies making U.S. weapons have\nbeen compromised. Some U.S. weapons may have “kill switches” or backdoors\ninserted by potential enemies. The civilian infrastructure the U.S. military\nneeds to go to war can be successfully attacked by cyber weapons right now.\nThe U.S. military lacks the ability to degrade significantly the military\noperations of potential enemies.\n\nIf the U.S. military cannot degrade an enemy using cyber weapons during a\ngrowing crisis that has already seen limited combat, if it cannot defend\nitself or our allies from disabling cyberattacks, then it will quickly\nescalate to a larger conventional war. We just saw that happen in our\nfictional scenario. That is crisis instability, the inability to control\nescalation. That is likely where we would be today were a crisis to occur with\nRussia, China, Iran, or even North Korea.\n\n### Seven Steps for Stability\n\nHow do we fix that sad and unstable state of affairs? We suggest these seven\nmeasures:\n\n#### Unity of Command\n\nIt is a major tenet of military operations that there needs to be a single,\nclearly defined commander for a military operation. Everyone necessary for the\nsuccess of the battle must be under the control of that one commander. For\nAlexander the Great, that meant both the hoplite infantry and the cavalry did\nwhat he told them in battle. For Dick’s late friend General Norm Schwarzkopf,\nit meant in the First Gulf War that Norm controlled the air strikes, the armor\nunits, and the aircraft carriers. In the creation of the U.S. nuclear Navy, it\nmeant that the design, build, and operation of the reactor-powered ships were\nall subject to Admiral Hyman Rickover’s direction, for decades.\n\nToday in the Pentagon, policy, direction, and oversight on some things cyber\nresides in a Deputy Assistant Secretary of Defense (DASD) in the policy chain,\nwith little or no responsibility for research, development, or procurement. As\nour friend Eric Rosenbach, who once had that DASD job, told us, “It’s not\nalways obvious to a four-star general, like one running Cyber Command, that\nthey take direction from a DASD.”\n\nThere needs to be one very senior civilian in the DoD whose only job is to\nhave clear policy and operations authority over not only U.S. Cyber Command,\nbut also both the Pentagon’s intranet run by the Defense Information Systems\nAgency (DISA) and its own internal counterintelligence force for cyberattacks,\nthe Defense Cyber Crime Center (DC3). Such an official must have authority and\ncyber responsibility over existing U.S. weapon and support systems,\nprocurement of new systems from defense industrial companies, and the\ncontracting for critical infrastructure support from civilian providers.\n\n#### Clarity of Mission\n\nThe 2018 DoD strategy envisions some Pentagon role in defending the power grid\nand other critical infrastructure essential for DoD Mission Support. Many of\nthe owners and operators of such networks are not pleased at the prospect of\nthe military tramping around in their systems. Moreover, it is not clear that\nthe Pentagon has either a plan or the legal authority to do so. Because of the\ninterconnected nature of the power grid, gas pipelines, and telephony\nnetworks, it is hard to define or defend the parts that just support the DoD.\nMoreover, prior laws and executive orders have given the Department of\nHomeland Security the role to defend critical infrastructure.\n\nWe think that it is urgent that the debate about the DoD’s cyber role must end\nsoon with a new law. The DoD, working with Homeland, must be able to demand\nand enforce high standards on its vendor supply chain, including the specific\npower and transportation systems it relies upon. They can do that through a\ncombination of regulatory power and contractual language. Such authority\nshould supersede any other federal or state regulation, and it should permit\nthe DoD to continuously monitor the state of cybersecurity of the corporations\ninvolved.\n\nThe DoD and the intelligence community should look for incoming attacks on the\npower grid, and a handful of other critical infrastructure sectors. They\nshould have procedures and authorities to block such attacks working with\ninfrastructure companies. The concerned industries, working with Homeland and\nthe DoD, should develop and operate continuous monitoring systems to find\nvulnerabilities and malicious actors within the infrastructure control planes\nand supply chain. Finally, industry, state-level emergency management agencies\nand the National Guard, DHS, and DoD should have detailed plans and\ncapabilities to restore operations quickly in the event of a successful\ncyberattack on key infrastructure.\n\nClarity of mission also requires that the Pentagon and the intelligence\ncommunity effectively deconflict their operations. They should not both be\ntrying to infiltrate the controls of Moscow’s power grid, but, until we\nachieve a diplomatic understanding with Russia and others about the laws of\ncyber war, one of them should definitely be doing it. Someone needs to ensure\nthat missions like that do not fall between the cracks.\n\n#### Crash Program to Secure U.S. Arsenal\n\nWe cannot wait for a real shooting war to discover that a weapon will not work\nbecause a potential adversary has been able to take control of our navigation,\ncommunications, guidance, or other systems.\n\nIn _Cyber War,_ we painted a picture of the U.S. trotting out its expensive\nnew weapons to go to war in the near future with some near-peer nation-state\nenemy only to have the enemy figuratively flip a switch to shut off the U.S.\nweapons and then attack the American “sitting ducks.” Five years after we\npainted that scary scene, the Pentagon’s Defense Science Board wrote an\nalarming report with the same conclusion. In 2018, the GAO concluded that\nlittle had been done to secure U.S. weapons from enemy hacking. If true, this\nis a crisis of extraordinary proportions, for it would mean that after\nspending trillions of dollars on defense, we may be defenseless.\n\nThe Secretary of Defense should have no higher priority than determining the\nextent of the cyber vulnerabilities of U.S. weapons systems, and fixing them\nand the supporting infrastructure with the greatest possible speed. That may\nrequire, at the least, an unprecedented diversion of resources within the\nPentagon’s annual $700 billion budget to test for and remediate existing\nweapons.\n\nAfter the initial review-and-repair project, the Pentagon must constantly\nengage in large-scale testing and continuous monitoring of networks and\nweapons for cyber vulnerabilities, on both DoD and contractor networks. When\nmistakes are discovered, DoD or corporate staff should be penalized and fines\nlevied on the contractor. The commanders of the U.S. Navy Seventh Fleet\nwarships that were involved in the suspicious collisions with civilian vessels\nwere punished, as were their superiors. Yet when civilian contractors’\nemployees compromise the NSA’s most valuable secrets, the companies involved\ncontinue to receive valuable contracts and their leadership continues to take\nhome enormous paychecks. As Admiral Rickover knew when it came to establishing\na culture of safety for Navy nuclear reactor systems, there must be severe\nconsequences for nonperformance. So, too, in cyberspace the culture of\nsecurity can be created only by establishing a fault-intolerant system.\n\n#### Resource Adequacy\n\nThe DoD budget is too big. It has risen consistently, even without taking into\naccount the cost of the Long War operations against Iraq, the Taliban, al-\nQaeda, and ISIS. Within the DoD budget, resources for cyber missions have\ngrown disproportionately to other missions. Nonetheless, doing the kind of\nmajor security-assurance operation we believe is necessary on the DoD’s own\nnetworks, corporate networks, and weapons systems will require greater\nefforts. That means more money.\n\nIn fiscal year 2019, the Defense Department will spend more than $700 billion.\nOf that immense amount of money, the DoD is programming slightly less than 1\npercent for offensive and defensive cyber programs. We admit that how you\ndefine what is in that category is arbitrary, and some definitions would\nresult in the percentage being higher, but however you define it, the funding\nis inadequate to replace current DoD systems with a highly defensible and\nresilient set of capabilities anytime soon.\n\nInformation systems technology does not always reduce the cost of doing\nbusiness, as some people believed in the 1990s. IT system dependence and the\nneed to secure those systems can actually increase the cost of the systems you\nbuy, capital expenditure (CapEx), and the financial burden of running them,\noperating expenses (OpEx). Because the DoD, more than most large organizations\nin the world, is IT dependent, it needs to spend a huge percentage of its\nCapEx and OpEx on IT systems and their cybersecurity. Those resources can come\nfrom only one place: elsewhere in the DoD budget, even if that means reducing\nthe size of the conventional force structure. It will do us no good, for\nexample, to have ten aircraft carriers if none of them are combat effective\ndue to cyber vulnerabilities. It would be better to have six that worked even\nunder cyberattack.\n\n#### System Failure Capabilities\n\nEvery corporation in America knows it needs to spend money on disaster\nrecovery and business continuity. That’s without there being an enemy nation-\nstate actively attacking and sabotaging their systems (although for some\ncompanies that could be the problem someday). Even if the DoD leadership\nembraced everything we recommend in this chapter and embarked on an\naccelerated program to implement it, America’s military would still have\ncyber-vulnerable weapons and support infrastructure for years to come.\n\nThus, part of the immediate task before the Pentagon is to develop and deploy\nthe ability to fight in a degraded environment. Forces need to be able to\ncommunicate without the internet (or NIPRNet, SIPRNet, or JWICS), and need to\nbe able to coordinate when frequencies are jammed by an enemy. Weapons must\nwork even if the Global Positioning System does not. Senior U.S. military\ncommanders know this, but that has not yet translated into a real ability to\nperform the DoD’s missions in a world in which cyberattacks have brought our\nforces back to a preinternet era. Getting there will, as mentioned in the\npoint above, mean more money, not for shining new objects, but for boring old\ntech.\n\n#### Escalation Dominance\n\nOne way to control when and how escalation occurs is to quickly jump a few\nrungs up the escalatory ladder and combine that demonstration of strength with\nboth an offer to cease fire and a threat to do even more damage if that offer\nis ignored. To do that, the United States has to be able to execute\ndevastating cyberattacks against both infrastructure and military targets,\nwhile being relatively impervious to attempts to do similar things to us. We\nare a very long way from having those capabilities today, but we can and\nshould have a road map to achieve them.\n\n#### Supporting Diplomatic Arrangements\n\nOne way to judge who the good military commanders are is by examining the\nimportance they place on their “POLADs,” the diplomats and civil service\nexperts that the State Department provides to them. When fighting breaks out,\nthe system has failed. Peace and stability are achieved and maintained by\ncombining strong offensive and defensive military capabilities with smart and\nactive diplomacy. Today there is no real ongoing diplomacy with regard to\ncyberspace and cyber war.\n\nIn the Obama administration, a high-level advisory group recommended to the\nPresident that cyber war diplomacy be elevated by creating an Assistant\nSecretary of State for Cyberspace. Similar global threats such as terrorism\nand illegal narcotics have had Assistant Secretary–led bureaus in State for\nyears, to give focus and ensure the issues are placed on the department’s list\nof top diplomatic initiatives. Obama rejected the recommendation for an\nAssistant Secretary for Cybersecurity Policy. Trump went one step further and\neliminated the State Department office and senior adviser of cyberspace. The\nTrump administration then eliminated the position in the National Security\nCouncil staff that coordinated cyber-diplomatic efforts.\n\nReducing tensions in cyberspace, enhancing stability, and avoiding wars\n(accidental or intentional) requires combining strong military capabilities\n(offensive and defensive) with a diplomatic architecture. Diplomacy helps to\ndefine what acceptable and unacceptable activity is in peacetime, and in the\nevent of conflict. A diplomatic architecture creates international systems for\navoiding misunderstandings, dealing with misbehavior without combat, and\ndesigning stable systems and institutions. It is how to achieve that\ndiplomatic system that we turn to in the next chapter.\n\n\n## Chapter 13\n\n## A SCHENGEN ACCORD FOR THE INTERNET\n\nCyberspace is not borderless; rather, everyone lives on the border.\n\n—MICHAEL DANIEL, FORMER WHITE HOUSE CYBERSECURITY COORDINATOR\n\nEric Schmidt thinks the internet will split in two. At a private dinner event\nin San Francisco in the fall of 2018, the chairman of Google and longtime tech\nluminary told the audience that in ten years there would be one internet\ndominated by the United States and its tech giants and one dominated by the\nChinese and its tech giants. The rest of the world would need to pick sides.\nNot to be outdone in the gloom-and-doom prognostications, the _New York Times_\neditorial board then upped the ante, predicting that the internet would not be\nsplit in two but into three, adding in a future that included a separate\nEuropean internet. These are but recent examples of a long-held concern in the\ncybersecurity community that the internet would “splinter” or “balkanize” into\nnational internets, ending the vision of what the Obama administration\ndescribed as an “open, interoperable, secure, and reliable” internet in its\n2011 International Strategy for Cyberspace.\n\nRumors of the coming disintegration of the internet are likely exaggerated.\nWhile Russia announced plans to create an “independent internet” by August of\n2018, as of the spring of 2019 it had yet to conduct a planned test of\ndisconnecting its network. As the internet has evolved from its humble\nbeginnings, it will continue to evolve and change in response to new\ntechnologies, new markets, and new government requirements. Ten years ago, the\ninternet had barely begun to connect mobile devices. Cloud was viewed as an\nuntrusted and unproven technology. Ten years from now, we are likely to see\nsimilar evolutionary changes. It’s fair to predict that some of those changes\nwill include the spread of the Chinese model of internet control and\ncensorship to other countries. The fight for the future of the internet will\nlikely take place in Africa, where China has invested heavily to shape the\nnetworks it is helping to build in its own image. Unfortunately, it seems\nlikely that internet freedom will be degraded in much of the world. No matter\nwhat, we will still be plagued with many of the problems we face today on the\ninternational stage, like cyber-criminal safe havens, poor international\ncooperation on investigations, and unclear rules for cross-border cyber\nactions involving third-party states. Unless, of course, the United States and\nits like-minded allies manage to adopt a new approach to global cyber\nleadership.\n\nInstead of waiting for the internet to disintegrate around us, an alternative\nstrategy would be to exclude those nations that do not respect freedom of\nexpression or privacy rights, that engage in disruptive activity, provide safe\nhavens to criminals, and are not responsive to law-enforcement requests for\nassistance. In turn, those nations who buy into the vision of an open,\ninteroperable, secure, and reliable internet would maintain and extend the\nbenefits of being connected. What might that look like? A real-world corollary\nis the European Union’s model of open borders within the Schengen zone.\n\nThe Schengen Accord created a bloc of countries within Europe where people and\ngoods could travel freely without going through customs and immigration\ncontrol. It’s why you can drive through countries from Germany to Spain\nwithout getting your passport stamped along the way. Once you are in the\nSchengen Area through one country’s border-security apparatus, you can freely\naccess any other country. Negotiating the Schengen Accord was a monumental\nundertaking, because control over borders has defined state sovereignty for\nthe last three hundred years. A Schengen Accord for the internet would allow\nthe free flow of data across borders, harmonizing national laws so that all\ndata that can be legally accessed in one country can also be legally accessed\nin other member states. To allow for that to take place, stronger mechanisms\nfor handling the bad that comes with the good of open borders in cyberspace\nmust be built.\n\nA few years back, such an idea would have been hard to implement. Today, as\nthe European Union looks to be on the verge of getting smaller and U.S.–EU\ncooperation reaches a new low, it looks all but impossible. Yet the problems\nthat it solves for both commerce and criminal response remain. The idea of a\nSchengen Accord for the internet might just be crazy enough to work.\n\n### Barlow Was Wrong\n\nThe internet is not what its founders thought they were building or what the\nearly adopters of the technology envisioned. What began as a project to\nconnect mainframes at research universities and morphed into the freewheeling\nglobal network of the 1990s is now being split up into smaller national and\ncorporate networks. At the highest level, however, the internet operates much\nas it did thirty years ago and uses the same (somewhat archaic) protocols to\ndo it. There is, at least for now, still a single global Domain Name System\nand data can still flow, if not entirely freely, from one country to another.\nAs the internet has gone from being the place you go to visit bulletin boards\non esoteric topics to undergirding all of modern existence, the early vision\nfor cyberspace as a domain beyond the reach of the state now seems hopelessly\nnaïve.\n\nThe internet pioneer John Perry Barlow is often held up as the embodiment of\nthis “techno-utopian” vision for the internet. The founder of the Electronic\nFrontier Foundation (EFF), Barlow is a fascinating character. Steven Levy\ndescribed him as a “cowboy, poet, romantic, family man, philosopher, and\nultimately, the bard of the digital revolution.” When he died in early 2018,\n_Rolling Stone_ titled his obituary “John Perry Barlow, Grateful Dead\nLyricist, Dead at 70.” Barlow wrote such classics as “Mexicali Blues” with\nband member Bob Weir. On his death, Weir said that Barlow would live on in the\nsongs they wrote together. Barlow’s work at EFF could have a longer-lasting\nlegacy. EFF has probably done more than any other organization to help protect\nfreedom of expression and the right to privacy online. It helped win court\nrulings that made intercepting electronic communications a violation of the\nWiretap Act.\n\nWhile William Gibson coined the word “cyberspace,” it was Barlow who\npopularized its use to capture a realm separate and apart from the physical\nworld, in which people could be freed from the limitations imposed on them by\ntheir bodies and the body politic in what he called “meatspace.” There are not\ntoo many people in the world who have had both a backstage pass to every Dead\nconcert and an open invitation to the World Economic Forum, but Barlow did,\nand in Davos in 1996 he tapped out his now famous “A Declaration of the\nIndependence of Cyberspace.” In it he exhorts governments to leave the\ndenizens of cyberspace alone, declaring, “You have no sovereignty where we\ngather.”\n\nOf course, that wasn’t true. As Tim Wu and Jack Goldsmith document in their\nexcellent 2006 book _Who Controls the Internet?,_ it didn’t take long for\ngovernments to impose their sovereignty on the internet. Barlow declared,\n“Your legal concepts of property, expression, identity, movement, and context\ndo not apply to us. They are all based on matter, and there is no matter\nhere.” The reality is that the 1s and 0s of computer code and the packets of\ninternet traffic are all reliant on physical systems and are used by people in\nsovereign jurisdictions. That means that states could manipulate and control\ncyberspace the same way they can manipulate and control matter and matters in\ntheir physical domains.\n\nThe trend toward government control over the internet that Wu and Goldsmith\nexamined over a decade ago has only accelerated in that time. China, Russia,\nIran, Syria, Burma, and many other states have created national networks where\ncommunication within their countries stays within their countries and where\nthere is at least the potential to inspect, filter out, or cut off\ncommunication with the outside world. Meanwhile, corporate players are busy\ndividing up the internet into commercial enclaves where users log in to a\ncontained world that is curated for them, probably by Facebook or Google. Real\nnames are increasingly mandatory. Even business communications, once the\ndomain of email and its open standard, are moving into proprietary channels\nsuch as Slack and Skype.\n\nFor a brief period, the corporate world did battle with governments. The\ncorporations lost. Early internet companies tried to convince bureaucrats that\nthe internet was an open, flat network and was therefore a “take-it-or-leave-\nit” proposition. Countries such as France and Germany were told that they\ncould either opt in to the global internet or opt out. What they could not do\nwas try to change it. This ruse worked for a short while, but government\nbureaucrats are rarely as dumb as technologists assume they are. When Yahoo\ntold France that it could not possibly filter out search results for copies of\n_Mein Kampf_ , France told Yahoo that it would put its executives in jail the\nnext time they landed at Charles de Gaulle. Very quickly, Yahoo and other\ncompanies learned how to do geolocation on their users and not serve up\nillegal content to those users in prohibited locations.\n\nLike all border-control efforts, these early pushes to force content providers\nto abide by laws in different nations were only partially effective. The\ndedicated and technically savvy could easily circumvent these controls. Leave\nGermany through a virtual private network, get a U.S. IP address, and Google\nwill serve up neo-Nazi websites to your heart’s content. Silicon Valley\nquickly realized there was far more money to be made by adapting their vision\nto the wider world than trying to force the wider world to adopt the vision of\nan internet where free speech reigned supreme. Barlow’s vision of cyberspace\nas a space unfettered by states has slowly been dying ever since.\n\n### Barlow Was Right\n\nBarlow may have been naïve, but he was not hopelessly so. Rather, he was\nhopefully so. “A good way to invent the future is to predict it,” said Barlow.\n“So I predicted Utopia, hoping to give Liberty a running start before the laws\nof Moore and Metcalfe delivered up what Ed Snowden now correctly calls ‘turn-\nkey totalitarianism.’”\n\nWhat Barlow saw, and captured in his elegant turn of phrase, was that the\ngrowth of processing power (Moore’s Law) together with the growth in value of\na connected network (Metcalfe’s Law) would inevitably mean that the internet\nwould be used as a surveillance tool rather than as a space where people were,\nin fact, more free. Yet what Barlow recognized was what many in the military\ncommunity have also recognized: cyberspace is the only changeable, man-made\ndomain. While the laws of physics do apply in cyberspace, they are guideposts.\nAs long as you stay within them, the domain can be altered, on the one hand,\nto create a surveillance state, or, on the other, to promote freedom of\nexpression.\n\nThe Obama administration put no small amount of energy into the preservation\nand extension of the U.S. vision of a global open internet. David Edelman\ncrafted the International Strategy for Cyberspace, enshrining that concept.\nChris Painter at the State Department racked up a million frequent-flier miles\npromoting that vision around the globe. Michele Markoff, another State\nDepartment official, has spent the last decade trying to persuade the Russians\nand other counterparts in the UN’s Group of Governmental Experts to get on\nboard with that vision. That vision is no longer tenable because it is no\nlonger true. The internet was always a “network of networks,” an _inter_\nconnected _net_ work (get it?), but whereas in the early days those networks\nwere all open and packets of data flowed across them based on the optimal\nroute, now many of those networks have erected barriers around themselves.\n\nStill holding it all together is the United States. Most global internet\ntraffic still travels through the United States. An email going from, say,\nBudapest to Hanoi would head across the Atlantic through undersea cables,\ntraverse the Lower 48 states, and plunge into the Pacific before hitting Japan\nand being dispersed in the direction of Vietnam. The United States continues\nto be the loudest voice in the various internet forums for maintaining the\nglobal internet. ICANN, the Internet Corporation for Assigned Names and\nNumbers, which manages the global Domain Name System, is still very much a\nU.S. entity (though it is no longer controlled by the U.S. government) and it\npromotes the original U.S. view of the internet.\n\nThe problem is that this view of the internet is fundamentally incompatible\nwith the direction Russia, China, and other authoritarian regimes wish to take\nit. As they carve off their chunk of the internet and continue to expand the\ncontrols they place on their citizens and on companies doing business within\ntheir country, they are also pressing to remake the global internet in their\nimage. That image would put states in charge, ending the multi-stakeholder\nmodel that would allow companies and users a voice in how the internet\noperates. Meanwhile, by controlling the internet and the systems and\ninformation that are accessible to it in their own countries, nations led by\nauthoritarian regimes are using our own relative openness against us,\nsiphoning up our intellectual property, manipulating our elections, and\ngenerally using the internet to wage a low-grade war against us. These\ncountries act as safe havens to cyber criminals or, in the case of North\nKorea, actively use cybercrime to support the regime.\n\nIt does not have to be this way. Instead of working to preserve a global\ninternet that is open, interoperable, secure, and reliable (something that was\nalways more fiction than reality), we could choose to structure the\nbalkanization. We will never persuade the Chinese and the Russians to accept\nour vision of the internet until we persuade them to accept our vision of an\nopen and tolerant democratic society that respects the rights of the\nindividual. The ability of the internet to shape societies was always\noverstated, at least in comparison with the ability of societies to shape the\ninternet. Thus, instead of begging and pleading with authoritarian states to\nplay by our rules, we should set the terms under which they get to have\nunfettered access to the unfettered internet and, in the meantime, as it were,\nfetter their access.\n\n### Why a Schengen Model Just Might Work\n\nIt’s an odd time to be basing anything on what some are now calling the\n“European experiment,” particularly its immigration and border policy. The\nUnited Kingdom has been having paroxysms over its exit from the EU and fully\none third of “leave” voters said that exiting the EU “offered the best chance\nfor the UK to regain control over immigration and its own borders.” More\nstrikingly, almost half of leave voters said their vote was about sovereignty,\nbelieving that membership in the EU broadly meant that the U.K. had simply\ngiven up too much of its authority to the bureaucrats in Brussels. As Britons\nwere getting cold feet about exiting, post-Brexit arrangements on borders and\nimmigration were looking like they may stay largely the same. That’s because\nfor all the ills that being connected to Europe seemingly (to many) brought to\nthe U.K., the benefits far outweigh the losses (the best we can hope for in\npublic policy).\n\nAt first, only five of the ten member states of the European Economic\nCommunity agreed to sign the Schengen Accord, then a limited agreement to\nharmonize visa policy and reduce border checkpoints. The goal was to let\nborder communities cross freely to work and shop. Five years later, the\nagreement was extended to completely eliminate all internal borders and to\nestablish a unified visa policy. Four hundred million people live within the\nSchengen Area and can roam freely over all its 4.3 million square kilometers.\nThe agreement became part of EU law in 1999, excepting only the U.K. and\nIreland from the area, at their request, and Bulgaria, Croatia, and Cyprus,\nbecause their external controls were deemed insufficient. To the north, the\nnon-EU states of Iceland, Norway, Switzerland, and Liechtenstein have chosen\nto join the Schengen Area.\n\nJoining the Schengen Area comes with three requirements. First, nations must\nissue uniform Schengen visas and demonstrate strong security on their external\nborders. Second, they must show that they have the capacity to coordinate with\nlaw enforcement in other Schengen countries. Finally, they must connect to and\nuse the Schengen Information System, a system for tracking entries and exits\ninto the Schengen Area and for law-enforcement coordination. The rules include\nhow cross-border surveillance can be conducted and the conditions under which\n“hot pursuit” across borders is allowed. They also allow for faster\nextradition of criminals between the states.\n\nUnlike efforts to tackle cybercrime alone, the Schengen Accord has a clear\nquid pro quo, a give-something, get-something model built in. Want your\ncitizens to have the right to live, work, and travel anywhere in the EU? Then\nenforce your borders, issue common visas, and cooperate in the investigation\nof cross-state crimes. To date, all efforts to bring the international\ncommunity together to address cybercrime, economic espionage, and other ills\nof the internet age lack such an incentive structure.\n\nThe most successful of these efforts, the Council of Europe Convention on\nCybercrime (also known as the Budapest Convention), sets out all the\nreasonable actions that states should undertake to combat cybercrime. It\nprovides model laws, requires extradition, and offers some nominal\ncoordination requirements. Sixty-one countries have ratified the treaty. Yet\nit is hard to find defenders of the Budapest Convention for the simple reason\nthat it hasn’t worked. The convention has failed to make any meaningful\nprogress on the problem of cross-border cybercrime.\n\nDamningly narrow in scope, the Budapest Convention needs to be replaced with\nan accord that provides real benefits to join and real consequences for\nfailing to live up to obligations. A Schengen Accord for the internet would\nabandon the conventional wisdom that the United States, its allies, and like-\nminded countries need to continue to press for a single, global, open\ninternet. Instead, these countries would work toward harmonizing not only laws\nthat deal with cybercrime, but also laws that define legal activity on the\ninternet and promote digital trade. The most effective way to pull countries\ninto the accord is to deny them some or all of the benefits of connecting to\nthe internet of Amazon, Google, Facebook, and Microsoft, not to mention the\nwallets of the 700 million consumers in Europe and the United States. Indeed,\nthe United States has had the most success combating moves toward data\nlocalization when it’s tied the issue to trade. The attempt to jettison NAFTA,\nthe United States–Mexico–Canada Agreement (USMCA), includes a chapter on\ndigital trade that, among other things, bans the three countries from\nrequiring data localization and has requirements for all three countries to\nhave rules to address things like spam and consumer protections online. What\nit fails to do is provide the necessary levels of specificity and to set up\nsufficient mechanisms for cross-border cooperation on cybercrime. As Michael\nGeist at the University of Ottawa points out, maintaining things like antispam\nlaws is useless without specific requirements and mechanisms for ensuring\naccountability.\n\nA hypothetical accord should provide common rules for how data is stored and\nhow it can be accessed by law enforcement in the country where it is stored,\nthe country where it is owned, and by third-party countries. By harmonizing\nthese rules, member states would be making it easier for companies to compete\nacross national boundaries. Companies would need to institute mechanisms to\ncoordinate on law enforcement. The CLOUD Act, passed by the U.S. Congress in\n2018, laid much of the groundwork, allowing the President to enter into\nagreements for the facilitation of cross-border access to electronic\ninformation by foreign law enforcement. A multilateral agreement could provide\nfar stronger and better mechanisms to deal with the downsides of open borders\nin cyberspace. Such an agreement would need to include a commitment to allow\nthe free flow of internet traffic across national borders. This commitment\nwould not mean that countries are giving up sovereignty but simply, as with\nthe Schengen Accord, that they will not exercise that sovereignty on their\nborders. Germany could still, for instance, make transmitting the text of\n_Mein Kampf_ a crime within Germany, but it would not attempt to filter out\nfiles that match its hash when they enter Germany.\n\nAs we have noted, we are not fans of borders in cyberspace. The ability to\nmeaningfully filter out malicious traffic on a national level is beyond the\ncapability of technology today. Moreover, doing so would require that\ngovernments have the ability to decrypt traffic, which would do more to harm\nsecurity than it would to help (to say nothing of privacy and civil\nliberties). Thus, we would not, at least initially, suggest that a Digital\nSchengen Accord would involve “hardening” external borders. Instead, we would\nfocus on promotion of the benefits of being within the accord and development\nof the mechanisms to address the drawbacks (such as law-enforcement\ncoordination). We would, however, have ISPs institute what some are already\ncalling “Schengen routing,” in which they keep all traffic internal to member\ncountries within those member countries or create massive, encrypted tunnels\nwhen doing so is not possible.\n\nEventually, as the attractiveness of being part of this new Digital Schengen\nAccord grows, the ability of its members to exclude countries from it or limit\ntheir connectivity to it could be used to shape behavior of problematic\ncountries. Together with traditional sanctions, dropping or limiting traffic\nfrom nuclear proliferators or unrepentant havens of cybercrime could prove a\npowerful tool for reforming bad actors. Before that can happen, though, states\nwithin the accord would need to clean up their own acts.\n\nIt’s no secret the United States typically ranks up with China as the country\nwhere most malicious cyber activity occurs. That is, in large part, because\nthere are more computers that are more powerful and connected at higher rates\nof bandwidth in the United States than anywhere else in the world. Rather than\nwaste time compromising networks of home machines to build a botnet, cyber\ncriminals are now doing what fledgling start-ups are doing and buying\ncomputing power from Amazon’s cloud (the only difference is that they use\nstolen credit cards to make the purchase). The United States lacks strong\nmechanisms for limiting misuse of its infrastructure. American internet\nservice providers do not have the kinds of systems for notifying and\nquarantining owners of infected systems that German and Scandinavian ISPs do.\nBecause of that, most DDoS attacks and all manner of other cybercrime\noriginate in the United States.\n\nOn the other side of the pond, European countries have been in a protracted\nbattle over protection of their citizens’ data when it is stored by U.S.\ncompanies and for access to it when a crime has been committed. The process to\naccess data in a foreign country for a criminal matter is still governed by\nagreements between individual countries, known as mutual legal assistance\ntreaties (MLATs), that are typically decades old and do not provide for rapid\nresponses. The CLOUD Act has partially addressed this problem, but a broader\nsolution is still required. What might that look like?\n\nFirst, the Digital Schengen Accord would need to require a broader\nharmonization of law and a clear process for handling differences. Respecting\nWestern values, it should set freedom of expression on the internet as the\ncommon denominator, and layer in exceptions on a case-by-case basis. For\ninstance, the United States would not be forced to accept European\nrestrictions on free speech but instead, like today, accept that U.S.\ncompanies would need to take reasonable efforts not to sell or display banned\ncontent in those countries. While this approach would, in many ways, enshrine\nthe status quo, it’s essential protection against the vision that China and\nother countries are now demanding for the internet as a whole: that foreign\ncountries must meet their standards for what they term “information security”\nin its full Orwellian meaning.\n\nSecond, we would need to establish a mechanism for monitoring adherence to the\nDigital Schengen Accord. Countries would need to be evaluated on whether their\nlaws are meeting the requirements of the accord and whether their law-\nenforcement agencies are implementing those laws. A model for this kind of\nmutual evaluation can be found in the Financial Action Task Force (FATF),\nwhich has effectively instituted measures to address money laundering.\n\nThe FATF was created by the Group of 7 countries in 1989, together with the\nEuropean Commission. Its first effort was to simply create a set of forty\npolicies that countries should adopt to combat money laundering. Its thirty-\nseven member countries account for much of the world’s financial transactions.\nFATF monitors compliance with its standards and helps countries implement\nthem. Instead of a heavy-handed centralized effort, monitoring is done on a\nmutual basis, with teams of countries reviewing the efforts of one another and\nmaking recommendations.\n\nFATF has also supported the creation of what the organization dubs FATF-style\nregional bodies. These FSRBs adopt FATF standards and work to implement them\non a regional basis. A FATF-like organization at the center of a new treaty on\ncross-border data flows would provide what the Budapest Convention never\ncould, a mechanism for assisting in and evaluating adherence to agreed-upon\npolicies.\n\nThird, the Digital Schengen Accord would then need mechanisms for monitoring\nand responding to malicious activity. In this case, the arena of public health\noffers a valuable model: a World Health Organization at the top, national\nequivalents to the Centers for Disease Control and Prevention, and teams that\nprovide international assistance. The WHO-like organization would be\nresponsible for organizing efforts to reduce vulnerable systems (the\nequivalent to vaccinations), identifying and responding to emerging malware\nfamilies and botnets to stem them before they cause widespread harm (the\nequivalent to outbreak monitoring), and coordinating takedown and remediation\nefforts when prevention fails (crisis response). National CERTs would be\nresponsible for contributing to the central organization and for leading\nefforts in these areas in their own countries. Under a new law passed in\nEurope, national CSIRTs (computer security incident response teams) are meant\nto fill this national role.\n\nFinally, the Digital Schengen Accord would need much stronger law-enforcement\ncoordination mechanisms than exist today. Almost a decade ago, the U.S.\nDepartment of Justice set up a 24/7 pager network among like-minded countries.\nThere are still DOJ employees handing off a single pager around the clock.\nSuffice it to say, in 2019, the cyber problem requires a 24/7 law-enforcement\ncoordination capability. Interpol has also made efforts in this direction but\nremains well understaffed and without sufficient authority. What is needed is\na central capability to receive and mediate requests for law-enforcement\nassistance.\n\nThe organization needs to have the capacity to coordinate requests among all\nmember states, and, when warranted, nonmember states. It will also need to be\nauthorized to call balls and strikes when unlawful requests are made.\nMaintaining and publicizing real-time metrics on the responsiveness of\ncountries can be a powerful naming-and-shaming function. With this kind of\nsystem in place, the United States and other countries that are part of this\ninternet Schengen zone would be much better positioned to push nonmember\nstates to be responsible actors in cyberspace. At present, U.S. pressure on\nChina to curtail cybercrime is often met with a somewhat fair “you first”\nresponse.\n\nUnder a Schengen-like system with stronger abuse reporting, streamlined\ntakedown requests, and rapid law-enforcement cooperation, member countries\nwould have a ready answer to such charges of hypocrisy. Moreover, the\ndifficult questions of when offensive cyber operations can be employed against\nthird-party countries would be answered. Such offensive operations would not\nbe permitted, because reliable means of achieving the desired outcome\n(shutting down of command-and-control servers or elimination of bots in a\nbotnet) would be established by the agreement and executed swiftly by the\nmechanisms it establishes. Of course, those countries that are outside the\nzone and do not have similar cooperative mechanisms or fail to use them would\nbe fair game for offensive cyber operations.\n\nThroughout this book we have been making the case that much of the\nresponsibility for addressing cyber threats falls to the owners and operators\nof those systems. We’ve argued that the view that offense has the advantage\ntoday is overstated and that we can take steps to reduce that advantage\nfurther. We are also painfully aware that there are threats that companies\ncannot address on their own, and that government has a role to play. That role\nis most clear in the international arena, where state power is most relevant.\nThe ad hoc approach we have taken as a government to diplomacy, law\nenforcement, sanctions, and norms development has not produced the outcomes\nthat many in the field believe are necessary.\n\nThe Schengen Accord began with only five members agreeing to a limited\nharmonization on visa policy. It was then expanded over a fifteen-year period\nuntil the agreement gave us the Schengen Area we have today. To replicate this\nmodel for a new internet accord, the United States and its like-minded allies\nshould continue to harmonize relevant laws through digital trade chapters in\ntrade agreements and begin to establish or strengthen the necessary mechanisms\nto handle malicious cross-border cyber activity. As these digital trade\nchapters grow, it will then make sense to harmonize them into a multilateral\ntreaty that would establish common rules across all member countries.\nEventually, such an approach could yield a single shared network with\nharmonized laws that reflect Western values and have the mechanisms in place\nto deal with the harms that a free and open internet will necessarily allow.\nWhile we fully endorse the vision of an open, interoperable, secure, and\nreliable internet, we are no longer convinced that version of the internet\nwill also be global. It is likely time to take a new approach. Perhaps that\nnew international approach should also address the use of cyberattacks and\ninfluence ops on our democratic processes. That’s next.\n\n\n## Chapter 14\n\n## DEMOCRACY’S SHIELD\n\n## Defending Electoral Systems from Cyber Risk\n\nBrush your teeth. Eat your spinach. Audit your elections.\n\n—POORVI VORA, PROFESSOR OF COMPUTER SCIENCE, GEORGE WASHINGTON UNIVERSITY\n\nAdrian Chen pulled back the curtain, figuratively and literally. He was\nsitting in a restaurant on Savushkina Street in Primorsky, a neighborhood in\nSt. Petersburg, Russia, peering out from behind a drapery at the nondescript\noffice building across the street, a building where people were busy making\nthings up.\n\nChen revealed his findings in a prescient article in _The New York Times_\n_Magazine_ in June 2015. We read it that Sunday and then reread it on Monday.\nThat it was important seemed clear to us, but why it was important we could\nnot then guess. In hindsight, of course, it seems obvious.\n\n### The Clue on Savushkina\n\nThe building on Savushkina was home to the Internet Research Agency, an\nallegedly private Russian organization that was busy creating very\nprofessional-looking videos and social media posts about what seemed to be\npurely random and completely fictitious stories. The one that was most\nstriking was a highly developed, multimedia effort to convince readers that a\nparticular chemical plant in Louisiana had blown up. It hadn’t. What was the\npoint of saying it had?\n\nWe asked reporters and ex–intelligence officers back then, in 2015, that very\nquestion. Most shrugged. When we pressed them, the answers we got were things\nlike “trial run” and “rehearsal.” But for what? No one could guess.\n\nWell, now we know. The Russians were experimenting, trying to see if American\nsocial media would stop them from creating fiction and promoting it as real.\nThey were also learning how gullible Americans on social media might be. They\nwere perfecting the skills of Russians living in St. Petersburg pretending\nthey were Americans living in Louisiana, among other places. They did it all\nin plain sight and, for the most part, no one noticed.\n\nEven if American authorities had thought it was a problem that Russians were\npretending to be Americans online, it was not clear that any laws were being\nbroken. Even had American authorities focused on the “troll factory,” they\nwould not have known that the Internet Research Agency’s activities were only\none small part of a multifaceted assault on our democracy. Nor would the\nreason for the activity have been obvious.\n\nBy 2018, what the Internet Research Agency was doing was so obvious that U.S.\nCyber Command reportedly attacked the organization’s computer network, perhaps\nnot coincidentally on Election Day. It was a rare if not unprecedented event,\nthe U.S. military attacking a Russian organization, and it gave great\nsatisfaction to Dick Clarke, who had called for just such an attack in a\nseries of television appearances.\n\nThe Russian government of Vladimir Putin has for years been involved in an\nundeclared “hybrid war” with the United States and the West in general. Cyber\ntools have been his most commonly used weapons. Unable to significantly\nincrease the military or economic power of his country, he wants to pull down\nother countries, so that the gaps between them and Russia are narrowed. He\nwants to reduce the power of the United States and the Western alliance\nrelative to Russia. His strategy is simple: divide.\n\nHe seeks to divide Americans from one another, to divide Britain from the\nEuropean Union, to divide Turkey from NATO, to divide Catalonia from the rest\nof Spain, to divide parts of Ukraine from the rest of the country, etc. Hybrid\nwar includes cyber war, of every sort. It also includes classical intelligence\noperations to buy influence, paramilitary activity, and diplomacy. It is\neverything short of major armed conflict. We, however, are going to focus on\nthe cyber-war components.\n\nWhen the potential for cyber war began to emerge in the 1990s, the U.S.\nmilitary called it “information warfare.” The problem with that was that they\nhad already called the massive propaganda operations of the Cold War\n“information warfare” too. It was confusing, the Pentagon labeling two\ndifferent things with the same phrase. Eventually, the computer network\noperations were labeled “cyber,” in part due to the Clinton administration, to\nthe eternal frustration of language purists.\n\nThe Russians, however, never saw cyber war and propaganda as separate. From\nbefore the Russian Revolution, they had been masters at spying, deception, and\ndisinformation. They had Russian words and phrases for their tools, such as\n_maskirovka_ , _disinformatia_ , and _kompromat_. It was literally part of\ntheir military’s checklist. The advent of computer networks just gave them\nanother place to practice spying, deception, and disinformation when permitted\nby civilian authorities. Putin not only permitted, he ordered.\n\nIn the words of Alex Stamos, Facebook’s former CSO, “Their [U.S. adversaries’]\ndream is when most Americans say [about the election], ‘I don’t have a choice\nin this.’” Putin ordered an attack to undermine America by heightening its\ninternal divisions and undermining its citizens’ confidence in their\ndemocracy. He unleashed hybrid war against a score or more of countries of the\nformer Soviet Union and Europe, but the campaign against the United States was\nspecifically tailored to take advantage of our own vulnerabilities. It is on\nhis cyber-enabled attack on U.S. democracy that we will focus in this chapter.\n\n### Defenders of Democracy\n\nLaura Rosenberger and Eric Rosenbach not only share similar last names, but\nalso both served as Obama administration officials, one at State and one at\nDefense, and are now separately spending their days trying to counteract\nRussian efforts to subvert U.S. democracy.\n\nLike so many other Americans of her generation, Laura Rosenberger saw her life\nchange in 2001, on 9/11.\n\nA senior in college and thinking of what should come next, she was thrust into\na state of shock, as was all of America, on that day. The day after, however,\nshe knew: “I need to dedicate my career to do my small part to make sure this\nnever happens again.” After graduate school in government and a brief stint\nwith an international peace organization in Kosovo, Rosenberger entered the\nState Department as a Presidential Management Fellow during the George W. Bush\nadministration. That program is undoubtedly the most valuable way in which the\nU.S. government recruits its future leaders. Rosenberger quickly proved she\nmay be one of them.\n\nAfter a tour on the Korea desk, she moved to the National Security Council\nstaff for a rotation and eventually ended up in the West Wing, helping to make\nthe Deputies Committee work. It is the Deputies Committee, the number two\nofficials or chief operating officers of the national security departments and\nagencies, that meets almost daily to make and implement policy in response to\nthe ever-changing global situation. Staffing the “DC,” as it’s called inside\nthe Beltway, Rosenberger saw it all, including Putin’s hybrid war and military\ninvasion of Ukraine. The U.S. response, however, was less than optimum, in\nlarge part because the United States did not fully recognize what a hybrid war\nwas at the time.\n\n“We weren’t seeing the whole picture, given the kinds of tools the Russians\nwere using,” she told us. “Connecting how the hacks related to the Little\nGreen Men (the Russian troops pretending to be local militia or civilian\nvolunteers), related to the _disinformatia_ , related to the financial\nmanipulation.” Putin, the career intelligence officer, had orchestrated the\nuse of all of the tools available to the Russian state to invade and occupy a\nlarge and valuable chunk of the neighboring country, but had done so in ways\nthat did not look like a traditional war and, therefore, never quite triggered\na fullthroated U.S. and NATO response. It worked.\n\n“So I had that experience around Ukraine, and then fast-forward to the [2016]\nelection and I am watching from inside the campaign and I see the same things\nhappening again.” Rosenberger had left the White House in 2016 to work as a\nnational security adviser to candidate Hillary Clinton. “We were trying to\nraise alarm bells right and left, but people thought we were crazy or alarmist\nor doing it for political purposes.”\n\nLike many who worked in the Clinton campaign, Rosenberger thought then, and\neven more so now, that the Obama administration should have done more to say\nwhat the U.S. government knew about Russian interference before the American\npeople voted. Clinton herself has tried to understand why there were few\nalarms sounding, and has written about Initial Occurrence Syndrome, citing\nDick Clarke’s 2017 book _Warnings_. The first time a phenomenon occurs, there\nis a cognitive bias against believing it is true, or as significant as the\ndata indicates.\n\nFor Rosenberger, as for us, the day after the election gave her a very brief\ninsight into what clinical depression might feel like. “I don’t even know how\nto describe what recovery was like. I was trying to fall off the face of the\nearth for a while.” Then, when it was less raw, she looked back at what had\nhappened and realized that before the vote neither the Clinton campaign nor\neven the U.S. intelligence community were fully aware of some of the hybrid\nwar tools that were being used.\n\n“There were a lot of things we did not know were happening,” she told us. “The\nsocial media stuff, all of that, was a postelection realization.” Then, as she\nhad on 9/12, she asked herself what she could personally do about it. The\nresult was the Alliance for Securing Democracy (ASD), a new, bipartisan,\ntransatlantic, nongovernmental organization dedicated to exposing the\ncontinued Russian subversion and explaining its corrosion of Western\ndemocracies.\n\nSitting in the German Marshall Fund building in downtown D.C., Rosenberger\ncodirects the ASD in the United States and Europe with Jamie Fly, a former\nnational security adviser to Republican Marco Rubio. “I knew from the\nbeginning it had to be truly bipartisan. Putin’s strategy is to divide us, so\nif you respond from a divided perspective, you really play into his hands.”\nTogether, along with a team on both sides of the Atlantic, they created the\nPolicy Blueprint for Countering Authoritarian Interference in Democracies, an\naction plan for defending against hybrid war.\n\nThe ASD is transatlantic because the Russian cyber and disinformation\noperations haven’t just been directed at the United States. In fact, they had\ntested them extensively in Europe before bringing them to America. “Our\nEuropean friends had been sounding the alarm for a long time and maybe, we\nthought, we should start listening to them in ways that we hadn’t been.”\n\nTwo of the key recommendations in the Policy Blueprint are closing known cyber\nand information vulnerabilities, and exposing ongoing activities. What\nfrustrates Rosenberger is that many of the vulnerabilities remain. “Our house\nwas robbed, so at least let’s lock the door,” she vented to us. The problem is\nthat there are many doors in the United States. There are more than three\nthousand county governments, each of which has some modicum of sovereignty\nover how it manages and secures, or doesn’t secure, the election process.\n\nExposing the ongoing activities is necessary because, according to\nRosenberger, “the Russians are much more brazen. What they used to hide, they\nnow do out in the open.” The same phony Russian Twitter personas that were\nthumping for Trump in 2016 are now pretending to support far-left candidates\nand progressive causes in the United States, with the goal of stoking division\nin the Democratic Party and in the United States more broadly. ASD tracks the\ntweets, Facebook posts, and other social media content in real time on its\nHamilton 68 website. It looks like the big screen inside a corporation’s\nsecurity operations center, spotting and calling out the Russian activity for\nthe world to see.\n\nWhile the Alliance for Securing Democracy has done good work, Rosenberger sees\na need for government to step up. “We have to break down the silos of cyber\nand info ops, money laundering . . . and civil society subversion . . . and\nunderstand them as part of a tool kit,” the tool kit that Putin uses. To do\nthat, she calls for a multifaceted, coordinated U.S. government effort,\norchestrated from the National Security Council staff. For complex, emerging\nproblems, having an “orchestra director” in the White House has always seemed\nto us the sine qua non of effective government response.\n\nCaptain Eric Rosenbach was a young U.S. Army officer in Europe during the\nBosnian and Kosovo wars, using cyber operations and signal intercepts to\nprovide real-time intelligence to U.S. and NATO forces in the Balkans. It was\nthe 1990s, and techniques to wage cyber war were only just being\nconceptualized. Upon leaving the Army, Eric stayed in Europe and married a\nGerman lawyer. While she practiced law, he worked on cybersecurity for a\nEuropean internet provider and learned just how insecure corporations and\nprivate users typically were online.\n\nAfter graduating from Harvard’s Kennedy School of Government in 2004,\nRosenbach went to Washington and earned a coveted staff position with the\nSenate Select Committee on Intelligence, working for Republican Senator Chuck\nHagel. Later, he moved to the Pentagon to fill a new slot, Deputy Assistant\nSecretary of Defense for Cyber. Not long thereafter he was promoted to\nAssistant Secretary, and then in 2015, when his former Kennedy School\nprofessor Ash Carter became the SECDEF, Rosenbach became his Chief of Staff.\nIn that job he saw almost everything that went on in the vast Defense\nDepartment bureaucracy. With the end of the Obama administration, Rosenbach\nand Secretary Carter returned to the Kennedy School to codirect the storied\nBelfer Center for Science and International Affairs.\n\nBack on the banks of the Charles in February 2017, Rosenbach didn’t have to\nthink hard about how to keep the Belfer Center relevant. “When I was in the\nPentagon I saw in near real time what the Russians were doing to mess with our\nelection. We didn’t do enough,” he admitted. “The administration made a huge\nmistake. It was burning in my gut.” Rosenbach decided he would build a program\nto help state and local governments defend against another wave of attacks.\nThe resulting Defending Digital Democracy Project is something that Eric,\nstill addicted to Pentagon-style acronyms, calls D3P.\n\nBy a year later he would have state and county election officials from forty-\ntwo states in the Kennedy School quad, making the problem real for them by\nmaking them play the kind of stress test that the war gamers in the Pentagon\ncalled a tabletop exercise, or TTX.\n\nIn the TTX, Rosenbach and his team put the election officials through their\npaces by demonstrating the numerous ways in which a Russian, or other\nattacker, could try to interfere with the election ecosystem. The D3P\ndirector, Caitlin Conley, an active-duty U.S. Army Major and Kennedy School\ngraduate, knew how to run an effective TTX. She divided the officials into\nfour fictitious states and then compressed months of cyberattacks and hybrid\nwar operations against the states’ election infrastructure into a three-hour\ngame. No one left the game thinking the problem we face is anything but\nsignificant.\n\nD3P did more than play war games or restrict its activities to Harvard Square.\nThe project invited students from Carnegie Mellon, Tufts, Georgia Tech,\nGeorgetown, and other top universities to develop tools to help defend\ndemocracy. In a 2018 hackathon, teams from these schools competed for a cash\nprize for the most valuable contribution to the defense.\n\nRosenbach’s team went on to write a playbook for defending candidates,\ncampaigns, and state and local election operations. Among other\nrecommendations, the playbook spells out five primary measures, simple things\nsuch as using two-factor authentication, which gets you 90 percent of the way\nto being secure, Rosenbach contends.\n\nWhile Rosenbach is more sanguine than we are about the skills and intentions\nof the thousands of county-level election officials, he agrees that “no\nelection official should be required to defend against the pointy end of the\nspear of Russian military cyberattacks.” At heart, Rosenbach thinks about the\nproblem through the lens of systems analysis. He told us, “It’s important to\nthink about the election infrastructure as a system of systems, all\ninterconnected, and any of which can have vulnerabilities that the Russians\ncan exploit.”\n\n### The Election Ecosystem\n\nIn the United States, the election ecosystem has seven major components: 1)\nthe candidates, their personal devices, and their emails; 2) the campaigns,\npop-up organizations with a short life span and almost never enough money to\nconduct even traditional voter drives; 3) the two major political parties,\nwith their national, statewide, and local offices; 4) the state government and\ncounty government, which run voter registries, databases that say who can vote\nand where they have to go to do so; 5) the voting machines on which votes are\ncast and recorded; 6) the devices and networks that send the machines’ total\nto statewide election officials for tallying; and 7) the social media\nplatforms that people, the media, parties, and candidates use to discuss the\nelection and political issues. All seven can and have been targeted by the\nRussian military.\n\nWe are not going to rehash here the stories of the Russian attacks in 2016, or\ntheir continuing role in the 2018 election as the electoral battlefield is\nbeing shaped for 2020. There are plenty of good accounts of what happened and\nwhat is ongoing. We want to focus on solutions. Before we do, let’s examine\nthe “security through diversity” and constitutional arguments that some state-\nlevel election officials have used to contend that there is no need for, or\nlegal basis for, federal action to defend the election system.\n\nThe security through diversity theory is that the great strength of the U.S.\nelectoral ecosystem lies in the fact that each state (and to some degree, each\ncounty) gets to design its election infrastructure and, therefore, the theory\ngoes, every state’s system would require a unique approach to attack.\nProponents of this theory postulate that so many disparate systems would mean\nthat the Russians could never figure out how to compromise any significant\nnumber of them. Well, think again. What infrastructure diversity actually does\nis create a tier of bottom crawlers whose security is so bad it invites\nattack.\n\nMoreover, the Russians do not have to attack every machine or precinct. They\njust need to affect enough of the “right” districts to tip the election.\nAmerican elections are often close, and it is usually very easy to figure out\nin advance which precincts are going to go heavy for one candidate, and which\nwill be toss-ups. With that knowledge, you could construct a limited series of\nattacks that could change the outcome.\n\nAn attacker could crash a few voting machines to make lines long at polling\nplaces where the candidate they want to defeat is expected to do well.\nAlternatively, they could drop voters from the registry database, preventing\ncertain swaths of citizens from voting entirely, or change their designated\nvoting precinct, resulting in long conversations and arguments at the check-in\ndesks. Many voters, confronted with long lines at the end of the day, would\ngive up and go home without voting, something we saw happen in 2004 in Ohio.\nMany John Kerry supporters thought the long lines at pro-Kerry precincts were\nintentionally created by the Republican election officials and may have cost\nhim the state. Had Kerry won Ohio, he would have defeated George W. Bush in\nhis bid for reelection.\n\nCould the Russians do that? Almost certainly. We know because the U.S.\ngovernment admits that the Russians attempted to break into more than half the\nstates’ voting registries. Did they succeed? The state election officials say\nno, but how would we ever really know? None of the states have the\nsophisticated threat-hunting capabilities that major U.S. banks possess. After\nall, “state IT officials did not sign up to go against Chinese or Russian\ncolonels,” as Alex Stamos said. We cannot expect our state-level bureaucrats\nto fend off military-grade attacks.\n\nWe know that nation-state-sponsored hackers regularly penetrate government and\ncorporate systems. Three quarters of all corporations that have been\nsuccessfully attacked did not discover that fact themselves, but were told\nlater by somebody else, often law enforcement.\n\nIf nation-states regularly penetrate networks without being noticed, why would\nwe believe that state electoral organizations, with tiny cybersecurity budgets\nand limited cybersecurity expertise, would detect an attack that altered the\nvoter registration data? Furthermore, few states have done sophisticated\naudits to look for penetrations or alterations. What is that old saying? “The\nabsence of evidence is not the evidence of absence.”\n\nAs for the argument that the Constitution says the states should decide the\n“time, place, and manner” of Congressional elections, yes it does. The same\nsentence then has the word “but” and another clause that says Congress may\npass laws regulating the time and manner of Congressional elections. Congress\ncould, using authority granted by the Constitution, establish minimum\ncybersecurity standards for voting devices, databases, and networks.\nIncredibly, even after the 2016 debacle, it has not.\n\nCongress did not act in part because it had been controlled by Republicans who\nhave found a variety of reasons to justify not doing more to defend the state\nsystems. Republicans blocked additional funds for the states to enhance\nelection security. Perhaps some Republicans think that if Russian meddling\nhappened, it might have helped the party achieve its 2016 electoral victory. A\nmore powerful reason for inaction has been the opposition of state and local\nelection officials, who see Washington’s help as an inconvenience, a\ncondescending allegation of their failure to secure the vote, and an\narrogation of local government powers. Many local election officials are in a\nstate of denial rivaled only by climate-change deniers for their damaging\neffects on our country.\n\n### Election Security Solution Sets\n\nBecause the election ecosystem has numerous components, there is no single,\nall-encompassing solution. We see four discrete solution sets.\n\nThe first solution set outlines minimum essential cybersecurity standards for\nfederal elections set by law, combined with federal funding to achieve those\nstandards. We are not suggesting a particular network architecture or a list\nof specific products, but we do think there are some procedures that at a\nminimum should (or should not) be used, and some types of products that ought\nto be mandated.\n\nToday, only a handful of vendors produce voting machines. Time and time again\nthey have refused to allow government officials to examine their software for\nvulnerabilities that could lead to exploits. That is simply outrageous and has\nto stop. While we would not dictate which voting machines in particular should\nbe chosen, we would insist that all hardware or software required to conduct\nan election be certified as secure by one of a handful of approved and\nimpartial expert labs. Think “Underwriters Lab” approval for toasters and\nother household appliances, but instead, for election infrastructure.\n\nWe envision minimum essential security standards for voter registration\ndatabases, for voting machines, for devices and networks that report results\nup the tape, and for pre- and postelection audits of devices, databases, and\nresults. Among those requirements would be continuous monitoring software,\nvulnerability detection software, endpoint protection, code analysis,\nintrusion prevention software, data loss prevention software, multifactor\nauthentication of users, and support from a managed security service provider\n(MSSP), all performed by certified firms using software and devices that have\ngone through the same certification process that the Defense Department\nrequires of its cyber vendors. It will not produce perfect results, but it\nsure will be better than the target-rich and insecure environment we have\ntoday.\n\nThen there are obvious dos and don’ts. Do use a paper ballot backup that can\nbe audited. Without a paper trail, it’s impossible to know if the results (as\nreported by the largely insecure voting machines) are accurate. Do not use\ninternet voting, even for overseas military voters. The risks of internet\nvoting far outweigh the benefit of the small amount of time saved by not\nhaving to deal with paper ballots or tabulation machines.\n\nWhen Terry McAuliffe was running for Governor of the Commonwealth of Virginia\nin 2013, he entered the voting booth, ready to cast a vote for himself. He\ntouched his name on the screen, but nothing happened. Then he tried again. And\nagain. “It took the third time, I think,” he told us. With or without his own\nvote, he won, but he never forgot the experience he had, and always wondered\nhow many voters never caught the glitch in the machine. As Governor in 2014,\nwhen he tried voting for Mark Warner in the U.S. Senate race, his Republican\nopponent Ed Gillespie’s name lit up on the WINVote machine instead.\n\nHe had had it. McAuliffe put $1.6 million in his budget to have the state,\ninstead of the local government, pay to replace the three different types of\ndirect-recording electronic (DRE) machines still in use in some counties of\nthe Commonwealth, machines with no paper backup that could be audited. Between\nthe curious politicization of the issue and the influence of voting-machine\nmanufacturers, the bill did not pass the legislature. “Some thought the state\nshouldn’t be doing what is a local issue,” he remembered. And there was a lot\nof lobbying by the voting-machine companies. “A summer vacation paid for, a\ntrip, maybe this, maybe that.”\n\nAfter the Russian interference of 2016, McAuliffe’s patience with the\nlegislative process had run out. He ordered examination of all DRE machines in\nthe Commonwealth. “Counties didn’t want to turn them over. They were afraid we\nwould easily hack them and they would be embarrassed.” It turns out their\nfears were not unfounded. “We were able to hack into all of them.”\n\n“At that point,” McAuliffe said, “I had the Board of Elections, which I\nappointed, vote to decertify all DREs two months before the election of 2017.”\nThis time the counties had to pay to replace them immediately. There was no\nstate money. The counties had missed their chance. “Now every machine in use\nhas a paper audit trail. It’s what’s needed throughout America.” But as in\nVirginia, there are local election administrators who resent the intrusion\ninto their realm, there are voting-machine company lobbyists who see their\nclients’ business threatened, there are politicians who are more than willing\nto accept gifts and campaign contributions to look the other way, and there\nare easily hacked voting machines despite what the local officials tell you.\n\nThe second solution set is extending federal election campaign advertising\nrules and adding other controls to social media. We agree with Laura\nRosenberger that “if our work is focused on protecting democracy, let’s not\nundermine the First Amendment in the name of [it].” Knowing who said\nsomething, if they were a real person or a bot, if they were in Moscow or\nCincinnati, is another matter. Similarly, disclosing who paid for a political\nadvertisement is a well-established norm of American politics that could and\nshould be ported from television and radio to the internet.\n\nAfter the Congressional hearings of 2017–2018, Facebook, Twitter, and other\nsocial media companies have faced mounting public pressure to spend time and\nmoney trying to identify bots and fake identity trolls on their platforms. It\nturns out, identifying these sorts of users is doable and they could have been\ndoing it all along, but purging accounts would have made their user numbers\nsmaller and, in turn, would have modestly decreased their advertising revenue.\nSimon Rosenberg and his colleagues at the Democratic Congressional Campaign\nCommittee (“the D-trip,” the organization supporting Democratic candidates for\nthe House of Representatives) got Facebook and Twitter to do just that in the\n2018 election.\n\nUsing open-source software developed at the University of Indiana, the D-trip\ngroup found Russian bots and trolls. On their first run with it, they found\n110 fake Russian Twitter accounts. They immediately, and privately, informed\nTwitter. The accounts were quickly taken down. As the campaign progressed,\nRosenberg and the team were in regular contact with both Twitter and Facebook,\ntelling the companies things that their corporate programs were not catching.\nHaving been burned by the Congressional hearing earlier in the year, the two\ncompanies cooperated. Rosenberg told us, “Working together, we even took down\none account within half an hour.” Not everyone was so cooperative. YouTube,\nowned by Google Alphabet, did not respond to requests from Rosenberg and the\nD-trip team. Given their limited staff and funding, Rosenberg told us, the\nD-trip unit did not focus on all social media. Reddit and other platforms were\nnot scanned. We now know, however, based on a report from the Senate Select\nIntelligence Committee, that in 2016, Reddit, Tumblr, Instagram, Snapchat, and\na host of lesser-known social media platforms were used by the Russian\nmanipulation campaign. Getting all of the platforms to do the right thing,\nespecially after the public scrutiny diminishes, may require a law and\nregulation.\n\nTo assure a minimum level of scrutiny, Congress should by law require social\nmedia to look for and delete bots and foreign entities pretending to be\nAmericans. The Federal Trade Commission, which has a decent record of\nprotecting consumers online, should rise to the challenge and issue\nregulations governing disinformation campaigns on the internet. While they are\nat it, Congress should take the minimal step of requiring online political ads\nto disclose who paid for them, and then ban foreign money from ads supporting\ncandidates or causes.\n\nSimon Rosenberg would also have political parties and candidates sign a\nvoluntary and public pledge that they will not use fake personas on social\nmedia or engage in the kind of bot and troll operations pioneered by the\nRussians. The pledge could also include an obligation to report publicly and\nto social media platforms when the candidates or their organizations become\naware of such operations.\n\nThe third solution set is intelligence and law-enforcement reporting of\nforeign cyber and information operations in near real time. It is interesting\nto know now that Facebook and Twitter posts allegedly from Black Lives Matter\ngroups saying not to vote for Clinton were actually being posted by very white\npeople in Russia, not black people in Chicago. It would have been useful to\nknow that before the election. The same goes for the posts telling Americans\nto vote for Jill Stein of the Green Party because “Hillary is going to win\nanyway.” Whether or not you supported Clinton, you might have wanted to know\nthat the Russians were behind these social media posts. In addition to\nrequiring social media companies to disclose what they find, the government\nshould be required to disclose what it uncovers.\n\nSometimes federal law-enforcement officials say they cannot reveal things they\nknow because the facts have been, or might be in the future, presented to a\ngrand jury as part of an effort to indict somebody for breaking a law.\nSometimes intelligence officials say they cannot publicly reveal what they\nknow because of the mysterious and intentionally obfuscatory phrase “sources\nand methods.” Eric Rosenbach told us that, with regard to the decisions he\nparticipated in, the intelligence community’s fear about losing valuable\n“sources or methods” was very often exaggerated or completely “bogus.”\n\nIn 2016, the Obama administration did publicly say that there was foreign\ninterference in the election, but not in a way that attracted a lot of voter\nattention or fully reflected the severity of the problem. While the government\ndid know a lot about Russian involvement, the extent of Russian social media\nmanipulation was not known until after the election.\n\nIn 2018, the National Security Agency and U.S. Cyber Command created the\n“Russia Small Group” to conduct operations to counter Russian cyber-related\ninterference in that year’s Congressional elections. General Paul Nakasone,\nthe head of both organizations, briefed Senators behind closed doors on what\nthe two units observed the Russians doing and on what the U.S. did to counter\nit. While the Senators seemed pleased, one of them, Senator Richard Blumenthal\nof Connecticut, noted that while the Russians know what the U.S. did to\ncounter them, the American people do not.\n\nTo clarify what the intelligence services and law enforcement should do,\nCongress should by law require ongoing and unclassified reports to the public\nof incidents and activities involving foreign entities’ attempts to masquerade\nas Americans to influence elections. Specifically, there should be a detailed\nreport issued two weeks before every federal election, drawing on everything\nthat any agency of the U.S. government knows.\n\nThe fourth solution set is to cooperate with and assist other democracies\nunder Russian attack, or attack from other foreign cyber and information\noperations, aimed at undermining their democratic processes. We are not alone\nin being the target of Russian attempts to sow division, dissension, and doubt\nwithin democracy. Nor were we the first target. Former Soviet republics,\nformer Warsaw Pact nations, and NATO allies across Europe have been similarly\nattacked.\n\nTo act on that principle of mutual defense of democracy by democracies, the\nUnited States should make gathering information about such activities a high-\nlevel intelligence collection requirement. As suggested by Laura Rosenberger,\na center within the U.S. intelligence community should fuse intelligence and\nanalysis, drawing heavily on so-called open-source (not secret) sources. Then\nwe should share what we know with the foreign targets and with the public.\n\nIn addition to sharing intelligence, we should be part of a forum of\ndemocracies that shares best practices, other resources, and training to help\none another identify, prevent, and counter foreign attempts to undermine our\ndemocratic processes and institutions. This kind of mutual aid and learning\nshould take place both at the government-to-government level and at the\npolitical-party-to-political-party level.\n\nThat alliance of democracies should also pledge to engage in collective\nsanctions against the individuals, the organizations (we are talking about\nyou, GRU), and the governments that engage in subversion of democracies.\nSanctions are far more likely to have impact if they are collective,\nsimultaneously applied, and enforced by many nations.\n\nOne of the old saws in cyber-policy discussion is whether it will take a\n“cyber Pearl Harbor” to get America to do the right things on cybersecurity,\nor whether there could ever be such a thing as a “cyber Pearl Harbor” to begin\nwith. Well, we had one. It took place in 2016 when the Russian military\nengaged in cyberattacks, _disinformatia_ , and other techniques to attack the\nmost precious thing we have as a country, our democracy.\n\nEric Rosenbach thinks something like it, maybe even worse, could happen again.\n“It’s not going to look like Pearl Harbor or 9/11. The big cyberattack is\ngoing to be something that undermines our democracy in a way that leads\nAmericans to question the viability of our system,” he told us. “It’s going to\nbe something that’s much quieter than explosive, but it’s really going to\nhurt.”\n\nThe attack on Pearl Harbor in 1941 really hurt, but in 1942 America came\nroaring back against the threat. It’s time to realize that what has happened\nwith a foreign military attacking our democracy in 2016 is just as\nsignificant, and requires the same kind of national unity and resolve in\nresponse. That unity has not happened yet, but it should, and still could.\n\n\n# PART V\n\n# THE (NEAR) FUTURE IN CYBERSPACE\n\n\n## Chapter 15\n\n## REAL AND ARTIFICIAL INTELLIGENCE\n\nWhoever becomes the leader [in AI] will become the ruler of the world.\n\n—VLADIMIR PUTIN\n\nWe headed for the Eiffel Tower to see the future of cyberspace. It was a hot\nAugust day in 2016, and we were not in Paris, but in the Paris Hotel and\nCasino, with its replica of the Eiffel Tower, in Las Vegas. After a briefing\nin a small white-and-gold ballroom meant to be reminiscent of eighteenth-\ncentury Versailles, we were ushered into a hall next door, a vast twenty-\nfirst-century space filled with computer racks and purple lights. We had one\nquestion in mind: Was artificial intelligence (AI) the revolutionary tool that\nwould finally give cyber defense the advantage?\n\nWe will return to Las Vegas in a bit, but first let’s put in perspective the\nintroduction of AI into cyber-war. The ongoing low-grade cyber wars around the\nworld are not static. Both offense and defense are forever developing tools\nor, as in the case of AI, entirely new classes of weapons. Having new\ntechnologies hit the battlefield during a period of conflict is not unusual.\n\nDuring World War II, warring nations spent six years engaged in the most\ndestructive campaigns in human history, killing millions and wiping out\nhundreds of cities. They did so with technology such as tanks and bomber\naircraft that had evolved significantly since they were introduced, when the\nnations involved had engaged in the same kind of mass folly in Europe only\ntwenty years earlier.\n\nThose evolved weapons were far more destructive the second time around, but\nthey were merely more advanced versions of the same kinds of technologies that\nhad emerged in the Great War. While WWII was going on, however, some of the\nparticipants were engaged in frantic work back in the labs. The Germans made\nadvances in rockets and weaponized them, creating ballistic missiles (the V-2)\nthat were impervious to air defenses and could destroy entire city blocks. The\nAmericans, with considerable help from immigrant European scholars, invented\nnuclear weapons. The Americans had been using large formations of B-29\nSuperfortress aircraft to drop thousands of conventional explosive bombs on\nJapanese cities. They then used one B-29, dropping only one bomb, to\nobliterate an entire city. A few days later, they did it again.\n\nNuclear weapons are a technology and have an outcome that is so qualitatively\nand quantitatively different from any weapon ever employed before that experts\nagreed that they created an entirely new era in war. They also created a form\nof peace. Almost seventy-five years after the first two nuclear weapons were\nused, no further nuclear combat detonations have occurred. The weapons are,\nhowever, used every day to deter and prevent certain kinds of warfare.\nSignificant diplomatic and intelligence agency efforts have been expended\ntrying to prevent other nations from acquiring nuclear weapons, but eight\nnations followed the Americans in successfully acquiring them, at considerable\nfinancial cost.\n\nJust as nuclear weapons were developed during the war, AI and quantum cyber\nweapons are being developed during the present period of cyber hostilities.\nThe more important historical similarity at work here, however, is that the\nqualitative and quantitative changes in cyber warfare that these two new\nclasses of weapons can bring about could be as significant as the difference\nbetween what one conventional bomb dropped by a single B-29 aircraft could do\ncompared with what one nuclear weapon dropped from that same aircraft actually\ndid.\n\nThat may seem like hyperbole, especially given what AI has been used to do\nthus far in cybersecurity, but the use of AI in cyber war has barely started,\nand quantum capabilities have yet to be employed at all in the cybersecurity\nrealm. Moreover, few analysts have begun to examine what the combination of\nthe two new technologies could bring to the effort to secure cyberspace.\n\nBoth AI and quantum have been the subject of a lot of hype, venture-capital\ninvestment, and fearmongering about an arms race of sorts with China. So, in\nthis and the next chapter we are going to explore these two new computer\nscience technologies and specifically what they mean to cyber war.\n\n### The Reality of the Artificial\n\nWhen Vladimir Putin told an audience of Russian students in September 2017,\n“Whoever becomes the leader [in AI] will become the ruler of the world,” he\nsounded a bit like a pseudo-technologist McKinsey consultant. China’s\nPresident Xi seems to agree with Putin, however, because China has set a\nnational goal of being the dominant country in AI by 2030. These and other\nstatements kicked off a round of punditry focused on the new “arms race in\nAI,” and what America must do to win it.\n\nIn the nonmilitary, nonsecurity arena, America seems to be doing quite well\ndeploying AI. It is already widely in use in fields as diverse as banking and\nfinance, logistics, advertising, and even medicine. To see what AI means for\ncybersecurity, we are going to take a bit of a digression to discuss the AI\nfield in general, beginning by defining what we mean by the term. It is often\nthe case in the field of information technology generally, and in the subset\nof IT that is cybersecurity specifically, that terms are thrown around loosely\nand commonly utilized definitions are hard to find.\n\nBuzzword bingo is a common parlor game in cybersecurity. At least since 2012\nat cybersecurity conferences, such as the huge RSA convention, the term “AI”\nhas been used with wanton abandon and imprecision. AI, it would seem, is like\nbacon: it makes everything taste better. Thus, it is now alleged to be\nincorporated in many cybersecurity products. The frequent use and misuse of\nthe term “AI,” and especially of the subsets of AI, can be confusing,\nespecially to policy wonks.\n\nHistorians point to the 1956 Dartmouth Summer Research Project on Artificial\nIntelligence as the birthplace of AI, a meeting at which computer scientists\nagreed that it could be possible someday to have computational machines do\nthings that hitherto had only been done by humans. AI was, thus, originally\nmeant to be the simulation by machines of certain human cerebral activity.\nMany of the current uses of AI are still, in fact, attempts to have machines\ndo things that humans do. What is important for us, however, is that AI has\nmoved on to do things that no individual human could do, indeed what even\ngroups of highly trained humans could not reliably do in any reasonable amount\nof time.\n\nUsing AI, machines can now have meaningful visual capacity, so-called computer\nvision. They can see things by translating images into code and classifying or\nidentifying what appears in the image or video. Cars can now see other cars,\nview and understand certain traffic signs, and use the knowledge they gain\nfrom their visual capacity to make and implement decisions such as braking to\navoid an accident. AI can “see” someone doing something on a digital video\nfeed and recognize that the action requires an alarm: a package has been left\nunattended on a train platform, alert a guard. AI can “see” a face and,\nperhaps, recognize and associate it with a name, and maybe even correlate it\nwith a police be-on-the-lookout (BOLO) notice. These types of facial\nrecognition systems have been deployed in concert with CCTV systems in China\non a massive scale in order to apprehend wanted persons with unparalleled\nspeed.\n\nOf course, many life-forms have visual capacity, so AI is not doing something\nuniquely human when it sees things and reacts to them, but humans were unique\nin their ability to engage in speech and conversation with other humans, until\nAI. Now machines can speak, not merely playing back recorded messages, but\nthinking about what it is appropriate to say in a context and then doing so.\nMoreover, they can then react to what is spoken back at them by a human, and\nsometimes, within the limits of their programming, even do so with an\nappropriate and humanlike response. (If you are thinking about Siri and its\nlimitations, be assured that there are far more powerful programs working\ntoday in research labs.)\n\nAI is also being used to allow machines to walk and perform other movements,\nidentifying what is an obstacle and determining what to do to get around it.\nMachines created by Boston Dynamics have demonstrated remarkable dexterity\nusing AI programs to guide their decision making as they traverse real-world\nobstacles outside the laboratory.\n\nThe field of AI gained greatest acceptance in the corporate world when it\nbegan processing the sea of data that the rest of information technology was\nproducing. The subset of AI that is data mining proved that software could far\nexceed human capabilities. It could sift through great volumes of data in\nseconds to find what a large team of humans would have taken weeks to do.\nMoreover, it could read and correlate data from multiple databases, each\nformatted in a different way. Advanced forms of data mining could look at and\npull information from both structured data, such as organized databases or\nMicrosoft Excel spreadsheets, and unstructured data, such as a photograph,\naudio recording, or text document.\n\nThe smarter cousin of data mining and the most powerful type of AI is machine\nlearning (ML). ML applications began with categorization. Computer scientists\ninput data with labels assigning inputs to one category or another: this is a\ndog, this is a cat. The software “learned” what the distinctions were in the\ndata that led to the labels, and was then able to do the sorting itself\nwithout them. This form of ML that requires training the application is called\nsupervised learning _._ Other ML applications can sift through oceans of data\nand detect commonalities and patterns without being told what to look for.\nThis unsupervised learning actually does somewhat simulate human learning and\nthought, most of which comes down to noting differences and patterns.\n\nWithin ML (got those acronyms now?) are two other subsets, deeper levels,\nliterally, of machine learning. The first is what is called an artificial\nneural network. ANNs somewhat simulate in software design the way human\ncerebral wiring is structured, the way neurons interact with other neurons to\nsend messages with charges of varying strength to cause thoughts within the\nhuman brain or to cause body parts to take actions. ANNs can adjust their own\n“wiring” and weighting based upon patterns in data, in order to improve\nthemselves and their predictive abilities. For instance, an ANN that\nclassifies pictures of cats or dogs will, over time, learn the distinguishing\nfactors of the two types of animals and adjust its “wiring” so that its cat or\ndog predictions are more accurate. The second type of ML you will also hear\nabout is deep learning, which is in turn a type of ANN that uses multiple\nlayers of “neurons” to analyze data, allowing it to perform very complex\nanalysis. Enough with the definitions. What can AI do defensively or\noffensively in security and warfare?\n\n### Artificially Intelligent About Security? AI/ML for the Defense\n\nOn a large corporate network today, there are between three and six dozen\nseparate cybersecurity software applications in use, each contributing to the\nsecurity of the overall network in a specific capacity. Pity the poor chief\ninformation security officer, who has to make the best-of-breed selection for\neach of those dozens of tools and then integrate them. She will likely select\nproducts from more than twenty different vendor companies. In the last three\nyears, many of those vendors have claimed that they have woven AI into their\nproducts, and in fact many have done so to one degree or another. This trend\ntoward AI-enabled, single-function, or “one-trick” security applications is\none of the reasons that the balance is shifting away from offense and toward\ndefense.\n\nThe most widely deployed cybersecurity products incorporating AI today are\nendpoint protection systems. In fact, this kind of software has begun to\nreplace the traditional antivirus software packages, which were the first\ncybersecurity products in widespread use beginning thirty years ago. Unlike\ntraditional antivirus or intrusion detection systems, which check network\npackets against “known bad” signatures (a blacklist approach), the endpoint\nprotection systems using AI ask whether the user is trying to do something\nthey have never done before. Is the activity unneeded or even unauthorized for\nthe user’s role? Would the activity being attempted damage the network or\nsecurity safeguards on the network? These products are learning patterns,\nrather than applying blacklists, and modifying their behavior as they learn.\nThis software learns not just from what it sees on its endpoint, not just from\nwhat happens on other endpoints on the network, but, in a classic example of\nMetcalfe’s law, they learn from every endpoint on every network on which they\nare deployed.\n\nA second widespread use of AI today is in applications known as vulnerability\nmanagers. AI can intake machine-readable intelligence reports on new threats\nand can automatically prioritize those threats based upon what it already\nknows or can quickly find out about your network. For example, an AI-driven\nvulnerability manager could check to see whether you have already addressed\nthe weakness the new attack exploits. Have you installed a patch from the\nsoftware manufacturer, or is the newly reported exploit attacking something\nyou have not yet fixed on your network?\n\nA third use of AI/ML is in cybersecurity software products known as identity\nand access management (IAM) and privileged access management (PAM)_._ The\nsoftware determines if the user is who they claim to be by checking multiple\ndatabases simultaneously. The AI would ask: Where physically in the real world\nis the user? Did the user already badge out of the building? Does travel data\nshow that the user is not in the building, but actually in London today? Is\nthe user originating on the appropriate computer? Is the user accessing\napplications and databases they normally use? Is the user attempting to do\nsomething with the data that is unusual, such as encrypting it, compressing\nit, downloading it, or transmitting it to an inappropriate destination? Are\nthe mouse movements and stylistic keyboard usage of the actor consistent with\ntheir previous patterns? Or is the user acting too quickly and smoothly, like\na bot?\n\nThe answer to those questions is not binary; rather, each of them is likely to\nproduce a score relative to the confidence that the AI has in each answer\nbased upon what data is available and how accurate it has been in the past.\nThe combination of the weighted scores from the several questions asked will\nresult in a decision, and the user will be allowed in, kept out, permitted\nonly to perform limited functions, asked for further proof of identity, or\nplaced under ongoing observation.\n\nWhen conventional security software does detect possible malicious activity,\nit sends a message to a security-monitoring console being watched by a human.\nUnfortunately, today in most corporate or government networks, alarm messages\nare coming into security monitoring systems at such a high rate that triage\nmust be performed by the human(s) in a security operations center, or SOC.\n\nThe humans might get distracted in ways any of us do at work, eating, nodding\noff, visiting a bathroom, or texting with a partner. AI, however, is always\non, continuously at the same level of attentiveness. AI could prioritize\nthreats for itself, or for the humans in the SOC. If trusted and authorized by\nthe network owner to do so, AI could take action to block malicious activity,\nor to delay execution of a dubious command until a responsible human can\nreview it.\n\nThus, there was a lot of hope for the new companies that rushed into the\nmarket claiming to be using AI to stop cyberattacks. When NSA Director Keith\nAlexander retired from the military, he quickly started an AI cybersecurity\nfirm, IronNet, and gained more than $100 million in backing. A British firm,\nDarktrace, claimed its ML software could learn about an attack while it was\nongoing and alert network operators. Darktrace soon became a “unicorn,” a\ncompany worth more than a billion dollars. Critics of IronNet and Darktrace\nclaimed that the AI actually still needed a lot of human assistance.\n\nIndeed, no cybersecurity firm has at this time deployed what we envision as\nthe full promise of AI/ML, what we call the Network Master, the one AI to rule\nthem all. A Network Master AI/ML program could correlate billions of actions\non tens of thousands of machines over weeks of activity, drawing on all the\ndata logs from the dozens of security software programs and network management\nsystems. Within milliseconds of coming to a conclusion based on correlating\nscores of diverse data sources, the Network Master could quarantine suspicious\nactivity, create honeypots, modify firewall rules, increase authentication\nrequirements, isolate subnets, or even in an extreme emergency disconnect the\ncorporate network from the internet. Such capacity does not yet exist.\n\nIf all of that sounds like AI could give the defender the decisive upper hand\nin dealing with cyberattacks, the reality is that we are not yet there. Yes,\nsome previously existing one-trick security applications like those mentioned\nabove have added AI/ML techniques and are now better at some specific tasks.\nHowever, the ML that runs the network, spotting and swatting attacks that no\nhuman would detect, is not yet a reality for a variety of technical and\nprocedural reasons.\n\nFor example, AI/ML works best when it has a lot of data to analyze,\nparticularly when that data is in a variety of databases and formats. Then\nAI/ML can do what humans manifestly can’t do, quickly cross-correlate billions\nof seemingly unrelated pieces of information to infer a conclusion. For most\nAI/ML programs to work well, that data all needs to be swimming in the same\nplace, in what big corporations call their data lake. It seldom is. It’s\nscattered. Or sometimes it is not even collected or stored, or not stored for\nvery long, or not stored in the right format. Then it has to be converted into\na usable format through what data scientists politely call “manicuring” (and\nbehind the scenes call “data mangling”) for the AI/ML engine to perform its\nwork.\n\nCapturing all the data and storing it for six weeks or more to catch the “low-\nand-slow” attacks (ones that take each step in the attack days or weeks apart\nso as not to be noticed) would be a very expensive proposition for any\ncompany. Only the wealthy _and_ highly risk-averse corporations would do that.\nIn our discussions with network operators at major corporations, we have found\nthat very few have such vast and complete data lakes readily accessible.\n\nMost network operators do not yet trust AI/ML programs to wander around their\nlive databases. Maybe their fears are irrational, but they are real. How do\nthey know if that semi-sentient ML program is going to morph its software and\nthen do something it has not done before, like wipe software off a server or\ndisconnect a key router from the network? While such nightmares have never\nhappened, there is always a first time, and what paranoid network security\nofficer is going to take that risk?\n\nIf, however, instead of allowing access to your live database, you only permit\nthe database to rummage on a near real-time basis, that may mean that you have\nto replicate your vast data lake at considerable expense by adding many\nphysical or cloud servers. If you do that, the AI/ML cannot really tell you\nabout a live security event, only about something that happened before you\nmirrored the databases. Even then, while ML programs are learning, they are\noften returning so many false positive alarms themselves that they are\nactually making the monitoring problem worse for all the humans watching panes\nof glass in the SOC.\n\nFor a real Network Master to be created two conditions are necessary, beyond\nthe enormous software challenges. First, someone or some group would have to\nbe willing to fund the development. Most venture-capital or private-equity\nfirms would not normally be willing to place a bet on that kind of\ndevelopment. It will likely require a well-heeled tech company willing to fund\na “moon shot,” or possibly a government agency willing to sponsor and fund it.\nSecond, after the AI/ML had been proven on simulated networks, it would\nrequire a large network whose owner-operator was willing to be the first mover\nto employ it on a live network. It is difficult to imagine who that might be.\n\nIf (and as you can see it is a big IF) those problems can be overcome, AI/ML\ncould make it very difficult for today’s attackers to succeed. Meanwhile,\nhowever, today’s bad guys are not standing still. They are also playing around\nwith AI/ML. Of course they are.\n\n### Weaponizing Nonhuman Sentience? AI/ML on the Offense\n\nWhen most people think about AI, they’re not thinking about cybersecurity.\nThey’re thinking about killer robots. Given all of the existing applications\nof AI that are in everyday use behind the scenes doing good things (such as\ninstantly making a decision on whether a credit-card purchase made online is\nactually fraud), it is disappointing to data scientists that when (and if) the\naverage citizen thinks about artificial intelligence, the Terminator comes to\nmind. Many people have already internalized the idea of weaponized AI, even\nthough the kind of thing they fear does not really exist except in some\nexperimental Russian programs.\n\nIn the field of kinetic war, the Russians, the Chinese, and the Pentagon do\nseem to have a fascination with semi-sentient swarms of fire-and-forget drones\nthat could fly around, talk to one another, decide on what things look like\ntargets, divide up which drone would go after what target, and so forth. Think\nof a bunch of smart, angry hornets, then give them explosives. A DoD directive\nbans autonomous weapons that would use AI to determine on their own if\nsomething or someone should be attacked. There still must be a human in the\nloop authorizing a weapon to attempt a kill. While that is mildly comforting,\nwith a few keystrokes, autonomous killing AI software not used in peacetime\nmight be activated on a drone or missile in wartime. In a shooting war with a\nnear peer, it would be hard to resist such a tool, especially if the opponent\nwere the first to use autonomous AI weapons to find, swarm, and kill.\n\nAll of those fears involve drones and kinetic kills in the physical world in\nthe future, but for cybersecurity experts, the reality is more immediate. The\nsame kind of defensive AI/ML software we discussed above can be used in a\nslightly modified way to perform a cyberattack on a network.\n\nCyber criminals and malicious actors are no longer, if they ever were, the\narchetypical acne-plagued boys alone in their parents’ basement hacking for\nfun and profit on a Red Bull–induced, pizza-fueled jag. Malicious actors in\ncyberspace today can be military or intelligence officers or well-funded\ncriminals. Both types are staffed and supported by computer science graduates\nwith advanced degrees and AI/ML proficiency. The criminals can afford the\nhighly qualified help because cybercrime pays, and it pays well.\n\nUsing AI/ML on the offensive is not just theoretical. In August 2016, DARPA,\nthe Defense Department’s Advanced Research Projects Agency, commissioned six\nteams from universities to develop attack AI programs to attempt to break into\nand steal information from a highly defended network, with no human in the\nloop after the attacks were launched. The teams convened at the Paris Hotel\nand Casino in Las Vegas. So, back to our visit to Vegas.\n\nAfter DARPA Director Regina Dugan explained the competition to a select group\nof observers, and us, we all walked into a vast event space, with six stacks\nof servers on a stage. On signal, the competing teams launched their attack\nmachines and then walked away. For hours there was no human participating in\nor overseeing their activity. The AI/ML software programs scanned the defended\nnetwork for faults and defenses, learning and trying tools and techniques to\nbreak in until they succeeded, then climbing up through layers of protection\nsoftware, acting on their own, until they captured the flag (the data they\nsought), and exfiltrated it back to their own computers.\n\nIf you had been there expecting to see something dramatic happen, the DARPA\nevent was somewhat anticlimactic. The servers just sat there and blinked at\nus. Their fans whirred softly. For hours. Finally, the DARPA judges announced\nthat the attack AI software created by the team from Carnegie Mellon\nUniversity had broken through all the defenses and extracted the target data.\nWe celebrated their win at one of the casino bars and concluded there were not\nmany networks that could have successfully defended against that CMU attack\nbot. We said to each other then that we had just seen the future. Well, that\nfuture is now.\n\nComputer scientists at Cornell University showed in a 2017 paper that one\ncould use a “generative adversarial network” to fool other software defending\nagainst attacks (in other words, software that creates an attack AI perfectly\nsuited to beat the defensive software it is up against). At the Black Hat\ncybersecurity conference in 2018, also in Las Vegas, an IBM team demonstrated\nan AI attack program called DeepLocker. As they described it, DeepLocker is a\nhighly targeted and evasive malware powered by AI, which is trained to reason\nabout its environment and is able to unleash its malicious behavior only when\nit recognizes its target. DeepLocker learns to recognize a specific target,\nconcealing its attack payload in benign carrier applications until the\nintended target is identified.\n\nIn other words, like the fire-and-forget killer drones that would fly around\nuntil they saw something that looked like the kind of target they were\nsupposed to blow up, DeepLocker would scan the internet looking for the kinds\nof networks it was supposed to attack. DeepLocker would do so in a camouflaged\nmanner, perhaps while looking like a legitimate service used by the internet\nservice provider. Then, DeepLocker would adaptively use multiple attack tools\nand techniques, learning about the defenses in use, until it got in.\n\nIt occurred to us that what IBM was showing off to the public in Vegas was\nprobably something like what the United States and some other governments had\nalready come up with on their own, and probably already used. Indicators of\nwhat may be happening behind closed doors often come from what cybersecurity\nexperts not involved in classified programs are discussing publicly.\n\nFor example, an expert at the cybersecurity firm Endgame has publicly\ndemonstrated how offensive AI can be used to “poison” defensive AI software by\nessentially fooling the defensive technology engaged in the learning phases of\nML. Think of it this way: ML could be fooled by creating a flood of false\npositive alarms, which could cause the detection system to disregard a type of\nattack. Then the real attack, looking sufficiently like the false positive,\ncould be launched successfully.\n\nAlternatively, defensive systems could be attacked repeatedly and, after each\ntime the attack was defeated, AI could alter the attack a little and try\nagain. In that way, the attacker could persistently change its signature just\nenough so that it no longer matched what the defense was looking to block, but\nit would have sufficient functionality for the attack package to remain\neffective. Hackers have been doing this manually, testing their attack tools\nagainst antivirus software, but AI/ML would do this so much faster and more\neffectively.\n\nHackers have a big data problem too: lots of personally identifiable\ninformation stolen from hundreds of companies. An expert at McAfee has\npublicly discussed how AI could be used to plow through the troves of data\nthat hackers have already stolen from numerous databases. Data in only one\ndatabase may not be sufficient for the hacker to successfully impersonate you,\nbut by using AI, they could scan multiple databases they had hacked and\ncompile a sufficient amount of information to successfully impersonate your\nonline identity. Maybe they have discovered your password on one website, and\nthen they use the same password successfully to get into a secure network,\npretending to be you, because you made the mistake of using the same password\non multiple applications. You don’t do that, do you?\n\n### Neglected Defensive Potential\n\nIn the next three to five years, we are likely to see continued growth in the\nuse of AI/ML as a part of applications that will do specific defensive tasks\nbetter than they are now being done. AI/ML use will become more sophisticated\nin one-trick security applications doing identity and access management,\nprivileged access management, endpoint protection, and vulnerability scanning.\nSome vendors will incorporate the technology into their defensive applications\nmore successfully than others. Already companies like Illumio are beginning to\napply AI/ML to assist in network management orchestration. Some network\noperators will buy the better products, others will fall for flawed defensive\napplications, and some will neglect to buy cybersecurity products\nincorporating AI/ML technology altogether. Many cyber vendors will claim that\nthey have an AI/ML application that will do everything, but they will be, to\nput it kindly, exaggerating.\n\nThe Network Master controller AI/ML for cybersecurity is unlikely to emerge\nsoon for the reasons we have discussed. A time frame of three to six years\nfrom now is more likely. On the other hand, AI/ML for the offense, something\nlike the weaponization of the 2016 DARPA Grand Challenge, is probably already\nin use to some degree and is likely to grow steadily in its application by a\nsmall set of nation-state actors. If recent history is any guide, such\ntechnology will eventually make its way into the hands of the second-tier\nnations and to nonstate actors. This second tier of players may not use AI/ML\nattack tools in as sophisticated ways as the U.S. and Chinese governments\nwill, but AI/ML will still make them much more capable of successful attacks\nthan they are currently.\n\nOn balance, in the near term the growing use of AI/ML in defensive software is\nlikely to increase the ability of the defenders, unless they are being\nattacked by a sophisticated and determined state actor using AI/ML\noffensively.\n\n\n## Chapter 16\n\n## A QUANTUM OF SOLACE FOR SECURITY\n\nThose who are not shocked when they first come across quantum theory cannot\npossibly have understood it.\n\n—NIELS BOHR\n\nHe just wanted to keep on wrestling. Growing up on a farm in the vast open\nspaces of Saskatchewan, Chad Rigetti assumed that after high school he would\nbe the fifth generation working the family farm. That’s what Rigettis did.\nEven the farms adjacent to his father’s property were owned and operated by\nother Rigettis. With high school coming to an end, however, Chad assumed he\nwould no longer be on a wrestling team. He had not even thought of going to\ncollege until he was recruited by the wrestling coach from the University of\nRegina. He agreed to go to college because it meant he could continue\nwrestling for four years. He didn’t know that going to college also meant he\nwould end up wrestling with qubits.\n\nIn the international race for quantum supremacy, there are at least four major\nU.S. contestants. Three are well-recognized tech giants Google, IBM, and\nMicrosoft. The fourth company is Rigetti, a start-up based in a dingy\nwarehouse district in Berkeley, California.\n\nWhile most Americans, and even more readers of this book, have given little to\nno thought to quantum physics and computing, their relevance to cybersecurity\nmeans that we would all do well to understand them better. Simply put, quantum\ncomputers will soon be able to solve complex problems that no conventional\ncomputer has ever been able to. You cannot think about the future of cyber war\nwithout understanding the momentous changes that are about to happen to\ncomputing and IT in general, as well as cybersecurity specifically, with the\nadvent of quantum computing.\n\nBefore we went to Berkeley, we brushed up on quantum physics, and before we\ntalk here about the effect quantum computing may have on cybersecurity, we\nneed first to take a deep dive to understand quantum in general. It is a dive\nto the lowest, tiniest level of existence, the quantum level. It is the level\nat which, we think, particles cannot be further subdivided into smaller\nthings.\n\n### Comprehending the Incomprehensible, and Why It Matters to Cyber\n\nThe first discussion of quantum computing and its cybersecurity implications\never held in the White House may have been the meeting Dick Clarke convened in\n1999. Back then, he asked experts from the NSA and the University of Maryland\nto begin by explaining how a quantum computer would work. Unfortunately, they\nbegan, as many quantum physicists do, by talking about Schrödinger’s cat\n(which is both dead and alive simultaneously). If you are new to quantum, we\nadvise you to avoid that analogy, which we find usually confuses people more\nthan it helps explain the quantum phenomenon.\n\nWe find it more useful to begin by cautioning the newcomer to quantum that the\nlaws of physics that you know, or have implicitly grasped by observation, do\nnot apply at the level of the smallest elements of matter. Once we know or are\ntold about the way things work at the very tiny quantum level, most of us\nintuitively reject it. It just does not make sense.\n\nTo overcome your cognitive bias to what we are about to discuss, think about\nDick’s grandparents or Rob’s great-grandparents, people born in the nineteenth\ncentury. If they were brought back to life with the knowledge they had as\nteenagers and were shown an Airbus A380, a metal object weighing six hundred\ntons, they would not believe for a second that it could fly. If they then saw\nit fly, they would think it was magic. Nothing about a six-hundred-ton metal\nobject traveling at five hundred miles an hour seven miles up in the air would\nmake any sense to them.\n\nTruthfully, most of us do not really understand the physics behind what makes\nthat A380 fly. Maybe some of us heard something about a guy named Bernoulli,\nbut we accept that the aircraft flies. We know it is real, it happens, and it\nis not magic. Well, treat quantum computing the same way. A century from now\nit will be as broadly accepted as a real phenomenon as flight is today.\n\nWhat is so mind bending about quantum physics? Well, let’s focus on two\nproperties of the really small objects at the atomic level. First,\nobservation: Matter at the atomic level (electrons, photons) may be either a\nparticle or a wave, but in experiments like the famous double-slit experiment\n(see the endnote and watch the video), which form they take (wave or particle)\nis dictated by whether or not they are observed in motion by a measuring\nsystem, such as a camera or a particle detector.\n\nDoes the quantum matter somehow “know” that it is being observed? Probably\nnot. There are a variety of theoretical explanations, but the experiments do\nmake it seem that the matter knows when it is being watched, and there is no\nsatisfying explanation in classical physics for the behavior.\n\nThe qubit, the quantum bit, is not actually in one state, such as positive or\nnegative. It is in all possible positions or values until it is acted upon by\nobservation. This state of “being about to be” in one position or another is\ncalled superposition.\n\nThe second unusual phenomenon occurring at the qubit level is entanglement.\nWhen a particle, for example a photon shot by a laser through a crystal, is\nsplit in two, or in some other way two qubits are made to be related, the two\nquantum particles are said to be entangled. When they are thereafter modified,\nwhatever is done to one causes the other to change in the same manner\ninstantly. The weirdness comes in when you realize that this “change one, the\nother instantly changes” phenomenon occurs even when the two particles are\nsignificantly separated in distance. No one really knows how this happens, but\nrepeated laboratory experiments over many years have demonstrated that it\ndoes. The separation distance can be quite immense, as a 2017 experiment\nproved.\n\nIn the experiment, Chinese scientists created two entangled photons on a\nsatellite in space and then shot them via laser, one photon to each of two\nground locations 748 miles apart. Then, once on the ground, when the polarity\nof one of the photons was modified, the other one simultaneously changed. In\nwhat might be called an understatement, the Chinese scientists said of their\ntest, “The result again confirms the nonlocal feature of entanglement and\nexcludes the models of reality that rest on the notions of locality and\nrealism.” Yeah, so much for that model of reality that rests on realism, we\nnever liked it anyhow.\n\nEinstein famously called entanglement “spooky action at a distance.”\nScientists still debate why and how it happens, but no longer argue that it\ndoes occur. Some physicists think it opens the door for new methods of\ncommunication. The more visionary, or perhaps imaginative, believe it could be\nthe basis of a future system of teleportation, but don’t plan on that\nhappening in time to ease your commute. What it does in 2019 is open up new\ncomputing possibilities.\n\nIn standard computers, electrical signals open or close gates, making an\nelectron into a signal or “bit” that is either a 1 or a 0. This is why it is\ncalled a binary system. It has to be in one of two states. Everything in your\ncomputer is based on that principle, lots of little 1 or 0 signals happening\ndown in the computer chip. Because in conventional computers the electrons\nhave only those two possible states, 1 or 0, it takes a large number of bits\nto encode a piece of data. For example, the letter _m_ is expressed as\n01101101, and the word “Hello” is 01001000 01100101 01101100 01101100\n01101111. That’s a lot of digits just to say hello.\n\nEach qubit, such as those made from electrons, ions, or photons, has multiple\npotential values (not just 1 or 0) simultaneously, based on such\ncharacteristics as their spin or polarity. Herein lies the revolutionary\nadvantage. With a few qubits, much more information could be encoded. Each\nadded qubit doubles the capacity of encoded information. If one qubit encodes\ntwo values, two encodes four, three encodes eight, four encodes sixteen. By\nthe time you have sixty-four qubits you can encode the equivalent of more than\na million terabytes of classical computer data. The traditional way of\nexplaining great volumes of data to laymen is to say that the entire U.S.\nLibrary of Congress is about fifteen terabytes, and a copy of all the books in\nthe world would be about sixty terabytes. So, sixty-four qubits would be the\nequivalent of, well, a lot more books than actually exist.\n\nChad Rigetti is shooting for 128 qubits on his machine in 2019, and may have\ndone so by the time you got around to reading this book. That would be a\ndevice that could encode more than all the data that moved on the internet\nglobally in a year, and then could process that data in some desired way.\n\nSince each qubit can have multiple values at the same time, a quantum computer\nexploiting that odd phenomenon can process data using all of the possible\nvalues for each of its qubits almost simultaneously. Conversely, classical\ncomputers are sequential; they proceed in serial fashion. Something a quantum\ncomputer could do in a second might take a classical computer four centuries.\nIf you had begun crunching a hard mathematical problem when the first\noperational computer, ENIAC, started on the Penn campus in 1946, and if ENIAC\nalways had the capacity of a modern scientific computer, it would still need\nabout another 330 years to complete what a 128-qubit device could do in a\nsecond. Quantum computers with 128 qubits will soon be able to solve math\nproblems that no conventional computer has ever been able to. That will enable\nthem to break codes, design new materials, develop new drugs, and perhaps to\nsimulate the human brain.\n\nGetting the idea now? When a quantum computer works with three hundred qubits,\nit will have capabilities that exceed the computational requirements of any\nproblem known today. “The most exciting applications of that kind of computing\nwill be things we haven’t even dreamed of yet,” Rigetti gushed to us. Buckle\nup.\n\n### The Struggle to Get Quantum Working\n\nThe key words in the last paragraph were “when a quantum computer works.”\nConsensus hasn’t prevailed on whether anyone has really got one running in a\npractical sense yet. What experts agree on is that some people are simulating\nwhat a quantum computer would do, some people are using quantum principles in\nspecialized devices, and others have experimental systems running. The\nexperimental systems, however, still have a lot of problems.\n\nThe 1s and 0s of classical computing are easily generated with electrical\npulses moving in silicon. Qubits are much more difficult to create. Doing so\nusually requires a lot of equipment to chill the quantum computer close to\nabsolute zero. Although a lot of work is going into quantum chipsets that work\nat room temperature, most quantum computers, such as Google’s and IBM’s, still\nlook like some sort of Rube Goldberg science fair project or a 1950s science\nfiction movie set in an evil genius’s lab, with vats of super-cooled gases and\na complete maze of pipes and wires.\n\nThe major obstacle is that qubits, even when created and maintained at\nabsolute zero, do not last very long. They decohere; that is, they lose their\nsuperposition in mere fractions of a second. Interference and noise from the\nenvironment can easily alter the intended state of a qubit. Moreover, thus\nfar, most experimental quantum computers generate results that are, well,\nwrong a lot of the time and have to be modified using classical or\nconventional computers. The race to make practical quantum computers today is\nall about these two problems: decoherence and error correction.\n\nJim Gable and Wil Oxford of Bra-Ket, one of the many smaller start-up\ncompanies in quantum computing, think they are on a path to solving both\nproblems using what they call pure photonics: in other words, light, rather\nthan the electrons and ions in other companies’ approaches. Their goal is to\ncreate quantum computer chips that manipulate single particles of light on\nsilicon, which they believe reduces the error rate, and to maintain coherence\nfor a full second of time.\n\nMaking quantum computing chips using photonics and operating at room\ntemperature is also the approach of Christian Weedbrook of Xanadu, a Canadian\nstart-up. To see such a chip we went to Toronto, where Xanadu is trying to\ncreate this magic in an old textiles building. The room across the corridor\nstill had spindles, but in the quantum lab, Weedbrook was squeezing photons\ninto pathways on chips. We had to look really closely to see the Xanadu\nquantum chip, which was the size of a child’s fingernail, but it was working\nand at room temperature.\n\nXanadu and Bra-Ket are among scores of quantum start-ups. Few are as well\nfunded as Rigetti, which has already gathered $120 million in investment. In\nfact, Rigetti has created what it calls an ecosystem of affiliated start-ups\nso that the company can eventually offer “full stack” capability, from quantum\nchips to cloud computing to an App Store offering quantum software to solve\nspecific kinds of problems. Right now, however, Rigetti is focused on keeping\na qubit alive long enough to be useful and creating software and hardware that\nwill produce low error results.\n\nThe proof that someone has achieved that, at least in an experimental way,\nwill come when they can prove that they have done something no classical\ncomputer has ever done, such as solving for a hitherto unsolvable mathematical\nequation. You can probably find a Vegas bookie who will take your bet on when\nthat event, called quantum supremacy, will be achieved. In 2017, Google said\nit would achieve quantum supremacy in 2018. In 2018, the company said that it\nwould do it soon, but no longer gave a date. Chad Rigetti told us, “Quantum\ncomputing will take people by surprise. We will get there very fast.”\n\nThe race to quantum supremacy is primarily between the United States and\nChina. The Chinese government has what has been reported as a billion-dollar\ninvestment in quantum computing, including a planned “Quantum Research City.”\nIn 2018, the U.S. Congress _authorized_ a billion-dollar research program,\nthough it has yet to actually _appropriate_ that much money. The governments,\nscientists, and venture capitalists behind the new quantum industry obviously\nthink they are on to something that will be a game changer.\n\nWhoever wins the quantum computing race may be able to create an ecosystem of\nspecialized chips and applications around their standard. Leadership in\nquantum computing is, however, likely to change as often as the front car in a\nFormula 1 race. Although some limited capability may be developed and\nmaintained for a while in secret, real achievements will have to undergo peer\nreview to maximize the potential of breakthroughs in quantum computing.\nNonetheless, many quantum industry experts and national security officials we\ntalked to assume that there are secret quantum computing programs in\ngovernment labs in China, the U.S., and Russia.\n\n### Quantum and The Magic Decoder Ring\n\nWhat sparked governments’ interest in quantum computing was fear, or hope, of\nbreaking secret codes. As they have learned more about it, other possibilities\nhave drawn their attention. If you could easily break encryption,\ncybersecurity would be in much worse shape than it is today. Encryption is not\njust a tool that governments use to transmit secret messages to spies and\nsoldiers. Encryption is ubiquitous, working behind the scenes in our web\nbrowsers, emails, databases, ATMs, and a lot more. Without encryption, it\nwould be almost impossible to defend against hacking successfully. So, should\nwe fear that quantum computing research will endanger cybersecurity?\n\nIf you thought quantum physics is complicated, the mathematics behind modern\nencryption can also quickly leave you in the dust. Again, we are going to\nsimplify. Most encryption codes are based on a mathematical process called\nfactoring: By what whole numbers can another, larger number be divided? So,\nfor the number 12, the factors are 1, 2, 3, 4, 6, and 12. You can do that kind\nof factoring in your head, but it’s a lot harder when the number you are\nfactoring is not just two digits (like the number 12) but, say, hundreds of\ndigits.\n\nMost encryption algorithms utilize factors (prime factors, to be precise) of\nvery large numbers as their basis. The assumption is that, even with a modern\nsupercomputer trying out all the permutations, it could not correctly guess\nthe factors that are being used as the basis for a particular encryption code\nwithout thousands of years of run time. If quantum computers can be made to\nwork, thousands of years’ worth of conventional computing could be done in\nseconds and modern encryption could be cracked.\n\nWith that hope in mind, governments have been rumored for years to be\ncollecting and storing other nations’ encrypted messages that they now cannot\ncrack. Someday, perhaps in the next few years, quantum computing might allow\nChina, Russia, the U.K., or the U.S. to read messages that they intercepted\nyears ago, what you might think of as reading other people’s old mail or\nyesterday’s news. That may prove interesting and maybe even useful in the\nfield of counterintelligence, tracking down spies and their sources. If and\nwhen this happens, don’t expect anyone to announce it. This is one aspect of\nthe quantum computing race where no one is going to claim to be first across\nthe finish line.\n\nAs for cracking encryption codes in use currently, remember that a functioning\nquantum computer, when it appears, will not be generally available any more\nthan a supercomputer is today. No one would argue, however, that\nsupercomputers are unimportant. Indeed, they are necessary for any number of\nimportant uses, including designing nuclear weapons. Quantum computers will be\nowned and operated only by governments and a few large companies. The\ngovernments that have them will be able to use them to revolutionize many\naspects of science and technology, including cybersecurity. If you are not\nworking in those governments or the few companies that will have a functioning\nquantum computer and you want to use one, you will have to access quantum\nmachines in clouds operated by IBM, Google, Microsoft, and probably Rigetti.\nSorry, but they are not going to let you rent time in their quantum cloud to\ndecrypt Citibank’s codes.\n\nMoreover, cryptologists, the mathematicians who live in the abstract world of\ncodes, have seen the threat from quantum computing coming for years now. They\nhave created quantum-resistant coding algorithms, systems of encryption that\nare more complex, some of which use entirely different approaches than long\nnumber factoring. It is a safe assumption that major governments have been\nusing quantum-resistant encryption methods for some time.\n\nIn fact, the U.S. government’s National Institute for Standards (NIST) has\nbeen openly and publicly working with leading academic cryptologists to create\na new quantum-resistant encryption standard that could be used by banks and\nother commercial and private-sector organizations. NIST is hoping to have a\nstandard ready by 2024. Some people think that will be too late.\n\nOne of the new encryption methods being explored actually uses a form of\nquantum computing to transmit secure messages, using quantum to deal with\nquantum. Remember that at the quantum level, things change when you look at\nthem? That quality may make it possible to transmit codes or even the messages\nthemselves in a way that the recipient could be confident that the content was\nnot cracked, observed, or copied (this is referred to as the no-cloning rule).\n\nCompanies, including Hewlett Packard, are trying to commercialize quantum key\ndistribution (QKD), a way to send a “one-time pad,” or single-use code, that\nboth ends of a communication could use to encrypt and decrypt. Such\nsymmetrical codes have in the past been risky because someone could intercept\nand copy the code book. With QKD, sending the pad as quantum photon-based\nmessages eliminates that risk because by definition you know if someone has\nlooked at a piece of quantum code. Unfortunately, thus far, the distance that\nQKD messages, which are made up of photons, can be transmitted is limited by\nthe fact that the energy in a photon fades with time and distance.\n\nIn classical computing, messages made up of photons travel across the country\non fiber-optic cables, but the photons are “boosted” or retransmitted\nrepeatedly on their rapid journey. The method used to boost the photon signals\non the internet backbone today observes and reproduces the photon, and would\nthus break the security of QKD. Solving that problem, being able to transmit\nquantum messages at a distance, is a high research priority, but not one to\nwhich experts are willing to assign a time frame. If someone succeeds at it,\nquantum computing, far from putting an end to encryption, might actually offer\na highly secure method of communication.\n\nIn the meantime, banks and other commercial and private-sector organizations\nare going to have to shift from the encryption systems they use now to\nquantum-resistant systems. Whether that is two years away or ten is a matter\nof debate and conjecture, but there is a role for government to require that\nshift by a certain date through regulation and a new encryption standard.\n\nThink of it as Y2K for encryption: a time when everyone is forced to update\ntheir software to ensure that a hacker with access to a quantum computer\ncannot someday become a problem. It is not a dire or immediate threat quite\nyet, but it will arrive sooner than most realize.\n\n### The Real Promise of Quantum Computing\n\nSo, assuming Chad Rigetti, his giant corporate competitors, or the Chinese can\nget a real quantum computer to operate as more than a science experiment, what\nwill we do with it? Konstantinos Karagiannis of BT has been tracking how\npeople are getting ready to use quantum computers by looking at what software\nthey are writing and what quantum algorithms have been developed. “So far only\ntwo of the sixty quantum algorithms I know of are about encryption,” he told\nus. Many of the nonencryption algorithms are for machine learning, which as\nwe’ve seen has significant implications for cybersecurity.\n\nKaragiannis thinks that “for AI to go to the next step it may need quantum\ncomputing to integrate all of those little AI programs” that are doing single\ntasks on a computer network. Chad Rigetti is excited about the possibility.\n“There is a very deep connection between machine learning and quantum\ncomputing. They could work together in a beautiful and elegant way.”\n\nWhat we discovered is that there is an enormous amount of academic work going\non in anticipation of marrying quantum computing and machine learning. NASA,\nStanford, and Google have come together to create QuAIL, the Quantum and AI\nLaboratory in Palo Alto. Even before there is a real operational quantum\ncomputer, teams at places such as MIT and the University of Toronto are busy\nwriting machine learning applications in the new computer languages developed\nfor quantum.\n\nNow, think back to the previous chapter in which we said AI/ML was adding some\nnice single-function capabilities for network defense, but that no one had yet\nreally done network orchestration and defense in real time without a human in\nthe loop, using a Network Master AI/ML program. Instead, we suggested ML might\nalready be in use as a tool for network attack today.\n\nIf, however, you were to combine a truly operational quantum computer with\nsome specialized ML and orchestration applications for running and defending a\nclassical computer network, it might just be possible to deal with the\nmillions of actions that are simultaneously taking place on a network and its\nperiphery, taking into account all of the data that is in storage about the\nnetwork, factoring in information about what is happening in near real time\nelsewhere in cyberspace, and repairing or writing code on the fly. In short,\nyou might be able to create the “one AI to rule them all” on a network. You\nmight actually be able to defend a network successfully. Or attack one.\n\nHere is where the so-called quantum arms race may be real. If an attack\nalgorithm were written in new quantum code, taking advantage of an operational\nquantum computer’s computational capacity, it might be possible to develop a\ntool that would collect everything that is known about a network, simulate it,\nand find the best way to attack it. Indeed, it could be possible to design a\nseries of optimized attacks for a host of networks and then launch them more\nor less simultaneously, bringing a target nation or group of nations to a\npre–industrial era condition in seconds or minutes.\n\nSuch a crippling attack is probably too difficult for teams of humans to\nexecute today, but an operational quantum computer with bespoke, optimized\nML/quantum programming might be able to do it. Former University of Southern\nCalifornia president C. L. Max Nikias offered the prediction that “whoever\ngets this technology first will be able to cripple traditional defenses and\npower grids and manipulate the global economy.”\n\nThis may have been an overstatement, but given what we know of the tendencies\nof Russia, China, and the U.S. militaries and intelligence services, once they\nrealize what an operational quantum computer could do, it probably will not\ntake them long to start thinking like that. Will they create quantum-powered\nnetwork defense first? Unlikely. Militaries think first of offensive weapons.\nIt’s in their DNA.\n\nAssume for the sake of argument that a functional, operational 128-qubit\nquantum computer will be running by 2020, as Chad Rigetti predicts, and that\ndozens of ML and orchestration applications will be designed for it and\nrunning successfully by 2022. It should be possible by then to try a Network\nMaster AI/ML system to defend a large, complicated network. Maybe that effort\nwould, if funded properly, show progress by 2024, just five years from now.\n\nIn the meantime, people are putting processors in everything and connecting\neverything to networks at an amazing rate. Few of them are thinking about\nsecurity, as we shall see in the next chapter.\n\n\n## Chapter 17\n\n## 5G AND IOT\n\n## Machines Too Dumb to Be Safe\n\n5G will have an impact similar to the introduction of electricity or the car,\naffecting entire economies and benefiting entire societies.\n\n—STEVE MOLLENKOPF, CEO OF QUALCOMM, CES KEYNOTE, JANUARY 6, 2017\n\nDo you live in a city in the United States? If so, sometime in 2019 or more\nlikely in 2020 you may notice something new on your street. Or more\naccurately, several new things may appear. There may be a light gray box\nattached to the streetlight near you. Another such box will be on the lamppost\njust down the street. On the sidewalk there may be what looks like one of\nthose Postal Service relay boxes where the letter carrier picks up the mail to\nbe delivered on her route. The box will not, however, belong to the Postal\nService. It will belong to a “phone company.” When this happens, 5G will have\narrived near you. So too will a new set of cyber risks. The fifth generation\nof mobile telephony technology (5G) will supercharge the Internet of Things\n(IoT), and neither will be secure.\n\nIf Verizon, AT&T, Sprint, and other carriers move ahead with their plans, they\nwill initially spend a quarter trillion dollars dotting U.S. cities with these\nnew 5G transmitters on poles and accompanying electrical transformers in what\nlook like mailboxes. Globally it may cost as much as $5 trillion to install\nthe 5G infrastructure. This is not going to be like when they shifted your\nmobile phone from 3G to 4G. You may not even remember when that happened\nbecause the change in your mobile phone’s capabilities may have seemed slight.\nYou will notice 5G.\n\nYou will actually know about 5G before it shows up on your doorstep. The\n“phone companies” will be spending millions on advertising, telling you about\nthe 5G “revolution.” While most ads about technology revolutions are, to be\npolite, hyperbole, when it comes to 5G the word may be justified. The fifth\ngeneration of mobile telephony technology, 5G, won’t be twice as fast as the\ncurrent 4G. It may be ten times as fast.\n\nWhile 5G is much more capable in many ways than existing technology, on one\nimportant criterion it is actually inferior. 5G waves do not travel very far.\nThat’s why the boxes will be lower and closer to you and, therefore, you will\nsee many more of them than the current, high-up 4G towers.\n\nThose newly ubiquitous boxes will also be able to handle vastly more devices\nsimultaneously. The international 5G standard calls for the ability to support\none million devices in one square kilometer. Devices in your house or\napartment, such as your TV, laptop, or nanny cam, might connect wirelessly\ndirectly to the 5G tower and, thereby, to the internet. The same thing may\nhappen in your office building, where elevators, vending machines,\nsurveillance cameras, printers, and copiers may all link directly. Just plug\nthem in and they will be on the internet. You might be able to get rid of your\nwi-fi altogether, although that is a matter of debate among the experts.\n\nOne thing telecommunications experts agree on is that 5G will make it possible\nto connect many more devices, either directly or indirectly, to the internet\nand give all of those devices the ability to work much more rapidly. There\nwill be no more latency, no more buffering, which will make possible more\ntypes of devices, including those that require reliable and instantaneous\nconnectivity to the Internet of Things, such as autonomous vehicles.\n\nFor autonomous vehicles, otherwise known as driverless cars, to achieve their\nfull potential, multiple sensors and devices on each vehicle will have to\ncommunicate instantly with nearby vehicles, sensors in the road, street signs,\nand traffic lights. To do all of that, the vehicles will need 5G\ncommunications, fast, unbuffered, and able to handle many devices in a small\nspace. So, 5G is coming, fast, and so is a world of billions of devices\ntalking to one another.\n\n### The 5G Security Debates\n\nIf you have already heard about 5G in the media, it has probably been in the\ncontext of a debate about security. The U.S. government somewhat belatedly\nnoticed that a lot of new 5G equipment was going to be installed around the\nUnited States and the world and that the company most likely to be making the\nequipment was called Huawei. The Pentagon and the National Security Agency\nhave never trusted that Chinese internet electronics company, thinking that\nits products might be laced with Chinese government backdoors and bugs. Huawei\nand its lawyers and lobbyists have vehemently denied the allegations.\n\nHuawei has evolved from a maker of lower-quality knockoffs of U.S. technology\n(it originally made internet routers that looked identical to those made by\nthe U.S. giant Cisco). It now has its own designs, which are high-quality\nproducts, and it sells them at a fraction of the price of U.S. and European\ncompetitors. In most of the world, earlier-generation U.S.-made internet\nrouters have been replaced by Huawei’s. That is not generally the case in the\nUnited States, where government pressure has kept large telecom companies\nbuying from the more expensive U.S. or European vendors.\n\nBefore senior levels of the U.S. government seemed to notice, Huawei was\nwrapping up contracts to install 5G technology around the world. Alarmed, one\nTrump White House staffer, a U.S. Air Force general, publicly suggested that\nthe U.S. government should operate the coming 5G network in America. The\ncriticisms from the telephony carriers and Congress were instant and intense.\nThe general was quickly off the White House staff, but the fear of Huawei\nowning the global 5G infrastructure grew. By 2019, the issue had become of\nsuch importance to the Trump administration that Secretary of State Mike\nPompeo was flying around the world pressuring potential Huawei buyers, with\nmixed results. Some of America’s close allies began announcing that they would\nban Huawei from competing for the 5G build-out, but most of the world was\nstill ordering from the Chinese.\n\nAll of this controversy may, however, be the wrong 5G security debate, or at\nleast there may be a second 5G security issue that is equally important, but\nis not much discussed. That issue is about whether there should be security\nrequirements for the 5G network, what they should be, and who should set them.\nThis concern is not that companies, in addition to Huawei, may install\nbackdoors and bugs. The fear is that hackers could.\n\nThe professional staff at the Federal Communications Commission was so\nconcerned about the possibility of 5G being susceptible to hacking that they\npublicly published 132 questions to the communications industry about 5G\nsecurity. They asked all about 5G security and authentication, encryption,\nphysical security, DDoS attacks, patch management, and risk segmentation. Then\nthey got to 5G and the Internet of Things.\n\nThe FCC professionals began by noting the obvious: “It is widely expected that\n5G networks will be used to connect the myriad devices, sensors and other\nelements that will form the Internet of Things (IoT). The anticipated\ndiversity and complexity of these networks, how they interconnect, and the\nsheer number of discrete elements they will comprise raise concerns about the\neffective management of cyber threats.”\n\nThey went on to note that “some IoT devices will have limited security\nfeatures.” No kidding? “Could this have a negative effect on overall 5G\nnetwork security?” Duh. “Are any lessons being learned from the October 2016\nDDoS attacks?” You bet there are, and they are scary, as we will discuss in a\nminute.\n\nWhy did the professional staff experts at the FCC have to ask these questions\npublicly? They did so because the FCC commissioners, the people who decide on\nregulation, refuse to regulate the internet. The Republican appointees,\nencouraged by internet companies, have argued that they just can’t regulate\nthe internet even if it might need it, and can’t regulate 5G security, because\nthe law does not give them that authority. Nonsense.\n\nMoreover, if the existing laws actually did not give the FCC the authority to\nregulate the internet, the FCC commissioners could ask the Congress for that\npower. They have not. Indeed, they have argued that it would stifle innovation\nand do any number of horrific things if anyone ever regulated anything related\nto the internet. So, here come 5G and the Internet of Things without any\nsecurity regulations. Get ready. Strap in.\n\n### IoT: Down on the Farm\n\nEven before autonomous vehicles begin running around on your street, they are\ndriving about on some farms. Our favorite story about the IoT, one that\ndemonstrates how it is creeping into every walk of life and simultaneously\nopening up vulnerabilities to global hackers, comes from down on the farm. If\nyou have opened up your internal combustion engine car’s hood lately to\nattempt do-it-yourself maintenance on the engine, you have been met with a\nsealed box that is relatively impervious to any owner’s attempts to manipulate\nit. Well, it turns out the same is true on newer tractors, such as those from\nthat staple of Americana, John Deere.\n\nNewer tractors also come with satellite or wi-fi links, giving the driver\nprecise location data and allowing for automated driving, fertilizing, and\nplowing. The link also allows data to flow back to John Deere, so the\nmothership will know when one of its green machines is about to break down in\nsome way. It sounded like a good idea.\n\nWhat apparently happened, however, was that many small problems with the\ntractor had to be addressed by a John Deere dealer’s mobile repair team.\nOwners were left with their expensive, high-tech tractors sitting helplessly\nin fields waiting for the maintenance guys with the digital keys that opened\nup the engine and the digital diagnostic equipment that could be plugged into\nthe vehicle. Of course, it cost money just to have the mobile repair truck\nshow up and more if the problem needed any serious work. This is the part of\nthe story where the Iowa farmer meets the Russian-speaking cyber criminal and\nthe local problem goes global.\n\nSomehow, no one is too sure how, irate farmers learned that hackers in Ukraine\ncould help them “jailbreak” their tractors, meaning allow them to get around\nthe factory-installed systems to prevent owners from getting at the innards,\nfiguring out what the problem is, and repairing things themselves. For a small\nfee paid to a website in Ukraine, farmers were able to download a software\ntool to hack their own tractors. Wyatt, meet Ivan, and welcome to the global\nvillage, in which there are IoT devices arriving everywhere and hackers right\nbehind them.\n\n### You Say IT and I Say OT, SCADA, Potato . . .\n\nPart of the problem with understanding the IoT problem, what it is, and how to\nfix it is the terminology. As is often the case in technology, there are a lot\nof terms thrown around without precision or commonly accepted and widely\nunderstood definitions. In the case of IoT, there are a few adjacent\ntechnologies and terms that often get confused with it. They include:\n\nIT and OT: Information technology and operations technology. The former is\nbasically the internet and computer networks and devices designed to work\nusing them. The latter is the world of industrial machine controls that\npreceded the internet and generally use an entirely different kind of\nsoftware.\n\nICS and SCADA: These two types of software generally belong to the OT world.\nThe former are industrial control systems, software from companies such as\nSiemens, Johnson Controls, and General Electric. ICS software runs factories\nand the machines in them. SCADA software can be thought of as a subset of\nprograms that engage in supervisory controls and data acquisition. SCADA\nsoftware often runs on little sensors that report data such as temperatures or\nvoltages or pressure levels. Based on that data, some controls react\nautomatically to avoid overloads and, uh, explosions.\n\nThe acronym SCADA is often used to describe the software that runs the power\ngrid. It is also used to describe the controlling software on other networks\nsuch as railroad lines, pipelines, and petrochemical facilities.\n\nThe Stuxnet software attack on the Iranian nuclear centrifuges was an attack\non an OT or ICS software created by Siemens. The attack’s purpose was to make\nthe controlling software cause devices to do irreparable self-harm. It worked\nfor a while, reportedly destroying eight hundred centrifuges. In that case,\nthe devices might not technically have been IoT because, as a defensive\ntactic, the Iranians had made sure that the plant was not in any way connected\nto the internet. The lesson to remember from that incident is that even when\nyou think a device is not connected to the internet, it can be hit with a\ncyberattack.\n\n### Gimme That OT Religion\n\nIt may have been Stuxnet that gave religion to the OT and ICS world. For years\nthe experts and operators who developed and wrote OT software wanted to have\nnothing to do with the internet and its inherent cyber threats. They were\nadamant that the threats and malicious actors in cyberspace could not get to\nthem, and if they did, they would not be able to harm them. All of that has\nchanged. John Livingston watched it change.\n\nLivingston was a partner at the consulting firm McKinsey. After running the\nconsultancy’s offices in Singapore and South Africa, he took control in\nChicago and ran the wireless and telecoms practice. John noticed the\nbeginnings of the IoT and, upon deeper diligence, he noticed a resistance to\nputting sensors and analytics on industrial systems. “I can’t put sensors on,”\nhe quoted clients as telling him, “because of cybersecurity.” Industrial\nclients wanted to put sensors on networks, but knew that making that\nconnection without being able to secure it was a recipe for disaster. So\nLivingston looked around and found a company called RK Neal in Kentucky. They\nwere a small industrial-controls firm that had been making headway selling\nsecurity software to electric power companies.\n\nPlanning to expand the firm’s focus beyond the power companies, John quit\nMcKinsey and signed on as CEO of a renamed company, now called Verve. The\nelectric power industry’s self-regulating body, NERC, had created\ncybersecurity standards for some parts of the power grid, and Verve had a\nsoftware package that met the NERC compliance requirements. They knew the\npower grid and its vulnerabilities well. “But if you really want to shut off\nelectric power, that’s not who you attack,” Livingston told us. “You attack\nthe gas pipelines. They are way less protected than the power grid.” So many\npower plants have shifted from coal to natural gas that if you cut off the\nnatural gas feed, you shut out the lights. The natural gas system is “far more\ndistributed with its compression stations, gasification, satellite comms to\nwireless modems to PLCs.” And how well secured are all those devices? we\nasked. “Security just doesn’t exist. They may have a password, but that’s it.”\nWhat could possibly go wrong? Recall from chapter 10 that the U.S.\nintelligence community’s threat assessment of January 2019 said that the\nChinese government has the ability to disrupt the U.S. natural gas pipeline\nsystem.\n\nTen months before that public assessment, in March 2018, the gas industry had\na wake-up call. The call came to Energy Services Group, not exactly a\nhousehold name. Yet, as is the case in so many of the industries that we have\nexamined, ESG is that company you never heard of that turns out to be a\ncrucial vendor to most of the big-name companies in the sector. When ESG got\nhacked, things started to go wrong at the big gas pipeline companies such as\nDuke Energy, Boardwalk Pipelines, and Energy Transfer Partners. ESG provided\nthe network they all used for buying and selling gas, billing customers, and\nother essential activities. The pipeline companies disconnected from ESG to\nprevent the hack from spreading to their controls, an admission that an\ninternet-based attack could migrate into the controls for the nation’s\npipelines.\n\nA few months later, the city of Lawrence, Massachusetts, and the nearby towns\nof North Andover and Andover, an hour northwest of Boston, went up in flames.\nAlmost simultaneously, hundreds of calls lit up the 911 emergency call\ncenters. Houses were spontaneously combusting, everywhere. In minutes the\nthree fire departments had more houses burning down than they had fire trucks.\nThey called for help from cities and towns all over eastern Massachusetts.\nFire trucks raced up Interstate 495 in convoys escorted by the state police.\n\nWhat they found looked like the area had been firebombed. There were more than\nseventy structures, at as many locations, enveloped in flame, their roofs\nblown off, walls collapsed. There had not just been fires. There had first\nbeen explosions. Suspicion quickly focused on the natural gas systems in the\nhomes and on the local provider, Columbia Gas. Police and fire personnel,\nfearful that there would be more explosions, ordered everyone out of all homes\nconnected to Columbia Gas. Thousands of people had to find someplace else to\nspend the night as first responders inspected and cleared hundreds of homes.\nIt would be many weeks, well into a chilly New England autumn, before most of\nthe homes had heat again.\n\nAmong the hundreds of emergency responders who headed to Lawrence that\nSeptember night in 2018 were the members of the go-team from the National\nTransportation Safety Board (NTSB). Famous for investigating airplane crashes\naround the world, and the far more frequent train derailments in the United\nStates, the NTSB also has jurisdiction over pipelines. Their conclusion was\nthat a contractor working for Columbia had created an overpressure situation,\nputting vastly too much gas into the system. No one thought that it was a\nhack, just a stupid mistake. In the OT and SCADA world, however, there were\nwhispers. This time it wasn’t a hack, but what would stop some bad guy from\ndoing that intentionally and having the same result? Not much.\n\nJohn Livingston was more discreet with us in describing the attitude of the\ngas industry. “The leadership is aware,” he said cautiously, “but you have to\nconvince the CEO and CFO or the board or nothing happens.”\n\nWhen it does happen, “it’s eighteen to twenty-four months from getting\nreligion to deploying solutions.” That is if it is a straightforward\ndeployment of security controls. “If the industrial control system ties in to\nthe enterprise network,” he said, referring to a company’s internet-connected\nadministrative computer systems, “it’s a huge undertaking to fix it.”\n\nWhen Livingston’s Verve team deploys to a firm, the first task they get asked\nto do is asset management. “Most people have no idea what they have” on their\nOT networks. It’s hard to secure devices if you don’t know you have them.\n\nWe don’t mean to pick on the natural gas industry (okay, actually we do), but\nit is a good example of the old industries that have been running OT software\non old metal devices for years and are now connecting their OT and IT\nnetworks. It turns out that letting OT and IT touch is like putting matter and\nantimatter together. It allows hackers to do things like they tried at a Saudi\npetrochemical facility, as John Livingston described it, “trying to kill\npeople.”\n\n### What’s New? Ubiquitous Sensors—and They’re Connected\n\nIf the world of old OT sensors and switches is not enough of a problem, what’s\nnew is the introduction and rapid growth of sensors that are intentionally\ndesigned to be connected to the internet. Your next refrigerator may be part\nof this trend. If so, welcome to the Internet of Things.\n\nOne fact we know about these IoT devices is that they seem to be multiplying\nrapidly. Gartner, the IT consultancy known for coming up with educated guesses\nthat become generally accepted facts, estimated there were 8.4 billion IoT\ndevices in 2017. That was a 31 percent increase over their estimate the prior\nyear. Now their 2020 guess is 20.4 billion devices. In other words, a few\nyears ago there was about one such device for every human being on Earth and\nin a few years there will be three such devices per human. If humans\nmultiplied at that rate, the planet’s ecosystem would quickly collapse. There\nis concern that the IoT devices, if manipulated malevolently, could produce a\nsimilar effect on networks.\n\nWhat kind of device qualifies as part of the IoT? Any electronic device that\nhas some sort of computer chip or computing ability and is connected to a\nnetwork that is in turn connected to the internet is part of the IoT. The\nplaces they are used vary enormously and include heart pacemakers, self-\ndriving cars, safety monitors on refineries and chemical plants, surveillance\ncameras, subway cars and airport trams, drones, switches on electric power\nsubstations, robotic welders on assembly lines, sensors in Coke vending\nmachines, office building HVAC sensors and controls, self-diagnostic\nelevators, and on and on.\n\nIoT devices are often basically just sensors with diagnostics that trigger\nsoftware to do things like brake the car or train, order a human to come and\nrefill the Coke machine, call a human to do preventive maintenance on a jet\nengine or an elevator, or give the human’s heart a jolt. These devices often\nhave very little software, storage space, or computing ability on them.\nNonetheless, these IoT devices save a vast amount of money for the owners and\noperators of factories, office buildings, and grids of various kinds. What is\nnot to like? We could start with: most of them are not secure, and many of\nthem never can be.\n\n### What Harm Could a Little IoT Widget Do?\n\nSo what? Let’s come back to the Saudi plant John Livingston mentioned.\nSometime in 2018 a malicious actor hacked into the safety-monitoring system in\na petrochemical plant in Saudi Arabia and shut off the IoT systems that were\nthere to detect when pipes and vats are about to explode from overpressure or\nother errors. “The only thing that prevented an explosion was a mistake in the\nattackers’ code,” experts concluded after the fact. If there are IoT devices\ndesigned to detect impending explosions and shut things off, then hacking\nthose devices is necessary if you want to create an explosion. It turned out\nthat hacking those IoT devices in the Saudi facility was easy because, wait\nfor it, they allegedly had no security designed in.\n\nThat is the problem with many IoT devices. You can get to them over the\ninternet and you can shut them off, or in some cases turn them on even when\nyou are not authorized to do so. Former Vice President Dick Cheney famously\nwanted his pacemaker or in-chest defibrillator modified so that it could not\nbe activated remotely from the internet. In this case, Cheney’s paranoia was\njustified. There have been studies that indicated potential problems with such\ndevices. In 2017, the Food and Drug Administration, which regulates health-\ncare-related products, ordered Abbott Laboratories–St. Jude Medical to fix its\npacemakers and implanted defibrillators because of “third-party control risk”\nof initiating shock or draining batteries.\n\nIndeed the FDA is considering regulations that will require all medical\ndevices to be “patchable,” meaning that their software can be updated and\nrepaired when necessary. They are also considering requiring a “bill of\nmaterials” for every device, listing the software and hardware involved and\ntheir provenance. (Does that IV drip device have some open-source software in\nit that might mean it is hackable?) For the FDA, this proactive attitude is a\nbig turnaround, because for years they would not allow medical devices to\naccept security patches without prolonged, elaborate, and expensive testing.\nAs a result, many medical devices were running ancient versions of Microsoft\nWindows software replete with known vulnerabilities. Many still are.\n\n### Other Bad Ways to Use the IoT\n\nBecause IoT devices have very little software on them and often have bespoke\ncomputer chips, there is seldom enough room on them to add security software\nsuch as identity and access management or endpoint protection. Thus, if you\ncan maneuver your way on a network to get to the device (or if you just walk\nup to it in the real world), you can often give it a command and it will\ncomply. The device usually has no way of knowing whether the command is\nauthentic and comes from the network operations center of the company or\nwhether it’s malicious and from some GRU guy in Sverdlovsk.\n\nThe innocent, defenseless, not too bright IoT device can be used in\ninteresting ways by hackers. First, the IoT device can be used as an access\nport into the corporate network. Walk up to the device, hook up your laptop or\nattach your thumb drive, and you might be able to run a hack into the company.\n\nSecond, you could use the IoT device to run a flood attack, or DDoS, pinging a\nwebsite so often that no other traffic can get through. The target could be\nanywhere, or it could be on the same network as the device. The most famous\ninstance of this kind of attack so far happened in October 2016 and involved\nbaby monitors, a Latin American embassy in London, hundreds of major U.S.\ncorporations (Amazon, PayPal, and Twitter among them), and a little-known\ncompany in an office park in New Hampshire.\n\nDyn, the company in New Hampshire, provides internet look-up and routing\ninformation (DNS) for a lot of big companies. It is another one of those\ncompanies, like ESG is to natural gas, that exist in every sector that no one\nhas ever heard about but is actually essential (and could become an Achilles’\nheel) for well-known giants. Beginning at 7:00 A.M. on October 21, 2016, Dyn’s\nservers were flooded by millions of pings, making it difficult for their\ncustomers to access the crucial Dyn DNS servers. The effect was to disrupt\ninternet connectivity across North America.\n\nThe pings came from hundreds of thousands of IoT devices, including nanny\ncams, more sophisticated surveillance and security cameras, and a host of\nother devices. All of those devices had been affected by a malicious bot, a\npiece of software that guided itself around the world looking for unprotected\nIoT devices to infect and take over. The bot was given a name by the\ncybersecurity world. They called it Mirai.\n\nSuspicions about who launched Mirai fell on the supporters in North America of\nthe hacker Julian Assange, who has been linked to Russian intelligence and the\nhacking of the U.S. 2016 election. Word had been spreading that the United\nStates was putting pressure on Ecuador to throw Assange out of their embassy\nin London, where he had taken refuge after arrest warrants were issued for\nhim. Assange’s organization eventually publicly called on his supporters to\n“stop taking down the U.S. internet. You proved your point.” Apparently the\nhackers thought that if they disrupted the U.S. internet, the American\ngovernment would relent in its efforts to arrest their hero. (Fourteen months\nlater three men were indicted in the United States for cybercrimes using the\nMirai botnet.)\n\nWhat the Stuxnet attack, the hack of the Saudi petrochemical facility, and\nmany other incidents demonstrate is that what sensors think is happening may\nnot always be accurate and what control boards show is the condition may not\nalways reflect reality. When simple artificial intelligence applications are\ngiven too much autonomy to act with too little verification of the readings\nthey are employing, bad things can happen on the Internet of Things. They can\nhappen without malicious activity, as may have been the case in the crashes of\nthe 737 Max aircrafts (where a bad sensor reading may have caused an AI\nprogram to take control of the aircraft without telling the pilot), or they\ncan be the result of hacking, as in the case of the two Ukrainian electrical\npower grid blackouts (where the control boards were hacked to indicate all was\nwell, even after the GRU hackers had thrown the breakers on transformers all\nacross the region).\n\nYou can: 1) seize control of unprotected IoT devices and use them to do damage\n(let gas pressure build up); 2) use the device to attack the network it’s on;\n3) use the device to launch attacks elsewhere; 4) store illicit data on the\ndevice (child pornography, stolen secrets, attack tools); or 5) employ any\nexcess computing power on the device for purposes like Bitcoin mining.\n\n### Securing a Moving Train\n\nIf ever there were a case of painting a moving train, securing the IoT is one.\nThe deployment of billions of devices is well under way and may be\naccelerating. Getting all of those devices to be secure will be impossible. As\nLenin once asked, “What is to be done?” We suggest steps that would likely\nwork only if they are part of a high-level government campaign to educate\ncorporate leaders, device designers, and government regulators.\n\nFirst, corporations or other network owners should ban any new IoT device from\nbeing connected unless it has been demonstrably proven to be secure.\n\nSecond, corporate leaders should initiate an inventory of what IoT devices\nhave already been linked to their networks and disable the internet\nconnections. That includes printers, photocopiers, and other office equipment\nthat “phones home” to its manufacturer or maintenance provider. It was the\nfood freezers at Target connecting to the HVAC service company that caused the\n2013 hack that ended up getting the CEO and CIO fired.\n\nThird, government regulators should have prevented the deployment of internet-\nconnected devices that were insecure. They did not. Now, they must insist that\nno new IoT device be permitted to operate in a regulated environment until a\nthird-party security assessment has determined the device poses no threat.\nThen, they need to use their regulatory powers to require all existing devices\nbe retrofitted with security or replaced by newly designed devices created\nfrom the ground up with security in mind. For example:\n\n  * The U.S. Department of Transportation has made noises about issuing regulations requiring such assurances for driverless cars. At the same time, however, that department is, without much thought to security, requiring train operators to install new IoT sensors that could literally stop trains in their tracks (so-called positive train control systems).\n\n  * The FDA has said that new devices should be patchable, but what about all the old ones that are out there? They should issue regulations that require all IoT medical devices to be secured or replaced by a certain date.\n\n  * Federal Aviation Administration regulations maintain a high standard for physical security and reliability of aircraft parts, but less so for the huge volume of data that is downloaded from every aircraft and every engine after each flight. The FAA should set a minimum standard for what flight data is downloaded, how it is analyzed, how long it is stored in a data lake, and what sort of ongoing AI review of the accumulated data is conducted to search for indications of compromise.\n\n  * The Federal Energy Regulatory Commission should require any existing diagnostic or reporting devices anywhere on the power grid or pipelines to be physically and virtually walled off from the “control plane” of the grid and placed on a separate network. Physical and software firewalls can be placed between the IoT devices and the controls. Physical diodes, devices that restrict data flows to one direction, can be required. Future devices should not be allowed to connect to the network unless they have been certified as secure from malicious attack.\n\n  * Finally, government, academic, and industry experts should work together to define new, more demanding security standards for IoT devices and develop baseline procedures for continuous testing of those devices. We suggest that standards include the device being able to handle multifactor authentication, so that only authorized users can tell it what to do. We would add having an endpoint agent on the device to monitor for and prevent suspicious activity.\n\nUntil then, just be aware that a guy in Kiev can maybe kill your tractor, a\ngal in Beijing can possibly see you on your camera and listen to you on your\npersonal device, while the folks in Moscow can probably blow up your gas\npipeline or set your house on fire. As the intrepid cable news reporters\nalways ask the disaster victims, “How does that make you feel?”\n\nFor now we have to accept that what cybersecurity people call the “attack\nsurface” (the target deck that can be hacked) is growing enormously. The\nopportunities for the offense are growing, again. The problem for the defense\nis being made more difficult by the combination of insecure 5G and insecure\nIoT. For all the progress we are making in securing corporate and government\nnetworks, for all the promise of AI and quantum, the problem keeps expanding\nbecause neither government nor the IT industry will wait for a new technology\nto be secure before they deploy it.\n\n\n# PART VI\n\n# YOU AND THE WAY AHEAD\n\n\n## Chapter 18\n\n## DERISKING OURSELVES\n\n## Personal Cybersecurity\n\nPasswords are like underwear. Don’t let people see them, change them often,\nand don’t share them with anyone.\n\n—ANONYMOUS\n\nThank you for your thoughts on defending the Pentagon in a cyber war, but what\nabout me?” the young woman in the audience asked us. “How do I defend me?” At\nevery lecture, every book signing, every extended family dinner gathering,\nsomeone will ask that practical question. Now that we’ve dealt with what\ncorporations, governments, and the military should do, let’s talk about what\nyou should be doing to protect yourself.\n\n### What Do You Value?\n\nJust as we do when we are consulting for big corporations, we begin by asking\nyou the question we ask the CEOs: What is important to you? The answer is not\nalways obvious. You may think that your so-called personally identifiable\ninformation (PII) is important. You wouldn’t want strangers to know your\nSocial Security number, birth date, or telephone number. In truth, they\nalready do. Everybody’s Social Security number has already been compromised.\nThat’s why we don’t think any organization should use that number as a means\nto authenticate you. Even Medicare agrees. They just recently transitioned\nfrom using Social Security numbers for identifying patients.\n\nPII has been stolen so many times now that the acceptance rate on the free\ncredit-score monitoring service that you get offered after a data breach is\naround 15 percent. That means about 85 percent of people who have been told\nthat their PII has been compromised do nothing. That is probably the\nappropriate response. Nonetheless, if you fear that someone is going to use\nyour PII to take out a loan or get a credit card in your name, then you can go\nonline to each of the major credit scoring agencies (including the notorious\nEquifax, which suffered a PII data breach of epic proportions in 2017) and\n“lock” your credit reporting. That way no one can access your score to process\na loan without offering additional proof that they are, in fact, you.\n\nSo, if it’s not your PII that you should worry about, what is it? Maybe it\nshould be your passwords.\n\nMost people now have dozens of online accounts: airlines, banks, email,\ninsurance, social media, the DMV, etc. Keep a list of these accounts. Every\ntime you have to use a password, add it to that list. In a month, we bet\nyou’ll be shocked at the number of accounts you have, and we also bet that\nmost of your account credentials will be the same, or minor variations on a\ntheme like your birthday or a loved one’s birthday. In that case, you have a\nproblem. If one website or app that you use gets hacked, and one will, the\nhacker will know your username (or email address) and password for that\nwebsite. They will then use that username and password combination on a\nvariety of large banking websites such as Bank of America, Wells Fargo, or\nCitibank. They will keep trying banks until they find yours. _Do not use the\nsame password on more than one site._\n\nIf your password is “password” or “123456” or some other brain-dead idea, you\nmight as well stand on the corner and just pass out your money to the\nhomeless. You would at least be doing some good in the process.\n\nIf your password is composed of six or fewer letters and/or numbers, it’s also\nreally easy for hackers to crack it using “brute-force” software. As its name\nwould suggest, the brute-force method simply tries every combination of\nletters, numbers, and symbols until it gets the right combination, at a rate\nof millions of guesses per second. To confound such brute-force tools, longer\npasswords are better. You want a password of at least eight characters in\nlength, but more is better. We like ten-character passwords that use a\ncombination of lower- and uppercase letters, numbers, and those little symbols\non the keyboard such as #, ^, *, and +. For an eight-character password that\nuses all of these different character types, there are 645,753,531,245,761\npossible combinations. That’s a lot of passwords for a hacker to guess.\n\nYou are thinking that you will not be able to remember all those different\nlong, complex passwords. Of course you won’t, unless you have some freakish\nphotographic memory. You may think about writing them down on a yellow sticky\nand putting them under the mousepad by your computer. That’s where we always\nlook for them when we are at a new client site. Usually, we only have to visit\na dozen cubicles before we find a password under a mousepad or in a desk\ndrawer. Even at home, it’s not a good idea to write them down on a piece of\npaper. You just never know who might find themselves looking through your\ndesk.\n\nInstead, we suggest you use a password manager. Apple has one built in to Macs\nand iPhones. Or you can pay a small fee and subscribe to one such as LastPass,\nDashlane, or Zoho. Then you only have to remember the password you use for\nthat service. It will remember the other twenty or thirty you use. Better yet,\nit will create long, complex, and unique passwords for each different account\nthat you have. When you log in to a site with your phone or laptop, the\npassword manager will automatically enter your password. These services\nsynchronize on all of your devices, no matter how many laptops, desktops, or\nmobile phones you use.\n\nTo be doubly safe, use a password _and_ something else, an additional factor.\nLots of services now allow you to use two-factor authentication to access your\naccount. This is true on Facebook, iTunes, Office 365, and most financial\ninstitutions. Usually, the second factor is a number that the website will\nsend as a text message to your phone. You can also buy a USB thumb drive or\nother such device that you need to use in addition to your password to\nauthenticate yourself. The problem with such a device is that, if you are like\nRob Knake, you will immediately lose it and then you are really in trouble\nbecause you are locked out for good. While these solutions aren’t airtight,\nthey are probably better than the protection you have now.\n\n### Banks, Stocks, and Credit Cards\n\nEverybody’s credit-card account information gets stolen. It wasn’t your fault.\nYou didn’t do anything wrong. _They_ did, the people who run the brick-and-\nmortar store, the online store, the restaurant, or the hotel. There was a\nplague at gas stations and restaurants where hackers had emplaced physical\nscanners inside the credit-card readers, so that as the card reader was\nreading your card, they were too (newer cards with chips make this kind of\nattack harder to do). Many establishments, even if they are high-end ones, can\noffer poor cybersecurity.\n\nYes, it’s inconvenient when you have to go to all of your service providers\nthat deduct automatically from your credit card every month and tell them the\nnew credit-card number. It is worth it to keep a list of all of those\nservices, so when this happens to you (and it will), you can just sit down\nonce for an hour or so and update all of the accounts.\n\nAlmost always the bank behind your credit card will make good. They will not\ncharge you for the new TV that somebody bought at Walmart in Daytona Beach\nwith your credit card. For unauthorized credit-card charges, you’re only\nliable for up to fifty dollars of the losses. Credit-card fraud is now just\nconsidered a cost of doing business to your bank, but don’t worry, they have\nalready priced in their anticipated losses and they are still making a lot of\nmoney off of you.\n\nWhen credit-card fraud started to get out of control years ago, banks all\nbought artificial-intelligence software that makes quick decisions in the\nbackground to determine whether or not it actually is you buying a TV at that\nWalmart in Florida. Fraudulent debit-card charges are a different story.\nYou’re liable for up to fifty dollars of the losses if you report the fraud\nwithin two (business) days, up to five hundred dollars if you report it more\nthan two days after the theft, and up to the full amount of the fraudulent\ncharge if you take more than sixty days to report it.\n\nThe banks’ protections can be a pain when the AI gets it wrong. What if you do\nactually show up at that Florida Walmart and your card is declined at the\ncheckout? Fortunately, most banks will allow you to talk to a human in advance\nof your traveling to someplace unusual (Really, you’re actually going to\nChad?) or before you buy a big-ticket item (Your first cruise in the Caribbean\nand you’re spending ten grand?). You can often get the bank to agree not to\nprocess a charge outside of the country or over a certain dollar amount\nwithout you calling them in advance and giving them authorization, using a PIN\nor other proof.\n\nThe two best techniques to use if you are worried about someone getting your\ncard information are: 1) only use a credit card, not a debit card, and 2) have\na low spending limit on the credit line associated with the card, say, a\nthousand dollars a month (or more depending upon how profligate you want to\nbe).\n\nFor all online banking and stock transactions, be sure that your financial\ninstitution will let you use two-factor authentication, as we discussed\nbefore. For transactions above a certain dollar value, ask them to have a\nhuman call you and ask you several security questions. Remember when you do\nset up security questions that the right answer is whatever you want it to be.\nIf the question is “In what city were you born?” do not use the actual city\nwhere your mother gave birth to you. That is usually a matter of public\nrecord. Where were you born? Mos Eisley from _Star Wars_. What is your\nfavorite sports team? Well, if everybody knows you are from Boston, do not\nanswer that question with “The Red Sox.” Try some nonexistent franchise like\nthe Montreal Mavericks. Just remember your answer or put the answer in the\nnotes section of your password manager.\n\nDeception can often be helpful in security. You may want to actually spread\nfalse information about yourself. Create a fake birthday for your social media\naccounts. You don’t have to tell a social media company what your birthday is,\nbut go ahead and give them one anyway. Let all the world see it. Make sure\nit’s fictional. The only downside is when all of your Facebook friends send\nyou happy birthday messages in the wrong month, but when that happens, revel\nin your deception. It’s working.\n\n### Security Settings\n\nYou can probably make your laptop or other device more secure than it is now.\nYour operating system is almost always in need of a security update. That is\nparticularly true if you are running some old version, such as Windows 98,\nWindows XP, or Windows Vista. Get rid of them now. They cannot be fixed. Buy\nWindows 10. If you use a Mac, get the latest OS by clicking on the apple in\nthe upper left, then About This Mac, then Software Update. It’s free.\n\nTurn on automatic software updates so you do not have to decide to do it every\ntime. The same is true of your web browser. Chrome is the best web browser\nchoice. Similarly, get rid of software with bad reputations for security, like\nAdobe Flash.\n\nShould you use antivirus software? Yes. Download Sophos, McAfee, or Symantec.\nWhatever you use, turn on automatic updates. Even these antivirus companies\ncan fail to protect you in time when a new virus enters the wild, so how do\nyou avoid being infected to begin with? Email is one of the most common ways\nthat computers become infected. You may receive phishing, or the more targeted\nspear-phishing, emails that attempt to trick you into thinking that they’re\nfrom a legitimate source. Fraudsters will send out phishing emails to\nthousands (or even millions) of users at once, but increasingly we are seeing\ncrafted phishing emails that are intended for a specific person. Phishing\nattempts may be fake password-reset emails “from” Microsoft, Google, Apple, or\nFacebook telling you that you need to log in to receive a message or that you\nneed to open an attachment. Some of these emails are so expertly crafted that\nthey are nearly indistinguishable from a genuine email from the company or\nperson in question.\n\nNo matter how innocent or authentic an email appears, _do not_ click any link\nor open any attachment contained within it without first checking the sender’s\nemail address, or hovering over the link with your mouse to make sure that it\nreally does go to the website it claims to go to. If the email is not\nlegitimate, just delete it. You can lose everything on your device by slipping\nup just once. (Remember the gullible employee, Dave, from chapter 4? Don’t be\nDave.)\n\nWhen your device becomes compromised, the attacker can use your computer’s\npower to participate in a flood attack on another network, or secretly steal\nyour computational power to mine cryptocurrencies like Bitcoin. So, while they\nare not stealing data, files, or money from you, they are nonetheless hurting\nsomebody somewhere with your computer. Without your knowing it, your machine\nis being used to do bad things.\n\n### Every Move You Make, Every Step You Take\n\nIt may or may not be a security risk, but it is more than a little creepy to\nthink that somebody is watching you. Who wants a GRU officer in wintry Tula,\nduring a boring shift posting Green Party propaganda on Facebook, amusing\nhimself by seeing what’s going on in your house?\n\nYou have cameras on your mobile device. You more than likely have a camera on\nyour laptop, desktop, or both. Millions of Americans have installed security\ncameras inside their homes to keep an eye on hired help or pets. Many of these\ncameras now come with built-in microphones and speakers, so you can yell at\nthe local youth to get off your lawn, or listen to hear your baby crying.\nWebcams and security cameras are notoriously insecure systems, so it is not\ndifficult for hackers to gain access to those cameras and their microphones to\nwatch and listen to you. It is even possible for these cameras to appear to be\n“off” when they really aren’t.\n\nThere are countless cases of these devices being compromised. Some of this is\ndue to poor engineering or software development on the part of the camera’s\nmanufacturer, which is by extension just a by-product of the low standards for\ncybersecurity in the Internet of Things world.\n\nWe do not know of a good way to be highly confident that your security cameras\nare secure, but if you’re able to access them via a web browser without\nentering any username or password, you can probably assume that if somebody\nreally had a reason for wanting to watch what your cameras are picking up,\nthey could probably do so with very little work. If your cameras do use\nauthentication, use the aforementioned best practices for choosing a password.\n\nSo, what can you do about this? To begin with, tape over the camera (or use a\nPost-it note) on your laptop or desktop until you want to use it for FaceTime\nor Skype, or use a sliding webcam cover, which can be found with ease on the\ninternet (and is now ubiquitous in the cybersecurity world). Again, there is\nlittle probability that someone is sitting around watching what goes on in\nyour household all day, but if you’re worried regardless, turn the interior\ncameras off when you get home. Turn the computer off when you are not using\nit. If you are _really_ paranoid and you have a device with a removable\nbattery, take it out when you are not going to use it for a while.\n\nOn your mobile device, go into the controls or settings and find the part\nwhere you can decide which applications can use a cellular connection. It is\nthere that you can also see which applications have decided that they should\nhave access to your camera or microphone. Set them all to off. Instagram does\nnot need access to your microphone all the time. No app does. Sure, some\napplications genuinely need access to these things, but you can always\nreinstate access when the app prompts you next time.\n\nIn fact, be aware of where you leave your mobile device when you are having\nprivate conversations or activities. You might want to put it in another room\nif you are worried about someone listening, which is especially true when\nyou’re traveling internationally. Some governments around the world have wide-\nreaching surveillance powers and would not hesitate to start spying on you\nthrough your smartphone the moment you step into the country. This is why many\nindividuals in the cybersecurity community have cheap travel laptops that they\nuse exclusively when they are out of the country.\n\nWhat about Alexa, Siri, and friends? While their manufacturers give assurance\nafter assurance that they are not recording all of your conversations or\nsending your data back to the mothership, it seems to be within the realm of\npossibility that someone could hack them to do just that. If you are paranoid,\nthese household-assistant devices are really not a problem. No paranoid person\nwould ever use one.\n\n### Back It Up\n\nAs someone who has had his White House emails paraded on national television,\nDick Clarke is a little more careful than most people about what he writes,\nbut anyone can slip up. There is also the potential for someone else’s\ncomputer, with your email correspondence on it, being hacked. Yes, we have had\nthat happen too.\n\nAs a general rule, if you do not want your comments ever to appear in the\nnewspaper, a court case, or in a heated bedtime conversation with your\npartner, don’t write them. If you have to write it, use Signal, Wickr, or some\nother encrypted messaging app. If you do elect to use one of these secure\nmessaging apps, set it up so that it erases the messages after some short\nperiod of time. Otherwise, they can be read by anyone who unlocks your phone\nor the recipient’s.\n\nWhy do you have five years’ worth of emails on your iPhone and laptop anyway?\nErase them, and just keep a couple months’ worth of emails at a time. Oh,\nyou’re a digital pack rat and think that you may need to refer to them\nsomeday, or that your biographer will really enjoy using them for that great\nbook about you? Well, if you insist on saving those _bon mots_ for posterity,\ntransfer them to a separate hard drive or thumb drive and erase them from your\ndevices.\n\nIn fact, when you get that external hard drive, back up everything on your\ncomputer: emails, documents, and, most importantly, pictures. No one has hard\ncopy pictures anymore, so when you lose your digital pictures, they may be\nlost forever. Back up everything at least once a month, as if you are paying\nyour monthly bills, but make sure that you keep your external hard drive\ndisconnected when it is not being used. If your backup is always connected, it\ncan be hacked just as easily as your computer. If you are hit by a ransomware\nor wiperware attack, your backup might be as well. So keep it disconnected\nuntil your daily, weekly, or monthly session of backing up everything.\n\nYes, you can back up everything to the cloud, and more and more people are\ndoing so. However, bear in mind that you are then at the mercy of the cloud\nprovider’s security and authentication practices, as well as the strength of\nyour password. If you set it up properly and use a cloud service provider with\na good track record of security, you will probably be okay, but there are\ninherent risks.\n\nOverall, we think the best policy is to keep as few files as possible on your\ndevices. Put everything in an external hard drive and a secure cloud drive,\nor, for the particularly paranoid, on a laptop that is never used to connect\nto the internet.\n\n### Losing Your Device\n\nIt is a real insight into how dependent we have all become on our mobile\ndevices that, when we lose one, we feel powerless, and at our wits’ end. There\nare some simple steps to ease the pain of the loss, but you have to take them\nin advance, as in right now.\n\nFirst, use whole-disk encryption so that no one can open your device without a\nlengthy password or biometric authentication.\n\nSecond, as we said before, have everything backed up so you can quickly\nrestore all of your data on your replacement device when you buy a new one.\n\nThird, most devices now allow you to turn on a GPS tracker in advance so that\nyou will know where the device is.\n\nFourth, configure your settings so that you can remotely wipe the device of\nall its data. For iPhone users, you can set this up so that you have to\nperform the wipe manually (though it will have to connect to the internet to\nreceive the command), or so that the device wipes itself after a number of\nfailed unlock attempts.\n\nIt can at times be prudent to give a very close friend access to some of your\naccounts. You can configure your cloud backups so that a friend can access\nthem in the event that you are incapacitated. You can choose “trusted\ncontacts” on Facebook that will receive security codes to help you recover\naccess to your account in the event that you have forgotten your password.\nSome people are now attaching their various accounts’ passwords to their last\nwill, especially their investment or banking accounts. Morbid, we know, but\nyou might want to make things easier for those who have to deal with that\nsituation, whether sudden or expected. If you don’t want to think about when\nyou become “The Departed,” then think what will happen when you have to access\nyour parents’ or partner’s accounts after their demise. Have that talk now.\nDigital assets are sometimes as important as your physical assets, if not more\nso.\n\nWe know that all of this may have sent some of you running to find your\ncomputers so you can throw them out of the house (by the way, remove the hard\ndrives first and physically destroy them), but that is not really necessary.\nFor most people, the worst thing that happens when they are hacked is that\nthey have to get new credit cards and tell all of their service providers the\nnew card numbers. The bottom line is don’t be so concerned about personal\ncyber risks that you fail to enjoy all the many wonderful things that the\ninternet provides modern society just because there are threats lurking in the\nshadows.\n\n\n## Chapter 19\n\n## EVERYTHING DONE BUT THE CODING\n\nThe best time to plant a tree is twenty years ago. The second-best time is\nnow.\n\n—FAKE CHINESE PROVERB\n\nIn 2011, the Obama administration released its International Strategy for\nCyberspace. It was a solid document that built on work done in academia and\nthe think-tank community as well as by a group of experts from like-minded\ncountries that had been meeting to hash out how to handle conflict in\ncyberspace for years. When four longtime experts in the field (Matt Devost,\nJeff Moss, Neal Pollard, and Robert Stratton) looked at it, they came to a\nsimple conclusion: everything was done but “the coding.” They wrote a paper\nlaying out their argument in “All Done Except the Coding: Implementing the\nInternational Strategy for Cyberspace.” In essence, the strategy was right.\nNow came the hard part of implementing it. They noted that the document\n“rightfully commented on the need for innovative incentives for the private\nsector to fulfill national security goals,” but “the challenge, of course, is\nhow to achieve this.”\n\nThe challenge then is, of course, the same challenge we face today. We know\nwhat the strategy is. What we need to do now is work to implement it. All that\nis left is the coding. That, unfortunately, is the hard part. For twenty years\nwe have had the right strategy, questioned it, and returned to it. Yet for\ntwenty years we have failed to implement it while searching in vain for an\nalternate that would get us out of doing the hard work. It’s as if, after\ncoming up with nuclear deterrence strategy in the Cold War, we never got\naround to building the nuclear triad. We need to summon the resources and\npolitical will to overcome this failure now.\n\nWhen we teach, we often admonish our students that coming up with policy is\nthe easy part. Implementing it is the hard part. We wish we could say that we\nhave done the hard work already, but the thinking comes easier than the doing.\nWe wish that government and business had taken the threat more seriously in\nits nascence and we had a stronger base on which to build a resilient cyber\nfuture. Yet we remain optimistic that this nation and those of like minds\naround the world can solve these problems.\n\nWe began this book by recalling the extensive damage that malicious activity\nin cyberspace has already done, the increasing militarization of network\nattacks, and the potential for far more significant activity. We do not mean\nto needlessly scare anybody, but things could get worse and the instability in\ncyberspace could spill over from war in the fifth domain to more traditional\nforms of combat in the other four. Because of the dependence of our society\nand economy on networks, severely damaging activity in cyberspace could still\nfundamentally change our way of life for extended periods of postattack\nrecovery. It does not have to be this way.\n\nWe can fix things. We can do so with existing technologies and even using\nbasically the same resilience strategy that several U.S. administrations have\nespoused but not implemented. In this book we have reiterated and elaborated\nupon that basic strategy with some new specifics, none of which are\nrevolutionary approaches. Instead, we have looked for incentives,\ndisincentives, nudges, and shoves to make the basic strategy of resilience\nwork. That is not to say that implementing the ideas will be simple,\nstraightforward, or without cost.\n\nThe resilience strategy seeks a continuous process to reduce risks and\nvulnerabilities, while creating systems that limit potential damage. We can\nreduce the threat of cyber warfare from something threatening our way of life\nto something akin to a major hurricane, a storm that can cause a localized\ndislocation for a short period of time.\n\nThroughout this book, we have come back many times to the theme of working to\nshift the advantage from the attacker to the defender. This effort should be\nthe overall goal of our national policy, and that of like-minded countries and\ncompanies. Ultimately, what we want is to be able to ignore cyberattacks.\nInstead of escalating, we want to be able to slough them off and continue on\nwith our business.\n\nNo matter how secure our systems become, the forces that propel people to\nattack them will never cease. A future in which systems are harder to\ncompromise, where the likelihood of attacks failing is higher, and where there\nare consequences for getting caught may drive many would-be attackers out of\nthe field. It’s possible to envision a future in which finding a zero-day\nvulnerability would require millions of dollars’ worth of effort and yield\nonly thousands of dollars in return. There may come a time when even the best-\nfinanced criminal groups can hammer on companies all day every day for years\non end without receiving a dollar in return. Even if we can achieve these\noutcomes, even if most cyber criminals give up the game and decide to do\nsomething useful with their technical skills, there will still be those who\nseek to do us harm in cyberspace.\n\nThus, we must recognize what everyone in the field intuits, that there is no\nultimate state, no resting place, no landing spot on the Sea of Tranquillity\nin which we can plant a flag. We must continually adapt and improve\ncapabilities for individual companies and for the ecosystem as a whole. The\ngoal is to achieve a state of ongoing improvement, where systems are\ncontinually being made more secure and the work of attacking these systems is\nharder, takes longer, and comes with greater risk of failure and punishment.\n\nAbove all else, we believe that what is necessary is a shift in mind-set. We\nneed to accept that achieving cyber resilience is not a vague “shared\nresponsibility.” Instead, it requires the government to put the onus on owners\nand operators of networks and systems to make those assets resilient.\nGovernment has its roles, but the primary responsibility lies with the private\nsector. We need to stop pretending that the offense has an insurmountable\nadvantage and to recognize that simple shifts in thinking like the kill chain\nand advances in technology such as endpoint detection and cloud computing have\nstarted to level the playing field.\n\nSecuring our countries, our businesses, and ourselves in cyberspace is far\nfrom hopeless. We have the strategy. We have the tools. Now we just need to do\nthe hard work. What is missing is national consensus, will, and priority-\nsetting. We as a nation have choices when it comes to how we live in the age\nof cyberspace: significantly reducing risks now, muddling through, or dealing\nwith this set of issues later at great cost. Avoiding a decision is, in\nitself, a decision, and a dangerous one.\n\n\n# Glossary\n\nAdvanced Persistent Threat (APT): A term to describe the most capable\noffensive cyber actors, often nation-states, that are able to maintain long-\nterm campaigns against even the most hardened targets.\n\nAuthentication: A procedure that verifies a user is who he or she claims to\nbe.\n\nBackdoor: A pathway to maintain access to a computer system or network whose\nexistence is known only to a small number of individuals. A backdoor can be\nimplanted in software intentionally by its developers for debugging purposes\nor under the compulsion of a government, or can be created by a threat actor\nthat has successfully exploited a vulnerability in the system or software.\n\nBorder Gateway Protocol (BGP): An internet protocol that is used to make\ndecisions regarding the routing of information among major ISPs (also called\nTier 1 information service providers) such as Verizon, AT&T, China Telecom,\nBritish Telecom, Deutsche Telekom, and Japan Telecom. BGP tables posted by\nthose providers list to which corporations and institutions they connect and\nfor whom traffic should be routed to them. BGP is an insecure system subject\nto manipulation.\n\nBotnet: A network of devices that have been co-opted by a malicious actor and\ncan be used to execute large-scale operations in a coordinated fashion, such\nas distributed denial-of-service (DDoS) attacks. Devices that belong to a\nbotnet generally “phone home” to a command-and-control server many times each\nday to receive instructions.\n\nChief Information Officer (CIO): The most senior information technology\nexecutive in an organization, a position that has become more and more\ncommonplace since the 1980s. The CIO generally reports to the CEO, but may\ninstead report to the COO.\n\nChief Information Security Officer (CISO): The most senior cybersecurity\nexecutive in an organization. The CISO should report to either the chief risk\nofficer or CEO and is usually responsible for managing security technologies\nand ensuring compliance with the applicable cyber regulatory regimes.\n\nCloud: Computing infrastructure usually managed and maintained by a third\nparty. Use of the cloud permits organizations to purchase only the data\nstorage and computational power that they need at any given time. Cloud\nservice providers exploit economies of scale to minimize the cost of their\nservices, and use of the cloud also allows their customers to avoid expending\ncapital on their own computing infrastructure.\n\nCyber Command: A unified military command within the U.S. Department of\nDefense tasked with managing and coordinating the U.S. military’s offensive\nand defensive cyber operations. The U.S. Cyber Command was created in 2009 and\nconsists of personnel from the Army, Navy, Air Force, and Marine Corps\nbranches of the U.S. armed forces.\n\nCybersecurity and Infrastructure Security Agency (CISA): A unit in the U.S.\nDepartment of Homeland Security created in late 2018 out of the National\nProtection and Programs Directorate (NPPD) to assist the private sector and\ncivilian U.S. government agencies with their cybersecurity. CISA also has some\nresponsibility for the physical security of key infrastructure components\nunrelated to information technology.\n\nCyber War Risk Insurance Act (CWRIA): A proposal made in this book for a Cyber\nWar Risk Insurance Act modeled along the lines of an existing government\nprogram to backstop commercial insurance in the event of a major terrorist\nattack.\n\nData Lake: A virtual repository in which current and perhaps past data is\nstored. The information contained within a data lake can be queried and is\noften useful for business intelligence or analytical purposes.\n\nDefense Advanced Research Projects Agency (DARPA): A U.S. Defense Department\noffice that funds university and laboratory investigations and experiments\ninto new concepts, and known, inter alia, for funding the research that led to\nthe creation of the internet.\n\nDefense Industrial Base (DIB): Those privately owned and operated corporations\nthat manufacture weapons and supporting systems utilized by the armed forces.\n\nDirect-Recording Electronic (DRE): A term used to describe a class of\nelectronic voting machines that do not create a paper trail to permit auditing\nof votes cast.\n\nDistributed Denial-of-Service (DDoS) Attack: An offensive cyber operation in\nwhich a network is paralyzed by an inundation of requests by a large number of\ndevices. DDoS attacks are generally executed by a botnet consisting of tens of\nthousands of machines, which allows threat actors to overwhelm websites or\nnetworks, making them unusable.\n\nDomain Name System (DNS): A system underpinning the internet that converts\ndomain names into numerical IP addresses needed for routing. DNS exists as a\ndistributed directory, whereby low-level DNS servers contain only routing\ninformation for small organizations, and the highest-level DNS servers contain\nrouting information for major websites, services, and top-level domains such\nas .com, .net, or .org.\n\nD-Trip: Nickname of the Democratic Congressional Campaign Committee (DCCC), an\norganization of the Democratic Party devoted to the election of members to the\nlower house of the U.S. Congress.\n\nEncryption: The scrambling of information so that it is unreadable to those\nwho do not have the encryption key needed to unscramble it. Encrypting traffic\nprevents those who intercept it from being able to read it. Most encryption\ntoday is achieved by using public-key encryption, whose strength resides in\nthe fact that one must determine the prime factors of a very large number in\norder to break the code. Even employing all computational resources on Earth,\nmodern encryption now cannot be broken on a time scale meaningful to human\nlife.\n\nEndpoint: A device connected to a network, typically a desktop or laptop\ncomputer. Endpoint security software monitors activity of the device for\nunusual or prohibited activity. EDR software (endpoint detection and response)\nis typically an agent installed on the device.\n\nExploit: A method by which an actor can take advantage of a vulnerability in a\npiece of software, hardware, or a computing system. Exploits can take the form\nof a short script, intricately developed software, or a sequence of commands.\nThey are generally used to gain unauthorized persistence on a network, or\nescalate administrative privileges for the threat actor to enable them to\ncarry out espionage or other forms of cybercrime.\n\nFinancial Action Task Force (FATF): An international organization of nation-\nstate governments created to combat international money laundering through the\ncreation of banking and legal standards.\n\nGRU: The Main Directorate of the General Staff of the Armed Forces of the\nRussian Federation. The GRU is a Russian military-intelligence and special-\noperations service, whose head reports to the Ministry of Defense. The GRU has\nbeen responsible for a number of high-profile cyber activities, most notably\nthe hacking and disinformation campaign related to the 2016 U.S. presidential\nelection.\n\nHoneypots: Files on a network designed to attract hackers so that their\nactivities and techniques can be observed. Such files are usually populated\nwith data that looks real, but is actually fake.\n\nIdentity and Access Management (IAM): A class of software used to authenticate\nnetwork users in order to prevent unauthorized access to data or services.\nModern identity and access management products often integrate with user\ndirectory databases to manage permissions, and utilize multifactor\nauthentication for an extra layer of security.\n\nIndustrial Control System (ICS): A blanket term used to describe a collection\nof programmable logic controllers (PLCs), supervisory control and data\nacquisition (SCADA) systems, and various other control devices used to manage\nindustrial processes. Industrial control systems interpret data from sensors\nwith command functions and translate these inputs into actions that manipulate\ndevices such as valves, regulators, actuators, relays, or switches.\n\nInformation Sharing and Analysis Center (ISAC): A consortium of companies in a\nparticular industry created for the purpose of sharing data about computer\nsecurity threats and security best practices.\n\nInformation Technology (IT): Hardware and software that create, store,\nretrieve, transmit, and manipulate data.\n\nIntercontinental Ballistic Missile (ICBM): A land-based, guided missile\ncapable of traveling in excess of five thousand kilometers to deploy and\ndetonate one or more nuclear weapons on an enemy target(s).\n\nInternet of Things (IoT): The expanding network of devices that are internet\nconnected. This includes, but is not limited to, devices such as “smart”\nappliances, networked health-care equipment, and infrastructure monitoring\nelectronics. In the context of cybersecurity, Internet of Things devices are\nnotoriously insecure, and when used in an enterprise or otherwise sensitive\nsetting, can present a significant security risk to an organization.\n\nIslamic State in Syria (ISIS): A name widely used to denote a terrorist\norganization that calls itself simply Islamic State, and that Arab governments\ncall Daesh. The group occupied and controlled major cities during the\n2013–2017 period in Libya, Syria, and Iraq, and had cells elsewhere, including\nin Yemen and Afghanistan. As of 2019, it continues to exist in underground\ncells and in remote areas in the Middle East.\n\nMachine Learning (ML): The employment of algorithms to progressively train\nsoftware models to complete a specific task more effectively. Machine learning\nis often used to identify spam email, classify images, or, in the case of\ncybersecurity, detect malicious network traffic.\n\nMalware: Software that causes computers or networks to behave in an unintended\nmanner. Examples of malware include ransomware, Trojans, viruses, keyloggers,\nand worms.\n\nManaged Security Service Provider (MSSP): A company to which other firms\noutsource some security of their network.\n\nMultifactor Authentication (MFA): An authentication process that employs more\nthan one authenticating factor to grant a user access to a device,\napplication, network, or database. Multifactor authentication usually requires\nthat users provide something they know, something they have, and something\nthey are. Examples of these factors are passwords (which satisfy the knowledge\nrequirement), one-time log-in codes sent to a user’s phone (which satisfy the\npossession requirement), and fingerprints (which satisfy the inherence\nrequirement). Modern identity and access management software uses multifactor\nauthentication to prevent threat actors from maliciously gaining authenticated\naccess to a network.\n\nNational Institute of Standards and Technology (NIST): An agency within the\nU.S. Department of Commerce known for creating generally accepted norms and\nprocedures (standards), formerly called the Bureau of Weights and Measures.\n\nNorth American Electric Reliability Council (NERC): An association of electric\npower generation and distribution companies that issues standards and self-\nregulatory guidelines for the power industry in the United States and Canada.\nNERC seeks to preempt and prevent significant government regulation, which, in\nthe United States, would be issued by the Federal Energy Regulatory Commission\n(FERC).\n\nOperations Technology (OT): Hardware and software designed to facilitate\nmanufacturing processes and infrastructure operations.\n\nP5+1: The five permanent members of the United Nations Security Council\n(China, France, Russia, the United Kingdom, and the United States) and Germany\nwere the nations that negotiated the nuclear development restrictions\nagreement with Iran.\n\nPatch: A software update pushed over the internet by the software developer,\nusually to correct a mistake in code, including errors that may create the\npossibility of misuse of the software.\n\nPeople’s Liberation Army (PLA): The armed forces of the People’s Republic of\nChina.\n\nPersonally Identifiable Information (PII): Information about an individual\nthat can be used either on its own or in conjunction with information from\nother sources to identify the individual. Examples of PII are Social Security\nnumbers, addresses, dates of birth, passport numbers, and more.\n\nPresidential Decision Directive (PDD): A formal policy statement signed by the\nPresident of the United States, articulating decisions on a set of national\nsecurity issues. Traditionally, presidents from the Democratic Party use\nacronyms beginning with P for this purpose and those from the Republican Party\nuse similar acronyms beginning with N, as in NSPM 13 for National Security\nPolicy Memorandum 13. Bush-era documents are National Security presidential\ndirectives and Homeland Security presidential directives. Obama-era documents\nare presidential policy directives (PPDs).\n\nPrivileged Access Management (PAM): See “Identity and Access Management.” PAM\nsoftware protects extremely sensitive data and involves more extensive proof\nof identity to access that data.\n\nQuantum Computing: Computation that exploits quantum-mechanical phenomena such\nas superposition performed on particles called qubits. Classical computing\noperates digitally with bits that are in either an on or off state, 1 or 0.\nQubits can be in many states simultaneously, allowing greater computational\npower.\n\nRansomware: A form of malware that encrypts critical system files or user data\nand holds it for ransom, often instructing the user to send a payment in\ncryptocurrency to the malware author before the encryption key will be\nreleased.\n\nReallyU: A system proposed in this book to verify an identity online or in\nperson using a federated multifactor system created by consortiums of private\ncompanies and government agencies.\n\nRSA: The RSA Corporation, now a division of Dell, is a cybersecurity and\nencryption vendor, which created one of the first public key-encryption\nsystems. Also used to describe a series of annual conferences and exhibitions\non cybersecurity. The acronym is derived from the cofounders’ names: Rivest,\nShamir, and Adleman.\n\nSchengen Accord: A 1985 treaty signed by five of the then ten member states of\nthe European Economic Community that abolished internal border checks, and is\nthe basis for the free movement of EU citizens within the EU. The original\nagreement was superseded by the Schengen Convention in 1990, which adopted a\ncommon visa policy. The Schengen rules were incorporated into EU law in 1999.\n\nSecure Development Life Cycle (SDLC): A set of procedures first developed by\nMicrosoft to ensure that software was developed and then maintained in a\nsecure manner.\n\nSecure Segmented Diverse-Source Microgrid (SSDM): A proposal made in this book\nto create a system to generate electricity locally, including using\nalternative energy sources. The SSDM would not be connected to regional or\nnational networks.\n\nSecurity Operations Center (SOC): A physical location in a corporation where\ncomputer security specialists monitor the company’s network for signs of\nintrusion or other threats.\n\nSoftware as a Service (SaaS): A model in which a customer buys a subscription\nto use a piece of software for a finite period, contrasted with the license\nmodel in which the customer buys and then owns a copy of the software. For\nSaaS software models, the software may reside online rather than on the\ncustomers’ own machines.\n\nStuxnet: The popular name of software allegedly designed and utilized by the\nUnited States to destroy certain physical objects, specifically nuclear\nenrichment centrifuges at Natanz, Iran.\n\nSupervisory Control and Data Acquisition (SCADA): Software for networks of\ndevices that control systems of machines such as valves, pumps, generators,\nand transformers. SCADA software collects information about the condition and\nactivities of the system, and can use this data to execute commands.\n\nTabletop Exercise (TTX): Usually a meeting around a large conference table\nutilizing a fictional scenario, meant to simulate a meeting that would occur\nif a real event or series of events happened, often called a crisis management\nevent. TTXs are used to train personnel on their crisis roles and\nresponsibilities and to identify gaps in an organization’s preparedness or\nsecurity.\n\nTailored Access Operations (TAO): An office within the U.S. National Security\nAgency assigned the task of penetrating foreign information technology\nnetworks and targets of special significance or difficulty. TAO was\nreorganized and merged into Computer Network Operations in 2017.\n\nThreat Actor: An entity that regularly engages in unauthorized penetration of\ncomputer networks to access and exfiltrate information or to engage in\ndestructive activities on the network.\n\nTwo-Factor Authentication (2FA): A means of proving user identity in order to\nbe granted access to a device, application, network, or database. Two-factor\nauthentication usually requires that users provide something they know, and\nprove possession of something they have. Examples of these factors are\npasswords (which satisfy the knowledge requirement) and one-time log-in codes\nsent to a user’s phone (which satisfy the possession requirement). Multifactor\nauthentication (MFA) sometimes takes this a step further and may include a\nbiometric identification procedure such as a thumbprint, an iris scan, or\nfacial recognition.\n\nVirtual Private Network (VPN): An encrypted pathway or “tunnel” over the\ninternet usually from a remote site, such as one’s home, to an organization’s\nprimary network. VPNs are thought to be a secure means of accessing corporate\ndatabases and applications from off-site and may involve a corporate gateway\nthat examines the security status of the remote computer before granting\naccess.\n\nWiper: Sometimes rendered “wipr,” it is a software attack tool that erases all\ndata found on a device or network in such a manner that the erased data is not\nrecoverable. Wiperware may lurk on a network for days, waiting to be included\nin a network backup so that when the backup is mounted after an attack, the\nwiperware will activate and erase that too.\n\nYear Two Thousand (Y2K): Refers to an international effort prior to January 1,\n2000, to modify computer software in order to avoid an expected malfunction on\nthat date. There was a belief that failure to modify such software in time\nwould result in widespread failure of software-controlled devices and\nmachinery at 12:01 A.M. of 01/01/2000.\n\nZero-day vulnerability: A software attack tool that has never been used before\nand for which, therefore, no defense currently exists. A zero-day attack tool\nis an exploit that utilizes a previously unused vulnerability in software or\nhardware. _Zero Days_ is also the name of a 2016 documentary film about\nStuxnet, directed by Alex Gibney.\n\n\n# Acknowledgments and Disclosures\n\nAs we note in the text, the cyber workforce is stretched thin. We observed\nthis firsthand as we tried to schedule time with many of the people who appear\nin or have otherwise influenced what we write. Meetings were often canceled as\nincidents popped up or news headlines unfolded. Thus, we are grateful to those\nwho took time to share their insights and experience with us.\n\nIn one sense, this book was about a year in development from when our first\neditor at Penguin Press, Warren Bass, green-lit the project to when we\nfinalized the manuscript with the highly capable Emily Cunningham (we thank\nthem both). In another sense, it was about ten years in the making.\n\nIn the decade since we wrote _Cyber War,_ we have continued to learn and\ndebate the topic with countless professionals in the field. Too many people\nhave shaped our thinking to list them all here, but we are grateful to the\nbipartisan community of policy makers who care deeply about this issue and the\nlarge pool of practitioners and technologists who have patiently (and\nsometimes not so patiently) explained to us much of the technical minutiae of\nhow cyberspace works.\n\nAmong the many people who helped us with advice, research, or granted us\ninterviews are Ed Amoroso, Konstantinos Karagiannis, Wil Oxford, Bob Brennan,\nJim Gable, Seth Lloyd, Bob Ackerman, Peiter Zatko, Terry McAuliffe, Eric\nRosenbach, Chad Rigetti, Chris Weedbrook, Ray Rothrock, Chris Coleman, Simon\nRosenberg, John Livingston, Laura Rosenberger, Corey Schou, Phil Dunkelberger,\nJoe Weiss, Connor Pate, Erin Michelle Perri, Aaron Ach, Aaron Rinehart, Casey\nRosenthal, Dan Guido, Adam Shostack, Michael Sechrist, Todd Inskeep, Bill\nRose, Bill Phelps, Evan Wolff, John Woods, Phil Venables, Rohan Amin, Jason\nHealey, Chris Day, Norm Laudermilch, Malcolm Harkins, Dmitri Alperovitch,\nDustin Hillard, Fred Wilmot, Bryan Hurd, Jim Routh, Keith Alexander, Gary\nGagnon, Jeremy Grant, Ori Eisen, Dave Aitel, Andy Ozment, Neal Jenkins, Sameer\nBhalotra, Sounil Yu, Frank DiGiovanni, Evan Dornbush, Larry Zelvin, and Alex\nNiejelow.\n\nRob Knake fully acknowledges that many of his views on what the nation needs\nto do to secure itself were formed in the crucible of the Obama-era cyber\noffice at the National Security Council. Thus, they borrow from the insights\n(in no particular order) of Howard Schmidt, Miriam Perlberg, Sameer Bhalotra,\nDavid Edelman, Peter Lord, Andrew Scott, Robert Novy, Jennifer Silk, Andy\nOzment, Tom Donahue, Ryan Gillis, Chris Finan, Eric Greenwald, Ari Schwartz,\nAaron Cooper, Naomi Lefkovitz, Zach Nunn, Megan Stifel, Alex Niejelow, Samara\nMoore, Nathaniel Gleicher, Michael Daniel, Dan Prieto, and Earl Crane.\n\nThe crew at Good Harbor Security Risk Management has been a steady source of\nideas, comments, research, and encouragement. This book would not have been\npossible without the diligent work of Tyler Pedigo and Chris Kotyk,\nresearching and editing. Thanks also to Good Harbor president Emilian\nPapadopoulos, as well as Evan Sills, Jake Gilden, Paul Kumst, and Reda Baig.\n\nRob Knake would like to thank Jim Lindsay and Adam Segal at the Council on\nForeign Relations, and Stephen Flynn and Phil Anderson at Northeastern\nUniversity’s Global Resilience Institute for supporting his work on this book.\nMatt Cohen and Lorand Lasaki at the Council on Foreign Relations and Akash\nPatel, Nate Toll, Justin Haner, Rebecca Leeper, Duo Hong, and Emmanuel Ortega\nat Northeastern University all provided valuable research support.\n\nWe also wish to thank those who helped and advised and would rather not be\nnamed. They know who they are and that we are grateful.\n\nBecause we both are active as cyber consultants and cyber investment advisers,\nwe have also drawn on our day jobs for ideas. Lest anyone think that we have a\nconflict of interest from any past or current affiliation, in the spirit of\nfull disclosure we note the following relationships: Dick Clarke is an adviser\nto the Paladin Capital Group, one of the leading cybersecurity venture-capital\nfirms in the United States. He either has been or is now a member of the\ncorporate board of directors or the advisory board of the following cyber-\nrelated companies: Akamai, Bit9 + Carbon Black, MultiPlan, PGP, TruSTAR, Red\n5, Veracode, Nok Nok Labs, Wickr, HawkEye 360, BlueCat Networks, and Versive.\nHe has also consulted for a large number of firms, among them the following\ncyber-product companies: Symantec, Microsoft, RSA, McAfee, and SRA. He has\nsmall personal investments in several publicly traded cyber-related companies,\nincluding Apple.\n\nAs pertaining to companies mentioned in this book, Rob Knake advises Oracle\nCorporation, of which the Dyn Corporation is a subsidiary and Immensive, Inc.\nHe has been an adviser to Cylance and has done consulting work for Microsoft,\nNorthrop Grumman, and Booz Allen Hamilton. He has also consulted at the\nDepartment of Homeland Security as well as having been an employee there.\n\nAs required by law and security agreements signed by both authors as a\ncondition of their employment in the White House in past administrations, the\ntext of this book was reviewed by National Security Council staff to prevent\nany unauthorized disclosure of classified information.\n\n\n# Notes\n\nChapter 1: The Back of the Beast\n\n[Venture capital investment in\ncybersecurity](07_Chapter_1_The_Back_of.xhtml#EndnotePhraseInText0): Gertrude\nChavez-Dreyfuss, “Venture Capital Funding of Cybersecurity Firms Hit Record\nHigh in 2018: Report,” Reuters, January 17, 2019, [www.reuters.com/article/us-\nusa-cyber-investment/venture-capital-funding-of-cybersecurity-firms-hit-\nrecord-high-in-2018-report-idUSKCN1PB163](http://www.reuters.com/article/us-\nusa-cyber-investment/venture-capital-funding-of-cybersecurity-firms-hit-\nrecord-high-in-2018-report-idUSKCN1PB163).\n\n[Cyber insurance was\nlong](07_Chapter_1_The_Back_of.xhtml#EndnotePhraseInText1): “Aon: U.S. Cyber\nInsurance Premiums Rise 37%, to $1.84B,” _Claims Journal_ , July 11, 2018,\n[www.claimsjournal.com/news/national/2018/07/11/285644.htm](http://www.claimsjournal.com/news/national/2018/07/11/285644.htm).\n\n[It is a positive attribute of\ncyberspace](07_Chapter_1_The_Back_of.xhtml#EndnotePhraseInText2): For a\ndiscussion on the malleability of cyberspace as a man-made domain, see Dorothy\nDenning, “Rethinking the Cyber Domain and Deterrence,” _Joint Force Quarterly_\n77 (April 2015),\n[ndupress.ndu.edu/portals/68/documents/jfq/jfq-77/jfq-77_8-15_denning.pdf](http://ndupress.ndu.edu/portals/68/documents/jfq/jfq-77/jfq-77_8-15_denning.pdf),\nand Joseph S. Nye Jr., “Cyber Power,” Belfer Center, Harvard Kennedy School,\nHarvard University, May 2010,\n[www.belfercenter.org/sites/default/files/files/publication/cyber-\npower.pdf](http://www.belfercenter.org/sites/default/files/files/publication/cyber-\npower.pdf).\n\n[By some estimates, the digital\neconomy](07_Chapter_1_The_Back_of.xhtml#EndnotePhraseInText3): “How Big Is the\nDigital Economy?,” Bureau of Economic Analysis, U.S. Department of Commerce,\n[www.bea.gov/sites/default/files/2018-04/infographic-how-big-is-the-digital-\neconomy.pdf](http://www.bea.gov/sites/default/files/2018-04/infographic-how-\nbig-is-the-digital-economy.pdf).\n\n[McKinsey estimates\nthat](07_Chapter_1_The_Back_of.xhtml#EndnotePhraseInText4): James Manyika,\n“Digital Economy: Trends, Opportunities and Challenges,” McKinsey Global\nInstitute Research, May 2016,\n[www.ntia.doc.gov/files/ntia/publications/james_manyika_digital_economy_deba_may_16_v4.pdf](http://www.ntia.doc.gov/files/ntia/publications/james_manyika_digital_economy_deba_may_16_v4.pdf).\n\n[Presidential Decision Directive\n63](07_Chapter_1_The_Back_of.xhtml#EndnotePhraseInText5): Presidential\nDecision Directive/NSC-63, Critical Infrastructure Protection, May 22, 1998,\n[fas.org/irp/offdocs/pdd/pdd-63.htm](http://fas.org/irp/offdocs/pdd/pdd-63.htm).\n\n[Late in the Obama\nadministration](07_Chapter_1_The_Back_of.xhtml#EndnotePhraseInText6):\n“Stewardship of IANA Functions Transitions to Global Internet Community as\nContract with U.S. Government Ends,” ICANN, October 1, 2016,\n[www.icann.org/news/announcement-2016-10-01-en](http://www.icann.org/news/announcement-2016-10-01-en).\n\n[The best strategies can be summed\nup](07_Chapter_1_The_Back_of.xhtml#EndnotePhraseInText7): We borrowed this\nidea from Jason Healey at Columbia University, who attributes it to former\nNational Security Adviser Brent Scowcroft.\n\n[It’s the right idea](07_Chapter_1_The_Back_of.xhtml#EndnotePhraseInText8):\nJason Healey called for a “defense-dominant” strategy in a 2017 Atlantic\nCouncil report. Again, we like the approach but think the label is wrong. See\nJason Healey, “A Nonstate Strategy for Saving Cyberspace,” Atlantic Council\nStrategy Papers, January 2017,\n[www.atlanticcouncil.org/images/publications/AC_StrategyPapers_No8_Saving_Cyberspace_WEB.pdf](http://www.atlanticcouncil.org/images/publications/AC_StrategyPapers_No8_Saving_Cyberspace_WEB.pdf).\n\n[the word “resilience”](07_Chapter_1_The_Back_of.xhtml#EndnotePhraseInText9):\nSee, for example, Executive Order 13636 from the Obama administration, which\nstated: “It is the policy of the United States to enhance the security and\nresilience of the Nation’s critical infrastructure. . . .” “Executive\nOrder—Improving Critical Infrastructure Cybersecurity,” White House, February\n12, 2013, [obamawhitehouse.archives.gov/the-press-office/2013/02/12/executive-\norder-improving-critical-infrastructure-\ncybersecurity](http://obamawhitehouse.archives.gov/the-press-\noffice/2013/02/12/executive-order-improving-critical-infrastructure-\ncybersecurity). See also the Trump administration’s National Cyber Strategy,\nwhich made “foster[ing] a vibrant and resilient digital economy” one of its\npillars; White House, September 2018, [www.whitehouse.gov/wp-\ncontent/uploads/2018/09/National-Cyber-\nStrategy.pdf](http://www.whitehouse.gov/wp-content/uploads/2018/09/National-\nCyber-Strategy.pdf).\n\n[an ill-defined and vague\nconcept](07_Chapter_1_The_Back_of.xhtml#EndnotePhraseInText10): There is a\ndanger with an idea as vague and open-ended as cyber resilience. If the\nconcept just means accepting that losses will occur and recovering from them\nquickly, then it becomes part of the defeatist attitude in the field. Using a\nnarrow definition, Equifax, which lost every single one of its hundred-\nmillion-plus records of individuals’ credit reports, was perfectly resilient.\nThe incident never stopped the company from collecting more data or from\nselling it. A year after the breach, the company’s stock had recovered all its\nlosses. While anyone who bought Equifax on the way down and sold it before\nthird-quarter results came in would have something to celebrate, everyone else\nimpacted by the data breach would have tarred and feathered any executive at\nthe company who claimed that they were resilient.\n\n[For resilience to be a useful\nconcept](07_Chapter_1_The_Back_of.xhtml#EndnotePhraseInText11): In his book\n_Antifragile,_ Nassim Taleb suggested that “antifragility” was the next\nevolution beyond resilience, that we want to form businesses and societies\nthat are, in the words of Max Cleland, “strong at the broken places.”\nAntifragility is the right concept. But it was poor branding. Where the\nconcept of _The Black Swan,_ Taleb’s previous book, became widely used in\nbusiness schools and boardrooms, antifragility never did. It’s unfortunate\nbecause it is the right concept.\n\n[Rodin defines resilience\nas](07_Chapter_1_The_Back_of.xhtml#EndnotePhraseInText12): Judith Rodin, _The\nResilience Dividend: Being Strong in a World Where Things Go Wrong_ (New York:\nPublicAffairs, 2014), 3.\n\nChapter 2: EternalBlue, Eternal War\n\n[patients were sent\naway](08_Chapter_2_Eternalblue.xhtml#EndnotePhraseInText13): Damien Gayle,\nAlexandra Topping, Ian Sample, Sarah Marsh, and Vikram Dodd, “NHS seeks to\nrecover from global cyber-attack as security concerns resurface,” _Guardian,_\nMay 13, 2017, [www.theguardian.com/society/2017/may/12/hospitals-across-\nengland-hit-by-large-scale-cyber-\nattack](http://www.theguardian.com/society/2017/may/12/hospitals-across-\nengland-hit-by-large-scale-cyber-attack).\n\n[National Security Agency’s EternalBlue\nweapon](08_Chapter_2_Eternalblue.xhtml#EndnotePhraseInText14): Security\nResponse Team, “Petya ransomware outbreak: Here’s what you need to know,”\nSymantec Blogs/Threat Intelligence, October 24, 2017,\n[www.symantec.com/blogs/threat-intelligence/petya-ransomware-\nwiper](http://www.symantec.com/blogs/threat-intelligence/petya-ransomware-\nwiper).\n\n[damages cost them almost $900\nmillion](08_Chapter_2_Eternalblue.xhtml#EndnotePhraseInText15): Andy\nGreenberg, “The Untold Story of NotPetya, the Most Devastating Cyberattack in\nHistory,” _Wired_ , August 22, 2018, [www.wired.com/story/notpetya-\ncyberattack-ukraine-russia-code-crashed-the-\nworld](http://www.wired.com/story/notpetya-cyberattack-ukraine-russia-code-\ncrashed-the-world).\n\n[NotPetya was an\noperation](08_Chapter_2_Eternalblue.xhtml#EndnotePhraseInText16): Ellen\nNakashima, “Russian Military Was Behind ‘NotPetya’ Cyberattack in Ukraine, CIA\nConcludes,” _Washington Post,_ January 12, 2018,\n[wapo.st/2AV5FxW](http://wapo.st/2AV5FxW).\n\n[cyber tools without his personal\napproval](08_Chapter_2_Eternalblue.xhtml#EndnotePhraseInText17): David E.\nSanger, “Trump Loosens Secretive Restraints on Ordering Cyberattacks,” _New\nYork Times_ , September 20, 2018,\n[www.nytimes.com/2018/09/20/us/politics/trump-cyberattacks-\norders.html](http://www.nytimes.com/2018/09/20/us/politics/trump-cyberattacks-\norders.html).\n\n[removed those restrictions in\n2018](08_Chapter_2_Eternalblue.xhtml#EndnotePhraseInText18): Dustin Volz,\n“White House Confirms It Has Relaxed Rules on U.S. Use of Cyberweapons,” _Wall\nStreet Journal_ , September 20, 2018, [www.wsj.com/articles/white-house-\nconfirms-it-has-relaxed-rules-on-u-s-use-of-cyber-\nweapons-1537476729](http://www.wsj.com/articles/white-house-confirms-it-has-\nrelaxed-rules-on-u-s-use-of-cyber-weapons-1537476729).\n\n[One of those\nrecommendations](08_Chapter_2_Eternalblue.xhtml#EndnotePhraseInText19):\nRecommendation 30 of the NSA Review Group reads, “We recommend that the\nNational Security Council staff should manage an interagency process to review\non a regular basis the activities of the U.S. Government regarding attacks\nthat exploit a previously unknown vulnerability in a computer application or\nsystem. These are often called ‘Zero Day’ attacks because developers have had\nzero days to address and patch the vulnerability. U.S. policy should generally\nmove to ensure that Zero Days are quickly blocked, so that the underlying\nvulnerabilities are patched on U.S. Government and other networks. In rare\ninstances, U.S. policy may briefly authorize using a Zero Day for high\npriority intelligence collection, following senior, interagency review\ninvolving all appropriate departments.” See “Liberty and Security in a\nChanging World,” Report and Recommendations of the President’s Review Group on\nIntelligence and Communications Technologies, December 12, 2013.\n\n[issue a patch for the\nproblem](08_Chapter_2_Eternalblue.xhtml#EndnotePhraseInText20): Ellen\nNakashima and Craig Timberg, “NSA officials worried about the day its potent\nhacking tool would get loose. Then it did.,” _Washington Post_ , May 16, 2017,\n[www.washingtonpost.com/business/technology/nsa-officials-worried-about-the-\nday-its-potent-hacking-tool-would-get-loose-then-it-\ndid/2017/05/16/50670b16-3978-11e7-a058-ddbb23c75d82_story.html](http://www.washingtonpost.com/business/technology/nsa-\nofficials-worried-about-the-day-its-potent-hacking-tool-would-get-loose-then-\nit-did/2017/05/16/50670b16-3978-11e7-a058-ddbb23c75d82_story.html).\n\n[walking out of NSA\nfacilities](08_Chapter_2_Eternalblue.xhtml#EndnotePhraseInText21): Josh\nGerstein, “Judge Won’t Release Ex-NSA Contractor Accused of Hoarding\nClassified Data,” _Politico,_ October 21, 2016,\n[www.politico.com/story/2016/10/hal-harold-martin-nsa-classified-\ndata-230168](http://www.politico.com/story/2016/10/hal-harold-martin-nsa-\nclassified-data-230168).\n\n[Kaspersky denies that this is what\nhappened](08_Chapter_2_Eternalblue.xhtml#EndnotePhraseInText22): Shane Harris\nand Gordon Lubold, “Russian Hackers Stole NSA Data on U.S. Cyber Defense,”\n_Wall Street_ _Journal_ , October 5, 2017, [www.wsj.com/articles/russian-\nhackers-stole-nsa-data-on-u-s-cyber-\ndefense-1507222108](http://www.wsj.com/articles/russian-hackers-stole-nsa-\ndata-on-u-s-cyber-defense-1507222108).\n\n[Israel’s military intelligence Unit\n8200](08_Chapter_2_Eternalblue.xhtml#EndnotePhraseInText23): Alex Hern and\nPeter Beaumont, “Israel hack uncovered Russian spies’ use of Kaspersky in\n2015, report says,” _Guardian_ , October 11, 2017,\n[www.theguardian.com/technology/2017/oct/11/israel-hack-uncovered-russian-\nspies-use-kaspersky-lab-2015-report-us-software-federal-\ngovernment](http://www.theguardian.com/technology/2017/oct/11/israel-hack-\nuncovered-russian-spies-use-kaspersky-lab-2015-report-us-software-federal-\ngovernment).\n\n[no one in the U.S.\ngovernment](08_Chapter_2_Eternalblue.xhtml#EndnotePhraseInText24): Brad Smith,\n“The Need for Urgent Collective Action to Keep People Safe Online: Lessons\nfrom Last Week’s Cyberattack,” _Microsoft Blog,_ May 14, 2017,\n[blogs.microsoft.com/on-the-issues/2017/05/14/need-urgent-collective-action-\nkeep-people-safe-online-lessons-last-weeks-\ncyberattack](http://blogs.microsoft.com/on-the-issues/2017/05/14/need-urgent-\ncollective-action-keep-people-safe-online-lessons-last-weeks-cyberattack).\n\n[in the Vault 7\ndocuments](08_Chapter_2_Eternalblue.xhtml#EndnotePhraseInText25): Semantic\nSecurity Response, “Longhorn: Tools used by cyberespionage group linked to\nVault 7,” Symantec Official Blog, April 10, 2017,\n[www.symantec.com/connect/blogs/longhorn-tools-used-cyberespionage-group-\nlinked-vault-7](http://www.symantec.com/connect/blogs/longhorn-tools-used-\ncyberespionage-group-linked-vault-7).\n\n[groups known as APT 3 and APT\n10](08_Chapter_2_Eternalblue.xhtml#EndnotePhraseInText26): Andrew Griffin,\n“Wikileaks Files Detail CIA ‘Umbrage’ Project, Which Would Allow Spies to Pin\nAttacks on Other Countries,” _Independent_ , March 8, 2017,\n[www.independent.co.uk/life-style/gadgets-and-tech/news/wikileaks-files-cia-\numbrage-hacker-secret-spies-explained-countries-donald-trump-\nrussia-a7618661.html](http://www.independent.co.uk/life-style/gadgets-and-\ntech/news/wikileaks-files-cia-umbrage-hacker-secret-spies-explained-countries-\ndonald-trump-russia-a7618661.html).\n\n[most “reckless and\nindiscriminate”](08_Chapter_2_Eternalblue.xhtml#EndnotePhraseInText27): This\nquote is attributed to British Defense Secretary Gavin Williamson, said at a\nmeeting with U.S. Defense Secretary Jim Mattis and other defense ministers in\nBrussels in 2018.\n\n[shut down a French television\nnetwork](08_Chapter_2_Eternalblue.xhtml#EndnotePhraseInText28): Joseph Menn\nand Leigh Thomas, “France Probes Russian Lead in TV5Monde Hacking: Sources,”\nReuters, June 10, 2015, [reut.rs/1IGfCBo](http://reut.rs/1IGfCBo).\n\n[“the warning lights are blinking\nred”](08_Chapter_2_Eternalblue.xhtml#EndnotePhraseInText29): On July 13, 2018,\nDNI Coats made these statements at a Hudson Institute event regarding cyber\nthreats posed by Russia.\n\n[shut down by an Iranian\nattack](08_Chapter_2_Eternalblue.xhtml#EndnotePhraseInText30): David Sanger,\n“US Indicts 7 Iranians in Cyberattacks on Banks and a Dam,” _New York Times,_\nMarch 24, 2016, [www.nytimes.com/2016/03/25/world/middleeast/us-indicts-\niranians-in-cyberattacks-on-banks-and-a-\ndam.html](http://www.nytimes.com/2016/03/25/world/middleeast/us-indicts-\niranians-in-cyberattacks-on-banks-and-a-dam.html).\n\n[lethal chemical leak in the\nfuture](08_Chapter_2_Eternalblue.xhtml#EndnotePhraseInText31): Clifford Krauss\nand Nicole Perlroth, “A Cyberattack in Saudi Arabia Had a Deadly Goal. Experts\nFear Another Try.,” _New York Times_ , March 15, 2018,\n[www.nytimes.com/2018/03/15/technology/saudi-arabia-hacks-\ncyberattacks.html](http://www.nytimes.com/2018/03/15/technology/saudi-arabia-\nhacks-cyberattacks.html).\n\n[disrupt other nation’s cyber\nactivities](08_Chapter_2_Eternalblue.xhtml#EndnotePhraseInText32): Robert\nChesney, “The 2018 DOD Cyber Strategy: Understanding ‘Defense Forward’ in\nLight of the NDAA and PPD-20 Changes,” _Lawfare_ , September 25, 2018,\n[www.lawfareblog.com/2018-dod-cyber-strategy-understanding-defense-forward-\nlight-ndaa-and-ppd-20-changes](http://www.lawfareblog.com/2018-dod-cyber-\nstrategy-understanding-defense-forward-light-ndaa-and-ppd-20-changes).\n\nChapter 3: Two Kinds of Companies?\n\n[“If we have data”](10_Chapter_3_Two_Kinds_o.xhtml#EndnotePhraseInText33):\nNick Theodore, “‘We Have Data, Let’s Look at Data,’” Virtual Store Trials,\nJune 7, 2017, <https://casestudies.storetrials.com/we-have-data-lets-look-at-\ndata-e8a06e2e3331>.\n\n[Very quickly, CrowdStrike\nobserved](10_Chapter_3_Two_Kinds_o.xhtml#EndnotePhraseInText34): Joseph Menn,\n“China Tried to Hack U.S. Firms Even After Cyber Pact: CrowdStrike,” Reuters,\nOctober 19, 2015, [www.reuters.com/article/us-usa-china-cybersecurity-\nidUSKCN0SD0AT20151020](http://www.reuters.com/article/us-usa-china-\ncybersecurity-idUSKCN0SD0AT20151020).\n\n[Alperovitch wrote on the company\nblog](10_Chapter_3_Two_Kinds_o.xhtml#EndnotePhraseInText35): Dmitri\nAlperovitch, “The Latest on Chinese-affiliated Intrusions into Commercial\nCompanies,” CrowdStrike, October 19, 2015, [www.crowdstrike.com/blog/the-\nlatest-on-chinese-affiliated-intrusions-into-commercial-\ncompanies](http://www.crowdstrike.com/blog/the-latest-on-chinese-affiliated-\nintrusions-into-commercial-companies).\n\n[significant opponent of Obama-era\nrules](10_Chapter_3_Two_Kinds_o.xhtml#EndnotePhraseInText36): Rob Knake and\nAitel have a long-running feud over the VEP process. It’s complicated. For a\nmore thorough discussion, see Ari Schwartz and Rob Knake, “Government’s Role\nin Vulnerability Disclosure,” Cyber Security Project, Belfer Center, Harvard\nKennedy School, Harvard University, June 2016,\n[www.belfercenter.org/sites/default/files/legacy/files/vulnerability-\ndisclosure-web-\nfinal3.pdf](http://www.belfercenter.org/sites/default/files/legacy/files/vulnerability-\ndisclosure-web-final3.pdf); Dave Aitel and Matt Tait, “Everything You Know\nAbout the Vulnerability Equities Process Is Wrong,” _LawFare_ , August 18,\n2016, [www.lawfareblog.com/everything-you-know-about-vulnerability-equities-\nprocess-wrong](http://www.lawfareblog.com/everything-you-know-about-\nvulnerability-equities-process-wrong).\n\n[Only months after _Cyber War_ was\npublished](10_Chapter_3_Two_Kinds_o.xhtml#EndnotePhraseInText37): For a\nthorough discussion of Stuxnet, see Kim Zetter, _Countdown to Zero Day:\nStuxnet and the Launch of the_ _World’s First Digital Weapon_ (New York:\nCrown, 2014); for the movie version, see Alex Gibney’s 2016 documentary _Zero\nDays_.\n\n[there are seventy-seven Chinese APT groups\nalone](10_Chapter_3_Two_Kinds_o.xhtml#EndnotePhraseInText38): APT Groups and\nOperations is a publicly available Google Sheet maintained by Florian Roth,\nthe CTO at Nextron Systems, a German cybersecurity company. The database can\nbe accessed at\n[docs.google.com/spreadsheets/d/1H9_xaxQHpWaa4O_Son4Gx0YOIzlcBWMsdvePFX68EKU/edit#gid=361554658](http://docs.google.com/spreadsheets/d/1H9_xaxQHpWaa4O_Son4Gx0YOIzlcBWMsdvePFX68EKU/edit#gid=361554658).\n\n[the Department of Health and Human\nServices](10_Chapter_3_Two_Kinds_o.xhtml#EndnotePhraseInText39): The\nDepartment of Health and Human Services Breach Portal is available at\n[ocrportal.hhs.gov/ocr/breach/breach_report.jsf](http://ocrportal.hhs.gov/ocr/breach/breach_report.jsf).\n\n[When Inskeep and other\nresearchers](10_Chapter_3_Two_Kinds_o.xhtml#EndnotePhraseInText40): Inskeep’s\npresentation of this data at the 2018 RSA Conference can be accessed at\n[www.rsaconference.com/events/us18/agenda/sessions/10891-evidence-based-\nsecurity-the-new-top-five-\ncontrols](http://www.rsaconference.com/events/us18/agenda/sessions/10891-evidence-\nbased-security-the-new-top-five-controls). Knake advised Booz Allen Hamilton\non this project.\n\n[analysis of public information on cybersecurity\nincidents](10_Chapter_3_Two_Kinds_o.xhtml#EndnotePhraseInText41): This\nanalysis was performed by Akash Patel at Northeastern University’s Global\nResilience Institute, based on data from\n[www.privacyrights.org](http://www.privacyrights.org),\n[www.databreaches.net](http://www.databreaches.net),\n[www.idtheftcenter.org](http://www.idtheftcenter.org), ocrportal.hhs.gov,\n[www.krebsonsecurity.com](http://www.krebsonsecurity.com),\n[www.law360.com](http://www.law360.com), and the state attorneys general\nwebsites for California, Montana, New Jersey, and New Hampshire.\n\n[It is difficult to square the fact that in\n2013](10_Chapter_3_Two_Kinds_o.xhtml#EndnotePhraseInText42): Ellen Nakashima,\n“U.S. Notified 3,000 Companies in 2013 About Cyberattacks,” _Washington Post_\n, March 24, 2014, [www.washingtonpost.com/world/national-\nsecurity/2014/03/24/74aff686-aed9-11e3-96dc-d6ea14c099f9_story.html](http://www.washingtonpost.com/world/national-\nsecurity/2014/03/24/74aff686-aed9-11e3-96dc-d6ea14c099f9_story.html)\n\n[Keith Alexander, the former director of the\nNSA](10_Chapter_3_Two_Kinds_o.xhtml#EndnotePhraseInText43): See Alexander’s\nspeech at the American Enterprise Institute, Washington, D.C., July 9, 2012,\n[www.youtube.com/watch?v=JOFk44yy6IQ](http://www.youtube.com/watch?v=JOFk44yy6IQ).\n\n[“Basically, you are either dealing with\nMossad”](10_Chapter_3_Two_Kinds_o.xhtml#EndnotePhraseInText44): James Mickens,\n“This World of Ours,” Usenix.org, January 2014,\n[www.usenix.org/system/files/1401_08-12_mickens.pdf](http://www.usenix.org/system/files/1401_08-12_mickens.pdf).\n\n[National Institute of Standards and Technology (NIST, pronounced like\n“mist”)](10_Chapter_3_Two_Kinds_o.xhtml#EndnotePhraseInText45): The NIST\nCybersecurity Framework is available free to the public at\n[www.nist.gov/cyberframework](http://www.nist.gov/cyberframework).\n\n[known as the 800\nseries](10_Chapter_3_Two_Kinds_o.xhtml#EndnotePhraseInText46): NIST Special\nPublication 800-series General Information, May 21, 2018,\n[www.nist.gov/itl/nist-special-publication-800-series-general-\ninformation](http://www.nist.gov/itl/nist-special-publication-800-series-\ngeneral-information).\n\n[When Inskeep looked at last year’s\nreport](10_Chapter_3_Two_Kinds_o.xhtml#EndnotePhraseInText47): “2017 Data\nBreach Investigations Report,” 10th ed., Verizon,\n[www.ictsecuritymagazine.com/wp-content/uploads/2017-Data-Breach-\nInvestigations-Report.pdf](http://www.ictsecuritymagazine.com/wp-\ncontent/uploads/2017-Data-Breach-Investigations-Report.pdf).\n\nChapter 4: The Kill Chain\n\n[“Intelligence-Driven Computer Network\nDefense”](11_Chapter_4_The_Kill_Ch.xhtml#EndnotePhraseInText48): Eric\nHutchins, Michael Cloppert, and Rohan Amin, “Intelligence-Driven Computer\nNetwork Defense Informed by Analysis of Adversary Campaigns and Intrusion Kill\nChains,” Lockheed Martin Corporation, 2011,\n[www.lockheedmartin.com/content/dam/lockheed-martin/rms/documents/cyber/LM-\nWhite-Paper-Intel-Driven-\nDefense.pdf](http://www.lockheedmartin.com/content/dam/lockheed-\nmartin/rms/documents/cyber/LM-White-Paper-Intel-Driven-Defense.pdf).\n\n[He dubbed the chart](11_Chapter_4_The_Kill_Ch.xhtml#EndnotePhraseInText49):\nThe ATT&CK Matrix is conveniently located at <https://attack.mitre.org> (there\nis no ampersand in the web address).\n\nChapter 5: The Tech Stack\n\n[“not built to be\nused”](12_Chapter_5_The_Tech_St.xhtml#EndnotePhraseInText50): Pete Johnson,\n“#gluecon 2013 Day 2 Recap,” June 7, 2013, _Nerd Guru_(blog),\n<https://nerdguru.wordpress.com>.\n\n[The matrix tries to capture\neverything](12_Chapter_5_The_Tech_St.xhtml#EndnotePhraseInText51): Yu’s\npresentation of the Cyber Defense Matrix at the 2016 RSA Conference can be\nfound at\n[www.rsaconference.com/writable/presentations/file_upload/pdil-w02f_understanding_the_security_vendor_landscape...-final.pdf](http://www.rsaconference.com/writable/presentations/file_upload/pdil-w02f_understanding_the_security_vendor_landscape...-final.pdf).\n\n[“Solving Cybersecurity in the Next Five\nYears”](12_Chapter_5_The_Tech_St.xhtml#EndnotePhraseInText52): Yu’s\npresentation at the 2017 RSA Conference can be found at\n[www.youtube.com/watch?v=NckLpAEwkJE](http://www.youtube.com/watch?v=NckLpAEwkJE).\n\n[a concept borrowed from the\nmilitary](12_Chapter_5_The_Tech_St.xhtml#EndnotePhraseInText53): For a\nthorough discussion of the OODA loop, see Daniel Ford, _Vision So Noble: John\nBoyd, the OODA Loop, and America’s War on Terror_ (n.p.: CreateSpace\nIndependent Publishing Platform, 2010).\n\n[DevOps, short for “development and\noperations”](12_Chapter_5_The_Tech_St.xhtml#EndnotePhraseInText54): For a kind\nand gentle explanation of DevOps (in novel form) see Gene Kim, Kevin Behr, and\nGeorge Spafford, _The Phoenix Project: A Novel About IT, DevOps, and Helping\nYour Business Win_ (Glenside, Penn.: IT Revolution Press, 2013).\n\n[According to data from\nSpamhaus](12_Chapter_5_The_Tech_St.xhtml#EndnotePhraseInText55): The “Spamhaus\nBotnet Threat Report 2017” put Amazon at number two on its list, behind the\nFrench hosting provider OVH. See [www.spamhaus.org/news/article/772/spamhaus-\nbotnet-threat-report-2017](http://www.spamhaus.org/news/article/772/spamhaus-\nbotnet-threat-report-2017); rolling data from Spamhaus provided at\nwww.spamhaus.org/statistics/networks [inactive] showed Amazon as the number\nfour worst spammer on January 15, 2019.\n\n[how to defeat an APT\nactor](12_Chapter_5_The_Tech_St.xhtml#EndnotePhraseInText56): Rob Joyce’s\npresentation on “Disrupting NationState Hackers” at USENIX Enigma 2016\nconference, January 17, 2016, can be accessed at\n[www.youtube.com/watch?v=bDJb8WOJYdA](http://www.youtube.com/watch?v=bDJb8WOJYdA).\n\n[Amoroso, a member of the task\nforce](12_Chapter_5_The_Tech_St.xhtml#EndnotePhraseInText57): “Building a\nDefensible Cyberspace,” Report of the New York Cyber Taskforce, Columbia\nSchool of International and Public Affairs, November 2, 2017,\n[sipa.columbia.edu/sites/default/files/3668_SIPA%20Defensible%20Cyberspace-\nWEB.PDF](http://sipa.columbia.edu/sites/default/files/3668_SIPA%20Defensible%20Cyberspace-\nWEB.PDF).\n\n[dubbed Spectre and\nMeltdown](12_Chapter_5_The_Tech_St.xhtml#EndnotePhraseInText58): For a fuller\ndiscussion of Meltdown and Spectre, see Josh Fruhlinger, “Spectre and Meltdown\nExplained: What They Are, How They Work, What’s at Risk,” CSO Online, January\n15, 2018, [www.csoonline.com/article/3247868/vulnerabilities/spectre-and-\nmeltdown-explained-what-they-are-how-they-work-whats-at-\nrisk.html](http://www.csoonline.com/article/3247868/vulnerabilities/spectre-\nand-meltdown-explained-what-they-are-how-they-work-whats-at-risk.html).\n\n[Researchers at CrowdStrike\nuncovered](12_Chapter_5_The_Tech_St.xhtml#EndnotePhraseInText59): See Jason\nGeffner, “VENOM: Virtualized Environment Neglected Operations Manipulation,”\nCrowdStrike, May 21, 2015, venom.crowdstrike.com.\n\n[Mudge Zatko was the de facto\nleader](12_Chapter_5_The_Tech_St.xhtml#EndnotePhraseInText60): For a fuller\ntreatment, see Dennis Fisher, “‘We Got to Be Cool About This’: An Oral History\nof the LØpht,” Duo.com, March 6, 2018, [duo.com/decipher/an-oral-history-of-\nthe-l0pht](http://duo.com/decipher/an-oral-history-of-the-l0pht).\n\n[Taking a sample of](12_Chapter_5_The_Tech_St.xhtml#EndnotePhraseInText61):\nMudge Zatko’s PowerPoint presentation of this research at CanSecWest 2013 can\nbe found at [cansecwest.com/slides/2013/CanSecWest-Final-Mudge_v1-no-\nnotes.pptx](http://cansecwest.com/slides/2013/CanSecWest-Final-Mudge_v1-no-\nnotes.pptx) _._\n\n[By formally defining and\nverifying](12_Chapter_5_The_Tech_St.xhtml#EndnotePhraseInText62): There are a\nlot of problems still to be worked out in informal methods. For a thorough\ndiscussion, see Kathleen Fisher, “Using Formal Methods to Eliminate\nExploitable Bugs,” 24th USENIX Security Symposium, August 13, 2015,\n[www.usenix.org/conference/usenixsecurity15/technical-\nsessions/presentation/fisher](http://www.usenix.org/conference/usenixsecurity15/technical-\nsessions/presentation/fisher).\n\nChapter 6: Cyber Resilience: The Best Bad Idea We’ve Got\n\n[The websites of U.S. banks such as\nJPMorgan](13_Chapter_6_Cyber_Resil.xhtml#EndnotePhraseInText63): _United\nStates of America v. Ahmad Fathi_ , United States District Court, Southern\nDistrict of New York, March 24, 2016,\n[www.justice.gov/opa/file/834996/download](http://www.justice.gov/opa/file/834996/download);\nRob Knake has also written about these attacks in “Obama’s Cyberdoctrine,”\n_Foreign Affairs,_ May 6, 2016, [www.foreignaffairs.com/articles/united-\nstates/2016-05-06/obamas-\ncyberdoctrine](http://www.foreignaffairs.com/articles/united-\nstates/2016-05-06/obamas-cyberdoctrine).\n\n[“We’d like them to\nact”](13_Chapter_6_Cyber_Resil.xhtml#EndnotePhraseInText64): Siobhan Gorman\nand Danny Yadron, “Banks Seek U.S. Help on Iran Cyberattacks,” _Wall Street\nJournal_ , January 16, 2013,\n[www.wsj.com/articles/SB10001424127887324734904578244302923178548](http://www.wsj.com/articles/SB10001424127887324734904578244302923178548).\n\n[That study, released in\n1997](13_Chapter_6_Cyber_Resil.xhtml#EndnotePhraseInText65): “Critical\nFoundations: Protecting America’s Infrastructures,” Report of the President’s\nCommission on Critical Infrastructure Protection, October 1997,\n[fas.org/sgp/library/pccip.pdf](http://fas.org/sgp/library/pccip.pdf).\n\n[President Bush rescinded PDD\n63](13_Chapter_6_Cyber_Resil.xhtml#EndnotePhraseInText66): Homeland Security\nPresidential Directive HSPD 7, December 17, 2003,\n[www.energy.gov/oe/downloads/homeland-security-presidential-directive-\nhspd-7-december-17-2003](http://www.energy.gov/oe/downloads/homeland-security-\npresidential-directive-hspd-7-december-17-2003).\n\n[When a bipartisan group chaired by Jim\nLewis](13_Chapter_6_Cyber_Resil.xhtml#EndnotePhraseInText67): “Securing\nCyberspace for the 44th Presidency,” report of the CSIS Commission on\nCybersecurity for the 44th Presidency, Center for Strategic and International\nStudies, December 2008, [csis-prod.s3.amazonaws.com/s3fs-\npublic/legacy_files/files/media/csis/pubs/081208_securingcyberspace_44.pdf](http://csis-\nprod.s3.amazonaws.com/s3fs-\npublic/legacy_files/files/media/csis/pubs/081208_securingcyberspace_44.pdf).\n\n[Once President Obama came into\noffice](13_Chapter_6_Cyber_Resil.xhtml#EndnotePhraseInText68): “Cyberspace\nPolicy Review: Assuring a Trusted and Resilient Information and Communications\nInfrastructure,” White House, May 29, 2009, [fas.org/irp/eprint/cyber-\nreview.pdf](http://fas.org/irp/eprint/cyber-review.pdf).\n\n[With unusual candor](13_Chapter_6_Cyber_Resil.xhtml#EndnotePhraseInText69):\nFinancial data and information on its technology workforce is drawn from\nJPMorgan’s 2017 annual report, [www.jpmorganchase.com/corporate/investor-\nrelations/document/annualreport-2017.pdf](http://www.jpmorganchase.com/corporate/investor-\nrelations/document/annualreport-2017.pdf); data on JPMorgan’s cybersecurity\nspending is from “JPMorgan Chase Competitive Strategy Teardown: How The Bank\nStacks Up On Fintech & Innovation,” _CBInsights_ , January 11, 2018,\n[www.cbinsights.com/research/jpmorgan-chase-competitive-strategy-teardown-\nexpert-intelligence](http://www.cbinsights.com/research/jpmorgan-chase-\ncompetitive-strategy-teardown-expert-intelligence).\n\n[As Daniel explained](13_Chapter_6_Cyber_Resil.xhtml#EndnotePhraseInText70):\nMichael J. Daniel’s presentation at the 2013 RSA Conference, “007 or DDOS:\nWhat Is Real-World Cyber Policy?,”\n<https://obamawhitehouse.archives.gov/sites/default/files/docs/2013-02-28_final_rsa_speech.pdf>.\n\n[writing in the _Financial\nTimes_](13_Chapter_6_Cyber_Resil.xhtml#EndnotePhraseInText71) : Keith\nAlexander, “A Transatlantic Alliance Is Crucial in an Era of Cyberwarfare,”\n_Financial Times,_ September 4, 2018,\n[www.ft.com/content/c01a7f94-af81-11e8-87e0-d84e0d934341](http://www.ft.com/content/c01a7f94-af81-11e8-87e0-d84e0d934341).\n\n[Alan Charles Raul, the former vice\nchairman](13_Chapter_6_Cyber_Resil.xhtml#EndnotePhraseInText72): Alan Charles\nRaul, “Cyberdefense Is a Government Responsibility,” _Wall Street Journal_ ,\nJanuary 5, 2015, [www.wsj.com/articles/alan-charles-raul-cyberdefense-is-a-\ngovernment-responsibility-1420502942](http://www.wsj.com/articles/alan-\ncharles-raul-cyberdefense-is-a-government-responsibility-1420502942).\n\n[privacy impact\nassessments](13_Chapter_6_Cyber_Resil.xhtml#EndnotePhraseInText73): “Privacy\nImpact Assessments,”August 24, 2015, [www.dhs.gov/privacy-documents-national-\nprotection-and-programs-directorate-nppd](http://www.dhs.gov/privacy-\ndocuments-national-protection-and-programs-directorate-nppd).\n\n[Comprehensive National Cybersecurity\nInitiative](13_Chapter_6_Cyber_Resil.xhtml#EndnotePhraseInText74): “The\nComprehensive National Cybersecurity Initiative,”\n<https://obamawhitehouse.archives.gov/issues/foreign-\npolicy/cybersecurity/national-initiative>.\n\n[Enhanced Cybersecurity\nServices](13_Chapter_6_Cyber_Resil.xhtml#EndnotePhraseInText75): More\ninformation can be found at [www.dhs.gov/enhanced-cybersecurity-\nservices](http://www.dhs.gov/enhanced-cybersecurity-services).\n\n[This technical\nreality](13_Chapter_6_Cyber_Resil.xhtml#EndnotePhraseInText76): Joel Hruska,\n“UK Introduces Law to Ban Civilian Encryption, But Government Policies\nRecommend Its Use,” ExtremeTech.com, November 4, 2015,\n[www.extremetech.com/extreme/217478-uk-introduces-law-to-ban-civilian-\nencryption-but-government-policies-recommend-its-\nuse](http://www.extremetech.com/extreme/217478-uk-introduces-law-to-ban-\ncivilian-encryption-but-government-policies-recommend-its-use).\n\n[Nobody paid much attention\nuntil](13_Chapter_6_Cyber_Resil.xhtml#EndnotePhraseInText77): Corey Bennett,\n“John Bolton, Cyber Warrior,” _Politico,_ April 1, 2018,\n[www.politico.com/story/2018/04/01/john-bolton-cyber-hawk-\nrussia-451937](http://www.politico.com/story/2018/04/01/john-bolton-cyber-\nhawk-russia-451937).\n\n[the Active Cyber Defense Certainty\nAct](13_Chapter_6_Cyber_Resil.xhtml#EndnotePhraseInText78):\n[www.congress.gov/bill/115th-congress/house-\nbill/4036/text](http://www.congress.gov/bill/115th-congress/house-\nbill/4036/text).\n\n[In his classic _The Causes of\nWar_](13_Chapter_6_Cyber_Resil.xhtml#EndnotePhraseInText79)**:** Stephen Van\nEvera, _The Causes of War: Power and the Roots of Conflict_ (Ithaca, N.Y.:\nCornell University Press, 1999).\n\n[Allan Friedman and Peter Singer\nargue](13_Chapter_6_Cyber_Resil.xhtml#EndnotePhraseInText80): Allan Friedman\nand Peter Singer, “Cult of the Cyber Offensive,” _Foreign Policy,_ January 15,\n2014, [www.foreignpolicy.com/2014/01/15/cult-of-the-cyber-\noffensive](http://www.foreignpolicy.com/2014/01/15/cult-of-the-cyber-\noffensive).\n\n[When a group of Wall Street security\nexecutives](13_Chapter_6_Cyber_Resil.xhtml#EndnotePhraseInText81): “Building a\nDefensible Cyberspace,” New York Cyber Task Force, Columbia School of\nInternational and Public Affairs, November 2, 2017,\n<http://sipa.columbia.edu/sites/default/files/3668_SIPA%20Defensible%20Cyberspace-\nWEB.PDF>.\n\nChapter 7: Nudges and Shoves\n\n[the White House delivered to\nCongress](15_Chapter_7_Nudges_and_.xhtml#EndnotePhraseInText82): “Fact Sheet:\nCybersecurity Legislative Proposal,” White House, May 12, 2011,\n[obamawhitehouse.archives.gov/the-press-office/2011/05/12/fact-sheet-\ncybersecurity-legislative-proposal](http://obamawhitehouse.archives.gov/the-\npress-office/2011/05/12/fact-sheet-cybersecurity-legislative-proposal).\n\n[The CSIS commission\nreport](15_Chapter_7_Nudges_and_.xhtml#EndnotePhraseInText83): “Securing\nCyberspace for the 44th Presidency,” Report of the CSIS Commission on\nCybersecurity for the 44th Presidency, Center for Strategic and International\nStudies, December 2008, <https://csis-prod.s3.amazonaws.com/s3fs-\npublic/legacy_files/files/media/csis/pubs/081208_securingcyberspace_44.pdf>.\n\n[She pulled out a copy of a\nbook](15_Chapter_7_Nudges_and_.xhtml#EndnotePhraseInText84): Richard Thaler\nand Cass Sunstein, _Nudge:__Improving Decisions About Health, Wealth, and\nHappiness_ (New York: Penguin, 2009).\n\n[Twenty years ago, when President\nClinton](15_Chapter_7_Nudges_and_.xhtml#EndnotePhraseInText85): “Defending\nAmerica’s Cyberspace: National Plan for Information Systems Protection,” White\nHouse, 2000, <https://fas.org/irp/offdocs/pdd/CIP-plan.pdf>.\n\n[Surprisingly, the\nDepartment](15_Chapter_7_Nudges_and_.xhtml#EndnotePhraseInText86): U.S.\nDepartment of Homeland Security Cybersecurity Strategy, May 15, 2018,\n[www.dhs.gov/sites/default/files/publications/DHS-Cybersecurity-\nStrategy_1.pdf](http://www.dhs.gov/sites/default/files/publications/DHS-\nCybersecurity-Strategy_1.pdf).\n\n[Regulation E of the Electronic Funds Transfer\nAct](15_Chapter_7_Nudges_and_.xhtml#EndnotePhraseInText87): Robert K. Knake,\n“No, the FDIC Doesn’t Insure Your Bank Account Against Cybercrime (and Why\nThat Is OK),” Council on Foreign Relations, December 2, 2015,\n[www.cfr.org/blog/no-fdic-doesnt-insure-your-bank-account-against-cybercrime-\nand-why-ok](http://www.cfr.org/blog/no-fdic-doesnt-insure-your-bank-account-\nagainst-cybercrime-and-why-ok).\n\n[The Ponemon Institute](15_Chapter_7_Nudges_and_.xhtml#EndnotePhraseInText88):\n“2017 Cost of Data Breach Study,” Ponemon Institute, June 2017,\ninfo.resilientsystems.com/hubfs/IBM_Resilient_Branded_Content/White_Papers/2017_Global_CODB_Report_Final.pdf\n[inactive].\n\n[Oil tankers operating in U.S.\nwaters](15_Chapter_7_Nudges_and_.xhtml#EndnotePhraseInText89): Robert K.\nKnake, “To Prevent Another Equifax Breach, Treat Data Leaks Like Oil Spills,”\nCouncil on Foreign Relations, September 8, 2017, [www.cfr.org/blog/prevent-\nanother-equifax-breach-treat-data-leaks-oil-\nspills](http://www.cfr.org/blog/prevent-another-equifax-breach-treat-data-\nleaks-oil-spills).\n\n[California has required since\n2012](15_Chapter_7_Nudges_and_.xhtml#EndnotePhraseInText90): “California\nAttorney General Concludes That Failing to Implement the Center for Internet\nSecurity’s (CIS) Critical Security Controls ‘Constitutes a Lack of Reasonable\nSecurity,’” Center for Internet Security, February 22, 2016,\n[www.prnewswire.com/news-releases/california-attorney-general-concludes-that-\nfailing-to-implement-the-center-for-internet-securitys-cis-critical-security-\ncontrols-constitutes-a-lack-of-reasonable-\nsecurity-300223659.html](http://www.prnewswire.com/news-releases/california-\nattorney-general-concludes-that-failing-to-implement-the-center-for-internet-\nsecuritys-cis-critical-security-controls-constitutes-a-lack-of-reasonable-\nsecurity-300223659.html).\n\n[In September 2018, Governor Jerry\nBrown](15_Chapter_7_Nudges_and_.xhtml#EndnotePhraseInText91): Adi Robertson,\n“California Just Became the First State with an Internet of Things\nCybersecurity Law,” The Verge, September 28, 2018,\n[www.theverge.com/2018/9/28/17874768/california-iot-smart-device-\ncybersecurity-bill-sb-327-signed-\nlaw](http://www.theverge.com/2018/9/28/17874768/california-iot-smart-device-\ncybersecurity-bill-sb-327-signed-law).\n\n[Ohio enacted legislation in\n2018](15_Chapter_7_Nudges_and_.xhtml#EndnotePhraseInText92): Michael Kassner,\n“Ohio Law Creates Cybersecurity ‘Safe Harbor’ for Businesses,” TechRepublic,\nJanuary 3, 2019, [www.techrepublic.com/article/ohio-law-creates-cybersecurity-\nsafe-harbor-for-businesses](http://www.techrepublic.com/article/ohio-law-\ncreates-cybersecurity-safe-harbor-for-businesses).\n\n[New York’s Department of Financial\nServices](15_Chapter_7_Nudges_and_.xhtml#EndnotePhraseInText93): Nate Lord,\n“What Is the NYDFS Cybersecurity Regulation? A Cybersecurity Compliance\nRequirement for Financial Institutions,” Digital Guardian, January 3, 2019,\n[digitalguardian.com/blog/what-nydfs-cybersecurity-regulation-new-\ncybersecurity-compliance-requirement-\nfinancial](http://digitalguardian.com/blog/what-nydfs-cybersecurity-\nregulation-new-cybersecurity-compliance-requirement-financial).\n\n[According to Chris\nDemchak](15_Chapter_7_Nudges_and_.xhtml#EndnotePhraseInText94): Chris C.\nDemchak and Yuval Shavitt, “China’s Maxim—Leave No Access Point Unexploited:\nThe Hidden Story of China Telecom’s BGP Hijacking,” _Military Cyber Affairs_\n3, no. 1, article 7 (2018),\n[doi.org/10.5038/2378-0789.3.1.1050](http://doi.org/10.5038/2378-0789.3.1.1050).\n\n[regularly redirecting internet\ntraffic](15_Chapter_7_Nudges_and_.xhtml#EndnotePhraseInText95): Justin\nSherman, “Hijacking the Internet Is Far Too Easy,” _Slate,_ November 16, 2018,\n[slate.com/technology/2018/11/bgp-hijacking-russia-china-protocols-redirect-\ninternet-traffic.html](http://slate.com/technology/2018/11/bgp-hijacking-\nrussia-china-protocols-redirect-internet-traffic.html).\n\n[Zurich, the big Swiss insurance\ncompany](15_Chapter_7_Nudges_and_.xhtml#EndnotePhraseInText96): Steve Evans,\n“Mondelez’s NotPetya Cyber Attack Claim Disputed by Zurich,” Reinsurance News,\nDecember 17, 2018, [www.reinsurancene.ws/mondelezs-notpetya-cyber-attack-\nclaim-disputed-by-zurich-report](http://www.reinsurancene.ws/mondelezs-\nnotpetya-cyber-attack-claim-disputed-by-zurich-report).\n\n[According to the Royal Canadian Mounted\nPolice](15_Chapter_7_Nudges_and_.xhtml#EndnotePhraseInText97): “Ransomware:\nRecognize, Reject, and Report It!,” Royal Canadian Mounted Police, Scams and\nFrauds, accessed on January 15, 2019, [www.rcmp-grc.gc.ca/scams-\nfraudes/ransomware-rancongiciels-eng.htm#fn1](http://www.rcmp-grc.gc.ca/scams-\nfraudes/ransomware-rancongiciels-eng.htm#fn1).\n\n[The two Iranians\nwrote](15_Chapter_7_Nudges_and_.xhtml#EndnotePhraseInText98): “SamSam\nSubjects,” wanted poster, Federal Bureau of Investigation, accessed on January\n15, 2019, [www.fbi.gov/wanted/cyber/samsam-\nsubjects](http://www.fbi.gov/wanted/cyber/samsam-subjects).\n\n[declined to pay the fifty-thousand-dollar\ndemand](15_Chapter_7_Nudges_and_.xhtml#EndnotePhraseInText99): Chris Teale,\n“Atlanta Mayor Says Cyberattack Came as ‘Surprise’ to City, Residents,” Smart\nCities Dive, May 11, 2018, [www.smartcitiesdive.com/news/atlanta-cyberattack-\nsurprise-Keisha-Lance-\nBottoms/523323](http://www.smartcitiesdive.com/news/atlanta-cyberattack-\nsurprise-Keisha-Lance-Bottoms/523323).\n\nChapter 8: Is It Really You?\n\n[“rely less and less on\npasswords”](16_Chapter_8_Is_It_Reall.xhtml#EndnotePhraseInText100): Munir\nKotadia, “Gates Predicts Death of the Password,” CNET, February 25, 2004,\n[www.cnet.com/news/gates-predicts-death-of-the-\npassword](http://www.cnet.com/news/gates-predicts-death-of-the-password).\n\n[President Bush\nsigned](16_Chapter_8_Is_It_Reall.xhtml#EndnotePhraseInText101): Homeland\nSecurity Presidential Directive 12: Policy for a Common Identification\nStandard for Federal Employees and Contractors, White House, August 27, 2004,\n[www.dhs.gov/homeland-security-presidential-\ndirective-12](http://www.dhs.gov/homeland-security-presidential-directive-12).\n\n[So can anyone else with that\ninformation](16_Chapter_8_Is_It_Reall.xhtml#EndnotePhraseInText102): “Key IRS\nIdentity Theft Indicators Continue Dramatic Decline in 2017; Security Summit\nMarks 2017 Progress Against Identity Theft,” Internal Revenue Service,\nFebruary 8, 2018, [www.irs.gov/newsroom/key-irs-identity-theft-indicators-\ncontinue-dramatic-decline-in-2017-security-summit-marks-2017-progress-against-\nidentity-theft](http://www.irs.gov/newsroom/key-irs-identity-theft-indicators-\ncontinue-dramatic-decline-in-2017-security-summit-marks-2017-progress-against-\nidentity-theft).\n\n[One of the first\ninitiatives](16_Chapter_8_Is_It_Reall.xhtml#EndnotePhraseInText103): “National\nStrategy for Trusted Identities in Cyberspace,” White House, April 2011,\n[www.hsdl.org/?view&did=7010](http://www.hsdl.org/?view&did=7010).\n\n[Grant has helped bring\ntogether](16_Chapter_8_Is_It_Reall.xhtml#EndnotePhraseInText104): See Better\nIdentity Coalition, About Us,\n[www.betteridentity.org](http://www.betteridentity.org).\n\nChapter 9: Fixing the People Problem\n\n[fifty thousand new cybersecurity\npractitioners](17_Chapter_9_Fixing_the_.xhtml#EndnotePhraseInText105): “Report\non Securing and Growing the Digital Economy,” Commission on Enhancing National\nCybersecurity” December 1, 2016,\n[obamawhitehouse.archives.gov/sites/default/files/docs/cybersecurity_report.pdf](http://obamawhitehouse.archives.gov/sites/default/files/docs/cybersecurity_report.pdf).\n\nChapter 10: Power Grids and Power Plays\n\n[Bush’s 2003 National Strategy to Secure\nCyberspace](18_Chapter_10_Power_Grid.xhtml#EndnotePhraseInText106): “The\nNational Strategy to Secure Cyberspace,” White House, February 2003, [www.us-\ncert.gov/sites/default/files/publications/cyberspace_strategy.pdf](http://www.us-\ncert.gov/sites/default/files/publications/cyberspace_strategy.pdf).\n\n[an internet worm](18_Chapter_10_Power_Grid.xhtml#EndnotePhraseInText107):\n“Final Report on the August 14, 2003 Blackout in the United States and Canada:\nCauses and Recommendations,” U.S.-Canada Power System Outage Task Force, U.S.\nDepartment of Energy, April 2004,\n[www.energy.gov/sites/prod/files/oeprod/DocumentsandMedia/BlackoutFinal-\nWeb.pdf](http://www.energy.gov/sites/prod/files/oeprod/DocumentsandMedia/BlackoutFinal-\nWeb.pdf).\n\n[a generator was\nattacked](18_Chapter_10_Power_Grid.xhtml#EndnotePhraseInText108): Emanuel\nBernabeu and Farid Katiraei, “Aurora Vulnerability: Issues and Solutions,”\nQuanta Technology and Dominion _,_ July 24, 2011,\n[www.smartgrid.gov/files/Aurora_Vulnerability_Issues_Solution_Hardware_Mitigation_De_201102.pdf](http://www.smartgrid.gov/files/Aurora_Vulnerability_Issues_Solution_Hardware_Mitigation_De_201102.pdf).\n\n[Russian hackers plunged much of\nUkraine](18_Chapter_10_Power_Grid.xhtml#EndnotePhraseInText109): Jim Finkle,\n“US Firm Blames Russian ‘Sandworm’ Hackers for Ukraine Outage,” Reuters,\nJanuary 7, 2016, [reut.rs/1OebtCB](http://reut.rs/1OebtCB).\n\n[Bruce Willis’s _Live Free or Die\nHard_](18_Chapter_10_Power_Grid.xhtml#EndnotePhraseInText110) : In the movie,\nBruce Willis squared off against a villainous ex-government cybersecurity\nexpert that Manohla Dargis thought was inspired by Clarke. Manohla Dargis,\n“Pick Your Poison: Fists or Fireballs,” _New York Times_ , June 27, 2007,\n[www.nytimes.com/2007/06/27/movies/27hard.html](http://www.nytimes.com/2007/06/27/movies/27hard.html).\n\n[lower the threshold of incident\nreporting](18_Chapter_10_Power_Grid.xhtml#EndnotePhraseInText111): “FERC\nRequires Expanded Cybersecurity Incident Reporting,” Federal Energy Regulatory\nCommission, July 19, 2018, [www.ferc.gov/media/news-\nreleases/2018/2018-3/07-19-18-E-1.asp](http://www.ferc.gov/media/news-\nreleases/2018/2018-3/07-19-18-E-1.asp).\n\n[DoD Missile Defense\nAgency](18_Chapter_10_Power_Grid.xhtml#EndnotePhraseInText112): “Historical\nFunding for MDA FY85-17,” U.S. Department of Defense Missile Defense Agency,\naccessed January 8, 2019, mda.mil/global/documents/pdf/FY17_histfunds.pdf\n[inactive].\n\n[Congress approved $11.5\nbillion](18_Chapter_10_Power_Grid.xhtml#EndnotePhraseInText113): Mike Stone,\n“U.S. Missile Defense Agency Budget Boosted to $11.5 Billion,” Reuters, March\n22, 2018, [reut.rs/2GdhC8R](http://reut.rs/2GdhC8R).\n\n[upwards of $140\nbillion](18_Chapter_10_Power_Grid.xhtml#EndnotePhraseInText114): Jeff Daniels,\n“Competition to Replace US Nuclear Missiles Is Down to 2 Companies, but\nUncertainties Remain,” CNBC, August 22, 2017,\n[cnb.cx/2xaP8oY](http://cnb.cx/2xaP8oY).\n\nChapter 12: The Military, Domains, and Dominance\n\n[cyber operations to the\nPentagon](21_Chapter_12_The_Milita.xhtml#EndnotePhraseInText115): Ellen\nNakashima, “White House authorizes ‘offensive cyber operations’ to deter\nforeign adversaries,” _Washington Post_ , September 20, 2018,\n[www.washingtonpost.com/world/national-security/trump-authorizes-offensive-\ncyber-operations-to-deter-foreign-adversaries-bolton-\nsays/2018/09/20/b5880578-bd0b-11e8-b7d2-0773aa1e33da_story.html](http://www.washingtonpost.com/world/national-\nsecurity/trump-authorizes-offensive-cyber-operations-to-deter-foreign-\nadversaries-bolton-\nsays/2018/09/20/b5880578-bd0b-11e8-b7d2-0773aa1e33da_story.html).\n\n[President Obama had reined in cyber\noperations](21_Chapter_12_The_Milita.xhtml#EndnotePhraseInText116): David E.\nSanger, “Pentagon Puts Cyberwarriors on the Offensive, Increasing Risk of\nConflict,” _New_ _York Times_ , June 17, 2018,\n[www.nytimes.com/2018/06/17/us/politics/cyber-command-\ntrump.html](http://www.nytimes.com/2018/06/17/us/politics/cyber-command-\ntrump.html).\n\n[five stated\nobjectives](21_Chapter_12_The_Milita.xhtml#EndnotePhraseInText117): “1.\nEnsuring the Joint Force can achieve its missions in a contested cyberspace\nenvironment; 2. Strengthening the Joint Force by conducting cyberspace\noperations that enhance U.S. military advantages; 3. Defending U.S. critical\ninfrastructure from malicious cyber activity that alone, or as part of a\ncampaign, could cause a significant cyber incident; 4. Securing DoD\ninformation and systems against malicious cyber activity, including DoD\ninformation on non-DoD-owned networks; and 5. Expanding DoD cyber cooperation\nwith interagency, industry, and international partners.” See “Summary:\nDepartment of Defense Cyber Strategy 2018,” U.S. Department of Defense,\nSeptember 2018,\n[media.defense.gov/2018/Sep/18/2002041658/-1/-1/1/CYBER_STRATEGY_SUMMARY_FINAL.PDF](http://media.defense.gov/2018/Sep/18/2002041658/-1/-1/1/CYBER_STRATEGY_SUMMARY_FINAL.PDF).\n\n[Iran did penetrate](21_Chapter_12_The_Milita.xhtml#EndnotePhraseInText118):\nJulian E. Barnes and Siobhan Gorman, “U.S. Says Iran Hacked Navy Computers,”\n_Wall Street Journal_ , September 27, 2013, [www.wsj.com/articles/us-says-\niran-hacked-navy-computers-1380314771](http://www.wsj.com/articles/us-says-\niran-hacked-navy-computers-1380314771).\n\n[successfully used wiper\nhacks](21_Chapter_12_The_Milita.xhtml#EndnotePhraseInText119): Lily Hay\nNewman, “The Iran Hacks Cybersecurity Experts Feared May Be Here,” _Wired,_\nDecember 18, 2018, [www.wired.com/story/iran-hacks-nuclear-deal-shamoon-\ncharming-kitten](http://www.wired.com/story/iran-hacks-nuclear-deal-shamoon-\ncharming-kitten).\n\n[issued a scathing\nreport](21_Chapter_12_The_Milita.xhtml#EndnotePhraseInText120): “Weapon\nSystems Cybersecurity,” Report to the Committee on Armed Services, U.S.\nSenate, GAO-19-128, Government Accountability Office, October 2018,\n[www.gao.gov/assets/700/694913.pdf](http://www.gao.gov/assets/700/694913.pdf).\n\n[USS _Freedom_ -class combatants are vulnerable to\nhacking](21_Chapter_12_The_Milita.xhtml#EndnotePhraseInText121): Andrea\nShalal-Esa, “Cyber vulnerabilities found in Navy’s newest warship: official,”\nReuters, April 23, 2013, [www.reuters.com/article/us-usa-cybersecurity-\nship/cyber-vulnerabilities-found-in-navys-newest-warship-official-\nidUSBRE93N02X20130424](http://www.reuters.com/article/us-usa-cybersecurity-\nship/cyber-vulnerabilities-found-in-navys-newest-warship-official-\nidUSBRE93N02X20130424).\n\n[Naval Undersea Warfare Center in Rhode\nIsland](21_Chapter_12_The_Milita.xhtml#EndnotePhraseInText122): Gordon Lubold\nand Dustin Volz, “Navy, Industry Partners are ‘Under Cyber Siege’ by Chinese\nHackers, Review Asserts,” _Wall Street Journal_ , March 12, 2019,\n[www.wsj.com/articles/navy-industry-partners-are-under-cyber-siege-review-\nasserts-11552415553](http://www.wsj.com/articles/navy-industry-partners-are-\nunder-cyber-siege-review-asserts-11552415553).\n\n[Windows XP operating\nsystem](21_Chapter_12_The_Milita.xhtml#EndnotePhraseInText123): Jeremy Hsu,\n“Why the Military Can’t Quit Windows XP,” _Slate,_ June 4, 2018,\n[slate.com/technology/2018/06/why-the-military-cant-quit-windows-\nxp.html](http://slate.com/technology/2018/06/why-the-military-cant-quit-\nwindows-xp.html).\n\n[Among the weapons systems\ncompromised](21_Chapter_12_The_Milita.xhtml#EndnotePhraseInText124): Caitlin\nDewey, “The US Weapons Systems That Experts Say Were Hacked by the Chinese,”\n_Washington Post_ , May 28, 2013, [wapo.st/18qIQBk](http://wapo.st/18qIQBk).\n\n[he was “largely\ndisappointed”](21_Chapter_12_The_Milita.xhtml#EndnotePhraseInText125): Ash\nCarter, “A Lasting Defeat: The Campaign to Destroy ISIS,” Belfer Center,\nHarvard Kennedy School, Harvard University, October 2017,\n[www.belfercenter.org/publication/lasting-defeat-campaign-destroy-\nisis](http://www.belfercenter.org/publication/lasting-defeat-campaign-destroy-\nisis).\n\n[operations without his personal\napproval](21_Chapter_12_The_Milita.xhtml#EndnotePhraseInText126): David E.\nSanger, “Trump Loosens Secretive Restraints on Ordering Cyberattacks,” New\nYork Times, September 20, 2018, [www.nytimes.com/2018/09/20/us/politics/trump-\ncyberattacks-orders.html](http://www.nytimes.com/2018/09/20/us/politics/trump-\ncyberattacks-orders.html).\n\n[The CIA and the NSA\ndid](21_Chapter_12_The_Milita.xhtml#EndnotePhraseInText127): James Bamford,\n“NSA Snooping Was Only the Beginning. Meet the Spy Chief Leading Us into\nCyberwar,” _Wired_ , June 12, 2013, [www.wired.com/2013/06/general-keith-\nalexander-cyberwar](http://www.wired.com/2013/06/general-keith-alexander-\ncyberwar).\n\n[authorized a contingency\nplan](21_Chapter_12_The_Milita.xhtml#EndnotePhraseInText128): David E. Sanger\nand Mark Mazzetti, “U.S. Had Cyberattack Plan If Iran Nuclear Dispute Led to\nConflict,” _New York Times_ , February 16, 2016,\n[www.nytimes.com/2016/02/17/world/middleeast/us-had-cyberattack-planned-if-\niran-nuclear-negotiations-\nfailed.html](http://www.nytimes.com/2016/02/17/world/middleeast/us-had-\ncyberattack-planned-if-iran-nuclear-negotiations-failed.html).\n\n[They were not given that authority until\n2018](21_Chapter_12_The_Milita.xhtml#EndnotePhraseInText129): Robert Chesney,\n“The 2018 DOD Cyber Strategy: Understanding ‘Defense Forward’ in Light of the\nNDAA and PPD-20 Changes,” Lawfare, September 25, 2018,\n[www.lawfareblog.com/2018-dod-cyber-strategy-understanding-defense-forward-\nlight-ndaa-and-ppd-20-changes](http://www.lawfareblog.com/2018-dod-cyber-\nstrategy-understanding-defense-forward-light-ndaa-and-ppd-20-changes).\n\n[In the 2018 Department of Defense Cyber\nStrategy](21_Chapter_12_The_Milita.xhtml#EndnotePhraseInText130): “Department\nof Defense Cyber Strategy Summary,” Department of Defense, 2018,\n<https://media.defense.gov/2018/Sep/18/2002041658/-1/-1/1/CYBER_STRATEGY_SUMMARY_FINAL.PDF>.\n\n[North Korean ballistic missile\ntests](21_Chapter_12_The_Milita.xhtml#EndnotePhraseInText131): David E. Sanger\nand William J. Broad, “Trump Inherits a Secret Cyberwar Against North Korean\nMissiles,” _New York_ _Times,_ March 4, 2017,\n[www.nytimes.com/2017/03/04/world/asia/north-korea-missile-program-\nsabotage.html](http://www.nytimes.com/2017/03/04/world/asia/north-korea-\nmissile-program-sabotage.html).\n\n[authority to the Department of\nDefense](21_Chapter_12_The_Milita.xhtml#EndnotePhraseInText132): Dakota S.\nRudesill, “Trump’s Secret Order on Pulling the Cyber Trigger,” _Lawfare_ ,\nAugust 29 2018, [www.lawfareblog.com/trumps-secret-order-pulling-cyber-\ntrigger](http://www.lawfareblog.com/trumps-secret-order-pulling-cyber-\ntrigger).\n\nChapter 13: A Schengen Accord for the Internet\n\n[“Cyberspace is not\nborderless”](22_Chapter_13_A_Schengen.xhtml#EndnotePhraseInText133): Author\ninterview with Michael Daniel, 2019.\n\n[Eric Schmidt thinks the\ninternet](22_Chapter_13_A_Schengen.xhtml#EndnotePhraseInText134): Lora\nKolodny, “Former Google CEO Predicts the Internet Will Split in Two—And One\nPart Will Be Led by China,” CNBC, September 20, 2018,\n[www.cnbc.com/2018/09/20/eric-schmidt-ex-google-ceo-predicts-internet-split-\nchina.html](http://www.cnbc.com/2018/09/20/eric-schmidt-ex-google-ceo-\npredicts-internet-split-china.html).\n\n[**the** _New York Times_ editorial\nboard](22_Chapter_13_A_Schengen.xhtml#EndnotePhraseInText135): Editorial\nBoard, “There May Soon Be Three Internets. America’s Won’t Necessarily Be the\nBest,” _New York Times,_ October 15, 2018,\n[www.nytimes.com/2018/10/15/opinion/internet-google-china-\nbalkanization.html](http://www.nytimes.com/2018/10/15/opinion/internet-google-\nchina-balkanization.html).\n\n[“open, interoperable, secure, and\nreliable”](22_Chapter_13_A_Schengen.xhtml#EndnotePhraseInText136):\n“International Strategy for Cyberspace: Prosperity, Security, and Openness in\na Networked World,” White House, May 2011,\n<https://obamawhitehouse.archives.gov/sites/default/files/rss_viewer/international_strategy_for_cyberspace.pdf>.\n\n[While Russia announced\nplans](22_Chapter_13_A_Schengen.xhtml#EndnotePhraseInText137): Tracy Staedter,\n“Why Russia Is Building Its Own Internet,” IEEE Spectrum, January 17, 2018,\n[spectrum.ieee.org/tech-talk/telecom/internet/could-russia-really-build-its-\nown-alternate-internet](http://spectrum.ieee.org/tech-\ntalk/telecom/internet/could-russia-really-build-its-own-alternate-internet).\n\n[as of the spring of\n2019](22_Chapter_13_A_Schengen.xhtml#EndnotePhraseInText138): Catalin Cimpanu,\n“Russia to disconnect from the internet as part of a planned test,” ZDNet,\nFebruary 11, 2019, [www.zdnet.com/article/russia-to-disconnect-from-the-\ninternet-as-part-of-a-planned-test](http://www.zdnet.com/article/russia-to-\ndisconnect-from-the-internet-as-part-of-a-planned-test).\n\n[When Yahoo told\nFrance](22_Chapter_13_A_Schengen.xhtml#EndnotePhraseInText139): For an\nexcellent discussion on this topic, see Tim Wu and Jack Goldsmith, _Who\nControls the Internet? Illusions of a Borderless World_ (New York: Oxford\nUniversity Press, 2006).\n\n[UN’s Group of Governmental\nExperts](22_Chapter_13_A_Schengen.xhtml#EndnotePhraseInText140): Elaine\nKorzak, “UN GGE on Cybersecurity: The End of an Era?,” _The Diplomat_ , July\n31, 2017, <https://thediplomat.com/2017/07/un-gge-on-cybersecurity-have-china-\nand-russia-just-made-cyberspace-less-safe>.\n\n[“offered the best chance for the\nUK”](22_Chapter_13_A_Schengen.xhtml#EndnotePhraseInText141): Asa Bennett, “Did\nBritain really vote Brexit to cut immigration?,” _Telegraph_ , June 29, 2016,\n[www.telegraph.co.uk/news/2016/06/29/did-britain-really-vote-brexit-to-cut-\nimmigration](http://www.telegraph.co.uk/news/2016/06/29/did-britain-really-\nvote-brexit-to-cut-immigration).\n\n[The attempt to jettison\nNAFTA](22_Chapter_13_A_Schengen.xhtml#EndnotePhraseInText142): For an overview\nof these provisions, see Anupam Chander, “The Coming North American Digital\nTrade Zone,” Council on Foreign Relations, October 9, 2018,\n[www.cfr.org/blog/coming-north-american-digital-trade-\nzone](http://www.cfr.org/blog/coming-north-american-digital-trade-zone).\n\n[As Michael Geist](22_Chapter_13_A_Schengen.xhtml#EndnotePhraseInText143):\nMichael Geist, “How the USMCA falls short on digital trade, data protection\nand privacy,” _Washington Post_ , October 3, 2018,\n[www.washingtonpost.com/news/global-opinions/wp/2018/10/03/how-the-usmca-\nfalls-short-on-digital-trade-data-protection-and-\nprivacy](http://www.washingtonpost.com/news/global-opinions/wp/2018/10/03/how-\nthe-usmca-falls-short-on-digital-trade-data-protection-and-privacy).\n\n[The CLOUD Act,\npassed](22_Chapter_13_A_Schengen.xhtml#EndnotePhraseInText144): For a solid\noverview of the Cloud Act see Jennifer Daskal and Peter Swire, “Why the Cloud\nAct Is Good for Privacy and Human Rights,” _Lawfare_ , March 14, 2018,\n[www.lawfareblog.com/why-cloud-act-good-privacy-and-human-\nrights](http://www.lawfareblog.com/why-cloud-act-good-privacy-and-human-\nrights).\n\nChapter 14: Democracy’s Shield\n\n[“Brush your teeth”](23_Chapter_14_Democracy_.xhtml#EndnotePhraseInText145):\nAndy Greenberg, “Hacked or Not, Audit This Election (And All Future Ones),”\n_Wired,_ November 23, 2016, [www.wired.com/2016/11/hacked-not-audit-election-\nrest](http://www.wired.com/2016/11/hacked-not-audit-election-rest).\n\n[Chen revealed his\nfindings](23_Chapter_14_Democracy_.xhtml#EndnotePhraseInText146): Adrian Chen,\n“The Agency,” _New York Times,_ June 2, 2015,\n[www.nytimes.com/2015/06/07/magazine/the-\nagency.html](http://www.nytimes.com/2015/06/07/magazine/the-agency.html).\n\n[what the Internet Research Agency was\ndoing](23_Chapter_14_Democracy_.xhtml#EndnotePhraseInText147): Ellen\nNakashima, “US Cyber Command Operation Disrupted Internet Access of Russian\nTroll Factory on Day of 2018 Midterms,” _Washington Post_ , February 27, 2019,\n[www.washingtonpost.com/world/national-security/us-cyber-command-operation-\ndisrupted-internet-access-of-russian-troll-factory-on-day-\nof-2018-midterms/2019/02/26/1827fc9e-36d6-11e9-af5b-b51b7ff322e9_story.html](http://www.washingtonpost.com/world/national-\nsecurity/us-cyber-command-operation-disrupted-internet-access-of-russian-\ntroll-factory-on-day-\nof-2018-midterms/2019/02/26/1827fc9e-36d6-11e9-af5b-b51b7ff322e9_story.html).\n\n[“Their [U.S. adversaries’]\ndream”](23_Chapter_14_Democracy_.xhtml#EndnotePhraseInText148): Alex Stamos,\n“The Battle for the Soul of the Internet,” National Security and Technology\nCongressional Briefing Series, Washington, D.C., November 15, 2018.\n\n[an action plan for defending against hybrid\nwar](23_Chapter_14_Democracy_.xhtml#EndnotePhraseInText149): Jamie Fly, Laura\nRosenberger, and David Salvo, “The ASD Policy Blueprint for Countering\nAuthoritarian Interference in Democracies,” German Marshall Fund of the United\nStates, June 26, 2018, [www.gmfus.org/publications/asd-policy-blueprint-\ncountering-authoritarian-interference-\ndemocracies](http://www.gmfus.org/publications/asd-policy-blueprint-\ncountering-authoritarian-interference-democracies).\n\n[went on to write a\nplaybook](23_Chapter_14_Democracy_.xhtml#EndnotePhraseInText150):\n“Cybersecurity Campaign Playbook,” Belfer Center, Harvard Kennedy School,\nHarvard University, November 2017,\n[www.belfercenter.org/publication/cybersecurity-campaign-\nplaybook](http://www.belfercenter.org/publication/cybersecurity-campaign-\nplaybook).\n\n[would give up and go\nhome](23_Chapter_14_Democracy_.xhtml#EndnotePhraseInText151): Michael Powell\nand Peter Slevin, “Several Factors Contributed to ‘Lost’ Voters in Ohio,”\n_Washington Post,_ December 15, 2004, [www.washingtonpost.com/wp-\ndyn/articles/A64737-2004Dec14.html](http://www.washingtonpost.com/wp-\ndyn/articles/A64737-2004Dec14.html).\n\n[Russians attempted to break\ninto](23_Chapter_14_Democracy_.xhtml#EndnotePhraseInText152): Cynthia\nMcFadden, William M. Arkin, and Kevin Monahan, “Russians Penetrated U.S. Voter\nSystems, Top U.S. Official Says,” NBC News, February 7, 2018,\n[www.nbcnews.com/politics/elections/russians-penetrated-u-s-voter-systems-\nsays-top-u-s-n845721](http://www.nbcnews.com/politics/elections/russians-\npenetrated-u-s-voter-systems-says-top-u-s-n845721).\n\n[“state IT officials”](23_Chapter_14_Democracy_.xhtml#EndnotePhraseInText153):\nStamos, “The Battle for the Soul of the Internet.”\n\n[the American people do\nnot](23_Chapter_14_Democracy_.xhtml#EndnotePhraseInText154): Ellen Nakashima,\n“U.S. cyber force credited with helping stop Russia from undermining\nmidterms,” _Washington Post,_ February 14, 2019,\n[www.washingtonpost.com/world/national-security/us-cyber-force-credited-with-\nhelping-stop-russia-from-undermining-\nmidterms/2019/02/14/ceef46ae-3086-11e9-813a-0ab2f17e305b_story.html](http://www.washingtonpost.com/world/national-\nsecurity/us-cyber-force-credited-with-helping-stop-russia-from-undermining-\nmidterms/2019/02/14/ceef46ae-3086-11e9-813a-0ab2f17e305b_story.html).\n\nChapter 15: Real and Artificial Intelligence\n\n[“Whoever becomes the\nleader”](25_Chapter_15_Real_and_A.xhtml#EndnotePhraseInText155): Vladimir\nPutin made these remarks at National Knowledge Day while speaking to students\nin the Yaroslavl region of the Russian Federation in September 2017,\n<https://ruptly.tv/#/videos/20170901-032>.\n\n[the birthplace of AI](25_Chapter_15_Real_and_A.xhtml#EndnotePhraseInText156):\nJames Moor, “The Dartmouth College Artificial Intelligence Conference: The\nNext Fifty Years,” _AI Magazine_ 27, no. 4 (December 2006): 87–89.\n\n[bans autonomous\nweapons](25_Chapter_15_Real_and_A.xhtml#EndnotePhraseInText157): “Autonomy in\nWeapon Systems,” Department of Defense Directive Number 3000.09, U.S.\nDepartment of Defense, May 8, 2017,\n[www.esd.whs.mil/Portals/54/Documents/DD/issuances/dodd/300009p.pdf](http://www.esd.whs.mil/Portals/54/Documents/DD/issuances/dodd/300009p.pdf).\n\n[“generative adversarial network” to fool other\nsoftware](25_Chapter_15_Real_and_A.xhtml#EndnotePhraseInText158): Omid\nPoursaeed et al., “Generative Adversarial Perturbations,” _CVPR_ (2018),\n[vision.cornell.edu/se3/wp-\ncontent/uploads/2018/03/2387.pdf](http://vision.cornell.edu/se3/wp-\ncontent/uploads/2018/03/2387.pdf).\n\n[AI attack program called\nDeepLocker](25_Chapter_15_Real_and_A.xhtml#EndnotePhraseInText159): Marc Ph.\nStoecklin, with Jiyong Jang and Dhilung Kirat, “DeepLocker: How AI Can Power a\nStealthy New Breed of Malware,” IBM.com, August 8, 2018,\n[securityintelligence.com/deeplocker-how-ai-can-power-a-stealthy-new-breed-of-\nmalware](http://securityintelligence.com/deeplocker-how-ai-can-power-a-\nstealthy-new-breed-of-malware).\n\nChapter 16: A Quantum of Solace for Security\n\n[the famous double-slit\nexperiment](26_Chapter_16_A_Quantum_.xhtml#EndnotePhraseInText160): “The\nQuantum Experiment That Broke Reality,” _Space Time_ , PBS Digital Studios,\nJuly 27, 2016, [youtu.be/p-MNSLsjjdo](http://youtu.be/p-MNSLsjjdo).\n\n[Chinese scientists created two entangled\nphotons](26_Chapter_16_A_Quantum_.xhtml#EndnotePhraseInText161): Juan Yin et\nal., “Satellite-Based Entanglement Distribution over 1200 Kilometers,”\n_Science_ 356, no. 6343 (June 2017): 1140–44.\n\n[The Chinese government has\nwhat](26_Chapter_16_A_Quantum_.xhtml#EndnotePhraseInText162): Stephen Chen,\n“China Building World’s Biggest Quantum Research Facility,” _South China\nMorning Post,_ September 11, 2017,\n[www.scmp.com/news/china/society/article/2110563/china-building-worlds-\nbiggest-quantum-research-\nfacility](http://www.scmp.com/news/china/society/article/2110563/china-\nbuilding-worlds-biggest-quantum-research-facility).\n\n[quantum-resistant encryption\nstandard](26_Chapter_16_A_Quantum_.xhtml#EndnotePhraseInText163): “Post-\nQuantum Cryptography,” National Institute of Standards and Technology,\nCSRM.NIST.com, accessed January 4, 2019, [csrc.nist.gov/projects/post-quantum-\ncryptography](http://csrc.nist.gov/projects/post-quantum-cryptography).\n\nChapter 17: 5G and IoT\n\n[quarter trillion\ndollars](27_Chapter_17_5g_and_Iot.xhtml#EndnotePhraseInText164): Hillol Roy,\n“Tackling the Cost of a 5G Build,” Accenture, August 3, 2018,\n[www.accenture.com/us-en/insights/strategy/5G-network-\nbuild](http://www.accenture.com/us-en/insights/strategy/5G-network-build).\n\n[publicly published 132\nquestions](27_Chapter_17_5g_and_Iot.xhtml#EndnotePhraseInText165): “Promoting\nUnlicensed Use of the 6 Ghz Band,” Notice of Proposed Rulemaking, Federal\nCommunications Commission _,_ October 2, 2018,\n<https://docs.fcc.gov/public/attachments/DOC-354364A1.pdf>.\n\n[“It is widely expected that 5G\nnetworks”](27_Chapter_17_5g_and_Iot.xhtml#EndnotePhraseInText166): Federal\nCommunications Commission, “Fifth Generation Wireless Network and Device\nSecurity,” _Federal_ _Register_ 82, no.13 (January 23, 2017): 7825–30,\n[www.govinfo.gov/content/pkg/FR-2017-01-23/pdf/2017-01325.pdf](http://www.govinfo.gov/content/pkg/FR-2017-01-23/pdf/2017-01325.pdf).\n\n[farmers learned that\nhackers](27_Chapter_17_5g_and_Iot.xhtml#EndnotePhraseInText167): Jason\nKoebler, “Why American Farmers Are Hacking Their Tractors with Ukrainian\nFirmware,” _Motherboard_ , March 21, 2017,\n[motherboard.vice.com/en_us/article/xykkkd/why-american-farmers-are-hacking-\ntheir-tractors-with-ukrainian-\nfirmware](http://motherboard.vice.com/en_us/article/xykkkd/why-american-\nfarmers-are-hacking-their-tractors-with-ukrainian-firmware).\n\n[in a petrochemical plant in Saudi\nArabia](27_Chapter_17_5g_and_Iot.xhtml#EndnotePhraseInText168): David E.\nSanger, “Hack of Saudi Petrochemical Plant Was Coordinated from Russian\nInstitute,” _New York Times_ , October 23, 2018,\n[www.nytimes.com/2018/10/23/us/politics/russian-hackers-saudi-chemical-\nplant.html](http://www.nytimes.com/2018/10/23/us/politics/russian-hackers-\nsaudi-chemical-plant.html).\n\n[“third-party control\nrisk”](27_Chapter_17_5g_and_Iot.xhtml#EndnotePhraseInText169): Warning letter\nto Abbott Laboratories from the Food and Drug Administration, April 12, 2017,\n[www.fda.gov/iceci/enforcementactions/warningletters/2017/ucm552687.htm](http://www.fda.gov/iceci/enforcementactions/warningletters/2017/ucm552687.htm).\n\n[issuing regulations requiring such\nassurances](27_Chapter_17_5g_and_Iot.xhtml#EndnotePhraseInText170): Colin\nDwyer, “Department of Transportation Rolls Out New Guidelines for Self-Driving\nCars,” National Public Radio, September 12, 2017, [www.npr.org/sections/the-\ntwo-way/2017/09/12/550533833/department-of-transportation-rolls-out-new-\nguidelines-for-self-driving-cars](http://www.npr.org/sections/the-two-\nway/2017/09/12/550533833/department-of-transportation-rolls-out-new-\nguidelines-for-self-driving-cars).\n\nChapter 18: Derisking Ourselves\n\n[We like ten-character\npasswords](29_Chapter_18_Derisking_.xhtml#EndnotePhraseInText171): “How to\nChoose a Password,” Office of Information Security, University of Cincinnati,\naccessed January 6, 2019,\n[www.uc.edu/infosec/password/choosepassword.html](http://www.uc.edu/infosec/password/choosepassword.html).\n\n[Fraudulent debit-card\ncharges](29_Chapter_18_Derisking_.xhtml#EndnotePhraseInText172): “Lost or\nStolen Credit, ATM, and Debit Cards,” Consumer Information, Federal Trade\nCommission, August 2012, [www.consumer.ftc.gov/articles/0213-lost-or-stolen-\ncredit-atm-and-debit-cards](http://www.consumer.ftc.gov/articles/0213-lost-or-\nstolen-credit-atm-and-debit-cards).\n\nChapter 19: Everything Done but the Coding\n\n[released its International Strategy for\nCyberspace](30_Chapter_19_Everything.xhtml#EndnotePhraseInText173):\n“International Strategy for Cyberspace,” White House, May 2011,\n[obamawhitehouse.archives.gov/sites/default/files/rss_viewer/international_strategy_for_cyberspace.pdf](http://obamawhitehouse.archives.gov/sites/default/files/rss_viewer/international_strategy_for_cyberspace.pdf).\n\n[a simple conclusion](30_Chapter_19_Everything.xhtml#EndnotePhraseInText174):\nMatthew G. Devost, Jeff Moss, Neal A. Pollard, and Robert J. Stratton III,\n“All Done Except the Coding: Implementing the International Strategy for\nCyberspace,” _Georgetown Journal of International Affairs_ (2011), 197–208,\n[www.jstor.org/stable/43133830?seq=1#page_scan_tab_contents](http://www.jstor.org/stable/43133830?seq=1#page_scan_tab_contents).\n\n\nABCDEFGHIJKLMNOPQRSTUVWXYZ\n\n# Index\n\nThe page numbers in this index refer to the printed version of this book. The\nlink provided will take you to the beginning of that print page. You may need\nto scroll forward from that location to find the corresponding reference on\nyour e-reader.\n\nAckerman, Bob, [68](12_Chapter_5_The_Tech_St.xhtml#page_68)–69\n\nActive Cyber Defense Certainty Act,\n[99](13_Chapter_6_Cyber_Resil.xhtml#page_99)\n\nactuators, [66](12_Chapter_5_The_Tech_St.xhtml#page_66)–67,\n[83](12_Chapter_5_The_Tech_St.xhtml#page_83)\n\nadvanced persistent threat (APT),\n[33](10_Chapter_3_Two_Kinds_o.xhtml#page_33),\n[39](10_Chapter_3_Two_Kinds_o.xhtml#page_39),\n[42](10_Chapter_3_Two_Kinds_o.xhtml#page_42)–44,\n[46](10_Chapter_3_Two_Kinds_o.xhtml#page_46),\n[74](12_Chapter_5_The_Tech_St.xhtml#page_74),\n[76](12_Chapter_5_The_Tech_St.xhtml#page_76),\n[77](12_Chapter_5_The_Tech_St.xhtml#page_77),\n[148](17_Chapter_9_Fixing_the_.xhtml#page_148),\n[299](31_Glossary.xhtml#page_299)\n\nAetna, [40](10_Chapter_3_Two_Kinds_o.xhtml#page_40)–42,\n[133](16_Chapter_8_Is_It_Reall.xhtml#page_133)\n\nAir Force, U.S., [50](11_Chapter_4_The_Kill_Ch.xhtml#page_50),\n[102](13_Chapter_6_Cyber_Resil.xhtml#page_102),\n[166](18_Chapter_10_Power_Grid.xhtml#page_166),\n[183](21_Chapter_12_The_Milita.xhtml#page_183)\n\nAitel, Dave, [35](10_Chapter_3_Two_Kinds_o.xhtml#page_35)–36\n\nAkamai, [71](12_Chapter_5_The_Tech_St.xhtml#page_71),\n[87](13_Chapter_6_Cyber_Resil.xhtml#page_87),\n[119](15_Chapter_7_Nudges_and_.xhtml#page_119)\n\nAlexander, Keith, [43](10_Chapter_3_Two_Kinds_o.xhtml#page_43),\n[93](13_Chapter_6_Cyber_Resil.xhtml#page_93)–95,\n[105](13_Chapter_6_Cyber_Resil.xhtml#page_105),\n[161](18_Chapter_10_Power_Grid.xhtml#page_161),\n[246](25_Chapter_15_Real_and_A.xhtml#page_246)\n\nAlliance for Securing Democracy (ASD),\n[223](23_Chapter_14_Democracy_.xhtml#page_223),\n[224](23_Chapter_14_Democracy_.xhtml#page_224)\n\nAlperovitch, Dmitri, [33](10_Chapter_3_Two_Kinds_o.xhtml#page_33)–35,\n[40](10_Chapter_3_Two_Kinds_o.xhtml#page_40)\n\nAmazon, [73](12_Chapter_5_The_Tech_St.xhtml#page_73)–77,\n[98](13_Chapter_6_Cyber_Resil.xhtml#page_98),\n[153](17_Chapter_9_Fixing_the_.xhtml#page_153),\n[213](22_Chapter_13_A_Schengen.xhtml#page_213),\n[215](22_Chapter_13_A_Schengen.xhtml#page_215),\n[276](27_Chapter_17_5g_and_Iot.xhtml#page_276)\n\n_American Morning_ , [155](18_Chapter_10_Power_Grid.xhtml#page_155)\n\nAmin, Rohan, [49](11_Chapter_4_The_Kill_Ch.xhtml#page_49)–52\n\nAmoroso, Ed, [74](12_Chapter_5_The_Tech_St.xhtml#page_74),\n[75](12_Chapter_5_The_Tech_St.xhtml#page_75),\n[78](12_Chapter_5_The_Tech_St.xhtml#page_78)\n\nantivirus software, [22](08_Chapter_2_Eternalblue.xhtml#page_22)–23,\n[35](10_Chapter_3_Two_Kinds_o.xhtml#page_35)–36,\n[53](11_Chapter_4_The_Kill_Ch.xhtml#page_53),\n[65](12_Chapter_5_The_Tech_St.xhtml#page_65),\n[70](12_Chapter_5_The_Tech_St.xhtml#page_70),\n[244](25_Chapter_15_Real_and_A.xhtml#page_244),\n[251](25_Chapter_15_Real_and_A.xhtml#page_251),\n[288](29_Chapter_18_Derisking_.xhtml#page_288)\n\nApple, [8](07_Chapter_1_The_Back_of.xhtml#page_8),\n[24](08_Chapter_2_Eternalblue.xhtml#page_24),\n[124](15_Chapter_7_Nudges_and_.xhtml#page_124),\n[138](16_Chapter_8_Is_It_Reall.xhtml#page_138),\n[153](17_Chapter_9_Fixing_the_.xhtml#page_153)\n\napprenticeship programs, [152](17_Chapter_9_Fixing_the_.xhtml#page_152)–53\n\nArchuleta, Katherine, [175](19_Chapter_11_Securing_t.xhtml#page_175),\n[176](19_Chapter_11_Securing_t.xhtml#page_176)\n\n_Argo_ , [85](13_Chapter_6_Cyber_Resil.xhtml#page_85),\n[104](13_Chapter_6_Cyber_Resil.xhtml#page_104)\n\nArmy, U.S., [150](17_Chapter_9_Fixing_the_.xhtml#page_150),\n[170](19_Chapter_11_Securing_t.xhtml#page_170),\n[183](21_Chapter_12_The_Milita.xhtml#page_183),\n[195](21_Chapter_12_The_Milita.xhtml#page_195)\n\nartificial intelligence (AI), [53](11_Chapter_4_The_Kill_Ch.xhtml#page_53),\n[80](12_Chapter_5_The_Tech_St.xhtml#page_80)–82,\n[144](17_Chapter_9_Fixing_the_.xhtml#page_144),\n[153](17_Chapter_9_Fixing_the_.xhtml#page_153),\n[239](25_Chapter_15_Real_and_A.xhtml#page_239)–52,\n[280](27_Chapter_17_5g_and_Iot.xhtml#page_280)\n\nin cyber warfare, [239](25_Chapter_15_Real_and_A.xhtml#page_239)–41\n\ndata and, [247](25_Chapter_15_Real_and_A.xhtml#page_247)–48,\n[251](25_Chapter_15_Real_and_A.xhtml#page_251)\n\ndefensive use of, [244](25_Chapter_15_Real_and_A.xhtml#page_244)–48,\n[252](25_Chapter_15_Real_and_A.xhtml#page_252),\n[263](26_Chapter_16_A_Quantum_.xhtml#page_263)\n\nmachine learning, [42](10_Chapter_3_Two_Kinds_o.xhtml#page_42),\n[53](11_Chapter_4_The_Kill_Ch.xhtml#page_53),\n[80](12_Chapter_5_The_Tech_St.xhtml#page_80),\n[81](12_Chapter_5_The_Tech_St.xhtml#page_81),\n[243](25_Chapter_15_Real_and_A.xhtml#page_243)–52,\n[263](26_Chapter_16_A_Quantum_.xhtml#page_263)–64,\n[304](31_Glossary.xhtml#page_304)\n\noffensive use of, [248](25_Chapter_15_Real_and_A.xhtml#page_248)–52\n\nquantum computing and, [263](26_Chapter_16_A_Quantum_.xhtml#page_263)–64\n\nAssange, Julian, [23](08_Chapter_2_Eternalblue.xhtml#page_23)–24,\n[277](27_Chapter_17_5g_and_Iot.xhtml#page_277)\n\nAT&T, [74](12_Chapter_5_The_Tech_St.xhtml#page_74),\n[119](15_Chapter_7_Nudges_and_.xhtml#page_119),\n[120](15_Chapter_7_Nudges_and_.xhtml#page_120),\n[265](27_Chapter_17_5g_and_Iot.xhtml#page_265)–66\n\nauthentication, [42](10_Chapter_3_Two_Kinds_o.xhtml#page_42),\n[129](16_Chapter_8_Is_It_Reall.xhtml#page_129)–41,\n[299](31_Glossary.xhtml#page_299)\n\nmultifactor, [46](10_Chapter_3_Two_Kinds_o.xhtml#page_46),\n[129](16_Chapter_8_Is_It_Reall.xhtml#page_129),\n[131](16_Chapter_8_Is_It_Reall.xhtml#page_131)–34,\n[137](16_Chapter_8_Is_It_Reall.xhtml#page_137),\n[304](31_Glossary.xhtml#page_304)\n\nReallyU, [138](16_Chapter_8_Is_It_Reall.xhtml#page_138)–40,\n[306](31_Glossary.xhtml#page_306)\n\ntwo-factor, [129](16_Chapter_8_Is_It_Reall.xhtml#page_129),\n[131](16_Chapter_8_Is_It_Reall.xhtml#page_131),\n[132](16_Chapter_8_Is_It_Reall.xhtml#page_132),\n[285](29_Chapter_18_Derisking_.xhtml#page_285),\n[287](29_Chapter_18_Derisking_.xhtml#page_287),\n[308](31_Glossary.xhtml#page_308)\n\n_see also_ identity\n\nauthorization, [133](16_Chapter_8_Is_It_Reall.xhtml#page_133)\n\nAuthorization for Use of Military Force (AUMF),\n[196](21_Chapter_12_The_Milita.xhtml#page_196)\n\nAvery, Heidi, [110](15_Chapter_7_Nudges_and_.xhtml#page_110)\n\nbackdoors, [23](08_Chapter_2_Eternalblue.xhtml#page_23),\n[197](21_Chapter_12_The_Milita.xhtml#page_197),\n[299](31_Glossary.xhtml#page_299)\n\nbacking up data, [127](15_Chapter_7_Nudges_and_.xhtml#page_127),\n[291](29_Chapter_18_Derisking_.xhtml#page_291)–92\n\nBadin, Dmitriy Sergeyevich, [28](08_Chapter_2_Eternalblue.xhtml#page_28)\n\nBanga, Ajay, [152](17_Chapter_9_Fixing_the_.xhtml#page_152),\n[153](17_Chapter_9_Fixing_the_.xhtml#page_153)\n\nBank of America, [9](07_Chapter_1_The_Back_of.xhtml#page_9),\n[38](10_Chapter_3_Two_Kinds_o.xhtml#page_38),\n[85](13_Chapter_6_Cyber_Resil.xhtml#page_85),\n[136](16_Chapter_8_Is_It_Reall.xhtml#page_136),\n[284](29_Chapter_18_Derisking_.xhtml#page_284)\n\nbanks, bank accounts, [8](07_Chapter_1_The_Back_of.xhtml#page_8)–9,\n[27](08_Chapter_2_Eternalblue.xhtml#page_27),\n[38](10_Chapter_3_Two_Kinds_o.xhtml#page_38),\n[39](10_Chapter_3_Two_Kinds_o.xhtml#page_39),\n[85](13_Chapter_6_Cyber_Resil.xhtml#page_85)–87,\n[91](13_Chapter_6_Cyber_Resil.xhtml#page_91),\n[94](13_Chapter_6_Cyber_Resil.xhtml#page_94),\n[115](15_Chapter_7_Nudges_and_.xhtml#page_115),\n[119](15_Chapter_7_Nudges_and_.xhtml#page_119),\n[132](16_Chapter_8_Is_It_Reall.xhtml#page_132),\n[133](16_Chapter_8_Is_It_Reall.xhtml#page_133),\n[136](16_Chapter_8_Is_It_Reall.xhtml#page_136),\n[137](16_Chapter_8_Is_It_Reall.xhtml#page_137),\n[284](29_Chapter_18_Derisking_.xhtml#page_284),\n[286](29_Chapter_18_Derisking_.xhtml#page_286)–87,\n[292](29_Chapter_18_Derisking_.xhtml#page_292)–93\n\nBarksdale, Jim, [33](10_Chapter_3_Two_Kinds_o.xhtml#page_33)\n\nBarlow, John Perry, [207](22_Chapter_13_A_Schengen.xhtml#page_207)–10\n\nBenioff, Marc, [75](12_Chapter_5_The_Tech_St.xhtml#page_75)\n\nBennett, Corey, [97](13_Chapter_6_Cyber_Resil.xhtml#page_97)\n\nBetter Identity Coalition, [136](16_Chapter_8_Is_It_Reall.xhtml#page_136)\n\nBezos, Jeff, [73](12_Chapter_5_The_Tech_St.xhtml#page_73)\n\nBhalotra, Sameer, [134](16_Chapter_8_Is_It_Reall.xhtml#page_134)–36\n\nbiometrics, [129](16_Chapter_8_Is_It_Reall.xhtml#page_129)–30,\n[137](16_Chapter_8_Is_It_Reall.xhtml#page_137),\n[138](16_Chapter_8_Is_It_Reall.xhtml#page_138)\n\nBitcoin, [18](08_Chapter_2_Eternalblue.xhtml#page_18),\n[125](15_Chapter_7_Nudges_and_.xhtml#page_125),\n[126](15_Chapter_7_Nudges_and_.xhtml#page_126),\n[277](27_Chapter_17_5g_and_Iot.xhtml#page_277),\n[289](29_Chapter_18_Derisking_.xhtml#page_289)\n\nBlack Hat Briefings, [49](11_Chapter_4_The_Kill_Ch.xhtml#page_49),\n[73](12_Chapter_5_The_Tech_St.xhtml#page_73),\n[102](13_Chapter_6_Cyber_Resil.xhtml#page_102)\n\nblacklists, [35](10_Chapter_3_Two_Kinds_o.xhtml#page_35)–36,\n[244](25_Chapter_15_Real_and_A.xhtml#page_244),\n[245](25_Chapter_15_Real_and_A.xhtml#page_245)\n\nblackout of 2003, [155](18_Chapter_10_Power_Grid.xhtml#page_155)–57\n\nblockchain, [6](07_Chapter_1_The_Back_of.xhtml#page_6),\n[126](15_Chapter_7_Nudges_and_.xhtml#page_126)\n\nBlumenthal, Richard, [233](23_Chapter_14_Democracy_.xhtml#page_233)\n\nBoeing, [37](10_Chapter_3_Two_Kinds_o.xhtml#page_37),\n[79](12_Chapter_5_The_Tech_St.xhtml#page_79)–80\n\nBohr, Niels, [253](26_Chapter_16_A_Quantum_.xhtml#page_253)\n\nBolton, John, [97](13_Chapter_6_Cyber_Resil.xhtml#page_97)\n\nBooz Allen Hamilton, [40](10_Chapter_3_Two_Kinds_o.xhtml#page_40),\n[170](19_Chapter_11_Securing_t.xhtml#page_170),\n[189](21_Chapter_12_The_Milita.xhtml#page_189)\n\nBorder Gateway Protocol (BGP), [78](12_Chapter_5_The_Tech_St.xhtml#page_78),\n[118](15_Chapter_7_Nudges_and_.xhtml#page_118)–20,\n[299](31_Glossary.xhtml#page_299)\n\nbotnets, [73](12_Chapter_5_The_Tech_St.xhtml#page_73),\n[300](31_Glossary.xhtml#page_300)\n\nBottoms, Keisha, [126](15_Chapter_7_Nudges_and_.xhtml#page_126)\n\nBra-Ket, [258](26_Chapter_16_A_Quantum_.xhtml#page_258),\n[259](26_Chapter_16_A_Quantum_.xhtml#page_259)\n\nbreach disclosure, [115](15_Chapter_7_Nudges_and_.xhtml#page_115)–16\n\nBrennan, John, [110](15_Chapter_7_Nudges_and_.xhtml#page_110)\n\nBritain, [17](08_Chapter_2_Eternalblue.xhtml#page_17)–18,\n[25](08_Chapter_2_Eternalblue.xhtml#page_25),\n[96](13_Chapter_6_Cyber_Resil.xhtml#page_96),\n[211](22_Chapter_13_A_Schengen.xhtml#page_211)–12,\n[220](23_Chapter_14_Democracy_.xhtml#page_220)–21\n\nBrown, Jerry, [117](15_Chapter_7_Nudges_and_.xhtml#page_117)\n\nBudapest Convention, [212](22_Chapter_13_A_Schengen.xhtml#page_212)–13,\n[216](22_Chapter_13_A_Schengen.xhtml#page_216)\n\nBush, George H. W., [6](07_Chapter_1_The_Back_of.xhtml#page_6)\n\nBush, George W., [6](07_Chapter_1_The_Back_of.xhtml#page_6),\n[11](07_Chapter_1_The_Back_of.xhtml#page_11),\n[88](13_Chapter_6_Cyber_Resil.xhtml#page_88),\n[89](13_Chapter_6_Cyber_Resil.xhtml#page_89),\n[96](13_Chapter_6_Cyber_Resil.xhtml#page_96),\n[113](15_Chapter_7_Nudges_and_.xhtml#page_113),\n[130](16_Chapter_8_Is_It_Reall.xhtml#page_130),\n[135](16_Chapter_8_Is_It_Reall.xhtml#page_135),\n[156](18_Chapter_10_Power_Grid.xhtml#page_156),\n[222](23_Chapter_14_Democracy_.xhtml#page_222),\n[228](23_Chapter_14_Democracy_.xhtml#page_228)\n\nCalifornia, [117](15_Chapter_7_Nudges_and_.xhtml#page_117),\n[123](15_Chapter_7_Nudges_and_.xhtml#page_123)\n\ncameras, [289](29_Chapter_18_Derisking_.xhtml#page_289)–90\n\nCarlin, John, [125](15_Chapter_7_Nudges_and_.xhtml#page_125)\n\ncars, driverless, [266](27_Chapter_17_5g_and_Iot.xhtml#page_266)–67,\n[269](27_Chapter_17_5g_and_Iot.xhtml#page_269)–70\n\nCarter, Ash, [193](21_Chapter_12_The_Milita.xhtml#page_193),\n[225](23_Chapter_14_Democracy_.xhtml#page_225)\n\n_Causes of War, The_ (Van Evera),\n[100](13_Chapter_6_Cyber_Resil.xhtml#page_100)\n\nCenter for Internet Security, [117](15_Chapter_7_Nudges_and_.xhtml#page_117)\n\nCenter for Strategic and International Studies (CSIS),\n[89](13_Chapter_6_Cyber_Resil.xhtml#page_89),\n[101](13_Chapter_6_Cyber_Resil.xhtml#page_101),\n[110](15_Chapter_7_Nudges_and_.xhtml#page_110),\n[113](15_Chapter_7_Nudges_and_.xhtml#page_113)\n\ncertified information security manager,\n[146](17_Chapter_9_Fixing_the_.xhtml#page_146)\n\ncertified information system auditor,\n[146](17_Chapter_9_Fixing_the_.xhtml#page_146)\n\ncertified information systems security professional,\n[146](17_Chapter_9_Fixing_the_.xhtml#page_146),\n[149](17_Chapter_9_Fixing_the_.xhtml#page_149)\n\nChamber of Commerce, [44](10_Chapter_3_Two_Kinds_o.xhtml#page_44),\n[109](15_Chapter_7_Nudges_and_.xhtml#page_109)–11,\n[113](15_Chapter_7_Nudges_and_.xhtml#page_113),\n[118](15_Chapter_7_Nudges_and_.xhtml#page_118)\n\nChaudhuri, Swarat, [80](12_Chapter_5_The_Tech_St.xhtml#page_80)\n\nChemical Facility Anti-Terrorism Standards,\n[114](15_Chapter_7_Nudges_and_.xhtml#page_114)–15\n\nChen, Adrian, [219](23_Chapter_14_Democracy_.xhtml#page_219)\n\nCheney, Dick, [275](27_Chapter_17_5g_and_Iot.xhtml#page_275)\n\nchief information officers (CIOs),\n[72](12_Chapter_5_The_Tech_St.xhtml#page_72),\n[300](31_Glossary.xhtml#page_300)\n\nchief information security officers (CISOs),\n[5](07_Chapter_1_The_Back_of.xhtml#page_5),\n[33](10_Chapter_3_Two_Kinds_o.xhtml#page_33),\n[40](10_Chapter_3_Two_Kinds_o.xhtml#page_40),\n[49](11_Chapter_4_The_Kill_Ch.xhtml#page_49),\n[56](11_Chapter_4_The_Kill_Ch.xhtml#page_56),\n[64](12_Chapter_5_The_Tech_St.xhtml#page_64),\n[65](12_Chapter_5_The_Tech_St.xhtml#page_65),\n[69](12_Chapter_5_The_Tech_St.xhtml#page_69),\n[72](12_Chapter_5_The_Tech_St.xhtml#page_72),\n[87](13_Chapter_6_Cyber_Resil.xhtml#page_87),\n[151](17_Chapter_9_Fixing_the_.xhtml#page_151),\n[170](19_Chapter_11_Securing_t.xhtml#page_170),\n[177](19_Chapter_11_Securing_t.xhtml#page_177),\n[178](19_Chapter_11_Securing_t.xhtml#page_178),\n[244](25_Chapter_15_Real_and_A.xhtml#page_244),\n[300](31_Glossary.xhtml#page_300)\n\nChina, [5](07_Chapter_1_The_Back_of.xhtml#page_5),\n[24](08_Chapter_2_Eternalblue.xhtml#page_24),\n[28](08_Chapter_2_Eternalblue.xhtml#page_28),\n[33](10_Chapter_3_Two_Kinds_o.xhtml#page_33)–34,\n[39](10_Chapter_3_Two_Kinds_o.xhtml#page_39)–41,\n[43](10_Chapter_3_Two_Kinds_o.xhtml#page_43),\n[46](10_Chapter_3_Two_Kinds_o.xhtml#page_46),\n[50](11_Chapter_4_The_Kill_Ch.xhtml#page_50),\n[97](13_Chapter_6_Cyber_Resil.xhtml#page_97),\n[159](18_Chapter_10_Power_Grid.xhtml#page_159)–60,\n[166](18_Chapter_10_Power_Grid.xhtml#page_166),\n[182](21_Chapter_12_The_Milita.xhtml#page_182),\n[187](21_Chapter_12_The_Milita.xhtml#page_187),\n[195](21_Chapter_12_The_Milita.xhtml#page_195),\n[196](21_Chapter_12_The_Milita.xhtml#page_196),\n[198](21_Chapter_12_The_Milita.xhtml#page_198),\n[214](22_Chapter_13_A_Schengen.xhtml#page_214),\n[217](22_Chapter_13_A_Schengen.xhtml#page_217),\n[241](25_Chapter_15_Real_and_A.xhtml#page_241),\n[242](25_Chapter_15_Real_and_A.xhtml#page_242),\n[248](25_Chapter_15_Real_and_A.xhtml#page_248),\n[252](25_Chapter_15_Real_and_A.xhtml#page_252),\n[272](27_Chapter_17_5g_and_Iot.xhtml#page_272)\n\n5G and, [267](27_Chapter_17_5g_and_Iot.xhtml#page_267)–68\n\ninternet and Great Firewall of, [87](13_Chapter_6_Cyber_Resil.xhtml#page_87),\n[205](22_Chapter_13_A_Schengen.xhtml#page_205),\n[206](22_Chapter_13_A_Schengen.xhtml#page_206),\n[208](22_Chapter_13_A_Schengen.xhtml#page_208),\n[210](22_Chapter_13_A_Schengen.xhtml#page_210),\n[211](22_Chapter_13_A_Schengen.xhtml#page_211),\n[215](22_Chapter_13_A_Schengen.xhtml#page_215)\n\nPeople’s Liberation Army, [26](08_Chapter_2_Eternalblue.xhtml#page_26),\n[28](08_Chapter_2_Eternalblue.xhtml#page_28),\n[176](19_Chapter_11_Securing_t.xhtml#page_176),\n[305](31_Glossary.xhtml#page_305)\n\nquantum computing and, [256](26_Chapter_16_A_Quantum_.xhtml#page_256),\n[259](26_Chapter_16_A_Quantum_.xhtml#page_259),\n[260](26_Chapter_16_A_Quantum_.xhtml#page_260),\n[262](26_Chapter_16_A_Quantum_.xhtml#page_262),\n[264](26_Chapter_16_A_Quantum_.xhtml#page_264)\n\nChina Telecom, [119](15_Chapter_7_Nudges_and_.xhtml#page_119)–20\n\nCIA, [23](08_Chapter_2_Eternalblue.xhtml#page_23)–24,\n[37](10_Chapter_3_Two_Kinds_o.xhtml#page_37),\n[110](15_Chapter_7_Nudges_and_.xhtml#page_110),\n[124](15_Chapter_7_Nudges_and_.xhtml#page_124),\n[152](17_Chapter_9_Fixing_the_.xhtml#page_152),\n[173](19_Chapter_11_Securing_t.xhtml#page_173),\n[194](21_Chapter_12_The_Milita.xhtml#page_194)\n\nCitibank, [8](07_Chapter_1_The_Back_of.xhtml#page_8),\n[38](10_Chapter_3_Two_Kinds_o.xhtml#page_38),\n[136](16_Chapter_8_Is_It_Reall.xhtml#page_136),\n[284](29_Chapter_18_Derisking_.xhtml#page_284)\n\ncivil service system, [171](19_Chapter_11_Securing_t.xhtml#page_171),\n[173](19_Chapter_11_Securing_t.xhtml#page_173)\n\nClarke, Richard A., [3](07_Chapter_1_The_Back_of.xhtml#page_3)–4,\n[6](07_Chapter_1_The_Back_of.xhtml#page_6),\n[10](07_Chapter_1_The_Back_of.xhtml#page_10)–11,\n[21](08_Chapter_2_Eternalblue.xhtml#page_21),\n[59](11_Chapter_4_The_Kill_Ch.xhtml#page_59),\n[65](12_Chapter_5_The_Tech_St.xhtml#page_65),\n[89](13_Chapter_6_Cyber_Resil.xhtml#page_89),\n[124](15_Chapter_7_Nudges_and_.xhtml#page_124)–25,\n[156](18_Chapter_10_Power_Grid.xhtml#page_156),\n[168](19_Chapter_11_Securing_t.xhtml#page_168),\n[220](23_Chapter_14_Democracy_.xhtml#page_220),\n[254](26_Chapter_16_A_Quantum_.xhtml#page_254),\n[291](29_Chapter_18_Derisking_.xhtml#page_291)\n\n_Cyber War,_ [6](07_Chapter_1_The_Back_of.xhtml#page_6)–7,\n[13](07_Chapter_1_The_Back_of.xhtml#page_13),\n[26](08_Chapter_2_Eternalblue.xhtml#page_26),\n[37](10_Chapter_3_Two_Kinds_o.xhtml#page_37),\n[78](12_Chapter_5_The_Tech_St.xhtml#page_78),\n[192](21_Chapter_12_The_Milita.xhtml#page_192),\n[200](21_Chapter_12_The_Milita.xhtml#page_200)\n\n_Warnings,_ [162](18_Chapter_10_Power_Grid.xhtml#page_162),\n[223](23_Chapter_14_Democracy_.xhtml#page_223)\n\nCLEAR, [137](16_Chapter_8_Is_It_Reall.xhtml#page_137)\n\nClinton, Bill, [3](07_Chapter_1_The_Back_of.xhtml#page_3)–4,\n[6](07_Chapter_1_The_Back_of.xhtml#page_6),\n[11](07_Chapter_1_The_Back_of.xhtml#page_11),\n[88](13_Chapter_6_Cyber_Resil.xhtml#page_88),\n[113](15_Chapter_7_Nudges_and_.xhtml#page_113),\n[168](19_Chapter_11_Securing_t.xhtml#page_168),\n[221](23_Chapter_14_Democracy_.xhtml#page_221)\n\nClinton, Hillary, [223](23_Chapter_14_Democracy_.xhtml#page_223),\n[232](23_Chapter_14_Democracy_.xhtml#page_232)–33\n\nClipper chip, [124](15_Chapter_7_Nudges_and_.xhtml#page_124)\n\ncloud, [5](07_Chapter_1_The_Back_of.xhtml#page_5)–6,\n[71](12_Chapter_5_The_Tech_St.xhtml#page_71)–77,\n[104](13_Chapter_6_Cyber_Resil.xhtml#page_104),\n[206](22_Chapter_13_A_Schengen.xhtml#page_206),\n[215](22_Chapter_13_A_Schengen.xhtml#page_215),\n[291](29_Chapter_18_Derisking_.xhtml#page_291)–92,\n[298](30_Chapter_19_Everything.xhtml#page_298),\n[300](31_Glossary.xhtml#page_300)\n\nCLOUD Act, [214](22_Chapter_13_A_Schengen.xhtml#page_214),\n[215](22_Chapter_13_A_Schengen.xhtml#page_215)\n\nCloudflare, [87](13_Chapter_6_Cyber_Resil.xhtml#page_87),\n[119](15_Chapter_7_Nudges_and_.xhtml#page_119)\n\nCoats, Dan, [26](08_Chapter_2_Eternalblue.xhtml#page_26),\n[159](18_Chapter_10_Power_Grid.xhtml#page_159)\n\nCole, Alma, [170](19_Chapter_11_Securing_t.xhtml#page_170)\n\nColumbia University, [102](13_Chapter_6_Cyber_Resil.xhtml#page_102)\n\nComey, James, [124](15_Chapter_7_Nudges_and_.xhtml#page_124),\n[125](15_Chapter_7_Nudges_and_.xhtml#page_125)\n\nCommerce Department, [88](13_Chapter_6_Cyber_Resil.xhtml#page_88),\n[140](16_Chapter_8_Is_It_Reall.xhtml#page_140)\n\n_see also_ National Institute of Standards and Technology\n\nComprehensive National Cyber Initiative,\n[96](13_Chapter_6_Cyber_Resil.xhtml#page_96)\n\nCompTIA Security+ certification,\n[146](17_Chapter_9_Fixing_the_.xhtml#page_146)\n\nComputer Fraud and Abuse Act, [100](13_Chapter_6_Cyber_Resil.xhtml#page_100)\n\nCongress, U.S., [99](13_Chapter_6_Cyber_Resil.xhtml#page_99),\n[109](15_Chapter_7_Nudges_and_.xhtml#page_109),\n[114](15_Chapter_7_Nudges_and_.xhtml#page_114),\n[116](15_Chapter_7_Nudges_and_.xhtml#page_116)–18,\n[124](15_Chapter_7_Nudges_and_.xhtml#page_124),\n[130](16_Chapter_8_Is_It_Reall.xhtml#page_130),\n[144](17_Chapter_9_Fixing_the_.xhtml#page_144),\n[159](18_Chapter_10_Power_Grid.xhtml#page_159),\n[165](18_Chapter_10_Power_Grid.xhtml#page_165)–66,\n[171](19_Chapter_11_Securing_t.xhtml#page_171),\n[172](19_Chapter_11_Securing_t.xhtml#page_172),\n[178](19_Chapter_11_Securing_t.xhtml#page_178),\n[196](21_Chapter_12_The_Milita.xhtml#page_196),\n[214](22_Chapter_13_A_Schengen.xhtml#page_214),\n[228](23_Chapter_14_Democracy_.xhtml#page_228),\n[231](23_Chapter_14_Democracy_.xhtml#page_231)–33,\n[259](26_Chapter_16_A_Quantum_.xhtml#page_259),\n[268](27_Chapter_17_5g_and_Iot.xhtml#page_268)–69\n\nReallyU and, [138](16_Chapter_8_Is_It_Reall.xhtml#page_138),\n[140](16_Chapter_8_Is_It_Reall.xhtml#page_140),\n[141](16_Chapter_8_Is_It_Reall.xhtml#page_141)\n\nSenate, [78](12_Chapter_5_The_Tech_St.xhtml#page_78),\n[232](23_Chapter_14_Democracy_.xhtml#page_232)\n\nConley, Caitlin, [225](23_Chapter_14_Democracy_.xhtml#page_225)–26\n\nConstitution, U.S., [94](13_Chapter_6_Cyber_Resil.xhtml#page_94),\n[228](23_Chapter_14_Democracy_.xhtml#page_228)\n\ncontainers, [71](12_Chapter_5_The_Tech_St.xhtml#page_71),\n[77](12_Chapter_5_The_Tech_St.xhtml#page_77)\n\ncontractors, [170](19_Chapter_11_Securing_t.xhtml#page_170)–71,\n[174](19_Chapter_11_Securing_t.xhtml#page_174)\n\nCook, Tim, [124](15_Chapter_7_Nudges_and_.xhtml#page_124),\n[125](15_Chapter_7_Nudges_and_.xhtml#page_125)\n\nCornell University, [250](25_Chapter_15_Real_and_A.xhtml#page_250)\n\nCouncil of Europe Convention on Cybercrime,\n[212](22_Chapter_13_A_Schengen.xhtml#page_212)–13,\n[216](22_Chapter_13_A_Schengen.xhtml#page_216)\n\ncredit cards, [286](29_Chapter_18_Derisking_.xhtml#page_286)–87,\n[293](29_Chapter_18_Derisking_.xhtml#page_293)\n\ncredit reporting, [284](29_Chapter_18_Derisking_.xhtml#page_284)\n\nCrowdStrike, [33](10_Chapter_3_Two_Kinds_o.xhtml#page_33),\n[34](10_Chapter_3_Two_Kinds_o.xhtml#page_34),\n[36](10_Chapter_3_Two_Kinds_o.xhtml#page_36),\n[46](10_Chapter_3_Two_Kinds_o.xhtml#page_46),\n[55](11_Chapter_4_The_Kill_Ch.xhtml#page_55),\n[60](11_Chapter_4_The_Kill_Ch.xhtml#page_60),\n[61](11_Chapter_4_The_Kill_Ch.xhtml#page_61),\n[67](12_Chapter_5_The_Tech_St.xhtml#page_67),\n[77](12_Chapter_5_The_Tech_St.xhtml#page_77),\n[83](12_Chapter_5_The_Tech_St.xhtml#page_83)\n\ncryptocurrencies, [6](07_Chapter_1_The_Back_of.xhtml#page_6),\n[73](12_Chapter_5_The_Tech_St.xhtml#page_73),\n[289](29_Chapter_18_Derisking_.xhtml#page_289)\n\nCyber Command, [23](08_Chapter_2_Eternalblue.xhtml#page_23),\n[43](10_Chapter_3_Two_Kinds_o.xhtml#page_43),\n[97](13_Chapter_6_Cyber_Resil.xhtml#page_97),\n[150](17_Chapter_9_Fixing_the_.xhtml#page_150)–51,\n[173](19_Chapter_11_Securing_t.xhtml#page_173),\n[183](21_Chapter_12_The_Milita.xhtml#page_183),\n[184](21_Chapter_12_The_Milita.xhtml#page_184),\n[191](21_Chapter_12_The_Milita.xhtml#page_191)–98,\n[220](23_Chapter_14_Democracy_.xhtml#page_220),\n[233](23_Chapter_14_Democracy_.xhtml#page_233),\n[300](31_Glossary.xhtml#page_300)\n\nCyberCorps, [168](19_Chapter_11_Securing_t.xhtml#page_168)–70,\n[172](19_Chapter_11_Securing_t.xhtml#page_172)–73,\n[177](19_Chapter_11_Securing_t.xhtml#page_177),\n[178](19_Chapter_11_Securing_t.xhtml#page_178)\n\nCyber Defense Matrix, [65](12_Chapter_5_The_Tech_St.xhtml#page_65)–67,\n[82](12_Chapter_5_The_Tech_St.xhtml#page_82)\n\nCyber Independent Testing Lab, [82](12_Chapter_5_The_Tech_St.xhtml#page_82)\n\ncyber insurance, [5](07_Chapter_1_The_Back_of.xhtml#page_5),\n[121](15_Chapter_7_Nudges_and_.xhtml#page_121)–23\n\nCyber Operations Academy Course,\n[148](17_Chapter_9_Fixing_the_.xhtml#page_148)\n\ncyber resilience, [13](07_Chapter_1_The_Back_of.xhtml#page_13)–15,\n[42](10_Chapter_3_Two_Kinds_o.xhtml#page_42),\n[70](12_Chapter_5_The_Tech_St.xhtml#page_70)–72,\n[82](12_Chapter_5_The_Tech_St.xhtml#page_82),\n[104](13_Chapter_6_Cyber_Resil.xhtml#page_104),\n[105](13_Chapter_6_Cyber_Resil.xhtml#page_105),\n[296](30_Chapter_19_Everything.xhtml#page_296)–97\n\ncybersecurity:\n\nAI in, [244](25_Chapter_15_Real_and_A.xhtml#page_244)–48,\n[252](25_Chapter_15_Real_and_A.xhtml#page_252)\n\napprenticeship programs for, [152](17_Chapter_9_Fixing_the_.xhtml#page_152)–53\n\nbuilding in, [67](12_Chapter_5_The_Tech_St.xhtml#page_67),\n[72](12_Chapter_5_The_Tech_St.xhtml#page_72)\n\ncenter for policy on, [101](13_Chapter_6_Cyber_Resil.xhtml#page_101)\n\ndata on, [39](10_Chapter_3_Two_Kinds_o.xhtml#page_39)–43,\n[72](12_Chapter_5_The_Tech_St.xhtml#page_72)\n\ninformation sharing in, [58](11_Chapter_4_The_Kill_Ch.xhtml#page_58)–61,\n[95](13_Chapter_6_Cyber_Resil.xhtml#page_95),\n[112](15_Chapter_7_Nudges_and_.xhtml#page_112)\n\nas part of national security, [90](13_Chapter_6_Cyber_Resil.xhtml#page_90),\n[94](13_Chapter_6_Cyber_Resil.xhtml#page_94)\n\npersonal, [283](29_Chapter_18_Derisking_.xhtml#page_283)–93\n\nquantum computing and, [254](26_Chapter_16_A_Quantum_.xhtml#page_254)\n\nas shared responsibility between government and private sector,\n[10](07_Chapter_1_The_Back_of.xhtml#page_10)–13,\n[88](13_Chapter_6_Cyber_Resil.xhtml#page_88)–96,\n[105](13_Chapter_6_Cyber_Resil.xhtml#page_105)\n\nspending on, [5](07_Chapter_1_The_Back_of.xhtml#page_5),\n[91](13_Chapter_6_Cyber_Resil.xhtml#page_91)\n\nventure capital investment in, _see_ venture capital\n\nworkforce for, [144](17_Chapter_9_Fixing_the_.xhtml#page_144)–53,\n[167](19_Chapter_11_Securing_t.xhtml#page_167)–78\n\nCybersecurity and Infrastructure Security Agency (CISA),\n[171](19_Chapter_11_Securing_t.xhtml#page_171)–72,\n[177](19_Chapter_11_Securing_t.xhtml#page_177),\n[178](19_Chapter_11_Securing_t.xhtml#page_178),\n[300](31_Glossary.xhtml#page_300)\n\nCybersecurity Talent Initiative,\n[152](17_Chapter_9_Fixing_the_.xhtml#page_152)–53\n\nCyberseek, [145](17_Chapter_9_Fixing_the_.xhtml#page_145),\n[146](17_Chapter_9_Fixing_the_.xhtml#page_146)\n\ncyberspace, [6](07_Chapter_1_The_Back_of.xhtml#page_6),\n[88](13_Chapter_6_Cyber_Resil.xhtml#page_88),\n[208](22_Chapter_13_A_Schengen.xhtml#page_208),\n[210](22_Chapter_13_A_Schengen.xhtml#page_210)\n\nCyber Threat Alliance, [61](11_Chapter_4_The_Kill_Ch.xhtml#page_61)\n\ncyber war, [7](07_Chapter_1_The_Back_of.xhtml#page_7)–10,\n[19](08_Chapter_2_Eternalblue.xhtml#page_19),\n[182](21_Chapter_12_The_Milita.xhtml#page_182)–84,\n[197](21_Chapter_12_The_Milita.xhtml#page_197)–98,\n[221](23_Chapter_14_Democracy_.xhtml#page_221),\n[239](25_Chapter_15_Real_and_A.xhtml#page_239),\n[296](30_Chapter_19_Everything.xhtml#page_296)–97\n\nAI in, [239](25_Chapter_15_Real_and_A.xhtml#page_239)–41\n\ndiplomacy and, [202](21_Chapter_12_The_Milita.xhtml#page_202)–3\n\nescalation of instability into,\n[28](08_Chapter_2_Eternalblue.xhtml#page_28)–29,\n[198](21_Chapter_12_The_Milita.xhtml#page_198)\n\nnaming cyber warriors, [27](08_Chapter_2_Eternalblue.xhtml#page_27)–28\n\nquantum computing and, [254](26_Chapter_16_A_Quantum_.xhtml#page_254),\n[263](26_Chapter_16_A_Quantum_.xhtml#page_263)–64\n\n_Cyber War_ (Clarke and Knake), [6](07_Chapter_1_The_Back_of.xhtml#page_6)–7,\n[13](07_Chapter_1_The_Back_of.xhtml#page_13),\n[26](08_Chapter_2_Eternalblue.xhtml#page_26),\n[37](10_Chapter_3_Two_Kinds_o.xhtml#page_37),\n[78](12_Chapter_5_The_Tech_St.xhtml#page_78),\n[192](21_Chapter_12_The_Milita.xhtml#page_192),\n[200](21_Chapter_12_The_Milita.xhtml#page_200)\n\nCyber War Risk Insurance Act (CWRIA),\n[123](15_Chapter_7_Nudges_and_.xhtml#page_123),\n[301](31_Glossary.xhtml#page_301)\n\nCylance, [34](10_Chapter_3_Two_Kinds_o.xhtml#page_34),\n[55](11_Chapter_4_The_Kill_Ch.xhtml#page_55),\n[67](12_Chapter_5_The_Tech_St.xhtml#page_67),\n[83](12_Chapter_5_The_Tech_St.xhtml#page_83)\n\nDaniel, Michael, [61](11_Chapter_4_The_Kill_Ch.xhtml#page_61),\n[92](13_Chapter_6_Cyber_Resil.xhtml#page_92)–93,\n[205](22_Chapter_13_A_Schengen.xhtml#page_205)\n\nDarktrace, [246](25_Chapter_15_Real_and_A.xhtml#page_246)\n\ndark web, [38](10_Chapter_3_Two_Kinds_o.xhtml#page_38),\n[40](10_Chapter_3_Two_Kinds_o.xhtml#page_40),\n[41](10_Chapter_3_Two_Kinds_o.xhtml#page_41),\n[126](15_Chapter_7_Nudges_and_.xhtml#page_126)\n\ndata, [257](26_Chapter_16_A_Quantum_.xhtml#page_257)\n\nAI and, [247](25_Chapter_15_Real_and_A.xhtml#page_247)–48,\n[251](25_Chapter_15_Real_and_A.xhtml#page_251)\n\nbacking up, [127](15_Chapter_7_Nudges_and_.xhtml#page_127),\n[291](29_Chapter_18_Derisking_.xhtml#page_291)–92\n\non security, [39](10_Chapter_3_Two_Kinds_o.xhtml#page_39)–43,\n[72](12_Chapter_5_The_Tech_St.xhtml#page_72)\n\ndata lake, [247](25_Chapter_15_Real_and_A.xhtml#page_247),\n[301](31_Glossary.xhtml#page_301)\n\ndata mining, [243](25_Chapter_15_Real_and_A.xhtml#page_243)\n\nDEF CON, [73](12_Chapter_5_The_Tech_St.xhtml#page_73),\n[102](13_Chapter_6_Cyber_Resil.xhtml#page_102),\n[127](15_Chapter_7_Nudges_and_.xhtml#page_127)\n\nDefending Digital Democracy, [225](23_Chapter_14_Democracy_.xhtml#page_225)–26\n\ndefense, _see_ offense and defense\n\nDefense Advanced Research Projects Agency (DARPA),\n[12](07_Chapter_1_The_Back_of.xhtml#page_12),\n[78](12_Chapter_5_The_Tech_St.xhtml#page_78),\n[249](25_Chapter_15_Real_and_A.xhtml#page_249)–50,\n[252](25_Chapter_15_Real_and_A.xhtml#page_252),\n[301](31_Glossary.xhtml#page_301)\n\nDefense Cyber Crime Center, [198](21_Chapter_12_The_Milita.xhtml#page_198)\n\nDefense Department (DoD), [6](07_Chapter_1_The_Back_of.xhtml#page_6),\n[27](08_Chapter_2_Eternalblue.xhtml#page_27),\n[79](12_Chapter_5_The_Tech_St.xhtml#page_79),\n[81](12_Chapter_5_The_Tech_St.xhtml#page_81),\n[94](13_Chapter_6_Cyber_Resil.xhtml#page_94)–95,\n[132](16_Chapter_8_Is_It_Reall.xhtml#page_132),\n[147](17_Chapter_9_Fixing_the_.xhtml#page_147),\n[149](17_Chapter_9_Fixing_the_.xhtml#page_149),\n[152](17_Chapter_9_Fixing_the_.xhtml#page_152),\n[165](18_Chapter_10_Power_Grid.xhtml#page_165),\n[176](19_Chapter_11_Securing_t.xhtml#page_176),\n[181](21_Chapter_12_The_Milita.xhtml#page_181)–203,\n[181](21_Chapter_12_The_Milita.xhtml#page_181)–203,\n[221](23_Chapter_14_Democracy_.xhtml#page_221)–22,\n[225](23_Chapter_14_Democracy_.xhtml#page_225),\n[229](23_Chapter_14_Democracy_.xhtml#page_229)–30,\n[249](25_Chapter_15_Real_and_A.xhtml#page_249)\n\nbudget of, [201](21_Chapter_12_The_Milita.xhtml#page_201)\n\nclarity of mission in, [199](21_Chapter_12_The_Milita.xhtml#page_199)–200\n\nCyber Command, _see_ Cyber Command\n\nCyber Strategy of, [181](21_Chapter_12_The_Milita.xhtml#page_181)–82,\n[195](21_Chapter_12_The_Milita.xhtml#page_195)\n\ndiplomacy and, [202](21_Chapter_12_The_Milita.xhtml#page_202)–3\n\nescalation dominance and, [202](21_Chapter_12_The_Milita.xhtml#page_202)\n\nfive missions of, [184](21_Chapter_12_The_Milita.xhtml#page_184)–92\n\nNational Security Agency, _see_ National Security Agency\n\nand securing arsenal, [200](21_Chapter_12_The_Milita.xhtml#page_200)–201\n\nsystem failure capabilities and,\n[202](21_Chapter_12_The_Milita.xhtml#page_202)\n\ntabletop exercises and, [185](21_Chapter_12_The_Milita.xhtml#page_185)–92,\n[198](21_Chapter_12_The_Milita.xhtml#page_198),\n[225](23_Chapter_14_Democracy_.xhtml#page_225)–26\n\nunity of command in, [198](21_Chapter_12_The_Milita.xhtml#page_198)–99\n\ndefense industrial base (DIB), [49](11_Chapter_4_The_Kill_Ch.xhtml#page_49),\n[50](11_Chapter_4_The_Kill_Ch.xhtml#page_50),\n[184](21_Chapter_12_The_Milita.xhtml#page_184),\n[190](21_Chapter_12_The_Milita.xhtml#page_190),\n[301](31_Glossary.xhtml#page_301)\n\nDefense Information Systems Agency,\n[198](21_Chapter_12_The_Milita.xhtml#page_198)\n\nDefense Science Board, [190](21_Chapter_12_The_Milita.xhtml#page_190)\n\nDemchak, Chris, [120](15_Chapter_7_Nudges_and_.xhtml#page_120)\n\nDemocratic Congressional Campaign Committee,\n[231](23_Chapter_14_Democracy_.xhtml#page_231)–32,\n[302](31_Glossary.xhtml#page_302)\n\nDemocratic National Committee, [26](08_Chapter_2_Eternalblue.xhtml#page_26)\n\nDemocratic Party, [11](07_Chapter_1_The_Back_of.xhtml#page_11),\n[224](23_Chapter_14_Democracy_.xhtml#page_224)\n\nDeputies Committee, [222](23_Chapter_14_Democracy_.xhtml#page_222)\n\nDeputy Assistant Secretary of Defense (DASD),\n[198](21_Chapter_12_The_Milita.xhtml#page_198),\n[225](23_Chapter_14_Democracy_.xhtml#page_225)\n\ndesign basis threat, [115](15_Chapter_7_Nudges_and_.xhtml#page_115)\n\n“detect” function, [45](10_Chapter_3_Two_Kinds_o.xhtml#page_45),\n[66](12_Chapter_5_The_Tech_St.xhtml#page_66),\n[70](12_Chapter_5_The_Tech_St.xhtml#page_70)–71\n\nDevOps, [72](12_Chapter_5_The_Tech_St.xhtml#page_72),\n[80](12_Chapter_5_The_Tech_St.xhtml#page_80)\n\nDevost, Matt, [295](30_Chapter_19_Everything.xhtml#page_295)\n\nDiGiovanni, Frank, [143](17_Chapter_9_Fixing_the_.xhtml#page_143),\n[147](17_Chapter_9_Fixing_the_.xhtml#page_147)–50,\n[153](17_Chapter_9_Fixing_the_.xhtml#page_153)\n\n_Digital Resilience_ (Rothrock), [14](07_Chapter_1_The_Back_of.xhtml#page_14)\n\nDimon, Jamie, [91](13_Chapter_6_Cyber_Resil.xhtml#page_91),\n[92](13_Chapter_6_Cyber_Resil.xhtml#page_92),\n[191](21_Chapter_12_The_Milita.xhtml#page_191)\n\ndiplomacy, [202](21_Chapter_12_The_Milita.xhtml#page_202)–3,\n[218](22_Chapter_13_A_Schengen.xhtml#page_218),\n[221](23_Chapter_14_Democracy_.xhtml#page_221)\n\ndirect-recording electronic (DRE) machines,\n[230](23_Chapter_14_Democracy_.xhtml#page_230)–31,\n[301](31_Glossary.xhtml#page_301)\n\ndistributed denial-of-service (DDoS) attacks,\n[38](10_Chapter_3_Two_Kinds_o.xhtml#page_38),\n[73](12_Chapter_5_The_Tech_St.xhtml#page_73),\n[85](13_Chapter_6_Cyber_Resil.xhtml#page_85)–87,\n[118](15_Chapter_7_Nudges_and_.xhtml#page_118)–19,\n[191](21_Chapter_12_The_Milita.xhtml#page_191),\n[215](22_Chapter_13_A_Schengen.xhtml#page_215),\n[268](27_Chapter_17_5g_and_Iot.xhtml#page_268),\n[276](27_Chapter_17_5g_and_Iot.xhtml#page_276),\n[301](31_Glossary.xhtml#page_301)\n\nDLA Piper, [19](08_Chapter_2_Eternalblue.xhtml#page_19),\n[37](10_Chapter_3_Two_Kinds_o.xhtml#page_37)\n\nDocker, [71](12_Chapter_5_The_Tech_St.xhtml#page_71),\n[77](12_Chapter_5_The_Tech_St.xhtml#page_77)\n\ndomain names, [88](13_Chapter_6_Cyber_Resil.xhtml#page_88)\n\nDomain Name System (DNS), [12](07_Chapter_1_The_Back_of.xhtml#page_12),\n[118](15_Chapter_7_Nudges_and_.xhtml#page_118)–20,\n[207](22_Chapter_13_A_Schengen.xhtml#page_207),\n[210](22_Chapter_13_A_Schengen.xhtml#page_210),\n[276](27_Chapter_17_5g_and_Iot.xhtml#page_276),\n[301](31_Glossary.xhtml#page_301)\n\nDornbush, Evan, [148](17_Chapter_9_Fixing_the_.xhtml#page_148),\n[149](17_Chapter_9_Fixing_the_.xhtml#page_149)\n\ndriver’s licenses, [135](16_Chapter_8_Is_It_Reall.xhtml#page_135)–37\n\ndrones, [248](25_Chapter_15_Real_and_A.xhtml#page_248)–50\n\nD-Trip, [231](23_Chapter_14_Democracy_.xhtml#page_231)–32,\n[302](31_Glossary.xhtml#page_302)\n\nDugan, Regina, [249](25_Chapter_15_Real_and_A.xhtml#page_249)\n\nDuo, [131](16_Chapter_8_Is_It_Reall.xhtml#page_131)–33\n\nDyn, [276](27_Chapter_17_5g_and_Iot.xhtml#page_276)–77\n\n_Economist_ , [103](13_Chapter_6_Cyber_Resil.xhtml#page_103),\n[181](21_Chapter_12_The_Milita.xhtml#page_181)\n\neconomy, [8](07_Chapter_1_The_Back_of.xhtml#page_8),\n[109](15_Chapter_7_Nudges_and_.xhtml#page_109)–10\n\nEdelman, David, [210](22_Chapter_13_A_Schengen.xhtml#page_210)\n\nEinstein, Albert, [9](07_Chapter_1_The_Back_of.xhtml#page_9),\n[256](26_Chapter_16_A_Quantum_.xhtml#page_256)\n\nEinstein program, [95](13_Chapter_6_Cyber_Resil.xhtml#page_95),\n[96](13_Chapter_6_Cyber_Resil.xhtml#page_96)\n\nelections, [219](23_Chapter_14_Democracy_.xhtml#page_219)–35\n\nRussia and, [26](08_Chapter_2_Eternalblue.xhtml#page_26),\n[159](18_Chapter_10_Power_Grid.xhtml#page_159),\n[160](18_Chapter_10_Power_Grid.xhtml#page_160),\n[222](23_Chapter_14_Democracy_.xhtml#page_222)–23,\n[227](23_Chapter_14_Democracy_.xhtml#page_227),\n[228](23_Chapter_14_Democracy_.xhtml#page_228),\n[230](23_Chapter_14_Democracy_.xhtml#page_230)–35\n\nof 2016, [26](08_Chapter_2_Eternalblue.xhtml#page_26),\n[159](18_Chapter_10_Power_Grid.xhtml#page_159),\n[160](18_Chapter_10_Power_Grid.xhtml#page_160),\n[222](23_Chapter_14_Democracy_.xhtml#page_222)–23,\n[227](23_Chapter_14_Democracy_.xhtml#page_227),\n[228](23_Chapter_14_Democracy_.xhtml#page_228),\n[230](23_Chapter_14_Democracy_.xhtml#page_230),\n[232](23_Chapter_14_Democracy_.xhtml#page_232)–35\n\nElectronic Frontier Foundation (EFF),\n[207](22_Chapter_13_A_Schengen.xhtml#page_207),\n[208](22_Chapter_13_A_Schengen.xhtml#page_208)\n\nElectronic Funds Transfer Act, [115](15_Chapter_7_Nudges_and_.xhtml#page_115)\n\nemail, [46](10_Chapter_3_Two_Kinds_o.xhtml#page_46),\n[52](11_Chapter_4_The_Kill_Ch.xhtml#page_52)–55,\n[59](11_Chapter_4_The_Kill_Ch.xhtml#page_59),\n[133](16_Chapter_8_Is_It_Reall.xhtml#page_133),\n[288](29_Chapter_18_Derisking_.xhtml#page_288)–89,\n[291](29_Chapter_18_Derisking_.xhtml#page_291)\n\nencryption, [10](07_Chapter_1_The_Back_of.xhtml#page_10),\n[18](08_Chapter_2_Eternalblue.xhtml#page_18),\n[96](13_Chapter_6_Cyber_Resil.xhtml#page_96),\n[103](13_Chapter_6_Cyber_Resil.xhtml#page_103),\n[124](15_Chapter_7_Nudges_and_.xhtml#page_124)–25,\n[260](26_Chapter_16_A_Quantum_.xhtml#page_260)–62,\n[291](29_Chapter_18_Derisking_.xhtml#page_291),\n[292](29_Chapter_18_Derisking_.xhtml#page_292),\n[302](31_Glossary.xhtml#page_302)\n\nEndgame, [251](25_Chapter_15_Real_and_A.xhtml#page_251)\n\nendpoint detection and response (EDR),\n[55](11_Chapter_4_The_Kill_Ch.xhtml#page_55),\n[61](11_Chapter_4_The_Kill_Ch.xhtml#page_61),\n[83](12_Chapter_5_The_Tech_St.xhtml#page_83),\n[96](13_Chapter_6_Cyber_Resil.xhtml#page_96)–97,\n[149](17_Chapter_9_Fixing_the_.xhtml#page_149),\n[163](18_Chapter_10_Power_Grid.xhtml#page_163),\n[175](19_Chapter_11_Securing_t.xhtml#page_175),\n[298](30_Chapter_19_Everything.xhtml#page_298)\n\nendpoints, [65](12_Chapter_5_The_Tech_St.xhtml#page_65),\n[245](25_Chapter_15_Real_and_A.xhtml#page_245),\n[302](31_Glossary.xhtml#page_302)\n\nEnergy Services Group, [272](27_Chapter_17_5g_and_Iot.xhtml#page_272),\n[276](27_Chapter_17_5g_and_Iot.xhtml#page_276)\n\nEquifax, [115](15_Chapter_7_Nudges_and_.xhtml#page_115)–16,\n[284](29_Chapter_18_Derisking_.xhtml#page_284)\n\nEscalate, [149](17_Chapter_9_Fixing_the_.xhtml#page_149),\n[152](17_Chapter_9_Fixing_the_.xhtml#page_152)\n\nEternalBlue, [18](08_Chapter_2_Eternalblue.xhtml#page_18),\n[22](08_Chapter_2_Eternalblue.xhtml#page_22),\n[23](08_Chapter_2_Eternalblue.xhtml#page_23)\n\nEuropean Commission, [216](22_Chapter_13_A_Schengen.xhtml#page_216)\n\nEuropean Union (EU), [206](22_Chapter_13_A_Schengen.xhtml#page_206)–7,\n[211](22_Chapter_13_A_Schengen.xhtml#page_211)–12,\n[220](23_Chapter_14_Democracy_.xhtml#page_220)–21\n\nexploits, [21](08_Chapter_2_Eternalblue.xhtml#page_21),\n[35](10_Chapter_3_Two_Kinds_o.xhtml#page_35),\n[51](11_Chapter_4_The_Kill_Ch.xhtml#page_51),\n[57](11_Chapter_4_The_Kill_Ch.xhtml#page_57)–58,\n[302](31_Glossary.xhtml#page_302)\n\nExtended Area Protection and Survivability System,\n[190](21_Chapter_12_The_Milita.xhtml#page_190)\n\nFacebook, [67](12_Chapter_5_The_Tech_St.xhtml#page_67),\n[71](12_Chapter_5_The_Tech_St.xhtml#page_71),\n[91](13_Chapter_6_Cyber_Resil.xhtml#page_91),\n[134](16_Chapter_8_Is_It_Reall.xhtml#page_134),\n[209](22_Chapter_13_A_Schengen.xhtml#page_209),\n[213](22_Chapter_13_A_Schengen.xhtml#page_213),\n[221](23_Chapter_14_Democracy_.xhtml#page_221),\n[224](23_Chapter_14_Democracy_.xhtml#page_224),\n[231](23_Chapter_14_Democracy_.xhtml#page_231),\n[232](23_Chapter_14_Democracy_.xhtml#page_232),\n[285](29_Chapter_18_Derisking_.xhtml#page_285),\n[287](29_Chapter_18_Derisking_.xhtml#page_287)–88,\n[292](29_Chapter_18_Derisking_.xhtml#page_292)\n\nFarook, Syed, [123](15_Chapter_7_Nudges_and_.xhtml#page_123)–25\n\nFATF-style regional bodies, [216](22_Chapter_13_A_Schengen.xhtml#page_216)\n\nFBI, [22](08_Chapter_2_Eternalblue.xhtml#page_22),\n[23](08_Chapter_2_Eternalblue.xhtml#page_23),\n[43](10_Chapter_3_Two_Kinds_o.xhtml#page_43),\n[78](12_Chapter_5_The_Tech_St.xhtml#page_78),\n[93](13_Chapter_6_Cyber_Resil.xhtml#page_93),\n[95](13_Chapter_6_Cyber_Resil.xhtml#page_95),\n[98](13_Chapter_6_Cyber_Resil.xhtml#page_98),\n[99](13_Chapter_6_Cyber_Resil.xhtml#page_99),\n[124](15_Chapter_7_Nudges_and_.xhtml#page_124)–25,\n[152](17_Chapter_9_Fixing_the_.xhtml#page_152)\n\nFederal Aviation Administration,\n[279](27_Chapter_17_5g_and_Iot.xhtml#page_279)\n\nFederal Communications Commission (FCC),\n[120](15_Chapter_7_Nudges_and_.xhtml#page_120),\n[268](27_Chapter_17_5g_and_Iot.xhtml#page_268)–69\n\nFederal Deposit Insurance Corporation,\n[115](15_Chapter_7_Nudges_and_.xhtml#page_115)\n\nFederal Energy Regulatory Commission (FERC),\n[158](18_Chapter_10_Power_Grid.xhtml#page_158),\n[279](27_Chapter_17_5g_and_Iot.xhtml#page_279)\n\nFederal Financial Institutions Examination Council,\n[114](15_Chapter_7_Nudges_and_.xhtml#page_114)\n\nFederal Trade Commission, [232](23_Chapter_14_Democracy_.xhtml#page_232)\n\nFedEx, [19](08_Chapter_2_Eternalblue.xhtml#page_19),\n[37](10_Chapter_3_Two_Kinds_o.xhtml#page_37)\n\n_Fierce Domain, A_ (Healey), [102](13_Chapter_6_Cyber_Resil.xhtml#page_102)\n\nFinancial Action Task Force (FATF),\n[216](22_Chapter_13_A_Schengen.xhtml#page_216),\n[302](31_Glossary.xhtml#page_302)\n\nFinancial Services Information Sharing and Analysis Center,\n[59](11_Chapter_4_The_Kill_Ch.xhtml#page_59)–60\n\nFinancial Systemic Analysis & Resilience Center (FSARC),\n[60](11_Chapter_4_The_Kill_Ch.xhtml#page_60)\n\n_Financial Times_ , [94](13_Chapter_6_Cyber_Resil.xhtml#page_94)\n\nfingerprint readers, [131](16_Chapter_8_Is_It_Reall.xhtml#page_131)\n\nFireEye, [34](10_Chapter_3_Two_Kinds_o.xhtml#page_34),\n[36](10_Chapter_3_Two_Kinds_o.xhtml#page_36),\n[53](11_Chapter_4_The_Kill_Ch.xhtml#page_53)\n\nfirewalls, [70](12_Chapter_5_The_Tech_St.xhtml#page_70),\n[87](13_Chapter_6_Cyber_Resil.xhtml#page_87),\n[159](18_Chapter_10_Power_Grid.xhtml#page_159),\n[160](18_Chapter_10_Power_Grid.xhtml#page_160)\n\n5G mobile telephony, [265](27_Chapter_17_5g_and_Iot.xhtml#page_265)–69,\n[280](27_Chapter_17_5g_and_Iot.xhtml#page_280)\n\nFive Guys, [21](08_Chapter_2_Eternalblue.xhtml#page_21)–22\n\nFly, Jamie, [223](23_Chapter_14_Democracy_.xhtml#page_223)\n\nFood and Drug Administration (FDA),\n[275](27_Chapter_17_5g_and_Iot.xhtml#page_275)–76,\n[278](27_Chapter_17_5g_and_Iot.xhtml#page_278)–79\n\nFrance, [25](08_Chapter_2_Eternalblue.xhtml#page_25),\n[209](22_Chapter_13_A_Schengen.xhtml#page_209)\n\nFriedman, Allan, [101](13_Chapter_6_Cyber_Resil.xhtml#page_101)\n\nGable, Jim, [258](26_Chapter_16_A_Quantum_.xhtml#page_258)\n\nGagnon, Gary, [56](11_Chapter_4_The_Kill_Ch.xhtml#page_56)–58\n\nGartner, Inc., [65](12_Chapter_5_The_Tech_St.xhtml#page_65),\n[274](27_Chapter_17_5g_and_Iot.xhtml#page_274)\n\ngas industry, [272](27_Chapter_17_5g_and_Iot.xhtml#page_272)–73\n\nGates, Bill, [129](16_Chapter_8_Is_It_Reall.xhtml#page_129)–31,\n[133](16_Chapter_8_Is_It_Reall.xhtml#page_133)\n\nGeist, Michael, [213](22_Chapter_13_A_Schengen.xhtml#page_213)\n\nGermany, [209](22_Chapter_13_A_Schengen.xhtml#page_209),\n[214](22_Chapter_13_A_Schengen.xhtml#page_214),\n[215](22_Chapter_13_A_Schengen.xhtml#page_215)\n\nGibson, William, [3](07_Chapter_1_The_Back_of.xhtml#page_3),\n[10](07_Chapter_1_The_Back_of.xhtml#page_10),\n[208](22_Chapter_13_A_Schengen.xhtml#page_208)\n\nGillespie, Ed, [230](23_Chapter_14_Democracy_.xhtml#page_230)\n\nGlobal Information Assurance Certification,\n[146](17_Chapter_9_Fixing_the_.xhtml#page_146)\n\nglossary, [299](31_Glossary.xhtml#page_299)–308\n\nGoldsmith, Jack, [208](22_Chapter_13_A_Schengen.xhtml#page_208)\n\nGoogle, [8](07_Chapter_1_The_Back_of.xhtml#page_8),\n[52](11_Chapter_4_The_Kill_Ch.xhtml#page_52),\n[63](12_Chapter_5_The_Tech_St.xhtml#page_63)–64,\n[74](12_Chapter_5_The_Tech_St.xhtml#page_74)–76,\n[80](12_Chapter_5_The_Tech_St.xhtml#page_80),\n[81](12_Chapter_5_The_Tech_St.xhtml#page_81),\n[91](13_Chapter_6_Cyber_Resil.xhtml#page_91),\n[132](16_Chapter_8_Is_It_Reall.xhtml#page_132),\n[134](16_Chapter_8_Is_It_Reall.xhtml#page_134),\n[138](16_Chapter_8_Is_It_Reall.xhtml#page_138),\n[149](17_Chapter_9_Fixing_the_.xhtml#page_149),\n[153](17_Chapter_9_Fixing_the_.xhtml#page_153),\n[205](22_Chapter_13_A_Schengen.xhtml#page_205),\n[209](22_Chapter_13_A_Schengen.xhtml#page_209),\n[213](22_Chapter_13_A_Schengen.xhtml#page_213),\n[232](23_Chapter_14_Democracy_.xhtml#page_232),\n[253](26_Chapter_16_A_Quantum_.xhtml#page_253),\n[258](26_Chapter_16_A_Quantum_.xhtml#page_258),\n[259](26_Chapter_16_A_Quantum_.xhtml#page_259),\n[261](26_Chapter_16_A_Quantum_.xhtml#page_261),\n[263](26_Chapter_16_A_Quantum_.xhtml#page_263)\n\ngovernment, [24](08_Chapter_2_Eternalblue.xhtml#page_24),\n[85](13_Chapter_6_Cyber_Resil.xhtml#page_85)–88,\n[109](15_Chapter_7_Nudges_and_.xhtml#page_109)–28,\n[297](30_Chapter_19_Everything.xhtml#page_297)\n\ncloud and, [77](12_Chapter_5_The_Tech_St.xhtml#page_77)\n\ncybersecurity as shared responsibility between private sector and,\n[10](07_Chapter_1_The_Back_of.xhtml#page_10)–13,\n[88](13_Chapter_6_Cyber_Resil.xhtml#page_88)–96,\n[105](13_Chapter_6_Cyber_Resil.xhtml#page_105)\n\ncybersecurity positions and, [153](17_Chapter_9_Fixing_the_.xhtml#page_153),\n[167](19_Chapter_11_Securing_t.xhtml#page_167)–78\n\nequities issue and, [21](08_Chapter_2_Eternalblue.xhtml#page_21)\n\nidentification and, [134](16_Chapter_8_Is_It_Reall.xhtml#page_134),\n[135](16_Chapter_8_Is_It_Reall.xhtml#page_135),\n[139](16_Chapter_8_Is_It_Reall.xhtml#page_139)–41\n\ninternet and, [12](07_Chapter_1_The_Back_of.xhtml#page_12)–13,\n[86](13_Chapter_6_Cyber_Resil.xhtml#page_86),\n[88](13_Chapter_6_Cyber_Resil.xhtml#page_88)\n\nand naming cyber warriors, [27](08_Chapter_2_Eternalblue.xhtml#page_27)–28\n\nnational security and, [88](13_Chapter_6_Cyber_Resil.xhtml#page_88),\n[90](13_Chapter_6_Cyber_Resil.xhtml#page_90),\n[153](17_Chapter_9_Fixing_the_.xhtml#page_153)\n\nPresidential Decision Directive 63 and,\n[10](07_Chapter_1_The_Back_of.xhtml#page_10)–11,\n[59](11_Chapter_4_The_Kill_Ch.xhtml#page_59),\n[89](13_Chapter_6_Cyber_Resil.xhtml#page_89)\n\nregulation by, [109](15_Chapter_7_Nudges_and_.xhtml#page_109)–20,\n[122](15_Chapter_7_Nudges_and_.xhtml#page_122)–23,\n[139](16_Chapter_8_Is_It_Reall.xhtml#page_139)–40,\n[268](27_Chapter_17_5g_and_Iot.xhtml#page_268)–69,\n[278](27_Chapter_17_5g_and_Iot.xhtml#page_278)\n\nsmart cards and, [130](16_Chapter_8_Is_It_Reall.xhtml#page_130)\n\nstate, [117](15_Chapter_7_Nudges_and_.xhtml#page_117)–18,\n[174](19_Chapter_11_Securing_t.xhtml#page_174)–75,\n[177](19_Chapter_11_Securing_t.xhtml#page_177)\n\nGovernment Accountability Office (GAO),\n[175](19_Chapter_11_Securing_t.xhtml#page_175),\n[189](21_Chapter_12_The_Milita.xhtml#page_189),\n[200](21_Chapter_12_The_Milita.xhtml#page_200)\n\nGranholm, Jennifer, [155](18_Chapter_10_Power_Grid.xhtml#page_155)\n\nGrant, Jeremy, [135](16_Chapter_8_Is_It_Reall.xhtml#page_135),\n[136](16_Chapter_8_Is_It_Reall.xhtml#page_136)\n\nGreat Britain, [17](08_Chapter_2_Eternalblue.xhtml#page_17)–18,\n[25](08_Chapter_2_Eternalblue.xhtml#page_25),\n[96](13_Chapter_6_Cyber_Resil.xhtml#page_96),\n[211](22_Chapter_13_A_Schengen.xhtml#page_211)–12,\n[220](23_Chapter_14_Democracy_.xhtml#page_220)–21\n\nGroup of 7, [216](22_Chapter_13_A_Schengen.xhtml#page_216)\n\nGRU, [19](08_Chapter_2_Eternalblue.xhtml#page_19)–23,\n[25](08_Chapter_2_Eternalblue.xhtml#page_25)–26,\n[28](08_Chapter_2_Eternalblue.xhtml#page_28),\n[165](18_Chapter_10_Power_Grid.xhtml#page_165),\n[234](23_Chapter_14_Democracy_.xhtml#page_234),\n[277](27_Chapter_17_5g_and_Iot.xhtml#page_277),\n[302](31_Glossary.xhtml#page_302)\n\nGuido, Dan, [81](12_Chapter_5_The_Tech_St.xhtml#page_81)\n\nhackers, [73](12_Chapter_5_The_Tech_St.xhtml#page_73),\n[78](12_Chapter_5_The_Tech_St.xhtml#page_78),\n[79](12_Chapter_5_The_Tech_St.xhtml#page_79),\n[127](15_Chapter_7_Nudges_and_.xhtml#page_127),\n[147](17_Chapter_9_Fixing_the_.xhtml#page_147)–48,\n[251](25_Chapter_15_Real_and_A.xhtml#page_251)\n\nHagel, Chuck, [225](23_Chapter_14_Democracy_.xhtml#page_225)\n\nHarkins, Malcolm, [83](12_Chapter_5_The_Tech_St.xhtml#page_83)\n\nHarris, Kamala, [117](15_Chapter_7_Nudges_and_.xhtml#page_117)\n\nHarvard University, [44](10_Chapter_3_Two_Kinds_o.xhtml#page_44),\n[152](17_Chapter_9_Fixing_the_.xhtml#page_152)\n\nBelfer Center, [100](13_Chapter_6_Cyber_Resil.xhtml#page_100),\n[225](23_Chapter_14_Democracy_.xhtml#page_225)\n\nHayden, Michael, [35](10_Chapter_3_Two_Kinds_o.xhtml#page_35)\n\nHealey, Jason, [102](13_Chapter_6_Cyber_Resil.xhtml#page_102)–3\n\nHealth and Human Services Department (HHS),\n[40](10_Chapter_3_Two_Kinds_o.xhtml#page_40),\n[136](16_Chapter_8_Is_It_Reall.xhtml#page_136)\n\nhealth care, [40](10_Chapter_3_Two_Kinds_o.xhtml#page_40)–42,\n[83](12_Chapter_5_The_Tech_St.xhtml#page_83),\n[123](15_Chapter_7_Nudges_and_.xhtml#page_123)\n\nHernandez, Steve, [170](19_Chapter_11_Securing_t.xhtml#page_170)\n\nHomeland Security, Department of (DHS),\n[6](07_Chapter_1_The_Back_of.xhtml#page_6),\n[21](08_Chapter_2_Eternalblue.xhtml#page_21),\n[86](13_Chapter_6_Cyber_Resil.xhtml#page_86),\n[93](13_Chapter_6_Cyber_Resil.xhtml#page_93),\n[95](13_Chapter_6_Cyber_Resil.xhtml#page_95),\n[96](13_Chapter_6_Cyber_Resil.xhtml#page_96),\n[109](15_Chapter_7_Nudges_and_.xhtml#page_109),\n[110](15_Chapter_7_Nudges_and_.xhtml#page_110),\n[113](15_Chapter_7_Nudges_and_.xhtml#page_113),\n[114](15_Chapter_7_Nudges_and_.xhtml#page_114),\n[136](16_Chapter_8_Is_It_Reall.xhtml#page_136),\n[152](17_Chapter_9_Fixing_the_.xhtml#page_152),\n[168](19_Chapter_11_Securing_t.xhtml#page_168),\n[175](19_Chapter_11_Securing_t.xhtml#page_175),\n[191](21_Chapter_12_The_Milita.xhtml#page_191),\n[199](21_Chapter_12_The_Milita.xhtml#page_199)\n\nCybersecurity and Infrastructure Security Agency,\n[171](19_Chapter_11_Securing_t.xhtml#page_171)–72,\n[177](19_Chapter_11_Securing_t.xhtml#page_177),\n[178](19_Chapter_11_Securing_t.xhtml#page_178)\n\nOffice of Cybersecurity and Communications,\n[151](17_Chapter_9_Fixing_the_.xhtml#page_151)\n\npower grid and, [158](18_Chapter_10_Power_Grid.xhtml#page_158)–59,\n[162](18_Chapter_10_Power_Grid.xhtml#page_162)\n\nHomeland Security Council, [102](13_Chapter_6_Cyber_Resil.xhtml#page_102)\n\nHomeland Security Policy Directive 7 (HSPD 7),\n[89](13_Chapter_6_Cyber_Resil.xhtml#page_89)\n\nHomeland Security Presidential Directive 12,\n[130](16_Chapter_8_Is_It_Reall.xhtml#page_130)\n\nHomer, Jonathan, [159](18_Chapter_10_Power_Grid.xhtml#page_159)\n\nhoneypots, [246](25_Chapter_15_Real_and_A.xhtml#page_246),\n[303](31_Glossary.xhtml#page_303)\n\nHoward, Rick, [60](11_Chapter_4_The_Kill_Ch.xhtml#page_60)–61\n\nHuang Zhenyu, [28](08_Chapter_2_Eternalblue.xhtml#page_28)\n\nHuawei, [267](27_Chapter_17_5g_and_Iot.xhtml#page_267)–68\n\nIBM, [80](12_Chapter_5_The_Tech_St.xhtml#page_80),\n[251](25_Chapter_15_Real_and_A.xhtml#page_251),\n[253](26_Chapter_16_A_Quantum_.xhtml#page_253),\n[258](26_Chapter_16_A_Quantum_.xhtml#page_258),\n[261](26_Chapter_16_A_Quantum_.xhtml#page_261)\n\nIdaho National Laboratory, [157](18_Chapter_10_Power_Grid.xhtml#page_157)\n\nIdaho State University, [167](19_Chapter_11_Securing_t.xhtml#page_167)–70\n\n“identify” function, [45](10_Chapter_3_Two_Kinds_o.xhtml#page_45),\n[66](12_Chapter_5_The_Tech_St.xhtml#page_66),\n[70](12_Chapter_5_The_Tech_St.xhtml#page_70)\n\nidentity, [133](16_Chapter_8_Is_It_Reall.xhtml#page_133)–34,\n[138](16_Chapter_8_Is_It_Reall.xhtml#page_138)\n\nfederated, [134](16_Chapter_8_Is_It_Reall.xhtml#page_134)\n\ngovernment and, [134](16_Chapter_8_Is_It_Reall.xhtml#page_134),\n[135](16_Chapter_8_Is_It_Reall.xhtml#page_135),\n[139](16_Chapter_8_Is_It_Reall.xhtml#page_139)–41\n\nID cards, [135](16_Chapter_8_Is_It_Reall.xhtml#page_135),\n[137](16_Chapter_8_Is_It_Reall.xhtml#page_137),\n[139](16_Chapter_8_Is_It_Reall.xhtml#page_139),\n[140](16_Chapter_8_Is_It_Reall.xhtml#page_140)\n\nidentity and access management (IAM),\n[245](25_Chapter_15_Real_and_A.xhtml#page_245),\n[303](31_Glossary.xhtml#page_303)\n\npersonally identifiable information (PII),\n[115](15_Chapter_7_Nudges_and_.xhtml#page_115)–16,\n[141](16_Chapter_8_Is_It_Reall.xhtml#page_141),\n[283](29_Chapter_18_Derisking_.xhtml#page_283)–84,\n[305](31_Glossary.xhtml#page_305)\n\nproofing, [133](16_Chapter_8_Is_It_Reall.xhtml#page_133)–36,\n[138](16_Chapter_8_Is_It_Reall.xhtml#page_138),\n[140](16_Chapter_8_Is_It_Reall.xhtml#page_140)\n\n_see also_ authentication\n\nImmersive Labs, [149](17_Chapter_9_Fixing_the_.xhtml#page_149)–50\n\nindustrial control systems (ICS),\n[163](18_Chapter_10_Power_Grid.xhtml#page_163),\n[270](27_Chapter_17_5g_and_Iot.xhtml#page_270),\n[271](27_Chapter_17_5g_and_Iot.xhtml#page_271),\n[303](31_Glossary.xhtml#page_303)\n\ninformation sharing, [58](11_Chapter_4_The_Kill_Ch.xhtml#page_58)–61,\n[95](13_Chapter_6_Cyber_Resil.xhtml#page_95),\n[112](15_Chapter_7_Nudges_and_.xhtml#page_112)\n\ninformation sharing and analysis centers (ISACs),\n[11](07_Chapter_1_The_Back_of.xhtml#page_11),\n[303](31_Glossary.xhtml#page_303)\n\ninformation technology (IT), [18](08_Chapter_2_Eternalblue.xhtml#page_18),\n[36](10_Chapter_3_Two_Kinds_o.xhtml#page_36),\n[37](10_Chapter_3_Two_Kinds_o.xhtml#page_37),\n[50](11_Chapter_4_The_Kill_Ch.xhtml#page_50),\n[53](11_Chapter_4_The_Kill_Ch.xhtml#page_53),\n[54](11_Chapter_4_The_Kill_Ch.xhtml#page_54),\n[65](12_Chapter_5_The_Tech_St.xhtml#page_65),\n[66](12_Chapter_5_The_Tech_St.xhtml#page_66),\n[68](12_Chapter_5_The_Tech_St.xhtml#page_68),\n[70](12_Chapter_5_The_Tech_St.xhtml#page_70)–72,\n[74](12_Chapter_5_The_Tech_St.xhtml#page_74),\n[75](12_Chapter_5_The_Tech_St.xhtml#page_75),\n[83](12_Chapter_5_The_Tech_St.xhtml#page_83),\n[87](13_Chapter_6_Cyber_Resil.xhtml#page_87),\n[110](15_Chapter_7_Nudges_and_.xhtml#page_110),\n[173](19_Chapter_11_Securing_t.xhtml#page_173),\n[174](19_Chapter_11_Securing_t.xhtml#page_174),\n[243](25_Chapter_15_Real_and_A.xhtml#page_243),\n[270](27_Chapter_17_5g_and_Iot.xhtml#page_270),\n[303](31_Glossary.xhtml#page_303)\n\ncost of, [201](21_Chapter_12_The_Milita.xhtml#page_201)\n\nIT Services Agency proposal, [176](19_Chapter_11_Securing_t.xhtml#page_176)–78\n\nOT and, [273](27_Chapter_17_5g_and_Iot.xhtml#page_273)–74\n\nShadow, [72](12_Chapter_5_The_Tech_St.xhtml#page_72)\n\nspending on, [91](13_Chapter_6_Cyber_Resil.xhtml#page_91)\n\nstatewide departments, [174](19_Chapter_11_Securing_t.xhtml#page_174)–75\n\ninfrastructure as a service, [75](12_Chapter_5_The_Tech_St.xhtml#page_75)\n\nInitial Occurrence Syndrome, [162](18_Chapter_10_Power_Grid.xhtml#page_162),\n[223](23_Chapter_14_Democracy_.xhtml#page_223)\n\nInskeep, Todd, [40](10_Chapter_3_Two_Kinds_o.xhtml#page_40),\n[45](10_Chapter_3_Two_Kinds_o.xhtml#page_45)–46\n\nintellectual property, [34](10_Chapter_3_Two_Kinds_o.xhtml#page_34),\n[42](10_Chapter_3_Two_Kinds_o.xhtml#page_42)–43\n\n“Intelligence-Driven Computer Network Defense Informed by Analysis of\nAdversary Campaigns and Intrusion Kill Chains” (Hutchins, Cloppert, and Amin),\n[49](11_Chapter_4_The_Kill_Ch.xhtml#page_49),\n[51](11_Chapter_4_The_Kill_Ch.xhtml#page_51),\n[52](11_Chapter_4_The_Kill_Ch.xhtml#page_52)\n\nintercontinental ballistic missile (ICBM),\n[166](18_Chapter_10_Power_Grid.xhtml#page_166),\n[303](31_Glossary.xhtml#page_303)\n\nInternational Conference on Information Warfare,\n[49](11_Chapter_4_The_Kill_Ch.xhtml#page_49)\n\nInternational Strategy for Cyberspace,\n[205](22_Chapter_13_A_Schengen.xhtml#page_205),\n[210](22_Chapter_13_A_Schengen.xhtml#page_210),\n[295](30_Chapter_19_Everything.xhtml#page_295)\n\ninternet, [8](07_Chapter_1_The_Back_of.xhtml#page_8),\n[9](07_Chapter_1_The_Back_of.xhtml#page_9),\n[11](07_Chapter_1_The_Back_of.xhtml#page_11)–13,\n[78](12_Chapter_5_The_Tech_St.xhtml#page_78),\n[86](13_Chapter_6_Cyber_Resil.xhtml#page_86),\n[90](13_Chapter_6_Cyber_Resil.xhtml#page_90),\n[91](13_Chapter_6_Cyber_Resil.xhtml#page_91),\n[96](13_Chapter_6_Cyber_Resil.xhtml#page_96),\n[120](15_Chapter_7_Nudges_and_.xhtml#page_120),\n[157](18_Chapter_10_Power_Grid.xhtml#page_157),\n[205](22_Chapter_13_A_Schengen.xhtml#page_205)–11,\n[215](22_Chapter_13_A_Schengen.xhtml#page_215),\n[293](29_Chapter_18_Derisking_.xhtml#page_293)\n\ngovernment and, [12](07_Chapter_1_The_Back_of.xhtml#page_12)–13,\n[86](13_Chapter_6_Cyber_Resil.xhtml#page_86),\n[88](13_Chapter_6_Cyber_Resil.xhtml#page_88)\n\nRussia and, [206](22_Chapter_13_A_Schengen.xhtml#page_206),\n[208](22_Chapter_13_A_Schengen.xhtml#page_208),\n[210](22_Chapter_13_A_Schengen.xhtml#page_210),\n[211](22_Chapter_13_A_Schengen.xhtml#page_211),\n[219](23_Chapter_14_Democracy_.xhtml#page_219)–20\n\nSchengen Accord for, [205](22_Chapter_13_A_Schengen.xhtml#page_205)–18\n\nInternet Corporation for Assigned Names and Numbers (ICANN),\n[12](07_Chapter_1_The_Back_of.xhtml#page_12),\n[102](13_Chapter_6_Cyber_Resil.xhtml#page_102),\n[210](22_Chapter_13_A_Schengen.xhtml#page_210)\n\nInternet of Things (IoT), [265](27_Chapter_17_5g_and_Iot.xhtml#page_265),\n[266](27_Chapter_17_5g_and_Iot.xhtml#page_266),\n[268](27_Chapter_17_5g_and_Iot.xhtml#page_268)–70,\n[274](27_Chapter_17_5g_and_Iot.xhtml#page_274)–80,\n[289](29_Chapter_18_Derisking_.xhtml#page_289),\n[303](31_Glossary.xhtml#page_303)\n\nvehicles, [266](27_Chapter_17_5g_and_Iot.xhtml#page_266)–67,\n[269](27_Chapter_17_5g_and_Iot.xhtml#page_269)–70\n\nInternet Research Agency, [219](23_Chapter_14_Democracy_.xhtml#page_219)–20\n\nInterpol, [161](18_Chapter_10_Power_Grid.xhtml#page_161),\n[217](22_Chapter_13_A_Schengen.xhtml#page_217)\n\nintrusion prevention systems (IPS),\n[70](12_Chapter_5_The_Tech_St.xhtml#page_70)–71,\n[94](13_Chapter_6_Cyber_Resil.xhtml#page_94)–95,\n[244](25_Chapter_15_Real_and_A.xhtml#page_244)\n\niPhones, [36](10_Chapter_3_Two_Kinds_o.xhtml#page_36),\n[68](12_Chapter_5_The_Tech_St.xhtml#page_68),\n[124](15_Chapter_7_Nudges_and_.xhtml#page_124)–25,\n[292](29_Chapter_18_Derisking_.xhtml#page_292)\n\nIran, [5](07_Chapter_1_The_Back_of.xhtml#page_5),\n[27](08_Chapter_2_Eternalblue.xhtml#page_27),\n[28](08_Chapter_2_Eternalblue.xhtml#page_28),\n[85](13_Chapter_6_Cyber_Resil.xhtml#page_85)–87,\n[98](13_Chapter_6_Cyber_Resil.xhtml#page_98)–99,\n[119](15_Chapter_7_Nudges_and_.xhtml#page_119),\n[120](15_Chapter_7_Nudges_and_.xhtml#page_120),\n[126](15_Chapter_7_Nudges_and_.xhtml#page_126),\n[163](18_Chapter_10_Power_Grid.xhtml#page_163),\n[185](21_Chapter_12_The_Milita.xhtml#page_185)–88,\n[191](21_Chapter_12_The_Milita.xhtml#page_191)–96,\n[198](21_Chapter_12_The_Milita.xhtml#page_198),\n[208](22_Chapter_13_A_Schengen.xhtml#page_208)\n\nnuclear program of, [20](08_Chapter_2_Eternalblue.xhtml#page_20),\n[37](10_Chapter_3_Two_Kinds_o.xhtml#page_37)–38,\n[85](13_Chapter_6_Cyber_Resil.xhtml#page_85),\n[87](13_Chapter_6_Cyber_Resil.xhtml#page_87),\n[97](13_Chapter_6_Cyber_Resil.xhtml#page_97),\n[160](18_Chapter_10_Power_Grid.xhtml#page_160),\n[193](21_Chapter_12_The_Milita.xhtml#page_193),\n[194](21_Chapter_12_The_Milita.xhtml#page_194),\n[270](27_Chapter_17_5g_and_Iot.xhtml#page_270)–71\n\nIronNet, [93](13_Chapter_6_Cyber_Resil.xhtml#page_93)–94,\n[246](25_Chapter_15_Real_and_A.xhtml#page_246)\n\nIRS, [136](16_Chapter_8_Is_It_Reall.xhtml#page_136),\n[138](16_Chapter_8_Is_It_Reall.xhtml#page_138)–40\n\nIslamic State in Syria (ISIS), [193](21_Chapter_12_The_Milita.xhtml#page_193),\n[201](21_Chapter_12_The_Milita.xhtml#page_201),\n[303](31_Glossary.xhtml#page_303)–4\n\nIsrael, [23](08_Chapter_2_Eternalblue.xhtml#page_23),\n[160](18_Chapter_10_Power_Grid.xhtml#page_160),\n[185](21_Chapter_12_The_Milita.xhtml#page_185)–86,\n[190](21_Chapter_12_The_Milita.xhtml#page_190),\n[192](21_Chapter_12_The_Milita.xhtml#page_192)\n\nMossad, [44](10_Chapter_3_Two_Kinds_o.xhtml#page_44),\n[46](10_Chapter_3_Two_Kinds_o.xhtml#page_46)\n\nIT Services Agency (ITSA), [176](19_Chapter_11_Securing_t.xhtml#page_176)–78\n\nJaffer, Jamil, [94](13_Chapter_6_Cyber_Resil.xhtml#page_94)\n\nJanow, Merit, [102](13_Chapter_6_Cyber_Resil.xhtml#page_102)\n\nJenkins, Neil, [61](11_Chapter_4_The_Kill_Ch.xhtml#page_61)\n\nJoint Improvised Explosive Device Defeat Organization,\n[51](11_Chapter_4_The_Kill_Ch.xhtml#page_51)\n\nJoint Worldwide Intelligence Communications System,\n[189](21_Chapter_12_The_Milita.xhtml#page_189)\n\nJoyce, Rob, [73](12_Chapter_5_The_Tech_St.xhtml#page_73)–74,\n[97](13_Chapter_6_Cyber_Resil.xhtml#page_97)\n\nJPMorgan Chase, [9](07_Chapter_1_The_Back_of.xhtml#page_9),\n[49](11_Chapter_4_The_Kill_Ch.xhtml#page_49)–50,\n[85](13_Chapter_6_Cyber_Resil.xhtml#page_85),\n[91](13_Chapter_6_Cyber_Resil.xhtml#page_91)–92,\n[94](13_Chapter_6_Cyber_Resil.xhtml#page_94),\n[101](13_Chapter_6_Cyber_Resil.xhtml#page_101),\n[136](16_Chapter_8_Is_It_Reall.xhtml#page_136),\n[191](21_Chapter_12_The_Milita.xhtml#page_191)\n\nJustice Department (DOJ), [10](07_Chapter_1_The_Back_of.xhtml#page_10),\n[12](07_Chapter_1_The_Back_of.xhtml#page_12),\n[22](08_Chapter_2_Eternalblue.xhtml#page_22),\n[27](08_Chapter_2_Eternalblue.xhtml#page_27)–28,\n[124](15_Chapter_7_Nudges_and_.xhtml#page_124),\n[125](15_Chapter_7_Nudges_and_.xhtml#page_125),\n[194](21_Chapter_12_The_Milita.xhtml#page_194),\n[217](22_Chapter_13_A_Schengen.xhtml#page_217)\n\nKaragiannis, Konstantinos, [263](26_Chapter_16_A_Quantum_.xhtml#page_263)\n\nKaspersky Anti-Virus, [22](08_Chapter_2_Eternalblue.xhtml#page_22)–23,\n[36](10_Chapter_3_Two_Kinds_o.xhtml#page_36)\n\nKennan, George, [13](07_Chapter_1_The_Back_of.xhtml#page_13)\n\nKennedy, John F., [9](07_Chapter_1_The_Back_of.xhtml#page_9)\n\nKerry, John, [227](23_Chapter_14_Democracy_.xhtml#page_227)–28\n\nkill chain, [49](11_Chapter_4_The_Kill_Ch.xhtml#page_49)–61,\n[70](12_Chapter_5_The_Tech_St.xhtml#page_70),\n[298](30_Chapter_19_Everything.xhtml#page_298)\n\nKnake, Robert K., [6](07_Chapter_1_The_Back_of.xhtml#page_6),\n[61](11_Chapter_4_The_Kill_Ch.xhtml#page_61),\n[153](17_Chapter_9_Fixing_the_.xhtml#page_153),\n[286](29_Chapter_18_Derisking_.xhtml#page_286)\n\n_Cyber War_ , [6](07_Chapter_1_The_Back_of.xhtml#page_6)–7,\n[13](07_Chapter_1_The_Back_of.xhtml#page_13),\n[26](08_Chapter_2_Eternalblue.xhtml#page_26),\n[37](10_Chapter_3_Two_Kinds_o.xhtml#page_37),\n[78](12_Chapter_5_The_Tech_St.xhtml#page_78),\n[192](21_Chapter_12_The_Milita.xhtml#page_192),\n[200](21_Chapter_12_The_Milita.xhtml#page_200)\n\nKoppel, Ted, [155](18_Chapter_10_Power_Grid.xhtml#page_155)–57\n\nKurtz, George, [34](10_Chapter_3_Two_Kinds_o.xhtml#page_34)\n\nLevy, Steven, [207](22_Chapter_13_A_Schengen.xhtml#page_207)\n\nLewis, Jim, [89](13_Chapter_6_Cyber_Resil.xhtml#page_89)\n\n_Lights Out_ (Koppel), [157](18_Chapter_10_Power_Grid.xhtml#page_157)\n\nLivingston, John, [271](27_Chapter_17_5g_and_Iot.xhtml#page_271)–75\n\nLockheed Martin, [49](11_Chapter_4_The_Kill_Ch.xhtml#page_49)–52\n\nLong, Fan, [80](12_Chapter_5_The_Tech_St.xhtml#page_80)\n\nLonghorn, [24](08_Chapter_2_Eternalblue.xhtml#page_24),\n[37](10_Chapter_3_Two_Kinds_o.xhtml#page_37)\n\nL0pht, [78](12_Chapter_5_The_Tech_St.xhtml#page_78),\n[79](12_Chapter_5_The_Tech_St.xhtml#page_79),\n[119](15_Chapter_7_Nudges_and_.xhtml#page_119)\n\nmachine learning (ML), [42](10_Chapter_3_Two_Kinds_o.xhtml#page_42),\n[53](11_Chapter_4_The_Kill_Ch.xhtml#page_53),\n[80](12_Chapter_5_The_Tech_St.xhtml#page_80),\n[81](12_Chapter_5_The_Tech_St.xhtml#page_81),\n[243](25_Chapter_15_Real_and_A.xhtml#page_243)–52,\n[263](26_Chapter_16_A_Quantum_.xhtml#page_263)–64,\n[304](31_Glossary.xhtml#page_304)\n\n_see also_ artificial intelligence\n\n_Madam Secretary_ , [157](18_Chapter_10_Power_Grid.xhtml#page_157),\n[161](18_Chapter_10_Power_Grid.xhtml#page_161)\n\nMaersk, [19](08_Chapter_2_Eternalblue.xhtml#page_19),\n[29](08_Chapter_2_Eternalblue.xhtml#page_29),\n[37](10_Chapter_3_Two_Kinds_o.xhtml#page_37)\n\nMalik, Tashfeen, [123](15_Chapter_7_Nudges_and_.xhtml#page_123)–25\n\nmalware, [46](10_Chapter_3_Two_Kinds_o.xhtml#page_46),\n[53](11_Chapter_4_The_Kill_Ch.xhtml#page_53)–55,\n[59](11_Chapter_4_The_Kill_Ch.xhtml#page_59)–61,\n[79](12_Chapter_5_The_Tech_St.xhtml#page_79),\n[85](13_Chapter_6_Cyber_Resil.xhtml#page_85),\n[86](13_Chapter_6_Cyber_Resil.xhtml#page_86),\n[149](17_Chapter_9_Fixing_the_.xhtml#page_149),\n[304](31_Glossary.xhtml#page_304)\n\nmanaged security service provider (MSSP),\n[144](17_Chapter_9_Fixing_the_.xhtml#page_144),\n[229](23_Chapter_14_Democracy_.xhtml#page_229),\n[304](31_Glossary.xhtml#page_304)\n\nManhattan Project, [9](07_Chapter_1_The_Back_of.xhtml#page_9)\n\nMansouri, Mohammad, [126](15_Chapter_7_Nudges_and_.xhtml#page_126)\n\nMarkoff, Michele, [210](22_Chapter_13_A_Schengen.xhtml#page_210)\n\nMarsh, Robert, [88](13_Chapter_6_Cyber_Resil.xhtml#page_88)–89\n\nMartin, Harold, [22](08_Chapter_2_Eternalblue.xhtml#page_22)–23\n\nMastercard, [152](17_Chapter_9_Fixing_the_.xhtml#page_152),\n[153](17_Chapter_9_Fixing_the_.xhtml#page_153)\n\nMattis, James, [195](21_Chapter_12_The_Milita.xhtml#page_195)\n\nMcAfee, [33](10_Chapter_3_Two_Kinds_o.xhtml#page_33),\n[61](11_Chapter_4_The_Kill_Ch.xhtml#page_61),\n[67](12_Chapter_5_The_Tech_St.xhtml#page_67),\n[251](25_Chapter_15_Real_and_A.xhtml#page_251),\n[288](29_Chapter_18_Derisking_.xhtml#page_288)\n\nMcAuliffe, Terry, [230](23_Chapter_14_Democracy_.xhtml#page_230)–31\n\nMcGeehan, Ryan, [71](12_Chapter_5_The_Tech_St.xhtml#page_71)\n\nMcKinsey & Company, [8](07_Chapter_1_The_Back_of.xhtml#page_8),\n[271](27_Chapter_17_5g_and_Iot.xhtml#page_271)\n\nMcLaughlin, Mark, [60](11_Chapter_4_The_Kill_Ch.xhtml#page_60)–61\n\nmedical devices, [275](27_Chapter_17_5g_and_Iot.xhtml#page_275)–76,\n[278](27_Chapter_17_5g_and_Iot.xhtml#page_278)–79\n\nMerck, [19](08_Chapter_2_Eternalblue.xhtml#page_19),\n[29](08_Chapter_2_Eternalblue.xhtml#page_29),\n[37](10_Chapter_3_Two_Kinds_o.xhtml#page_37)\n\nMetcalfe’s Law, [209](22_Chapter_13_A_Schengen.xhtml#page_209)–10,\n[245](25_Chapter_15_Real_and_A.xhtml#page_245)\n\nMickens, James, [44](10_Chapter_3_Two_Kinds_o.xhtml#page_44)\n\nmicrophones, [290](29_Chapter_18_Derisking_.xhtml#page_290)\n\nMicrosoft, [8](07_Chapter_1_The_Back_of.xhtml#page_8),\n[18](08_Chapter_2_Eternalblue.xhtml#page_18),\n[20](08_Chapter_2_Eternalblue.xhtml#page_20)–22,\n[24](08_Chapter_2_Eternalblue.xhtml#page_24),\n[36](10_Chapter_3_Two_Kinds_o.xhtml#page_36),\n[37](10_Chapter_3_Two_Kinds_o.xhtml#page_37),\n[44](10_Chapter_3_Two_Kinds_o.xhtml#page_44),\n[74](12_Chapter_5_The_Tech_St.xhtml#page_74)–76,\n[81](12_Chapter_5_The_Tech_St.xhtml#page_81),\n[129](16_Chapter_8_Is_It_Reall.xhtml#page_129),\n[131](16_Chapter_8_Is_It_Reall.xhtml#page_131),\n[152](17_Chapter_9_Fixing_the_.xhtml#page_152),\n[213](22_Chapter_13_A_Schengen.xhtml#page_213),\n[253](26_Chapter_16_A_Quantum_.xhtml#page_253),\n[261](26_Chapter_16_A_Quantum_.xhtml#page_261),\n[285](29_Chapter_18_Derisking_.xhtml#page_285)\n\nWindows, [18](08_Chapter_2_Eternalblue.xhtml#page_18),\n[36](10_Chapter_3_Two_Kinds_o.xhtml#page_36),\n[79](12_Chapter_5_The_Tech_St.xhtml#page_79),\n[129](16_Chapter_8_Is_It_Reall.xhtml#page_129),\n[190](21_Chapter_12_The_Milita.xhtml#page_190),\n[276](27_Chapter_17_5g_and_Iot.xhtml#page_276),\n[288](29_Chapter_18_Derisking_.xhtml#page_288)\n\nmilitary, [11](07_Chapter_1_The_Back_of.xhtml#page_11)–12,\n[13](07_Chapter_1_The_Back_of.xhtml#page_13),\n[87](13_Chapter_6_Cyber_Resil.xhtml#page_87),\n[95](13_Chapter_6_Cyber_Resil.xhtml#page_95),\n[150](17_Chapter_9_Fixing_the_.xhtml#page_150),\n[161](18_Chapter_10_Power_Grid.xhtml#page_161),\n[163](18_Chapter_10_Power_Grid.xhtml#page_163),\n[181](21_Chapter_12_The_Milita.xhtml#page_181)–203\n\nAir Force, [50](11_Chapter_4_The_Kill_Ch.xhtml#page_50),\n[102](13_Chapter_6_Cyber_Resil.xhtml#page_102),\n[166](18_Chapter_10_Power_Grid.xhtml#page_166),\n[183](21_Chapter_12_The_Milita.xhtml#page_183)\n\nArmy, [150](17_Chapter_9_Fixing_the_.xhtml#page_150),\n[170](19_Chapter_11_Securing_t.xhtml#page_170),\n[183](21_Chapter_12_The_Milita.xhtml#page_183),\n[195](21_Chapter_12_The_Milita.xhtml#page_195)\n\ncybersecurity training and, [143](17_Chapter_9_Fixing_the_.xhtml#page_143),\n[147](17_Chapter_9_Fixing_the_.xhtml#page_147)–48\n\nNavy, [95](13_Chapter_6_Cyber_Resil.xhtml#page_95),\n[150](17_Chapter_9_Fixing_the_.xhtml#page_150),\n[163](18_Chapter_10_Power_Grid.xhtml#page_163),\n[183](21_Chapter_12_The_Milita.xhtml#page_183),\n[189](21_Chapter_12_The_Milita.xhtml#page_189)–90,\n[198](21_Chapter_12_The_Milita.xhtml#page_198),\n[200](21_Chapter_12_The_Milita.xhtml#page_200),\n[201](21_Chapter_12_The_Milita.xhtml#page_201)\n\n_see also_ Defense Department\n\nMirai, [119](15_Chapter_7_Nudges_and_.xhtml#page_119),\n[277](27_Chapter_17_5g_and_Iot.xhtml#page_277)\n\nmissiles, [165](18_Chapter_10_Power_Grid.xhtml#page_165)–66,\n[303](31_Glossary.xhtml#page_303)\n\nMIT, [80](12_Chapter_5_The_Tech_St.xhtml#page_80),\n[152](17_Chapter_9_Fixing_the_.xhtml#page_152),\n[169](19_Chapter_11_Securing_t.xhtml#page_169),\n[263](26_Chapter_16_A_Quantum_.xhtml#page_263)\n\nMITRE Corporation, [55](11_Chapter_4_The_Kill_Ch.xhtml#page_55)–58,\n[60](11_Chapter_4_The_Kill_Ch.xhtml#page_60),\n[112](15_Chapter_7_Nudges_and_.xhtml#page_112)\n\nmobile devices, [289](29_Chapter_18_Derisking_.xhtml#page_289)–90,\n[292](29_Chapter_18_Derisking_.xhtml#page_292)\n\n5G and, [265](27_Chapter_17_5g_and_Iot.xhtml#page_265)–69,\n[280](27_Chapter_17_5g_and_Iot.xhtml#page_280)\n\nMohammadi, Ehsan, [28](08_Chapter_2_Eternalblue.xhtml#page_28)\n\nMollenkopf, Steve, [265](27_Chapter_17_5g_and_Iot.xhtml#page_265)\n\nMondelēz, [19](08_Chapter_2_Eternalblue.xhtml#page_19),\n[37](10_Chapter_3_Two_Kinds_o.xhtml#page_37),\n[121](15_Chapter_7_Nudges_and_.xhtml#page_121)\n\nMoore’s Law, [209](22_Chapter_13_A_Schengen.xhtml#page_209)–10\n\nMorenets, Alexei, [28](08_Chapter_2_Eternalblue.xhtml#page_28)\n\nMoss, Jeff, [127](15_Chapter_7_Nudges_and_.xhtml#page_127),\n[295](30_Chapter_19_Everything.xhtml#page_295)\n\nMossad, [44](10_Chapter_3_Two_Kinds_o.xhtml#page_44),\n[46](10_Chapter_3_Two_Kinds_o.xhtml#page_46)\n\nMueller, Robert, [161](18_Chapter_10_Power_Grid.xhtml#page_161)\n\nmultifactor authentication (MFA),\n[46](10_Chapter_3_Two_Kinds_o.xhtml#page_46),\n[129](16_Chapter_8_Is_It_Reall.xhtml#page_129),\n[131](16_Chapter_8_Is_It_Reall.xhtml#page_131)–34,\n[137](16_Chapter_8_Is_It_Reall.xhtml#page_137),\n[304](31_Glossary.xhtml#page_304)\n\nMurphy, Matt, [181](21_Chapter_12_The_Milita.xhtml#page_181)\n\nmutual legal assistance treaties,\n[215](22_Chapter_13_A_Schengen.xhtml#page_215)\n\nNAFTA, [213](22_Chapter_13_A_Schengen.xhtml#page_213)\n\nNakasone, Paul, [233](23_Chapter_14_Democracy_.xhtml#page_233)\n\nNASA, [79](12_Chapter_5_The_Tech_St.xhtml#page_79),\n[169](19_Chapter_11_Securing_t.xhtml#page_169),\n[263](26_Chapter_16_A_Quantum_.xhtml#page_263)\n\nNash, Lorina, [17](08_Chapter_2_Eternalblue.xhtml#page_17)\n\nNational Academy of Sciences, [3](07_Chapter_1_The_Back_of.xhtml#page_3)\n\nNational Cybersecurity Protection System,\n[96](13_Chapter_6_Cyber_Resil.xhtml#page_96)\n\nNational Cyber Strategy, [92](13_Chapter_6_Cyber_Resil.xhtml#page_92),\n[182](21_Chapter_12_The_Milita.xhtml#page_182)\n\nNational Defense Authorization Act,\n[195](21_Chapter_12_The_Milita.xhtml#page_195)–96\n\nNational Institute of Standards and Technology (NIST),\n[64](12_Chapter_5_The_Tech_St.xhtml#page_64)–65,\n[140](16_Chapter_8_Is_It_Reall.xhtml#page_140),\n[261](26_Chapter_16_A_Quantum_.xhtml#page_261),\n[304](31_Glossary.xhtml#page_304)\n\nCybersecurity Framework, [44](10_Chapter_3_Two_Kinds_o.xhtml#page_44)–45,\n[66](12_Chapter_5_The_Tech_St.xhtml#page_66),\n[70](12_Chapter_5_The_Tech_St.xhtml#page_70),\n[111](15_Chapter_7_Nudges_and_.xhtml#page_111),\n[117](15_Chapter_7_Nudges_and_.xhtml#page_117)\n\ncybersecurity workforce crisis and,\n[144](17_Chapter_9_Fixing_the_.xhtml#page_144)–45\n\nNational Plan for Information Systems Protection,\n[109](15_Chapter_7_Nudges_and_.xhtml#page_109)\n\nNational Science Foundation, [168](19_Chapter_11_Securing_t.xhtml#page_168)\n\nnational security, [88](13_Chapter_6_Cyber_Resil.xhtml#page_88),\n[90](13_Chapter_6_Cyber_Resil.xhtml#page_90),\n[94](13_Chapter_6_Cyber_Resil.xhtml#page_94),\n[104](13_Chapter_6_Cyber_Resil.xhtml#page_104)–5,\n[153](17_Chapter_9_Fixing_the_.xhtml#page_153)\n\nNational Security Agency (NSA), [18](08_Chapter_2_Eternalblue.xhtml#page_18),\n[21](08_Chapter_2_Eternalblue.xhtml#page_21)–23,\n[35](10_Chapter_3_Two_Kinds_o.xhtml#page_35)–37,\n[43](10_Chapter_3_Two_Kinds_o.xhtml#page_43),\n[68](12_Chapter_5_The_Tech_St.xhtml#page_68),\n[73](12_Chapter_5_The_Tech_St.xhtml#page_73),\n[93](13_Chapter_6_Cyber_Resil.xhtml#page_93),\n[96](13_Chapter_6_Cyber_Resil.xhtml#page_96),\n[103](13_Chapter_6_Cyber_Resil.xhtml#page_103),\n[124](15_Chapter_7_Nudges_and_.xhtml#page_124),\n[125](15_Chapter_7_Nudges_and_.xhtml#page_125),\n[168](19_Chapter_11_Securing_t.xhtml#page_168),\n[189](21_Chapter_12_The_Milita.xhtml#page_189),\n[194](21_Chapter_12_The_Milita.xhtml#page_194),\n[200](21_Chapter_12_The_Milita.xhtml#page_200),\n[233](23_Chapter_14_Democracy_.xhtml#page_233),\n[254](26_Chapter_16_A_Quantum_.xhtml#page_254),\n[267](27_Chapter_17_5g_and_Iot.xhtml#page_267)\n\nTailored Access Operations, [73](12_Chapter_5_The_Tech_St.xhtml#page_73),\n[148](17_Chapter_9_Fixing_the_.xhtml#page_148),\n[307](31_Glossary.xhtml#page_307)\n\nNational Security Council (NSC), [6](07_Chapter_1_The_Back_of.xhtml#page_6),\n[89](13_Chapter_6_Cyber_Resil.xhtml#page_89),\n[97](13_Chapter_6_Cyber_Resil.xhtml#page_97),\n[102](13_Chapter_6_Cyber_Resil.xhtml#page_102),\n[110](15_Chapter_7_Nudges_and_.xhtml#page_110),\n[111](15_Chapter_7_Nudges_and_.xhtml#page_111),\n[203](21_Chapter_12_The_Milita.xhtml#page_203),\n[222](23_Chapter_14_Democracy_.xhtml#page_222),\n[224](23_Chapter_14_Democracy_.xhtml#page_224)\n\nNational Security Presidential Memorandum 13,\n[182](21_Chapter_12_The_Milita.xhtml#page_182),\n[196](21_Chapter_12_The_Milita.xhtml#page_196)\n\nNational Strategy for Trusted Identities in Cyberspace (NSTIC),\n[111](15_Chapter_7_Nudges_and_.xhtml#page_111)–12,\n[134](16_Chapter_8_Is_It_Reall.xhtml#page_134)–36,\n[138](16_Chapter_8_Is_It_Reall.xhtml#page_138)\n\nNational Strategy to Secure Cyberspace,\n[156](18_Chapter_10_Power_Grid.xhtml#page_156)\n\nNational Transportation Safety Board,\n[273](27_Chapter_17_5g_and_Iot.xhtml#page_273)\n\nNATO, [221](23_Chapter_14_Democracy_.xhtml#page_221),\n[222](23_Chapter_14_Democracy_.xhtml#page_222),\n[225](23_Chapter_14_Democracy_.xhtml#page_225),\n[234](23_Chapter_14_Democracy_.xhtml#page_234)\n\nnatural gas, [272](27_Chapter_17_5g_and_Iot.xhtml#page_272)–73\n\nNavy, U.S., [95](13_Chapter_6_Cyber_Resil.xhtml#page_95),\n[150](17_Chapter_9_Fixing_the_.xhtml#page_150),\n[163](18_Chapter_10_Power_Grid.xhtml#page_163),\n[183](21_Chapter_12_The_Milita.xhtml#page_183),\n[189](21_Chapter_12_The_Milita.xhtml#page_189)–90,\n[198](21_Chapter_12_The_Milita.xhtml#page_198),\n[200](21_Chapter_12_The_Milita.xhtml#page_200),\n[201](21_Chapter_12_The_Milita.xhtml#page_201)\n\nNavy Marine Corps Intranet, [27](08_Chapter_2_Eternalblue.xhtml#page_27)\n\nNeSmith, Brian, [144](17_Chapter_9_Fixing_the_.xhtml#page_144)\n\nNetflix, [72](12_Chapter_5_The_Tech_St.xhtml#page_72),\n[76](12_Chapter_5_The_Tech_St.xhtml#page_76)\n\nNetwork Master, [246](25_Chapter_15_Real_and_A.xhtml#page_246),\n[248](25_Chapter_15_Real_and_A.xhtml#page_248),\n[252](25_Chapter_15_Real_and_A.xhtml#page_252),\n[263](26_Chapter_16_A_Quantum_.xhtml#page_263),\n[264](26_Chapter_16_A_Quantum_.xhtml#page_264)\n\nneural networks, [80](12_Chapter_5_The_Tech_St.xhtml#page_80),\n[243](25_Chapter_15_Real_and_A.xhtml#page_243)–44\n\nNew York, [117](15_Chapter_7_Nudges_and_.xhtml#page_117),\n[123](15_Chapter_7_Nudges_and_.xhtml#page_123),\n[155](18_Chapter_10_Power_Grid.xhtml#page_155)–56,\n[174](19_Chapter_11_Securing_t.xhtml#page_174)\n\nNew York Cyber Task Force, [75](12_Chapter_5_The_Tech_St.xhtml#page_75),\n[101](13_Chapter_6_Cyber_Resil.xhtml#page_101)–4\n\n_New York Times_ , [205](22_Chapter_13_A_Schengen.xhtml#page_205)\n\n_New York Times Magazine_ , [219](23_Chapter_14_Democracy_.xhtml#page_219)\n\nNiejelow, Alex, [153](17_Chapter_9_Fixing_the_.xhtml#page_153)\n\nNikias, C. L., Max, [264](26_Chapter_16_A_Quantum_.xhtml#page_264)\n\n9/11 attacks, [26](08_Chapter_2_Eternalblue.xhtml#page_26),\n[88](13_Chapter_6_Cyber_Resil.xhtml#page_88),\n[114](15_Chapter_7_Nudges_and_.xhtml#page_114),\n[123](15_Chapter_7_Nudges_and_.xhtml#page_123),\n[137](16_Chapter_8_Is_It_Reall.xhtml#page_137),\n[155](18_Chapter_10_Power_Grid.xhtml#page_155),\n[196](21_Chapter_12_The_Milita.xhtml#page_196),\n[222](23_Chapter_14_Democracy_.xhtml#page_222),\n[234](23_Chapter_14_Democracy_.xhtml#page_234)\n\nNorth American Electric Reliability Council (NERC),\n[158](18_Chapter_10_Power_Grid.xhtml#page_158)–59,\n[271](27_Chapter_17_5g_and_Iot.xhtml#page_271),\n[304](31_Glossary.xhtml#page_304)–5\n\nNorth Korea, [18](08_Chapter_2_Eternalblue.xhtml#page_18),\n[22](08_Chapter_2_Eternalblue.xhtml#page_22),\n[26](08_Chapter_2_Eternalblue.xhtml#page_26)–28,\n[97](13_Chapter_6_Cyber_Resil.xhtml#page_97),\n[187](21_Chapter_12_The_Milita.xhtml#page_187),\n[188](21_Chapter_12_The_Milita.xhtml#page_188),\n[195](21_Chapter_12_The_Milita.xhtml#page_195),\n[196](21_Chapter_12_The_Milita.xhtml#page_196),\n[198](21_Chapter_12_The_Milita.xhtml#page_198),\n[211](22_Chapter_13_A_Schengen.xhtml#page_211)\n\nNotPetya, [8](07_Chapter_1_The_Back_of.xhtml#page_8),\n[18](08_Chapter_2_Eternalblue.xhtml#page_18)–22,\n[26](08_Chapter_2_Eternalblue.xhtml#page_26),\n[29](08_Chapter_2_Eternalblue.xhtml#page_29),\n[37](10_Chapter_3_Two_Kinds_o.xhtml#page_37),\n[121](15_Chapter_7_Nudges_and_.xhtml#page_121)\n\nNuclear Regulatory Commission, [115](15_Chapter_7_Nudges_and_.xhtml#page_115)\n\nnuclear weapons, [9](07_Chapter_1_The_Back_of.xhtml#page_9),\n[11](07_Chapter_1_The_Back_of.xhtml#page_11),\n[13](07_Chapter_1_The_Back_of.xhtml#page_13),\n[27](08_Chapter_2_Eternalblue.xhtml#page_27),\n[94](13_Chapter_6_Cyber_Resil.xhtml#page_94),\n[115](15_Chapter_7_Nudges_and_.xhtml#page_115),\n[166](18_Chapter_10_Power_Grid.xhtml#page_166),\n[182](21_Chapter_12_The_Milita.xhtml#page_182)–83,\n[197](21_Chapter_12_The_Milita.xhtml#page_197),\n[240](25_Chapter_15_Real_and_A.xhtml#page_240)–41\n\nIran and, [20](08_Chapter_2_Eternalblue.xhtml#page_20),\n[37](10_Chapter_3_Two_Kinds_o.xhtml#page_37)–38,\n[85](13_Chapter_6_Cyber_Resil.xhtml#page_85),\n[87](13_Chapter_6_Cyber_Resil.xhtml#page_87),\n[97](13_Chapter_6_Cyber_Resil.xhtml#page_97),\n[160](18_Chapter_10_Power_Grid.xhtml#page_160),\n[193](21_Chapter_12_The_Milita.xhtml#page_193),\n[194](21_Chapter_12_The_Milita.xhtml#page_194),\n[270](27_Chapter_17_5g_and_Iot.xhtml#page_270)–71\n\nmissiles, [166](18_Chapter_10_Power_Grid.xhtml#page_166),\n[303](31_Glossary.xhtml#page_303)\n\nNavy and, [150](17_Chapter_9_Fixing_the_.xhtml#page_150),\n[198](21_Chapter_12_The_Milita.xhtml#page_198),\n[201](21_Chapter_12_The_Milita.xhtml#page_201)\n\n_Nudge_ (Thaler and Sunstein), [111](15_Chapter_7_Nudges_and_.xhtml#page_111)\n\nObama, Barack, [6](07_Chapter_1_The_Back_of.xhtml#page_6),\n[10](07_Chapter_1_The_Back_of.xhtml#page_10),\n[11](07_Chapter_1_The_Back_of.xhtml#page_11),\n[12](07_Chapter_1_The_Back_of.xhtml#page_12),\n[21](08_Chapter_2_Eternalblue.xhtml#page_21),\n[22](08_Chapter_2_Eternalblue.xhtml#page_22),\n[25](08_Chapter_2_Eternalblue.xhtml#page_25),\n[26](08_Chapter_2_Eternalblue.xhtml#page_26),\n[33](10_Chapter_3_Two_Kinds_o.xhtml#page_33),\n[36](10_Chapter_3_Two_Kinds_o.xhtml#page_36),\n[44](10_Chapter_3_Two_Kinds_o.xhtml#page_44),\n[61](11_Chapter_4_The_Kill_Ch.xhtml#page_61),\n[77](12_Chapter_5_The_Tech_St.xhtml#page_77),\n[85](13_Chapter_6_Cyber_Resil.xhtml#page_85)–87,\n[89](13_Chapter_6_Cyber_Resil.xhtml#page_89),\n[92](13_Chapter_6_Cyber_Resil.xhtml#page_92),\n[96](13_Chapter_6_Cyber_Resil.xhtml#page_96),\n[100](13_Chapter_6_Cyber_Resil.xhtml#page_100),\n[109](15_Chapter_7_Nudges_and_.xhtml#page_109)–11,\n[113](15_Chapter_7_Nudges_and_.xhtml#page_113),\n[124](15_Chapter_7_Nudges_and_.xhtml#page_124),\n[134](16_Chapter_8_Is_It_Reall.xhtml#page_134)–35,\n[152](17_Chapter_9_Fixing_the_.xhtml#page_152),\n[176](19_Chapter_11_Securing_t.xhtml#page_176),\n[177](19_Chapter_11_Securing_t.xhtml#page_177),\n[182](21_Chapter_12_The_Milita.xhtml#page_182),\n[193](21_Chapter_12_The_Milita.xhtml#page_193)–94,\n[203](21_Chapter_12_The_Milita.xhtml#page_203),\n[205](22_Chapter_13_A_Schengen.xhtml#page_205),\n[210](22_Chapter_13_A_Schengen.xhtml#page_210),\n[221](23_Chapter_14_Democracy_.xhtml#page_221)–23,\n[225](23_Chapter_14_Democracy_.xhtml#page_225),\n[233](23_Chapter_14_Democracy_.xhtml#page_233),\n[295](30_Chapter_19_Everything.xhtml#page_295)\n\nOdile, [149](17_Chapter_9_Fixing_the_.xhtml#page_149)\n\noffense and defense, [4](07_Chapter_1_The_Back_of.xhtml#page_4),\n[5](07_Chapter_1_The_Back_of.xhtml#page_5),\n[13](07_Chapter_1_The_Back_of.xhtml#page_13),\n[35](10_Chapter_3_Two_Kinds_o.xhtml#page_35)–39,\n[51](11_Chapter_4_The_Kill_Ch.xhtml#page_51),\n[83](12_Chapter_5_The_Tech_St.xhtml#page_83),\n[100](13_Chapter_6_Cyber_Resil.xhtml#page_100),\n[102](13_Chapter_6_Cyber_Resil.xhtml#page_102)–4\n\ncollective defense, [58](11_Chapter_4_The_Kill_Ch.xhtml#page_58)–61\n\ncost and, [37](10_Chapter_3_Two_Kinds_o.xhtml#page_37)\n\noffensive advantage or preference,\n[4](07_Chapter_1_The_Back_of.xhtml#page_4)–10,\n[35](10_Chapter_3_Two_Kinds_o.xhtml#page_35),\n[37](10_Chapter_3_Two_Kinds_o.xhtml#page_37),\n[100](13_Chapter_6_Cyber_Resil.xhtml#page_100)–101,\n[297](30_Chapter_19_Everything.xhtml#page_297)–98\n\nOffice of Information and Regulatory Affairs,\n[110](15_Chapter_7_Nudges_and_.xhtml#page_110)–11\n\nOffice of Management and Budget (OMB),\n[111](15_Chapter_7_Nudges_and_.xhtml#page_111),\n[167](19_Chapter_11_Securing_t.xhtml#page_167),\n[175](19_Chapter_11_Securing_t.xhtml#page_175)\n\nOffice of Personnel Management (OPM),\n[130](16_Chapter_8_Is_It_Reall.xhtml#page_130),\n[168](19_Chapter_11_Securing_t.xhtml#page_168),\n[176](19_Chapter_11_Securing_t.xhtml#page_176)\n\nO’Grady, Stephen, [63](12_Chapter_5_The_Tech_St.xhtml#page_63)\n\nOhio, [117](15_Chapter_7_Nudges_and_.xhtml#page_117)\n\noil tankers, [116](15_Chapter_7_Nudges_and_.xhtml#page_116)\n\nOkta, [131](16_Chapter_8_Is_It_Reall.xhtml#page_131),\n[133](16_Chapter_8_Is_It_Reall.xhtml#page_133)\n\nOODA loop, [70](12_Chapter_5_The_Tech_St.xhtml#page_70),\n[72](12_Chapter_5_The_Tech_St.xhtml#page_72)\n\nOperation Glowing Symphony, [193](21_Chapter_12_The_Milita.xhtml#page_193)\n\noperations technology (OT), [270](27_Chapter_17_5g_and_Iot.xhtml#page_270)–74,\n[305](31_Glossary.xhtml#page_305)\n\nOxford, Wil, [258](26_Chapter_16_A_Quantum_.xhtml#page_258)\n\nOzment, Andy, [127](15_Chapter_7_Nudges_and_.xhtml#page_127)\n\nP5+1, [194](21_Chapter_12_The_Milita.xhtml#page_194),\n[305](31_Glossary.xhtml#page_305)\n\nPainter, Chris, [210](22_Chapter_13_A_Schengen.xhtml#page_210)\n\nPalo Alto Networks, [60](11_Chapter_4_The_Kill_Ch.xhtml#page_60)–61\n\nPark Jin Hyok, [28](08_Chapter_2_Eternalblue.xhtml#page_28)\n\npassports, [135](16_Chapter_8_Is_It_Reall.xhtml#page_135)\n\npasswords, [45](10_Chapter_3_Two_Kinds_o.xhtml#page_45)–46,\n[129](16_Chapter_8_Is_It_Reall.xhtml#page_129)–33,\n[251](25_Chapter_15_Real_and_A.xhtml#page_251),\n[283](29_Chapter_18_Derisking_.xhtml#page_283)–86,\n[292](29_Chapter_18_Derisking_.xhtml#page_292)\n\npatches, [275](27_Chapter_17_5g_and_Iot.xhtml#page_275)–76,\n[278](27_Chapter_17_5g_and_Iot.xhtml#page_278)–79,\n[305](31_Glossary.xhtml#page_305)\n\nPate, Connor, [167](19_Chapter_11_Securing_t.xhtml#page_167)–70,\n[173](19_Chapter_11_Securing_t.xhtml#page_173)\n\nPearl Harbor, [123](15_Chapter_7_Nudges_and_.xhtml#page_123),\n[234](23_Chapter_14_Democracy_.xhtml#page_234),\n[235](23_Chapter_14_Democracy_.xhtml#page_235)\n\nPeople’s Liberation Army (PLA), [26](08_Chapter_2_Eternalblue.xhtml#page_26),\n[28](08_Chapter_2_Eternalblue.xhtml#page_28),\n[176](19_Chapter_11_Securing_t.xhtml#page_176),\n[305](31_Glossary.xhtml#page_305)\n\npersonally identifiable information (PII),\n[115](15_Chapter_7_Nudges_and_.xhtml#page_115)–16,\n[141](16_Chapter_8_Is_It_Reall.xhtml#page_141),\n[283](29_Chapter_18_Derisking_.xhtml#page_283)–84,\n[305](31_Glossary.xhtml#page_305)\n\nPetya, [18](08_Chapter_2_Eternalblue.xhtml#page_18)\n\nphishing, [53](11_Chapter_4_The_Kill_Ch.xhtml#page_53)–55,\n[59](11_Chapter_4_The_Kill_Ch.xhtml#page_59),\n[288](29_Chapter_18_Derisking_.xhtml#page_288)\n\nPoint3 Security, [148](17_Chapter_9_Fixing_the_.xhtml#page_148)–49\n\nPolicy Blueprint for Countering Authoritarian Interference in Democracies,\n[223](23_Chapter_14_Democracy_.xhtml#page_223)–24\n\n_Politico_ , [97](13_Chapter_6_Cyber_Resil.xhtml#page_97)\n\nPollard, Neal, [295](30_Chapter_19_Everything.xhtml#page_295)\n\nPompeo, Mike, [267](27_Chapter_17_5g_and_Iot.xhtml#page_267)–68\n\nPonemon Institute, [116](15_Chapter_7_Nudges_and_.xhtml#page_116)\n\nPostal Service, [135](16_Chapter_8_Is_It_Reall.xhtml#page_135),\n[140](16_Chapter_8_Is_It_Reall.xhtml#page_140)\n\nPower, Samantha, [111](15_Chapter_7_Nudges_and_.xhtml#page_111)\n\npower grids, [155](18_Chapter_10_Power_Grid.xhtml#page_155)–66,\n[190](21_Chapter_12_The_Milita.xhtml#page_190)–91,\n[199](21_Chapter_12_The_Milita.xhtml#page_199),\n[270](27_Chapter_17_5g_and_Iot.xhtml#page_270)–72,\n[277](27_Chapter_17_5g_and_Iot.xhtml#page_277)\n\nRussia and, [26](08_Chapter_2_Eternalblue.xhtml#page_26),\n[159](18_Chapter_10_Power_Grid.xhtml#page_159)–61,\n[164](18_Chapter_10_Power_Grid.xhtml#page_164)–66,\n[200](21_Chapter_12_The_Milita.xhtml#page_200)\n\nsecure segmented diverse-source microgrid,\n[164](18_Chapter_10_Power_Grid.xhtml#page_164)–65\n\npresidential decision directives,\n[182](21_Chapter_12_The_Milita.xhtml#page_182),\n[305](31_Glossary.xhtml#page_305)\n\nPresidential Decision Directive 63,\n[10](07_Chapter_1_The_Back_of.xhtml#page_10)–11,\n[59](11_Chapter_4_The_Kill_Ch.xhtml#page_59),\n[89](13_Chapter_6_Cyber_Resil.xhtml#page_89)\n\nprivileged access management, [245](25_Chapter_15_Real_and_A.xhtml#page_245),\n[305](31_Glossary.xhtml#page_305)\n\n“protect” function, [45](10_Chapter_3_Two_Kinds_o.xhtml#page_45),\n[66](12_Chapter_5_The_Tech_St.xhtml#page_66),\n[70](12_Chapter_5_The_Tech_St.xhtml#page_70)\n\nPutin, Vladimir, [220](23_Chapter_14_Democracy_.xhtml#page_220)–23,\n[239](25_Chapter_15_Real_and_A.xhtml#page_239),\n[241](25_Chapter_15_Real_and_A.xhtml#page_241)\n\nQuAIL, [263](26_Chapter_16_A_Quantum_.xhtml#page_263)\n\nquantum computing, [6](07_Chapter_1_The_Back_of.xhtml#page_6),\n[81](12_Chapter_5_The_Tech_St.xhtml#page_81),\n[241](25_Chapter_15_Real_and_A.xhtml#page_241),\n[253](26_Chapter_16_A_Quantum_.xhtml#page_253)–64,\n[280](27_Chapter_17_5g_and_Iot.xhtml#page_280),\n[305](31_Glossary.xhtml#page_305)–6\n\nAI and, [263](26_Chapter_16_A_Quantum_.xhtml#page_263)–64\n\nencryption and, [260](26_Chapter_16_A_Quantum_.xhtml#page_260)–62\n\nquantum key distribution, [262](26_Chapter_16_A_Quantum_.xhtml#page_262)\n\nqubit (quantum bit), [253](26_Chapter_16_A_Quantum_.xhtml#page_253),\n[255](26_Chapter_16_A_Quantum_.xhtml#page_255)–59\n\nransomware, [18](08_Chapter_2_Eternalblue.xhtml#page_18),\n[38](10_Chapter_3_Two_Kinds_o.xhtml#page_38),\n[125](15_Chapter_7_Nudges_and_.xhtml#page_125)–28,\n[188](21_Chapter_12_The_Milita.xhtml#page_188),\n[306](31_Glossary.xhtml#page_306)\n\nRattray, Greg, [101](13_Chapter_6_Cyber_Resil.xhtml#page_101)–3\n\nRaul, Alan Charles, [95](13_Chapter_6_Cyber_Resil.xhtml#page_95)\n\nReallyU, [138](16_Chapter_8_Is_It_Reall.xhtml#page_138)–40,\n[306](31_Glossary.xhtml#page_306)\n\nreconnaissance, [51](11_Chapter_4_The_Kill_Ch.xhtml#page_51),\n[52](11_Chapter_4_The_Kill_Ch.xhtml#page_52)\n\n“recover” function, [45](10_Chapter_3_Two_Kinds_o.xhtml#page_45),\n[66](12_Chapter_5_The_Tech_St.xhtml#page_66),\n[71](12_Chapter_5_The_Tech_St.xhtml#page_71)\n\nregulation, [109](15_Chapter_7_Nudges_and_.xhtml#page_109)–20,\n[122](15_Chapter_7_Nudges_and_.xhtml#page_122)–23,\n[139](16_Chapter_8_Is_It_Reall.xhtml#page_139)–40,\n[268](27_Chapter_17_5g_and_Iot.xhtml#page_268)–69,\n[278](27_Chapter_17_5g_and_Iot.xhtml#page_278)\n\nReitinger, Phil, [140](16_Chapter_8_Is_It_Reall.xhtml#page_140)\n\nremote access tools, [38](10_Chapter_3_Two_Kinds_o.xhtml#page_38)\n\nReno, Janet, [168](19_Chapter_11_Securing_t.xhtml#page_168)\n\nRepublican Party, [11](07_Chapter_1_The_Back_of.xhtml#page_11),\n[228](23_Chapter_14_Democracy_.xhtml#page_228),\n[268](27_Chapter_17_5g_and_Iot.xhtml#page_268)\n\nresilience, [14](07_Chapter_1_The_Back_of.xhtml#page_14)–15,\n[42](10_Chapter_3_Two_Kinds_o.xhtml#page_42),\n[70](12_Chapter_5_The_Tech_St.xhtml#page_70)–72,\n[82](12_Chapter_5_The_Tech_St.xhtml#page_82),\n[104](13_Chapter_6_Cyber_Resil.xhtml#page_104),\n[105](13_Chapter_6_Cyber_Resil.xhtml#page_105),\n[296](30_Chapter_19_Everything.xhtml#page_296)–97\n\n“respond” function, [45](10_Chapter_3_Two_Kinds_o.xhtml#page_45),\n[66](12_Chapter_5_The_Tech_St.xhtml#page_66),\n[71](12_Chapter_5_The_Tech_St.xhtml#page_71)\n\nRice University, [80](12_Chapter_5_The_Tech_St.xhtml#page_80)–81\n\nRickover, Hyman, [150](17_Chapter_9_Fixing_the_.xhtml#page_150),\n[198](21_Chapter_12_The_Milita.xhtml#page_198),\n[201](21_Chapter_12_The_Milita.xhtml#page_201)\n\nRigetti, Chad, [253](26_Chapter_16_A_Quantum_.xhtml#page_253)–54,\n[257](26_Chapter_16_A_Quantum_.xhtml#page_257),\n[259](26_Chapter_16_A_Quantum_.xhtml#page_259),\n[262](26_Chapter_16_A_Quantum_.xhtml#page_262)–64\n\nRigetti Computing, [253](26_Chapter_16_A_Quantum_.xhtml#page_253)–54,\n[259](26_Chapter_16_A_Quantum_.xhtml#page_259),\n[261](26_Chapter_16_A_Quantum_.xhtml#page_261)\n\nRinard, Martin, [80](12_Chapter_5_The_Tech_St.xhtml#page_80)\n\nRodin, Judith, [15](07_Chapter_1_The_Back_of.xhtml#page_15)\n\n_Rolling Stone_ , [207](22_Chapter_13_A_Schengen.xhtml#page_207)–8\n\nRoosevelt, Franklin, [9](07_Chapter_1_The_Back_of.xhtml#page_9)\n\nRosenbach, Eric, [198](21_Chapter_12_The_Milita.xhtml#page_198),\n[221](23_Chapter_14_Democracy_.xhtml#page_221)–22,\n[224](23_Chapter_14_Democracy_.xhtml#page_224)–26,\n[233](23_Chapter_14_Democracy_.xhtml#page_233),\n[234](23_Chapter_14_Democracy_.xhtml#page_234)\n\nRosenberg, Simon, [231](23_Chapter_14_Democracy_.xhtml#page_231)–32\n\nRosenberger, Laura, [221](23_Chapter_14_Democracy_.xhtml#page_221)–24,\n[231](23_Chapter_14_Democracy_.xhtml#page_231),\n[234](23_Chapter_14_Democracy_.xhtml#page_234)\n\nRothrock, Ray, [14](07_Chapter_1_The_Back_of.xhtml#page_14)\n\nRouth, Jim, [41](10_Chapter_3_Two_Kinds_o.xhtml#page_41)–42,\n[133](16_Chapter_8_Is_It_Reall.xhtml#page_133)\n\nRSA, [49](11_Chapter_4_The_Kill_Ch.xhtml#page_49),\n[69](12_Chapter_5_The_Tech_St.xhtml#page_69),\n[92](13_Chapter_6_Cyber_Resil.xhtml#page_92),\n[102](13_Chapter_6_Cyber_Resil.xhtml#page_102),\n[124](15_Chapter_7_Nudges_and_.xhtml#page_124)–25,\n[129](16_Chapter_8_Is_It_Reall.xhtml#page_129),\n[241](25_Chapter_15_Real_and_A.xhtml#page_241),\n[306](31_Glossary.xhtml#page_306)\n\nRubio, Marco, [223](23_Chapter_14_Democracy_.xhtml#page_223)\n\nRussia, [5](07_Chapter_1_The_Back_of.xhtml#page_5),\n[17](08_Chapter_2_Eternalblue.xhtml#page_17),\n[21](08_Chapter_2_Eternalblue.xhtml#page_21),\n[28](08_Chapter_2_Eternalblue.xhtml#page_28),\n[33](10_Chapter_3_Two_Kinds_o.xhtml#page_33),\n[46](10_Chapter_3_Two_Kinds_o.xhtml#page_46),\n[94](13_Chapter_6_Cyber_Resil.xhtml#page_94),\n[97](13_Chapter_6_Cyber_Resil.xhtml#page_97),\n[120](15_Chapter_7_Nudges_and_.xhtml#page_120),\n[121](15_Chapter_7_Nudges_and_.xhtml#page_121),\n[157](18_Chapter_10_Power_Grid.xhtml#page_157),\n[163](18_Chapter_10_Power_Grid.xhtml#page_163),\n[166](18_Chapter_10_Power_Grid.xhtml#page_166),\n[182](21_Chapter_12_The_Milita.xhtml#page_182),\n[187](21_Chapter_12_The_Milita.xhtml#page_187),\n[188](21_Chapter_12_The_Milita.xhtml#page_188),\n[195](21_Chapter_12_The_Milita.xhtml#page_195),\n[196](21_Chapter_12_The_Milita.xhtml#page_196),\n[198](21_Chapter_12_The_Milita.xhtml#page_198),\n[200](21_Chapter_12_The_Milita.xhtml#page_200),\n[210](22_Chapter_13_A_Schengen.xhtml#page_210),\n[219](23_Chapter_14_Democracy_.xhtml#page_219)–34,\n[241](25_Chapter_15_Real_and_A.xhtml#page_241),\n[248](25_Chapter_15_Real_and_A.xhtml#page_248),\n[277](27_Chapter_17_5g_and_Iot.xhtml#page_277)\n\nelections and, [26](08_Chapter_2_Eternalblue.xhtml#page_26),\n[159](18_Chapter_10_Power_Grid.xhtml#page_159),\n[160](18_Chapter_10_Power_Grid.xhtml#page_160),\n[222](23_Chapter_14_Democracy_.xhtml#page_222)–23,\n[227](23_Chapter_14_Democracy_.xhtml#page_227),\n[228](23_Chapter_14_Democracy_.xhtml#page_228),\n[230](23_Chapter_14_Democracy_.xhtml#page_230)–35\n\nGRU, [19](08_Chapter_2_Eternalblue.xhtml#page_19)–23,\n[25](08_Chapter_2_Eternalblue.xhtml#page_25)–26,\n[28](08_Chapter_2_Eternalblue.xhtml#page_28),\n[165](18_Chapter_10_Power_Grid.xhtml#page_165),\n[234](23_Chapter_14_Democracy_.xhtml#page_234),\n[277](27_Chapter_17_5g_and_Iot.xhtml#page_277),\n[302](31_Glossary.xhtml#page_302)\n\ninternet and, [206](22_Chapter_13_A_Schengen.xhtml#page_206),\n[208](22_Chapter_13_A_Schengen.xhtml#page_208),\n[210](22_Chapter_13_A_Schengen.xhtml#page_210),\n[211](22_Chapter_13_A_Schengen.xhtml#page_211),\n[219](23_Chapter_14_Democracy_.xhtml#page_219)–20\n\npower grid and, [26](08_Chapter_2_Eternalblue.xhtml#page_26),\n[159](18_Chapter_10_Power_Grid.xhtml#page_159)–61,\n[164](18_Chapter_10_Power_Grid.xhtml#page_164)–66,\n[200](21_Chapter_12_The_Milita.xhtml#page_200)\n\nquantum computing and, [259](26_Chapter_16_A_Quantum_.xhtml#page_259),\n[260](26_Chapter_16_A_Quantum_.xhtml#page_260),\n[264](26_Chapter_16_A_Quantum_.xhtml#page_264)\n\nUkraine and, [19](08_Chapter_2_Eternalblue.xhtml#page_19)–20,\n[25](08_Chapter_2_Eternalblue.xhtml#page_25),\n[29](08_Chapter_2_Eternalblue.xhtml#page_29),\n[157](18_Chapter_10_Power_Grid.xhtml#page_157),\n[222](23_Chapter_14_Democracy_.xhtml#page_222)\n\nSalesforce, [75](12_Chapter_5_The_Tech_St.xhtml#page_75)\n\nSamsung, [24](08_Chapter_2_Eternalblue.xhtml#page_24),\n[37](10_Chapter_3_Two_Kinds_o.xhtml#page_37)\n\nSaudi Arabia, [27](08_Chapter_2_Eternalblue.xhtml#page_27),\n[274](27_Chapter_17_5g_and_Iot.xhtml#page_274),\n[275](27_Chapter_17_5g_and_Iot.xhtml#page_275),\n[277](27_Chapter_17_5g_and_Iot.xhtml#page_277)\n\nSaudi Aramco, [27](08_Chapter_2_Eternalblue.xhtml#page_27),\n[188](21_Chapter_12_The_Milita.xhtml#page_188)\n\nSavandi, Faramarz, [126](15_Chapter_7_Nudges_and_.xhtml#page_126)\n\nSchell, Roger, [103](13_Chapter_6_Cyber_Resil.xhtml#page_103)\n\nSchengen Accord, [206](22_Chapter_13_A_Schengen.xhtml#page_206)–7,\n[212](22_Chapter_13_A_Schengen.xhtml#page_212),\n[218](22_Chapter_13_A_Schengen.xhtml#page_218),\n[306](31_Glossary.xhtml#page_306)\n\nfor the internet, [205](22_Chapter_13_A_Schengen.xhtml#page_205)–18\n\nSchmidt, Eric, [205](22_Chapter_13_A_Schengen.xhtml#page_205)\n\nSchou, Corey, [167](19_Chapter_11_Securing_t.xhtml#page_167)–69\n\nSchulte, Joshua, [23](08_Chapter_2_Eternalblue.xhtml#page_23)–24\n\nSchwarzkopf, Norman, Jr., [198](21_Chapter_12_The_Milita.xhtml#page_198)\n\nsecure development life cycle (SDLC),\n[79](12_Chapter_5_The_Tech_St.xhtml#page_79),\n[80](12_Chapter_5_The_Tech_St.xhtml#page_80),\n[306](31_Glossary.xhtml#page_306)\n\nsecure segmented diverse-source microgrid (SSDM),\n[164](18_Chapter_10_Power_Grid.xhtml#page_164)–65,\n[306](31_Glossary.xhtml#page_306)\n\nSecurities and Exchange Commission,\n[8](07_Chapter_1_The_Back_of.xhtml#page_8),\n[43](10_Chapter_3_Two_Kinds_o.xhtml#page_43),\n[87](13_Chapter_6_Cyber_Resil.xhtml#page_87),\n[115](15_Chapter_7_Nudges_and_.xhtml#page_115)\n\nsecurity information and event management,\n[71](12_Chapter_5_The_Tech_St.xhtml#page_71)\n\nsecurity operations centers (SOCs),\n[71](12_Chapter_5_The_Tech_St.xhtml#page_71),\n[74](12_Chapter_5_The_Tech_St.xhtml#page_74),\n[153](17_Chapter_9_Fixing_the_.xhtml#page_153),\n[246](25_Chapter_15_Real_and_A.xhtml#page_246),\n[248](25_Chapter_15_Real_and_A.xhtml#page_248),\n[307](31_Glossary.xhtml#page_307)\n\nSeehra, Jasmeet, [111](15_Chapter_7_Nudges_and_.xhtml#page_111)\n\nSenate, U.S., [78](12_Chapter_5_The_Tech_St.xhtml#page_78),\n[232](23_Chapter_14_Democracy_.xhtml#page_232)\n\nSenior Cyber Service, [173](19_Chapter_11_Securing_t.xhtml#page_173),\n[178](19_Chapter_11_Securing_t.xhtml#page_178)\n\nsensors, [66](12_Chapter_5_The_Tech_St.xhtml#page_66)–67,\n[83](12_Chapter_5_The_Tech_St.xhtml#page_83)\n\nShanahan, Patrick, [181](21_Chapter_12_The_Milita.xhtml#page_181)\n\nSharkseer, [95](13_Chapter_6_Cyber_Resil.xhtml#page_95)\n\nShavitt, Yuval, [120](15_Chapter_7_Nudges_and_.xhtml#page_120)\n\nSiemens, [37](10_Chapter_3_Two_Kinds_o.xhtml#page_37),\n[270](27_Chapter_17_5g_and_Iot.xhtml#page_270)\n\nSilicon Valley, [5](07_Chapter_1_The_Back_of.xhtml#page_5),\n[7](07_Chapter_1_The_Back_of.xhtml#page_7),\n[63](12_Chapter_5_The_Tech_St.xhtml#page_63)–64,\n[67](12_Chapter_5_The_Tech_St.xhtml#page_67),\n[73](12_Chapter_5_The_Tech_St.xhtml#page_73),\n[140](16_Chapter_8_Is_It_Reall.xhtml#page_140)\n\nSinger, Peter, [101](13_Chapter_6_Cyber_Resil.xhtml#page_101)\n\nsmart cards, [129](16_Chapter_8_Is_It_Reall.xhtml#page_129),\n[130](16_Chapter_8_Is_It_Reall.xhtml#page_130),\n[133](16_Chapter_8_Is_It_Reall.xhtml#page_133)\n\nsmartphones, [131](16_Chapter_8_Is_It_Reall.xhtml#page_131),\n[289](29_Chapter_18_Derisking_.xhtml#page_289)–91\n\niPhones, [36](10_Chapter_3_Two_Kinds_o.xhtml#page_36),\n[68](12_Chapter_5_The_Tech_St.xhtml#page_68),\n[124](15_Chapter_7_Nudges_and_.xhtml#page_124)–25,\n[292](29_Chapter_18_Derisking_.xhtml#page_292)\n\nSmith, Brad, [24](08_Chapter_2_Eternalblue.xhtml#page_24)\n\nSnowden, Edward, [21](08_Chapter_2_Eternalblue.xhtml#page_21),\n[23](08_Chapter_2_Eternalblue.xhtml#page_23),\n[209](22_Chapter_13_A_Schengen.xhtml#page_209)\n\nSocial Security, [133](16_Chapter_8_Is_It_Reall.xhtml#page_133),\n[134](16_Chapter_8_Is_It_Reall.xhtml#page_134),\n[136](16_Chapter_8_Is_It_Reall.xhtml#page_136),\n[138](16_Chapter_8_Is_It_Reall.xhtml#page_138)–40,\n[283](29_Chapter_18_Derisking_.xhtml#page_283)\n\nsoftware, [21](08_Chapter_2_Eternalblue.xhtml#page_21),\n[22](08_Chapter_2_Eternalblue.xhtml#page_22)\n\ncoding of, [78](12_Chapter_5_The_Tech_St.xhtml#page_78)–82\n\nsecurity and, [288](29_Chapter_18_Derisking_.xhtml#page_288)\n\nsoftware as a service (SaaS), [75](12_Chapter_5_The_Tech_St.xhtml#page_75),\n[76](12_Chapter_5_The_Tech_St.xhtml#page_76),\n[307](31_Glossary.xhtml#page_307)\n\nSophos, [61](11_Chapter_4_The_Kill_Ch.xhtml#page_61),\n[288](29_Chapter_18_Derisking_.xhtml#page_288)\n\nSouth Korea, [27](08_Chapter_2_Eternalblue.xhtml#page_27),\n[120](15_Chapter_7_Nudges_and_.xhtml#page_120),\n[188](21_Chapter_12_The_Milita.xhtml#page_188)\n\nSoviet Union, [13](07_Chapter_1_The_Back_of.xhtml#page_13),\n[135](16_Chapter_8_Is_It_Reall.xhtml#page_135),\n[182](21_Chapter_12_The_Milita.xhtml#page_182),\n[221](23_Chapter_14_Democracy_.xhtml#page_221),\n[234](23_Chapter_14_Democracy_.xhtml#page_234)\n\nSpamhaus, [73](12_Chapter_5_The_Tech_St.xhtml#page_73)\n\nspear phishing, [53](11_Chapter_4_The_Kill_Ch.xhtml#page_53)–55,\n[59](11_Chapter_4_The_Kill_Ch.xhtml#page_59),\n[288](29_Chapter_18_Derisking_.xhtml#page_288)\n\nStamos, Alex, [221](23_Chapter_14_Democracy_.xhtml#page_221),\n[228](23_Chapter_14_Democracy_.xhtml#page_228)\n\nState Department, [6](07_Chapter_1_The_Back_of.xhtml#page_6),\n[25](08_Chapter_2_Eternalblue.xhtml#page_25),\n[86](13_Chapter_6_Cyber_Resil.xhtml#page_86),\n[93](13_Chapter_6_Cyber_Resil.xhtml#page_93),\n[95](13_Chapter_6_Cyber_Resil.xhtml#page_95),\n[136](16_Chapter_8_Is_It_Reall.xhtml#page_136),\n[173](19_Chapter_11_Securing_t.xhtml#page_173),\n[202](21_Chapter_12_The_Milita.xhtml#page_202),\n[203](21_Chapter_12_The_Milita.xhtml#page_203),\n[210](22_Chapter_13_A_Schengen.xhtml#page_210),\n[221](23_Chapter_14_Democracy_.xhtml#page_221)–22\n\nstate governments, [117](15_Chapter_7_Nudges_and_.xhtml#page_117)–18,\n[174](19_Chapter_11_Securing_t.xhtml#page_174)–75,\n[177](19_Chapter_11_Securing_t.xhtml#page_177)\n\nStein, Jill, [232](23_Chapter_14_Democracy_.xhtml#page_232)\n\nStempfley, Bobbie, [151](17_Chapter_9_Fixing_the_.xhtml#page_151)\n\nstock transactions, [287](29_Chapter_18_Derisking_.xhtml#page_287)\n\nStratton, Robert, [295](30_Chapter_19_Everything.xhtml#page_295)\n\nStuxnet, [20](08_Chapter_2_Eternalblue.xhtml#page_20)–21,\n[37](10_Chapter_3_Two_Kinds_o.xhtml#page_37)–38,\n[85](13_Chapter_6_Cyber_Resil.xhtml#page_85),\n[160](18_Chapter_10_Power_Grid.xhtml#page_160),\n[182](21_Chapter_12_The_Milita.xhtml#page_182),\n[193](21_Chapter_12_The_Milita.xhtml#page_193)–94,\n[270](27_Chapter_17_5g_and_Iot.xhtml#page_270)–71,\n[277](27_Chapter_17_5g_and_Iot.xhtml#page_277),\n[307](31_Glossary.xhtml#page_307)\n\nSulmeyer, Michael, [100](13_Chapter_6_Cyber_Resil.xhtml#page_100)\n\nSunstein, Cass, [111](15_Chapter_7_Nudges_and_.xhtml#page_111)\n\nsupervisory control and data acquisition (SCADA),\n[163](18_Chapter_10_Power_Grid.xhtml#page_163),\n[270](27_Chapter_17_5g_and_Iot.xhtml#page_270),\n[273](27_Chapter_17_5g_and_Iot.xhtml#page_273),\n[307](31_Glossary.xhtml#page_307)\n\nSymantec, [24](08_Chapter_2_Eternalblue.xhtml#page_24),\n[37](10_Chapter_3_Two_Kinds_o.xhtml#page_37),\n[46](10_Chapter_3_Two_Kinds_o.xhtml#page_46),\n[61](11_Chapter_4_The_Kill_Ch.xhtml#page_61),\n[83](12_Chapter_5_The_Tech_St.xhtml#page_83),\n[288](29_Chapter_18_Derisking_.xhtml#page_288)\n\ntabletop exercises (TTXs), [185](21_Chapter_12_The_Milita.xhtml#page_185)–92,\n[198](21_Chapter_12_The_Milita.xhtml#page_198),\n[225](23_Chapter_14_Democracy_.xhtml#page_225)–26,\n[307](31_Glossary.xhtml#page_307)\n\nTailored Access Operations (TAO),\n[73](12_Chapter_5_The_Tech_St.xhtml#page_73),\n[148](17_Chapter_9_Fixing_the_.xhtml#page_148),\n[307](31_Glossary.xhtml#page_307)\n\nterrorism, [13](07_Chapter_1_The_Back_of.xhtml#page_13),\n[110](15_Chapter_7_Nudges_and_.xhtml#page_110),\n[114](15_Chapter_7_Nudges_and_.xhtml#page_114)–15,\n[123](15_Chapter_7_Nudges_and_.xhtml#page_123)–25,\n[137](16_Chapter_8_Is_It_Reall.xhtml#page_137),\n[156](18_Chapter_10_Power_Grid.xhtml#page_156)\n\n9/11 attacks, [26](08_Chapter_2_Eternalblue.xhtml#page_26),\n[88](13_Chapter_6_Cyber_Resil.xhtml#page_88),\n[114](15_Chapter_7_Nudges_and_.xhtml#page_114),\n[123](15_Chapter_7_Nudges_and_.xhtml#page_123),\n[137](16_Chapter_8_Is_It_Reall.xhtml#page_137),\n[155](18_Chapter_10_Power_Grid.xhtml#page_155),\n[196](21_Chapter_12_The_Milita.xhtml#page_196),\n[222](23_Chapter_14_Democracy_.xhtml#page_222),\n[234](23_Chapter_14_Democracy_.xhtml#page_234)\n\nTerrorism Risk Insurance Act, [123](15_Chapter_7_Nudges_and_.xhtml#page_123)\n\nThaler, Richard, [111](15_Chapter_7_Nudges_and_.xhtml#page_111)\n\nthreat actors, [12](07_Chapter_1_The_Back_of.xhtml#page_12),\n[41](10_Chapter_3_Two_Kinds_o.xhtml#page_41),\n[64](12_Chapter_5_The_Tech_St.xhtml#page_64),\n[77](12_Chapter_5_The_Tech_St.xhtml#page_77),\n[307](31_Glossary.xhtml#page_307)\n\ntractors, [269](27_Chapter_17_5g_and_Iot.xhtml#page_269)–70\n\nTransportation, Department of, [278](27_Chapter_17_5g_and_Iot.xhtml#page_278)\n\nTreasury Department, [21](08_Chapter_2_Eternalblue.xhtml#page_21),\n[152](17_Chapter_9_Fixing_the_.xhtml#page_152)\n\nTrump, Donald, [11](07_Chapter_1_The_Back_of.xhtml#page_11),\n[21](08_Chapter_2_Eternalblue.xhtml#page_21),\n[27](08_Chapter_2_Eternalblue.xhtml#page_27),\n[89](13_Chapter_6_Cyber_Resil.xhtml#page_89),\n[92](13_Chapter_6_Cyber_Resil.xhtml#page_92),\n[113](15_Chapter_7_Nudges_and_.xhtml#page_113),\n[123](15_Chapter_7_Nudges_and_.xhtml#page_123),\n[152](17_Chapter_9_Fixing_the_.xhtml#page_152),\n[160](18_Chapter_10_Power_Grid.xhtml#page_160),\n[171](19_Chapter_11_Securing_t.xhtml#page_171),\n[181](21_Chapter_12_The_Milita.xhtml#page_181),\n[196](21_Chapter_12_The_Milita.xhtml#page_196),\n[203](21_Chapter_12_The_Milita.xhtml#page_203),\n[224](23_Chapter_14_Democracy_.xhtml#page_224),\n[267](27_Chapter_17_5g_and_Iot.xhtml#page_267)\n\nTSA (Transportation Security Administration),\n[137](16_Chapter_8_Is_It_Reall.xhtml#page_137),\n[140](16_Chapter_8_Is_It_Reall.xhtml#page_140),\n[177](19_Chapter_11_Securing_t.xhtml#page_177)\n\nTwitter, [224](23_Chapter_14_Democracy_.xhtml#page_224),\n[231](23_Chapter_14_Democracy_.xhtml#page_231),\n[232](23_Chapter_14_Democracy_.xhtml#page_232),\n[276](27_Chapter_17_5g_and_Iot.xhtml#page_276)\n\ntwo-factor authentication, [129](16_Chapter_8_Is_It_Reall.xhtml#page_129),\n[131](16_Chapter_8_Is_It_Reall.xhtml#page_131),\n[132](16_Chapter_8_Is_It_Reall.xhtml#page_132),\n[285](29_Chapter_18_Derisking_.xhtml#page_285),\n[287](29_Chapter_18_Derisking_.xhtml#page_287),\n[308](31_Glossary.xhtml#page_308)\n\nUkraine, [8](07_Chapter_1_The_Back_of.xhtml#page_8),\n[19](08_Chapter_2_Eternalblue.xhtml#page_19)–20,\n[25](08_Chapter_2_Eternalblue.xhtml#page_25),\n[29](08_Chapter_2_Eternalblue.xhtml#page_29),\n[37](10_Chapter_3_Two_Kinds_o.xhtml#page_37),\n[157](18_Chapter_10_Power_Grid.xhtml#page_157),\n[222](23_Chapter_14_Democracy_.xhtml#page_222),\n[269](27_Chapter_17_5g_and_Iot.xhtml#page_269)–70,\n[277](27_Chapter_17_5g_and_Iot.xhtml#page_277)\n\nUnited Health, [40](10_Chapter_3_Two_Kinds_o.xhtml#page_40)–41\n\nUnited Kingdom, [17](08_Chapter_2_Eternalblue.xhtml#page_17)–18,\n[25](08_Chapter_2_Eternalblue.xhtml#page_25),\n[96](13_Chapter_6_Cyber_Resil.xhtml#page_96),\n[211](22_Chapter_13_A_Schengen.xhtml#page_211)–12,\n[220](23_Chapter_14_Democracy_.xhtml#page_220)–21\n\nUnited Nations (UN), [210](22_Chapter_13_A_Schengen.xhtml#page_210)\n\nUnited States–Mexico–Canada Agreement,\n[213](22_Chapter_13_A_Schengen.xhtml#page_213)\n\nU.S. Code, [194](21_Chapter_12_The_Milita.xhtml#page_194)\n\nVan Evera, Stephen, [100](13_Chapter_6_Cyber_Resil.xhtml#page_100)\n\nvehicles, [266](27_Chapter_17_5g_and_Iot.xhtml#page_266)–67,\n[269](27_Chapter_17_5g_and_Iot.xhtml#page_269)–70\n\nVenables, Phil, [101](13_Chapter_6_Cyber_Resil.xhtml#page_101)–3\n\nVENOM vulnerability, [77](12_Chapter_5_The_Tech_St.xhtml#page_77)\n\nventure capital (VC), [5](07_Chapter_1_The_Back_of.xhtml#page_5),\n[63](12_Chapter_5_The_Tech_St.xhtml#page_63)–64,\n[67](12_Chapter_5_The_Tech_St.xhtml#page_67)–69,\n[82](12_Chapter_5_The_Tech_St.xhtml#page_82)–83,\n[94](13_Chapter_6_Cyber_Resil.xhtml#page_94),\n[136](16_Chapter_8_Is_It_Reall.xhtml#page_136),\n[140](16_Chapter_8_Is_It_Reall.xhtml#page_140),\n[248](25_Chapter_15_Real_and_A.xhtml#page_248)\n\nVeracode, [79](12_Chapter_5_The_Tech_St.xhtml#page_79)–80\n\nVerizon, [45](10_Chapter_3_Two_Kinds_o.xhtml#page_45)–46,\n[119](15_Chapter_7_Nudges_and_.xhtml#page_119),\n[138](16_Chapter_8_Is_It_Reall.xhtml#page_138),\n[265](27_Chapter_17_5g_and_Iot.xhtml#page_265)–66\n\nVerve, [271](27_Chapter_17_5g_and_Iot.xhtml#page_271),\n[273](27_Chapter_17_5g_and_Iot.xhtml#page_273)\n\nVirginia, [174](19_Chapter_11_Securing_t.xhtml#page_174),\n[176](19_Chapter_11_Securing_t.xhtml#page_176),\n[230](23_Chapter_14_Democracy_.xhtml#page_230),\n[231](23_Chapter_14_Democracy_.xhtml#page_231)\n\nvirtual private networks (VPNs), [20](08_Chapter_2_Eternalblue.xhtml#page_20),\n[65](12_Chapter_5_The_Tech_St.xhtml#page_65),\n[160](18_Chapter_10_Power_Grid.xhtml#page_160),\n[308](31_Glossary.xhtml#page_308)\n\nVM escape attack, [77](12_Chapter_5_The_Tech_St.xhtml#page_77)\n\nVora, Poorvi, [219](23_Chapter_14_Democracy_.xhtml#page_219)\n\nVulnerabilities Equities Process, [36](10_Chapter_3_Two_Kinds_o.xhtml#page_36)\n\nvulnerability managers, [245](25_Chapter_15_Real_and_A.xhtml#page_245)\n\n_Wall Street Journal_ , [86](13_Chapter_6_Cyber_Resil.xhtml#page_86),\n[95](13_Chapter_6_Cyber_Resil.xhtml#page_95)\n\nWannaCry, [18](08_Chapter_2_Eternalblue.xhtml#page_18),\n[22](08_Chapter_2_Eternalblue.xhtml#page_22),\n[27](08_Chapter_2_Eternalblue.xhtml#page_27)\n\nwar, [7](07_Chapter_1_The_Back_of.xhtml#page_7)–8,\n[87](13_Chapter_6_Cyber_Resil.xhtml#page_87),\n[100](13_Chapter_6_Cyber_Resil.xhtml#page_100),\n[182](21_Chapter_12_The_Milita.xhtml#page_182)–83,\n[198](21_Chapter_12_The_Milita.xhtml#page_198)\n\nnuclear, _see_ nuclear weapons\n\n_see also_ cyber war\n\nWarner, Mark, [230](23_Chapter_14_Democracy_.xhtml#page_230)\n\n_Warnings_ (Clarke and Eddy), [162](18_Chapter_10_Power_Grid.xhtml#page_162),\n[223](23_Chapter_14_Democracy_.xhtml#page_223)\n\nweaponization, [51](11_Chapter_4_The_Kill_Ch.xhtml#page_51)–53\n\nWeedbrook, Christian, [258](26_Chapter_16_A_Quantum_.xhtml#page_258)–59\n\nWells Fargo, [79](12_Chapter_5_The_Tech_St.xhtml#page_79)–80,\n[136](16_Chapter_8_Is_It_Reall.xhtml#page_136),\n[284](29_Chapter_18_Derisking_.xhtml#page_284)\n\n_Who Controls the Internet?_ (Wu and Goldsmith),\n[208](22_Chapter_13_A_Schengen.xhtml#page_208)\n\nWikiLeaks, [21](08_Chapter_2_Eternalblue.xhtml#page_21),\n[24](08_Chapter_2_Eternalblue.xhtml#page_24),\n[37](10_Chapter_3_Two_Kinds_o.xhtml#page_37)\n\nwipers, [18](08_Chapter_2_Eternalblue.xhtml#page_18)–19,\n[38](10_Chapter_3_Two_Kinds_o.xhtml#page_38),\n[188](21_Chapter_12_The_Milita.xhtml#page_188),\n[308](31_Glossary.xhtml#page_308)\n\nWolff, Evan, [112](15_Chapter_7_Nudges_and_.xhtml#page_112)\n\nWorkday, [152](17_Chapter_9_Fixing_the_.xhtml#page_152)\n\nWorld War I, [100](13_Chapter_6_Cyber_Resil.xhtml#page_100)–101,\n[183](21_Chapter_12_The_Milita.xhtml#page_183),\n[240](25_Chapter_15_Real_and_A.xhtml#page_240)\n\nWorld War II, [73](12_Chapter_5_The_Tech_St.xhtml#page_73),\n[150](17_Chapter_9_Fixing_the_.xhtml#page_150),\n[183](21_Chapter_12_The_Milita.xhtml#page_183),\n[240](25_Chapter_15_Real_and_A.xhtml#page_240)\n\nWu, Tim, [208](22_Chapter_13_A_Schengen.xhtml#page_208)\n\nXanadu, [258](26_Chapter_16_A_Quantum_.xhtml#page_258)–59\n\nXi Jinping, [26](08_Chapter_2_Eternalblue.xhtml#page_26),\n[33](10_Chapter_3_Two_Kinds_o.xhtml#page_33)–34,\n[241](25_Chapter_15_Real_and_A.xhtml#page_241)\n\nXu, Yanjun, [28](08_Chapter_2_Eternalblue.xhtml#page_28)\n\nYahoo, [209](22_Chapter_13_A_Schengen.xhtml#page_209)\n\nYear Two Thousand (Y2K), [262](26_Chapter_16_A_Quantum_.xhtml#page_262),\n[208](22_Chapter_13_A_Schengen.xhtml#page_208)\n\nYouTube, [232](23_Chapter_14_Democracy_.xhtml#page_232)\n\nYu, Sounil, [65](12_Chapter_5_The_Tech_St.xhtml#page_65)–67,\n[69](12_Chapter_5_The_Tech_St.xhtml#page_69)–72,\n[82](12_Chapter_5_The_Tech_St.xhtml#page_82),\n[83](12_Chapter_5_The_Tech_St.xhtml#page_83)\n\nZatko, Mudge, [78](12_Chapter_5_The_Tech_St.xhtml#page_78)–79,\n[82](12_Chapter_5_The_Tech_St.xhtml#page_82),\n[119](15_Chapter_7_Nudges_and_.xhtml#page_119)\n\nZatko, Sarah, [82](12_Chapter_5_The_Tech_St.xhtml#page_82)\n\nZelvin, Larry, [73](12_Chapter_5_The_Tech_St.xhtml#page_73)\n\nzero-day vulnerability, [21](08_Chapter_2_Eternalblue.xhtml#page_21)–24,\n[36](10_Chapter_3_Two_Kinds_o.xhtml#page_36),\n[38](10_Chapter_3_Two_Kinds_o.xhtml#page_38),\n[46](10_Chapter_3_Two_Kinds_o.xhtml#page_46),\n[297](30_Chapter_19_Everything.xhtml#page_297),\n[308](31_Glossary.xhtml#page_308)\n\nZuckerberg, Mark, [67](12_Chapter_5_The_Tech_St.xhtml#page_67)\n\nZurich Insurance Group, [121](15_Chapter_7_Nudges_and_.xhtml#page_121)\n\nABCDEFGHIJKLMNOPQRSTUVWXYZ\n\n\n# About the Authors\n\n**Richard A. Clarke** is one of the world’s leading experts on security,\ncyberspace, and terrorism. He served in the U.S. government for thirty years,\nincluding as White House counterterrorism coordinator under Presidents Bill\nClinton and George W. Bush, and became the first White House official placed\nin charge of U.S. cybersecurity policy. He is the author of eight books (four\nworks of nonfiction and four novels), including the number-one national\nbestseller _Against All Enemies: Inside America’s War on Terror_.\n\n**Robert K. Knake** is a senior fellow at the Council on Foreign Relations, a\nsenior research scientist at Northeastern University, and an adviser to\nstartups, investment firms, and Fortune 500 companies. Knake served from\n2011-15 in the Obama White House as director for cybersecurity policy at the\nNational Security Council. He is the co-author (with Clarke) of the _New York\nTimes_ bestseller _Cyber War_.\n\n\n![Penguin Random House Next Reads logo](../images/next-reads_logo.jpg)\n\n#  What’s next on  \nyour reading list?\n\n[Discover your next  \ngreat\nread!](http://links.penguinrandomhouse.com/type/prhebooklanding/isbn/9780525561972/display/1)\n\nGet personalized book picks and up-to-date news about this author.\n\n[Sign up\nnow.](http://links.penguinrandomhouse.com/type/prhebooklanding/isbn/9780525561972/display/2)\n\n\n# Contents\n\n  1. [Cover](xhtml/01_Cover.xhtml)\n  2. [Title Page](xhtml/02_Title_Page.xhtml)\n  3. [Copyright](xhtml/03_Copyright.xhtml)\n  4. [Dedication](xhtml/04_Dedication.xhtml)\n  5. [Contents](xhtml/05_Contents.xhtml)\n  6. [Part I: The Twenty-Year War](xhtml/06_Part_I_The_Twenty-Yea.xhtml)\n     1. [Chapter 1: The Back of the Beast](xhtml/07_Chapter_1_The_Back_of.xhtml)\n     2. [Chapter 2: Eternalblue, Eternal War](xhtml/08_Chapter_2_Eternalblue.xhtml)\n  7. [Part II: The Corporate Frontline](xhtml/09_Part_II_The_Corporate.xhtml)\n     1. [Chapter 3: Two Kinds of Companies?](xhtml/10_Chapter_3_Two_Kinds_o.xhtml)\n     2. [Chapter 4: The Kill Chain](xhtml/11_Chapter_4_The_Kill_Ch.xhtml)\n     3. [Chapter 5: The Tech Stack](xhtml/12_Chapter_5_The_Tech_St.xhtml)\n     4. [Chapter 6: Cyber Resilience: The Best Bad Idea We’ve Got](xhtml/13_Chapter_6_Cyber_Resil.xhtml)\n  8. [Part III: The Government’s Supporting Role](xhtml/14_Part_III_The_Governme.xhtml)\n     1. [Chapter 7: Nudges and Shoves: The Government in Corporate Cyberspace](xhtml/15_Chapter_7_Nudges_and_.xhtml)\n     2. [Chapter 8: Is It Really You?](xhtml/16_Chapter_8_Is_It_Reall.xhtml)\n     3. [Chapter 9: Fixing the People Problem](xhtml/17_Chapter_9_Fixing_the_.xhtml)\n     4. [Chapter 10: Power Grids and Power Plays](xhtml/18_Chapter_10_Power_Grid.xhtml)\n     5. [Chapter 11: Securing the Feds](xhtml/19_Chapter_11_Securing_t.xhtml)\n  9. [Part IV: Warriors, Diplomats, and Candidates](xhtml/20_Part_IV_Warriors_Dipl.xhtml)\n     1. [Chapter 12: The Military, Domains, and Dominance](xhtml/21_Chapter_12_The_Milita.xhtml)\n     2. [Chapter 13: A Schengen Accord for the Internet](xhtml/22_Chapter_13_A_Schengen.xhtml)\n     3. [Chapter 14: Democracy’s Shield: Defending Electoral Systems from Cyber Risk](xhtml/23_Chapter_14_Democracy_.xhtml)\n  10. [Part V: The (near) Future in Cyberspace](xhtml/24_Part_V_The_near_Futur.xhtml)\n     1. [Chapter 15: Real and Artificial Intelligence](xhtml/25_Chapter_15_Real_and_A.xhtml)\n     2. [Chapter 16: A Quantum of Solace for Security](xhtml/26_Chapter_16_A_Quantum_.xhtml)\n     3. [Chapter 17: 5g and Iot: Machines Too Dumb to Be Safe](xhtml/27_Chapter_17_5g_and_Iot.xhtml)\n  11. [Part VI: You and the Way Ahead](xhtml/28_Part_VI_You_and_the_W.xhtml)\n     1. [Chapter 18: Derisking Ourselves: Personal Cybersecurity](xhtml/29_Chapter_18_Derisking_.xhtml)\n     2. [Chapter 19: Everything Done but the Coding](xhtml/30_Chapter_19_Everything.xhtml)\n  12. [Glossary](xhtml/31_Glossary.xhtml)\n  13. [Acknowledgments and Disclosures](xhtml/32_Acknowledgments_and_D.xhtml)\n  14. [Notes](xhtml/33_Notes.xhtml)\n  15. [Index](xhtml/34_Index.xhtml)\n  16. [About the Authors](xhtml/35_About_the_Authors.xhtml)\n\n# Landmarks\n\n  1. [Cover](xhtml/01_Cover.xhtml)\n  2. [Cover](xhtml/01_Cover.xhtml)\n  3. [Title Page](xhtml/02_Title_Page.xhtml)\n  4. [Table of Contents](xhtml/05_Contents.xhtml#_idParaDest-4)\n  5. [Start](xhtml/06_Part_I_The_Twenty-Yea.xhtml)\n\n# Print Page List\n\n  1. [i](xhtml/02_Title_Page.xhtml#page_i)\n  2. [ii](xhtml/02_Title_Page.xhtml#page_ii)\n  3. [iii](xhtml/02_Title_Page.xhtml#page_iii)\n  4. [iv](xhtml/03_Copyright.xhtml#page_iv)\n  5. [v](xhtml/04_Dedication.xhtml#page_v)\n  6. [vi](xhtml/04_Dedication.xhtml#page_vi)\n  7. [vii](xhtml/05_Contents.xhtml#page_vii)\n  8. [viii](xhtml/05_Contents.xhtml#page_viii)\n  9. [1](xhtml/06_Part_I_The_Twenty-Yea.xhtml#page_1)\n  10. [2](xhtml/06_Part_I_The_Twenty-Yea.xhtml#page_2)\n  11. [3](xhtml/07_Chapter_1_The_Back_of.xhtml#page_3)\n  12. [4](xhtml/07_Chapter_1_The_Back_of.xhtml#page_4)\n  13. [5](xhtml/07_Chapter_1_The_Back_of.xhtml#page_5)\n  14. [6](xhtml/07_Chapter_1_The_Back_of.xhtml#page_6)\n  15. [7](xhtml/07_Chapter_1_The_Back_of.xhtml#page_7)\n  16. [8](xhtml/07_Chapter_1_The_Back_of.xhtml#page_8)\n  17. [9](xhtml/07_Chapter_1_The_Back_of.xhtml#page_9)\n  18. [10](xhtml/07_Chapter_1_The_Back_of.xhtml#page_10)\n  19. [11](xhtml/07_Chapter_1_The_Back_of.xhtml#page_11)\n  20. [12](xhtml/07_Chapter_1_The_Back_of.xhtml#page_12)\n  21. [13](xhtml/07_Chapter_1_The_Back_of.xhtml#page_13)\n  22. [14](xhtml/07_Chapter_1_The_Back_of.xhtml#page_14)\n  23. [15](xhtml/07_Chapter_1_The_Back_of.xhtml#page_15)\n  24. [16](xhtml/07_Chapter_1_The_Back_of.xhtml#page_16)\n  25. [17](xhtml/08_Chapter_2_Eternalblue.xhtml#page_17)\n  26. [18](xhtml/08_Chapter_2_Eternalblue.xhtml#page_18)\n  27. [19](xhtml/08_Chapter_2_Eternalblue.xhtml#page_19)\n  28. [20](xhtml/08_Chapter_2_Eternalblue.xhtml#page_20)\n  29. [21](xhtml/08_Chapter_2_Eternalblue.xhtml#page_21)\n  30. [22](xhtml/08_Chapter_2_Eternalblue.xhtml#page_22)\n  31. [23](xhtml/08_Chapter_2_Eternalblue.xhtml#page_23)\n  32. [24](xhtml/08_Chapter_2_Eternalblue.xhtml#page_24)\n  33. [25](xhtml/08_Chapter_2_Eternalblue.xhtml#page_25)\n  34. [26](xhtml/08_Chapter_2_Eternalblue.xhtml#page_26)\n  35. [27](xhtml/08_Chapter_2_Eternalblue.xhtml#page_27)\n  36. [28](xhtml/08_Chapter_2_Eternalblue.xhtml#page_28)\n  37. [29](xhtml/08_Chapter_2_Eternalblue.xhtml#page_29)\n  38. [30](xhtml/08_Chapter_2_Eternalblue.xhtml#page_30)\n  39. [31](xhtml/09_Part_II_The_Corporate.xhtml#page_31)\n  40. [32](xhtml/09_Part_II_The_Corporate.xhtml#page_32)\n  41. [33](xhtml/10_Chapter_3_Two_Kinds_o.xhtml#page_33)\n  42. [34](xhtml/10_Chapter_3_Two_Kinds_o.xhtml#page_34)\n  43. [35](xhtml/10_Chapter_3_Two_Kinds_o.xhtml#page_35)\n  44. [36](xhtml/10_Chapter_3_Two_Kinds_o.xhtml#page_36)\n  45. [37](xhtml/10_Chapter_3_Two_Kinds_o.xhtml#page_37)\n  46. [38](xhtml/10_Chapter_3_Two_Kinds_o.xhtml#page_38)\n  47. [39](xhtml/10_Chapter_3_Two_Kinds_o.xhtml#page_39)\n  48. [40](xhtml/10_Chapter_3_Two_Kinds_o.xhtml#page_40)\n  49. [41](xhtml/10_Chapter_3_Two_Kinds_o.xhtml#page_41)\n  50. [42](xhtml/10_Chapter_3_Two_Kinds_o.xhtml#page_42)\n  51. [43](xhtml/10_Chapter_3_Two_Kinds_o.xhtml#page_43)\n  52. [44](xhtml/10_Chapter_3_Two_Kinds_o.xhtml#page_44)\n  53. [45](xhtml/10_Chapter_3_Two_Kinds_o.xhtml#page_45)\n  54. [46](xhtml/10_Chapter_3_Two_Kinds_o.xhtml#page_46)\n  55. [47](xhtml/10_Chapter_3_Two_Kinds_o.xhtml#page_47)\n  56. [48](xhtml/10_Chapter_3_Two_Kinds_o.xhtml#page_48)\n  57. [49](xhtml/11_Chapter_4_The_Kill_Ch.xhtml#page_49)\n  58. [50](xhtml/11_Chapter_4_The_Kill_Ch.xhtml#page_50)\n  59. [51](xhtml/11_Chapter_4_The_Kill_Ch.xhtml#page_51)\n  60. [52](xhtml/11_Chapter_4_The_Kill_Ch.xhtml#page_52)\n  61. [53](xhtml/11_Chapter_4_The_Kill_Ch.xhtml#page_53)\n  62. [54](xhtml/11_Chapter_4_The_Kill_Ch.xhtml#page_54)\n  63. [55](xhtml/11_Chapter_4_The_Kill_Ch.xhtml#page_55)\n  64. [56](xhtml/11_Chapter_4_The_Kill_Ch.xhtml#page_56)\n  65. [57](xhtml/11_Chapter_4_The_Kill_Ch.xhtml#page_57)\n  66. [58](xhtml/11_Chapter_4_The_Kill_Ch.xhtml#page_58)\n  67. [59](xhtml/11_Chapter_4_The_Kill_Ch.xhtml#page_59)\n  68. [60](xhtml/11_Chapter_4_The_Kill_Ch.xhtml#page_60)\n  69. [61](xhtml/11_Chapter_4_The_Kill_Ch.xhtml#page_61)\n  70. [62](xhtml/11_Chapter_4_The_Kill_Ch.xhtml#page_62)\n  71. [63](xhtml/12_Chapter_5_The_Tech_St.xhtml#page_63)\n  72. [64](xhtml/12_Chapter_5_The_Tech_St.xhtml#page_64)\n  73. [65](xhtml/12_Chapter_5_The_Tech_St.xhtml#page_65)\n  74. [66](xhtml/12_Chapter_5_The_Tech_St.xhtml#page_66)\n  75. [67](xhtml/12_Chapter_5_The_Tech_St.xhtml#page_67)\n  76. [68](xhtml/12_Chapter_5_The_Tech_St.xhtml#page_68)\n  77. [69](xhtml/12_Chapter_5_The_Tech_St.xhtml#page_69)\n  78. [70](xhtml/12_Chapter_5_The_Tech_St.xhtml#page_70)\n  79. [71](xhtml/12_Chapter_5_The_Tech_St.xhtml#page_71)\n  80. [72](xhtml/12_Chapter_5_The_Tech_St.xhtml#page_72)\n  81. [73](xhtml/12_Chapter_5_The_Tech_St.xhtml#page_73)\n  82. [74](xhtml/12_Chapter_5_The_Tech_St.xhtml#page_74)\n  83. [75](xhtml/12_Chapter_5_The_Tech_St.xhtml#page_75)\n  84. [76](xhtml/12_Chapter_5_The_Tech_St.xhtml#page_76)\n  85. [77](xhtml/12_Chapter_5_The_Tech_St.xhtml#page_77)\n  86. [78](xhtml/12_Chapter_5_The_Tech_St.xhtml#page_78)\n  87. [79](xhtml/12_Chapter_5_The_Tech_St.xhtml#page_79)\n  88. [80](xhtml/12_Chapter_5_The_Tech_St.xhtml#page_80)\n  89. [81](xhtml/12_Chapter_5_The_Tech_St.xhtml#page_81)\n  90. [82](xhtml/12_Chapter_5_The_Tech_St.xhtml#page_82)\n  91. [83](xhtml/12_Chapter_5_The_Tech_St.xhtml#page_83)\n  92. [84](xhtml/12_Chapter_5_The_Tech_St.xhtml#page_84)\n  93. [85](xhtml/13_Chapter_6_Cyber_Resil.xhtml#page_85)\n  94. [86](xhtml/13_Chapter_6_Cyber_Resil.xhtml#page_86)\n  95. [87](xhtml/13_Chapter_6_Cyber_Resil.xhtml#page_87)\n  96. [88](xhtml/13_Chapter_6_Cyber_Resil.xhtml#page_88)\n  97. [89](xhtml/13_Chapter_6_Cyber_Resil.xhtml#page_89)\n  98. [90](xhtml/13_Chapter_6_Cyber_Resil.xhtml#page_90)\n  99. [91](xhtml/13_Chapter_6_Cyber_Resil.xhtml#page_91)\n  100. [92](xhtml/13_Chapter_6_Cyber_Resil.xhtml#page_92)\n  101. [93](xhtml/13_Chapter_6_Cyber_Resil.xhtml#page_93)\n  102. [94](xhtml/13_Chapter_6_Cyber_Resil.xhtml#page_94)\n  103. [95](xhtml/13_Chapter_6_Cyber_Resil.xhtml#page_95)\n  104. [96](xhtml/13_Chapter_6_Cyber_Resil.xhtml#page_96)\n  105. [97](xhtml/13_Chapter_6_Cyber_Resil.xhtml#page_97)\n  106. [98](xhtml/13_Chapter_6_Cyber_Resil.xhtml#page_98)\n  107. [99](xhtml/13_Chapter_6_Cyber_Resil.xhtml#page_99)\n  108. [100](xhtml/13_Chapter_6_Cyber_Resil.xhtml#page_100)\n  109. [101](xhtml/13_Chapter_6_Cyber_Resil.xhtml#page_101)\n  110. [102](xhtml/13_Chapter_6_Cyber_Resil.xhtml#page_102)\n  111. [103](xhtml/13_Chapter_6_Cyber_Resil.xhtml#page_103)\n  112. [104](xhtml/13_Chapter_6_Cyber_Resil.xhtml#page_104)\n  113. [105](xhtml/13_Chapter_6_Cyber_Resil.xhtml#page_105)\n  114. [106](xhtml/13_Chapter_6_Cyber_Resil.xhtml#page_106)\n  115. [107](xhtml/14_Part_III_The_Governme.xhtml#page_107)\n  116. [108](xhtml/14_Part_III_The_Governme.xhtml#page_108)\n  117. [109](xhtml/15_Chapter_7_Nudges_and_.xhtml#page_109)\n  118. [110](xhtml/15_Chapter_7_Nudges_and_.xhtml#page_110)\n  119. [111](xhtml/15_Chapter_7_Nudges_and_.xhtml#page_111)\n  120. [112](xhtml/15_Chapter_7_Nudges_and_.xhtml#page_112)\n  121. [113](xhtml/15_Chapter_7_Nudges_and_.xhtml#page_113)\n  122. [114](xhtml/15_Chapter_7_Nudges_and_.xhtml#page_114)\n  123. [115](xhtml/15_Chapter_7_Nudges_and_.xhtml#page_115)\n  124. [116](xhtml/15_Chapter_7_Nudges_and_.xhtml#page_116)\n  125. [117](xhtml/15_Chapter_7_Nudges_and_.xhtml#page_117)\n  126. [118](xhtml/15_Chapter_7_Nudges_and_.xhtml#page_118)\n  127. [119](xhtml/15_Chapter_7_Nudges_and_.xhtml#page_119)\n  128. [120](xhtml/15_Chapter_7_Nudges_and_.xhtml#page_120)\n  129. [121](xhtml/15_Chapter_7_Nudges_and_.xhtml#page_121)\n  130. [122](xhtml/15_Chapter_7_Nudges_and_.xhtml#page_122)\n  131. [123](xhtml/15_Chapter_7_Nudges_and_.xhtml#page_123)\n  132. [124](xhtml/15_Chapter_7_Nudges_and_.xhtml#page_124)\n  133. [125](xhtml/15_Chapter_7_Nudges_and_.xhtml#page_125)\n  134. [126](xhtml/15_Chapter_7_Nudges_and_.xhtml#page_126)\n  135. [127](xhtml/15_Chapter_7_Nudges_and_.xhtml#page_127)\n  136. [128](xhtml/15_Chapter_7_Nudges_and_.xhtml#page_128)\n  137. [129](xhtml/16_Chapter_8_Is_It_Reall.xhtml#page_129)\n  138. [130](xhtml/16_Chapter_8_Is_It_Reall.xhtml#page_130)\n  139. [131](xhtml/16_Chapter_8_Is_It_Reall.xhtml#page_131)\n  140. [132](xhtml/16_Chapter_8_Is_It_Reall.xhtml#page_132)\n  141. [133](xhtml/16_Chapter_8_Is_It_Reall.xhtml#page_133)\n  142. [134](xhtml/16_Chapter_8_Is_It_Reall.xhtml#page_134)\n  143. [135](xhtml/16_Chapter_8_Is_It_Reall.xhtml#page_135)\n  144. [136](xhtml/16_Chapter_8_Is_It_Reall.xhtml#page_136)\n  145. [137](xhtml/16_Chapter_8_Is_It_Reall.xhtml#page_137)\n  146. [138](xhtml/16_Chapter_8_Is_It_Reall.xhtml#page_138)\n  147. [139](xhtml/16_Chapter_8_Is_It_Reall.xhtml#page_139)\n  148. [140](xhtml/16_Chapter_8_Is_It_Reall.xhtml#page_140)\n  149. [141](xhtml/16_Chapter_8_Is_It_Reall.xhtml#page_141)\n  150. [142](xhtml/16_Chapter_8_Is_It_Reall.xhtml#page_142)\n  151. [143](xhtml/17_Chapter_9_Fixing_the_.xhtml#page_143)\n  152. [144](xhtml/17_Chapter_9_Fixing_the_.xhtml#page_144)\n  153. [145](xhtml/17_Chapter_9_Fixing_the_.xhtml#page_145)\n  154. [146](xhtml/17_Chapter_9_Fixing_the_.xhtml#page_146)\n  155. [147](xhtml/17_Chapter_9_Fixing_the_.xhtml#page_147)\n  156. [148](xhtml/17_Chapter_9_Fixing_the_.xhtml#page_148)\n  157. [149](xhtml/17_Chapter_9_Fixing_the_.xhtml#page_149)\n  158. [150](xhtml/17_Chapter_9_Fixing_the_.xhtml#page_150)\n  159. [151](xhtml/17_Chapter_9_Fixing_the_.xhtml#page_151)\n  160. [152](xhtml/17_Chapter_9_Fixing_the_.xhtml#page_152)\n  161. [153](xhtml/17_Chapter_9_Fixing_the_.xhtml#page_153)\n  162. [154](xhtml/17_Chapter_9_Fixing_the_.xhtml#page_154)\n  163. [155](xhtml/18_Chapter_10_Power_Grid.xhtml#page_155)\n  164. [156](xhtml/18_Chapter_10_Power_Grid.xhtml#page_156)\n  165. [157](xhtml/18_Chapter_10_Power_Grid.xhtml#page_157)\n  166. [158](xhtml/18_Chapter_10_Power_Grid.xhtml#page_158)\n  167. [159](xhtml/18_Chapter_10_Power_Grid.xhtml#page_159)\n  168. [160](xhtml/18_Chapter_10_Power_Grid.xhtml#page_160)\n  169. [161](xhtml/18_Chapter_10_Power_Grid.xhtml#page_161)\n  170. [162](xhtml/18_Chapter_10_Power_Grid.xhtml#page_162)\n  171. [163](xhtml/18_Chapter_10_Power_Grid.xhtml#page_163)\n  172. [164](xhtml/18_Chapter_10_Power_Grid.xhtml#page_164)\n  173. [165](xhtml/18_Chapter_10_Power_Grid.xhtml#page_165)\n  174. [166](xhtml/18_Chapter_10_Power_Grid.xhtml#page_166)\n  175. [167](xhtml/19_Chapter_11_Securing_t.xhtml#page_167)\n  176. [168](xhtml/19_Chapter_11_Securing_t.xhtml#page_168)\n  177. [169](xhtml/19_Chapter_11_Securing_t.xhtml#page_169)\n  178. [170](xhtml/19_Chapter_11_Securing_t.xhtml#page_170)\n  179. [171](xhtml/19_Chapter_11_Securing_t.xhtml#page_171)\n  180. [172](xhtml/19_Chapter_11_Securing_t.xhtml#page_172)\n  181. [173](xhtml/19_Chapter_11_Securing_t.xhtml#page_173)\n  182. [174](xhtml/19_Chapter_11_Securing_t.xhtml#page_174)\n  183. [175](xhtml/19_Chapter_11_Securing_t.xhtml#page_175)\n  184. [176](xhtml/19_Chapter_11_Securing_t.xhtml#page_176)\n  185. [177](xhtml/19_Chapter_11_Securing_t.xhtml#page_177)\n  186. [178](xhtml/19_Chapter_11_Securing_t.xhtml#page_178)\n  187. [179](xhtml/20_Part_IV_Warriors_Dipl.xhtml#page_179)\n  188. [180](xhtml/20_Part_IV_Warriors_Dipl.xhtml#page_180)\n  189. [181](xhtml/21_Chapter_12_The_Milita.xhtml#page_181)\n  190. [182](xhtml/21_Chapter_12_The_Milita.xhtml#page_182)\n  191. [183](xhtml/21_Chapter_12_The_Milita.xhtml#page_183)\n  192. [184](xhtml/21_Chapter_12_The_Milita.xhtml#page_184)\n  193. [185](xhtml/21_Chapter_12_The_Milita.xhtml#page_185)\n  194. [186](xhtml/21_Chapter_12_The_Milita.xhtml#page_186)\n  195. [187](xhtml/21_Chapter_12_The_Milita.xhtml#page_187)\n  196. [188](xhtml/21_Chapter_12_The_Milita.xhtml#page_188)\n  197. [189](xhtml/21_Chapter_12_The_Milita.xhtml#page_189)\n  198. [190](xhtml/21_Chapter_12_The_Milita.xhtml#page_190)\n  199. [191](xhtml/21_Chapter_12_The_Milita.xhtml#page_191)\n  200. [192](xhtml/21_Chapter_12_The_Milita.xhtml#page_192)\n  201. [193](xhtml/21_Chapter_12_The_Milita.xhtml#page_193)\n  202. [194](xhtml/21_Chapter_12_The_Milita.xhtml#page_194)\n  203. [195](xhtml/21_Chapter_12_The_Milita.xhtml#page_195)\n  204. [196](xhtml/21_Chapter_12_The_Milita.xhtml#page_196)\n  205. [197](xhtml/21_Chapter_12_The_Milita.xhtml#page_197)\n  206. [198](xhtml/21_Chapter_12_The_Milita.xhtml#page_198)\n  207. [199](xhtml/21_Chapter_12_The_Milita.xhtml#page_199)\n  208. [200](xhtml/21_Chapter_12_The_Milita.xhtml#page_200)\n  209. [201](xhtml/21_Chapter_12_The_Milita.xhtml#page_201)\n  210. [202](xhtml/21_Chapter_12_The_Milita.xhtml#page_202)\n  211. [203](xhtml/21_Chapter_12_The_Milita.xhtml#page_203)\n  212. [204](xhtml/21_Chapter_12_The_Milita.xhtml#page_204)\n  213. [205](xhtml/22_Chapter_13_A_Schengen.xhtml#page_205)\n  214. [206](xhtml/22_Chapter_13_A_Schengen.xhtml#page_206)\n  215. [207](xhtml/22_Chapter_13_A_Schengen.xhtml#page_207)\n  216. [208](xhtml/22_Chapter_13_A_Schengen.xhtml#page_208)\n  217. [209](xhtml/22_Chapter_13_A_Schengen.xhtml#page_209)\n  218. [210](xhtml/22_Chapter_13_A_Schengen.xhtml#page_210)\n  219. [211](xhtml/22_Chapter_13_A_Schengen.xhtml#page_211)\n  220. [212](xhtml/22_Chapter_13_A_Schengen.xhtml#page_212)\n  221. [213](xhtml/22_Chapter_13_A_Schengen.xhtml#page_213)\n  222. [214](xhtml/22_Chapter_13_A_Schengen.xhtml#page_214)\n  223. [215](xhtml/22_Chapter_13_A_Schengen.xhtml#page_215)\n  224. [216](xhtml/22_Chapter_13_A_Schengen.xhtml#page_216)\n  225. [217](xhtml/22_Chapter_13_A_Schengen.xhtml#page_217)\n  226. [218](xhtml/22_Chapter_13_A_Schengen.xhtml#page_218)\n  227. [219](xhtml/23_Chapter_14_Democracy_.xhtml#page_219)\n  228. [220](xhtml/23_Chapter_14_Democracy_.xhtml#page_220)\n  229. [221](xhtml/23_Chapter_14_Democracy_.xhtml#page_221)\n  230. [222](xhtml/23_Chapter_14_Democracy_.xhtml#page_222)\n  231. [223](xhtml/23_Chapter_14_Democracy_.xhtml#page_223)\n  232. [224](xhtml/23_Chapter_14_Democracy_.xhtml#page_224)\n  233. [225](xhtml/23_Chapter_14_Democracy_.xhtml#page_225)\n  234. [226](xhtml/23_Chapter_14_Democracy_.xhtml#page_226)\n  235. [227](xhtml/23_Chapter_14_Democracy_.xhtml#page_227)\n  236. [228](xhtml/23_Chapter_14_Democracy_.xhtml#page_228)\n  237. [229](xhtml/23_Chapter_14_Democracy_.xhtml#page_229)\n  238. [230](xhtml/23_Chapter_14_Democracy_.xhtml#page_230)\n  239. [231](xhtml/23_Chapter_14_Democracy_.xhtml#page_231)\n  240. [232](xhtml/23_Chapter_14_Democracy_.xhtml#page_232)\n  241. [233](xhtml/23_Chapter_14_Democracy_.xhtml#page_233)\n  242. [234](xhtml/23_Chapter_14_Democracy_.xhtml#page_234)\n  243. [235](xhtml/23_Chapter_14_Democracy_.xhtml#page_235)\n  244. [236](xhtml/23_Chapter_14_Democracy_.xhtml#page_236)\n  245. [237](xhtml/24_Part_V_The_near_Futur.xhtml#page_237)\n  246. [238](xhtml/24_Part_V_The_near_Futur.xhtml#page_238)\n  247. [239](xhtml/25_Chapter_15_Real_and_A.xhtml#page_239)\n  248. [240](xhtml/25_Chapter_15_Real_and_A.xhtml#page_240)\n  249. [241](xhtml/25_Chapter_15_Real_and_A.xhtml#page_241)\n  250. [242](xhtml/25_Chapter_15_Real_and_A.xhtml#page_242)\n  251. [243](xhtml/25_Chapter_15_Real_and_A.xhtml#page_243)\n  252. [244](xhtml/25_Chapter_15_Real_and_A.xhtml#page_244)\n  253. [245](xhtml/25_Chapter_15_Real_and_A.xhtml#page_245)\n  254. [246](xhtml/25_Chapter_15_Real_and_A.xhtml#page_246)\n  255. [247](xhtml/25_Chapter_15_Real_and_A.xhtml#page_247)\n  256. [248](xhtml/25_Chapter_15_Real_and_A.xhtml#page_248)\n  257. [249](xhtml/25_Chapter_15_Real_and_A.xhtml#page_249)\n  258. [250](xhtml/25_Chapter_15_Real_and_A.xhtml#page_250)\n  259. [251](xhtml/25_Chapter_15_Real_and_A.xhtml#page_251)\n  260. [252](xhtml/25_Chapter_15_Real_and_A.xhtml#page_252)\n  261. [253](xhtml/26_Chapter_16_A_Quantum_.xhtml#page_253)\n  262. [254](xhtml/26_Chapter_16_A_Quantum_.xhtml#page_254)\n  263. [255](xhtml/26_Chapter_16_A_Quantum_.xhtml#page_255)\n  264. [256](xhtml/26_Chapter_16_A_Quantum_.xhtml#page_256)\n  265. [257](xhtml/26_Chapter_16_A_Quantum_.xhtml#page_257)\n  266. [258](xhtml/26_Chapter_16_A_Quantum_.xhtml#page_258)\n  267. [259](xhtml/26_Chapter_16_A_Quantum_.xhtml#page_259)\n  268. [260](xhtml/26_Chapter_16_A_Quantum_.xhtml#page_260)\n  269. [261](xhtml/26_Chapter_16_A_Quantum_.xhtml#page_261)\n  270. [262](xhtml/26_Chapter_16_A_Quantum_.xhtml#page_262)\n  271. [263](xhtml/26_Chapter_16_A_Quantum_.xhtml#page_263)\n  272. [264](xhtml/26_Chapter_16_A_Quantum_.xhtml#page_264)\n  273. [265](xhtml/27_Chapter_17_5g_and_Iot.xhtml#page_265)\n  274. [266](xhtml/27_Chapter_17_5g_and_Iot.xhtml#page_266)\n  275. [267](xhtml/27_Chapter_17_5g_and_Iot.xhtml#page_267)\n  276. [268](xhtml/27_Chapter_17_5g_and_Iot.xhtml#page_268)\n  277. [269](xhtml/27_Chapter_17_5g_and_Iot.xhtml#page_269)\n  278. [270](xhtml/27_Chapter_17_5g_and_Iot.xhtml#page_270)\n  279. [271](xhtml/27_Chapter_17_5g_and_Iot.xhtml#page_271)\n  280. [272](xhtml/27_Chapter_17_5g_and_Iot.xhtml#page_272)\n  281. [273](xhtml/27_Chapter_17_5g_and_Iot.xhtml#page_273)\n  282. [274](xhtml/27_Chapter_17_5g_and_Iot.xhtml#page_274)\n  283. [275](xhtml/27_Chapter_17_5g_and_Iot.xhtml#page_275)\n  284. [276](xhtml/27_Chapter_17_5g_and_Iot.xhtml#page_276)\n  285. [277](xhtml/27_Chapter_17_5g_and_Iot.xhtml#page_277)\n  286. [278](xhtml/27_Chapter_17_5g_and_Iot.xhtml#page_278)\n  287. [279](xhtml/27_Chapter_17_5g_and_Iot.xhtml#page_279)\n  288. [280](xhtml/27_Chapter_17_5g_and_Iot.xhtml#page_280)\n  289. [281](xhtml/28_Part_VI_You_and_the_W.xhtml#page_281)\n  290. [282](xhtml/28_Part_VI_You_and_the_W.xhtml#page_282)\n  291. [283](xhtml/29_Chapter_18_Derisking_.xhtml#page_283)\n  292. [284](xhtml/29_Chapter_18_Derisking_.xhtml#page_284)\n  293. [285](xhtml/29_Chapter_18_Derisking_.xhtml#page_285)\n  294. [286](xhtml/29_Chapter_18_Derisking_.xhtml#page_286)\n  295. [287](xhtml/29_Chapter_18_Derisking_.xhtml#page_287)\n  296. [288](xhtml/29_Chapter_18_Derisking_.xhtml#page_288)\n  297. [289](xhtml/29_Chapter_18_Derisking_.xhtml#page_289)\n  298. [290](xhtml/29_Chapter_18_Derisking_.xhtml#page_290)\n  299. [291](xhtml/29_Chapter_18_Derisking_.xhtml#page_291)\n  300. [292](xhtml/29_Chapter_18_Derisking_.xhtml#page_292)\n  301. [293](xhtml/29_Chapter_18_Derisking_.xhtml#page_293)\n  302. [294](xhtml/29_Chapter_18_Derisking_.xhtml#page_294)\n  303. [295](xhtml/30_Chapter_19_Everything.xhtml#page_295)\n  304. [296](xhtml/30_Chapter_19_Everything.xhtml#page_296)\n  305. [297](xhtml/30_Chapter_19_Everything.xhtml#page_297)\n  306. [298](xhtml/30_Chapter_19_Everything.xhtml#page_298)\n  307. [299](xhtml/31_Glossary.xhtml#page_299)\n  308. [300](xhtml/31_Glossary.xhtml#page_300)\n  309. [301](xhtml/31_Glossary.xhtml#page_301)\n  310. [302](xhtml/31_Glossary.xhtml#page_302)\n  311. [303](xhtml/31_Glossary.xhtml#page_303)\n  312. [304](xhtml/31_Glossary.xhtml#page_304)\n  313. [305](xhtml/31_Glossary.xhtml#page_305)\n  314. [306](xhtml/31_Glossary.xhtml#page_306)\n  315. [307](xhtml/31_Glossary.xhtml#page_307)\n  316. [308](xhtml/31_Glossary.xhtml#page_308)\n  317. [309](xhtml/32_Acknowledgments_and_D.xhtml#page_309)\n  318. [310](xhtml/32_Acknowledgments_and_D.xhtml#page_310)\n  319. [311](xhtml/32_Acknowledgments_and_D.xhtml#page_311)\n  320. [312](xhtml/32_Acknowledgments_and_D.xhtml#page_312)\n  321. [313](xhtml/33_Notes.xhtml#page_313)\n  322. [314](xhtml/33_Notes.xhtml#page_314)\n  323. [315](xhtml/33_Notes.xhtml#page_315)\n  324. [316](xhtml/33_Notes.xhtml#page_316)\n  325. [317](xhtml/33_Notes.xhtml#page_317)\n  326. [318](xhtml/33_Notes.xhtml#page_318)\n  327. [319](xhtml/33_Notes.xhtml#page_319)\n  328. [320](xhtml/33_Notes.xhtml#page_320)\n  329. [321](xhtml/33_Notes.xhtml#page_321)\n  330. [322](xhtml/33_Notes.xhtml#page_322)\n  331. [323](xhtml/33_Notes.xhtml#page_323)\n  332. [324](xhtml/33_Notes.xhtml#page_324)\n  333. [325](xhtml/33_Notes.xhtml#page_325)\n  334. [326](xhtml/33_Notes.xhtml#page_326)\n  335. [327](xhtml/33_Notes.xhtml#page_327)\n  336. [328](xhtml/33_Notes.xhtml#page_328)\n  337. [329](xhtml/33_Notes.xhtml#page_329)\n  338. [330](xhtml/33_Notes.xhtml#page_330)\n  339. [331](xhtml/33_Notes.xhtml#page_331)\n  340. [332](xhtml/33_Notes.xhtml#page_332)\n  341. [333](xhtml/34_Index.xhtml#page_333)\n  342. [334](xhtml/34_Index.xhtml#page_334)\n  343. [335](xhtml/34_Index.xhtml#page_335)\n  344. [336](xhtml/34_Index.xhtml#page_336)\n  345. [337](xhtml/34_Index.xhtml#page_337)\n  346. [338](xhtml/34_Index.xhtml#page_338)\n  347. [339](xhtml/34_Index.xhtml#page_339)\n  348. [340](xhtml/34_Index.xhtml#page_340)\n  349. [341](xhtml/34_Index.xhtml#page_341)\n  350. [342](xhtml/34_Index.xhtml#page_342)\n  351. [343](xhtml/34_Index.xhtml#page_343)\n  352. [344](xhtml/34_Index.xhtml#page_344)\n\n",
    "book_id": "the_fifth_domain",
    "book_title": "The Fifth Domain",
    "book_author": "Richard A. Clarke",
    "topic_id": "cybersecurity_history",
    "topic_label": "history",
    "chunk_index": 2
  },
  {
    "chunk_full": "![](images/Stol_9780307819420_epub_cvi_r1.jpg)\n\n\n![](images/Stol_9780307819420_epub_tp_r1.jpg)\n\n\nPUBLISHED BY DOUBLEDAY\n\na division of Bantam Doubleday Dell Publishing Group, Inc.  \n666 Fifth Avenue, New York, New York 10103\n\nDOUBLEDAY and the portrayal of an anchor with a dolphin are trademarks of\nDoubleday, a division of Bantam Doubleday Dell Publishing Group, Inc.\n\nLibrary of Congress Cataloging-in-Publication Data\n\nStoll, Clifford.  \nThe cuckoo’s egg : tracking a spy through the maze of computer espionage / by\nClifford Stoll. — 1st ed.  \np. cm.  \n1\\. Hess, Marcus. 2. Stoll, Clifford. 3. Espionage, Soviet—  \nUnited States. 4. Espionage, Soviet—Germany (West)—  \nHannover. 5. Defense information, Classified—United States—Data  \nbases. 6. Computer crimes—United States. 7. Computer crimes—  \nGermany (West)—Hannover. I. Title.  \nUB271.R92H477 1989  \n364.1′68′0973—dc20 89-7808  \n364.1′68′0973—dc20\n\neISBN: 978-0-307-81942-0\n\nCopyright © 1989 by Clifford Stoll\n\nAll Rights Reserved\n\nv3.1\n\n![](images/Stol_9780307819420_epub_L02_r1.jpg)\n\n\n# Contents\n\n[Cover](Stol_9780307819420_epub_cvi_r1.htm)\n\n[Title Page](Stol_9780307819420_epub_tp_r1.htm)\n\n[Copyright](Stol_9780307819420_epub_cop_r1.htm)\n\n[Acknowledgments](Stol_9780307819420_epub_ack_r1.htm)\n\n[Chapter 1](Stol_9780307819420_epub_c01_r1.htm)\n\n[Chapter 2](Stol_9780307819420_epub_c02_r1.htm)\n\n[Chapter 3](Stol_9780307819420_epub_c03_r1.htm)\n\n[Chapter 4](Stol_9780307819420_epub_c04_r1.htm)\n\n[Chapter 5](Stol_9780307819420_epub_c05_r1.htm)\n\n[Chapter 6](Stol_9780307819420_epub_c06_r1.htm)\n\n[Chapter 7](Stol_9780307819420_epub_c07_r1.htm)\n\n[Chapter 8](Stol_9780307819420_epub_c08_r1.htm)\n\n[Chapter 9](Stol_9780307819420_epub_c09_r1.htm)\n\n[Chapter 10](Stol_9780307819420_epub_c10_r1.htm)\n\n[Chapter 11](Stol_9780307819420_epub_c11_r1.htm)\n\n[Chapter 12](Stol_9780307819420_epub_c12_r1.htm)\n\n[Chapter 13](Stol_9780307819420_epub_c13_r1.htm)\n\n[Chapter 14](Stol_9780307819420_epub_c14_r1.htm)\n\n[Chapter 15](Stol_9780307819420_epub_c15_r1.htm)\n\n[Chapter 16](Stol_9780307819420_epub_c16_r1.htm)\n\n[Chapter 17](Stol_9780307819420_epub_c17_r1.htm)\n\n[Chapter 18](Stol_9780307819420_epub_c18_r1.htm)\n\n[Chapter 19](Stol_9780307819420_epub_c19_r1.htm)\n\n[Chapter 20](Stol_9780307819420_epub_c20_r1.htm)\n\n[Chapter 21](Stol_9780307819420_epub_c21_r1.htm)\n\n[Chapter 22](Stol_9780307819420_epub_c22_r1.htm)\n\n[Chapter 23](Stol_9780307819420_epub_c23_r1.htm)\n\n[Chapter 24](Stol_9780307819420_epub_c24_r1.htm)\n\n[Chapter 25](Stol_9780307819420_epub_c25_r1.htm)\n\n[Chapter 26](Stol_9780307819420_epub_c26_r1.htm)\n\n[Chapter 27](Stol_9780307819420_epub_c27_r1.htm)\n\n[Chapter 28](Stol_9780307819420_epub_c28_r1.htm)\n\n[Chapter 29](Stol_9780307819420_epub_c29_r1.htm)\n\n[Chapter 30](Stol_9780307819420_epub_c30_r1.htm)\n\n[Chapter 31](Stol_9780307819420_epub_c31_r1.htm)\n\n[Chapter 32](Stol_9780307819420_epub_c32_r1.htm)\n\n[Chapter 33](Stol_9780307819420_epub_c33_r1.htm)\n\n[Chapter 34](Stol_9780307819420_epub_c34_r1.htm)\n\n[Chapter 35](Stol_9780307819420_epub_c35_r1.htm)\n\n[Chapter 36](Stol_9780307819420_epub_c36_r1.htm)\n\n[Chapter 37](Stol_9780307819420_epub_c37_r1.htm)\n\n[Chapter 38](Stol_9780307819420_epub_c38_r1.htm)\n\n[Chapter 39](Stol_9780307819420_epub_c39_r1.htm)\n\n[Chapter 40](Stol_9780307819420_epub_c40_r1.htm)\n\n[Chapter 41](Stol_9780307819420_epub_c41_r1.htm)\n\n[Chapter 42](Stol_9780307819420_epub_c42_r1.htm)\n\n[Chapter 43](Stol_9780307819420_epub_c43_r1.htm)\n\n[Chapter 44](Stol_9780307819420_epub_c44_r1.htm)\n\n[Chapter 45](Stol_9780307819420_epub_c45_r1.htm)\n\n[Chapter 46](Stol_9780307819420_epub_c46_r1.htm)\n\n[Chapter 47](Stol_9780307819420_epub_c47_r1.htm)\n\n[Chapter 48](Stol_9780307819420_epub_c48_r1.htm)\n\n[Chapter 49](Stol_9780307819420_epub_c49_r1.htm)\n\n[Chapter 50](Stol_9780307819420_epub_c50_r1.htm)\n\n[Chapter 51](Stol_9780307819420_epub_c51_r1.htm)\n\n[Chapter 52](Stol_9780307819420_epub_c52_r1.htm)\n\n[Chapter 53](Stol_9780307819420_epub_c53_r1.htm)\n\n[Chapter 54](Stol_9780307819420_epub_c54_r1.htm)\n\n[Chapter 55](Stol_9780307819420_epub_c55_r1.htm)\n\n[Chapter 56](Stol_9780307819420_epub_c56_r1.htm)\n\n[Epilogue](Stol_9780307819420_epub_epl_r1.htm)\n\n[Bibliography](Stol_9780307819420_epub_bib_r1.htm)\n\n[About the Author](Stol_9780307819420_epub_ata_r1.htm)\n\n\n# ![](images/Stol_9780307819420_epub_063_r1.jpg)\n\n![](images/Stol_9780307819420_epub_L04_r1.jpg) How do you spread the word when\na computer has a security hole? Some say nothing, fearing that telling people\nhow to mix explosives will encourage them to make bombs. In this book I’ve\nexplicitly described some of these security problems, realizing that people in\nblack hats are already aware of them.\n\nI’ve tried to reconstruct this incident as I experienced it. My main sources\nare my logbooks and diaries, cross-checked by contacting others involved in\nthis affair and comparing reports from others. A few people appear under\naliases, several phone numbers are changed, and some conversations have been\nrecounted from memory, but there’s no fictionalizing.\n\nFor supporting me throughout the investigation and writing, thanks to my\nfriends, colleagues, and family. Regina Wiggen has been my editorial mainstay;\nthanks also to Jochen Sperber, Jon Rochlis, Dean Chacon, Donald Alvarez,\nLaurie McPherson, Rich Muller, Gene Spafford, Andy Goldstein, and Guy\nConsolmagno.\n\nI posted a notice to several computer networks, asking for title suggestions.\nSeveral hundred people from around the world replied with zany ideas. My\nthanks to Karen Anderson in San Francisco and Nigel Roberts in Munich for the\ntitle and subtitle.\n\nDoubleday’s editors, David Gernert and Scott Ferguson, have helped me\nthroughout. To them, as well as my agent, John Brockman, thanks for your\ncontinued encouragement and wise advice.\n\nTo each of these people, I’m indebted; I owe most of them boxes of cookies as\nwell.\n\nLawrence Berkeley Laboratory supported me throughout this quest; the people of\nSmithsonian Astrophysical Observatory—especially Joe Schwarz and Steve\nMurray—have been most gracious and supportive while I’ve been writing this\nbook. My deep thanks go to my friends at both institutes, and my hopes that\nI’ll now be able to return to astronomy.\n\nI was ten years old when Ernst Both of the Buffalo Museum of Science invited\nme to look through a telescope, opening up a universe of astronomy. I wonder\nif I’ll ever be able to thank him properly.\n\nI needn’t thank my sweetheart and wife, Martha Matthews. She’s been as much a\npart of writing this book as she was in the story. I love her with all my\nheart.\n\n—Cliff Stoll-Matthews  \n[cliff@cfa.harvard.edu](mailto:cliff@cfa.harvard.edu)\n\n\n![](images/Stol_9780307819420_epub_001_r1.jpg) Me, a wizard? Until a week ago,\nI was an astronomer, contentedly designing telescope optics. Looking back on\nit, I’d lived in an academic dreamland. All these years, never planning for\nthe future, right up to the day my grant money ran out.\n\nLucky for me that my laboratory recycled used astronomers. Instead of standing\nin the unemployment line, I found myself transferred from the Keck Observatory\nat the Lawrence Berkeley Lab, down to the computer center in the basement of\nthe same building.\n\nWell, hell, I could fake enough computing to impress astronomers, and maybe\npick it up fast enough that my co-workers wouldn’t catch on. Still, a computer\nwizard? Not me—I’m an astronomer.\n\nNow what? As I apathetically stared at my computer terminal, I still thought\nof planetary orbits and astrophysics. As new kid on the block, I had my choice\nof a cubicle with a window facing the Golden Gate Bridge, or an unventilated\noffice with a wall of bookshelves. Swallowing my claustrophobia, I picked the\noffice, hoping that nobody would notice when I slept under the desk. On either\nside were offices of two systems people, Wayne Graves and Dave Cleveland, the\nold hands of the system. I soon got to know my neighbors through their\nbickering.\n\nViewing everyone as incompetent or lazy, Wayne was crossthreaded with the rest\nof the staff. Yet he knew the system thoroughly, from the disk driver software\nup to the microwave antennas. Wayne was weaned on Digital Equipment company’s\nVax computers and would tolerate nothing less: not IBM, not Unix, not\nMacintoshes.\n\nDave Cleveland, our serene Unix buddha, patiently listened to Wayne’s running\nstream of computer comparisons. A rare meeting didn’t have Wayne’s pitch,\n“Vaxes are the choice of scientists everywhere and helps build strong programs\ntwelve ways.” Dave retorted, “Look, you keep your Vax addicts happy and I’ll\nhandle the rest of the world.” Dave never gave him the satisfaction of getting\nriled, and Wayne’s complaints eventually trailed off to a mutter.\n\nGreat. First day on the job, sandwiched between two characters who were\nalready ruining my daydreams with their periodic disputes.\n\nAt least nobody could complain about my appearance. I wore the standard\nBerkeley corporate uniform: grubby shirt, faded jeans, long hair, and cheap\nsneakers. Managers occasionally wore ties, but productivity went down on the\ndays they did.\n\nTogether, Wayne, Dave, and I were to run the computers as a lab-wide utility.\nWe managed a dozen mainframe computers—giant workhorses for solving physics\nproblems, together worth around six million dollars. The scientists using the\ncomputers were supposed to see a simple, powerful computing system, as\nreliable as the electric company. This meant keeping the machines running full\ntime, around the clock. And just like the electric company, we charged for\nevery cycle of computing that was used.\n\nOf four thousand laboratory employees, perhaps a quarter used the main\ncomputers. Each of these one thousand accounts were tallied daily, and ledgers\nkept inside the computer. With an hour of computing costing three hundred\ndollars, our bookkeeping had to be accurate, so we kept track of every page\nprinted, every block of disk space, and every minute of processor time. A\nseparate computer gathered these statistics and sent monthly bills to\nlaboratory departments.\n\nAnd so it happened that on my second day at work, Dave wandered into my\noffice, mumbling about a hiccup in the Unix accounting system. Someone must\nhave used a few seconds of computing time without paying for it. The\ncomputer’s books didn’t quite balance; last month’s bills of $2,387 showed a\n75-cent shortfall.\n\nNow, an error of a few thousand dollars is obvious and isn’t hard to find. But\nerrors in the pennies column arise from deeply buried problems, so finding\nthese bugs is a natural test for a budding software wizard. Dave said that I\nought to think about it.\n\n“First-degree robbery, huh?” I responded.\n\n“Figure it out, Cliff, and you’ll amaze everyone,” Dave said.\n\nWell, this seemed like a fun toy, so I dug into the accounting program. I\ndiscovered our accounting software to be a patchwork of programs written by\nlong-departed summer students. Somehow, the hodgepodge worked well enough to\nbe ignored. Looking at the mixture of programs, I found the software in\nAssembler, Fortran, and Cobol, the most ancient of computer languages. Might\nas well have been classical Greek, Latin, and Sanskrit.\n\nAs with most home-brew software, nobody had bothered to document our\naccounting system. Only a fool would poke around such a labyrinth without a\nmap.\n\nStill, here was a plaything for the afternoon and a chance to explore the\nsystem. Dave showed me how the system recorded each time someone connected to\nthe computer, logging the user’s name, and terminal. It timestamped each\nconnection, recording which tasks the user executed, how many seconds of\nprocessor time he used, and when he disconnected.\n\nDave explained that we had two independent accounting systems. The ordinary\nUnix accounting software just stored the timestamped records into a file. But\nto satisfy some bureaucrat, Dave had built a second accounting system which\nkept more detailed records of who was using the computer.\n\nOver the years, a succession of bored summer students had written programs to\nanalyze all this accounting information. One program collected the data and\nstashed it into a file. A second program read that file and figured how much\nto charge for that session. Yet a third program collected all these charges\nand printed out bills to be mailed to each department. The last program added\nup all user charges and compared that total to the result from the computer’s\ninternal accounting program. Two accounting files, kept in parallel by\ndifferent programs, ought to give the same answer.\n\nFor a year, these programs had run without a glitch, but weren’t quite perfect\nthis week. The obvious suspect was round-off error. Probably each accounting\nentry was correct, but when added together, tenths of a penny differences\nbuilt up until an error of 75 cents accumulated. I ought to be able to prove\nthis either by analyzing how the programs worked, or by testing them with\ndifferent data.\n\nRather than trying to understand the code for each program, I wrote a short\nprogram to verify the data files. In a few minutes, I had checked the first\nprogram: indeed, it properly collected the accounting data. No problem with\nthe first.\n\nThe second program took me longer to figure out. In an hour I had slapped\ntogether enough makeshift code to prove that it actually worked. It just added\nup time intervals, then multiplied by how much we charge for computer time. So\nthe 75-cent error didn’t come from this program.\n\nAnd the third program worked perfectly. It looked at a list of authorized\nusers, found their laboratory accounts, and then printed out a bill. Round-off\nerror? No, all of the programs kept track of money down to the hundredths of a\npenny. Strange. Where’s this 75-cent error coming from?\n\nWell, I’d invested a couple hours in trying to understand a trivial problem. I\ngot stubborn: dammit, I’d stay there till midnight, if I had to.\n\nSeveral test programs later, I began actually to have confidence in the\nmishmash of locally built accounting programs. No question that the accounts\ndidn’t balance, but the programs, though not bulletproof, weren’t dropping\npennies. By now, I’d found the lists of authorized users, and figured out how\nthe programs used the data structures to bill different departments. Around 7\nP.M. my eye caught one user, Hunter. This guy didn’t have a valid billing\naddress.\n\nHa! Hunter used 75 cents of time in the past month, but nobody had paid for\nhim.\n\nHere’s the source of our imbalance. Someone had screwed up when adding a user\nto our system. A trivial problem caused by a trivial error.\n\nTime to celebrate. While writing this first small triumph into the beginning\npages of my notebook, Martha, my sweetheart, stopped by and we celebrated with\nlate-night cappuccinos at Berkeley’s Cafe Roma.\n\nA real wizard would have solved the problem in a few minutes. For me, it was\nunknown territory, and finding my way around hadn’t been easy. As a\nconsolation, I’d learned the accounting system and practiced a couple obsolete\nlanguages. Next day, I sent an electronic mail message to Dave, preening my\nfeathers by pointing out the problem to him.\n\nAround noon, Dave stopped by to drop off a pile of manuals, and casually\nmentioned that he had never added a user named Hunter—it must have been one of\nthe other system managers. Wayne’s curt response: “It wasn’t me. RTFM.” Most\nof his sentences ended with acronyms, this one meaning, “Read the fucking\nmanual.”\n\nBut I’d read the manuals. Operators weren’t supposed to add a new user without\nan account. At other computer centers, you just log into a privileged account\nand tell the system to add a new user. Since we also had to make several\nbookkeeping entries, we couldn’t run such a vanilla system. Ours was complex\nenough that we had special programs which automatically did the paperwork and\nthe systems juggling.\n\nChecking around, I found that everyone agreed the automatic system was so\nsuperior that nobody would have manually added a new user. And the automatic\nsystem wouldn’t make this mistake.\n\nWell, I couldn’t figure out who had made this goof. Nobody knew Hunter, and\nthere wasn’t an account set for him. So I erased the name from the system—when\nhe complained, we could set him up properly.\n\nA day later, an obscure computer named Dockmaster sent us an electronic mail\nmessage. Its system manager claimed that someone from our laboratory had tried\nto break into his computer over the weekend.\n\nDockmaster’s return address might have been anywhere, but signs pointed to\nMaryland. The e-mail had passed through a dozen other computers, and each had\nleft a postmark.\n\nDave answered the message with a noncommittal “We’ll look into it.” Uh, sure.\nWe’d look when all our other problems disappeared.\n\nOur laboratory’s computers connect to thousands of other systems over a dozen\nnetworks. Any of our scientists can log into our computer, and then connect to\na distant computer. Once connected, they can log into the distant computer by\nentering an account name and password. In principle, the only thing protecting\nthe networked computer is the password, since account names are easy to figure\nout. (How do you find account names? Just use a phone book—most people use\ntheir names on computers.)\n\nDockmaster’s electronic mail message was a curiosity, and Dave passed it to\nWayne, attaching a question, “Who’s Dockmaster?” Wayne forwarded it to me with\nhis guess—“Probably some bank.”\n\nEventually, Wayne bounced the message to me. I guessed Dockmaster was some\nNavy shipyard. It wasn’t important, but it seemed worth spending a few minutes\nlooking into.\n\nThe message gave the date and time when someone on our Unix computer tried to\nlog into Dockmaster’s computer. Since I’d just mucked around the accounting\nsystem, scrabbled around the files, looking for records from Saturday morning\nat 8:46. Again, the two accounting systems disagreed. The stock Unix\naccounting file showed a user, Sventek, logging in at 8:25, doing nothing for\nhalf an hour, and then disconnecting. No timestamped activity in between. Our\nhome-brew software also recorded Sventek’s activity, but it showed him using\nthe networks from 8:31 until 9:01 A.M.\n\nJeez. Another accounting problem. The time stamps didn’t agree. One showed\nactivity when the other account said everything was dormant.\n\nOther things seemed more pressing, so I dropped the problem. After wasting an\nafternoon chasing after some operator’s mistake, I wasn’t about to touch the\naccounting system again.\n\nOver lunch with Dave, I mentioned that Sventek was the only one connected when\nDockmaster reported the break-in. He stared and said, ‘Joe Sventek? He’s in\nCambridge. Cambridge, England. What’s he doing back?’ Turned out that Joe\nSventek had been the laboratory’s Unix guru, a software wizard who built a\ndozen major programs over the past decade. Joe had left for England a year\nago, leaving behind a glowing reputation throughout the California computer\ncommunity.\n\nDave couldn’t believe Joe was back in town, since none of Joe’s other friends\nhad heard from him. ‘He must have entered our computer from some network,’\nDave said.\n\n‘So you think Joe’s responsible for this problem?’ I asked Dave.\n\n“No way,” Dave replied. “Joe’s a hacker of the old school. A smart, quick,\ncapable programmer. Not one of those punks that have tarnished the word\n‘hacker.’ In any case, Sventek wouldn’t try to break into some Maryland\ncomputer. And if he did try, he’d succeed, without leaving any trace.”\n\nCurious: Joe Sventek’s been in England a year, yet he shows up early Saturday\nmorning, tries to break into a Maryland computer, disconnects, and leaves\nbehind an unbalanced accounting system. In the hallway I mention this to\nWayne, who’s heard that Joe’s on vacation in England; he’s hiding out in the\nbackwoods, far away from any computers. “Forget that message from Dockmaster.\nSventek’s due to visit Berkeley RSN and he’ll clear it up.”\n\nRSN? Real Soon Now. Wayne’s way of saying, “I’m not sure when.”\n\nMy worry wasn’t Sventek. It was the unbalanced accounts. Why were the two\naccounting systems keeping different times? And why was some activity logged\nin one file without showing up in the other?\n\nBack to the accounting system for an afternoon. I found that the five minute\ntime difference between the time stamps came from our various computers’\nclocks drifting over the months. One of our computer’s clocks lost a few\nseconds every day.\n\nBut all of Sventek’s activities should have appeared in both tallies. Was this\nrelated to last week’s accounting problem? Had I screwed things up when I\npoked around last week? Or was there some other explanation?\n\n\n![](images/Stol_9780307819420_epub_002_r1.jpg) That afternoon, I sat through\nan impressively boring lecture on the structure of galaxies. The learned\nprofessor not only spoke in a monotone, but filled the chalkboard with a\nsnake’s nest of mathematical equations.\n\nTrying to stay awake, I tossed around the problems I’d bumped into. Someone\nscrewed up when adding a new account. A week later, Sventek logs in and tries\nto break into some computer in Maryland. The accounting record for that event\nseems garbled. Sventek’s unavailable. Something’s amiss. It’s almost as if\nsomeone’s avoiding the accounting program.\n\nWhat would it take, I wondered, to use our computers for free? Could someone\nhave found a way around our accounting system?\n\nBig computers have two types of software: user programs and systems software.\nPrograms that you write or install yourself are user programs—for example, my\nastronomy routines which analyze a planet’s atmosphere.\n\nAlone, user programs can’t do much. They don’t talk directly to the computer;\nrather, they call upon the operating system to manipulate the computer. When\nmy astronomy program wants to write something, it doesn’t just slap a word on\nmy screen. Instead, it passes the word to the operating system, which, in\nturn, tells the hardware to write a word.\n\nThe operating system, along with the editors, software libraries, and language\ninterpreters, make up the systems software. You don’t write these\nprograms—they come with the computer. Once they’re set up, nobody should\ntamper with them.\n\nThe accounting program is systems software. To modify or bypass it, you have\nto either be system manager, or somehow have acquired a privileged position\nwithin the operating system.\n\nOK, how do you become privileged? The obvious way is to log onto our computer\nwith the system manager’s password. We hadn’t changed our password in months,\nbut nobody would have leaked it. And an outsider would never guess our secret\npassword, “wyvern”—how many people would think of a mythological winged dragon\nwhen guessing our password?\n\nBut even if you became system manager, you wouldn’t fool with the accounting\nsoftware. It’s too obscure, too poorly documented. Anyway, I’d seen that it\nworked.\n\nWait—our home-brew software worked properly. Someone had added a new account\nwithout using it. Perhaps they didn’t know about it. If someone had come in\nfrom the cold, they’d be unaware of our local wrinkles. Our system managers\nand operators knew this. Joe Sventek, even in England, surely would know.\n\nBut what about someone from the outside—a hacker?\n\nThe word hacker has two very different meanings. The people I knew who called\nthemselves hackers were software wizards who managed to creatively program\ntheir way out of tight corners. They knew all the nooks and crannies of the\noperating system. Not dull software engineers who put in forty hours a week,\nbut creative programmers who can’t leave the computer until the machine’s\nsatisfied. A hacker identifies with the computer, knowing it like a friend.\n\nAstronomers saw me that way. “Cliff, he’s not much of an astronomer, but what\na computer hacker!” (The computer folks, of course, had a different view:\n“Cliff’s not much of a programmer, but what an astronomer!” At best, graduate\nschool had taught me to keep both sides fooled.)\n\nBut in common usage, a hacker is someone who breaks into computers.* In 1982,\nafter a group of students used terminals, modems, and long distance telephone\nlines to break into computers in Los Alamos and the Columbia Medical Center,\nthe computing people suddenly became aware of the vulnerability of our\nnetworked systems.\n\nEvery few months, I’d hear a rumor about someone else’s system being invaded;\nusually this was at universities, and it was often blamed on students or\nteenagers. “Brilliant high school student cracks into top security computer\ncenter.” Usually it was harmless and written off as some hacker’s prank.\n\nCould the movie _War Games_ actually happen—might some teenage hacker break\ninto a Pentagon computer and start a war?\n\nI doubted it. Sure, it’s easy to muck around computers at universities where\nno security was needed. After all, colleges seldom even lock the doors to\ntheir buildings. I imagined that military computers were a whole different\nstory—they’d be as tightly secured as a military base. And even if you did get\ninto a military computer, it’s absurd to think you could start a war. Those\nthings just aren’t controlled by computers, I thought.\n\nOur computers at Lawrence Berkeley Laboratory weren’t especially secure, but\nwe were required to keep outsiders away from them and make an effort to\nprevent their misuse. We weren’t worried about someone hurting our computers,\nwe just wanted to keep our funding agency, the Department of Energy, off our\nbacks. If they wanted our computers painted green, then we’d order\npaintbrushes.\n\nBut to make visiting scientists happy, we had several computer accounts for\nguests. With an account name of “guest” and a password of “guest,” anyone\ncould use the system to solve their problems, as long as they didn’t use more\nthan a few dollars of computing time. A hacker would have an easy time\nbreaking into that account—it was wide open. This would hardly be much of a\nbreak-in, with time limited to one minute. But from that account, you could\nlook around the system, read any public files, and see who was logged in. We\nfelt the minor security risk was well worth the convenience.\n\nMulling over the situation, I kept doubting that a hacker was fooling around\nin my system. Nobody’s interested in particle physics. Hell, most of our\nscientists would be delighted if anyone would read their papers. There’s\nnothing special here to tempt a hacker—no snazzy supercomputer, no sexy trade\nsecrets, no classified data. Indeed, the best part of working at Lawrence\nBerkeley Labs was the open, academic atmosphere.\n\nFifty miles away, Lawrence Livermore Labs did classified work, developing\nnuclear bombs and Star Wars projects. Now, that might be a target for some\nhacker to break into. But with no connections to the outside, Livermore’s\ncomputers can’t be dialed into. Their classified data’s protected by brute\nforce: isolation.\n\nIf someone did break into our system, what could they accomplish? They could\nread any public files. Most of our scientists set their data this way, so\ntheir collaborators can read it. Some of the systems software was public as\nwell.\n\nThough we call this data public, an outsider shouldn’t wander through it. Some\nof it’s proprietary or copyrighted, like our software libraries and word\nprocessing programs. Other databases aren’t for everyone’s consumption—lists\nof our employees’ addresses and incomplete reports on work in progress. Still,\nthese hardly qualify as sensitive material, and it’s a long way from\nclassified.\n\nNo, I wasn’t worried about someone entering our computer as a guest and\nwalking off with somebody’s telephone number. My real concern centered on a\nmuch bigger problem: could a stranger become a super-user?\n\nTo satisfy a hundred users at once, the computer’s operating system splits the\nhardware resources much as an apartment house splits a building into many\napartments. Each apartment works independently of the others. While one\nresident may be watching TV, another talks on the phone, and a third washes\ndishes. Utilities—electricity, phone service, and water—are supplied by the\napartment complex. Every resident complains about slow service and the\nexorbitant rents.\n\nWithin the computer, one user might be solving a math problem, another sending\nelectronic mail to Toronto, yet a third writing a letter. The computer\nutilities are supplied by the systems software and operating system; each user\ngrumbles about the unreliable software, obscure documentation, and the\nexorbitant costs.\n\nPrivacy within the apartment house is regulated by locks and keys. One\nresident can’t enter another’s apartment without a key, and (if the walls are\nsturdy), one resident’s activity won’t bother another. Within the computer,\nit’s the operating system that ensures user privacy. You can’t get into\nsomeone’s area without the right password, and (if the operating system is\nfair about handing out resources), one user’s programs won’t interfere with\nanother’s.\n\nBut apartment walls are never sturdy enough, and my neighbor’s parties thunder\ninto my bedroom. And my computer still slows down when there’s more than one\nhundred people using it at one time. So our apartment houses need\nsuperintendents, and our computers need system managers, or super-users.\n\nWith a passkey, the apartment house superintendent can enter any room. From a\nprivileged account, the system manager can read or modify any program or data\non the computer. Privileged users bypass the operating system protections and\nhave the full run of the computer. They need this power to maintain the\nsystems software (“Fix the editor!”), to tune the operating system’s\nperformance (“Things are too slow today!”), and to let people use the computer\n(“Hey, give Barbara an account.”)\n\nPrivileged users learn to tread lightly. They can’t do much damage if they’re\nonly privileged to read files. But the super-user’s license lets you change\nany part of the system—there’s no protections against the super-user’s\nmistakes.\n\nTruly, the super-user is all-powerful: he controls the horizontal, he controls\nthe vertical. When daylight savings time comes around, she resets the system\nclock. A new disk drive? He’s the only one who can graft the necessary\nsoftware into the system. Different operating systems have various names for\nprivileged accounts—super-user, root, system manager—but these accounts must\nalways be jealously guarded against outsiders.\n\nWhat if an outside hacker became privileged on our system? For one thing, he\ncould add new user accounts.\n\nA hacker with super-user privileges would hold the computer hostage. With the\nmaster key to our system, he could shut it down whenever he wishes, and could\nmake the system as unreliable as he wishes. He could read, write, or modify\nany information in the computer. No user’s file would be protected from him\nwhen he operates from this privileged high ground. The system files, too,\nwould be at his disposal—he could read electronic mail before it’s delivered.\n\nHe could even modify the accounting files to erase his own tracks.\n\nThe lecturer on galactic structure droned on about gravitational waves. I was\nsuddenly awake, aware of what was happening in our computer. I waited around\nfor the question period, asked one token question, then grabbed my bike and\nstarted up the hill to Lawrence Berkeley Labs.\n\nA super-user hacker. Someone breaks into our system, finds the master keys,\ngrants himself privileges, and becomes a super-user hacker. Who? How? From\nwhere? And, mostly, why?\n\n* What word describes someone who breaks into computers? Old style software wizards are proud to be called hackers, and resent the scofflaws who have appropriated the word. On the networks, wizards refer to these hoodlums of our electronic age as “crackers” or “cyberpunks.” In the Netherlands, there’s the term “computervredebreuk”—literally, computer peace disturbance. Me? The idea of a vandal breaking into my computer makes me think of words like “varmint,” “reprobate,” and “swine.”\n\n\n![](images/Stol_9780307819420_epub_003_r1.jpg) It’s only a quarter mile from\nthe University of California to Lawrence Berkeley Labs, but Cyclotron Road is\nsteep enough to make it a fifteen-minute bike ride. The old ten-speed didn’t\nquite have a low enough gear, so my knees felt the last few hundred feet. Our\ncomputer center’s nestled between three particle accelerators: the 184-inch\ncyclotron, where Ernest Lawrence first purified a milligram of fissionable\nuranium; the Bevatron, where the anti-proton was discovered; and the Hilac,\nthe birthplace of a half-dozen new elements.\n\nToday, these accelerators are obsolete—their mega-electron volt energies long\nsurpassed by giga-electron volt particle colliders. They’re no longer winning\nNobel prizes, but physicists and graduate students still wait six months for\ntime on an accelerator beamline. After all, our accelerators are fine for\nstudying exotic nuclear particles and searching out new forms of matter, with\nesoteric names like quark-gluon plasmas or pion condensates. And when the\nphysicists aren’t using them, the beams are used for biomedical research,\nincluding cancer therapy.\n\nBack in the heyday of World War II’s Manhattan project, Lawrence’s cyclotron\nwas the only way to measure the cross sections of nuclear reactions and\nuranium atoms. Naturally, the lab was shrouded in secrecy; it served as the\nmodel for building atomic bomb plants.\n\nDuring the 1950s, Lawrence Berkeley Laboratory’s research remained classified,\nuntil Edward Teller formed the Lawrence Livermore Laboratory an hour’s drive\naway. All the classified work went to Livermore, while the unclassified\nscience remained in Berkeley.\n\nPerhaps to spread confusion, both laboratories are named after California’s\nfirst Nobel Laureate, both are centers for atomic physics, and both are funded\nby the Atomic Energy Commission’s offspring, the Department of Energy. That’s\nabout the end of the similarity.\n\nI needed no security clearance to work in the Berkeley Lab—there’s no\nclassified research, not a military contract in sight. Livermore, on the other\nhand, is a center for designing nuclear bombs and Star Wars laser beams.\nHardly the place for a long-haired ex-hippie. While my Berkeley Lab survived\non meager scientific grants and unreliable university funding, Livermore\nconstantly expanded. Ever since Teller designed the H-bomb, Livermore’s\nclassified research has never been short of funds.\n\nBerkeley no longer has huge military contracts, yet openness has its rewards.\nAs pure scientists, we’re encouraged to research any curious phenomena, and\ncan always publish our results. Our accelerators might be peashooters compared\nto the behemoths at CERN in Switzerland, or Fermilab in Illinois; still, they\ngenerate huge amounts of data, and we run some respectable computers to\nanalyze it. In fact, it’s a source of local pride to find physicists recording\ntheir data at other accelerators, then visiting LBL to analyze their results\non our computers.\n\nIn raw number-crunching power, Livermore’s computers dwarfed ours. They\nregularly bought the biggest, fastest, and most expensive Crays. They need ’em\nto figure out what happens in the first few nanoseconds of a thermonuclear\nexplosion.\n\nBecause of their classified research, most of Livermore’s computers are\nisolated. Of course, they have some unclassified systems too, doing ordinary\nscience. But for their secret work—well, it’s not for ordinary mortal eyes.\nThese classified computers have no connections to the outside world.\n\nIt’s just as impossible to import data into Livermore from the outside.\nSomeone designing nuclear bomb triggers using Livermore’s classified computers\nhas to visit the lab in person, bringing his data in on magnetic tape. He\ncan’t use the dozens of networks crossing the country, and can’t log in from\nhome, to see how his program is running. Since their computers are often the\nfirst ones off the production line, Livermore usually has to write their own\noperating systems, forming a bizarre software ecology, unseen outside of their\nlaboratory. Such are the costs of living in a classified world.\n\nWhile we didn’t have the number-crunching power of Livermore, our computers\nwere no slouches. Our Vax computers were speedy, easy to use, and popular\namong physicists. We didn’t have to invent our own operating systems, since we\nbought Digital’s VMS operating system, and grabbed Unix from campus. As an\nopen lab, our computers could be networked anywhere, and we supported\nscientists from around the world. When problems developed in the middle of the\nnight, I just dialed the LBL computer from my home—no need to bicycle into\nwork when a phone call might solve it.\n\nBut there I was, bicycling up to work, wondering if some hacker was in our\nsystem. This just might explain some of my accounting problems. If some\noutsider had picked the locks on our Unix operating system and acquired super-\nuser privileges, he’d have the power to selectively erase the accounting\nrecords. And, worse, he could use our network connections to attack other\ncomputers.\n\nI ducked my bike into a corner and jogged over to the cubicle maze. By now it\nwas well past five, and the ordinary folks were at home. How could I tell if\nsomeone was hacking inside our system? Well, we could just send an electronic\nmail message to the suspicious account, saying something like, “Hey, are you\nthe real Joe Sventek?” Or we could disable Joe’s account, and see if our\ntroubles ended.\n\nMy thoughts about the hacker were sidetracked when I found a note in my\noffice: the astronomy group needed to know how the quality of the telescope’s\nimages degraded if they loosened the specifications for the mirrors. This\nmeant an evening of model building, all inside the computer. I wasn’t\nofficially working for them anymore, but blood’s thicker than water … by\nmidnight, I’d plotted the graphs for them.\n\nThe next morning, I eagerly explained my suspicions about a hacker to Dave\nCleveland, “I’ll bet you cookies to doughnuts it’s a hacker.”\n\nDave sat back, closed his eyes, and whispered, “Yep, cookies for sure.”\n\nHis mental acrobatics were almost palpable. Dave managed his Unix system with\na laid-back style. Since he competed for scientists with the VMS systems, he\nhad never screwed down the security bolts on his system, figuring that the\nphysicists would object and take their business elsewhere. By trusting his\nusers, he ran an open system and devoted his time to improving their software,\ninstead of building locks.\n\nWas someone betraying his trust?\n\nMarv Atchley was my new boss. Quiet and sensitive, Marv ran a loose group that\nsomehow managed to keep the computers running. Marv stood in contrast to our\ndivision head, Roy Kerth. At fifty-five, Roy looked like Rodney Dangerfield as\na college professor. He did physics in the grand style of Lawrence Laboratory,\nbouncing protons and antiprotons together, looking at the jetsam from these\ncollisions.\n\nRoy treated his students and staff much as his subatomic particles: keep them\nin line, energize them, then shoot them into immovable objects. His research\ndemanded heavy number crunching, since his lab generated millions of events\neach time the accelerator was turned on. Years of delays and excuses had\nsoured him on computer professionals, so when I knocked on his door, I made\nsure we talked about relativistic physics and ignored computing.\n\nNow, Dave and I could guess Roy’s reaction to our problem: “Why the hell did\nyou leave our doors wide open?”\n\nOur boss’s reaction might be predictable, but how should we react? Dave’s\nfirst thought was to disable the suspect account and forget about it. I felt\nwe ought to send a nastygram to whoever was breaking in, telling him to stay\naway or we’d call his parents. After all, if someone was breaking in, it was\nbound to be some student from down on campus.\n\nBut we weren’t certain that someone was breaking into our system. It might\nexplain some of our accounting problems—someone learns the system manager’s\npassword, connects to our machine, creates a new account, and tampers with the\naccounting system. But why would someone use a new account if they already had\naccess to the system manager account?\n\nOur boss never wanted to hear bad news, but we swallowed hard and called a\nlunchtime meeting. We had no clear proof of a hacker, just circumstantial\npointers, extrapolated from trivial accounting errors. If there was a break-\nin, we didn’t know how far it extended, nor who was doing it. Roy Kerth\nblasted us. “Why are you wasting my time? You don’t know anything and you\nhaven’t proven a whit. Go back and find out. Show me proof.”\n\nSo how do you find a hacker? I figured it was simple: just watch for anyone\nusing Sventek’s accounts, and try to trace their connection.\n\nI spent Thursday watching people log into the computer. I wrote a program to\nbeep my terminal whenever someone connected to the Unix computer. I couldn’t\nsee what each user was doing, but I could see their names. Every couple\nminutes my terminal beeped, and I’d see who had logged in. A few were friends,\nastronomers working on research papers or graduate students plugging away on\ndissertations. Most accounts belonged to strangers, and I wondered how I could\ntell which connection might be a hacker.\n\nAt 12:33 on Thursday afternoon, Sventek logged in. I felt a rush of adrenaline\nand then a complete letdown when he disappeared within a minute. Where was he?\nThe only pointer left for me was the identifier of his terminal: he had used\nterminal port tt23.\n\nSitting behind a computer terminal, fingers resting on his keyboard, someone\nwas connecting into our lab. My Unix computer gave him the address of port\ntt23.\n\nWell, that’s a start. My problem was to figure out which physical wires\ncorresponded to the logical name tt23.\n\nTerminals from our laboratory and modems from dial-in telephones are all\nassigned “tt” labels, while network connections show up as “nt.” I figured\nthat the guy must be either from our laboratory or dialing in on a phone line\nover a modem.\n\nFor a few seconds, I’d sensed a hesitant feeler into our computer.\nTheoretically, it must be possible to trace the path from computer to human.\nSomeone must be at the far end of that connection.\n\nIt would take six months to track that path, but my first step was to trace\nthe connection out of the building. I suspected a dial-in modem, connected\nfrom some telephone line, but it conceivably might be someone at the\nlaboratory. Over the years, well over five hundred terminals had been wired\nin, and only Paul Murray kept track. With luck, our homegrown hardware\nconnections were documented better than the home-brew accounting software.\n\nPaul’s a reclusive hardware technician who hides in thickets of telephone\nwire. I found him behind a panel of electronics, connecting some particle\ndetector to the lab-wide ethernet system. Ethernets are electronic pipelines\nconnecting hundreds of small computers. A few miles of orange ethernet cable\nsnaked through our lab, and Paul knew every inch of it.\n\nCursing me for surprising him in the middle of soldering a wire, he refused to\ngive me any help until I proved that I had a legitimate need to know. Aw,\nhell. Hardware technicians don’t understand software problems, and software\njockeys know nothing about hardware.\n\nYears of ham radio had taught me to solder, so Paul and I had at least one\ncommon denominator. I picked up his spare soldering iron and earned his\ngrudging respect after a few minutes of burning my fingers and squinting.\nFinally, he disentangled himself from the ethernet cables and showed me around\nthe LBL communications switchyard.\n\nIn this roomful of wires, the telephones, intercoms, radios, and computers\nwere all interconnected by a tangle of cables, wires, optical fibers, and\npatch panels. The suspicious port tt23 entered this room and a secondary\ncomputer switched it to one of a thousand possible terminals. Anyone dialing\ninto the lab would be randomly assigned to a Unix port. The next time I saw a\nsuspicious character, I’d have to run over to the switchyard and unwind the\nconnection by probing the switching computer. If he disappeared before I\ndisentangled the connection, well, tough. And even if I did succeed, I’d only\nbe able to point to a pair of wires entering the laboratory. I’d still be a\nlong way from the hacker.\n\nBy lucky accident, though, the noontime connection had left some footprints\nbehind. Paul had been collecting statistics on how many people used the\nswitchyard. By chance he had recorded the port numbers of each connection for\nthe past month. Since I knew the time when Sventek was active on port tt23, we\ncould figure out where he came from. The printout of the statistics showed a\none-minute 1200-baud connection had taken place at 12:33.\n\n1200 baud, huh? That says something. The baud rate measures the speed that\ndata flows through a line. And 1,200 baud means 120 characters per second—a\nfew pages of text every minute.\n\nDial-up modems over telephone lines run at 1200 baud. Any lab employee here on\nthe hill would run at high speed: 9600 or 19,200 baud. Only someone calling\nthrough a modem would let their data dribble out a 1200-baud soda straw. And\nthe anonymity and convenience of these dial-in lines are most inviting to\nstrangers. So pieces were beginning to fit together. I couldn’t prove that we\nhad a hacker in the system, but someone dialed into our lab and used Sventek’s\naccount.\n\nStill, the 1200-baud connection was hardly proof that a hacker entered our\nsystem. An incomplete trace, especially one that went no farther than my\nbuilding, would never convince my boss that something was up, something weird.\nI needed to find incontrovertible evidence of a hacker. But how?\n\nRoy Kerth had shown me the high-energy particle detectors attached to the\nBevatron: they find jillions of subatomic interactions, and 99.99 percent are\nexplainable by the laws of physics. Spending your time exploring each particle\ntrail will lead you to conclude that all the particles obey known physics, and\nthere’s nothing left to discover. Alternatively, you could throw away all the\nexplainable interactions, and only worry about those that don’t quite satisfy\nthe canonical rules.\n\nAstronomers, distant cousins of high-energy physicists, work along similar\nlines. Most stars are boring. Advances come from studying the weirdies—the\nquasars, the pulsars, the gravitational lenses—that don’t seem to fit into the\nmodels that you’ve grown up with. Knowing cratering statistics on the planet\nMercury tells you how often the planet was bombarded in the early solar\nsystem. But study the few craters intersected by scarps and ridges and you’ll\nlearn how the planet shrank as it cooled during its first billion years.\nCollect raw data and throw away the expected. What remains challenges your\ntheories.\n\nWell, let’s apply this way of thinking to watching someone visiting my\ncomputer. I’ve got a terminal on my desk, and can borrow a couple others.\nSuppose I just watched the traffic coming into the computer center. There’s\nabout five hundred lines entering the system. Most of these lines run at 9600\nbaud, or around one hundred fifty words per second. If half the lines are used\nat any time, I’d have to read well over ten thousand pages every minute.\nRight. No way could I monitor that kind of traffic on my terminal.\n\nBut the high speed lines come from people at LBL. We’d already traced one\nsuspicious connection to a 1200-baud line. There are fewer of them (we can’t\nafford too many incoming phone lines), and they’re slower. Fifty lines at 1200\nbaud might generate a hundred pages a minute, still far too fast to watch on\nthe screen of my terminal. I might not be able to watch fifty people running\nat once, but maybe I could print out all their interactive sessions, and read\nthe piles of paper at my leisure. A paper printout would provide hard proof of\nsomeone messing around; if we found nothing suspicious, we could drop the\nwhole project.\n\nI’d record everything that happened during each 1200-baud connection. This\nwould be technically challenging—since I didn’t know which line the hacker was\ncalling, I’d have to monitor four dozen. More worrisome was the ethical\nproblem of monitoring our communications. Did we have the right to watch the\ntraffic running through our lines?\n\nMy sweetheart, Martha, was just finishing law school. Over a deep-dish pizza,\nwe talked about the implications of someone breaking into a computer. I\nwondered how much trouble I’d be in by listening to incoming traffic.\n\n“Look,” she mumbled, burning the roof of her mouth on the vulcanized\nmozzarella. “You’re not the government, so you don’t need a search warrant.\nThe worst it would be is invasion of privacy. And people dialing up a computer\nprobably have no right to insist that the system’s owner not look over their\nshoulder. So I don’t see why you can’t.”\n\nSo with a clear conscience, I started building a monitoring system. We had\nfifty 1200-baud lines, and a hacker might be using any of them. I had no\nequipment designed to record the traffic.\n\nBut there’s an easy way to record a hacker’s activity. Modify the Unix\noperating system so that whenever a suspicious person logged in, the system\nrecords all the keystrokes. This was tempting, because I only had to add some\nlines of code to the Unix daemon software.\n\nThe daemons themselves are just programs that copy data from the outside world\ninto the operating system—the eyes and ears of Unix. (The ancient Greek\ndaemons were inferior divinities, midway between gods and men. In that sense,\nmy daemons are midway between the god-like operating system and the world of\nterminals and disks.)\n\nI could split the daemon’s output like a T-joint in a pipe, so the hacker’s\nkeystrokes would simultaneously go to both the operating system and a printer.\nSoftware solutions are simple and elegant.\n\n“Muck with the daemons at your own risk,” Dave Cleveland said. “Just respect\ntheir timing needs.”\n\nWayne also warned me, “Look, if you goof up, you’ll break the system for sure.\nIt will turn the system into molasses, and there’s no way you’ll follow\neverything that happens. Just wait till you see the system console print out\n‘Panic kernel mode interrupt’—don’t come crying on my shoulder!”\n\nDave chipped in, “Hey, if your hacker has any Unix experience, he’s bound to\nnotice a change in the daemons.”\n\nThat convinced me. A sharp systems person would notice that we’d changed the\noperating system. The moment the hacker knew someone was watching him, he’d\ntrash our databases and scram. Our wiretaps had to be completely undetectable,\neven to an omnipotent super-user. Silent, invisible monitors to trap the\nhacker’s activity.\n\nMaybe just tape recording the telephone lines would work, but tape recorders\ndidn’t feel right, too much of a kludge. We’d have to play them back, and\ncouldn’t watch the keystrokes until long after a hacker had disconnected.\nFinally, where would I find fifty tape recorders?\n\nAbout the only other place to watch our traffic was in between the modems and\nthe computers. The modems converted the tones of a telephone into electronic\npulses, palatable to our computers and the daemons in their operating systems.\nThese modem lines appeared as flat, twenty-five conductor wires, snaking\nunderneath the switchyard’s false floor. A printer or personal computer could\nbe wired to each of these lines, recording every keystroke that came through.\n\nA kludge? Yes. Workable? Maybe.\n\nAll we’d need are fifty teletypes, printers, and portable computers. The first\nfew were easy to get—just ask at the lab’s supplies desk. Dave, Wayne, and the\nrest of the systems group grudgingly lent their portable terminals. By late\nFriday afternoon, we’d hooked up a dozen monitors down in the switchyard. The\nother thirty or forty monitors would show up after the laboratory was\ndeserted. I walked from office to office, liberating personal computers from\nsecretaries’ desks. There’d be hell to pay on Monday, but it’s easier to give\nan apology than get permission.\n\nStrewn with four dozen obsolete teletypes and portable terminals, the floor\nlooked like a computer engineer’s nightmare. I slept in the middle, nursing\nthe printers and computers. Each was grabbing data from a different line, and\nwhenever someone dialed our system, I’d wake up to the chatter of typing.\nEvery half hour, one of the monitors would run out of paper or disk space, so\nI’d have to roll over and reload.\n\nSaturday morning, Roy Kerth shook me awake. “Well, where’s your hacker?”\n\nStill in my sleeping bag, I must have smelled like a goat. I blinked stupidly\nand mumbled something about looking at the fifty piles of paper.\n\nHe snorted, “Well, before you start poking around those printouts, return\nthose printers. You’ve been running around here like a maniac swiping\nequipment used by people who are getting work done. You’ve pissed off a dozen\nastronomers. Are _you_ getting work done? No. Whaddya think this place is,\nyour own personal sandbox?”\n\nBleary-eyed, I dragged each printer back to its rightful owner. The first\nforty-nine showed nothing interesting. From the fiftieth trailed eighty feet\nof printout. During the night, someone had sneaked in through a hole in the\noperating system.\n\n\n![](images/Stol_9780307819420_epub_004_r1.jpg) For three hours, a hacker had\nstrolled through my system, reading whatever he wished. Unknown to him, my\n1200-baud Decwriter had saved his session on eighty feet of single-spaced\ncomputer paper. Here was every command he issued, every typing mistake, and\nevery response from the computer.\n\nThis printer monitored the line from Tymnet. I didn’t realize it, but a few of\nour 1200-baud lines weren’t dial-in modem lines. Rather, they came from\nTymnet, a communications company that interconnected computers around the\nworld.\n\nBack before divestment, the Bell system monopolized communications. AT&T was\nthe only way to connect New York to Chicago. By using modems, the phone system\ncould handle data, but the noise and expense of the long distance service made\nit unsuitable for computers. By the late ’70s, a few other companies dipped\ntheir toes in the water, offering specialized services like data phones.\nTymnet created a network to interconnect computers in major cities.\n\nTymnet’s idea was simple and elegant: create a digital communications\nbackbone, let anyone connect to the backbone by making a local telephone call,\nthen send the data to any computer on the network. Tymnet would compress\ndozens of users’ data into a few packets, and economically send these around\nthe country. The system was immune to noise, and each user could run as fast\nas he wished. Customers saved money because they could access a distant\ncomputer by making a local call.\n\nTo satisfy scientists around the country, LBL subscribed to Tymnet. When a\nresearcher in Stonybrook, New York, wanted to connect to our computer, he\ndialed his local Tymnet number. Once his modem was connected to Tymnet, he\njust asked for LBL and worked as if he were in Berkeley. Physicists from far\naway loved the service, and we were delighted to find them spending their\nresearch dollars on our computers, rather than their home machines.\n\nSomeone was breaking in, using the Tymnet line. Since Tymnet interconnected\nthe whole country, our hacker might be anywhere.\n\nFor the moment, though, I was fascinated not by where the hacker came from,\nbut what he had done in three hours. My guess was right: Sventek’s account was\nbeing used to break into our Unix computer.\n\nNot just break in. This hacker was a super-user.\n\nThe hacker had sneaked through a hole in our system to become a super-\nuser—he’d never even logged into the system manager’s account. He was like a\ncuckoo bird.\n\nThe cuckoo lays her eggs in other birds’ nests. She is a nesting parasite:\nsome other bird will raise her young cuckoos. The survival of cuckoo chicks\ndepends on the ignorance of other species.\n\nOur mysterious visitor laid an egg-program into our computer, letting the\nsystem hatch it and feed it privileges.\n\nThat morning, the hacker wrote a short program to grab privileges. Normally,\nUnix won’t allow such a program to run, since it never gives privileges beyond\nwhat a user is assigned. But run this program from a privileged account, and\nhe’ll become privileged. His problem was to masquerade this special\nprogram—the cuckoo’s egg—so that it would be hatched by the system.\n\nEvery five minutes, the Unix system executes its own program named _atrun_. In\nturn, atrun schedules other jobs and does routine housecleaning tasks. It runs\nin a privileged mode, with the full power and trust of the operating system\nbehind it. Were a bogus atrun program substituted, it would be executed within\nfive minutes, with full system privileges. For this reason, atrun sits in a\nprotected area of the system, available only to the system manager. Nobody but\nthe system manager has the license to tamper with atrun.\n\nHere was the Cuckoo’s nest: for five minutes, he would swap his egg for the\nsystem’s atrun program.\n\nFor this attack, he needed to find a way to move his egg-program into the\nprotected systems nest. The operating system’s barriers are built specifically\nto prevent this. Normal copy programs can’t bypass them; you can’t issue a\ncommand to “copy my program into systems space.”\n\nBut there was a wildcard that we’d never noticed. Richard Stallman, a free-\nlance computer programmer, loudly proclaimed that information should be free.\nHis software, which he gives away for free, is brilliantly conceived,\nelegantly written, and addictive.\n\nOver the past decade Stallman created a powerful editing program called Gnu-\nEmacs. But Gnu’s much more than just a text editor. It’s easy to customize to\nyour personal preferences. It’s a foundation upon which other programs can be\nbuilt. It even has its own mail facility built in. Naturally, our physicists\ndemanded Gnu; with an eye to selling more computing cycles, we installed it\nhappily.\n\nJust one problem: there’s a bug in that software.\n\nIn the way it was installed on our Unix computer, the Gnu-Emacs editor lets\nyou forward a mail file from your own directory to anyone else in an unusual\nway. It doesn’t check to see who’s receiving it, or even whether they want the\nfile. It just renames the file and changes its ownership label. You’ve just\ntransferred ownership of the file from you to me.\n\nNo problem to send a file from your area to mine. But you’d better not be able\nto move a file into the protected systems area: only the system manager is\nallowed there. Stallman’s software had better make sure this can’t happen.\n\nGnu didn’t check. It let anyone move a file into protected systems space. The\nhacker knew this; we didn’t.\n\nThe hacker used Gnu to swap his special _atrun_ file for the system’s\nlegitimate version. Five minutes later, the system hatched his egg, and he\nheld the keys to my computer.\n\nHe had used this technique to fool the computer into giving him power. He\nplanted his phony program where the system expected to find a valid one. The\ninstant that Unix executed his bogus _atrun_ program, he became super-user.\nThe whole operation depended on his being able to move a file anywhere he\nwished.\n\nGnu was the hole in our system’s security. A subtle bug in an obscure section\nof some popular software. Installed blindly by our systems programmers, we’d\nnever thought that it might destroy our whole system’s security.\n\nNow I understood. Our friend must have entered a guest account, leveraged his\nprivileges using Gnu’s hole, and then added a new account to the computer’s\nfiles.\n\nIn front of me, the first few feet of the printout showed the cuckoo preparing\nthe nest, laying the egg, and waiting for it to hatch. The next seventy feet\nshowed the fledgling cuckoo testing its wings.\n\nAs super-user, he had the run of our system. First thing he did was erase his\ntracks: he switched the good copy of _atrun_ back where it belonged. Then he\nlisted the electronic mail of all our users, reading news, gossip, and love\nletters. He learned of the past month’s computer changes, grant proposals, and\nnew hires. He searched for changes in the system managers’ files, and\ndiscovered that I’d just started work. He checked my salary and résumé. More\nworrisome, he realized that I was a system manager, and my account name.\n\nWhy me? What did I do? At any rate, from now on, I’d better use a different\nname.\n\nEvery ten minutes, the hacker issued the command, “who,” to list everyone\nlogged onto the computer. Apparently, he worried that someone might see him\nconnected, or might be watching. Later, he searched for any changes in the\noperating system—had I modified the daemons to record his session, as I’d\nfirst planned to do, he would surely have discovered it. I felt like a kid\nplaying hide-and-seek, when the seeker passes within inches of his hiding\nplace.\n\nWithin the first hour, he wrote a program to scan everyone’s mail messages for\nany mention of his activity. He searched for the word, “hacker,” and\n“security.”\n\nOne scientist had started a program that assembled data from an experiment\nover the weekend. Running under the name “gather,” this program innocuously\ncollected information every few minutes and wrote it to a file. The hacker saw\nthis program, spent ten minutes trying to understand what it did, and killed\nit.\n\nYow! Here’s someone looking over his shoulder every few minutes, checking to\nsee if anyone’s around. He kills any jobs that he thinks might monitor him. He\nopens my mail, checking to see if anyone’s written about hackers. Wayne was\nright: if you stay in the open, he’ll know you’re watching. From now on, we’d\nhave to be subtle and invisible.\n\nWhen he wasn’t looking back over his shoulder, the hacker was reading files.\nBy studying several scientists’ command files and scripts, he discovered\npathways into other lab computers. Every night, our computer automatically\ncalls twenty others, to exchange mail and network news. When the hacker read\nthese phone numbers, he learned twenty new targets.\n\nFrom the mail file of an engineer:\n\n**“Hi, Ed!**\n\n**I’ll be on vacation for the next couple weeks. If you need to get any of my\ndata, just log into my account on the Vax computer. Account name is Wilson,\npassword is Maryanne (that’s my wife’s name). Have fun!”**\n\nThe hacker had fun, even if Ed didn’t. He connected through our local area\nnetwork into that Vax, and had no problem logging into Wilson’s account.\nWilson wouldn’t notice the hacker reading his files, and probably wouldn’t\ncare. They contained numerical data, meaningless to anyone but another nuclear\nphysicist.\n\nOur visitor knew about our lab’s internal networks. Our dozen big computers\nwere tied to a hundred laboratory computers using ethernets, serial lines, and\nchewing gum. When physicists wanted to get data from a computer at the\ncyclotron into our big computer, elegance meant nothing. They’d use any port,\nany line, any network. Over the years technicians had woven a web of cables\naround the lab, interconnecting most of the computers with whatever seemed to\nwork. This local area network reached into every office, connecting PC’s,\nMacintoshes, and terminals to our mainframe computers.\n\nOften, these networked computers had been arranged to trust each other. If\nyou’re OK on that computer, then you’re OK on this one. This saved a bit of\ntime: people wouldn’t need to present more than one password when using\nseveral computers.\n\nThe hacker exploited that trust to enter a half dozen computers. As super-user\non our main Unix computer, he disguised himself under someone else’s account\nname. Then he just knocked on the door of another networked machine, and he\nwas admitted without even whispering the password. Our visitor couldn’t know\nwhat these systems were used for; still, he felt his way around the net,\nsearching for connections into unexplored computers.\n\nBy the end of the session, the printer’s ribbon had run out of ink. By rubbing\na pencil lightly over the paper, I could just make out the impressions left\nfrom the printhead: the hacker had copied our password file, then\ndisconnected.\n\nA bass guitar note took my attention from the hacker’s trail. The Grateful\nDead were playing outdoors at the Berkeley Greek Theater, only a hundred yards\ndownhill from the lab. The police couldn’t keep people from sitting in the\nfield overlooking the concert, so I skipped over there, mingling with a\nthousand others in tie-dyed shirts. Burnt-out panhandlers, left over from the\nsixties, walked the crowd, begging tickets and selling posters, buttons, and\ngrass. The drum solo in the second set echoed from Strawberry Canyon, adding a\nweird backbeat appreciated only by us cheapskates in the fields. Life was\nfull: no hacker is worth missing a Dead concert for.\n\n\n![](images/Stol_9780307819420_epub_005_r1.jpg) Monday morning marked my second\nweek on the job. I was an uneasy computer jockey: surrounded by overworked\nexperts, yet not knowing what tasks I ought to be doing. Something fun would\nturn up, in the meantime, I might as well finish this hacker project.\n\nLike a freshman in physics lab, I wrote about the weekend’s activity in a\nlogbook. Not that I planned to use this logbook: it was a chance to learn a\nword processor on my Macintosh. The astronomer’s rule of thumb: if you don’t\nwrite it down, it didn’t happen.\n\nI passed the results to the gang, hoping nobody would notice that I’d slept\novernight in the machine room.\n\nThe boss wanted to see me as soon as he arrived.\n\nI suspected he was mad about my grabbing all those terminals. Management might\nbe loose, but computer jocks still weren’t supposed to borrow piles of lab\nequipment without telling anyone.\n\nBut Roy didn’t even grinch about the terminals. He wanted to know about the\nhacker.\n\n“When did he show up?”\n\n“Sunday morning at five for three hours.”\n\n“Delete any files?”\n\n“Killed one program that he thought was monitoring him.”\n\n“Are we in danger?”\n\n“He’s super-user. He can wipe out all our files.”\n\n“Can we shut him down?”\n\n“Probably. We know the one hole, it’s a quick patch.”\n\n“Think that’ll stop him?”\n\nI could sense where his thoughts were leading. Roy wasn’t concerned about\nslamming the door. He knew we could easily deactivate the stolen Sventek\naccount. And now that we understood it, fixing the Gnu-Emacs hole wasn’t\ndifficult: just add a couple lines of code to check the target directory.\n\nShould we close our doors or remain open? Closing up shop was the obvious\nreaction. We knew how this hacker entered our system and knew how to kick him\nout.\n\nBut what else was wrong? What other gifts had our mysterious visitor left for\nus? How many other accounts did he access? What other computers did he break\ninto?\n\nThere was the worry. The printout showed the hacker to be a competent systems\nprogrammer, able to exploit obscure bugs that we’d never seen before. What\nelse had he done?\n\nWhen you’re super-user, you can modify any file in the system. Did the hacker\nmodify a system program to open a backdoor entrance? Had he patched our system\nto recognize a magic password?\n\nDid he plant a computer virus? On home computers, viruses spread by copying\nthemselves into other pieces of software. When you give an infected piece of\nsoftware to someone else, the virus copies itself into other software,\nspreading from disk to disk.\n\nIf the virus is benign, it’ll be hard to detect and probably won’t do much\ndamage. But it’s easy to build malicious viruses which duplicate themselves\nand then erase data files. Just as easy to create a virus that lies dormant\nfor months and then erupts some day in the future.\n\nViruses are the creatures that haunt programmers’ nightmares.\n\nAs super-user, the hacker could infect our system in a way that would be\nalmost impossible to eradicate. His virus could copy itself into systems\nsoftware and hide in obscure areas of the computer. By copying itself from\nprogram to program, it would defy our efforts to erase it.\n\nUnlike a home computer, where you can rebuild the operating system from\nscratch, we had extensively modified our operating system. We couldn’t go to a\nmanufacturer and say, “Give us an original copy.” Once infected, we could only\nrebuild our system from backup tapes. If he’d planted a virus six months ago,\nour tapes would be infected as well.\n\nMaybe he’d planted a logic bomb—a program timed to blow up sometime in the\nfuture. Or perhaps this intruder had only rifled our files, killed a couple\njobs, and screwed up our accounting. But how could we tell that he hadn’t done\nmuch worse? For a week, our computer was wide open to this hacker. Could we\nprove that he hadn’t tampered with our databases?\n\nHow could we again trust our programs and data?\n\nWe couldn’t. Trying to shut him out wouldn’t work, as he’d only find another\nway in. We needed to find out what he had done and what he was doing.\n\nMost of all, we needed to know who was at the other end of the line.\n\n“It’s gotta be some student on the Berkeley campus,” I said to Roy. “They’re\nthe Unix wizards, and they think of us as bozos.”\n\n“I wouldn’t be too sure.” Roy leaned back in his chair. “Why would someone\nfrom Berkeley come in through Tymnet, when they could more easily have dialed\nour system over the telephone lines?”\n\n“Maybe Tymnet is just a cover,” I said. “A place to hide. If he dialed the lab\ndirectly, we’d trace him. But now, we’ve got to trace both Tymnet and a\ntelephone call.”\n\nMy hand waving didn’t convince the boss. Perhaps from his scientific\nexperience or maybe as a cynical ploy, Roy kept an open mind: it’s not a\nstudent until he’s dragged in. Sure, the weekend’s printouts showed a good\nprogrammer, but we might be watching any competent computer jockey, anywhere.\nTracking the guy meant tracing telephone lines. The price of hard evidence was\nhard work.\n\nConfronted with traces of a mysterious visitor, Roy only saw footprints. I saw\nan intruder.\n\nRoy decided not to decide. “Let’s close down all network connections for the\nday. Tomorrow morning, I’ll talk to the lab director, and get a sense of what\nto do.” We could delay, but sooner or later we’d have to either start tracing,\nor lock the guy out.\n\nDid I want to track someone through the city? It would keep me from scientific\ncomputing. It had nothing to do with astronomy or physics. And it sounded like\ncops and robbers—or a game of hide-and-seek.\n\nOn the plus side, though, I might learn about phone traces and networks. Best\nof all was imagining the look on some kid’s face when we barged into his dorm\nroom, shouting, “Freeze! Drop that keyboard!”\n\nTuesday afternoon, Roy called. “The director says, ‘This is electronic\nterrorism. Use all the resources you need to catch the bastard. Take all the\ntime you want. Spend three weeks, if you have to. Nail the bastard.’ ”\n\nIf I wanted to hunt the hacker, management backed me.\n\n\n![](images/Stol_9780307819420_epub_006_r1.jpg) I biked home, thinking of\ndevious hacker-trapping schemes. As I came closer to home, though, my thoughts\nturned to dinner. So great to have someone to come home to.\n\nMartha Matthews and I had lived together for a few years now, and been friends\nfor almost ten. We’d known each other so well that it was hard to remember a\ntime before I knew her.\n\nOld friends shook their heads. They’d never seen me stay with one woman this\nlong. I’d fall in love, hang around for a couple years, and then we’d grow\ntired of each other and move on. I was still good friends with several former\nlovers, but the romance never seemed to last. I’d always been cynical and\nsarcastic, protecting myself from getting too close to anyone.\n\nBut life with Martha felt different. Barrier after barrier came down, slowly,\nover time. She insisted on talking out our differences, demanded to know the\nreasons for my moods and tempers, demanded that we think of ways to get along\nbetter. It was unbearable sometimes—I hated to talk when I was mad—but it\nusually seemed to work.\n\nI found myself feeling nesting instincts. The perfect afternoon was to tinker\naround the house, rewiring a switch, planting some bulbs, or soldering a\nstained glass window. We spent many a quiet evening, sewing or reading or\nplaying scrabble. I began to feel …\n\nMarried? Who, me? No. Definitely not. Marriage was stultifying, a trap for the\nconventional. You married someone and they expected you to stay the same\nforever, never changing, never doing anything new. There’d be fights and you\ncouldn’t leave, you’d get tired of the same person every evening, every\nmorning. Limiting, dreary, artificial, and conventional.\n\nLiving together was different. We were both free. We freely chose to share\neach day, and either of us could leave if the relationship was no longer good\nfor us. It was better this way, and Martha seemed content.\n\nUh, right.\n\nI wondered if she’d remain cheerful if I spent the next few weeks sleeping at\nwork.\n\nThree weeks to catch a hacker. How long should this take? Perhaps a couple\ndays to set up traces, another few days to track him through the networks, and\nthen bust him. Probably we’d need the cooperation of the police, so add a day\nor two. We could wrap it up in two weeks, then I’d be back to managing a\ncomputer, and maybe a bit of astronomy on the side.\n\nWe needed to weave a net fine enough to catch the hacker, but coarse enough to\nlet our scientists through. I’d have to detect the hacker as soon as he came\non line and call Tymnet’s technicians to trace the call.\n\nDetecting the hacker was easy: I’d just camp out in my office alongside two\nterminals. One terminal for working, another to watch the system. Each time\nsomeone logged onto the computer, two beeps would tell me to check out the new\nuser. As soon as a stranger showed up, I’d run down to the switchyard and see\nwhat they were doing.\n\nTheoretically foolproof. Impossible in practice. From a thousand users, I knew\nabout twenty. The other 980? Well, I had to check each one. So every two\nminutes I’d jog down the hall, thinking that I’d caught someone. And since I’d\nmiss the signal if I went home, I ignored Martha and slept under the desk.\n\nThe rug smelled like a seat on a crosstown bus and whenever the terminal\nbeeped, I’d sit up and gouge my head on the bottom of a drawer. A couple\nnights of slicing my forehead convinced me that there had to be an easier way.\n\nIf I knew the stolen account names, it would be easy to write a program that\nwatched for the bad guy to show up. No need to check out every person using\nthe computer; just ring a bell when a stolen account was in use. But I also\nremembered Wayne Graves’ warning—stay invisible.\n\nThat meant no jobs running on the main computer. But I could watch from\nanother computer. We’d just installed a new Unix computer, our Unix-8 system.\nNobody had used it yet, so it might not be secure, but it surely wasn’t\ncontaminated. I could connect it to our local area network, secure it against\nall possible attacks, and let it watch the Unix-4 and Unix-5 computers.\n\nI’d protect my Unix-8 castle with a one-way moat. Information could come into\nthe computer, but nothing could go out. Dave Cleveland, hardly excited about\nchasing a hacker, smiled slightly and told me how to set Unix-8 to reject all\nlog-in attempts, yet covertly scan the other Unix machines for signs of bad\nguys.\n\nThe program wasn’t hard—just a few dozen lines of code to get a status block\nfrom each of the local computers. From long tradition, astronomers have\nprogrammed in Fortran, so I wasn’t surprised when Dave gave me the hairy\neyeball for using such an antiquated language. He challenged me to use the C\nlanguage; in a few minutes he’d reduced it to twenty lines of tightly written\ncode.\n\nWe fired up Dave’s watchdog program on the Unix-8 computer. From the outside,\nit looked like just one more laboratory system. Anyone inquiring about its\nstatus received an invitation to log in. But you couldn’t log on, since that\ncomputer rejected everyone except Dave and me. The hacker shouldn’t be\nsuspicious, since that computer didn’t appear to be hooked up.\n\nFrom this high ground, a network messenger asked each of the other Unix\ncomputers, “Hey, who’s logged on?” Each minute, the Unix-8 program analyzed\nthese reports, and searched for Sventek’s name. When Sventek showed up, my\nterminal beeped, and it was forehead-gouging time.\n\nBut alarms alone wouldn’t catch the hacker. We needed to track him through our\nsystem, and back to his lair. And to protect ourselves, we had to know what he\nwas doing.\n\nThere was no way to grab fifty printers again to monitor all the traffic\nthrough our system, so I had to watch only those lines that he’d be likely to\nuse. Saturday morning, he’d entered through one of our four Tymnet\nconnections, so that seemed like a good place to start.\n\nI couldn’t buy, steal, or borrow four printers for a few weeks, so I went out\nbegging. One physics professor gave me a beat-up old Decwriter, delighted that\nsomeone would take the ten-year-old heap off his hands. A secretary donated a\nspare IBM PC in exchange for my teaching her how to use spreadsheet programs.\nA combination of cookies, coaxing, and conniving led to two more obsolete\nprinters. We were back in business, recording all our Tymnet traffic.\n\nWednesday afternoon marked a week since we’d first detected the hacker.\nBerkeley was sunny, though I could barely see the windows from across the maze\nof cubicles. Dave’s watchdog was awake, the printers busy chattering with\nevery keystroke, and I was absentmindedly thinking of infrared emissions from\nthe Pleiades star cluster. Suddenly, the terminal beeped twice: Sventek’s\naccount was active. My adrenaline pumped as I ran to the switchyard; the top\nof the ream of paper showed the hacker had logged in at 2:26 and was still\nactive.\n\nLetter by letter, the printer spat out the hacker’s keystrokes.\n\nLogged into the Unix-4 computer as Sventek, he first listed the names of\neveryone connected. Lucky—there was nobody but the usual gang of physicists\nand astronomers; my watchdog program was well concealed within the Unix-8\ncomputer. “Looking over your shoulder again,” I thought. “Sorry, nobody here\nbut us astrophysicists,” I whispered to the terminal.\n\nAll the same, he scanned all the processes running. The Unix command, _ps_\nprints the status of other processes. Habitually, I usually typed in _ps -axu_\n, the last three characters telling mother Unix to tell everyone’s status. The\nintruder, however, entered _ps -eafg_. Strange. I’d never seen anyone use the\n_g_ flag. Not that he discovered much: just a few scientific analysis\nprograms, and a cranky typesetting program—and a network link to the Unix-8\nsystem.\n\nIt’d taken him just three minutes to discover the Unix-8 computer, loosely\nlinked to the Unix-4 system. But could he get in? With the Unix _rlogin_\ncommand he tried a half-dozen times, knocking on the door of the Unix-8\nmachine with Sventek’s account name and password. No luck. Dave had nailed\nthat door closed.\n\nApparently satisfied that nobody was watching him, he listed the system\npassword file. There wasn’t much for him to see there: all the passwords are\nencrypted and then stored. An encrypted password looks like gibberish; without\nsolving an extremely difficult cipher, the password file gave the hacker\nlittle more than a dream.\n\nHe didn’t become super-user; rather he checked that the Gnu-Emacs file hadn’t\nbeen modified. This ended any doubts about whether the same hacker was\nconnected: nobody else would search out the security hole in our system. At\n2:37, eleven minutes after he logged in, he abruptly logged off the Unix-4\ncomputer. But not before we’d started the trace.\n\nTymnet! I’d forgotten to warn their network operations center that they’d have\nto trace some connections. I hadn’t even asked whether they could trace their\nown network. Now, watching the printer copy every key that the hacker pressed,\nthere were only minutes to get the trace.\n\nRon Vivier traces Tymnet’s network within North America. While I talked to him\non the phone, I could hear him punching keys on his terminal. In a staccato\nvoice, he asked for our node’s address. At least I’d prepared that much. In a\ncouple minutes, Ron had traced the connection from LBL’s Tymnet port into an\nOakland Tymnet office, where someone had dialed in from a telephone.\n\nAccording to Ron, the hacker had called Tymnet’s modem in Oakland, just three\nmiles from our lab.\n\nIt’s easier to call straight into our Berkeley lab than to go through\nOakland’s Tymnet office. Why call through Tymnet when you can dial directly\ninto our system? Calling direct would eliminate Tymnet’s intermediate\nconnections and might be a tad more reliable. But calling via Tymnet added one\nmore layer to trace.\n\nThe hacker had called the local Tymnet access number instead of our lab. It\nwas like taking the interstate to drive three blocks. Whoever was at the other\nend of the line knew how to hide. Ron Vivier gave his condolences—I hadn’t\nwanted just some Tymnet telephone number; I was hunting for a person.\n\nWell, we were on the trail, but there were bends in the road. Somehow, we’d\nhave to trace the phone call, and phone traces meant court orders. Phooey.\n\nWhen the hacker logged off, I looked up from the printout. Like a firehouse\ndog, Roy Kerth had picked up the news and made it down to the switchyard. So\nhad Dave and Wayne.\n\nWhen Ron hung up, I announced, “He’s calling Oakland Tymnet. So he must be\nfrom around here. If he were in Peoria, he’d save his nickel and call the\nPeoria Tymnet modem.”\n\n“Yeah, you’re probably right.” Roy didn’t look forward to losing a bet.\n\nDave wasn’t thinking about the phone trace. “This _ps -eafg_ command bothers\nme,” he said. “I can’t say why, it just doesn’t taste right. Maybe it’s just\nparanoia, but I’m sure that I’ve seen that combination before.”\n\n“To hell with Unix. Serves us right for running such a dog operating system.”\nWayne saw a chance to bait Dave. “Hey, that password file isn’t much use to\nhim, is it?”\n\n“Only if he owns a supercomputer. You’d need one to unravel the encryption.\nUnix isn’t VMS—it’s got the tightest cypher locks around,” Dave countered.\n\nRoy had heard it before; he saw himself as above the war of the operating\nsystems. “Looks like _you_ need some phone traces, Cliff.”\n\nI didn’t like his choice of pronoun, but, yes, that was the point. “Any ideas\non where to start?”\n\n“Let your fingers do the walking.”\n\n\n![](images/Stol_9780307819420_epub_007_r1.jpg) The morning after we watched\nthe hacker break into our computer, the boss met with Aletha Owens, the lab’s\nattorney. Aletha didn’t care about computers, but had a wary eye for problems\non the horizon. She wasted no time in calling the FBI.\n\nOur local FBI office didn’t raise an eyebrow. Fred Wyniken, special agent with\nthe Oakland resident agency, asked incredulously, “You’re calling us because\nyou’ve lost seventy-five cents in computer time?” Aletha tried explaining\ninformation security, and the value of our data. Wyniken interrupted and said,\n“Look, if you can demonstrate a loss of more than a million dollars, or that\nsomeone’s prying through classified data, then we’ll open an investigation.\nUntil then, leave us alone.”\n\nRight. Depending on how you looked at it, our data was worth either nothing or\nzillions of dollars. How much is the structure of an enzyme worth? What’s the\nvalue of a high-temperature superconductor? The FBI thought in terms of bank\nembezzlement; we lived in a world of research. Classified data? We weren’t a\nmilitary base or an atomic weapons lab.\n\nYet we needed the FBI’s cooperation. When the hacker next popped his periscope\nabove the water, we’d probably track him to the Tymnet’s Oakland telephone\naccess number. From there, I hoped a phone trace would lead to him. But I’d\nheard that the phone company wouldn’t trace a line without a search warrant.\nAnd we needed the FBI to get that warrant.\n\nAfter hitting the FBI’s brick wall, Aletha called our local District Attorney.\nThe Oakland DA didn’t fool around: “Someone’s breaking into your computer?\nHell, let’s get a warrant and trace them lines.” The FBI might not give a\ndamn, but our local prosecutors took us seriously. Still, they would have to\nconvince a judge. Our warrant was at least a week away.\n\nJust after five, Dave stopped by and started talking about the break-in.\n\n“Cliff, the hacker’s not from Berkeley.”\n\n“How do you know?”\n\n“You saw that guy typing in the _ps -eafg_ command, right?”\n\n“Yeah, here’s the printout,” I replied. “It’s just an ordinary Unix command to\nlist all the active processes—‘ps’ means print status, and the four letters\nmodify the display. In a sense, they’re like switches on a stereo—they change\nthe way the command works.”\n\n“Cliff, I can tell you’re used to Berkeley Unix. Ever since Berkeley Unix was\ninvented, we’ve mechanically typed ‘ps’ to see what’s happening on the system.\nBut tell me, what do those four letters modify?”\n\nDave knew my ignorance of obscure Unix commands. I put up the best front I\ncould: “Well, the _e_ flag means list both the process name and environment,\nand the _a_ flag lists everyone’s process—not just your process. So the hacker\nwanted to see everything that was running on the system.”\n\n“OK, you got half of ’em. So what are the _g_ and _f_ flags for?”\n\n“I dunno.” Dave let me flounder until I admitted ignorance.\n\n“You ask for a _g_ listing when you want both interesting and uninteresting\nprocesses. All the unimportant jobs, like accounting will show up. As will any\nhidden processes.”\n\n“And we know he’s diddling with the accounting program.”\n\nDave smiled. “So that leaves us with the _f_ flag. And it’s not in any\nBerkeley Unix. It’s the AT&T Unix way to list each process’s files. Berkeley\nUnix does this automatically, and doesn’t need the _f_ flag. Our friend\ndoesn’t know Berkeley Unix. He’s from the school of old-fashioned Unix.”\n\nThe Unix operating system was invented in the early 1970s at AT&T’s Bell\nLaboratories in New Jersey. In the late ’70s, Unix zealots from Bell Labs\nvisited the Berkeley campus, and a new, richer version of Unix was developed.\nAlong with hot tubs, leftist politics, and the free speech movement, Berkeley\nis known for its Unix implementation.\n\nA schism developed between advocates of the small, compact AT&T Unix and the\nmore elaborate Berkeley implementation. Despite conferences, standards, and\npromises, no consensus has appeared, and the world is left with two competing\nUnix operating systems.\n\nOf course, our lab used Berkeley Unix, as do all right-thinking folks. East\nCoast people were said to be biased towards AT&T Unix, but then, they hadn’t\ndiscovered hot tubs either.\n\nFrom a single letter, Dave ruled out the entire computing population of the\nWest Coast. Conceivably, a Berkeley hacker might use an old-fashioned command,\nbut Dave discounted this. “We’re watching someone who’s never used Berkeley\nUnix.” He sucked in his breath and whispered, “A heathen.”\n\nWayne didn’t give a damn about Unix. As a VMS junkie, Wayne was an infidel.\nMoreover, he felt the hacker couldn’t learn anything from our password file:\n“Look, there’s no way that anyone can decrypt those passwords. About all he’s\nlearned is our names. Why bother?”\n\nI’d rolled this around in my mind. Passwords are at the heart of security on a\nbig computer. Home computers don’t need passwords: there’s only one user.\nAnyone at the keyboard can access any program. But when there’s ten or twenty\npeople using a single system, the computer must be certain that the person\nbehind the terminal isn’t an imposter.\n\nLike an electronic signature, passwords verify the authenticity of a\ntransaction. Automatic teller machines, telephone credit cards, electronic\nfunds transfer networks, even some home telephone-answering machines depend on\npasswords. By filching or forging passwords, a hacker can create counterfeit\nwealth, steal services, or cover bounced checks. When money was stored in\nvaults, safecrackers attacked the combination locks. Now that securities are\njust bits in a computer’s memory, thieves go after the passwords.\n\nWhen your computer has fifty or a hundred users, you might just store each\nperson’s password in a file. When the user tries to log on, ask for his\npassword and compare that to what’s in your file. In a friendly environment,\nno problem. But how do you keep someone from sneaking a peek at that password\nfile? Well, protect the password file so that only the system can read it.\n\nEven if you protect the password file, every now and then all the files will\nbe copied onto backup tapes. Even a novice programmer could read those tapes\non another computer and list the contents of the password file. File\nprotection alone isn’t enough.\n\nIn 1975, Bob Morris and Fred Grampp of Bell Laboratories developed a way to\nprotect passwords, even when files weren’t secure. They would rely on\nencryption, rather than file protection. If you chose the password “cradle,”\nthe computer doesn’t simply store your choice into a file of passwords.\nInstead, Unix scrambles the letters into an encrypted word, say,\n“pn6yywersyq.” Your encrypted password is stored, not the plain text.\n\nSo a Unix password file might look something like this:\n\n**Aaron: fnqs24lkcvs**\n\n**Blacker: anvpqw0xcsr**\n\n**Blatz: pn6yywersyq**\n\n**Goldman: mwe785jcy12**\n\n**Henderson: rp2d9cl49b7**\n\nFollowing each account name is the encrypted password. Like Wayne said,\nstealing the password file just gives you a list of people.\n\nThe computer program that encrypts “cradle” into “pn6yywersyq” is built upon a\ntrapdoor algorithm: a process that’s easy to do, but difficult to undo. When\nSally Blatz logs in, she types in her account name, Blatz, and then her\npassword, cradle. The system encrypts the password into pn6yywersyq, and\ncompares that to the entry in the password file. If the encrypted entries\ndon’t match, Sally is booted off the machine. The plain text password itself\nisn’t compared, its encryption is. Password security depends on the trapdoor\nfunction.\n\nTrapdoor functions are mathematical ratchets: you can turn them forwards, but\nnot backwards. They quickly translate text into ciphers. To make these locks\npickproof, it’s got to be impossible to reverse the algorithm.\n\nOur trapdoors were built upon the Data Encryption Standard (DES), created by\nIBM and the National Security Agency. We’d heard rumors that the electronic\nspooks of NSA weakened the DES. They hobbled it just enough to be creckable by\nNSA, but kept it strong enough to resist the efforts of ordinary mortals. The\ngrapevine said that this way NSA could crack the code and read messages, but\nnobody else could.\n\nThe cryptographic DES program within our Unix computer was public. Anyone\ncould study it. NSA had analyzed its strengths and weaknesses, but these\nreports were secret. Occasionally, we’d heard rumors of someone cracking this\ncipher, but none of these panned out. Until NSA published its analyses of the\nDES, we’d have no choice but to trust that our encryption was strong enough.\n\nWayne and I had watched the hacker break in and steal our password file. The\nhacker now knew the names of a few hundred scientists. He might as well have\nasked for our telephone book—at least that included addresses. Unless he owned\na Cray supercomputer, he couldn’t invert the trapdoor function, and our\npasswords remained safe.\n\nWayne was still worried. “Maybe this guy’s stumbled on some brilliant way to\nreverse the trapdoor function. Let’s be a tad careful and change our important\npasswords.”\n\nI could hardly object. The system password hadn’t been changed for a couple\nyears, and outlasted people who had been hired and fired. I didn’t mind\nchanging my password; to make sure, I used a different password on each\ncomputer. If the hacker managed to figure out my password from the Unix-4\ncomputer, he’d still have no way to guess it on the others.\n\nBefore pedaling home, I again studied the printout of the previous day’s\nsession. Buried in the ten pages were clues to the hacker’s persona, location,\nand intentions. But too much conflicted: we traced him through Tymnet into\nOakland, California. But Dave didn’t believe he was from Berkeley. He copied\nour password file, yet our encryption made those passwords into gibberish.\nWhat was he doing with our encrypted passwords?\n\nIn some ways, this was like astronomy. We passively observed a phenomenon, and\nfrom a few clues tried to explain the event and find the location of the\nsource. Astronomers are accustomed to quietly gathering data, usually by\nfreezing behind a telescope on a mountaintop. Here the data appeared\nsporadically, from an unknown source. Instead of thermodynamics and optics, I\nneeded to understand cryptography and operating systems. Somehow, a physical\nconnection existed between our system and a distant terminal. By applying\nordinary physics, it must be possible to understand what was happening.\n\nPhysics: there was the key. Record your observations. Apply physical\nprinciples. Speculate, but only trust proven conclusions. If I were to make\nany progress, I’d have to treat the task as a freshman physics problem. Time\nto update my notebook.\n\n\n![](images/Stol_9780307819420_epub_008_r1.jpg) And just in time. Wednesday,\nSeptember 10, at 7:51 A.M., the hacker appeared in our system for six minutes.\nLong enough to ring the alarm on my terminal, but not enough time to do\nanything about it. I had stayed at home that night: “Five days at the lab is\nenough,” Martha said.\n\nI wasn’t at the lab to watch, but the printer saved three pages of the\nhacker’s trail. He had logged into our Unix-4 computer as Sventek. Well, I\nunderstand that—he had Sventek’s password, and had entered from Tymnet.\n\nBut he didn’t hang around my Unix-4 computer. Instead he leap-frogged through\nit and landed in the Milnet. Now it was no news flash that the Milnet\nexisted—it’s a part of the Internet, a computer network that cross-links a\nhundred other networks. From our Unix computer, we can reach the Internet, and\nfrom there, the Milnet.\n\nThe Milnet belongs to the Department of Defense.\n\nMy hacker connected to Milnet address 26.0.0.113, logged in there as “Hunter,”\nand checked that he had a copy of Gnu-Emacs, then disappeared.\n\nWhen I biked in around noon, there was no trace to follow upstream. But the\nhacker left an indelible trail downstream. Where was that Milnet address? The\nNetwork Information Center decoded it for me: the U.S. Army Depot, in\nAnniston, Alabama. The home of the Army’s Redstone missile complex, two\nthousand miles away from Berkeley.\n\nIn a couple minutes, he’d connected through our lab and into some Army base.\nThe printout left little doubt that this was the hacker. Nobody but the hacker\nwould use Sventek’s account. And who else would check for the Gnu-Emacs\nsecurity hole on some computer in Alabama?\n\nNobody was around to tell me to ignore it, so I called Anniston information.\nSure enough, the Anniston Army Depot had a computer center, and eventually I\nfound Chuck McNatt, the Anniston Unix wizard.\n\n“Hi, Chuck. You don’t know me but I think we found someone screwing around\nwith your computer.”\n\n“Who are you? How do I know _you’re_ not trying to break in?”\n\nAfter a few minutes of disbelief, he asked for my phone number, hung up, and\ncalled me back. Here’s someone that doesn’t trust strangers. Or did he call me\nback on a secure phone line?\n\n“Bad news,” I said. “I think I saw someone breaking into your system.”\n\n“Aw, hell—that son of a bitch, Hunter?”\n\n“Yeah. How’d you know?”\n\n“I’ve seen his ass before.”\n\nChuck McNatt explained through a thick Alabama drawl that the Army’s Redstone\nMissile Arsenal kept track of its supplies on a couple of Unix computers. To\nget orders processed quickly, they’d hooked up to Chuck’s computer at the\nAnniston Depot. Most of their traffic was news updates—not many people logged\nin remotely.\n\nOne Saturday morning, to escape the August heat, Chuck had gone into work and\nchecked the users on his system. Someone named Hunter was using up an enormous\namount of computing time. Surprised to see anyone on a Saturday, Chuck had\nflashed a message on Hunter’s screen, saying “Hey! Identify yourself!”\n\nThe mysterious Hunter typed back, “Who do you think I am?”\n\nChuck wasn’t that gullible. He sent another message, “Identify yourself now or\nI’ll knock you off the system!”\n\nBack came Hunter’s reply, “I cannot answer.”\n\n“So I bumped him off the machine,” Chuck said. “We called the FBI, but they\ndidn’t give a damn. So we talked CID into tracing every damn connection coming\nin on our phone lines.”\n\n“What’s the CID—Chestnut Inspection Department?”\n\n“Be serious,” Chuck said. “The CID’s the Army’s cops. The criminal\ninvestigation division. But they’re not doin’ much.”\n\n“No classified material lost, huh?”\n\nThe FBI in Montgomery, Alabama, told Chuck about the same story as Oakland had\ntold me. They’d investigate when a million dollars disappeared. Until then,\ndon’t bother ’em. Computer crimes weren’t sexy.\n\n“Who’d you find?”\n\n“The weirdest thing,” Chuck continued. “I caught Hunter sneaking into my\ncomputer two or three more times, but my telephone recorders didn’t show a\nthing.”\n\n“Betcha I know why. He’s been coming in through your back door. Your Milnet\nconnection. Some hacker’s been breaking into our system, and he got into your\ncomputer this morning.”\n\nChuck cursed—he’d missed the three-minute connection. He had set traps on all\nhis telephone lines, but hadn’t thought to watch his network links.\n\n“We’re trying to find out who’s hacking our system,” I said. “We figure he’s a\nstudent here in Berkeley, and we’re gearing up to track him down. Our first\ntrace points to Oakland or Berkeley.”\n\n“Well, I know how you feel. We all suspect it’s a student here in Alabama,”\nChuck said. “We thought about closing up, but we’re out to git him. I’d rather\nsee him behind bars than behind a terminal.”\n\nFor the first time, I worried for this hacker’s welfare. If the Army caught\nthe guy, he’d have a rough time.\n\n“Hey, Chuck, have I got a kicker for you. Betcha this guy’s super-user on your\nsystem.”\n\n“Naw. He might have stolen an account, but no way he’d get to be super-user.\nWe’re an Army base, not some goofball college.”\n\nI let the swipe at Berkeley pass. “He went looking for your Gnu-Emacs move-\nmail file.”\n\n“Yeah. So what?”\n\n“What do you know about the nesting habits of cuckoos?” I explained the\nworkings of the Gnu-Emacs security hole.\n\nChuck was taken aback. “You mean we’ve had this hole since White Sands sent us\nthis Gnu file?” Chuck whistled. “I wonder how long he’s been poking around.”\nHe understood the hole and the implications.\n\nThe hacker listed files at the Anniston system. Judging from the dates of\nthese files, he’d been in Anniston’s computers since early June. For four\nmonths, an illegitimate system manager used an Alabama Army computer. Yet he’d\nbeen discovered by accident, not through some logic bomb or lost information.\n\nNo obvious damage.\n\nLooking closely at the morning’s printout, I saw that the hacker had executed\nthe change password command. On the Anniston computer, he had changed Hunter’s\npassword to be “Hedges.” A clue at last: of zillions of possible passwords,\nhe’d chosen Hedges. Hedges Hunter? Hunter Hedges? A hedge hunter? Time to flip\nthrough the H’s in the Berkeley telephone book.\n\nThree phone calls to H. Hunter turned up Harold, Heidi, and Hilda Hunter. “Hi,\nare you interested in a free subscription to _Computer Reviews_?” No dice.\nNone of them said they cared about computers.\n\nWhat does a physics lab in Berkeley have in common with an army depot in\nAnniston, Alabama? You couldn’t find more politically opposite locations: a\ngood-old-boy Army base and a radical hippie town. Yet technically, we shared\nquite a bit. Both our computers ran Unix and connected through the Milnet\nnetwork.\n\nBut wait—Anniston’s system ran AT&T Unix, not the Berkeley dialect. If I\nbelieved Dave Cleveland, then the hacker was at home on Anniston’s system.\nMight it be a Southern hacker?\n\n\n![](images/Stol_9780307819420_epub_009_r1.jpg) I couldn’t stand the sterile,\nfluorescent lighted halls of the lab anymore, so I went outside to look at the\npanoramic view of the Bay Area below me. The Berkeley campus lay directly\nbeneath my laboratory. Once the home of the free speech movement and antiwar\nprotests, the campus is still known for its wild politics and ethnic\ndiversity. If I were a little closer, I could probably hear the Young\nRepublicans baiting the Socialist Workers, while the Chinese Club looked on in\namazement.\n\nSmoky coffeehouses crowded next to the campus, where haggard grad students\nscribbled their theses, fueled by espresso. At nearby ice cream shops,\ngiggling sorority girls mingled with punks in black leather and spiked hair.\nBest of all—Berkeley’s bookstores.\n\nFrom the front of the lab, I could look farther south, to the pleasant streets\nof north Oakland, where we lived. There I shared an old bungalow with an\nassortment of zany roommates. Across the bay, shrouded by fog, was San\nFrancisco—Oz.\n\nThree years ago, Martha had moved here to study law and I’d tagged along.\nShe’d been worth crossing the country for. She was a damned good hiking\npartner and caver. I first met her when I fell thirty feet inside a cave; she\ncame to the rescue, rapelling down to where I lay incapacitated by a bad\nsprain and utter infatuation. My injuries healed, thanks to her chicken soup;\nmy affection for the smart-aleck kid who climbed rocks so fearlessly ripened\ninto love.\n\nNow we lived together. She studied law, and actually enjoyed it. She didn’t\nwant to be a lawyer, but a legal philosopher. Somehow, she had time left over\nto practice aikido, a Japanese martial art, and often came home bruised but\ngrinning. She cooked, gardened, pieced quilts, did carpentry, and made stained\nglass windows. For all our zaniness, we wallowed in disgustingly wholesome\ndomestic bliss.\n\nI bicycled home and told Martha about the Alabama break-in, speculating about\nwho might be behind it.\n\n“So there’s technocratic vandals,” she said. “What else is new?”\n\n“That’s news in itself. Technicians now have incredible power to control\ninformation and communication,” I said.\n\n“So what? Somebody’s always had control over information, and others have\nalways tried to steal it. Read Machiavelli. As technology changes, sneakiness\nfinds new expressions.”\n\nMartha was still giving me a history lesson when Claudia bustled in,\ncomplaining about her fifth graders. Life in Berkeley usually includes a\nroommate or two. Claudia was ours, and a perfect one at that. She was generous\nand cheerful, eager to share her life, her music, and her kitchen gadgets with\nus. She was a professional violinist eking out a living by playing in two\nsymphony orchestras and a chamber music trio, and giving lessons to kids.\n\nClaudia was seldom still or quiet. In her few moments between jobs, she\nsimultaneously cooked meals, talked on the phone, and played with her dog.\n\nAt first I listened, but soon her voice became like the background chirp of a\nparakeet while I worried about how malicious this hacker might be. While I’m\nat home, how do I know what he’s up to?\n\nClaudia knew how to take my mind off the hacker: she brought home a video,\n_Plan 9 from Outer Space_ —aliens in tinfoil flying saucers drag vampires from\ngraves.\n\nWednesday, September 17, was a drizzly Berkeley day. As the only California\ncouple without a car, Martha and I had to bicycle through the rain. On my way\ninto the lab, I visited the switchyard, to check for any visits by the hacker.\nWater dripped off my sopping hair onto the printout, smudging the ink on the\npaper.\n\nSometime during the night, someone had connected to our computer, and\nmethodically tried to log into the Unix-4 computer. First they tried to log\ninto the Guest account, using the password “Guest.” Then they tried the\nVisitor account, with password “Visitor”; then accounts Root, System, Manager,\nService, and Sysop. After a couple of minutes, the attacker left.\n\nCould this be a different hacker? This guy didn’t even try valid accounts like\nSventek or Stoll. He simply tried obvious account names and simple passwords.\nI wondered how often such an attack might succeed.\n\nNot often—with six-letter passwords a hacker had a better chance of winning\nthe lottery than randomly guessing a particular password. Since the computer\nhangs up after a few log-in failures, the attacker would need all night to try\neven a few hundred possible passwords. No, a hacker couldn’t magically enter\nmy system. He’d need to know at least one password.\n\nBy 12:29, most of my clothes had dried off, though my sneakers still squished.\nI was part way into a soggy bagel, and most of the way through an astronomy\narticle about physics of the icy satellites of Jupiter. My terminal beeped.\nTrouble in the switchyard. A quick (though squeaky) trot down the hallway let\nme watch the hacker connect into our system as Sventek.\n\nAgain the adrenaline rush: I called Tymnet and quickly found Ron Vivier. Ron\nstarted the trace, and I huddled over the Decwriter, which now tapped out the\nhacker’s commands.\n\nThe hacker wasted no time. He issued commands to show all the active users and\nany background jobs running. He then fired up Kermit.\n\nNamed after the Muppet hero, Kermit is the universal language for connecting\ncomputers together. In 1980, Frank da Cruz of Columbia University needed to\nsend data to a number of different computers. Instead of writing five\ndifferent, incompatible programs, he created a single standard to exchange\nfiles between any systems. Kermit’s become the Esperanto of computers.\n\nAbsentmindedly chewing on a bagel, I watched as the hacker used Kermit to\ntransfer a short program into our Unix computer. Line by line, faithful Kermit\nreassembled it, and soon I could read the following program:\n\n**echo -n “WELCOME TO THE LBL UNIX-4 COMPUTER”**\n\n**echo -n “PLEASE LOG IN NOW”**\n\n**echo -n “LOGIN:”**\n\n**read account_name**\n\n**echo -n “ENTER YOUR PASSWORD:”**\n\n**(stty -echo; \\**\n\n**read password; \\**\n\n**stty echo; \\**\n\n**echo “ ”; \\**\n\n**echo $account_name $password » /tmp/.pub)**\n\n**echo “SORRY, TRY AGAIN.”**\n\nYikes! Now here was a strange program! This program, when installed in our\ncomputer, would prompt a user to enter his name and password. An ordinary user\nwho ran this program would see on his screen:\n\n**WELCOME TO THE LBL UNIX-4 COMPUTER**\n\n**PLEASE LOGIN NOW**\n\n**Login:**\n\nHis terminal would then wait until he entered his account name. After he typed\nhis name, the system responds:\n\n**ENTER YOUR PASSWORD:**\n\nAnd he’d naturally type in his password. The program then stashes the unlucky\nuser’s name and password into a file, tells the user,\n\n**“SORRY, TRY AGAIN”**\n\nand then disappears.\n\nThinking they’ve mistyped their passwords, most people will just try to log in\nagain. By then, their password will already have been stolen.\n\nFour thousand years ago, the city of Troy fell when Greek soldiers snuck in,\nhidden inside the Trojan horse.\n\nDeliver a gift that looks attractive, yet steals the very key to your\nsecurity. Sharpened over the millennia, this technique still works against\neveryone except the truly paranoid.\n\nThe hacker’s Trojan horse program collected passwords. Our visitor wanted our\npasswords badly enough to risk getting caught installing a program that was\nbound to be detected.\n\nWas this program a Trojan horse? Maybe I should call it a mockingbird: a false\nprogram that sounded like the real thing. I didn’t have time to figure out the\ndifference—within a minute, he was bound to install his program in the systems\narea, and start it running. What should I do? To disable it would show him\nthat I was watching him. Yet doing nothing would give him a new password every\ntime someone logged in.\n\nBut legitimate super-users have power, too. Before the hacker could run his\nprogram, I changed one line in it, making it look like he’d made a trivial\nerror. Then I diddled a couple system parameters to slow down the system. Slow\nenough that the hacker would need ten minutes to rebuild his program. Enough\ntime to let us respond to this new attack.\n\nI shouted down the hall for Guru Dave.\n\n“What do you feed a Trojan horse?”\n\nDave came running. We shifted the computer into high speed, and prepared a\nfodder of bogus accounts and false passwords.\n\nBut our panic wasn’t necessary. The hacker rebuilt his Trojan horse, but\ndidn’t install it properly. Dave instantly realized that it had been placed in\nthe wrong directory. His Trojan horse would be happy in standard AT&T Unix,\nbut couldn’t cavort in the fields of Berkeley Unix.\n\nDave grinned. “I won’t say, ‘I told you so,’ but we’re watching someone who’s\nnever been to California. Every Unix jockey on the West Coast would use\nBerkeley style commands, yet your hacker’s still using AT&T Unix.”\n\nDave descended from his tower to explain what he meant. “The spelling of his\ncommands is different from Berkeley Unix. But so is the very feel of the\nprogram. Kinda like how you can tell that a writer is British rather than\nAmerican. Sure, you’ll see words like ‘colour’ and ‘defence,’ but you can feel\nthe style difference as well.”\n\n“So what’s the difference?” I asked.\n\nDave sneered, “The hacker used the command, ‘read’ to get keyboard data. Any\ncivilized programmer would use the ‘set’ command.” For Dave, civilized\ncomputers spoke Berkeley Unix. All others were uncouth.\n\nThe hacker didn’t realize this. Confident that he’d put his Trojan horse in\nthe right pasture, he ran it as a background process, and logged off. Before\nhe disconnected, Ron Vivier had traced the hacker through Tymnet’s network,\nand into an Oakland, California, telephone line. The dust hadn’t yet settled\non our court order, so we couldn’t start the phone trace.\n\nThe hacker had left, but his Trojan horse stayed behind, running as a\nbackground task. As Dave predicted, it collected no passwords, for it had been\ninstalled in a place that wasn’t referenced during log-in. Sure enough, twenty\nminutes later, the hacker reappeared, searched for a collection of passwords,\nand must have been disappointed to find his program had failed.\n\n“Look, Dave, the poor guy needs your help,” I said.\n\n“Right. Should we send him some electronic mail telling him how to write a\nTrojan horse program that works?” Dave replied.\n\n“He’s got the basics right—imitating our log-in sequence, asking for the\nusername and password, then storing the stolen information. All he needs is a\nfew lessons in Berkeley Unix.”\n\nWayne stopped by to watch the hacker flounder. “Aw, what do you expect?\nThere’s just too many varieties of Unix. Next time make it easier on those\ninept hackers, and give them Digital’s VMS operating system. It might not be\neasier to hack, but at least it’s standardized. IOTTMCO.” Intuitively obvious\nto the most casual observer.\n\nWayne had a good point. The hacker’s Trojan horse attack had failed because\nthe operating system wasn’t exactly what he was accustomed to. If everyone\nused the same version of the same operating system, a single security hole\nwould let hackers into all the computers. Instead, there’s a multitude of\noperating systems: Berkeley Unix, AT&T Unix, DEC’s VMS, IBM’s TSO, VM, DOS,\neven Macintoshes and Ataris. This variety of software meant that no single\nattack could succeed against all systems. Just like genetic diversity, which\nprevents an epidemic from wiping out a whole species at once, diversity in\nsoftware is a good thing.\n\nDave and Wayne continued bickering as they left the switchyard. I hung around\na few more minutes, reloading paper. At 1:30 P.M., the hacker reappeared; I\nwas still adjusting the printer when he started typing.\n\nThis second session was predictable. Our visitor looked at his special file\nfor passwords and found none. He listed his Trojan horse program and tested it\na couple times. It didn’t work. Apparently, he didn’t have a Dave Cleveland\nfor help. Obviously frustrated, he erased the file and logged off in a couple\nminutes.\n\nBut even though he’d been on for only a few minutes, Tymnet managed to trace\nhim, again into Oakland. Ron Vivier, who’d traced Tymnet’s connections,\napparently welcomed any emergency that might extricate him from a meeting, so\nhe jumped when I called. If we could only get the phone company to continue\nthe trace, we could wrap up everything in a couple days.\n\nDave felt he could exclude anyone coming from the West Coast. Chuck in\nAnniston suspected a hacker from Alabama. Tymnet’s traces pointed to Oakland.\n\nMe? I didn’t know.\n\n\n![](images/Stol_9780307819420_epub_010_r1.jpg) Our Tymnet traces reached into\nOakland, at various times the home of Jack London, Ed Meese, and Gertrude\nStein. A twenty-minute bike ride from the Berkeley campus led to the Oakland\nParamount Theater, with its sublime art-deco architecture and eye-popping\nmurals. A few blocks away, in the basement of an ugly modern building, Tymnet\nrents space for fifty dialup modems. Ron Vivier had traced the hacker from our\nlab into this bank of modems. Now it was my local telephone company’s turn.\n\nA two-inch-thick cable runs under Broadway, connecting Tymnet’s modems to an\nunmarked, windowless building. There, Pacific Bell’s Franklin office houses an\nelectronic switch to handle ten thousand telephone lines in area code 415 with\nthe prefix 430. Tymnet leases fifty of these lines.\n\nFrom somewhere, the hacker had dialed 415/430-2900. The path to our mysterious\nvisitor led to Pac Bell’s ESS-5 switch.\n\nAcross San Francisco Bay, Lee Cheng’s office overlooks a grungy alley off\nMarket Street. Lee is Pac Bell’s bloodhound; from his office or up on a\ntelephone pole, he traces phone lines.\n\nLee’s degree is in criminology, and his graduate work is in accident\nreconstruction and causation. But eight years of telephone tracing gives him\nan engineer’s view of the phone company and a cop’s view of society. To him,\ncommunities are split by area codes, exchanges, and trunk lines, as well as\nprecincts and neighborhoods.\n\nWith advance warning, Lee starts a software program in the computer that runs\nthe telephone exchange. At the switching control center, he logs onto the ESS\nmaintenance channel, brings up line-condition-monitoring software, and starts\na trap program.\n\nThe automatic trap program monitors the status of an individual telephone\nline. It records the date, time, how many rings before an answer, and where\nthe call came from.\n\nIf the call came from a nearby phone—one from the same exchange—then the trace\nis complete, and Lee’s job is easy. More often, the call comes from another\nexchange, and Lee has to coordinate traces at perhaps five different phone\nexchanges.\n\nWhen a technician at an exchange receives a trace call, he drops what he’s\ndoing—Lee’s traces take precedence over everything except firefighting. He\nlogs into the control computer, commands his computer to display the phone\nnumber’s status (busy, idle, off-hook), and executes programs to show where\nthe connection came from (routing index, trunk group number, adjacent exchange\nname).\n\nWith luck, the trace might take a few seconds. But a few exchanges, left over\nfrom the 1950s, still use mechanical-stepping switches. When you dial through\nthese exchanges, you can hear a soft pulsing in the background, as relays move\na lever in tune with your dialing. The old grackles of the telephone system\nare proud of these antiques, saying, “They’re the only switches that’ll\nsurvive a nuclear attack.” But they complicate Lee’s job: he’s got to find a\ntechnician to run from rack to rack tracing these calls.\n\nLocal telephones can only be traced while connected. Once you hang up, the\nconnection evaporates and can no longer be traced. So Lee races against time\nto finish a trace before the connection is lost.\n\nPhone companies view phone traces as a waste of time. Only their most skilled\ntechnicians know how to trace a phone connection. Worse, traces are expensive,\ngenerate lawsuits, and upset customers.\n\nLee, of course, sees things otherwise. “Yesterday was a drug bust, today, it’s\nan extortion racket, tomorrow we’re tracing a burglary ring. Obscene phone\ncalls around the full moon. Lately, we’ve been tracing call girls’ pocket\npagers. Slice of life in the big city.” Still, the fear of lawyers keeps him\nfrom unofficially helping out.\n\nOur conversation in September 1986 was curt:\n\n“Hey, we need a telephone line traced.”\n\n“Got a search warrant?”\n\n“No, do we need one?”\n\n“We won’t trace without a warrant.”\n\nThat was quick. No progress until Aletha Owens got the court order.\n\nAfter yesterday’s attack, we couldn’t wait. My searches through the phone book\nwere leading nowhere. A more competent Trojan horse would panic my boss into\nclosing down the investigation. And my three-week allowance was down to ten\ndays.\n\nSandy Merola was Roy Kerth’s sidekick. When Roy’s acid tongue got to one of\nthe staff, Sandy applied balm. On a mission to the Berkeley campus, Sandy\nnoticed a set of IBM personal computers in a public section of the library.\nLike any computer jock would do, he wandered over and tried to use them. Just\nas he suspected, these computers were programmed to automatically dial Tymnet\nand log into the Dow Jones Information Service.\n\nTymnet? Sandy spent a few minutes diddling on the terminal, and discovered\nthat he could find the latest stock quotations and financial rumors from _The\nWall Street Journal_. More important, when he signed off the Dow Jones\nservice, the terminal prompted him for, “Tymnet username?” Seemed like nothing\nto lose by trying, so he entered, “LBL.” Sure enough, Sandy connected to my\nlab’s computers.\n\nMaybe these public terminals explained things. Anyone could use them; they\ndialed the Oakland Tymnet number; and the library was all of a hundred feet\naway from Cory Hall, where the Berkeley Unix jockeys hang out.\n\nSandy was a jogger the way some people are Catholics. He trotted up Cardiac\nHill and told the police of his discovery. Here was a way to avoid a phone\ntrace—the next time the hacker appeared, we’d just duck over to the library\nand grab the bastard. We didn’t even need a court order.\n\nSandy returned from the police station, still sweating. He caught me\npracticing a yo-yo trick.\n\n“Cut the clowning, Cliff. The police are all set to run over to the campus and\narrest whoever’s using those terminals.”\n\nBeing more accustomed to parking tickets and medical emergencies, the LBL\npolice don’t understand computers and are pretty wary of telephone traces. But\nthey had no problem with busting someone breaking into a computer.\n\n“Hadn’t we better make sure that it’s the hacker, first?” I had visions of\nsome undercover cops staking out a terminal and dragging a librarian into the\npaddy wagon for checking the Dow Jones industrials.\n\n“It’s easy. Call me the next time the hacker shows up. I’ll drive down to the\nlibrary with the police, and we’ll see what’s on the screen. If it’s data from\nLBL, then we’ll leave it to the police.”\n\n“Are they gonna stake out the terminal? You know, like in ‘Dragnet’? With one-\nway mirrors and binoculars?”\n\n“Huh? Be serious, Cliff.” Sandy jogged away. I guess scientists are graded in\nseriousness. It reminded me of when I’d filed a student health report, listing\nunder complaints, “Potato Famine.” The doctor called me aside and lectured me,\n“Son, we take health seriously around here.”\n\nWe got our chance to test Sandy’s theory soon enough. Two days after his\nfailed Trojan horse, the hacker returned at 12:42 P.M. Lunch hour. The perfect\ntime for a Berkeley student to wander over to the library and use their\nterminals.\n\nAt the alarm, I called Sandy. Five minutes later, he appeared with two\nundercover police agents, wearing suits, ties, and winter coats. Nothing could\nbe more conspicuous on a campus of hippies on a hot summer day. I glimpsed a\nlarge revolver under one of the cop’s coats. They were serious.\n\nFor the next twenty-five minutes, the hacker didn’t do much. He became super-\nuser via the Gnu-Emacs hole, listed the day’s electronic mail, and scanned\nthrough our processes. Ron Vivier skipped lunch to trace the Tymnet connection\ninto Oakland. Any minute, I expected to see the printer suddenly stop,\nsignaling that Sandy and the constabulary had caught their man. But no, the\nhacker took his time and logged off at 1:20.\n\nSandy returned a few minutes later.\n\n“No luck, huh?” His face said it all.\n\n“Nobody was at the library’s terminals. Nobody even near them. Are you sure\nthe hacker was on?”\n\n“Yeah, here’s the printout. And Tymnet traced it into Oakland again.”\n\nSandy was let down. Our short cut hit a dead end: progress now depended on a\ntelephone trace.\n\n\n![](images/Stol_9780307819420_epub_011_r1.jpg) That evening, Martha was\nsupposed to be studying constitutional law, but was actually piecing a calico\nquilt. I came home discouraged: the library stakeout had seemed so promising.\n\n“Forget the hacker. You’re home now.”\n\n“But he might be in my system right now.” I was obsessing.\n\n“Well, there’s nothing you can do about it, then. Here, thread a needle and\nhelp with this seam.” Martha escaped law school by quilting; surely it would\nwork for me as well. After twenty minutes of silence, while she studied, my\nsewing started to get crooked.\n\n“When we get the warrant, we’ll have to wait until the hacker shows up. For\nall we know, that’ll be at 3 A.M., and nobody will be around.”\n\n“I said, forget the hacker. You’re home now.” She didn’t even look up from her\nbook.\n\nSure enough, the hacker didn’t show up the next day. But the search warrant\ndid. It was legal now. Of course, I couldn’t be trusted to start anything as\nimportant as a phone trace: Roy Kerth was explicit that only he was to talk to\nthe police.\n\nWe went through a couple dry runs, making sure we knew who to call and\nchecking that we could unwind our own local network. Then I got bored and went\nback to writing some software to analyze optical formulas for an astronomer.\n\nIn the afternoon, Roy called our systems people and operators together. He\nlectured us about the need to keep our traces secret—we didn’t know where the\nhacker was coming from, so we mustn’t mention our work to anyone outside the\nlab. I figured that people would talk less if they knew what was going on, so\nI gave a chalk talk about what we’d seen and where we were heading. Dave\nCleveland chipped in about the Gnu-Emacs hole, and Wayne pointed out that we’d\nbetter discuss the hacker strictly by voice, since he regularly read our\nelectronic mail. The meeting broke up with Boris and Natasha imitations.\n\nTuesday, at 12:42 in the afternoon, Sventek’s account lit up. Roy called the\nlaboratory police—they wanted to be in charge of the phone traces. By the time\nTymnet had unwound their network, Roy was shouting over the phone. I could\nhear his side of the conversation.\n\n“We need a number traced. We have the search warrant. Now.”\n\nSilence for a moment. Then he exploded.\n\n“I don’t give a damn about your problems!! Start the trace now!”\n\nMore silence.\n\n“If you don’t get a trace immediately, you’ll hear about it from the Lab\ndirector.” Roy slammed down the receiver.\n\nThe boss was furious—his face turned purple. “Damn our police! They’ve never\nhandled a phone trace, and they don’t know who to call at the phone company!”\nSheesh. At least his anger was aimed elsewhere.\n\nPerhaps it was for the best. The hacker disconnected within a couple minutes,\nafter just listing the names of the active users. By the time the phone trace\nwas started, there’d be no connection to trace.\n\nWhile the boss cooled off, I took the printout to study. There wasn’t much to\nsummarize in my logbook. The hacker had just logged in, listed the users, then\nlogged off. Didn’t even check the mail.\n\nAah! I saw why he logged off so fast. The system operator was around. The\nhacker must know the sysops’s name. He had raised periscope, seen the enemy,\nthen disappeared. Sure enough, looking back to other printouts, he stayed\naround only when no operators were around. Paranoid.\n\nI talked with each of our operators, explaining this discovery. From now on,\nthey would run the system covertly, using pseudonyms.\n\nSeptember 16 marked the end of the second week on the trail. I tried working\non optics again, but my mind kept drifting to the printouts. Sure enough, just\nafter noon, my terminal beeped: the hacker had returned.\n\nI called Tymnet, and then the boss. This time, we set up a conference call,\nand I listened to the trace as I watched the hacker walk through our system.\n\n“Hi, Ron, it’s Cliff. We need another trace on our Tymnet line, LBL, Tymnet\nnode 128, port 3.”\n\nA minute of fumbling on the other end.\n\n“Looks like it’s the third modem in our block of 1200-baud lines. That would\nmake it line 2903. That’s 415/430-2903.”\n\n“Thanks, Ron.” The police heard this, and relayed it to Lee Cheng at the phone\ncompany.\n\n“That’s coming from the Franklin switch. Hold on.” I was accustomed to being\nput on hold by the phone company.\n\nI watched the hacker fire up the Gnu-Emacs move-mail file. He was becoming\nsuper-user. He’d be on for at least another ten minutes. Maybe long enough to\ncomplete a trace. Come on, Pac Bell!\n\nThree minutes passed by. Lee came back on line.\n\n“The line’s active, all right. Connects to a trunk leading into Berkeley. I’ve\ngot a technician checking that line right now.”\n\nAnother two minutes pass by. The hacker’s super-user now. He goes straight for\nthe system manager’s mail files.\n\n“The Berkeley technician shows the line connecting to AT&T long lines. Hold\non.” But Lee doesn’t punch hold, and I listen in on his conversation with the\nBerkeley office. The guy in Berkeley insists that the line’s coming from far\naway; Lee’s telling him to check it again. Meanwhile the hacker is working on\nour password file. Editing it, I think, but I’m trying to hear what’s\nhappening at the phone company.\n\n“It’s our trunk group 369, and damn it, that’s routed to 5096MCLN.” The\nBerkeley technician was speaking in tongues.\n\n“OK, I guess we’ll have to call New Jersey.” Lee seemed dismayed. “Cliff, are\nyou still there?”\n\n“Yeah. What’s going on?”\n\n“No matter. Is he going to stay on much longer?”\n\nI watched the printout. The hacker left our password file and was cleaning up\nhis temporary files.\n\n“I can’t tell. My guess is—oops, he’s logged off.”\n\n“Disconnected from Tymnet.” Ron Vivier had been quiet until now.\n\n“Dropped off the phone line.” Lee’s trace disappeared.\n\nOur police officer came on line. “Well, gentlemen, what’s the story?”\n\nLee Cheng spoke first. “I think the call’s coming from the East Coast. There’s\na slight chance that it’s a local Berkeley call, but … no, it’s from AT&T.”\nLee was thinking out loud, like a graduate student at an oral exam. “All our\nPacific Bell trunk lines are labeled with three digits; only the longdistance\ntrunks have four-digit identifiers. That line … let me look it up.”\n\nI heard Lee type into his computer.\n\nLee came back in a minute. “Hey, Cliff, do you know anyone in Virginia? Maybe\nNorthern Virginia?”\n\n“No. There’s no particle accelerators near there. Not even a physics lab. Of\ncourse, my sister’s there …”\n\n“Think your sister’s breaking into your computer?”\n\nYeah, sure. My sister was a tech writer for the goddamn Navy. She even\nattended night school at the Navy War College.\n\n“If she is,” I replied, “I’m the pope of San Francisco.”\n\n“Well then, we can’t go any further today. Next time, I’ll make the trace\nfaster.”\n\nIt was hard to imagine a faster trace. I’d taken five minutes getting everyone\non line. Ron Vivier had spent two minutes tracing the call through Tymnet; it\nhad taken Lee Cheng another seven minutes to snake through several telephone\nexchanges. In a shade under a quarter hour, we’d traced the hacker through a\ncomputer and two networks.\n\nHere was a conundrum. Sandy Merola felt the hacker came from the Berkeley\ncampus. Dave Cleveland was certain he came from anywhere except Berkeley.\nChuck McNatt from Anniston suspected someone from Alabama. The Tymnet trace\nled to Oakland, California. Now Pacific Bell said Virginia. Or was it New\nJersey?\n\nWith each session my logbook grew. It wasn’t enough to just summarize what had\nhappened. I began to annotate each printout and search for correlations\nbetween sessions. I wanted to know my visitor: understand his wishes, predict\nhis moves, learn his name, and find his address.\n\nWhile trying to coordinate the traces, I’d pretty much ignored what the hacker\nwas actually doing. After the tension died down, I hid in the library with the\nprintout from his most recent connection.\n\nRight off, it was obvious that the fifteen minutes which I’d watched were only\nthe coda of the hacker’s work. For two hours, he had been connected to our\nsystem; I’d only noticed him during the last quarter hour. Damn. If only I’d\ndetected him right away. Two hours would have been enough to complete a trace.\n\nMore damning, though, was why I hadn’t noticed him. I’d been watching for\nactivity on Sventek’s account, but he had used three other accounts before\ntouching Sventek’s account.\n\nAt 11:09 in the morning, some hacker had logged into an account belonging to a\nnuclear physicist, Elissa Mark. This account was valid, billed to the nuclear\nsciences department, though its owner had been on sabbatical at Fermilab for\nthe past year. It took just one phone call to find that Elissa was unaware of\nanyone using her computer account; she didn’t even know if it still existed.\nWas this the same hacker that I’d been following? Or someone else?\n\nI had no way of knowing in advance that the Mark account had been hacked. But\npaging through the printout left little doubt.\n\nWhoever was using the Mark account had become super-user by crawling through\nthe Gnu-Emacs hole. As system manager, he searched for accounts that hadn’t\nbeen used in a long time. He found three: Mark, Goran and Whitberg. The latter\ntwo belonged to physicists long departed from our lab.\n\nHe edited the password file and breathed life into the three dead accounts.\nSince none of these accounts had been deleted, all their files and accounting\ninformation remained valid. To steal these accounts, the hacker needed to\nlearn their passwords. But the passwords were protected by encryption: our DES\ntrapdoor functions. No hacker could cut through that armor.\n\nWith his purloined super-user powers, the hacker edited the system-wide\npassword file. He didn’t try to decrypt Goran’s encrypted password, instead,\nhe erased it. Now that the account had no password, the hacker could log in as\nGoran.\n\nWith this he disconnected. What’s he up to? He couldn’t crack passwords, but\nas super-user, he didn’t have to. He just edited the password file.\n\nHe reappeared a minute later as Goran, then chose a new password for this\naccount—Benson. The next time Rodger Goran tried to use our Unix computer,\nhe’d be frustrated to find his old password no longer worked.\n\nOur hacker had stolen another account.\n\nAah—here’s why the hacker stole old accounts. If he stole active accounts,\npeople would complain when their familiar passwords no longer worked. So my\nadversary stole old accounts that weren’t used anymore. Robbing the dead.\n\nEven as super-user, he couldn’t undo the DES trapdoor. So he couldn’t figure\nout someone else’s password. But he could swipe passwords, with a Trojan\nhorse, or steal a whole account, by changing the password to a new word.\n\nHaving stolen the Goran account, he then grabbed the Whitberg account. The\nhacker now controlled at least four accounts, Sventek, Whitberg, Goran, and\nMark, on two of our Unix computers. How many other accounts did he hold? On\nwhich other systems?\n\nWhile running under Whitberg’s pseudonym, the hacker tried to connect through\nour Milnet link into three Air Force systems. After waiting a minute for those\ndistant computers to respond, he gave up, and started listing files belonging\nto LBL folks. He grew tired of this after reading a few scientific papers,\nseveral boring research proposals, and a detailed description of how to\nmeasure the nuclear cross section of some beryllium isotope. Yawn. Breaking\ninto computers sure wasn’t the key to power, fame, and the wisdom of the ages.\n\nGetting into our two Unix systems hadn’t satisfied my voracious foe. He’d\ntried hurdling the moat around our secured Unix-8 computer, but failed—Dave\nhad sealed off that machine. Frustrated at this, he printed a list of remote\ncomputers available from our site.\n\nNothing secret there, just the names, phone numbers, and electronic addresses\nfor thirty Berkeley computers.\n\n\n![](images/Stol_9780307819420_epub_012_r1.jpg) With the full moon, I expected\nmore hacking and planned on sleeping under the desk. The hacker didn’t show up\nthat evening, but Martha did. Around seven, she biked up, bringing a thermos\nof minestrone and some quilting to keep me occupied. There’s no shortcut to\nhand stitching a quilt. Each triangle, square, and parallelogram must be cut\nto size, ironed, assembled, and sewn to its neighbors. Up close, it’s hard to\ntell the pieces from the scraps. The design becomes visible only after the\nscraps are discarded, and you stitch the pieces together. Hmmm. A lot like\nunderstanding this hacker.\n\nAround 11:30, I gave up my watch. If the hacker wanted to show up at midnight,\nthe printers would catch him anyway.\n\nThe next day, the hacker turned up once. I missed him, preferring to share\nlunch with Martha just off campus. It was worth it: on a street corner, a jazz\nband played 1930s tunes.\n\nThe singer belted out some ’30s ditty, “Everybody loves my baby, but my baby\nloves nobody but me.”\n\n“That’s absurd,” Martha said between tunes. “Logically analyzed, the singer\nmust be his own baby.”\n\n“Huh?” It sounded fine to me.\n\n“Look. ‘Everybody’ includes my baby. Since ‘Everybody loves my baby,’ then my\nbaby loves herself. Right?”\n\n“Uh, yeah.” I tried to follow.\n\n“But then he says, ‘My baby loves nobody but me.’ So my baby, who must love\nherself, cannot love anyone else. Therefore, my baby must be me.”\n\nShe explained it twice before I understood. The singer had never learned\nelementary logic. Neither had I.\n\nBy the time I returned from lunch, the hacker was long gone, leaving his trail\non a paper printout.\n\nFor once, he didn’t become super-user. Yes, in his paranoid way, he checked\nfor systems people and monitoring processes, but he didn’t sneak through the\nhole in the operating system.\n\nInstead, he went fishing over the Milnet.\n\nA single isolated computer, out of communication with the world, is immune to\nattack. But a hermit computer has limited value; it can’t keep up with what’s\nhappening around it. Computers are of the greatest use when they interact with\npeople, mechanisms, and other computers. Networks let people share data,\nprograms, and electronic mail.\n\nWhat’s on a computer network? What do computers have to say to each other?\nMost personal computers satisfy the needs of their owners, and don’t need to\ntalk to other systems. For word processing, accounting spread-sheets, and\ngames, you really don’t need any other computers. But hook up a modem to your\ncomputer, and your telephone will report the latest from the stock market,\nnews wires, and rumor mills. Connecting to another computer gives you a\npowerful way to tune in the latest news.\n\nOur networks form neighborhoods, each with a sense of community. The high-\nenergy physics networks transfer lots of data about subatomic particles,\nresearch proposals, as well as gossip about who’s pushing for a Nobel prize.\nUnclassified military networks probably pass along orders for shoes, requests\nfor funding, and rumors of who’s jockeying for base commander. Somewhere, I’ll\nbet there are classified networks, to exchange secret military orders and top\nsecret gossip like who’s sleeping with the base commander.\n\nThese electronic communities are bounded by the limits of their communications\nprotocols. Simple networks, like public bulletin boards, use the simplest ways\nto communicate. Anyone with a personal computer and a telephone can link into\nthem. Advanced networks require leased telephone lines and dedicated\ncomputers, interconnecting hundreds or thousands of computers. These physical\ndifferences set boundaries between networks. The networks themselves are\nlinked together by gateway computers, which pass reformatted messages between\ndifferent networks.\n\nLike Einstein’s universe, most networks are finite but unbounded. There’s only\na certain number of computers attached, yet you never quite reach the edge of\nthe network. There’s always another computer down the line. Eventually, you’ll\nmake a complete circuit and wind up back where you started. Most networks are\nso complicated and interwoven that no one knows where all their connections\nlead, so most people have to explore to find their way around.\n\nOur lab’s computers connect to a dozen computer networks. Some of them are\nlocal, like the ethernet that ties computers in one building to a lab next\ndoor. Other nets reach to an extended community: the Bay Area Research Net\nlinks a dozen northern California universities. Finally, the national and\ninternational networks let our scientists connect to computers around the\nworld. But the premier network is the Internet.\n\nIn the mid 1950s, the Federal government started building the interstate\nhighway system, a twentieth-century marvel of pork-barrel public-works\npolitics. With memories of wartime transportation shortages, military leaders\nmade certain that the interstate system could handle tanks, military convoys,\nand troop carriers. Today, few think of interstate highways as a military\nsystem, though they’re just as capable of sending tanks across the country as\ntrucks.\n\nWith the same reasoning, the Department of Defense began developing a network\nto link military computers together. In 1969, the Defense Advanced Research\nProjects Agency’s (DARPA) experiments evolved into the Arpanet and then into\nthe Internet: an electronic highway interconnecting a hundred-thousand\ncomputers around the world.\n\nIn the world of computing, the Internet is at least as successful as the\ninterstate system. Both have been overwhelmed by their success, and everyday\ncarry traffic far beyond what their designers dreamt. Each regularly inspires\ncomplaints of traffic jams, inadequate routes, shortsighted planning, and\ninadequate maintenance. Yet even these complaints reflect the phenomenal\npopularity of what was an uncertain experiment only a few years ago.\n\nAt first, DARPA’s network was simply a testbed to prove that computers could\nbe linked together. Since it was seen as an unreliable experiment,\nuniversities and laboratories used it, and mainstream military people ignored\nit. After eight years, only a few hundred computers connected into the\nArpanet, but gradually, others were attracted by the network’s reliability and\nsimplicity. By 1985 the network directory listed tens of thousands of\ncomputers; today, there must be over one hundred thousand. Taking a census of\nnetworked computers would be like counting the cities and towns reachable from\nthe interstate system—it’s hard to name many places which can’t be reached via\nsome convoluted route.\n\nThe network’s growing pains have been reflected in name changes. The first\nArpanet was a backbone connecting random university, military, and defense\ncontractor computers. As military people grew to depend on the network for\ncarrying messages and mail, they decided to split the network into a military\nportion, the Milnet, and a research section, the Arpanet.\n\nBut there’s not much difference between the military and academic nets, and\ngateways let traffic flow between them. Indeed, any Arpanet user can connect\nto any Milnet computer without so much as an invitation. Together, the\nArpanet, Milnet, and a hundred other networks make up the Internet.\n\nThere are thousands of university, commercial, and military computers\nconnected through the Internet. Like buildings in a city, each has a unique\naddress; most of these addresses are registered at the Network Information\nCenter (NIC) in Menlo Park, California. Any one computer may have dozens or\nhundreds of people using it, so individuals as well as computers are\nregistered in the NIC.\n\nThe NIC’s computers provide a directory: just connect to the NIC and ask for\nsomeone, and it’ll tell you where they’re located. They don’t have much luck\nkeeping their database up to date (computer people change jobs often), but the\nNIC still serves as a good phone directory of computer people.\n\nDuring my lunch break, the hacker ducked into the NIC. Our printer quietly\nsaved the session as he searched the NIC for the abbreviation, “WSMR”:\n\n![](images/Stol_9780307819420_epub_013_r1.jpg)\n\nWSMR? White Sands Missile Range. With two commands and twenty seconds, he\nfound five computers at White Sands.\n\nAstronomers know Sunspot, New Mexico, as one of the finest solar\nobservatories. Clear skies and great telescopes make up for the utter\nisolation of Sacramento Peak, a few hundred miles south of Albuquerque. The\nonly road to the observatory runs through White Sands, where the Army tests\ntheir guided missiles. Once, when I was studying the solar corona, an\nobserving run took me to Sunspot, past the desolation of White Sands. The\nlocked gates and guardhouses discourage onlookers; if the sun doesn’t fry you,\nthe electric fences will.\n\nI’d heard rumors that the Army was designing rockets to shoot down satellites.\nSeemed like an SDI/Star Wars project, but civilian astronomers can only guess.\nMaybe this hacker knew more about White Sands than I did.\n\nNo doubt, though, that the hacker wanted to know more about White Sands. He\nspent ten minutes trying to log into each of their computers, connecting to\nthem over the Internet.\n\nThe printer recorded his steps:\n\n**LBL > telnet WSMR-NET-GW.ARMY.MIL** **Trying…** | connect to a White Sands computer  \n---|---  \n**Connected to WSMR-NET-GW.ARMY.MIL** |   \n**4.2 BSD UNIX** |   \n**Welcome to White Sands Missile Range** |   \n**login: guest** | Try the guest account  \n**Password: guest** | Guesses a password  \n**Invalid password, try again** | But no luck  \n**login: visitor** | Try another likely account name  \n**Password: visitor** |   \n**Invalid password, try again** | No luck  \n**login: root** | He tries yet another account  \n**Password: root** |   \n**Invalid password, try again** | Still no luck  \n**login: system** | And a fourth try  \n**Password: manager** |   \n**Invalid password, disconnecting after 4 tries** |   \n  \nFor each computer, he tried to log in as guest, visitor, root, and system. We\nsaw him failing, time after time, as he tried to guess passwords. Perhaps\nthose accounts were valid; the hacker couldn’t enter them because he didn’t\nknow the right passwords.\n\nI smiled at the printout. No doubt, the hacker wanted to get into White Sands.\nBut they didn’t fool around with security. Between their electric fences and\npasswords, neither tourist nor hacker could enter. Someone at White Sands had\nlocked their doors.\n\nWith a snicker, I showed his attempts to the boss, Roy Kerth.\n\n“Well, what do we do about it?” I asked. “Since he didn’t get into White\nSands, should we tell them?”\n\n“Hell, yes, we’ll tell them,” Roy responded. “If someone tries to break into\nmy neighbor’s house, I’ll tell ’em. I’ll call the cops, too.”\n\nI asked what cops were in charge of the Internet.\n\n“Damned if I know,” Roy said. “But here’s our policy, from here out: anyone\nthat’s attacked, we tell them. I don’t care if the hacker didn’t get in, you\ncall them on the phone and tell them. Remember, keep this out of electronic\nmail. And find out who the cops are.”\n\n“Yessir.”\n\nIt took only one phone call to find out that the FBI wasn’t policing the\nInternet. “Look, kid, did you lose more than a half million dollars?”\n\n“Uh, no.”\n\n“Any classified information?”\n\n“Uh, no.”\n\n“Then go away, kid.” Another attempt at rousing the feds had failed.\n\nMaybe the Network Information Center would know who policed their net. I\ncalled Menlo Park and eventually found Nancy Fischer. To her, the Internet\nwasn’t just a collection of cables and software. It was a living creature, a\nbrain with neurons extending around the world, into which ten thousand\ncomputer users breathed life every hour. Nancy was fatalistic: “It’s a\nminiature of the society around us. Sooner or later, some vandal’s going to\ntry to kill it.”\n\nIt seemed that there were no network police. Since the Milnet—now called the\nDefense Data Network—isn’t allowed to carry classified data, nobody paid much\nattention to its security.\n\n“You ought to be talking to the Air Force Office of Special Investigations,”\nshe said. “They’re the narcs of the Air Force. Drug busts and murders. Not\nexactly white-collar crime, but it can’t hurt to talk to them. I’m sorry I\ncan’t help you, but it’s really not my bailiwick.”\n\nThree phone calls later, I’m in a conference call with Special Agent Jim\nChristy of the AFOSI and Major Steve Rudd of the Defense Communications\nAgency.\n\nJim Christy made me nervous—he sounded like a narc. “Let me get this straight.\nSome hacker broke into your computer, then got into an Army computer in\nAlabama, and is now going for White Sands Missile Range?”\n\n“Yes, that’s about what we’ve seen.” I didn’t want to explain the Unix Gnu-\nEmacs security hole. “Our traces aren’t complete yet; he might be from\nCalifornia, Alabama, Virginia, or maybe New Jersey.”\n\n“Oh … you’re not shutting him out so that you can catch the bastard.” He was\nahead of me.\n\n“And if we close him out, he’ll just enter the Internet through some other\nhole.”\n\nSteve Rudd, on the other hand, wanted the hacker nailed. “We can’t let this\ncontinue. Even without classified information, the Milnet’s integrity demands\nthat spies be kept out.”\n\nSpies? My ears pricked up.\n\nThe narc spoke next. “I don’t suppose the FBI has lifted a finger.”\n\nI summarized our five calls to the FBI in one word.\n\nAlmost apologetically, Jim Christy told me, “The FBI isn’t required to\ninvestigate every crime. Probably they look at one in five. Computer crimes\naren’t easy—not like kidnapping or bank robbery, where there’s witnesses and\nobvious losses. Don’t blame them for shying away from a tough case with no\nclear solution.”\n\nSteve pressed Jim, “OK, so the FBI won’t do anything. How about AFOSI?”\n\nJim answered slowly, “We’re the Air Force computer crime investigators. We\nusually hear about computer crimes only after a loss. This is the first one\nthat we’ve come across in progress.”\n\nSteve cut in, “Jim, you’re a special agent. The only difference between you\nand an FBI agent is your jurisdiction. Doesn’t this fall in your court?”\n\n“It does. It’s a strange case that falls in several courts.” Over the phone, I\ncould almost hear Jim think. “We’re interested, all right. I can’t tell if\nthis is a serious problem or a red herring, but it’s well worth\ninvestigating.”\n\nJim continued, “Look, Cliff. Each agency has thresholds. Our resources are\nfinite so we’re forced to choose what we investigate. That’s why the FBI asked\nyou about the dollar loss—they’re looking to get the most bang for their\neffort. Now if classified stuff gets stolen, it’s a different story. National\nsecurity doesn’t equate to dollars.”\n\nSteve interrupted, “But unclassified information can also equate to national\nsecurity. The problem is convincing law enforcement people.”\n\n“So what’ll you do?” I asked.\n\n“Right now, there’s really not much we can do. If this hacker’s using the\nmilitary networks, though, he’s walking on our territory. Keep us informed and\nwe’ll sharpen our stingers.”\n\nIn hopes of encouraging AFOSI, I sent Jim a copy of my logbook, and samples of\nthe hacker’s printouts.\n\nAfter this conversation, Jim Christy explained about the Milnet. What I called\nthe Milnet, Jim knew as the unclassified Defense Data Network, run by the\nDefense Communications Agency. “The Department of Defense runs the Milnet for\nall the services—Army, Navy, Air Force, and Marines. That way, each service\nhas equal access to the network, and you’ll find computers from every branch\non the net.”\n\n“So why is Steve Rudd in the Air Force?”\n\n“He’s really a purple-suiter—he works for all three branches. Naturally, when\nhe smelled a problem, he called the Air Force investigators.”\n\n“And you work full time on computer crime?”\n\n“You betcha. We’re watching ten thousand Air Force computers.”\n\n“Then why can’t you wrap up this case in a snap?”\n\nJim spoke slowly, “We’ve got to clearly define our territory. Unless we do, we\nstep on each other’s toes. You, Cliff, have no worries that you’ll be busted\nby the OSI—our bailiwick is the Air Force base.”\n\nBailiwicks always belong to someone else.\n\nYou know, much as I complained about bailiwicks, I realized that they\nprotected my own rights: our constitution prevents the military from grubbing\naround civilian affairs. Jim had put this into a new light—sometimes these\nrights actually do interfere with law enforcement. For the first time, I\nrealized that my civil rights actually limit what police can do.\n\nWhoops. I’d forgotten the boss’s instructions to call White Sands. Another few\nminutes on the phone, and I reached Chris McDonald, a civilian working for the\nmissile range.\n\nI outlined the case—Unix, Tymnet, Oakland, Milnet, Anniston, AFOSI, FBI.\n\nChris interrupted, “Did you say Anniston?”\n\n“Yes, the hacker was super-user at Anniston Army Depot. It’s a little place in\nAlabama, I think.”\n\n“I know Anniston, all right. They’re our sister Army base. After we test our\nmissiles, we ship ’em off to Anniston,” Chris said. “And their computers come\nfrom White Sands as well.”\n\nI wondered if this was just coincidence. Perhaps the hacker had read data in\nthe Anniston computers, and realized that the good stuff came from White\nSands. Maybe the hacker was sampling every site where the Army stored\nmissiles.\n\nOr maybe the hacker had a list of computers with security holes. “Say, Chris,\ndo you have Gnu-Emacs on your computers?”\n\nChris didn’t know, but he’d ask around. But to exploit that hole, the hacker\nhad to log in first. And the hacker had failed, after trying four times on\neach of five computers.\n\nWhite Sands kept their doors locked by forcing everyone on their computers to\nuse long passwords, and to change them every four months. A technician wasn’t\nallowed to choose her own password—the computer assigned unguessable\npasswords, like “agnitfom” or “nietoayx.” Every account had a password, and\nnone could be guessed.\n\nI didn’t like the White Sands system. I couldn’t remember computer-generated\npasswords, so I’d write them in my wallet or next to my terminal. Much better\nto allow people to choose their own passwords. Sure, some people would pick\nguessable passwords, like their names. But at least they wouldn’t complain\nabout having to memorize some nonsense word like “tremvonk,” and they wouldn’t\nwrite them down.\n\nBut the hacker got into my system and was rebuffed at White Sands. Maybe\nrandom passwords, obnoxious and dissonant, are more secure. I don’t know.\n\nI’d followed the boss’s orders. The FBI didn’t care about us, but the Air\nForce sleuths were on the case. And I’d notified White Sands that someone was\ntrying to break in. Satisfied, I met Martha at a vegetarian pizza stand. Over\nslices of thick-crust spinach and pesto, I described the day’s events.\n\n“Vell, Natasha, we have accomplished mission one.”\n\n“Vonderful, Boris, vhat a victory. Boris … vhat is mission one?”\n\n“We have made rendezvous vith ze secret air force police, Natasha.”\n\n“Yes, Boris?”\n\n“Ve have alerted ze missile base to ze counter-counter-intelligence efforts.”\n\n“Yes, Boris?”\n\n“And we have ordered ze secret spy pizza.”\n\n“But Boris, ven do we catch ze spy?”\n\n“Patience, Natasha. Zat is mission two.”\n\nIt wasn’t until we started walking home that we got to the serious side of our\ngame.\n\n“This thing is getting weirder and weirder,” Martha said. “It started out as a\nhobby, chasing some local prankster, and now you’re talking to these military\npeople who wear suits and have no sense of humor. Cliff, they’re not your\ntype.”\n\nI defended myself stuffily, “This is a harmless and possibly beneficial\nproject to keep them busy. After all, this is what they’re supposed to be\ndoing—keeping the bad guys out.”\n\nMartha wouldn’t let that sit. “Yeah, but what about you, Cliff. What are you\ndoing hanging out with these people? I understand that you have to at least\ntalk to them, but how deeply are you getting involved?”\n\n“Every step makes perfect sense from my point of view,” I said. “I’m a system\nmanager trying to protect my computer. If someone hacks into it, I have to\nchase him. To ignore the bastard will let him wreck other systems. Yes, I’m\ncooperating with the Air Force police, but that doesn’t mean I approve of\neverything the military stands for.”\n\n“Yes, but you have to decide how you want to live your life,” Martha said. “Do\nyou want to spend your time being a cop?”\n\n“A cop? No, I’m an astronomer. But here’s someone threatening to destroy our\nwork.”\n\n“We don’t know that,” Martha retorted. “Maybe this hacker is closer to us\npolitically than those security people. What if you’re chasing someone on your\nown side? Perhaps he’s trying to expose problems of military proliferation.\nSome sort of electronic civil disobedience.”\n\nMy own political views hadn’t evolved much from the late 1960s … a sort of\nfuzzy, mixed bag of the new-left. I’d never thought much about politics,\nfeeling that I was a harmless non-ideologue, trying to avoid unpleasant\npolitical commitments. I resisted radical left-wing dogma, but I sure wasn’t a\nconservative. I had no desire to buddy up with the feds. Yet here I was,\nwalking side by side with the military police.\n\n“About the only way to find out who’s at the other end is to trace the wires,”\nI said. “These organizations may not be our favorites, but the particular\nactions that we’re cooperating over aren’t bad. It’s not like I’m running guns\nto the Contras.”\n\n“Just watch your step.”\n\n\n![](images/Stol_9780307819420_epub_014_r1.jpg) My three weeks were almost up.\nIf I didn’t catch the hacker within twenty-four hours, the lab would shut down\nmy tracking operation. I camped out in the switchyard, jumping at every\nconnection. “Come into my parlor,” said the spider to the fly.\n\nSure enough, at 2:30 in the afternoon, the printer advanced a page, and the\nhacker logged in. Although this time he used the stolen account, _Goran_ , I\ndidn’t doubt that it was the hacker: he immediately checked who was on the\ncomputer. Finding no operator present, he searched out the Gnu-Emacs security\nhole, and started his delicate minuet to become super-user.\n\nI didn’t watch. A minute after the hacker connected, I called Ron Vivier at\nTymnet and Lee Cheng at the phone company. I took notes as Ron mumbled, “He’s\ncoming into your port 14, and entering Tymnet from Oakland. It’s our port 322\nwhich is, uh, let me see here.” I could hear him tapping his keyboard. “Yeah,\nit’s 2902. 430–2902. That’s the number to trace.”\n\nLee Cheng popped on the phone line. “Right. I’m tracing it.” More keytaps,\nthis time with a few beeps thrown in. “That line is live, all right. And it’s\ncoming from AT&T. AT&T in Virginia. Hold on, I’ll call New Jersey.”\n\nI listened in as Lee talked with some AT&T guy named Edsel (or was it Ed\nSell?) in Whippany, New Jersey. Apparently, all of AT&T’s long-distance phone\nlines are traced through New Jersey. Without understanding the jargon, I\ntranscribed what I heard. “Routing 5095, no that’s 5096MCLN.”\n\nAnother technician’s voice broke in. “I’ll call McLean.”\n\nThe New Jersey technician came back. “Yeah. 5096 terminates in 703 land.”\n\nThere were suddenly six people on the line. The phone company’s conference\ncalls were crisp and loud. The newest member of the conference call was a\nwoman with a slight drawl. “Y’all are trunked into McLean, and it’s almost\ndinnertime here at C and P.”\n\nLee’s clipped voice interrupted her. “Emergency trace on routing code\n5096MCLN, your termination line 427.”\n\n“I copy 5096MCLN line 427. I’m tracing right now.”\n\nSilence for a minute, then she came back on line. “Here it comes, boys. Hey,\nit looks like it’s from 415 territory.”\n\n“Yeah. Greetings from San Francisco Bay,” Lee slid in.\n\nShe spoke to no one in particular. “Trunk group 5096MCLN, routing 427 winds up\nin 448. Our ESS4 at 448. Is it a PBX?” She answered her own question: “No,\nit’s a rotary. Frame twenty-four. I’m almost at the tip ring sleeve. Here we\nare. Five hundred pair cable, group three number twelve … that’s ten, uh, ten\nsixty. You want me to confirm with a short dropout?”\n\nLee interpreted her jargon. “She’s completed the trace. To make sure that\nshe’s traced the right number, she wants to turn off the connection for a\nsecond. If she does that, it’ll hang up the line. Is that OK?”\n\nThe hacker was in the midst of reading some electronic mail. I doubted that\nhe’d miss a few characters. “Sure. Tell her to go ahead, and I’ll see what\nhappens here.”\n\nLee talked with her a bit, and announced with certainty, “Stand by.” He\nexplained that each telephone line has a set of fuses in the central switching\noffice; they protect the equipment from lightning and idiots that plug their\nphone lines into power outlets. The central office technician can go to the\ncable room and pull the line’s fuse, forcing it to hang up. It wasn’t\nnecessary, but it double checked their tracing efforts.\n\nIn a minute, the central office tech came onto the line and said, “I’m popping\nthe fuse … now.” Sure enough, the hacker dropped off, right in the middle of a\ncommand. They’d traced the right line.\n\nThe woman’s voice came on. “It’s 1060, all right. That’s all, boys. I’ll\nshuffle some tissues and ship it on upstairs.”\n\nLee thanked everyone, and I heard the conference call clear. “The trace is\ncomplete and the technician’s writing it up. As soon as I get the trace data,\nI’ll give it to the police.”\n\nI didn’t understand. Why didn’t he just tell me the owner of the phone?\n\nLee explained that the telephone company dealt with the police, not with\nindividuals. Moreover, he didn’t know where the line had been traced to. The\ntech that completed the trace would fill out the proper papers (aah!\n“shuffling tissues”) and release them to the authorities.\n\nI protested, “Can’t you just short-circuit the bureaucracy and tell me who the\nhacker is?”\n\nNo. First, Lee didn’t have the trace information. The technician in Virginia\ndid. Until the Virginia phone company released it, Lee knew as little as I\ndid.\n\nLee pointed out another problem: my search warrant was only valid in\nCalifornia. A California court couldn’t compel the Virginia telephone company\nto turn over evidence. We’d need either a Virginia or Federal court order.\n\nI protested, “The FBI’s turned us down five times already. And the guy’s\nprobably not breaking any Virginia law. Look, can’t you give me the phone\nnumber on the side and just wink?”\n\nLee didn’t know. He’d call Virginia and try to convince them to give us the\ninformation, but he didn’t hold out much hope. Damn. At the other end of the\nphone line, someone was breaking into military computers, and we couldn’t even\nget his phone number, ten seconds after the line was traced.\n\nThe phone trace was complete, though not quite successful. How do we get a\nVirginia search warrant? My boss, Roy Kerth, was gone for the next couple\nweeks, so I called the lab’s lawyer directly. To my surprise, Aletha paid\nserious attention to the problem. She’d rattle the FBI again, and see whether\nwe had a case in Virginia. I warned her that, as a peon, I had no authority to\neven be talking to her, let alone asking for legal services. She reassured me,\n“Don’t be silly. This is more fun than worrying about patent law.”\n\nThe laboratory police wanted to know all about the phone trace. I told them to\nprepare to stake out the entire state of Virginia. Despite my cynicism, they\nwere surprisingly sympathetic to my problem with the Virginia search warrant,\nand offered to use their old-boy-network to get the information through some\ninformal channel. I doubted it would work, but why not let them try?\n\n\n![](images/Stol_9780307819420_epub_015_r1.jpg) The phone company might conceal\nthe hacker’s phone number, but my printers showed his every move. While I\ntalked to Tymnet and the telephone techs, the hacker had prowled through my\ncomputer. He wasn’t satisfied reading the system manager’s mail; he also\nsnooped through mail for several nuclear physicists.\n\nAfter fifteen minutes of reading our mail, he jumped back into Goran’s stolen\naccount, using his new password, _Benson_. He started a program that searched\nour user’s files for passwords; while that executed, he called up the Milnet\nNetwork Information Center. Again, he knew who he was looking for:\n\n![](images/Stol_9780307819420_epub_016_r1.jpg)\n\nHe had asked for the pathway into the CIA. But instead of their computer, he\nfound four people who worked at the CIA.\n\nWhee! I pictured all these CIA spies playing cloak-and-dagger; meanwhile,\nsomeone’s pushing on their backdoor.\n\nSo I asked myself, “Should I tell them?”\n\n“No. Why waste my time telling them? Let some spy run around in the CIA’s\nbackyard. See if I care. My three weeks of chasing the hacker are up. It’s\nabout time to shut our doors and work on real problems of physics and\nastronomy. He’s someone else’s problem now.”\n\nAnd yet it didn’t feel right. The hacker walked through military computers,\nyet nobody noticed. The CIA didn’t know. The FBI didn’t care. Who would pick\nup where we left off?\n\nI reached for the telephone to call the people listed in the CIA, then put it\ndown. What’s a long-haired hippie doing calling some spooks? What would Martha\nsay?\n\nWell, whose side was I on? Not the CIA’s, for sure. But then, I wasn’t rooting\nfor someone to break in there, either. At least I didn’t think so.\n\nFoo. The jerk was trying to slither into someone’s computer. Nobody else will\nwarn them, so I’d better. I’m not responsible for the CIA’s actions, only my\nown.\n\nBefore I could change my mind again, I called the first CIA guy’s phone\nnumber. No answer. The second guy was on vacation—his answering machine said\nso. The third person …\n\nA business voice answered, “Extension 6161.”\n\nI stammered a bit, “Um, hello, I’m looking for Ed Manning.”\n\n“Yes?”\n\nI didn’t know where to begin. How do you introduce yourself to a spy? “Uh, you\ndon’t know me, but I’m a computer manager, and we’ve been following a computer\nhacker.”\n\n“Uh-huh.”\n\n“Well, he searched for a pathway to try to get into the CIA’s computers.\nInstead, he found your name and phone number. I’m not sure what this means,\nbut someone’s looking for you. Or maybe they’re just looking for the CIA and\nstumbled on your name.” I’m floundering, scared of the guy I’m talking to.\n\n“Who are you?”\n\nNervously, I told him, expecting him to send over a gang of hit men in trench\ncoats. I described our laboratory, making sure he understood that the People’s\nRepublic of Berkeley didn’t have official diplomatic relations with his\norganization.\n\n“Can I send someone over tomorrow? No, that’s Saturday. How about Monday\nafternoon?”\n\nUh oh. The hit men were on their way. I tried to backpedal. “This probably\nisn’t serious. The guy didn’t find anything except four names. You don’t have\nto worry about him getting into your computer.”\n\nMr. Manning wasn’t convinced. “I know why my name’s listed. Last year I worked\non some computers at the Ballistics Research Lab. But we’re professionally\ninterested in this, and we’d appreciate a chance to learn more. Conceivably,\nthis might be a serious problem.”\n\nWho was I talking to? Weren’t these the people who meddle in Central American\npolitics and smuggle arms to right-wing thugs? Yet the guy I’d just talked to\ndidn’t sound like a villain. He seemed like an ordinary person concerned with\na problem.\n\nAnd why not set them on the trail of someone just as meddlesome and\ndestructive as I always thought _they_ were? Tracking down a real wrongdoer\nwould give the CIA something harmless, perhaps even beneficial, to do—keep\nthem out of trouble.\n\nIt was no use arguing. They needed to know, and I couldn’t see a good reason\nto avoid telling them. And talking to the CIA wouldn’t hurt anyone—it wasn’t\nlike shipping guns to a military dictator. After all, isn’t this what they’re\nlegitimately supposed to do: protect us from bad guys? If I don’t tell them\nwhat’s happening, who will?\n\nI couldn’t help comparing the CIA’s immediate reaction with the response I got\nfrom the FBI. Six calls for help, and a half dozen responses, “Go away, kid.”\n\nWell, I agreed to meet with his agents, provided they didn’t wear trench\ncoats.\n\n“Now I’ve put my foot in it,” I thought. “Not only am I talking to the CIA,\nbut I’m inviting them up to Berkeley. What’ll I tell my radical friends?”\n\n\n![](images/Stol_9780307819420_epub_017_r1.jpg) Windmill Quarry is just across\nthe Niagara River from Buffalo, New York, where I grew up. It’s a ten-mile\nbicycle ride, across the Peace Bridge to Canada and down a few winding roads\nto the finest swimming hole around. If you dodge the potholes and speak\npolitely to the U.S. and Canadian customs agents, you’ll have no problems.\n\nHigh school had just let out in June of 1968 when I biked over to Windmill\nQuarry for a Saturday swim. Two other friends and I wore ourselves out trying\nto swim to the raft in the middle of the water. Around six, we ran out of\nsteam, hopped on our bikes, and headed back to Buffalo.\n\nThree miles shy of the Peace Bridge, we were pedaling along the stony margins\nof a country road when a pickup truck crowded us off the roadside. Someone\nswore at us and tossed a half-empty can of Genessee beer, hitting our lead\nrider. She wasn’t hurt but all three of us were furious.\n\nWe were on our bikes. No way to catch up with the SOBs. Even if we could, what\nwould we do? We were three miles inside of Canada, after all. We were\npowerless, unable to retaliate.\n\nBut I’d caught a glimpse of the license plate. From New York State. Oh …\nthey’re returning to Buffalo, too. Then it hit me.\n\nI stopped at the first phone booth—luckily there was a directory—and called\nthe U.S. customs agents. “There’s a green Chevy pickup truck heading for the\nPeace Bridge,” I reported. “I’m not sure, but I think they’re carrying some\ndrugs.” The agent thanked me, and I hung up.\n\nThe three of us biked back at a leisurely pace. We got to the bottom of the\nbridge, looked over at the side of the road … and my heart sang! Sure enough,\nthere was that green pickup, hood up, seat pulled out, and two wheels removed.\nCustoms agents were crawling all over it, searching for drugs.\n\nAah. The sense of recovered dignity.\n\nYears ago, I hadn’t asked that clown to throw a beer can at us. Nor today had\nI asked this hacker to invade my computer. I didn’t want to track him around\nthe networks. I’d rather be doing astronomy.\n\nBut now that I’d evolved a strategy, I could only follow the hacker by being\nsneaky and tenacious. And by informing the few authorities that seemed to\ncare. Like the CIA.\n\nRoy was on vacation, so not only couldn’t he tell me to drop the investigation\nnow that my three weeks were up, but he couldn’t say anything about the CIA\nvisiting. His stand-in, Dennis Hall, was to greet the spooks.\n\nDennis is a tranquil, introspective Zen master whose job is to link small\ncomputers to Cray supercomputers. He sees networks as channels to slosh\ncomputing power from laboratories to desktops. Little computers should talk to\npeople; leave the number crunching to the mainframes. If your desktop\nworkstation’s too slow, then move the hard work into a bigger computer.\n\nIn a sense, Dennis is the enemy of computer centers. He wants people to use\ncomputers without the mumbo jumbo of programming. As long as there are\nsoftware wizards and gurus, Dennis won’t be satisfied with the distribution of\ncomputing power.\n\nHis is a world of ethernets, optical fibers, and satellite links. Other\ncomputer folks measure size in megabytes of memory, and speed in\nmegaflops—millions of floating-point-operations per second. To Dennis, size is\nmeasured by counting computers on your network; speed is measured in megabytes\nper second—how fast the computers talk to each other. The system isn’t the\ncomputer, it’s the network.\n\nDennis saw the hacker problem in terms of social morality. “We’ll always find\na few dodos poking around our data. I’m worried about how hackers poison the\ntrust that’s built our networks. After years of trying to hook together a\nbunch of computers, a few morons can spoil everything.”\n\nI didn’t see how trust had anything to do with it. “Networks are little more\nthan cables and wires,” I said.\n\n“And an interstate highway is just concrete, asphalt, and bridges?” Dennis\nreplied. “You’re seeing the crude physical apparatus—the wires and\ncommunications. The real work isn’t laying wires, it’s agreeing to link\nisolated communities together. It’s figuring out who’s going to pay for the\nmaintenance and improvements. It’s forging alliances between groups that don’t\ntrust each other.”\n\n“Like the military and universities, huh?” I said, thinking of the Internet.\n\n“Yes, and more. The agreements are informal and the networks are overloaded,”\nDennis said. “Our software is fragile as well—if people built houses the way\nwe write programs, the first woodpecker would wipe out civilization.”\n\nWith the CIA due in ten minutes, Dennis and I talked about what to say. I had\nno idea what they wanted, other than a listing of last Friday’s activity. I\ncould imagine them: some secret agent looking like James Bond, or a hit man\nspecializing in rubouts. Of course there’d be Mr. Big behind them all, pulling\nthe puppet strings. They’d all be in dark glasses and trench coats.\n\nDennis gave me instructions. “Cliff, tell them what we know, but don’t\nspeculate. Confine yourself to facts.”\n\n“ ’S’all reet. But suppose there’s a hit man with ’em, who wants to rub me out\nbecause I found that they’re spying on the military?”\n\n“Be serious.” Everyone told me to be serious. “And for once, be polite.\nThey’ve got enough problems without a raving Berkeley longhair. And skip the\nyo-yo tricks.”\n\n“Yes, Daddy. I’ll be good. I promise.”\n\n“Don’t worry about them. They’re like anyone else around here, except a bit\nmore paranoid.”\n\n“And a bit more Republican,” I added.\n\nOK, so they didn’t wear trench coats. Not even sunglasses. Instead, boring\nsuits and ties. I should have warned them to dress like the natives: beat-up\ndungarees and flannel shirts.\n\nWayne saw the four of them walk up the drive and flashed a message to my\nterminal: “All hands on deck. Sales reps approach through starboard portal.\nCharcoal-gray suits. Set warp speed to avoid IBM sales pitch.” If only he\nknew.\n\nThe four spooks introduced themselves. One guy in his fifties said he was\nthere as a driver, and didn’t give his name—he just sat there quietly the\nwhole time. The second spy, Greg Fennel, I guessed to be a computer jockey,\nbecause he seemed uncomfortable in a suit.\n\nThe third agent was built like a halfback. Teejay didn’t give his last name—or\ndid he conceal his first name? If anyone was the hit man, Teejay was. The\nfourth guy must be the bigwig: everyone shut up when he talked. Together, they\nlooked more like bureaucrats than spies.\n\nThe four of them sat quietly while Dennis gave them an overview of what we’d\nseen. No questions. I walked to the chalkboard and drew a diagram:\n\n![](images/Stol_9780307819420_epub_018_r1.jpg)\n\nGreg Fennel wouldn’t let me get away with just a drawing. “Prove the\nconnection from the phone company to Tymnet.”\n\nI described the phone trace and the conference calls to Ron Vivier.\n\n“Since he’s not erasing anything, how did you detect him?”\n\n“A hiccup in our accounting system, you see, he imbalanced our accounts when\nhe …”\n\nGreg interrupted, “So he’s super-user on your Unix system? Bad news, huh?”\nGreg seemed to be a sharp systems guy. I figured I might as well go into\ndetail.\n\n“It’s a bug in the Gnu-Emacs editor. Its mail utility runs with root\nprivilege.” Technical questions were easy.\n\nWe talked Unix for a bit, and Mr. Big started playing with his pencil. “Can\nyou give us a profile of this guy? How old is he? What’s his level of\nexpertise?”\n\nTougher question. “Well, we’ve only watched him for three weeks, so it’s hard\nto say. He’s accustomed to AT&T Unix, so he’s not from around Berkeley.\nPerhaps he’s a high school student. He’s paranoid, always looking over his\nshoulder, yet patient, and not very creative.”\n\n“Does he know English?”\n\n“Well, we think that he once sent mail to our system manager, saying, ‘Hello.’\nAfter sending that message, he never again used that account.”\n\nTeejay, silent until now, asked “Is he recording his sessions?”\n\n“I can’t tell for certain, but I think that he’s keeping a notebook. At the\nvery least, he’s got a good memory.”\n\nMr. Big nodded and asked, “What keywords has he scanned for?”\n\n“He looks for words like _password, nuclear, SDI_ , and _Norad_. He’s picked\nsome curious passwords— _lblhack, hedges, jaeger, hunter_ , and _benson_. The\naccounts he stole, _Goran, Sventek, Whitberg_ , and _Mark_ don’t say much\nabout him because the names are people here at the laboratory.”\n\nTeejay suddenly lit up. He passed a note to Greg. Greg passed it on to Mr.\nBig, who nodded and asked, “Tell me what did he do at Anniston?”\n\n“I don’t have much of a printout there,” I said. “He was into their system for\nseveral months, perhaps as long as a year. Now, since he knows they’ve\ndetected him, he logs in only for a moment.”\n\nMr. Big fidgeted a bit, meaning that the meeting was about to break up. Greg\nasked one more question, “What machines has he attacked?”\n\n“Ours, of course, and the Army base in Anniston. He’s tried to get into White\nSands Missile Range, and some Navy shipyard in Maryland. I think it’s called\nDockmaster.”\n\n“Shit!” Greg and Teejay simultaneously exclaimed. Mr. Big looked at them\nquizzically. Greg said, “How do you know he hit Dockmaster?”\n\n“About the same time he screwed up our accounting, this Dockmaster place sent\nus a message saying that someone had tried to break in there.” I didn’t know\nwhat the big deal was.\n\n“Did he succeed?”\n\n“I don’t think so. What is this Dockmaster place, anyway? Aren’t they some\nNavy shipyard?”\n\nThey whispered among themselves, and Mr. Big nodded. Greg explained,\n“Dockmaster isn’t a Navy shipyard. It’s run by the National Security Agency.”\n\nA hacker breaking into NSA? Bizarre. This guy wanted to get into the CIA, the\nNSA, Army missile bases, and the North American Air Defense headquarters.\n\nI knew a little about the NSA. They’re the secret electronics spooks that\nlisten in on foreign radio broadcasts. They launch satellites to listen to\nSoviet telephone calls. I’d heard (and didn’t believe) rumors that they record\nevery overseas phone call and telegram.\n\nGreg explained from his standpoint. “Most of NSA works on collecting and\nanalyzing signals from abroad. One section, however, works on protecting\ninformation belonging to the United States.”\n\n“Yeah,” I said, “like making ciphers that you think the Commies can’t break.”\nDennis shot me a glance and silently mouthed the word, “Polite.”\n\n“Uh, yeah,” Greg said, “that group worries about computer security. They run\nthe Dockmaster computer.”\n\n“Sounds like Janus, the two-faced god,” I said. “One side tries to crack\nciphers of foreign countries; the other side tries to make unbreakable codes.\nAlways pulling in opposite directions.”\n\n“Sorta like our own agency,” Greg looked around nervously. “We’re known for\ndirty tricks, but we’re fundamentally a news organization. Most of our work is\njust gathering and analyzing information, yet try saying that on campus.” Greg\nrolled his eyes. He’d paid his dues as a college recruiter. Hard to say why,\nbut this spy seemed reasonable. Not arrogant, but sensitive and aware. If we\nmust poke around in dark corners, I’d be more comfortable with him in charge.\n\n“Well then, why can I reach NSA’s computers from my unclassified and obviously\ninsecure computer?” If I could reach out and touch NSA, then they could touch\nme.\n\n“Dockmaster is NSA’s only unclassified computer,” Greg said. “It belongs to\ntheir computer security group, which is actually public.”\n\nMr. Big started talking slowly. “There’s not much we can do about this affair.\nI think there’s no evidence of foreign espionage. Agents on assignment don’t\nsend notes to adversaries.”\n\n“Well, who should be working on this case?” I asked.\n\n“The FBI. I’m sorry, but this isn’t our bailiwick. Our entire involvement has\nbeen the exposure of four names—names that are already in the public domain, I\nmight add.”\n\nOn the way out, I showed our Vax computers to Greg and Teejay. Between rows of\ndisk drives, Greg said, “This is the most serious hacker problem I’ve heard\nof. Despite what the boss says, could you keep me informed?”\n\nI decided to trust this guy. “Sure. Want a copy of my logbook?”\n\n“Yes. Send me anything. Even if the agency can’t do anything, we need to\nbecome aware of this type of threat.”\n\n“Why? Do spooks have computers?”\n\nGreg looked at Teejay and laughed. “We’ve lost count. Our building floats on\ncomputers.”\n\n“What would the CIA use computers for? Can you overthrow foreign governments\nwith software?” Dennis wasn’t around to tell me to be polite.\n\n“Stop thinking that we’re arch villains and think of us instead as information\ngatherers. The information’s worthless until its correlated, analyzed, and\nsummarized. That alone is a lot of word processing.”\n\n“Personal computer stuff, I’ll bet.”\n\n“No, not if you want to do it right. We’re trying to avoid the next Pearl\nHarbor, and that means getting information to the right person fast. Right\noff, that says networks and computers. To analyze and predict the actions of\nforeign governments, we use computer-based models. Again, big computers.\nNowadays, everything from economic forecasts to image processing requires\npowerful number crunchers.”\n\nI’d never thought of the CIA as needing really major computers. “How do you\nkeep your systems secure?”\n\n“Strict isolation. There’s no wires connecting to the outside.”\n\n“Can any CIA agent read anyone else’s files?”\n\nGreg laughed, but Teejay didn’t. “No way. In our world, everyone’s\ncompartmentalized. So if one person turns out to be, how should I say, less\nthan trustworthy, the amount of damage is limited.”\n\n“Then how do you keep people from reading each other’s files?”\n\n“We use trusted operating systems. Computers with thick walls between each\nindividual’s data. If you want to read someone else’s files, then you’ve got\nto get permission. Teejay can tell you some horror stories.”\n\nTeejay looked sideways at Greg. Greg said, “Go ahead, Teejay. It’s already\npublic.”\n\n“Two years ago, one of our contractors built a centralized terminal\nswitchbox,” Teejay said. “We needed to interconnect a few thousand terminals\nto some of our computers.”\n\n“Oh, like my lab’s switchyard.”\n\n“Multiply your switchyard by fifty, and you have some idea.”\n\nTeejay continued, “Each employee of this contractor had to pass the same tests\nas our regular employees—compartmentalized top secret.\n\n“Well, one of our secretaries went on vacation for a month. When she returned\nand logged onto her computer, she noticed that her account had been accessed a\nweek earlier. You see, every time you sign onto our computers, it shows the\ndate when you last logged on.”\n\n“We started sniffing around. The SOB that had connected the terminals\nwiretapped them from our computer room. He’d capture passwords and text, and\nthen pry into our password disks.”\n\nI knew how easy it was to watch the traffic in the LBL switchyard. “Did you\nbump him off?” I asked, imagining some midnight action with a silenced gun.\n\nTeejay looked at me strangely. “Be serious. Where we come from, it’s ‘In God\nwe trust, all others we polygraph.’ ”\n\nGreg finished the story. “We wired him to a lie detector for a week, and the\nFBI indicted him. It’ll be a long time before he sees sunlight.”\n\nWalking out of the lab, I asked Teejay, “Looks like the CIA’s not going to do\nmuch for me, huh?”\n\n“If my superior doesn’t think it’s serious, there’s not much we can do. Ed\nManning has the power to make something happen.”\n\n“Huh? I thought Ed Manning was a programmer?”\n\n“Hardly. He’s director of information technology. When you called him, you hit\na central nerve.”\n\nA director who knew his way around the networks? Now that’s a rare\norganization. No wonder they flew four people out here. There’s a bigger Mr.\nBig back at the headquarters.\n\n“So when you report that there’s nothing shaking here, you’ll drop it?”\n\n“Well, there’s not much that we can do,” Greg said. “It’s the FBI’s\nterritory.”\n\n“Any chance you can rattle their cages and ask them to investigate?”\n\n“I’ll try, but don’t expect much. The FBI likes to chase bank robbers and\nkidnappers. Computer crime, well, let’s say they’ve got other worries.”\n\n“What I hear you saying is, ‘Stop watching and zipper things up.’ ”\n\n“Not quite. You’re watching an extensive attack on our networks. Someone’s\ngoing after the very heart of our information systems. We’ve expected minor\nattacks for several years, but I’ve never heard of anything this far reaching.\nThe convoluted connections, the singleminded search for sensitive targets … it\npoints to an adversary who’s determined to get into our computers. If you\nclose your doors, he’ll just find another way in.”\n\n“So you’re saying, ‘Stay open and keep monitoring’ even though the FBI ignores\nus.”\n\nGreg looked at Teejay. “I can’t buck my management. But you’re doing an\nimportant piece of, well, research. The FBI will eventually wake up. Until\nthen, keep at it.”\n\nI was astonished—these guys saw the severity of the situation but couldn’t do\nanything. Or were they just saying that?\n\nEncouraging words from the CIA.\n\n\n![](images/Stol_9780307819420_epub_019_r1.jpg) It would have been a fun show\nfor the spooks if the hacker appeared while they were visiting. Instead he\nshowed up the next morning at 9:10. Once again we started the traces through\nTymnet and the phone company; once again we struck a brick wall somewhere in\nVirginia. If only our California search warrant were good in Virginia …\n\nThat day the hacker seemed confident, even arrogant. He performed his usual\ntricks: checking who’s on the system, sneaking through the hole in our\noperating system, listing electronic mail. In the past he made occasional\nmistakes as he tried new commands. Today he used no new commands. He was\nsmooth, determined. No mistakes.\n\nAs if he were showing off.\n\nHe went straight for the Anniston Army Depot and printed out a short file\nabout the combat readiness of Army missiles. He then tried the Army’s\nBallistic Research Lab’s computers in Aberdeen, Maryland. The Milnet took only\na second to connect, but BRL’s passwords defeated him: he couldn’t get\nthrough.\n\nHe wasted the rest of my morning by raking through my scientists’ files,\nsearching for passwords. In a physicist’s area, he found one: an old file that\ndescribed the way to get into a Cray supercomputer at Lawrence Livermore Labs.\n\nTo keep people from guessing passwords into their supercomputer, Livermore\nalso used random computer-generated passwords, like _agnitfom_ or _ngagk_.\nNaturally, nobody can remember these passwords. Result? Some people save their\npasswords in computer files. What good is a combination lock when the\ncombination’s scribbled on the wall?\n\nDave Cleveland, our Unix Guru, watched the hacker. “At least he can’t get into\nthe classified computers at Livermore,” Dave said.\n\n“Why not?”\n\n“Their classified system is completely off net. It’s isolated.”\n\n“Then what’s the password lead to?”\n\n“Livermore has a few unclassified computers, where they research fusion\nenergy.”\n\n“Sounds like bomb making to me,” I said. Any kind of fusion seemed like bomb\nmaking.\n\n“They’re trying to build fusion energy reactors to generate cheap electricity.\nYou know, fusion reactions inside donut-shaped magnetic fields.”\n\n“Sure. I played with one when I was a kid.”\n\n“I thought so. Since it’s not weapons research, that computer’s accessible\nfrom networks.”\n\n“We’d better warn Livermore to disable that account.”\n\n“Just wait. You can’t reach the Magnetic Fusion Energy computer from here.\nYour hacker friend’s going to wear himself out trying.”\n\n“Uh, the ranger’s not gonna like this, Yogi …”\n\n“Trust me.”\n\nThe hacker stayed around for a few more minutes, then disconnected. Never even\ntried to get into Livermore.\n\n“So much for that theory,” Dave shrugged.\n\nIn hopes that they might be used as evidence, Dave and I signed the printouts.\nWe left the printers in the switchyard and I wandered back to my office.\nWithin an hour my terminal beeped: the hacker was back.\n\nBut none of the printers showed him. Checking the Unix systems, I saw him,\nlogged in as Sventek. But he wasn’t entering through our Tymnet ports!\n\nQuickly, I scanned the dial-in modems. Two scientists editing programs, a\nbureaucrat listing boilerplate from a contract, and a student writing a love\nletter. No obvious hacking.\n\nI ran back to my office and glanced at the Unix computer’s status. Sventek,\nall right. But coming from where?\n\nThere: the hacker’s port wasn’t an ordinary 1200-baud line. That’s why he\ndidn’t show up in the switchyard. No, he was coming from our local network.\nOur ethernet. The green cable that interconnected a hundred terminals and\nworkstations around our laboratory.\n\nI ran to Wayne’s office. “Look—the hacker’s on our local area network.”\n\n“Slow down, Cliff. Lemme see.” Wayne kept five terminals in his office, each\nwatching a different system. “Yeah, there’s Sventek, on the Unix-4 computer.\nWhatcha wanna do?”\n\n“But he’s the hacker. And he’s coming from our lab-wide ethernet.”\n\n“Big deal. There’s a dozen ways to get there.” Wayne turned to another\nterminal. “I’ll just switch on my friendly ethernet analyzer, and see who’s\ndoing what.”\n\nAs Wayne typed in the parameters, I thought about the implications of finding\nthe hacker on our local network. Our ethernet was a party line that snaked\nthrough every office. That he found a way into the ether was bad news: it\nmeant that the hacker could attack even personal computers attached to the\nethernet.\n\nBut maybe this would prove to be good news. Perhaps the hacker lived here in\nBerkeley and worked at our laboratory. If so, we were closing in on him\nquickly. Wayne would trace the ethernet to within a few feet of the source.\n\n“Here’s your connection. He’s coming from … from the computer that controls\nthe MFE net.”\n\n“You mean the hacker is entering our lab through the MFE network?”\n\n“Yeah. He’s coming from Lawrence Livermore Laboratory. The Magnetic Fusion\nEnergy Network.”\n\nI called down the hallway, “Hey, Dave! Guess who’s visiting Livermore?”\n\nDave ambled over to Wayne’s office. “How’d he get there? There’s no connection\nfrom there into our Unix system.”\n\n“I don’t know how he got into Livermore, but he’s in our ethernet, coming from\nLivermore.”\n\nDave raised his eyebrows. “I didn’t know you could do that. Your hacker found\na path to the Unix system that I didn’t know about.”\n\nWayne launched into Dave with his usual tirade against Unix. I left the two\nbosom enemies and called Livermore.\n\nIt took three calls to find the system manager of the MFE network. “Hi, you\ndon’t know me, but you’ve got a hacker in your system.”\n\nA woman answered, “Huh? Who are you?”\n\n“I work at LBL. Someone’s messing around in my computer and he’s coming in\nfrom the MFE network. It looks like he’s logged in from Livermore.”\n\n“Oh, hell. I’ll scan our users.… There’s only one job that’s connected from\nLivermore to Berkeley. Account 1674 … it belongs to someone named Cromwell.”\n\n“That’s him,” I said. “The hacker found the password a couple hours ago. Got\nthe password from a command file here in Berkeley.”\n\n“I’ll kill that account. Cromwell can use our system, when he learns to keep\nhis passwords secret.” She saw the problem as ignorant users, not unfriendly\nsystems that forced people to use bizarre passwords like _agnitfom_.\n\n“Can you trace the connection?” I wanted Livermore to keep the hacker on line,\nat least long enough to trace the line.\n\n“No, we’re not authorized to make any traces. You’ll have to talk to our\nmanagement first.”\n\n“But by the time anyone decides, the hacker will be gone.”\n\n“We run a secure installation,” she said. “If anyone finds out there’s a\nhacker at Livermore, heads will roll.”\n\n“Unless you trace where the hacker’s coming from, you’ll never know if he’s\nout of your system.”\n\n“My job is to run a computer. Not to catch criminals. Leave me out of your\nwild goose chase.”\n\nShe decided to chop off all access and disable the stolen account. The hacker\ndisappeared from Livermore’s computer, and from ours.\n\nMaybe it was just as well. Even if she had started a trace, I couldn’t monitor\nwhat the hacker was doing. I could detect that he was in my computer, all\nright. But the MFE network connected directly into my computer, without going\nthrough the switchyard. My printers wouldn’t capture what the hacker typed.\n\nDepressed, I shuffled to lunch. At the LBL cafeteria, Luis Alvarez sat down\nacross from me. Inventor, physicist, and Nobel Laureate, Luie was the\ntwentieth-century Renaissance man. He didn’t waste time on bureaucracy; he\ndemanded results.\n\n“How’s astronomy?” Even from the stratosphere, Alvarez still found time to\ntalk to pipsqueaks like me. “Still building that telescope?”\n\n“Naw, I’m working at the computer center now. I ought to be writing programs,\nbut I’ve been spending all my time chasing a hacker.”\n\n“Any luck?”\n\n“It’s playing hide-and-seek over the wires. First I think he’s coming from\nBerkeley, then Oakland, then Alabama, then Virginia. Lately I’ve traced him to\nLivermore.”\n\n“Called the FBI?”\n\n“Six times. They’ve got better things to do. The frustrating part is the\ncomplete lack of support.” I told him about the morning’s activity at\nLivermore.\n\n“Yes, they’ve got their jobs to worry about.”\n\n“But I’m trying to help them, damn it. They don’t care that their neighbor’s\nbeing burglarized.”\n\n“Stop acting like a crusader, Cliff. Why don’t you look at this as research.\nNobody else is interested—not Livermore, not the FBI. Hell, in a week or two,\nprobably not even our lab’s administration.”\n\n“They gave me three weeks. It’s already up.”\n\n“That’s what I mean. When you’re doing real research, you never know what\nit’ll cost, how much time it’ll take, or what you’ll find. You just know\nthere’s unexplored territory and a chance to discover what’s out there.”\n\n“That’s easy for you to say. But I’ve got to keep three managers off my back.\nThere’s programs to write and systems to manage.”\n\n“So what? You’re following a fascinating scent. You’re an explorer. Think of\nwho might be behind it. Some international spy, perhaps.”\n\n“More likely some bored high school kid.”\n\n“Well then, forget who’s causing the problems,” Luie said. “Don’t try to be a\ncop, be a scientist. Research the connections, the techniques, the holes.\nApply physical principles. Find new methods to solve problems. Compile\nstatistics, publish your results, and only trust what you can prove. But don’t\nexclude improbable solutions—keep your mind open.”\n\n“But what do I do when I hit a brick wall?”\n\n“Like Livermore’s system manager?” asked Luie.\n\n“Or the telephone company withholding a phone trace. Or the FBI refusing a\ncourt order. Or our laboratory shutting me down in a couple days?”\n\n“Dead ends are illusory. When did you ever let a ‘Do Not Enter’ sign keep you\naway from anything? Go around the brick walls. When you can’t go around, climb\nover or dig under. Just don’t give up.”\n\n“But who’s going to pay my salary?”\n\n“Permission, bah. Funding, forget it. Nobody will pay for research; they’re\nonly interested in results,” Luie said. “Sure, you could write a detailed\nproposal to chase this hacker. In fifty pages, you’ll describe what you knew,\nwhat you expected, how much money it would take. Include the names of three\nqualified referees, cost benefit ratios, and what papers you’ve written\nbefore. Oh, and don’t forget the theoretical justification.\n\n“Or you could just chase the bastard. Run faster than him. Faster than the\nlab’s management. Don’t wait for someone else, do it yourself. Keep your boss\nhappy, but don’t let him tie you down. Don’t give them a standing target.”\n\nThat’s why Luie won a Nobel Prize. It wasn’t what he did, so much as how he\nwent about it. He was interested in everything. From a few rocks slightly\nenriched in the element iridium, he’d inferred that meteorites (a source of\niridium) must have struck the earth some sixty-five million years ago. Despite\nskepticism from paleontologists, he recognized those meteors to be the death\nknell of the dinosaurs.\n\nLuis Alvarez never saw the subatomic fragments that won his Nobel prize.\nInstead, he photographed their trails inside bubble chambers. He analyzed\nthose trails—from their length, he calculated the particles’ lifetimes; from\ntheir curvature, their charge and mass.\n\nMy research was a far cry from his, but what have I got to lose? Maybe his\ntechniques would work for me. How do you scientifically research a hacker?\n\nAt 6:19 that evening, the hacker returned. This time, he came through Tymnet.\nI didn’t bother tracing it—no use rousting everyone from dinner when they\nwouldn’t give me the phone number.\n\nInstead, I sat and watched the hacker deliberately connect to the MX computer,\na PDP-10 at the MIT artificial intelligence labs in Cambridge, Massachusetts.\nHe logged in as user Litwin, and spent almost an hour learning how to operate\nthat computer. He seemed quite unaccustomed to the MIT system, and he’d\nfrequently ask for the automated help facility. In an hour, he’d learned\nlittle more than how to list files.\n\nPerhaps because artificial intelligence research is so arcane, he didn’t find\nmuch. Certainly, the antique operating system didn’t provide much\nprotection—any user could read anyone else’s files. But the hacker didn’t\nrealize this. The sheer impossibility of understanding this system protected\ntheir information.\n\nI worried about how the hacker might abuse our network connections over the\nweekend. Rather than camping out in the computer room, I pulled the plugs to\nall the networks. To cover my tracks, I posted a greeting for every user\nlogging in: “Due to building construction, all networks are down until\nMonday.” It would surely isolate the hacker from the Milnet. By counting\ncomplaints, I could take a census of how many people relied on this network.\n\nQuite a few, it turned out. Enough to get me in trouble.\n\nRoy Kerth was first. “Cliff, we’re taking a lot of heat for the network being\ndown. A couple dozen people are bitching that they haven’t received electronic\nmail. Can you look into it?”\n\nHe must have believed the greeting! “Uh, sure. I’ll see if I can get it\nworking right away.”\n\nIt took five minutes to patch the network through. The boss thought I’d done\nmagic. I kept my mouth shut.\n\nBut while the network was down, the hacker had appeared. My only record was a\nprintout from the monitor, but that was enough. He had shown up at 5:15 A.M.\nand tried to connect into a Milnet site in Omaha, Nebraska. Disappeared two\nminutes later. From the network directory, I found he tried to get into a\ndefense contractor there, SRI Inc.\n\nI called Ken Crepea of SRI, and he hadn’t noticed anyone trying to get in.\n“But I’ll call you back if I see anything strange.”\n\nKen called back two hours later. “Cliff, you won’t believe this, but I checked\nour accounting logs, and someone’s broken into my computer.”\n\nI believed him. “How do you know?”\n\n“There’s weekend connections from several places, on accounts that ought to be\ndead.”\n\n“From where?”\n\n“From Anniston, Alabama, and from Livermore, California. Someone used our old\naccount, SAC. It used to be used for the Strategic Air Command, here in\nOmaha.”\n\n“Any idea how it was invaded?”\n\n“Well, it never had much password protection,” Ken said. “The password was\nSAC. Guess we screwed up, huh?”\n\n“What was he up to?”\n\n“My accounting records don’t say what he did. I can only tell the times he\nconnected.”\n\nHe told me the times, and I entered them into my log book. To protect his\nsystem, Ken would change all passwords to all accounts, and make each person\nshow up in person to get a new password.\n\nThe hacker was on the Milnet through at least two other computers, Anniston\nand Livermore. And probably MIT.\n\nMIT. I’d forgotten to warn them. I called Karen Sollins of their computer\ndepartment and told her about Friday night’s intrusion. “Don’t worry,” she\nsaid, “there’s not much on that computer, and we’re throwing it away in a few\nweeks.”\n\n“That’s good to know. Can you tell me who owned the Litwin account?” I wanted\nto know where the hacker got Litwin’s password.\n\n“He’s a plasma physicist from the University of Wisconsin,” she said. “He uses\nLivermore’s big computers, and ships his results to our system.” Doubtless, he\nleft his MIT passwords on the Livermore computer.\n\nThis hacker silently followed scientists from one computer to another, picking\nup the crumbs they left. What he didn’t know was that someone was also picking\nup the crumbs he was leaving.\n\n\n![](images/Stol_9780307819420_epub_020_r1.jpg) The hacker knew his way around\nthe Milnet. Now I could see the futility of closing him out of our computers.\nHe’d just come in through some other door. Perhaps I could nail my own doors\nshut, but he’d still climb into other systems.\n\nNobody detected him. Unmolested, he had sneaked into Livermore, SRI, Anniston,\nand MIT.\n\nNobody chased him. The FBI certainly didn’t. The CIA and the Air Force Office\nof Special Investigations couldn’t or wouldn’t do anything.\n\nWell, almost nobody. I followed him, but I couldn’t figure out a way to catch\nhim. The telephone traces wouldn’t pan out. And since he used several\nnetworks, how was I to know where he came from? Today, he might enter through\nmy lab and break into a computer in Massachusetts, but tomorrow, he might just\nas well enter the nets in Peoria and break into Podunk. I could monitor him\nonly when he touched my system.\n\nIt was time to give up and go back to astronomy and programming, or make my\nsite so inviting that he preferred to use Berkeley as a jumping-off place.\n\nGiving up seemed best. My three weeks had expired, and I heard grumblings\nabout “Cliff’s quest for the Holy Grail.” So long as it looked like my chase\nmight bear fruit, the lab would tolerate me, but I had to show progress. For\nthe past week, only the hacker had made progress.\n\n“Do research,” Luis Alvarez had said. Well, OK, I’d watch this guy and call it\nscience. See what I can learn about networks, computer security, and maybe the\nhacker himself.\n\nSo I reopened our doors and sure enough, the hacker entered and poked around\nthe system. He found one interesting file, describing new techniques to design\nintegrated circuits. I watched as he fired up Kermit, the universal file-\ntransfer program, to ship our file back to his computer.\n\nThe Kermit program doesn’t just copy a file from one computer to another. It\nconstantly checks to make sure there haven’t been any mistakes in\ntransmission. So when the hacker launched our Kermit program, I knew he was\nstarting the same program on his own computer. I didn’t know where the hacker\nwas, but he certainly used a computer, not just a simple terminal. This, in\nturn, meant that the hacker could save all his sessions on a printout or\nfloppy disk. He didn’t have to keep notes in longhand.\n\nKermit copies files from one system to another. The two computers must\ncooperate—one sends a file, and the other receives it. Kermit runs on both\ncomputers: one Kermit does the talking, the other Kermit listens.\n\nTo make sure it doesn’t make mistakes, the sending Kermit pauses after each\nline, giving the listener a chance to say, “I got that line OK, go on to the\nnext one.” The sending Kermit waits for that OK, and goes on to send the next\nline. If there’s a problem, the sending Kermit tries again, until it hears an\nOK. Much like a phone conversation where one person says “Uh huh” every few\nphrases.\n\nMy monitoring post sat between my system’s Kermit and the hacker’s. Well, not\nexactly in the middle. My printer recorded their dialogue, but was perched at\nthe Berkeley end of a long connection. I watched the hacker’s computer grab\nour data and respond with acknowledgements.\n\nSuddenly it hit me. It was like sitting next to someone shouting messages\nacross a canyon. The echoes tell you how far the sound traveled. To find the\ndistance to the canyon wall, just multiply the echo delay by half the speed of\nsound. Simple physics.\n\nQuickly, I called our electronic technicians. Right away, Lloyd Bellknap knew\nthe way to time the echoes. “You just need an oscilloscope. And maybe a\ncounter.” In a minute, he scrounged up an antique oscilloscope from the Middle\nAges, built when vacuum tubes were the rage.\n\nBut that’s all we needed to see these pulses. Watching the trace, we timed the\nechoes. Three seconds. Three and a half seconds. Three and a quarter seconds.\n\nThree seconds for a round trip? If the signals traveled at the speed of light\n(not a bad assumption), this meant the hacker was 279,000 miles away.\n\nWith appropriate pomp, I announced to Lloyd, “From basic physics, I conclude\nthat the hacker lives on the moon.”\n\nLloyd knew his communications. “I’ll give you three reasons why you’re wrong.”\n\n“OK, I know one of them,” I said. “The hacker’s signals might be traveling\nthrough a satellite link. It takes a quarter second for microwaves to travel\nfrom earth to the satellite and back.” Communications satellites orbit twenty-\nthree thousand miles over the equator.\n\n“Yeah, that’s one reason,” Lloyd said. “But you’d need twelve satellite hops\nto account for that three-second delay. What’s the real reason for the delay?”\n\n“Maybe the hacker has a slow computer.”\n\n“Not that slow. Though maybe the hacker has programmed his Kermit to respond\nslowly. That’s reason two.”\n\n“Aah! I know the third delay. The hacker’s using networks that move his data\ninside of packets. His packets are constantly being rerouted, assembled, and\ndisassembled. Every time they pass through another node, it slows him down.”\n\n“Exactly. Unless you can count the number of nodes, you can’t tell how far\naway he is. In other words, ‘You lose.’ ” Lloyd yawned and returned to\nrepairing a terminal.\n\nBut there was still a way to find the hacker’s distance. After the hacker\nleft, I called a friend in Los Angeles and told him to connect to my computer\nthrough AT&T and Tymnet. He started Kermit running, and I timed his echoes.\nReal short, maybe a tenth of a second.\n\nAnother friend, this time in Houston, Texas. His echoes were around 0.15\nseconds. Three other people from Baltimore, New York, and Chicago each had\necho delays of less than a second.\n\nNew York to Berkeley is about two thousand miles. It had a delay of around a\nsecond. So a three-second delay means six thousand miles. Give or take a few\nthousand miles.\n\nWeird. The path to the hacker must be more convoluted than I suspected.\n\nI bounced this new evidence off Dave Cleveland. “Suppose the hacker lives in\nCalifornia, calls the East Coast, then connects to Berkeley. That could\nexplain the long delays.”\n\n“The hacker’s not from California,” my guru replied. “I tell you, he just\ndoesn’t know Berkeley Unix.”\n\n“Then he’s using a very slow computer.”\n\n“Not likely, since he’s no slouch at Unix.”\n\n“He’s purposely slowed down his Kermit parameters?”\n\n“Nobody does that—it wastes their time when they transfer files.”\n\nI thought about the meaning of this measurement. My friends’ samples told me\nhow much delay Tymnet and AT&T introduced. Less than a second. Leaving two\nseconds of delay unaccounted for.\n\nMaybe my method was wrong. Maybe the hacker used a slow computer. Or maybe he\nwas coming through another network beyond the AT&T phone lines. A network I\ndidn’t know about.\n\nEvery new piece of data pointed in a different direction. Tymnet had said\nOakland. The phone company had said Virginia. His echoes said four thousand\nmiles beyond Virginia.\n\n\n![](images/Stol_9780307819420_epub_021_r1.jpg) By the end of September, the\nhacker was appearing every other day. Often, he’d pop up his periscope, look\naround, and disappear in a few minutes. Not enough time to trace, and hardly\nworth getting excited about.\n\nI was tense and a little guilty. I often passed up dinner at home to sneak in\nsome extra hacker watching.\n\nThe only way I could keep following the hacker was by disguising my efforts as\nreal work. I’d muck around with computer graphics to satisfy the astronomers\nand physicists, then fool with the network connections to satisfy my own\ncuriosity. Some of our network software actually needed my attention, but\nusually I was just tinkering to learn how it worked. I called other computer\ncenters ostensibly to clear up network problems. But when I’d talk to them,\nI’d cautiously bring up the subject of hackers—who else had hacker problems?\n\nDan Kolkowitz at Stanford University was quite aware of hackers in his\ncomputer. He was an hour’s drive away from Berkeley, but that was an all-day\nbicycle ride. So we compared notes on the phone, and wondered if we were\nwatching the same rodent gnawing at our systems.\n\nSince I’d started watching my monitors, I’d seen an occasional interloper\ntrying to get onto my computer. Every few days, someone would dial into the\nsystem and try to log on as _system_ or _guest_. These inevitably failed, so I\ndidn’t bother following them. Dan had it much worse.\n\n“Seems like every kid in Silicon Valley tries to break into Stanford,” Dan\nmoaned. “They find out passwords to legitimate student accounts, then waste\ncomputing and connect time. An annoyance, but something we’ll have to tolerate\nso long as Stanford’s going to run a reasonably open system.”\n\n“Have you thought about clamping down?”\n\n“To really tighten up security would make everyone unhappy,” Dan said. “People\nwant to share information, so they make most of the files readable to everyone\non their computer. They complain if we force them to change their passwords.\nYet they demand that their data be private.”\n\nPeople paid more attention to locking their cars than securing their data.\n\nOne hacker in particular annoyed Dan. “Bad enough that he found a hole in\nStanford’s Unix system. But he had the nerve to call me on the phone. He\ntalked for two hours, at the same time pawing through my systems files.”\n\n“Did you trace him?”\n\n“I tried. While he was talking on the phone, I called the Stanford police and\nthe phone company. He was on for two hours, and they couldn’t trace it.”\n\nI thought of Lee Cheng at Pacific Bell. He needed just ten minutes to trace\nclear across the country. And Tymnet unwound their network in less than a\nminute.\n\nWe compared the two hackers. “My guy’s not wrecking anything,” I said. “Just\nscanning files and using my network connections.”\n\n“Precisely what I see. I changed my operating system so that I can watch what\nhe’s doing.”\n\nMy monitors were IBM PC’s, not modified software, but the principle was the\nsame. “Do you see him stealing password files and system utilities?”\n\n“Yes. He uses the pseudonym of ‘Pfloyd’ … I bet he’s a Pink Floyd fan. He’s\nonly active late at night.”\n\nThis was a difference. I often watched my hacker at noon. As I thought about\nit, Stanford was following different people. If anything, the Berkeley hacker\nseemed to prefer the name, “Hunter,” though I knew him by the several\ndifferent account names he stole.\n\nThree days later, the headlines of the October 3 _San Francisco Examiner_\nblared, “Computer Sleuths Hunt A Brilliant Hacker.” Reporter John Markoff had\nsniffed out the Stanford story. On the side, the newspaper mentioned that this\nhacker had also gotten into the LBL computers. Could this be true?\n\nThe story described Dan’s snares and his inability to catch Stanford’s Pfloyd\nhacker. But the reporter got the pseudonym wrong—the newspaper reported “a\ncrafty hacker using the name ‘Pink Floyd.’ ”\n\nCursing whoever leaked the story, I prepared to close things up. Bruce Bauer\nof our lab’s police department called and asked if I’d seen the day’s paper.\n\n“Yeah. What a disaster. The hacker won’t show up again.”\n\n“Don’t be so sure,” Bruce said. “This may be just the break we’re looking\nfor.”\n\n“But he’ll never show up, now that he knows that we know there’s a hacker in\nour system.”\n\n“Maybe. But he’ll want to see if you shut him out of the computer. And he’s\nprobably confident that if he can outwit the Stanford people, he can sneak\npast us as well.”\n\n“Yes, but we’re nowhere near tracing him.”\n\n“That’s actually what I called about. It’ll be a couple weeks before we get\nthe search warrant, but I’d like you to stay open until then.”\n\nAfter he hung up, I wondered about his sudden interest. Could it be the\nnewspaper story? Or had the FBI finally taken an interest?\n\nThe next day, doubtless thanks to Bruce Bauer, Roy Kerth told me to keep\nworking on following the hacker, though he pointedly said that my regular\nduties should take precedence.\n\nThat was my problem. Every time the hacker showed up, I’d spend an hour\nfiguring out what he did and how it related to his other sessions. Then a few\nmore hours calling people, spreading the bad news. Then I’d record what\nhappened in my logbook. By the time I’d finished, the day was pretty much\nwasted. Following our visitor was turning into a full-time job.\n\nIn my case, Bruce Bauer’s intuition was right. The hacker returned a week\nafter the article appeared. On Sunday, October 12, at 1:41, I was beating my\nhead against some astronomy problem—something about orthogonal\npolynomials—when my hacker alarm went off.\n\nI ran down the hallway and found him logged into Sventek’s old account. For\ntwelve minutes, he used my computer to connect to the Milnet. From there, he\nwent to the Anniston Army base, where he had no trouble logging in as Hunt. He\njust checked his files and then disconnected.\n\nOn Monday, Chuck McNatt from Anniston called.\n\n“I dumped this weekend’s accounting logs and found the hacker again.”\n\n“Yes, he was on your system for a few minutes. Just long enough to see if\nanyone was watching.” My printouts told the whole story.\n\n“I think I’d better close my doors to him,” Chuck said. “There’s too much at\nrisk here, and we don’t seem to be making headway in tracking him.”\n\n“Can’t you stay open a bit longer?”\n\n“It’s already been a month, and I’m afraid of him erasing my files.” Chuck\nknew the dangers.\n\n“Well, OK. Just be sure that you really eliminate him.”\n\n“I know. I’ll change all the passwords and check for any holes in the\noperating system.”\n\nOh well. Others didn’t quite have the patience to remain open to this hacker.\nOr was it foolishness?\n\nTen days later, the hacker reappeared. I got to the switchyard just as he was\ntrying Anniston.\n\n**LBL > Telnet ANAD.ARPA**\n\n**Connecting to 26.1.2.22**\n\n**Welcome To Anniston Army Depot**\n\n**login: Hunt**\n\n**password: jaeger**\n\n**Bad login. Try again**.\n\n**login: Bin**\n\n**password: jabber**\n\n**Welcome to Anniston Army Depot**.\n\n**Tiger Teams Bewarel**\n\n**Watch out for any unknown users**\n\n**Challenge all strangers using this computer**\n\nChuck had disabled the Hunt account, but hadn’t changed the password on the\nsystem account, _Bin_.\n\nThe greeting message warned the hacker that someone had noticed him. He\nquickly checked his Gnu-Emacs files, and found they had been erased. He looked\naround the Anniston system and found one file that had been created July 3. A\nfile that gave him super-user privileges. It was hidden in the public\ndirectory / usr / lib. An area that anyone could write into. He’d named the\nfile, “.d”. The same name he used to hide his files on our LBL system.\n\nBut he didn’t execute that program. Instead he logged off the Anniston system\nand disconnected from LBL.\n\nChuck hadn’t noticed this special file. On the phone, he said he’d changed\nevery user’s password—all two hundred. But he hadn’t changed any of the system\npasswords like _Bin_ , since he assumed he was the only one who knew them.\nHe’d thought that he’d thoroughly eradicated any dangerous files, but he’d\nmissed a few.\n\nThat _.d_ file at Anniston was a useful benchmark. The hacker had laid this\negg on July 3, yet remembered exactly where he’d hidden it three months later.\n\nHe didn’t guess or hunt around for the _.d_ file. No, he went straight for it.\n\nAfter three months, I can’t remember where I stash a file. At least not\nwithout a notebook.\n\nThis hacker must be keeping track of what he’s done.\n\nI glanced at my own logbook. Somewhere, someone was keeping a mirror-image\nnotebook.\n\nA kid on a weekend lark doesn’t keep detailed notes. A college joker won’t\npatiently wait three months before checking his prank. No, we were watching a\ndeliberate, methodical attack, from someone who knew exactly what he was\ndoing.\n\n\n![](images/Stol_9780307819420_epub_022_r1.jpg) Even though you have to coast\nslowly by the guardhouse, you can reach thirty miles an hour by pedaling down\nthe LBL hill. Tuesday evening I was in no hurry, but pedaled anyway: it’s a\nkicker to feel the wind. A mile downhill, then a rendezvous at the Berkeley\nBowl.\n\nThe old bowling alley was now a huge fruit and vegetable market, the cheapest\nplace for kiwis and guavas. Year ’round, it smelled of mangoes—even in the\nfish section. Next to a pyramid of watermelons, I saw Martha knocking some\npumpkins, hunting for the filling to our Halloween pie.\n\n“Vell, Boris, ze secret microfilm is hidden in ze pumpkin patch.” Ever since I\nmet the CIA, I was a spy in Martha’s eyes.\n\nWe decided on a dozen little pumpkins for a carving party, and one fresh big\none for the pie. After stuffing them in our backpacks, we biked home.\n\nThree blocks from the fruit market, at the corner of Fulton and Ward, there’s\na four-way stop. With a can of spray paint, someone’s changed one stop sign to\nread, “Stop the CIA.” Another, “Stop the NSA.”\n\nMartha grinned. I felt uneasy, and pretended to adjust my backpack. I didn’t\nneed another reminder of Berkeley politics.\n\nAt home, she tossed pumpkins to me, and I stashed them in a box. “What you’re\nmissing is a flag,” she said, throwing the last one low and inside, “some sort\nof pennant for chasing hackers.”\n\nShe ducked into a closet. “I had a bit left over from my costume, so I\nstitched this together.” She unrolled a shirt-sized banner, with a snake\ncoiled around a computer. Underneath, it said, “Don’t Tread on Me.”\n\nIn the weeks before Halloween, both of us sewed furiously to make costumes.\nI’d made a cardinal’s outfit, complete with miter, scepter and chalice.\nMartha, of course, kept her costume hidden—you can’t be too careful when your\nroommate uses the same sewing machine.\n\nNext day, I hoisted my hacker-hunter flag just above the four monitors that\nwatched the incoming Tymnet lines. I’d bought a cheap Radio Shack telephone\ndialer, and connected it to an expensive but obsolete logic analyzer.\nTogether, these waited patiently for the hacker to type in his password, and\nthen silently called my telephone.\n\nNaturally, the flag fell down and got caught in the printer, just as the\nhacker showed up. I quickly unsnarled the shreds of paper and cloth, just in\ntime to see the hacker change his passwords.\n\nThe hacker apparently didn’t like his old passwords— _hedges, jaeger, hunter\nand benson_. He replaced them, one by one, with a single new password,\n_lblhack_.\n\nWell, at least he and I agreed on what he was doing.\n\nHe picked the same password for four different accounts. If there were four\ndifferent people involved, they’d each have a separate account and password.\nBut here in one session, all four accounts were changed.\n\nI had to be following a single person. Someone persistent enough to return\nover and over to my computer. Patient enough to hide a poisonous file in the\nAnniston Army base and return to it three months later. And peculiar in aiming\nat military targets.\n\nHe chose his own passwords. “Lblhack” was obvious. I’d searched the Berkeley\nphone book for Jaegers and Bensons; maybe I ought to try Stanford. I stopped\nby the library. Maggie Morley, our forty-five-year-old documentmeister, plays\nrough and tumble Scrabble. Posted on her door is a list of all legal three-\nletter Scrabble words. To get in, you have to ask her one. “Keeps ’em fresh in\nmy mind,” she says.\n\n“Bog,” I said.\n\n“You may enter.”\n\n“I need a Stanford telephone book,” I said. “I’m looking for everyone in\nSilicon Valley named Jaeger or Benson.”\n\nMaggie didn’t have to search the card catalog. “You need directories for Palo\nAlto and San Jose. Sorry, but we don’t have either. It’ll take a week or so to\norder ’em.”\n\nA week wouldn’t slow things down, at the rate I was going.\n\n“Jaeger. A word that’s been kind to me,” Maggie smiled. “Worth sixteen points,\nbut I once won a game with it, when the ‘J’ landed on a triple-letter score.\nTurned into seventy-five points.”\n\n“Yeah, but I need it because it’s the hacker’s password. Hey, I didn’t know\nnames were legal in Scrabble.”\n\n“Jaeger’s not a name. Well, maybe it’s a name—Ellsworth Jaeger, the famous\nornithologist, for instance—but it’s a type of bird. Gets its name from the\nGerman word meaning hunter.”\n\n“Huh? Did you say, ‘Hunter’?”\n\n“Yes. Jaegers are hunting birds that badger other birds with full beaks. They\nharass weaker birds until they drop their prey.”\n\n“Hot ziggity! You answered my question. I don’t need the phone book.”\n\n“Well, what else can I do for you?”\n\n“How about explaining the relationship between the words _hedges, jaeger,\nhunter and benson?”_\n\n“Well, Jaeger and Hunter is obvious to anyone who knows German. And smokers\nknow Benson and Hedges.”\n\nOmigod—my hacker smokes Benson and Hedges. Maggie had won on a triple-word\nscore.\n\n\n![](images/Stol_9780307819420_epub_023_r1.jpg) I was all set on Halloween\nmorning. I’d finished my cardinal’s costume, even the miter. Tonight’s party\nwould be a gas: pasta with a dozen lunatics, followed by Martha’s fantastic\npumpkin pie, and an excursion into San Francisco’s Castro district.\n\nBut first I had to dodge my bosses at the lab. The physicists were ganging up\non the computer center, refusing to pay our salaries. Supporting central\ncomputing was expensive. The scientists figured that they could buy their own\nsmall machines, and avoid the overhead of paying our programming staff.\n\nSandy Merola tried to convince them otherwise. “You can hitch a thousand\nchickens to your plow or one horse. Central computing is expensive because we\ndeliver results, not hardware.”\n\nTo placate them, Sandy sent me to write a few graphics programs. “You’re a\nscientist. If you can’t make ’em happy, at least listen to their problems.”\n\nSo I spent the morning sitting in the back row of a physics seminar. A\nprofessor droned on about the quark function of the proton—something about how\neach proton has three quarks. I wasn’t tired enough to sleep, so I pretended\nto take notes while thinking about the hacker.\n\nReturning from the seminar, Sandy asked if I’d learned anything.\n\n“Sure.” I glanced at my notes. “The distribution function of quarks isn’t\nquantized over the proton. Happy?”\n\n“Be serious, Cliff. What did the physicists say about computing?”\n\n“Not much. They know they need us, but don’t want to pay.”\n\n“Same as the Air Force,” Sandy smiled. “I just got off the phone with one Jim\nChristy of their Office of Special Investigations.”\n\n“Hey, isn’t he the narc with the military spooks?”\n\n“Be serious. He’s a detective working for the Air Force, please.”\n\n“OK, he’s an all-American good guy. So what did he say?”\n\n“He says the same thing as our physicists. They can’t support us, but they\ndon’t want us to go away.”\n\n“Did he make any progress with the Virginia phone company?”\n\n“Naw. He called around, and they won’t budge without a Virginia search\nwarrant. He checked out the Virginia state law, and the hacker’s committing no\ncrime there.”\n\n“Breaking into our computer isn’t a crime?” I couldn’t believe it.\n\n“Breaking into a California computer isn’t a crime in Virginia.”\n\n“I don’t suppose the Air Force can lean on the FBI to get a warrant?”\n\n“Nope. But they want us to keep monitoring, at least until the Air Force\ndecides it’s a dead end.”\n\n“Did they cough up any dimes?” My time was funded through the grants of\nastronomers and physicists. They weren’t pleased to watch me spend their money\nchasing some ghost.\n\n“No bucks, nothing but an unofficial request. When I asked for support, Jim\ngave me the bailiwick story.”\n\nSandy wasn’t going to give in. “It’s been two months since we started, and\nnobody’s listened to us. Let’s stay open for another week, then call it\nquits.”\n\nBy five o’clock, I was ready for the Halloween party. On my way out, I checked\nthe floppy disks on the monitors. The printer suddenly started up. There was\nthe hacker. I glanced at the time—17:43:11 PST.\n\nNo. Not now. I’ve got a party to go to. A costume party no less. Can’t he\nchoose any other time?\n\nThe hacker logged into the old Sventek account, and checked who was on our\nsystem. Dave Cleveland was there, running under the alias of Sam Rubarb, but\nthe hacker couldn’t know.\n\nHe moved over to our accounting files, and collected the past month’s files in\none place. He scanned that long file, searching for the word, “Pink Floyd.”\n\nHmmmm. Interesting. He didn’t search for the word “Pfloyd,” which was the\nStanford hacker’s pseudonym. Rather, he searched for the pseudonym that was\nreported in the newspaper.\n\nMy hacker wasn’t the same guy as Stanford’s. If he were, he wouldn’t have to\nsearch for “Pink Floyd”—he’d know when he had been active.\n\nIn fact, my hacker wasn’t even in contact with Stanford’s. If the two had met,\nor even written to each other, my hacker would know to search for “Pfloyd,”\nnot “Pink Floyd.”\n\nThe hacker must have read the news. But it had been almost a month since the\narticle was published. Dave Cleveland must be right: the hacker wasn’t from\nthe West Coast.\n\nAt 6 P.M., the hacker gave up searching our accounting logs. Instead, he went\nthrough our computer onto the Milnet. From there, he went straight for the\nAnniston army base in Alabama. “Which hole will he sneak into this time?” I\nwondered.\n\n**LBL > Telnet Anad.arpa**\n\n**Welcome to Anniston Computer Center**\n\n**Login: Hunter**\n\n**Password: Jaeger**\n\n**Incorrect login, try again**.\n\n**Login: Bin**\n\n**Password: Jabber**\n\n**Incorrect login, try again**.\n\n**Login: Bin**\n\n**Password: Anadhack**\n\n**Incorrect login, 3 tries and you’re out**.\n\nChuck McNatt had finally locked him out. By changing all his passwords, Chuck\nhad nailed his door shut. He still might have holes in his system, but this\nhacker couldn’t exploit them.\n\nThe hacker didn’t give up. He reached over into the building design group.\n\nSome scientists at Lawrence Berkeley Lab worry about how to design energy\nefficient homes. Most other physicists look down on them—“Yech, applied\nphysics.” Protons and quarks are sexy. Saving ten dollars on your monthly\nheating bill isn’t.\n\nThe building design group searches for new glasses that let light in, but\nblock the infra-red. They build new insulators to prevent heat leaks through\nwalls. They’d just started analyzing basements and chimneys for thermal\nefficiency.\n\nThe hacker learned this because he dumped all their files. Page after page of\nthermal emissivity data. Memos about paint absorption in the ultraviolet. And\na note saying, “You can move to the Elxsi computer next week.”\n\nHe didn’t need to see that note twice. He interrupted his listing, and\ncommanded my Unix computer to connect him to the Elxsi system.\n\nI’d never heard of this computer. But my computer had. Within ten seconds,\nhe’d made the connection and the Elxsi prompted him for an account name and\npassword. I watched him try to get in:\n\n**LBL > Telnet Elxsi**\n\n**Elxsi at LBL**\n\n**login: root**\n\n**password: root**\n\n**incorrect password, try again**.\n\n**login: guest**\n\n**password: guest**\n\n**incorrect password, try again**.\n\n**login: uucp**\n\n**password: uucp**\n\n**WELCOME TO THE ELXSI COMPUTER AT LBL**\n\nHe got into the UUCP account. No password protection. Wide open.\n\nUUCP is the account for Unix to Unix copying. When one Unix computer wants to\ncopy a file from another, it logs into the UUCP account and gets the file.\nPeople should never be able to connect to this special account. The system\nmanager should disable it from human log-ins.\n\nWorse, this Elxsi had its UUCP account set up with system privileges. It took\nthe hacker only a minute to realize that he’d stumbled into a privileged\naccount.\n\nHe didn’t lose any time. He edited the password file, and added a new account,\none with system manager privileges. Named it _Mark_. “Keep it bland,” I\nthought.\n\nBut he didn’t know much about this computer. He spent an hour dumping its\nfiles, and learned about designing energy efficient buildings. Nothing about\nthe computer itself.\n\nSo he wrote a program to time the Elxsi computer. A short C program that\nmeasured its speed and reported its word length.\n\nHe needed three tries to get his program to work, but finally it flew. He\nfound the Elxsi to have thirty-two bit words, and he measured it at about ten\nmillion instructions per second.\n\nEight-bit and sixteen-bit computers are diddlysquat machines; the thirty-two-\nbit systems are the biggies. Thirty-two bits meant a big machine, ten MIPS\nmeant fast. He’d entered a super-minicomputer. One of the fastest in Berkeley.\nOne of the most mismanaged.\n\nAs I watched him walk through the Elxsi, I talked to Tymnet. While the hacker\ntried to understand the new computer, Ron Vivier searched out the needle that\npointed where the hacker came from.\n\n“No news. He’s coming in from Oakland again.” Ron knew that meant a phone\ntrace.\n\n“No use calling the phone company. They’ll just tell me to get a Virginia\nsearch warrant.”\n\nI hung up, disappointed. A long connection like this was perfect for tracing\nhim. I couldn’t shut him out of our system when he was into computers I’d\nnever even heard of. When he finally signed off at 7:30, he’d pretty much\nmapped out our lab’s major computers. He might not be able to get into each of\nthem, but he knew where they were.\n\n7:30. Damn, I’d forgotten the party. I ran down to my bike and pedaled home.\nThis hacker wasn’t wrecking my computer, he was destroying my life. Being late\nfor a Halloween party—that’s a capital crime in Martha’s book.\n\nNot only was I late, but I’d shown up without a costume. I slinked guiltily\nthrough the kitchen door. What a scene! Princess Diana, tastefully attired in\na tailored dress, pillbox hat and white gloves, shuddered as she removed a\ndripping handful of seeds from a pumpkin. Alice and the mad hatter were\nserving the last of the lasagna. Charlie Chaplin was dipping apples in\ncaramel. In the midst of this swirl of activity stood a small but fierce\nsamurai warrior in full battle gear, shouting orders. “You’re late,” the\nsamurai scowled. “Where’s your costume?”\n\nBuried in the back of the closet, I found my red velvet robe. Worn over\nMartha’s nightgown, with a sheet pinned around my shoulders and a tall,\njeweled miter of construction paper and sequins, I suddenly became … Cardinal\nCliff the First. I went around blessing the guests. Martha’s friend Laurie,\nwho usually wore a crew cut, jeans, and hiking boots, sidled up in a short\nblack cocktail dress and long pearl necklace. “Come on, your holiness, let’s\ngo forth and bless the Castro.”\n\nWe piled into the Mad Hatter’s car (Laurie rode her motorcycle) and crossed\nthe bridge to Babylon. Halloween is San Francisco’s favorite holiday. Five\nblocks along Castro Street are cordoned off, and thousands of elaborately\ncostumed revelers jostle up and down, looking at each other and at the drag\nqueens in sequined gowns who lip-sync to Ethel Merman on the fire escapes\noverlooking the street.\n\nThis year’s costumes were incredible: a person dressed as a giant bag of\ngroceries, complete with giant paper replicas of vegetables and cans; various\ncreatures from outer space; and several rival samurai’ whom Martha fought off\nwith her plastic sword. White-faced draculas mingled with witches, kangaroos,\nand butterflies. Over near the trolley stop, an assortment of ghouls\nharmonized with a three-legged pickle.\n\nI offered benedictions left and right—to demons and angels, gorillas and\nleopards. Medieval knights knelt to me, and nuns (some with mustaches) rushed\nup to greet me. A trio of sturdy, cheerful fellows in pink tutus and size-\nthirteen ballet shoes bowed gracefully to receive my blessings.\n\nDespite layoffs at the factories, rent payments due, drugs, and AIDS, somehow\nSan Francisco celebrated life.\n\nNext Monday I showed up late, expecting to find a message from the manager of\nthe Elxsi computer. No such luck. I called around the building design group,\nand talked with the physicist in charge of the Elxsi computer.\n\n“Noticed anything strange on your Elxsi?”\n\n“No, we’ve only had it a month. Anything wrong?”\n\n“Who set up your accounts?”\n\n“I did. I just signed on as system manager, then added users.”\n\n“Do you run accounting?”\n\n“No. I didn’t know you could.”\n\n“Someone broke into your computer through the UUCP account. He became system\nmanager and added a new account.”\n\n“I’ll be damned. What’s the UUCP account?”\n\nHere’s the problem. This guy’s a physicist, bored by computers. He didn’t know\nabout managing his machine. Probably didn’t care.\n\nThis guy wasn’t the problem. Elxsi was. They sold their computers with the\nsecurity features disabled. After you buy their machine, it’s up to you to\nsecure it. Just plow through a dozen manuals to find a paragraph saying how to\nmodify the permissions granted to the UUCP account. If you know that account\nexists.\n\nRight.\n\nThe same thing must be happening all over. The hacker didn’t succeed through\nsophistication. Rather he poked at obvious places, trying to enter through\nunlocked doors. Persistence, not wizardry, let him through.\n\nWell, he wasn’t going to get into our Elxsi anymore. Knowing my adversary, I\ncould easily lock him out in a way that would mystify him. I built a trap door\ninto our Elxsi: whenever the hacker touched the purloined accounts on that\nmachine, it notified me and pretended to be too busy to accept another user.\nThe Elxsi didn’t say, “Go away”; rather, it slowed down to a crawl whenever\nthe hacker showed up. The hacker wouldn’t realize that we were on to him, yet\nthe Elxsi was protected against him.\n\nStill, we were treading water. Without search warrants, our phone traces went\nnowhere. Sure, we read every word he typed into our computer, but how much did\nwe miss? He might be using a dozen other computers to get onto the Milnet.\n\nThis much is for sure: I was now dedicated to catching this hacker. The only\nway to snag this guy was to watch every minute of the day. I had to be ready\nall the time—noon or midnight.\n\nThat was the problem. Sure, I could sleep under my desk and rely on my\nterminal to wake me up. But at the cost of the domestic tranquility: Martha\nwasn’t pleased at my office campouts.\n\nIf only my computer would call me whenever the hacker appeared, then the rest\nof the time would be my own. Like a doctor on call.\n\nOf course. A pocket pager. I had a bank of personal computers watching for the\nhacker to appear. I’d just program them to dial my pocket pager. I’d have to\nrent a pager, but it’d be worth the $20 a month.\n\nIt took an evening to write the programs—no big deal. From now on, wherever I\nwent, I’d know within seconds of the hacker’s arrival. I’d become an extension\nof my computer.\n\nIt was him against me now. For real.\n\n\n![](images/Stol_9780307819420_epub_024_r1.jpg) Lawrence Berkeley Labs is\nfunded by the Department of Energy, the successor to the Atomic Energy\nCommission. Perhaps nuclear bombs and atomic power plants are fading into the\nmists of history, or maybe splitting atoms isn’t as sexy as it used to be. For\nwhatever reason, the DOE isn’t the same animated team that started atomic\nenergy plants two decades ago. I’d heard rumors that over the years, the\norganization had silted up like the Mississippi.\n\nThe DOE may not be the most nimble of our many Governmental agencies, but they\ndid pay our bills. For over a month, we’d kept silent about our problem,\nworrying that the hacker might find out we were tracking him. Now that our\ntrace led far from Berkeley, it seemed safe to tell our funding agency about\nthe hacker.\n\nOn November 12, I called around the DOE, trying to find out who I should talk\nto about a computer break-in. It took a half dozen calls to find out that\nnobody really wanted to listen. Eventually I reached the DOE manager of\ncomputer security for unclassified computers.\n\nRick Carr listened patiently as I told him about the hacker, occasionally\ninterrupting with questions. “Is he still active in your computer?”\n\n“Yes, and we’re homing in on him every time he shows up.”\n\nHe didn’t seem especially excited. “Well when you catch him, let us know.”\n\n“Want a copy of my logbook?” I asked.\n\n“No. Keep it quiet until you’re through.”\n\nI explained our need for search warrants and the FBI’s lack of interest. “Any\nchance you might be able to get the FBI to open a case?”\n\n“No, I wish they did, but the FBI doesn’t listen to us,” Rick said. “I’d like\nto help, but it’s just not my bailiwick.”\n\nBailiwicks again. I mumbled my thanks, and was about to hang up when Rick\nsaid, “You might want to call the National Computer Security Center, though.”\n\n“Who are they?” Seemed like a group that I should have heard of.\n\nRick explained, “The NCSC is a sidekick of the National Security Agency.\nThey’re supposed to make standards for securing computers.” From his emphasis\non the word “supposed,” it sounded like they weren’t.\n\n“Since when does the NSA talk to the public?” I’d always thought that the NSA\nwas the most secret of all government agencies.\n\n“The computer security section of NSA is the only part of NSA that’s\nunclassified,” Rick said. “Because of this, they’re treated as ugly ducklings\nwithin NSA. Nobody from the secret side of the house will talk to them.”\n\n“And since they’re a part of the NSA, nobody from the public trusts them\neither,” I realized where he was leading.\n\n“Right. They take flack from both sides. But you ought to tell them about your\nhacker. They’re certain to be interested, and they might just rattle the right\ncages in the bureaucracy.”\n\nNext call: the National Computer Security Center. Zeke Hanson was their desk\nofficer. His voice was cheerful and he seemed fascinated by the idea of\nsilently watching a hacker. He wanted all the technical details of our\nmonitors and alarms.\n\n“You’re an intercept operator,” Zeke informed me.\n\n“What’s that?” I’d never heard of it.\n\nHe stammered a bit, as if he wanted to unsay his last sentence. I figured out\nwhat he meant on my own. NSA must have thousands of people watching teletypes\naround the world. Intercept operators, huh?\n\nZeke asked about my computer. I explained, “A couple of Vaxes running Unix.\nLots of networks.” For the next twenty minutes, I told him about the holes\nthat the hacker exploited—Gnu-Emacs, passwords, Trojan horses. It hit him\nwhere he lived.\n\nBut when I asked if there was any way that he could finagle a search warrant,\nhe clammed up tight.\n\n“I’ll have to talk to my colleagues about this.”\n\nWell, what did I expect? Ideally, I’d call an electronic spy on the phone,\nexplain my need for a search warrant, and he’d kick the FBI into acting.\nRight. How would I react to someone calling my observatory, reporting an\ninvader from some unknown planet?\n\nStill, I might as well explain our problem. “Look, we’re about to call it\nquits. If someone doesn’t help out, we’re giving up on this monitoring. I’ve\nhad it with being a volunteer intercept operator.”\n\nNot a dent. “Cliff, I’d like to take over, but our charter prevents it. NSA\ncan’t engage in domestic monitoring, even if we’re asked. That’s prison term\nstuff.”\n\nHe took this seriously. NCSC or NSA, whichever he worked for, wouldn’t monitor\nmy hacker. They’d advise me on how to protect my computers and serve as a\nliaison to the FBI, but they wouldn’t take over my monitoring.\n\nGetting a search warrant? Zeke would look into it, but didn’t offer much help.\n“If you can’t interest the FBI, I doubt that they’ll listen to us. We’re here\nto make computers more secure, not to catch criminals.”\n\nAnother bailiwick problem.\n\nI hung up, discouraged. Five minutes later, I walked down the hallway and\nasked myself what I was doing talking to the NSA.\n\nMaybe Martha was right. She’d said I was on a slippery slope that led into\ndeep water. First you call the FBI, then the CIA, now the NSA.\n\nBut it wasn’t the spooks that bothered me. It was their inaction. Sure, they\nall listened to my troubles, but not one would lift a finger.\n\nFrustrating. Every agency seemed to have a good reason to do nothing.\nDisgusted, I paced the halls.\n\nThe hallways at Lawrence Berkeley Labs look like a plumber’s nightmare.\nThere’s no suspended ceiling tiles to hide the pipes, cables, and ducts.\nLooking up, I recognized the steam pipes, and the orange ethernet cables. The\nsteam runs at about one hundred pounds per square inch, the ethernet at around\nten million bits per second.\n\nMy networks were as essential to the lab as steam, water, or electricity.\n\nDid I say, “my networks?” The networks were no more mine than the steam pipes\nbelonged to the plumbers. But someone had to treat them as his own, and fix\nthe leaks.\n\nSomething strange was happening to me. In a daze, I sat down on the hallway\nfloor, still staring up at the pipes. For the first time in my life, something\nimportant was entirely up to me. My attitude at work had always been like my\ndays as an astronomer—I’d write proposals, observe at the telescope, publish\npapers, and stand cynically apart from the struggles and triumphs of the world\naround me. I didn’t care if my research led anywhere.\n\nNow, nobody was telling me what to do, yet I had a choice: should I quietly\nlet things drop? Or do I take arms against this sea of troubles?\n\nStaring at the pipes and cables, I realized that I could no longer fool around\nbehind the scenes, an irreverent, zany kid. I was serious. I cared. The\nnetwork community depended on me, without even knowing it. Was I becoming (oh,\nno!) responsible?\n\n\n![](images/Stol_9780307819420_epub_025_r1.jpg) That evening, Martha studied\ncriminal procedure at Boalt Hall Law Library. I stopped by to deliver some\nbagels and cream cheese, the high-octane fuel of law students. We necked and\npecked among the books, occasionally dodging a zombie cramming for the bar\nexam. Aah, Boalt library, where the law never sleeps.\n\nIn a back room, she showed me the law school’s Lexis computer. “Hey, want to\nplay with a fun toy while I study?” she asked.\n\nWithout waiting for a reply, she switched on the Lexis terminal. She pointed\nto the sign giving instructions on how to log into the document search system.\nShe dived back into her books, leaving me with some unknown computer.\n\nThe instructions couldn’t be plainer. Just press a couple buttons, type the\naccount name, a password, and begin searching judicial records for whatever\nseems interesting. Next to the instructions were scribbled five account names\nand passwords, so I picked a pair and logged in. Nobody had thought to protect\nits passwords. I wondered how many former law students were still freeloading\nfrom the library.\n\nSo I logged into the law computer and searched on the keywords _telephone\ntrace_. It took a while to understand the legal jargon, but eventually I\nstumbled on the law regulating telephone traces. It turned out that a search\nwarrant wasn’t necessary to trace a phone call made to your own telephone, so\nlong as you wanted the trace made.\n\nThis made sense. You shouldn’t need a court order to find out who was calling\nyou. Indeed, some telephone companies now sell phones that display the digits\nof the calling telephone as your phone is ringing.\n\nBut if we didn’t legally need a search warrant, why were the phone companies\nso insistent? Monday morning, clutching a xerox of 18 USCA §3121, I called Lee\nCheng at the phone company. “Why do you make us get search warrants, when the\nlaw doesn’t require it?”\n\n“It’s partly to protect ourselves from lawsuits and partly to filter out\nworthless traces,” Lee said.\n\n“Well, if the warrant isn’t required, why won’t the Virginia phone company\nrelease the information?”\n\n“I dunno. But they won’t. I’ve spent half an hour talking to them, and they\nwon’t budge.” If they wouldn’t release the number to another phone company,\nthere wasn’t much chance they’d tell my lab. Looked like the phone trace was a\ndead end after all.\n\nAletha Owens, our lawyer, called. “The FBI won’t give us the time of day, let\nalone a search warrant.”\n\nSame story with our lab police. They’d called around and got nowhere. Dead\nend.\n\nOver lunch at the lab cafeteria, I described the past week’s adventures to two\nastronomer pals, Jerry Nelson and Terry Mast.\n\n“You mean to say that they traced the call and won’t tell you the number?”\nJerry asked incredulously.\n\n“That’s about the size of it. No tickee, no laundry.”\n\nBetween sandwiches, I showed them my logbook. A couple weeks ago, while the\nphone technician was tracing the line, I’d copied all her jargon into my\nlogbook. Now, Jerry started interpreting like a palm reader.\n\n“Hey, look, Cliff—the phone technician said 703,” Jerry said. “Area code 703\nis in Virginia. And C and P … I bet that’s Chesapeake and Potomac. Yeah.\nThey’re the phone company for northern and western Virginia.”\n\nTerry Mast is an experimentalist. “You copied those numbers that the phone\ntechnician said. Why not call every permutation of those numbers in area code\n703, and find out if there’s a computer there?”\n\nJerry Nelson looked at my notes. “Yeah, that oughta work. The technician said\n1060 and 427 and 448. Try calling 703/427-1060. Or maybe 448–1060. There’s\nonly a few combinations.”\n\nIt was worth a try. But I’d be slightly more devious.\n\nI called my local telephone business office and said, “I have a couple calls\non my bill that I don’t remember making. Could you tell me who I dialed?”\n\nThe operator was completely cooperative. “Just read me the numbers and I’ll\ncheck them for you.”\n\nI told her six possible numbers, all in area code 703. Ten minutes later, she\ncalled back. “I’m very sorry, but five of those numbers are nonexistent or out\nof service. I don’t know how you got billed for them.”\n\nFive of the six were bad numbers! One might just do it. I said, “Oh yes,\nthat’s all right. Who is the owner of the sixth number?”\n\n“That’s Mitre, Incorporated spelled M-I-T-R-E, at 703/448-1060. Would you like\nme to start a refund for those five other calls?”\n\n“I’m in a hurry right now. I’ll take care of it later.”\n\nNervously, I dialed the phone number, ready to hang up when I heard a voice. A\ncomputer’s modem answered with a high-pitched whistle. Far out!\n\nMitre. I knew of a defense contractor, Mitre, in Massachusetts. But not in\nVirginia. I’d seen their ads in electronics magazines—they were always looking\nfor programmers who were U.S. citizens. Digging through the library, I found\nthat, yes, Mitre did have a branch in Virginia. McLean, Virginia.\n\nStrange. Where had I heard of that city? The library’s atlas told me.\n\nThe CIA’s headquarters are in McLean.\n\n\n![](images/Stol_9780307819420_epub_026_r1.jpg) I couldn’t believe it. The\nhacking seemed to be coming from Mitre in McLean, Virginia—a couple of miles\nfrom CIA headquarters. Time to call the boss.\n\n“Hey, Dennis, the calls are coming from Mitre. It’s a defense contractor just\ndown the road from CIA headquarters. What do you think Teejay will say to\nthat?”\n\n“How do you know it’s Mitre?”\n\n“Well, during the phone trace, I copied down all the numbers and digits that I\nheard from the technician. I called all combinations of them, and ended up at\na computer modem at Mitre.”\n\n“So you’re not certain.” Dennis saw the hole in my argument. “If we spread\nthis around and we’re wrong, we’ll be in hot water.”\n\n“But what are the chances of randomly dialing a telephone and getting a\ncomputer to answer?”\n\n“I don’t care. Until you find some proof, don’t act on it. Don’t call Mitre.\nAnd don’t tell our spooky friends.”\n\nBack to square one. I think I know the phone number of the hacker but how to\nprove it?\n\nAah! Just wait until the hacker calls back again. Then see if the phone is\nbusy. If it’s busy, then likely I’ve got the right number.\n\nThere was another way to get the phone number. Less sophisticated, but more\nreliable.\n\nBack in graduate school, I’d learned how to survive without funding, power, or\neven office space. Grad students are lowest in the academic hierarchy, and so\nthey have to squeeze resources from between the cracks. When you’re last on\nthe list for telescope time, you make your observations by hanging around the\nmountaintop, waiting for a slice of time between other observers. When you\nneed an electronic gizmo in the lab, you borrow it in the evening, use it all\nnight, and return it before anyone notices. I didn’t learn much about\nplanetary physics, but weaseling came naturally.\n\nStill, I couldn’t finagle a federal search warrant. All I had were the\nstandard tools of astronomers. Exactly enough to get the information I needed.\n\nI dialed Chesapeake and Potomac’s business office and asked for the security\noffice. After a few transfers, I recognized the voice of the technician that\nhad traced last week’s call.\n\nAfter a few minutes of casual chat, she mentioned that her eleven-year-old kid\nwas fascinated by astronomy. I saw my opening. “Think he’d like some star\ncharts and posters of the planets?”\n\n“Sure! Especially that ringed thing, you know, Saturn.”\n\nOne of the few resources that I’ve plenty of: pictures of planets and\ngalaxies. We talked a bit about her kid, and I returned to the matter on my\nmind.\n\n“By the way, I think the hacker is coming from Mitre, over in McLean.\n448-1060. Does this agree with your trace?”\n\n“I’m not supposed to release this information, but since you already know the\nnumber.…”\n\nAah! Grad school comes through.\n\nI rolled a dozen posters into a mailing tube. Today, somewhere in Virginia, a\nkid’s wall sports a collection of planetary and galactic photos.\n\nMcLean, Virginia … I knew more about Mars than McLean. I called my sister,\nJeannie, who lived somewhere near there. At least she had the same area code.\n\nJeannie had, indeed, heard of Mitre. They weren’t just a defense contractor\ngrabbing secret Pentagon contracts. They also had ties to the CIA and the NSA.\nAmong thousands of other projects, Mitre tested computers for security. When\nsomeone needed a secure computer, Mitre certified it.\n\nOdd. The hacker came from a company that certifies secure computers. Maybe one\nof their testers was fooling around on the side? Or did Mitre have some secret\ncontract to explore security on the military networks?\n\nTime to call Mitre. It took five phone calls to pierce their veil of\nsecretaries, but eventually I reached a man named Bill Chandler.\n\nIt took fifteen minutes to convince him that there really was a problem.\n“Simply impossible. We’re running a secure shop, and nobody can break in.” I\ndescribed my traces, leaving out the missing search warrants.\n\n“Well, I don’t know if someone’s hacking from our computers, but if they are,\nthey’re sure not coming from the outside.”\n\nIt took another ten minutes before he’d accept that it was _his_ problem. Five\nmore to decide what to do.\n\nI proposed a simple solution. Simple for me, at least. “The next time the\nhacker’s connected to Berkeley, just examine Mitre’s telephone line. Find out\nwho’s connected to it.”\n\nBill Chandler agreed. He’d round up some technicians and quietly watch Mitre’s\ntelephone line, 448-1060. As soon as I’d call him, he’d trace his internal\nnetwork and find the culprit.\n\n“I doubt we’ll find much,” he said. “It’s impossible to break into our secure\nsite, and all our employees have clearances.”\n\nRight. If he wanted to keep his head in the sand, it was all right with me.\nMaybe one of Mitre’s employees was screwing around the military networks, just\nfor kicks. But what if this was an organized effort?\n\nIf so, who was behind it? Could some secret agency have hired Mitre? If so, it\nhad to be someone right around the corner. Someone just a couple miles away.\nTime to call the CIA.\n\nTen minutes later, I’m on the phone with Teejay. “Uh, I don’t know how to ask\nthis, and you probably can’t tell me anyway, but what are the chances that our\nhacker is someone from the CIA?”\n\nTeejay wouldn’t consider it. “Absolutely zero. We don’t pry into domestic\naffairs. Period.”\n\n“Well, I can’t say for certain, but it looks like our phone traces lead to\nVirginia, and I was just wondering if …” I let my voice trail off, hoping\nTeejay would pick up.\n\n“Where in Virginia?” Teejay asked.\n\n“Northern Virginia. Someplace called McLean.”\n\n“Prove it.”\n\n“We got a telephone trace, but it hasn’t been officially released. We don’t\nhave a search warrant, but there’s no doubt it’s from McLean.”\n\n“How do you know?”\n\n“Standard techniques I picked up in graduate school,” I said. If I told him\nhow, he wouldn’t believe me. Anyway, he’d never reveal his methods to me.\n\n“What else do you know about this McLean connection?”\n\n“A little bit. Know any defense contractors there?” For once I played cat and\nmouse.\n\n“Cut the crap. Who is it?”\n\n“Mitre.”\n\n“Come on. Be serious.”\n\n“Would you believe 1820 Dolly Madison Road?”\n\n“Are you trying to tell me that someone from Mitre is hacking into military\ncomputers?”\n\n“That’s what our phone trace says.”\n\n“Well, I’ll be damned.… No, it’s just not possible.” Teejay went silent for a\nsecond. “Mitre’s a secure site.… Do you know anything more about this hacker?”\n\n“I know what brand of cigarettes he smokes.”\n\nTeejay laughed over the phone. “I guessed that last month.”\n\n“Then why didn’t you tell me?” Teejay wanted my news, but wasn’t forthcoming\nwith his own. “Look, I’ve got to know one thing. Mitre’s a mile from you. They\nwork on classified projects. Are you sure the hacker’s not with the CIA?”\n\nTeejay became suddenly bureaucratic. “I can only say that nobody in our agency\nis authorized to observe domestic activities, with or without a computer.” On\nthe side, he added, “Damned if I know who this guy is, but he’d better not be\none of us.”\n\n“Can you find out?”\n\n“Cliff, this is a domestic problem. I’d love to help, but we can’t touch it.”\n\nWell, the CIA was interested, but not much help. Time to call the FBI. For the\nseventh time, the Oakland FBI office didn’t raise an eyebrow. The agent there\nseemed more interested in how I traced the call than in where it led.\n\nStill, there was one more place to call. The Defense Communications Agency.\nThey seemed to be on good terms with the Air Force Office of Special\nInvestigations—maybe they could scare up some official interest.\n\nDespite ten thousand computers on the Milnet, only one person managed\nsecurity. A month ago, Major Steve Rudd had asked about our problems. He\nhadn’t promised any action, just wanted to hear any news. Maybe the word Mitre\nwould wake him up.\n\nI called him, and mentioned that we’d traced things back to McLean, Virginia.\n“I hope you’re kidding,” Steve said.\n\n“No kidding. The hacking’s coming from a defense contractor in McLean.”\n\n“Who?”\n\n“Can’t say till I check with my boss.” I wondered if he’d play cat and mouse.\n\nDespite his protests, I stood my ground. Maybe by keeping quiet, I could keep\nhim interested. After a few more minutes on the phone, he gave up,\nexasperated. “Look, talk to your boss and see if he’ll tell us. We might be\nable to help if we know who to lean on. Unless you tell us, though, we can’t\ndo much.”\n\nWhile it was fresh in my mind, I typed the day’s events into my logbook. The\nphone rang, and when I picked it up, a recorded message was playing: “This\nphone line is not secured. Do not discuss classified information.” It repeated\na couple times, so I hung up. I didn’t know anything classified, and didn’t\nwant to.\n\nThree minutes later, the same message came on my phone. By listening\ncarefully, you could hear where the tape was spliced. I was just getting into\nthe rhythm of the mechanical voice when an angry army officer interrupted.\n\n“Hello, is this Doctor Stoll?” People only used titles on me when I was in\ntrouble. “This is Jim Christy of the OSI.”\n\nThe Air Force narcs were on the phone. The Defense Communications Agency must\nhave rang their bell.\n\nThe narc had just one question. “Where did you trace the hacker in Virginia?”\n\n“Uh, I can’t tell you. This line isn’t secure.”\n\n“Be serious.”\n\nThere wasn’t any reason not to tell him. At worst, he’d do nothing. At best,\nhe might armtwist Mitre into cooperating. So I explained the traces to Jim\nChristy, and he seemed surprised, but satisfied.\n\n“I’ll call the Virginia FBI,” Jim said. “Maybe we can get some action from our\nend.”\n\n“Then you know something I don’t. The Oakland office won’t lift a finger\nunless there’s a million dollars involved.”\n\nJim explained that the FBI offices are pretty much autonomous. What excites\none agent, another won’t consider worthwhile. “It’s the luck of the draw.\nSometimes you get the elevator …”\n\n“… and sometimes you get the shaft.” I wished him luck, asked him to keep me\nposted, and went back to my logbook. Seemed like the rumors were true. No\npolice agency trusted another. The only way to solve the problem was to tell\neveryone who might be able to help. Sooner or later, someone might take\naction.\n\nNone of us, at that time, would have guessed anything close to the truth. None\nof us—not the CIA, not the FBI, not the NSA, and certainly not me—knew where\nthis twisted path would lead.\n\n\n![](images/Stol_9780307819420_epub_027_r1.jpg) The next morning I arrived at\nthe lab to find nothing more than a couple stale phone messages. My boss\nwanted me to call our funding agency, the Department of Energy—“Give them a\nheads-up.” And Dan Kolkowitz called from Stanford.\n\n“I would have sent you electronic mail,” Dan said, “but I’m worried that\nsomeone else might read it.” We both had learned that hackers scan electronic\nmail. The simple solution was to use the phone.\n\nIn between bites of a cashew-butter sandwich, I told Dan about my traces to\nMitre, omitting any mention of the CIA. No need to start rumors about someone\nin Berkeley cooperating with Big Brother.\n\nDan took it all in. “Strange. I called you to say that we’ve just traced our\nhacker into Virginia. McLean.”\n\nMy tongue stuck to my mouth—maybe it was cashew-butter—and it took a moment to\ntalk. “But your hacker’s not the same guy that I’m following.”\n\n“Yeah. Maybe a group of hackers are using the same methods to attack different\ncomputers. In any case, I know the name of the hacker that’s breaking into\nStanford.”\n\n“How’d you get that?”\n\n“Simple. We did the same thing as you: printed out everything the hacker\ntyped. Well, one night, the hacker logged into our Stanford Unix computer and\ntried to solve his homework. It was a simple calculus problem, solving the\narea under a curve by counting squares. But the hacker loaded the entire\nproblem into our computer, including his name and his instructor’s name.”\n\n“Ha! So who is he?”\n\n“I’m not sure. I know his name is Knute Sears. He’s in the fourth period math\nclass, taught by a Mr. Maher. But I haven’t any idea where he is. I’ve\nsearched the phone books in Stanford, and I can’t find him.”\n\nDan and I both realized that his hacker must be a high school student. Finding\nthe area under a curve is introductory calculus.\n\n“So how do you find a high school student named Sears?” Dan asked. “Ever heard\nof a directory of all kids in high school?”\n\n“No, but maybe there’s a directory of high school math teachers.” There’s a\ndirectory of everyone else, I figured.\n\nWe compared our logs, and again decided that we were following two different\npeople. Perhaps Knute Sears did know the hacker that was breaking into my\nsystem, but they certainly weren’t the same guy.\n\nAfter I hung up, I hopped on my bike and coasted down to campus. Surely the\nUniversity library would have a directory of high school teachers. No luck.\nFinding an individual isn’t easy when you know their name but not their city.\n\nAs a last straw, I could call my sister, Jeannie, in Virginia. Life was a\nlittle zooey for her. What was it like, from my sister’s perspective, to be\nsucked into this ever-widening vortex of computo-crud?\n\nAll I needed at first was a little telephone work. I’d be most appreciative if\nshe could call around the McLean area high schools to try and locate the\nmystery math teacher, Mr. Maher. Compared to the FBI’s foot-dragging, any help\non the East Coast, no matter how minor, would amount to a substantial dragnet.\nFurthermore, Jeannie had experience with the Department of Defense—well,\nanyone was more experienced with the military than me. I trusted Jeannie’s\ndiscretion; even if she did no more than just listen, it would be a service.\n\nI phoned Jeannie at work and launched into the requisite background\nexplanation, but as soon as I dropped the words, “hacker” and “Milnet,” she\nsaid, “Okay, what do you want from me?” It turned out that the Navy research\nand development center she worked for had warned its support staff about the\nrisks of leaky computers.\n\nJeannie did attach one thin string to her offer of help. “It would be real\nsweet if you could get someone to write me a nice, official thank-you note.\nSay, from the OSI or the FBI, or whoever.”\n\nWhen I next spoke to the OSI, I relayed Jeannie’s request. They assured me\nthat this was easy for them.… “We’re really good at writing notes.” (Hardly.\nDespite abundant promises in the next year, from majors, colonels and\ngenerals, my sister was never to receive her official pat on the back.\nEventually, we concluded that it’s just not possible for someone in one part\nof the federal bureaucracy to officially thank someone in another.)\n\nAt any rate, Jeannie decided to start her investigation during her lunch\nbreak. And she called back with something to report within an hour.\n\n“The public high school that’s closest to Mitre is McLean High School, so I\nstarted there,” she said. “I asked to talk to a math teacher named Mr. Maher.\nThey repeated the name, said, ‘One moment please,’ and connected me to\nsomeone. At that point, I hung up.”\n\nCould it have been that my sister, in one phone call, had gotten more done\nthan the FBI? Gee, maybe I should impose on her further. “How about dropping\nby that school and see if you can spot any computers—most schools have ’em.\nAlso, see if you can find Knute Sears in their yearbook. But be careful. The\nway I’ve got him scoped, he’s extremely skittish. Don’t spook the guy.”\n\n“Okey doke, I’ll take a long lunch tomorrow.”\n\nThe next day, while I pedaled the verdant hills of Berkeley, my sister\ncircumnavigated the Washington, D.C. beltway, feeling alternately exhilarated\nand foolish.\n\nIt turns out that McLean is the home of loads of elected officials,\npolicymakers, and upper-end military leaders. Jeannie reports that it looks\nlike the “apotheosis of the affluent second-ring suburb,” though I’m not sure\nwhat that means.\n\nAnd on that bright Virginia autumn day, its high school seemed a distillation\nof all the myths surrounding the Great American High School. Classes had just\nlet out. Expensively dressed kids spilled out of the front door. The student\nparking lot included Mercedes, BMWs, and an occasional Volvo. Jeannie’s pride\nand joy, a beat-up ’81 Chevy Citation, shrank to the remote outskirts of the\nlot in self-conscious mortification.\n\nJeannie reported that, like her car, she felt discomfort, not to mention an\nattack of absurdity, snooping around a suburban school.\n\nNow, my sister has better reason than most to hate being in a high school. In\nher younger and more vulnerable years, she taught eleventh-grade English. Now,\nteenagers give her the hives, especially teenagers that don’t belong to her.\nReally affluent ones are the worst, she reports.\n\nUnder the guise of a concerned parent, Jeannie visited the school office and\nsat for half an hour, scanning yearbook listings of the swim team, the Latin\nscholars, the debaters, for just one mention of the apocryphal Knute Sears. No\ndice.\n\nHaving thoroughly exhausted the resource material and convinced that there was\nno Knute at McLean, she turned her attention to the teachers’ mailboxes. Sure\nenough, one was labeled, “Mr. Maher.”\n\nAbruptly, a clerk appeared and asked what she wanted to see. With a ditsiness\nreminiscent of Gracie Allen, my sister burbled, “Gee, I don’t know, dear.…\nWell, well, what do you know? Here it is, right in front of my eyes.” The\nclerk smiled patronizingly as Jeannie grabbed a brochure from the nearest pile\non the counter—it turned out to explain how to register for night school. Half\ncovering a silly-me smirk with her hand, she waved bye-bye with the other hand\nand booked out of there.\n\nHer covert operation complete, Jeannie called me that afternoon. Stanford’s\nmythical Knute Sears was to remain a myth. He’d never registered at McLean\nHigh School. And their Mr. Maher wasn’t a math teacher. He taught history,\npart time.\n\nAnother dead end. Even today, I can’t talk to my sister without feeling acute\nembarrassment for sending her on a wild goose chase.\n\nI called Dan at Stanford with the bad news. He wasn’t surprised. “It’ll take a\nlong investigation. We’re giving up on the FBI. The Secret Service has a\ncomputer crime division that’s eager to work on the case.”\n\nThe Secret Service was helping Stanford? Weren’t they the people that caught\ncounterfeiters and protected the president?\n\n“Yes,” Dan said, “but they also investigate computer crimes. The Department of\nthe Treasury tries to protect banks from computer fraud, and the Secret\nService is a branch of the Treasury Department.”\n\nDan had found a way around a recalcitrant FBI. “They don’t know much about\ncomputers, but they’ve got moxie. We’ll provide the computer expertise, and\nthey’ll get the warrants.” Moxie?\n\nIt was too late for me, though. Our local FBI still didn’t care, but the FBI\noffice in Alexandria, Virginia, had noticed. Someone—Mitre, the Air Force, or\nthe CIA—had leaned on them, and Special Agent Mike Gibbons called.\n\nIn a couple minutes, I realized that at last, I was speaking to an FBI agent\nwho knew computers. He’d written Unix programs, used modems, and wasn’t scared\nby databases and word processors. His latest hobby was playing Dungeons and\nDragons on his Atari computer. J. Edgar Hoover must be rolling in his grave.\n\nBetter yet, Mike didn’t mind communicating by electronic mail, although since\nanyone might intercept our traffic we used an encryption scheme to keep our\nconversations private.\n\nFrom his voice, I guessed Mike wasn’t over thirty, but he knew computer law\nthoroughly. “There’s at least a violation of U.S. Code Section 1030. Probably\nbreaking and entering as well. When we find him, he’ll be looking at five\nyears or $50,000.” I liked how Mike said “when” rather than “if.”\n\nI explained my agreement with Mitre. “When the hacker next shows up in\nBerkeley, Bill Chandler will trace Mitre’s network from the inside. We’ll find\nhim then.”\n\nMike wasn’t so sure, but at least he didn’t object to my plan. The only\nmissing piece was the hacker: he hadn’t shown up since Halloween—a two-week\nhiatus. Each morning, I’d check the recorders. Day and night, I’d wear my\nbeeper, waiting for the hacker to step on our invisible tripwire. But not a\npeep.\n\nFinally, on November 18, my hacker returned to his Sventek account. He entered\nat 8:11 in the morning and stayed around for half an hour. Immediately, I\ncalled Mitre in McLean. Bill Chandler wasn’t in, and a stuffy manager told me\nthat only Bill Chandler was authorized to trace Mitre’s internal network. He\ntalked about “strict guidelines” and “certified secure networks.” I cut him\noff. With the hacker live on my system, I didn’t need to listen to some big-\nshot manager. Where were the technicians, the people who actually knew how\nMitre’s system worked?\n\nAnother chance to catch the hacker—foiled.\n\nHe showed up again in the afternoon. This time I got through to Bill Chandler,\nand he ran over to check his outbound modems. Sure enough, someone had dialed\nout through Mitre’s modem, and it looked like a long-distance call. But where\nwas the connection originating?\n\nBill explained, “Our network within Mitre is complex, and it’s not easy to\ntrace. We don’t have individual wires connecting one computer to another.\nInstead, a lot of signals travel on a single wire, and connections have to be\ntraced by decoding the addresses of each packet on our ethernet.”\n\nIn other words, Mitre couldn’t trace the calls.\n\nDamn. Someone was calling out from Mitre, but they couldn’t find where the\nhacker was coming from. We still didn’t know if it was a Mitre employee or\nsomeone from the outside.\n\nFurious, I looked over the printout from the hacker. Nothing new there. He\ntried once again to slip into the Army base in Anniston but was turned away.\nThe rest of the time he spent searching my Berkeley computer for words like\n“nuclear bomb,” and “SDI.”\n\nBill promised to get his best technicians on the problem. A few days later,\nwhen the hacker showed up, I heard the same story. No doubt that someone was\ndialing out from Mitre’s computer system. But they couldn’t trace it. They\nwere baffled. Who was behind it? And where was he hiding?\n\nOn Saturday, Martha dragged me on a day’s outing to Calistoga, where the\ngeysers and hot springs attract butterflies, geologists, and hedonists. For\nthe latter, there are mud baths, said to be the height of Northern California\ndecadence. For twenty dollars, you can be parboiled in an ooze of volcanic\nash, peat, and mineral water.\n\n“It’ll take your mind off your work,” Martha said. “You’ve been all twisted up\nover this hacker—a break will do you good.” Mired in an oversized bathtub\ndidn’t sound like a recipe for rejuvenation, but I’ll try anything once.\n\nWallowing in this private swamp, my mind drifted off to thoughts of Mitre. My\nhacker used Mitre’s outgoing telephone lines to cross the country. Stanford\nhad traced one hacker to McLean; likely he came through Mitre. Maybe Mitre\nprovided a central point for hackers, a sort of switchboard to place their\ncalls. That would mean the hackers weren’t Mitre employees, but were from\noutside the company.\n\nHow could this happen? Mitre would have to make three mistakes. They’d have to\ncreate a way for anyone to connect freely to their local network. Then, they’d\nhave to allow a stranger to log onto their computer. Finally, they’d have to\nprovide unaudited outgoing long-distance telephone service.\n\nThey’d met the third condition: the modems connected to their internal network\ncould call all over the country. We’d traced our troubles into those very\nlines.\n\nBut how could someone connect into Mitre? Surely they wouldn’t allow just\nanyone to dial into their network. As Bill Chandler had said, they’re running\na secure shop. Military secrets and stuff like that.\n\nWhat other ways could you get into Mitre? Over some network, perhaps? Could a\nhacker get there through Tymnet? If Mitre paid for Tymnet service and didn’t\nprotect it with passwords, you could call them from anywhere for free. Once\nconnected, Mitre’s internal network might let you turn around and call out.\nThen you could dial anywhere, with Mitre picking up the tab.\n\nIt would be easy to test my hypothesis: I’d become a hacker. I’d go home and\ntry to use Tymnet to connect to Mitre, trying to break into a place I wasn’t\nsupposed to be.\n\nThe mud smelled of sulfur and peat moss, and felt like a hot primordial ooze.\nI enjoyed the mud bath and the sauna that came afterward, but I still couldn’t\nwait to get out of the mud and return home. I had a lead. Or at least a hunch.\n\n\n![](images/Stol_9780307819420_epub_028_r1.jpg) Logbook, Sunday, November 23,\n1986\n\n10:30 A.M. Oakland Tymnet access number is 415/430-2900. Called from my\nMacintosh at home. 1200 baud, no parity. Tymnet asked for a username. I\nentered _MITRE_. Response: _Welcome to Mitre-Bedford_.\n\n10:40 A.M. Mitre has an internal network which gives a menu. Fourteen choices,\napparently different computers within Mitre. I try each in succession.\n\n10:52 A.M. One choice, _MWCC_ leads to another menu. That menu has twelve\nchoices. One choice is _DIAL_. I try:\n\n_DIAL 415 486 2984_ no effect\n\n_DIAL 1 415 486 2984_ no effect\n\n_DIAL 9 1 415 486 2984_ Connected into Berkeley computer.\n\nConclusion: An outsider can connect into Mitre through Tymnet. No password\nnecessary. Once in Mitre, they can dial out, either locally or long distance.\n\nMWCC means, “Mitre Washington Computing Center”; Bedford means “Bedford\nMassachusetts.” I’d entered Mitre in Bedford, and popped out five hundred\nmiles away in McLean.\n\n11:03 A.M. Disconnect from Berkeley computer, but remain at Mitre. I request\nconnection into system AEROVAX. It prompts for username. I enter “Guest.” It\naccepts and logs me in, without any password. Explore Aerovax computer.\n\nAerovax has programs for some sort of airport flight safety. Program to find\nallowable landing angles for high-speed and low-speed aircraft approaches.\nPresumably funded by government contracts.\n\nAerovax connects to several other computers over Mitre’s network. These are\npassword protected. “Guest” is not a valid username on these other Mitre\ncomputers. (I’m not sure they’re even at Mitre.)\n\nWait—something’s wrong here. The network controlling software doesn’t seem\nnormal—its greeting message shows up too quickly, but it completes its\nconnection too slowly. I wonder what’s in that program.…\n\nAha! It’s been modified. Someone has set a Trojan horse in the Aerovax network\nsoftware. It copies network passwords into a secret file for later use.\n\nConclusion: someone’s been tampering with Mitre’s software, successfully\nstealing passwords.\n\n11:35 A.M. Disconnect from Mitre and update logbook.\n\nReading my logbook today, I remember an hour of poking around Mitre’s internal\nnetwork. At once it felt exciting and forbidden. Any minute, I expected\nsomeone to send a message on my computer screen, “We caught you. Come out with\nyour hands up.”\n\nNo doubt Mitre had left a gaping hole in their system. Anyone could make a\nlocal telephone call, tell Tymnet to connect to Mitre, and spend an afternoon\nfooling around with Mitre’s computers. Most of their machines were protected\nwith passwords, but at least one was pretty much wide open.\n\nI remembered Mitre’s pious disclaimer, “We’re running a secure shop, and\nnobody can break in.” Right.\n\nThe “Guest” account on their Aerovax let anyone on. But the Trojan horse was\ndeadly. Someone had tampered with their network program to copy passwords into\na special area. Every time a legitimate employee used the Aerovax computer,\nher password was stolen. This gave the hacker keys to other Mitre computers.\nOnce the hacker penetrated their armor, he could roam anywhere.\n\nHow deeply was Mitre’s system infested? By listing their directory, I saw that\nthe Trojan horse was dated June 17. For six months, someone had silently\nbooby-trapped their computers.\n\nI couldn’t prove that it was the same hacker that I was dealing with. But this\nmorning’s exercises showed that anyone could enter Mitre’s system and dial\ninto my Berkeley computers. So the hacker wasn’t necessarily at Mitre. He\nmight be anywhere.\n\nIn all likelihood, Mitre served as a way station, a stepping stone on the way\nto breaking into other computers.\n\nThe McLean connection became clear. Someone dialed into Mitre, and turned\naround and dialed out from them. This way, Mitre paid the bills both ways: the\nincoming Tymnet connection and the outgoing long-distance telephone call. Even\nnicer, Mitre served as a hiding place, a hole in the wall that couldn’t be\ntraced.\n\nMitre, the high-security defense contractor—I’d been told that you can’t get\npast their lobby without showing picture ID. Their guards wear guns, and their\nfences are barbed. Yet all it takes is a home computer and a telephone to\nprowl through their databases.\n\nMonday morning, I called Bill Chandler at Mitre and told him the news. I\ndidn’t expect him to believe me, so I wasn’t disappointed to hear him insist\nthat his company was “highly secured and sensitive to any security problems.”\n\nI’d heard it before. “If you’re so concerned about security, why isn’t anyone\nauditing your computers?”\n\n“We do. We keep detailed records of how each computer’s used,” Bill said. “But\nthat’s for accounting, not to detect hackers.” I wondered what his people\nwould do about a 75 cent accounting error.\n\n“Ever hear about a system called the Aerovax?”\n\n“Yeah, what about it?”\n\n“Just wondering. Hold any classified data?”\n\n“Not that I know. It’s for an airport control system. Why?”\n\n“Oh, just wondering. You ought to check it over, though.” I couldn’t admit\nthat I’d danced through his system yesterday, discovering the Trojan horse.\n“Know any way for a hacker to enter your system?”\n\n“It had better be impossible.”\n\n“You might check out your public access dial in ports. While you’re at it, try\naccessing Mitre’s computers over Tymnet. Anyone can connect to your system,\nfrom anywhere.”\n\nThis latest news woke him up to some serious problems in his system. Mitre\nwasn’t inept. Just semi-ept.\n\nBill wasn’t sure how to react, but he wouldn’t keep his system open any\nlonger. I couldn’t blame him. His computers were naked.\n\nMostly, he wanted me to keep my mouth shut.\n\nI’d shut up, all right, on one condition. For months, Mitre’s computers had\ncalled around the country, using expensive, AT&T long-distance telephone\nlines. There must be phone bills for those calls.\n\nIn Berkeley, five of us shared a house. We had a monthly dinner party when the\nphone bill arrived. With poker faces, each of us would deny making _any_ of\nthe calls. But somehow, eventually, every call was accounted for, and the bill\npaid.\n\nIf the five of us could haggle through a phone bill, Mitre must be able to as\nwell. I asked Bill Chandler, “Who pays the phone bills for your computer?”\n\n“I’m not sure,” he replied. “Probably central accounting. I never see them.”\n\nThat’s how the hacker got away with it for so long. The people paying the\nphone bills never talked to the managers of the computers. Strange. Or was it\ntypical? The computer’s modems run up a long-distance phone bill. The phone\ncompany sends the bill to Mitre, and some faceless accountant signs a check.\nNobody closes the loop. Nobody asks about the legitimacy of those dozens of\ncalls to Berkeley.\n\nBill wanted me to be quiet about these problems. Well, yes, but I had a price.\n“Say, Bill, could you send me copies of your computer’s phone bills?”\n\n“What for?”\n\n“It might be fun to see where else this hacker got into.”\n\nTwo weeks later, a thick envelope arrived, stuffed with long-distance bills\nfrom Chesapeake and Potomac.\n\nAt home, my housemates and I haggled over a twenty-dollar phone bill. But I’d\nnever seen thousand-dollar bills. Every month, Mitre had paid for hundreds of\nlong-distance calls, all over North America.\n\nBut these weren’t people reaching out to touch each other. These bills showed\nMitre’s computer dialing hundreds of other computers. (I proved this to myself\nby calling a few. Sure enough, in each case, I heard a modem answer with a\nwhistle.)\n\nNow here’s some useful information. Mitre might not be interested in analyzing\nit, but together with my logbook, I might be able to understand how far the\nhacker had penetrated. I’d just have to somehow separate the hacker’s calls\nfrom the normal calls.\n\nPlenty of the calls were obvious hacking. On the list were lots of calls to\nAnniston, Alabama. And there were the calls to Tymnet in Oakland—they’d cost\nme a galaxy to trace.\n\nBut some of the calls on the bills must be legitimate. After all, Mitre’s\nemployees must call computers to transfer data or copy the latest software\nfrom the West Coast. How could I separate the hacker’s calls?\n\nBack home, when our phone bill arrived, Martha cooked up dinner, Claudia did\nthe salad, and I baked cookies.* Afterward, stuffed on chocolate chips, we’d\ndivvy up the phone bill.\n\nSitting around the dining table, my housemates and I had no problem figuring\nout who’d made which long-distance calls on our bill. If I had made a call to\nBuffalo from 9:30 until 9:35 and another to Baltimore from 9:35 to 9:45, then\nit was likely that I’d made the call to New York from 9:46 to 9:52.\n\nLooking at Mitre’s phone bills, I knew that only the hacker would call the\nArmy base in Anniston, Alabama. Pretty likely that a phone call made a minute\nafter calling Anniston belonged to the hacker. Same for a call that ended just\nbefore dialing Alabama.\n\nIn physics, this is correlation analysis. If you see a solar flare today and\ntonight there’s a bright aurora, chances are that these are correlated. You\nlook at things that occur close together in time, and try to find the\nprobability that they’re somehow connected.\n\nCorrelation analysis in physics is simply common sense.\n\nWell, here were six months of phone bills. Dates, times, phone numbers, and\ncities. Probably five thousand in all. Enough that I couldn’t analyze it by\nhand. Perfect for analyzing on a computer—there’s plenty of software written\nto search out correlations. All I had to do was enter them into my Macintosh\ncomputer and run a few programs.\n\nEver type five thousand phone numbers? It’s as boring as it sounds. And I had\nto do it twice, to make sure I didn’t make any mistakes. Took me two days.\n\nTwo days to enter the data, and an hour to analyze it. I told my program to\nassume that the hacker made all calls to the Anniston Army base. Find all\ncalls that immediately preceded or trailed those calls. It took a minute, and\nshowed me that the hacker had called Oakland’s Tymnet many times. Aah, the\nprogram behaved reasonably.\n\nI spent the afternoon tinkering with the program, refining its statistical\ntechniques and watching the effect of different algorithms on the output. It\ndetermined the probability that each call was made by the hacker. Cute—just\nthe thing to settle arguments at home.\n\nIt wasn’t until the evening that I realized what the program was telling me:\nthis hacker hadn’t just broken into my computer. He was into more than six,\nand possibly a dozen.\n\nFrom Mitre, the hacker had made long-distance connections to Norfolk, Oak\nRidge, Omaha, San Diego, Pasadena, Livermore, and Atlanta.\n\nAt least as interesting: he had made hundreds of one-minute-long phone calls,\nall across the country, to Air Force bases, Navy shipyards, aircraft builders,\nand defense contractors. What can you learn from a one-minute phone call to an\nArmy proving ground?\n\nFor six months, this hacker broke into Air Force bases and computers all\nacross the country. Nobody knew it. He was out there, alone, silent,\nanonymous, persistent, and apparently successful—but why? What’s he after?\nWhat’s he already learned? And what’s he doing with this information?\n\n* Two eggs, 1 cup brown sugar, 1/2 cup regular sugar, 2 sticks softened butter. Fold in 2 1/4 cups flour, 1/2 teaspoon salt, 1 teaspoon baking soda, and a couple tablespoons of vanilla. For an extra chocolate jag, mix in 3 tablespoons of cocoa. Oh, don’t forget 2 cups of chocolate chips. Bake at 375 degrees for 10 minutes.\n\n\n![](images/Stol_9780307819420_epub_029_r1.jpg) Mitre’s phone bills showed\nhundreds of telephone calls all around the country, most of them a minute or\ntwo long. But no human voice spoke over that line—it was one computer dialing\nanother.\n\nMy boss’s voice, though, was singularly human. Around the end of November, Roy\nKerth stopped in my office, and found me asleep under my desk.\n\n“Whacha been doing for the past month?”\n\nI could hardly say, “Oh, typing in phone bills from some East Coast defense\ncontractor.” Reminding him of my chase would jog his memory of a three-week\nlimit. Quickly, I thought of our department’s new graphics terminal—a spiffy\nnew toy that displays three-dimensional images of mechanical devices. I’d\nfiddled with it for an hour, just long enough to learn how difficult it was to\nuse. But it was an excuse to get the boss off my back, and I told him, “Oh,\nI’m helping some astronomers design their telescope with our new display\nterminal.” This wasn’t a total lie, since we’d talked about doing this. For\nall of five minutes.\n\nMy maneuver backfired. Roy smiled slyly and said, “OK. Next week show us some\npretty pictures.”\n\nBy never showing up before noon, I’d managed to avoid half of the department’s\nmeetings. If I didn’t have something by next week, no doubt my wings would get\nclipped.\n\nTime to slide the hacker onto the back burner—and just as the trail was\nheating up.\n\nOne week to learn how to program the beast, figure out what the astronomers\nneeded, and get something on the screen. I knew zero about computerized\ndesign. And the programming language was from the twenty-first century: it\nclaimed to be “an object-oriented language with graphical inheritance.”\nWhatever that meant.\n\nSo I wandered over to the telescope design team, where Jerry Nelson and Terry\nMast were arguing over how much their telescope would bend due to gravity.\nWhen looking at stars straight overhead, gravity wouldn’t bend the telescope\ntube. But when pointing near the horizon, the tube would bow slightly. Just\nenough to upset the delicate optical alignment. They wanted to know how much,\nand could I show the effect on the computer.\n\nThis seemed like fun—at least more fun than figuring out what “graphical\ninheritance” meant. We talked for a while, and Jerry mentioned that Professor\nErik Antonsson had written a program to display the telescope on a graphics\ndisplay terminal. The same type as I was supposed to program.\n\n“You mean that someone has already written the program to solve your problem\nand display a picture on the screen?” I asked.\n\n“Yes,” the astronomer explained. “But it’s down at Caltech in Pasadena.\nDoesn’t do us much good four hundred miles away. We need the results now.”\n\nI just had to get the Caltech program up to Berkeley and fit it into my Vax\ncomputer. No need to even figure out how to program the beast.\n\nI called Professor Antonsson at Caltech. He’d be happy if we used his program,\nbut how would he send it to us? Mail would take a week. Faster to send it\nelectronically. Aah—when you need a program, don’t mail a tape. Just ship it\nover the network. In twenty minutes, the program percolated across the wires,\nand settled into my computer.\n\nWell, Professor Antonsson had done a super job of programming the problem. By\nnine that evening, I’d customized his program for my system and the new\ntelescope data.\n\nAmazingly, the damn thing worked, though not quite the first time. By 2 A.M.,\nI got it to draw a multicolored picture of the Keck Telescope, complete with\nstruts, bearings, and mirrors. You could see where the tube bent, where the\nstresses built up, and which sections needed reinforcing. Technology comes\nthrough again.\n\nOne evening of real work, and I was off the hook. The hacker was back on the\nfront burner.\n\nBut not a peep from him. My alarms were set, the monitors active, but he’d\nbeen invisible for two weeks. On my way home, I wondered if he too might have\nan urgent project that kept him away from my computer. Or had he found a new\nway to enter the Milnet, completely bypassing my traps?\n\nAs usual, I slept late the next morning. (No need to work early when\nThanksgiving weekend was coming up.) At 11:30, I pedaled up the hill and\nducked into work, ready to show off my zero-work computer display. But once in\nmy office, I went back to wondering why the hacker wasn’t showing up. Time to\ncall Mitre, and find out what they’d done.\n\nBill Chandler’s voice crackled through a noisy long-distance connection. Yes,\na week ago, he’d disconnected their outgoing modems. The hacker could no\nlonger leapfrog through Mitre’s local network.\n\nThe gig was up. We didn’t know where he came from, and we’d never find out.\nSince Mitre had corked up their hole, the hacker would have to find another\npath into my system.\n\nNot likely. If someone had bolted my door shut, I’d be suspicious that they\nwere about to bust me. And I knew this hacker was paranoid. He’d disappear for\nsure.\n\nSo all my traps had been set in vain. The hacker was gone, and I’d never find\nout who he was. Three months of searching, with only a fuzzy question mark at\nthe end.\n\nNot that I should complain. Without a hacker to occupy my time, there was\nplenty of worthwhile work waiting. Like designing a telescope. Or managing a\ncomputer. And building scientific software. Jeez—I might even do something\nuseful.\n\nBut I’d miss the excitement. Running down the hallway and jumping to a\nprinter. Crowding around a computer screen, trying to trace connections\nthrough my computer out somewhere across the country.\n\nAnd I’d miss the satisfaction of building tools with which to follow him. By\nnow, my programs were almost instant. Seconds after the hacker touched my\ncomputer, my pocket pager beeped. It didn’t just tell me that the hacker was\naround. I’d programmed my pager to beep in Morse code, telling me the hacker’s\ntarget computer, his account name (usually Sventek), and which line the hacker\nhad entered from. Backup alarms and monitors made the system fail-safe.\n\nSomewhere out there, a stranger had come close to getting nailed. If only I’d\nbeen able to make one more trace.\n\nJust one more trace.\n\nThe hacker was gone, but I had a few loose ends. Mitre’s long-distance phone\nbills showed dozens of calls to a number in Norfolk, Virginia. By calling\naround (standard graduate school technique: keep pestering), I eventually\nfound that the hacker had been dialing the Navy Regional Automated Data\nCenter.\n\nWell, nobody’s stopping me, so I called the Navy data center and talked to\ntheir system manager, Ray Lynch. Ray seemed to be an outgoing, competent guy\nwho took his job very seriously. He ran an electronic mailbox\nsystem—pigeonholes for electronic mail.\n\nRay reported that back on July 23, from 3:44 until 6:26 P.M., someone had\nbroken into his Vax computer, using the account belonging to the field service\nengineers. Once inside his system, the hacker had created a new account named\nHunter.\n\nThere’s that name again. Same guy, no doubt.\n\nThe episode normally would have escaped Ray’s attention. With three hundred\nNavy officers using his computers, he’d never have noticed someone illegally\nadding a new account.\n\nBut the next day, he received a phone call from Jet Propulsion Laboratory in\nPasadena, California; the same people that run interplanetary spacecraft. An\nalert JPL operator had detected a new system manager at their mail management\ncomputer. This new user had entered from the Milnet, coming in from Virginia.\n\nJPL called Ray Lynch, and asked him why his field service people had been\nfooling with their computer. Ray didn’t wait around to ask questions. He shut\ndown his computer and changed all its passwords. The next day, he reregistered\neach of his users.\n\nSo my hacker had broken into JPL and a Navy computer. Months before I’d\ndetected him in Berkeley, he had been fooling around the Milnet.\n\nThese targets were news to me. Were they a clue to where the hacker was? Well,\nif you live in California, there’s no reason to go through Virginia to reach a\ncomputer in Pasadena. And why would someone in Virginia go through Mitre to\ndial another Virginia phone?\n\nSuppose this hacker had used Mitre to dial all his calls, except for local\nones. That meant that any state that showed up on Mitre’s phone bills was not\nthe hacker’s home. Ruled out Virginia, California, Alabama, Texas, Nebraska,\nand a dozen others. This didn’t lead anywhere, and hardly seemed convincing.\n\nI called some of the other places listed on Mitre’s phone bills. The hacker\nhad hit a college in Atlanta, Georgia. The system manager there hadn’t\ndetected it, but he wasn’t likely to, either. “We run a pretty open system.\nLots of students know the system password. The whole thing depends on trust.”\n\nThat was one way to run a computer. Leave all the doors open. Like one of my\nphysics profs: anyone could wander into his office. Didn’t do much good,\nthough. He kept his notes in Chinese.\n\nFrom talking to Ray, I learned one new wrinkle about the hacker. Up until now,\nI’d watched him exploit Unix systems. But Ray’s system was a Vax computer\nrunning the VMS operating system. The hacker might not know the Berkeley\nvariant of Unix, but he certainly knew how to break into Vax VMS systems.\n\nSince 1978, Digital Equipment Corporation had been making Vaxes, their first\nthirty-two-bit computers. They couldn’t make them fast enough: by 1985, over\nfifty thousand had been sold, at $200,000 each. Most of them used the\nversatile, friendly VMS operating system, although some contrary cusses threw\naway the VMS system, preferring the power of Unix.\n\nBoth Unix and VMS divide up the computer’s resources to give a separate area\nfor every user. There’s space reserved for the system and common space that\ncan be shared by everyone.\n\nSomehow, when you uncrate the machine and first switch it on, you’ve got to be\nable to create places for your users. If the machine comes to you protected\nwith passwords, you won’t be able to log on the first time.\n\nDigital Equipment Company answered this problem by packaging every Vax-VMS\ncomputer with three accounts, each with its own password. There’s the SYSTEM\naccount, with the password, “MANAGER.” An account named FIELD, password\n“SERVICE.” And an account USER with the password “USER.”\n\nThe instructions say to start the system running, create new accounts for your\nusers, and then change these passwords. Starting up a computer is a bit\ntricky, and well, some system managers have never changed these passwords.\nDespite Digital’s best efforts to make the system managers change those\npasswords, some never do. The result? Today, on some systems, you can still\nlog in as SYSTEM, with the password “MANAGER.”\n\nThat system account is completely privileged. From it, you can read any file,\nrun any program, and change any data. Seems nutty to leave it unprotected.\n\nThe hacker either knew about these backdoor passwords, or else he knew some\nvery subtle bug in the VMS operating system. Either way, there was little\ndoubt that he was skilled in two operating systems: Unix and VMS.\n\nSome high school students are impressive computer jockeys. But it’s a rare\nhigh school student who’s both deeply skilled and versatile—experienced in\nseveral computers. That takes time. Years, usually. Yes, most Unix systems\nfolks could exploit the Gnu-Emacs hole, once they realized its weakness. And\nmost VMS system managers knew about the not-so-secret default passwords. But\neach operating system took a couple years to become proficient in, and the\nskills weren’t very portable.\n\nMy hacker had a couple of years of Unix experience, and a couple of years in\nVMS. Probably had been system manager or administrator along the way.\n\nNot a high school student.\n\nBut not an experienced wizard, either. He didn’t know Berkeley Unix.\n\nI had been following someone in his twenties who smoked Benson and Hedges\ncigarettes. And broke into military computers, searching for classified\ninformation.\n\nBut was I following him anymore? No, not really. He wouldn’t show up again.\n\nTeejay called in the afternoon. “I’m just checking to hear what’s new about\nour boy.”\n\n“No, nothing really. I think I know how old he is, but not a whole lot.” I\nstarted explaining about the Navy data center and the backdoor passwords, but\nthen the CIA agent interrupted.\n\n“Got printouts of those sessions?”\n\n“Well, no, my direct evidence is Mitre’s phone bills. If that’s not\nconvincing, there’s other pointers. He created an account with the name\nHunter. Same as at Anniston.”\n\n“Did you write this in your logbook?”\n\n“Sure. I put everything there.”\n\n“Could you send me a copy?”\n\n“Well, it’s kinda private.…” Teejay wouldn’t send me copies of _his_ reports.\n\n“Come on, be serious. If we’re ever going to light a fire under the ‘F’\nentity, I’ve got to know what’s happening.”\n\nThe “F” entity? I searched my memory. Fourier transform? Fossils? Finger\npainting?\n\n“What’s the ‘F’ entity?” I asked, somewhat humiliated.\n\n“You know, the entity in Washington,” Teejay replied with a touch of\nannoyance. “J. Edgar’s boys. The Bureau.”\n\nWhy not just say the FBI?\n\n“Oh, I get it, you want my logbook to convince the ‘F’ entity to do\nsomething.” Entity, indeed. Spooktalk.\n\n“Yeah. Just send it to me.”\n\n“What’s your address?”\n\n“Just mail it to Teejay, Zip Code 20505. It’ll reach me.”\n\nNow there’s status. No last name, no street, no city, no state. I wondered if\nhe ever got junk mail.\n\nWith the CIA off my neck, I might as well go back to real work. I played\naround with Professor Antonsson’s graphics program for a while, and found that\nit was amazingly simple to understand. All this hype about object-oriented\nprogramming just meant that you didn’t write programs using variables and data\nstructures; instead, you told the computer about things. To describe a robot,\nyou’d detail its feet, legs, joints, torso, and head. No need to talk about\nX’s and Y’s. And “graphical inheritance” just meant that when the robot moved\nits leg, the feet and toes moved automatically. You didn’t have to write a\nseparate program to move each object.\n\nNeat. After a day or two of fooling with the Caltech program, its simplicity\nand elegance came shining through. What seemed a hairy programming challenge\nturned out to be easy. So I spiffed up the display, adding colors and titles.\nThe boss wanted me to jump through hoops; I’d put up a three-ring circus.\n\n\n![](images/Stol_9780307819420_epub_030_r1.jpg) Thanksgiving would be a corker.\nWith her bicycle and backpack, Martha had hauled home forty pounds of\ngroceries. She made only a few sarcastic comments about roommates who sleep\nlate, and set me to putting stuff away and cleaning the house.\n\n“Put away the veggies, honey,” she said. “I’m going to the Safeway.” How could\nthere possibly be more food to get? Seeing my amazement, she explained that\nthis was just the fresh stuff, and she still had to get the goose, flour,\nbutter, cream, and eggs. A corker, for sure.\n\nI put the food away and climbed back in bed. I woke up to the smell of\nbiscuits and goose wafting through the house. We expected Martha’s grad school\nfriends who couldn’t go home (or preferred Martha’s cooking to mom’s), a\ncouple of law professors, a few hungry warriors from her aikido dojo, and her\nzany friend Laurie. My conscience finally responded to all Martha’s bustling,\nand I revved up our 250-horsepower Hoover.\n\nAs I vacuumed the room, our roommate Claudia returned from a violin rehearsal.\n“Oh, don’t do that,” she exclaimed, “that’s my job.” Imagine—a roommate that\nenjoyed doing housework. Her only fault was playing late-night Mozart.\n\nThanksgiving passed by idyllically, with friends wandering in, helping in the\nkitchen, talking, and lounging around. It was an all-day feed, starting with\nfresh oysters from the San Francisco wharf, moving on leisurely to Martha’s\nwild mushroom soup, then the goose. Then we lay around like beached whales\nuntil we worked up the energy to take a short walk. Over pie and herbal tea,\nthe talk turned to law, and Martha’s friend Vicky held forth on environmental\nregulation while a couple of professors argued over affirmative action.\n\nFinally, too full and contented for intelligent conversation, we lay in front\nof the fire and roasted chestnuts. Vicky and Claudia played piano duets;\nLaurie sang a ballad, and I thought about planets and galaxies. Worries about\ncomputer networks and spies seemed unreal in this warm world of friends, food,\nand music. A down-home Thanksgiving in Berkeley.\n\nAt the lab, I forgot about the hacker. He’d been gone for almost a month. Why?\nI didn’t know.\n\nThe astronomers fiddled with their new graphics display, studying ways to\nstrengthen their telescope. By now, I’d figured out how to animate the\ndisplay, so they could zoom in on interesting parts, and rotate it on the\nscreen. Object-oriented programming—by accident, I’d learned a new buzzword.\nThe astronomers didn’t care, but I had to give a talk to computer folks.\n\nOn Wednesday, I was all set to dazzle the other systems folks. I’d memorized\nall the jargon and set up the display so that it wouldn’t foul up at the last\nminute.\n\nA dozen computer whizzes showed up at three o’clock. The display system worked\nflawlessly, and the Caltech software loaded without a hitch. Computer people\nare accustomed to boring talks on databases and structured programming, so\nthis three-dimensional color graphics display amazed them all.\n\nTwenty-five minutes into the show, I was answering a question about the\nprogramming language (“It’s object oriented, whatever that means …”) when my\npocket pager beeped.\n\nThree beeps. Morse code for the letter S. S for Sventek. The hacker had\nconnected to our system on the Sventek account.\n\nDamn. A month of quiet, and the SOB shows up now.\n\nWell, the show must go on. I couldn’t acknowledge that I was still chasing the\nhacker—my three-week allowance had long ago been used up. But I had to get\nover to the monitoring post and watch what he was doing.\n\nOf course. I stopped showing pretty pictures and began describing an obscure\narea of galactic astronomy. It took five minutes, but people began to squirm\nand yawn. My boss looked at his watch, and ended the meeting. Another\napplication for advanced astronomy.\n\nI dodged the gang in the hallway, and slipped into the switchyard. The hacker\nwasn’t active on any of my monitors.\n\nHe’d left his footprints though. The printer showed him here for two minutes.\nLong enough to check out our system. He checked that the system manager wasn’t\naround, then looked for the Gnu-Emacs hole—it still hadn’t been patched. And\nhe listed his four stolen accounts—no change there. Then, poof, gone.\n\nNo way to trace him after the fact. But the monitor that caught him was on the\nTymnet line. So he was coming in on the same line. Was his path from Mitre to\nAT&T to Pacific Bell to Tymnet?\n\nTime to call Mitre. Bill Chandler answered. “No, he couldn’t have used our\nmodems. They’re all turned off.”\n\nReally? Easy to check. I called Mitre through Tymnet. I could still reach into\nMitre’s network, but Bill had indeed shut off his modems. A hacker could fool\nwith his computers, but couldn’t get out. My hacker had come from somewhere\nelse.\n\nShould I feel elated or despondent? The varmint was back with super-user\nprivileges. But maybe this time I’d nail the bastard. If he kept returning to\nhis roost, I’d trace him for sure.\n\nI suppressed my vindictive feelings towards my unseen adversary. Research was\nthe answer. The question wasn’t, “Who’s doing it?” I’d get no satisfaction if\na postcard showed up saying, “Joe Blatz is breaking into your computer.”\n\nNo, the problem was to build the tools to find who was there. What if I traced\nthe whole connection, and it turned out to be a red herring? At least, I’d\nunderstand the phenomenon. Not all research yields exactly the results you\nexpect.\n\nMy tools were sharp. The alarms triggered as soon as he entered his stolen\naccount names. If they failed, a backup program, hidden behind my Unix-8\ncomputer would detect him within a minute. When the hacker touched the\ntripwire, my beeper told me about it instantly.\n\nThe hacker could hide, but he couldn’t violate physics. Every connection had\nto start somewhere. Whenever he showed up, he exposed himself. I just had to\nbe alert.\n\nThe fox was back. This hound was ready for the chase.\n\n\n![](images/Stol_9780307819420_epub_031_r1.jpg) After a month’s disappearance,\nthe hacker was back on my system. Martha wasn’t happy about this; she began to\nsee a mechanical rival in my pocket pager. “How long before you’re free from\nthat electronic leash?”\n\n“Just a couple more weeks. It’ll be over by New Year’s Day, for sure.” Even\nafter three months of chasing, I still thought I was close to the end.\n\nI was sure I’d catch him: since the hacker couldn’t hide behind Mitre anymore,\nthe next trace would move us one step closer. He didn’t know it, but he was\nrunning out of space. In a few more weeks he’d be mine.\n\nFriday, December 5, the hacker showed up again at 1:21 in the afternoon. He\nraised periscope, looking for our system manager and then listed our password\nfile.\n\nThis was the second time he’d ripped off my password file. What for? There’s\nno key to unlock these encrypted passwords: they’re just goulash until they’re\ndecrypted. And our encryption software is a one-way trapdoor: its mathematical\nscrambling is precise, repeatable, and irreversible.\n\nDid he know something that I didn’t? Did this hacker have a magic decryption\nformula? Unlikely. If you turn the crank of a sausage machine backwards, pigs\nwon’t come out the other end.\n\nFour months from now, I’d realize what he was doing, but for now, I had my\nhands full trying to trace him.\n\nNine minutes after he showed up, he disappeared. Enough time for me to trace\nthe connection to Tymnet. But their network sorcerer, Ron Vivier, was taking a\nlong lunch. So Tymnet couldn’t make the trace. Another chance lost.\n\nRon returned my call an hour later. “It was an office party,” he said. “I\nthought you’d given up on chasing this guy.”\n\nI explained the month-long hiatus. “We tracked him into Mitre, and they\nplugged the hole he was using. Stopped him for a month, but now he’s back.”\n\n“Why don’t you cork up your hole, too?”\n\n“Guess I ought to,” I said, “but we’ve sunk three months into this project. We\ncan’t be far from solving it.”\n\nRon had been in the middle of every trace. He’d invested plenty of time, all\nvoluntary. We didn’t pay Tymnet to trace hackers.\n\n“Hey, Cliff, how come you never call me at night?” Ron had given me his home\nnumber, but I only called him at his office.\n\n“Guess the hacker doesn’t show up at night. I wonder why.” He started me\nthinking. My logbook recorded every time the hacker had shown up. On the\naverage, when was he active?\n\nI’d remembered him on at 6 A.M. and at 7 P.M. But never at midnight. Isn’t\nmidnight operation the very image of a hacker?\n\nAs of December 6, the hacker had connected to us one-hundred-thirty-five\ntimes. Enough times for a statistical analysis of his work habits. In a couple\nof hours, I’d entered all the dates and times into a program. Now just average\nthem.\n\nWell, not exactly a simple average. What’s the average of 6 A.M. and 6 P.M.?\nIs it noon or midnight? But this is bread and butter for statistics folks.\nDave Cleveland showed me the right program, and I spent the rest of the day\nmaking all sorts of averages.\n\nOn the average, the hacker showed up at noon, Pacific time. Because of\ndaylight savings time, I could stretch this to 12:30 or even 1 P.M., but there\nwas no way that he was an evening person. Though sometimes he showed up in the\nmorning, and occasionally at night (I still resented him spoiling Halloween\nfor me!), he generally worked in the early afternoon. On the average, he\nstayed connected twenty minutes. A lot of two- or three-minute connections,\nand a few two-hour runs.\n\nSo what does this mean? Suppose he lives in California. Then he’s hacking\nduring the day. If he’s on the East Coast, he’s three hours ahead of us, so he\nworks around three or four in the afternoon.\n\nThis doesn’t make sense. He’d work at night to save on long-distance telephone\nfees. To avoid network congestion. And to avoid detection. Yet he brazenly\nbreaks in during the day. Why?\n\nConfidence? Perhaps. After he made certain that no system operator was\npresent, he roamed the insides of my computer without hesitation. Arrogance?\nPossibly. He was shameless in reading others’ mail and copying their data. But\nthis hardly could account for his showing up during midday.\n\nMaybe he felt he was less likely to be noticed when dozens of others were\nusing our computer. Although lots of programs ran at night, most of these were\nbatch jobs, submitted during the day and postponed until evening. By midnight,\nonly a couple of night owls were logged in.\n\nWhatever his reason, this peculiar habit made life slightly easier for me.\nFewer interruptions when sleeping with Martha. Less need to call the police at\nnight. And a greater chance that I’d be around when he showed up.\n\nAs we chopped onions at the kitchen table, I told Martha about my results.\n“I’m tailing a hacker that avoids the dark.”\n\nShe wasn’t impressed. “This doesn’t make sense. If the guy’s an amateur, then\nhe’d be breaking in during off-hours.”\n\n“So you say he’s a professional, keeping regular office hours?” I could\npicture someone punching a time card in the morning, spending eight hours\nbreaking into computers, then punching out.\n\n“No,” Martha said, “even professional burglars keep odd hours. What I want to\nknow is whether his hours change on weekends.”\n\nI couldn’t answer that one. I’d have to go back to the lab, cull out all the\nweekend times, and average them separately.\n\n“But suppose the hacker really only shows up around noon,” Martha continued.\n“It might be nighttime where he lives.”\n\nWhen it’s noon in California, where is it evening? Even astronomers get\nconfused by time changes, but I know it gets later as you move east. We’re\neight hours behind Greenwich, so lunchtime in Berkeley is bedtime in Europe.\nIs the hacker coming from Europe?\n\nImprobable, but worth thinking about. A month or two ago, I’d measured the\ndistance to the hacker by timing echos when the hacker ran Kermit. What I\nfound didn’t make much sense: the hacker seemed to be around six thousand\nmiles away.\n\nMade sense now. It’s five thousand miles to London. Small world.\n\nBut how do you get from Europe into our networks? Phoning across the Atlantic\nwould cost a fortune. And why go through Mitre?\n\nI had to keep reminding myself that these were just weak pointers. Nothing\nconclusive. But it was hard to fall asleep that evening. Tomorrow I’d go up to\nthe lab and reread my logbook with a new hypothesis: the hacker might be\ncoming in from abroad.\n\n\n![](images/Stol_9780307819420_epub_032_r1.jpg) Saturday morning I woke up\nnestled in Martha’s arms. We fooled around for a while, and I made a batch of\nmy quasi-stellar waffles—the ones that are advertised all over the Andromeda\ngalaxy.\n\nDespite the early hour, I couldn’t resist heading over to the lab. I bicycled\nalong side streets, scanning for yard sales. Right along the way, someone was\nselling their household, well preserved from the 1960s. Rock posters, bell-\nbottom jeans, even a Nehru jacket. I picked up a Captain Midnight Secret\nDecoder Ring for two dollars. It still had an endorsement for Ovaltine.\n\nAt the lab, I started analyzing the hacker’s log-in times, separating out his\nweekend sessions. It took a while, but I managed to show that on weekdays he\nshowed up from noon to three P.M.; on weekends he’d show up as early as six\nA.M.\n\nSuppose this sneak lived in Europe. He might break in at any hour on the\nweekend, but confine himself to evenings during the week. The log-in times\nagreed with this, but agreement is hardly proof. A dozen other theories could\nsatisfy the data.\n\nI’d ignored one source of information. The Usenet is a nationwide network of\nthousands of computers, tied together by telephone links. It’s a wide-area\nelectronic bulletin board, a sort of networked classified newspaper. Anyone\ncan post notes; every hour, dozens of new messages show up, divided into\ncategories like Unix Bugs, Macintosh Programs, and Science Fiction\nDiscussions. There’s nobody in charge: any Unix computer can link to Usenet,\nand post messages to the rest. Anarchy in action.\n\nSystem managers post a lot of the messages, so you’ll find notes like, “We\nhave a Foobar model 37 computer, and we’re trying to hook up a Yoyodyne tape\nto it. Can anyone help?” Often someone will respond, solving the problem in\nminutes. Other times, it’s a lone voice in an electronic wilderness.\n\nI couldn’t post a note saying, “Hackers are breaking into my computer. Any\nidea where they’re coming from?” Since most systems folks read these bulletin\nboards, the hacker would find out right away.\n\nBut I could scan for information. I started a text search, hunting for the\nword, “Hack.” Any messages with that keyword would pop out.\n\nOops. Bad choice of keyword. The word hacker is ambiguous. Computer people use\nit as a complement to a creative programmer; the public uses it to describe a\nskunk that breaks into computers. My search turned up lots of the former usage\nand not many of the latter.\n\nA few useful notes turned up, though. A guy in Toronto reported that his\ncomputer had been attacked by a group from Germany. They called themselves the\nChaos Computer Club and seemed to be technocratic vandals. Another note talked\nabout hackers in Finland trying to extort money from a corporation by holding\ntheir computers hostage. A third mentioned that a hacker in London ran a\ncredit card scam, where he sold credit card information over the telephone\nlines.\n\nNone of these seemed to describe what my hacker was doing. Nor was it much\ncomfort to realize that others face similar varmints.\n\nI walked out on the roof of the building and looked out over the bay. Below\nme, Berkeley and Oakland. Across the water, San Francisco and the Golden Gate\nBridge. For all I knew, someone within a few blocks was playing an elaborate\npractical joke on me. I was fiddling with my secret decoder ring when my\nbeeper went off. Three dots. Sventek again, and on my Unix machine.\n\nI ran down the staircase and into the switchyard. The hacker was just logging\nin. Quickly I called Ron Vivier at Tymnet. No answer. Of course, dummy, it’s a\nSaturday. Another call to his home. A woman answered.\n\n“I need to talk to Ron right away. He’s got to make a panic network trace\nright now.” I was out of breath and panting. Five flights of stairs.\n\nShe was taken aback. “He’s in the yard washing the van. I’ll get him.” A few\ncenturies later, Ron showed up. There were a couple kids screaming in the\nbackground.\n\n“I’ve got a live one for you,” I gasped. “Just trace my port 14.”\n\n“Right. It’ll take a minute. Good thing I’ve got two phone lines here.” I\nhadn’t realized that he didn’t have a whole switchboard at his fingertips. He\nmust be dialing into his computer.\n\nAnother couple eons passed, and Ron came back on the line. “Hey Cliff, are you\ncertain that it’s the same guy?”\n\nI watched him searching for the word SDI on our computer. “Yes, it’s him.” I\nwas still wheezing.\n\n“He’s coming in from a gateway that I’ve never heard of. I’m locked onto his\nnetwork address, so it doesn’t matter if he hangs up. But the guy’s coming\nfrom somewhere strange.”\n\n“Where’s that?”\n\n“I don’t know. It’s Tymnet node 3513, which is a strange one. I’ll have to\nlook it up in our directory.” In the background, Ron’s keyboard clicked. “Here\nit is. That node connects to ITT node DNIC 3106. He’s coming from the ITT\nIRC.”\n\n“Huh? What’s that mean to me?” His ante was beyond my purse.\n\n“Oh, I’m sorry,” Ron said. “I keep thinking that I’m talking to another Tymnet\nguy. Your hacker is coming from outside the Tymnet system. He’s entering\nTymnet from a communications line operated by the International Telephone and\nTelegraph company.”\n\n“So what?”\n\n“Tymnet moves data between countries using the IRCs. Once, international\nagreements forced us to use IRCs, now we choose the cheapest carrier around.\nThe IRCs are the go-betweens that link countries together.”\n\n“Are you saying that the hacker is coming from abroad?”\n\n“No doubt. ITT takes a Westar downlink.…” Ron spoke quickly and used plenty of\nacronyms.\n\n“Huh? What’s that mean?” I interrupted.\n\n“You know,” Ron said, “Westar 3.” I didn’t know, but I was learning by\nlistening.\n\nHe continued, “The communications satellite over the Atlantic. It handles ten\nor twenty thousand phone calls at once.”\n\n“So my hacker is coming from Europe?”\n\n“For sure.”\n\n“Where?”\n\n“That’s the part I don’t know, and I probably can’t find out. But hold on, and\nI’ll see what’s there.” More keyboard clicks.\n\nRon came back to the phone. “Well, ITT identifies the line as DSEA 744031.\nThat’s their line number. It can connect to either Spain, France, Germany, or\nBritain.”\n\n“Well, which is it?”\n\n“Sorry, I don’t know. You’ll have to call ITT. In three days, they’ll send us\nbilling information, and then I can find out. Meantime, I can’t tell you much\nmore than that.”\n\nFrom twenty-three thousand miles over Brazil, the Westar-3 satellite watches\nEurope and America at the same time. It relays microwave signals between the\ncontinents, each signal in its own channel. ITT, the multinational giant,\nleases a few thousand of Westar’s channels.\n\nRon went back to washing his car and I crossed the room to the monitoring\nprinter. Twenty minutes had passed, and my hacker hadn’t wasted a moment.\nEverything he typed was saved on my printer and displayed on my computer’s\nscreen. If he started to wreck our system, I could pull his plug by just\nreaching behind the table.\n\nBut he wasn’t interested in my lab’s computer. He first made sure that nobody\nwas watching him by seeing who was logged on, and listing their jobs. Good\nthing my monitors were concealed.\n\nThen, he went directly to our network links and logged into the Network\nInformation Center. This time, he searched for keywords like CIA, ICBM,\nICBMCOM, NORAD, and WSMR. After picking up a few computer names, he\nmethodically tried to log into each of them, using default account names like\nGuest and Visitor. He didn’t get far. Five systems bumped him off with bad\npasswords.\n\nLike a month ago, when he spent a while trying to get into the Army’s White\nSands Missile Range. Over and over, he tried to log onto their computers. He\nhad no problem finding the names of people working there—he just scanned the\nnetwork directory. But he couldn’t guess their passwords.\n\nThe Milnet connects to thousands of computers. Yet he wanted to get into White\nSands. Why bother?\n\nWhy’s this guy only interested in military stuff? There’s a whole world of\ncomputers, yet he’s targeting Army bases. Something serious is going on—it\nwould be a long time before I found out what.\n\nAfter half an hour, he gave up on White Sands and tried to get back into our\nElxsi computer. On Halloween, he’d sneaked in there and added a new account.\n\nAlong with the physicist that managed the Elxsi, I’d planted a trap there. The\ncomputer looked like it was still wide open, but when the hacker touched it,\nit slowed down. The more the hacker tried to use it, the slower it went.\n\nOur electronic tar baby worked like an ace. The hacker tried to log into the\nElxsi, and the machine coasted slower and slower. Not quite halting; he could\nsee that he was making progress, but at an appalling rate. Elxsi, Inc. would\nhave been ashamed—theirs is the zippiest of all minicomputers.\n\nTook him ten minutes to throw in the towel. But he came right back to our Unix\nmachines, and right out onto the Milnet. This time, he spent an hour trying to\nbreak into forty-two military computers, literally around the world.\n\nWith a single command, _telnet_ , he’d connect to a military system, and spend\none minute trying default account names and passwords. If he couldn’t guess\nhis way in with four tries, he’d go on to the next computer.\n\nHe knew how to guess. When greeted by the Unix response _login:_ , he’d try\ndefault accounts like _guest, root, who_ , and _visitor_. The Vax-VMS\noperating system greets you with _Username:_ , on those systems he tried the\ndefaults _system, field, service_ , and _user_. He’d done this before, and I’m\nsure that hackers will do it again.\n\nIf the Milnet was a roadway, connecting thousands of computers together, then\nhe was a burglar, patiently visiting each house. He’d twist the front doorknob\nto see if it was unlocked, then walk around and try the backdoor. Maybe try\nlifting a window or two.\n\nMost of the time, he found the doors and windows locked. After a minute\npushing them, he’d move on to the next place. Nothing sophisticated: he wasn’t\npicking locks or digging under foundations. Just taking advantage of people\nwho left their doors open.\n\nOne after another, he tried military computers: Army Ballistics Research Lab;\nU.S. Naval Academy; Naval Research Lab; Air Force Information Services Group;\nand places with bizarre acronyms, like WWMCCS and Cincusnaveur. (Cincus? Or\nwas it Circus? I never found out.)\n\nToday wasn’t lucky for him. None of his guesses panned out. Forty-two at-bats,\nforty-two outs.\n\nClearly, he was going to be on a long time. I reached into my pocket for a\nMilky Way candy bar—what else, for an astronomer?—and sat back to watch the\nhacker on my green monitor. I could imagine the far end of that long\nconnection. The hacker sitting behind his monitor, watching the same green\ncharacters on his screen. Probably chewing on his own Milky Way bar. Or\nsmoking a Benson and Hedges.\n\nIt was Saturday, but I figured I’d try to call the Air Force Office of Special\nInvestigations. They’d told me to call if anything bubbled up, and the\ncauldron was boiling now. But no answer. Anyway, there wasn’t much they could\ndo. I needed to know who was at the other end of ITT’s satellite channel.\n\nOnly two people knew where I was—Ron Vivier and Martha. Ron was washing his\ncar. So when the phone rang in the switchyard, I answered, “Hello, sweetie!”\n\nSilence, then, “Aah, I’ve probably got the wrong number. I’m looking for Cliff\nStoll.” A man’s voice with a profound English accent. Had some British spies\nfound me? Or was the hacker in London? What a mindgame.\n\nTurned out to be nothing so subtle. Ron Vivier had called Tymnet’s\ninternational department, where their experts in transatlantic communications\ntook over. One of Tymnet’s international specialists, Steve White, started\ntracing.\n\nSteve works in Vienna, Virginia, making certain that Tymnet’s customers can\ncommunicate worldwide. He grew up in Dorset, England, and first learned to\nprogram a computer by mail: he’d write a program at school, send it to a\ncomputer center, and receive the printout a week later. Steve claims that this\nmakes you write good programs the first time, since each mistake wastes a week\nof your time.\n\nSteve had studied zoology at the University of London, and found it just like\nastronomy: fascinating but impoverishing. So he moved to the states, and began\nworking in his other specialty: digital communications. Steve troubleshoots\ninternational communications systems.\n\nThere’s a dozen ways to tie computers together—telephones, optical fibers,\nsatellite links, and microwave links. At my laboratory, I didn’t care how my\ndata moved, so long as a scientist in Podunk could reach my computer in\nBerkeley. It was Steve’s job to make sure that data funnelled in one end of\nTymnet reached me at the far end.\n\nEvery communications company has someone like Steve White, or at least the\nsuccessful ones do. To him, the network is a gossamer web of connections:\ninvisible threads that appear and disappear every few seconds. Each of his\nthree thousand nodes have to be able to instantly talk to each other.\n\nYou could build a network by stringing a wire to every computer, and then\nconnecting them together in one big switch. With a thousand terminals at our\nlab, that’s exactly how we did things; a zillion wires in the switchyard.\nLocal phone companies still work that way: they route all the neighborhood\ntelephone wires to a single building, where mechanical switches make\nconnections.\n\nWith thousands of computers spread around the country, Tymnet couldn’t have a\ncentral exchange. Mechanical switches were out of the question: too slow and\nunreliable. Instead, Tymnet creates virtual circuits between computers. Across\nthe country, Tymnet’s switching computers, called nodes, communicate with each\nother over leased cables.\n\nWhen your computer sends a message to mine, Tymnet treats it like a piece of\nmail: it squeezes your data into a envelope and sends it to one of Tymnet’s\nnodes. There, Tymnet’s computers stamp the envelope with the forwarding\naddress, along with your own calling address. Like a post office running at\nthe speed of light, special software grabs each envelope and tosses it to a\nnode nearer its destination. When the envelope finally reaches my computer,\nTymnet removes the address, opens the envelope, and delivers the data.\n\nThere’s not one giant switch hooking your computer to mine. Instead, each\nnetwork node knows where to toss every data packet—a central computer tells it\nthe shortest path.* In crossing the country, a dozen Tymnet nodes may forward\nan envelope.\n\nWhen your computer’s silent, the network sits back and handles other\nenvelopes, but each Tymnet node still remembers where to send your packets.\nEvery node has a thousand pigeonholes, and is constantly sorting envelopes.\n\nThere’s no wire to trace; rather, there’s a thread of addresses between your\ncomputer and mine. Ron and Steve, the Tymnet guys, could trace the hacker’s\nconnections by untangling this thread. The tail of the thread originated at an\nITT earth station. Beyond there, who could tell?\n\n* The Internet, too, doesn’t have one central switch, but instead has many local switches, all around the country. The lowest-level switches (really, computers) are tied together, forming local networks. These, in turn, are grouped together into regional networks, which connect to national backbones. The Internet, then, connects networks together—like the Arpanet, the Milnet, and its hundred other networks.\n\nWhile Tymnet (and its many cousins) builds virtual circuits from one point to\nanother, the Internet is hierarchical. An Internet message moves from local\nroads, to state roads, onto the highways, and then down through state roads to\na specific street address.\n\nEnvelopes for messages on Tymnet can be simple—once the virtual circuit is\nestablished, each node knows where to toss the message. Internet messages,\nhowever, have envelopes with complete destination and return addresses, so\nthat each network can figure out how to send it one step closer to the\nultimate destination. Those more complex envelopes let Internet packets get\nthrough even when the system’s congested.\n\nWhich is better? Don’t ask me.\n\n\n![](images/Stol_9780307819420_epub_033_r1.jpg) So after months of tracking,\nthe hacker’s coming from Europe. He was still on my computer, trying to chisel\ninto the Navy Research Labs, when Steve White called.\n\n“Tymnet’s connection begins at ITT,” Steve said.\n\n“Yes, Ron Vivier already told me that. But he says that it could be from any\nof four countries.”\n\n“Ron can’t trace any farther,” Steve said, typing on his terminal. “I’ll do\nthe trace myself.”\n\n“You can trace ITT’s lines?”\n\n“Sure. The international record carriers give Tymnet permission to trace their\nlinks, in case of problems. I’ll just log into ITT’s switch and see who’s\ncalling.” Steve made it sound simple.\n\nI kept watching the hacker on my screen, hoping that he wouldn’t hang up while\nSteve made the trace.\n\nSteve came back on the line. In his modulated, almost theatric British accent,\nhe said, “Your hacker has the calling address DNIC dash 2624 dash 542104214.”\n\nI’d grown accustomed to not understanding the jargon, but on principle, I\ndutifully wrote it down in my logbook. Fortunately, Steve translated for me.\n\n“You see, as far as Tymnet’s concerned, the hacker’s coming from ITT’s\nsatellite. But from inside of ITT’s computers, I can see past their satellite\nlink and trace the connection all the way back.”\n\nSteve had X-ray vision. Satellites didn’t stop him.\n\n“That DNIC number is the data network identifier code. It’s just like a\ntelephone number—the area code tells where the call originates.”\n\n“So where’s the hacker coming from?”\n\n“Germany.”\n\n“East or West?”\n\n“West Germany. The German Datex network.”\n\n“What’s that?” Steve lived in a universe of networks.\n\n“Datex is the German equivalent of Tymnet. It’s their national network to\nconnect computers together,” Steve explained. “We’ll have to call the\nBundespost to find out more.”\n\nI forgot about the hacker on my computer, and listened to Steve. “You see, the\nDNIC completely identifies the computer that’s making the call. The first four\ndigits tell me that it’s from the German Datex network. The Bundespost can\nlook up that number in their catalog, and tell us exactly where it’s located.”\n\n“Who’s the Bundespost?” It sounded vaguely German.\n\n“They’re the German national postal service. The government communications\nmonopoly.”\n\n“Why’s the post office running networks?” I wondered out loud. Here, the post\noffice delivers letters, not data.\n\n“In a lot of countries, the post office owns the phone service. An historical\noutgrowth of government regulation. Germany’s probably the most centralized of\nall. You can’t get a telephone answering machine without government approval.”\n\n“So the hacker is coming from a government computer?”\n\n“No, it’s a private computer, probably. But the communications link is\noperated by the Bundespost. And that’s our next step. We’ll ring up the\nBundespost in the morning.”\n\nI liked how he said “we” rather than “you.”\n\nSteve and I talked for a solid hour. Listening to his descriptions of the\nnetwork was far more interesting than watching the hacker scan my computer for\nkeywords like SDI. Steve wasn’t a technician, but a craftsperson; no, an\nartist who expressed himself through an invisible tapestry of electronic\nthreads.\n\nTo hear Steve speak of it, the network is a living, growing organism. It\nsenses trouble and responds to its environment. To him, the network’s elegance\nlay in its simplicity. “Each node just passes the data on to the next.”\n\n“Every time your visitor types a key,” Steve said, “a character bounces from\nDatex to ITT to Tymnet and into your system. And between keystrokes, our\nnetwork wastes no time on him.”\n\nWith thousands of conversations threaded through his system and millions of\nbits of data, not one dialogue was lost, and not a byte of data spilled out.\nThe network kept track of the connections, and you couldn’t slip through the\ncracks.\n\nAll the same, Steve seemed pessimistic about completing a successful trace.\n“We know where he connects into the system. But there’s a couple possibilities\nthere. The hacker might be at a computer in Germany, simply connected over the\nGerman Datex network. If that’s the case, then we’ve got him cold. We know his\naddress, the address points to his computer, and the computer points to him.”\n\n“Seems unlikely,” I said, thinking of my trace to Mitre.\n\n“It is unlikely. More likely, the hacker is coming into the German Datex\nnetwork through a dial-in modem.”\n\nJust like Tymnet, Datex lets anyone dial into their system, and connect to\ncomputers on the network. Perfect for business people and scientists. And\nhackers.\n\n“The real problem is in German law,” Steve said. “I don’t think they recognize\nhacking as a crime.”\n\n“You’re kidding, of course.”\n\n“No,” he said, “a lot of countries have outdated laws. In Canada, a hacker\nthat broke into a computer was convicted of stealing electricity, rather than\ntrespassing. He was prosecuted only because the connection had used a\nmicrowatt of power from the computer.”\n\n“But breaking into a computer is a crime in the USA.”\n\n“Yes, but do you think the hacker will be extradited for that?” Steve asked.\n“Look at the support you got from the FBI. Be serious, Cliff.”\n\nSteve’s pessimism was contagious. But his trace jagged my spirits: so what if\nwe couldn’t nail the hacker—our circle was closing around him.\n\nThis hacker, though, knew nothing of our trace. He finally disconnected at\n5:22, after two hours of twisting doorknobs and scanning files. My printer\ncaptured everything, but the real news was Steve White’s work.\n\nGermany. I ran over to the library and dug out an atlas. Germany’s nine hours\nahead of us. The hacker showed up around noon or 1 P.M.; for him, it’s 9 or 10\nP.M. He’s probably taking advantage of cheap rates.\n\nPoring over the atlas, I remembered Maggie Morley recognizing the hacker’s\npassword. “Jaeger—it’s a German word meaning Hunter.” The answer had been\nright in front of me, but I’d been blind.\n\nThis explained the timing of the acknowledgement echos when the hacker used\nthe Kermit file transfers. I’d measured 6000 miles to the hacker, though I’d\nnever relied much on that figure. I should have. Germany was 5200 miles from\nBerkeley.\n\nNot just blind. Deaf as well.\n\nI’d been gathering facts. Not interpreting them.\n\nSitting alone in the library, I was suddenly deeply embarrassed over sending\nmy sister on a wild goose chase, searching for a high school kid in Virginia;\nand the Berkeley detectives, running around campus with revolvers.\n\nI’d messed up. For months, I’d scoured North America, searching for the\nhacker. Dave Cleveland kept telling me, “The hacker’s not from the West\nCoast.” No, not by 5200 miles.\n\nSome details were still fuzzy, but I understood how he operated. Somewhere in\nEurope, the hacker called into the German Datex network. He asked for Tymnet,\nand the Bundespost made the connection through the international record\ncarrier. Once he reached the States, he connected to my laboratory and hacked\nhis way around the Milnet.\n\nMitre must have been his stopover point. I could see how he made the\nconnection. He’d entered the German Datex system, asked for Tymnet, and then\nlogged into Mitre. Once there, he could explore their computers at his\nleisure. When he grew tired of reading the defense contractor’s reports, he\ncould dial out from Mitre, connecting anywhere in North America—with Mitre\npicking up the tab.\n\nBut who paid for his transatlantic connections? According to Steve, his\nsessions cost fifty or one hundred dollars an hour. Walking back to the\ncomputer room, I realized that I was following a well-heeled hacker. Or a\nclever thief.\n\nNow I realized why Mitre paid for a thousand one-minute-long phone calls. The\nhacker would connect to Mitre, and instruct their system to phone another\ncomputer. When it answered, he would try to log in with a default name and\npassword. Usually he failed, and went on to another phone number. He’d been\nscanning computers, with Mitre picking up the tab.\n\nBut he’d left a trail. On Mitre’s phone bills.\n\nThe path lead back to Germany, but it might not end there. Conceivably,\nsomeone in Berkeley had called Berlin, connected to the Datex network,\nconnected through Tymnet and came back to Berkeley. Maybe the start of the\npath was in Mongolia. Or Moscow. I couldn’t tell. For the present, my working\nhypothesis would be Germany.\n\nAnd he scanned for _military_ secrets. Could I be following a spy? A real spy,\nworking for _them_ —but who’s them?… Jeez—I didn’t even know who spies work\nfor.\n\nThree months ago, I’d seen some mouse droppings in my accounting files.\nQuietly, we watched this mouse, seeing him sneak through our computer, and out\nthrough a hole and into the military networks and computers.\n\nAt last I knew what this rodent was after. And where he was from. I’d been\nmistaken.\n\nThis wasn’t a mouse. It was a rat.\n\n\n![](images/Stol_9780307819420_epub_034_r1.jpg) I spent Saturday evening\nfilling in my logbook. Now I could tie up loose ends. Anniston’s search\nwouldn’t turn up a hacker in Alabama: they were off by five thousand miles.\nStanford’s hacker was certainly a different guy … my hacker would have\nhomework in German, not English. And there wasn’t much use in calling around\nBerkeley, looking for someone named Hedges.\n\nProbably the wrong name. Certainly the wrong continent.\n\nOur stack of printouts was a foot thick. I’d carefully sorted and dated each\nlisting, but I’d never combed through all the listings at one sitting. Most of\nit was dreary file listings and one-at-a-time guesses at passwords.\n\nIs it easy to break into computers?\n\nElementary, my dear Watson. Elementary, and tediously dull.\n\nI didn’t return home until 2 A.M. Martha waited up, piecing a quilt.\n\n“Out with a hussy?”\n\n“Yeah,” I replied. “Spent the day with a mysterious foreigner.”\n\n“So the hacker’s from Europe after all.” She’d guessed what I’d been doing.\n\n“He might live anywhere in the world,” I said, “but my bets are on Germany.”\n\nI wanted to sleep late Sunday morning, curled up with Martha. But, dammit, my\npager sounded at 10:44, a harsh, insistent squeal followed by a Morse code\ngreeting. The hacker was at it again. In my Unix-5 computer.\n\nI jumped into the dining room and dialed Steve White at his home. While his\nphone was ringing, I fired up my Macintosh computer. On the fifth ring, Steve\nanswered.\n\n“The hacker is live again, Steve,” I told him.\n\n“OK, Cliff. I’ll start the trace and call you back.”\n\nAs soon as I hung up, I reached for my Macintosh. The beast acted like a\nremote terminal, thanks to a modem and a stellar software program called Red\nRyder. Red automagically dialed my lab’s computer, logged onto the Vax, and\nshowed me what was up. There was my hacker, traipsing through the Milnet.\n\nLogged on like that, I appeared like an ordinary user, so the hacker could see\nme if he looked. So I disconnected quickly. Ten seconds was enough to see what\nmy visitor was up to.\n\nSteve called back in a couple minutes. The line didn’t come from the ITT\ninternational record carrier; today it was from RCA.\n\n“RCA doesn’t use the Westar satellite,” Steve said. “They talk through the\nComsat satellite.” Yesterday he used Westar, today Comsat. One elusive\nhacker—switching communications satellites from day to day.\n\nBut I had my facts wrong, and Steve set me straight.\n\n“Your hacker doesn’t have any choice in the matter,” Steve explained. “To\nprovide redundant service, we use a variety of international routes.”\n\nWith every call, Tymnet’s traffic takes a different route across the Atlantic.\nAs a customer I would never notice, but traffic is spread across four or five\nsatellites and cables.\n\n“Oh, like interstate trucking, before deregulation.”\n\n“Don’t get me started,” Steve said angrily. “You wouldn’t believe the\ninternational communications laws.”\n\n“So where’s the hacker coming from today?”\n\n“Germany. Same address. Same place.”\n\nThere wasn’t much more to do. I couldn’t monitor the hacker from home, and\nSteve had finished the trace. I sat shivering next to the Macintosh. Where do\nI go next?\n\nTo the lab. And quick. I scribbled a note for Martha (“The game is afoot”),\nthrew on some jeans, and hopped on my bike.\n\nI wasn’t fast enough. The hacker disappeared five minutes before I arrived. I\nshould have stayed in bed.\n\nWell, I paged through Sunday morning’s listing—Sunday evening for him—and saw\nhim up to his old tricks. One by one, trying to break into military computers\nby guessing obvious passwords. Tedious. About as interesting as guessing\nlocker combinations.\n\nSince he’d shown up in the morning, I might as well wait around and see if\nhe’d return. Based on my statistics, he’d be back within an hour or two.\n\nSure enough, he returned at 1:16 in the afternoon. My pager sounded off, and I\nran to the switchyard. There he was, logging into the stolen Sventek account.\n\nAs usual, he looked around for others on the computer. Had I been connected\nfrom my home, he’d have noticed me. But from my high ground in the switchyard,\nI was undetectable. He couldn’t pierce my electronic veil.\n\nConfident that nobody was watching him, he headed straight out through our\nMilnet port. With a few commands, he searched the Milnet directory for any\nlocations with the acronym “COC.” Huh? I’d never seen such a word. Did he\nmisspell something?\n\nI needn’t have wondered. The network information computer cranked for a minute\nor two, and then returned a half dozen military Command Operations Centers. He\nkept searching for other keywords: “Cheyenne,” “icbm,” “combat,” “kh11,”\n“Pentagon,” and “Colorado.”\n\nSitting there watching him paw through the Milnet directory, I felt like I was\nwatching someone thumbing through the yellow pages. Which numbers would he\ndial?\n\nAll of them. Every keyword brought up a few computer addresses, and after he’d\nfound thirty of them, he closed his connection to the Milnet directory. Then,\nonce again, he methodically tried to break into each of the sites; the Air\nForce Data Services Center in Arlington, Virginia, the Army Ballistics\nResearch Lab, an Air Force training center in Colorado Springs, the Navy\nPacific Monitoring Center in Hawaii, and thirty other places.\n\nBut again, he had no luck. By chance, he’d picked places which didn’t have\nobvious passwords. It must have been a frustrating evening for him.\n\nFinally, he tried to break into his old haunt, the Anniston Army base. Five\ntimes. No luck.\n\nSo he gave up on the Milnet and returned to messing with my Unix computer. I\nwatched the cuckoo lay its egg: once again, he manipulated the files in my\ncomputer to make himself super-user. His same old trick: use the Gnu-Emacs\nmove-mail to substitute his tainted program for the system’s atrun file. Five\nminutes later, shazam! He was system manager.\n\nNow I had to watch him carefully. With his illicit privileges, he could\ndestroy my system, either by accident or on purpose. And it would only take\none command, like _rm_ *—erase all files.\n\nFor now, though, he restrained himself. He just printed out phone numbers of\ndifferent computers, and logged off.\n\nUh oh. He took a list of telephone numbers that our computer often connects\nto.\n\nBut Mitre had cut off their outbound telephone service. He must have\ndiscovered this by now. Yet he still collected phone numbers. So he must have\nsome other way to make phone calls. Mitre wasn’t his only stepping stone to\nthe telephone system.\n\nHe came back to my system after fifteen minutes. Wherever he’d gone, none of\nhis calls had panned out. Bad passwords, I’ll bet.\n\nAs soon as he returned, he started Kermit running. He was going to copy a file\nback to his computer. My password file again? No, he wanted my network\nsoftware. He tried to export the source code to two programs: _telnet_ and\n_rlogin_.\n\nWhenever one of my scientists connects through the Milnet, they use _telnet_\nor _rlogin_. Both of them let someone remotely log into a foreign computer.\nEach of them transfers commands from a user over to a foreign computer. Either\nis a perfect place to plant a Trojan horse.\n\nBy changing a couple lines of code in our _telnet_ program, he could make a\npassword grabber. Whenever my scientists connected to a distant system, his\ninsidious program would stash their passwords into a secret file. Oh, they’d\nlog in successfully. But the next time the hacker came into my Berkeley\ncomputer, there’d be a list of passwords waiting to be picked up.\n\nLine by line, I watched Kermit shovel the program over to the hacker. No need\nto time the transfer—I now knew those long delays were caused by satellites\nand the long hop into Germany.\n\nWatching him, I got annoyed. No, pissed off. He was stealing my software.\nSensitive software at that. If he wanted it, he’d have to swipe it from\nsomeone else.\n\nBut I couldn’t just kill Kermit. He’d notice that right away. Now that I was\nclosing in on him, I especially didn’t want to tip my hand.\n\nI had to act fast. How do I stop a burglar without letting on that I’m\nwatching?\n\nI found my key chain and reached over to the wires connected to the hacker’s\nline. Jangling the keys across the connector, I shorted out his circuit for an\ninstant. This added just enough noise to confuse the computer, but not enough\nto kill the connection. To him, it would look like some characters had become\ngarbled. Misspelled words and unintelligible text—the computer equivalent of\nradio static.\n\nHe’d blame it on network interference. He might try again, but eventually,\nhe’d give up. When the connections are lousy, there’s no use in talking long\ndistance.\n\nIt worked like a charm. I’d jangle my keys, he’d see noise, and his computer\nwould ask for a replay of the last line. I was careful to let a little data\nget through. But so slowly that the whole file would take all night.\n\nThe hacker disconnected and tried again. No way. He couldn’t make it through\nmy fog, and he couldn’t figure out where the noise was coming from.\n\nHe gave up trying to steal our software, and contented himself with just\nlooking around. He found a pathway into Berkeley’s Opal computer, but didn’t\nexplore it.\n\nNow there’s a strange one. The Berkeley Opal computer is the home of some real\ncomputer research. You don’t have to look far to find some of the finest\ncommunications programs, academic software, and games. Apparently this hacker\ndidn’t care for the things students might be interested in. But show him\nsomething military, and he goes wild.\n\nIt was 5:51 in the afternoon when the hacker finally called it quits. I can’t\nsay that his every frustration gave me satisfaction. Rather, he responded the\nway I expected. My work was slowly yielding a solution.\n\nSteve White traced the connections throughout the day. Just as in the morning,\nthey all came from Germany.\n\n“Any chance that it’s someone from another European country?” I asked, knowing\nthe answer in advance.\n\n“The hacker could be from anywhere,” Steve answered. “My trace only proves a\nconnection from Berkeley into Germany.”\n\n“Any idea where in Germany?”\n\nSteve was as curious as I. “There’s no way to tell without a directory. Every\nnetwork has its own way of using the address. The Bundespost will tell us\ntomorrow.”\n\n“So you’ll call them in the morning?” I asked, wondering whether he spoke\nGerman.\n\n“No, it’s easier to send electronic mail,” Steve said. “I’ve already sent a\nmessage about yesterday’s incident; today’s will confirm it, and add a few\nmore details. Don’t worry, they’ll hop to it.”\n\nSteve couldn’t hang around this Sunday afternoon—he was cooking a dinner with\nhis lady friend Lynn—which reminded me of Martha. I hadn’t called home.\n\nMartha wasn’t pleased. She’d left word with Claudia that she’d be out late.\nWere it not for this hacker, we’d be hiking in the redwoods. Oops.\n\n\n![](images/Stol_9780307819420_epub_035_r1.jpg) Last night was a tense time at\nhome. Martha didn’t talk much. By spending the day watching the hacker, I’d\nwrecked a fine Sunday afternoon. Progress with the hacker had cost dearly on\nthe home front.\n\nWho should I tell about the latest discovery? My boss, for sure. We’d had a\nbet on where the hacker came from, and I’d lost. I owed him a box of cookies.\n\nThe FBI? Well, they hadn’t shown much interest, but this was now out of the\nleague of my local police. Might as well give them another chance to ignore\nus.\n\nAir Force Office of Special Investigations? They’d asked to be kept aware.\nWith the hacker’s attacks on military computers, I ought to tell someone from\nthe defense establishment, no matter how politically awkward I felt.\n\nIf it was hard to talk to the military, then calling the CIA was a real\nhurdle. A month ago, I’d accepted that they needed to know about someone\ntrying to break into their computers. I’d done my duty. Now, should I tell\nthem that it’s a foreigner?\n\nBut once again, they seemed like the right people to call. I could understand\nthe nodes, and networks, but espionage … well, they don’t teach you that stuff\nin grad school.\n\nSurely my friends among Berkeley’s flourishing left wing would tell me I’d be\nco-opted by the State. But I didn’t exactly feel like a tool of the ruling\nclass, unless imperialist running-dog puppets breakfasted on stale granola. I\nargued with myself as I biked through traffic, but my guts told me what to do:\nthe CIA should know, and I ought to tell them.\n\nIt had been a constant struggle to get the bureaucracy to move. Maybe I could\nget someone to notice by waving this flag in front of all the three-letter\nagencies.\n\nFirst I’d call the FBI. Their Oakland office hadn’t been interested, but maybe\nI could get a rise out of Mike Gibbons in Alexandria, Virginia. But Mike was\non vacation, so I left a message, figuring he’d hear it in a couple of weeks.\n“Just tell him that Cliff called. And that my friend has a return address in\nGermany.” You can’t fit much on a yellow while-you-were-out note.\n\nMy second pitch was to the Air Force OSI—the air force narcs. Two people got\non the line, a woman’s voice and a gravelly man’s voice.\n\nThe woman, Ann Funk, was a special agent specializing in family crimes. In a\nserious tone, she explained, “Wife beating, child abuse. The Air Force has the\nsame ugly problems as the rest of the world.” Not hi-tech stuff, but even over\nthe phone, her presence inspired respect and sympathy. Now, she worked with\nthe OSI’s computer crime group.\n\nA month ago, I’d spoken with Jim Christy. Today, his first question to me was\nthe same as I’d asked Steve: “East or West Germany?”\n\n“West,” I answered. “We’ll know more in the next couple days.”\n\n“Where’d did he get into?” Ann asked.\n\n“Nowhere, at least that I saw. Not that he didn’t try.” I rattled off some of\nthe places he tried to sneak into.\n\n“We’ll have to call you back,” Jim said. “We have an office in Europe that\nmight be able to work on this.”\n\nI’d given the Air Force a heads-up warning. Let’s see what they’d do.\n\nTime to call the CIA. Teejay’s office answered—he wasn’t in. Whew. Off the\nhook. I felt like a kid who had to give a report to the class, only to find\nthat the teacher was sick.\n\nBut having made up my mind to tell the spooks, I called Teejay’s fellow spy,\nGreg Fennel. Greg was in, all right.\n\n“Look, I’ve got a meeting in three minutes. Keep it short.” A busy day at the\nCIA.\n\n“In short, we traced the hacker to Germany. Goodbye!”\n\n“Huh? Wait! How’d you do it? Are you sure it’s the same guy?”\n\n“You’ve got a meeting now. We can talk tomorrow.”\n\n“Forget the meeting. Just tell me what happened. Don’t embellish, don’t\ninterpret.”\n\nEasy to do when you keep a logbook. I read off my weekend’s summary. An hour\nlater, Greg was still asking questions, and had forgotten his meeting. It hit\nhim where he lived.\n\n“Fascinating,” the spy thought out loud. “Someone in West Germany is breaking\ninto our networks. Or at least they’re coming through a West German gateway.”\nHe understood that we’d identified one link in the chain. The hacker still\ncould be anywhere.\n\n“Any chance that you’ll take action?” I asked.\n\n“That’s for someone else to decide. I’ll pass it up the chain of command, but\nI really don’t know what will happen.”\n\nWhat did I expect? The CIA couldn’t do much to solve the problem—they were\ninformation gatherers. I hoped they’d take over the whole mess, but that\nseemed unlikely. The hacker wasn’t in their machines, he was in ours.\n\nLawrence Berkeley Laboratory was tired of wasting time on the chase. I hid my\nhacker work, but everyone could see that I wasn’t tending to our system.\nScientific software slowly decayed while I built programs to analyze what the\nhacker was doing.\n\nFearing my vitriolic boss, I polished up on quantum mechanics before talking\nto Roy Kerth. Maybe if we talked physics for a while, he might overlook my\nwork on the hacker front. After all, he seemed pleased by my graphics\nsoftware, even though I thought it was comparatively trivial.\n\nBut no amount of shop talk could deflect Roy’s anger. He was irritated about\nthe time I’d spent tracking this hacker. I wasn’t contributing to the\ndepartment—nothing that he could show off, nothing he could quantify.\n\nAt least he didn’t shut me down. If anything, he seemed more eager than ever\nto nail this eggsucker.\n\nI spent a few hours searching bulletin boards on the Usenet network for news\nabout hackers, and found one note from Canada. I called the author on the\nphone—I didn’t trust electronic mail. Bob Orr, a scientist at the University\nof Toronto, told a sad story.\n\n“We connect to lots of networks, and it’s tough to convince funding agencies\nto pay for it. Some hackers from Germany have invaded our system, changing\nprograms and damaging our operating system.”\n\n“How’d they get in?” I asked, already suspecting the answer.\n\n“We collaborate with the Swiss physics lab, CERN. And those vandals have\nthoroughly walked through their computers. They probably stole passwords to\nour system, and linked directly to us.”\n\n“Did they do any damage?” I asked.\n\n“Damage! Haven’t you been listening?” Bob exploded. “Our networks are delicate\nthings—people connect to us in hope of mutual support. When someone breaks\ninto a computer, they destroy that trust. Aside from wasting days of my time,\nand forcing us to disable our network connections, these hackers undermine the\nopenness that lets us do science together.”\n\n“But did they erase your files?” I asked. “Did they change any programs?”\n\n“Well, they modified my system to give them a backdoor password. But if you’re\nlooking for headlines like, ‘Hacker wipes out entire system,’ you won’t find\nthem here. These break-ins are far more insidious. They’re technically skilled\nbut ethically bankrupt programmers without any respect for others’ work—or\nprivacy. They’re not destroying one or two programs. They’re trying to wreck\nthe cooperation that builds our networks.”\n\nWhew! Here was a guy who took his computing seriously. I hadn’t learned much\nabout hackers from Germany, but at last I’d spoken to someone who described\nthem with the same expletives that I used. Bob realized that damage wasn’t\nmeasured in dollars ripped off, but rather in trust lost. He didn’t see this\nas fun and games, but a serious assault on a open society.\n\nOnce, I would have argued with Bob, saying that these were only kids fooling\naround. Once, I might have smiled and respected anyone who could hack around\nin so many computers. Not any more.\n\nAs an aside, Bob told me the German Chaos Club was attacking the U.S. Fermilab\ncomputer as well. I called Fermilab in Illinois and talked with their system\nmanager. “Yes, some German hackers have been giving us headaches. They call\nthemselves the Chaos Computer Club.”\n\n“Were they spying?” I asked.\n\n“Be serious. There’s no classified work here.”\n\nI wondered. Were they vandals or spies? “Can you identify who’s breaking in?”\n\n“One guy uses the pseudonym Hagbard. Another, Pengo. I don’t know their real\nnames.”\n\n“Have you secured your system since you detected them?”\n\n“A little. We’re trying to do science, so we don’t want to shut our doors to\nthe world. But these vandals are making it tough to run an open computing\ncenter. I wish they’d pick on someone else—like the military, for instance. Or\nNSA.”\n\nIf only he knew. “I suppose the police haven’t been much help?” I asked.\n\n“Not much. They listen, but they’re not doing much.”\n\nI called Stanford and asked one of their system managers, Dan Kolkowitz, if\nhe’d heard anything from Germany.\n\n“Come to think of it, someone broke in a few months ago. I monitored what he\ndid, and have a listing of him. It looks German.”\n\nDan read the listing over the phone. Some hacker with the nom de guerre of\nHagbard was sending a file of passwords to some hackers named Zombie and\nPengo.\n\nHagbard and Pengo again. I wrote them in my logbook.\n\nStill, it seemed like these guys were right. Those hackers were vandals who\nwanted to create trouble. They attacked universities and scientific\ninstitutes—easy pickings. They didn’t seem interested in military targets, and\ndidn’t seem to know how to navigate the Milnet.\n\nI realized another difference between my hacker and the Chaos Club hoodlums.\nMy hacker seemed at home on Unix; not the Berkeley version, but Unix all the\nsame. The vandals that Bob and Dan described seemed to only attack Dec’s VMS\noperating systems.\n\nFrom now on, I’d watch for any news about the Chaos Computer Club, but I\ncouldn’t assume that all German hackers were in league together.\n\nOne good thing was happening. One by one, I was making contact with other\npeople who were losing sleep and slugging down Maalox over the same troubles\nthat obsessed me. It was comforting to learn that I wasn’t completely alone.\n\nIt was time to take my mind off the hacker and return to astronomy. No such\nluck—Mike Gibbons of the FBI called.\n\n“I thought you were on vacation,” I said.\n\n“I am. At my folk’s place, in Denver.”\n\n“Then how’d you get my message?” I wondered if the CIA had called.\n\n“Oh, that’s easy,” Mike said. “We’re on two-hour alert. Day or night, the\noffice can reach me. Sometimes makes my marriage uncomfortable.”\n\nI understood all too well. My own beeper was an albatross. “Did you hear about\nthe German connection?”\n\n“How about telling me what happened over the weekend.” (Just the facts,\nma’am.)\n\nOnce again, I read from my logbook. I’d reached the part about the DNIC\nnumbers, when Mike interrupted.\n\n“Can you Fed-ex your logbook here?”\n\n“Sure. I’ll print out a copy and ship it to you.” Easy to do when you keep\nyour notes inside a computer.\n\n“I’ll see if we can open a case. No promises, but this looks interesting.” By\nnow I’d learned that nobody ever promised to do anything.\n\nI printed out a copy of my logbook and dropped it off at the express office.\n\nWhen I returned, the phone was ringing. It was Teejay.\n\n“I heard the news,” said my CIA contact. “You’re sure your friend lives across\nthe puddle?”\n\n“Yes, if you mean the Atlantic.” Teejay’s shorthand might confuse an\neavesdropper, but they threw me for a loop every time. “Almost certainly he’s\nfrom Germany, and I’d be amazed if he’s from the States.”\n\n“Do you know his exact location?”\n\n“All I know is the electronic address of a computer. It’s a DNIC number,\nwhatever that means.”\n\n“Who’s going to decode it for you?”\n\n“I expect the Bundespost to tell us who’s at the other end. Maybe tomorrow.”\n\n“Have you called the, uh, northern entity?”\n\nNorthern entity? Who’s that? “You mean the ‘F’ entity?”\n\n“No, the entity in the north. You know, Mr. Meade’s place.”\n\nMeade. Fort Meade. He must mean the National Security Agency. “No, I called\nthe ‘F’ entity, though.”\n\n“Good. Are they moving or sitting on their butts?”\n\n“I don’t know. They might open an investigation, but they wouldn’t promise.”\n\n“They never do. I’ll get in touch with them and see if we can help things\nalong. Meanwhile, why don’t you call the northern entity, and see if they’ll\ndecode that address.”\n\nOf course. NSA must have lists of every telephone number and electronic\naddress in the world. I dialed the National Computer Security Center.\n\nZeke Hanson answered my call.\n\n“Hey, Zeke, remember that you said that NSA can’t help me if the hacker’s\ncoming from America?”\n\n“Yeah, so what?”\n\n“Well, he’s from Europe.”\n\n“You mean that you’ve been following a foreigner on the Milnet?”\n\n“You heard right.”\n\n“Let me call you right back.”\n\nBy now, I’d gotten used to these call backs. The spooks either have secure\ntelephone lines, or assume that I’m calling from a phone booth.\n\nFor the fifth time, I gave a how-I-spent-my-weekend talk. Zeke listened\nintently, obviously taking notes.\n\n“Think the hacker’s on assignment?”\n\n“I can’t say. But I suspect he’s saving his printouts.”\n\n“How about sending me a list of keywords that he’s searched for.”\n\n“Well, I’d be happy to, but I’m kinda busy today. Mostly, I’m trying to find\nthe electronic address that belongs to that German DNIC number. I’d be glad to\nswap information.”\n\n“You mean you’ll send me copies of the traffic in return for looking up that\naddress?”\n\n“Sure. Seems like a fair trade to me.” If I simply asked for the address point\nblank, he’d turn me down.\n\nIt didn’t work. Zeke stood his ground. “No possible way. I can’t even confirm\nthat we have such information.”\n\nStymied. I’d have to decode that address some other way.\n\nFrustrating, too. All day long, secret agencies were asking details from me,\nbut nobody ever told _me_ anything.\n\nThe day’s flurry left me exhausted, but hopeful. This one trace to Germany\nopened several doors. The spooks could no longer wash this away as a minor\ndomestic disturbance. It still might be minor, but it certainly wasn’t\ndomestic.\n\n\n![](images/Stol_9780307819420_epub_036_r1.jpg) I’d kicked over an anthill. For\nthe next few days, I couldn’t get away from my phone. The spooks kept calling\nback, asking for technical details—how do you connect from Europe into\nmilitary computers? Could I prove that the hacker came from Germany? Where did\nhe pick up passwords? How did he become super-user?\n\nThe Air Force OSI, however, worried about how to defend the Milnet. Did the\nhacker get into this site or that network? What type of computers did he\nattack? Could we contain him by locking him out of Lawrence Berkeley Labs?\n\nFinally, Steve White called. He’d received a terse message from the manager of\nthe German Datex network:\n\n“The address belongs to a computer in Bremen. We investigate.”\n\nOur circle was slowly closing.\n\nI was off to the library again, paging through the atlas. Bremen’s a port city\nin northern Germany, renowned for its medieval paintings and town hall.\nMomentarily, my thoughts flew across the Atlantic … these are places from\nhistory books.\n\nOn the heels of Steve’s call, Mike Muuss of the Ballistic Research Laboratory\ncalled. In Aberdeen, Maryland, the Army runs a research and development\nlaboratory; it’s one of the last government labs that doesn’t farm out its\nresearch to private contractors. Mike’s their computer honcho.\n\nMike Muuss—he’s famous throughout the Unix community as a pioneer in\nnetworking and as a creator of elegant programs to replace awkward ones. As\nMike puts it, good programs aren’t written or built. They’re grown. A six-\nfoot-tall, mustached runner, he’s incredibly driven, intense, and obsessed.\nMike’s paid his dues on ancient versions of Unix, dating back to the ’70s.\nWhen Mike talks, other wizards listen.\n\n“We detected Joe Sventek probing our system on Sunday,” Mike Muuss said. “I\nthought he was in England.”\n\nDo all wizards know each other? Is it telepathy?\n\n“He is,” I replied. “You detected a hacker masquerading as Joe.”\n\n“Well, keep him off the network. Boot him out.”\n\nI’d been through that before. “Closing him from my computer probably won’t\nstop him.”\n\n“Oh, he’s in a lot of computers, huh?” Mike understood.\n\nWe chatted about an hour, and I tried to hide my ignorance. Mike assumed that\nI knew about the Eniac, the world’s first big computer. “Yep, it was right\nhere at Ballistics Research Lab. Back in 1948. Ten years before I was born.”\n\nEniac might have been their first world class computer, but hardly their last.\nNow, the Army runs a pair of Cray supercomputers—the fastest in the world.\nWithout much modesty, Mike said, “If you want to see the Army in the year\n2010, look in my computers today. It’s all there.”\n\nExactly what the hacker wanted.\n\nSoon after that call, Chris McDonald of White Sands phoned. He’d also heard\nsomeone pounding at his doors and wanted to know what we intended to do about\nit.\n\n“Nothing,” I replied. “Nothing until the bastard’s been arrested.” A bluff,\nconsidering the chances of even discovering where the hacker lived.\n\nThe hacker had tried to chisel into eighty computers. Two system managers had\ndetected him.\n\nSuppose you walked along a city street trying to force doors open. How long\nwould it take before someone called the cops? Five houses? Ten?\n\nWell, with the help of the hacker, I knew the answer. On the computer\nnetworks, you can bang on forty doors before someone notices. With this kind\nof guard our computers are sitting ducks. Almost nobody’s watching for\nintruders trying to break in.\n\nMy own lab was as blind as anyone else. The hacker had broken in, become\nsystem manager, and had full run of my Unix computer before we detected him.\nEven then, we’d stumbled on him by accident.\n\nIt seemed unlikely that computer people could detect hackers in their systems.\nWell, maybe they could, but nobody was looking. So it was fruitful to keep\ncombing through Mitre’s phone bills. The hacker had clearly called TRW,\nIncorporated in Redondo Beach; he’d spent hours hooked into their computer.\n\nTRW—they’re a defense contractor, working for the Air Force and NASA.\n\nWhen I called Howard Siegal of TRW’s signal processing facility, he’d never\nheard a thing.\n\n“We can’t possibly have a hacker here. We’re running a secure facility.”\n\nBy definition, they were secure. I’d heard it before. “Just for my curiosity,\ncould you check your accounting logs for the past couple months?”\n\nHe agreed, though I didn’t expect to hear back from him. The next morning,\nthough, he called back with bad news.\n\n“You were right,” Howard said. “Someone’s been in our system, but I can’t\ndiscuss it. We’re closing all access to our computer.” He wouldn’t describe\nwhat evidence had changed his mind, nor would he say if the hacker had become\nsuper-user.\n\nI mentioned TRW to my friends at the Keck Observatory. Terry Mast raised his\neyebrows: “Hell, they’re the defense contractors that built the KH-11.”\n\nWait a second. I’d seen KH-11 before. The hacker scanned for that keyword on\nSaturday. “Say, Terry, what’s the KH-11?”\n\n“It’s a spy satellite. A secret spy satellite. KH stands for Key Hole. It’s\nthe eleventh in a series. It’s obsolete now.”\n\n“Replaced by the KH-12, I suppose.”\n\n“Yes, in fact. Massive cost overruns, the usual. Both of them are extremely\nsecret projects.” Secrecy automatically multiplied the cost of any project.\n\nAfter a while, Steve White of Tymnet called back. The German Bundespost had\ndetermined that the hacker came from the University of Bremen. The address\npointed to a Vax computer, not a telephone line, but the University knew\nnothing of any hacker. Apparently, they doubted that a hacker was on their\ncomputer. I wasn’t surprised: I’d heard it before. Give ’em a day or two, I\nthought.\n\nA Vax computer, at a university. A university pointed to a student. I wondered\nif my gut feeling was wrong: could I just be chasing some poor sophomore\nprankster?\n\nWhen talking to the CIA and NSA, I’d been careful to point out that\npossibility. It was bad enough to waste my time on this quest. I didn’t want\nthe spooks to gird up for battle, only to find some kid with a peashooter.\n\nBut the spooks asked me speculative questions. Zeke at the NSA: “Can you\ncharacterize this person’s computer experience?” Well, that’s easy. Just list\nwhat he’s done, and how adept he appears. Then, “How old is he?” and “Is he\npaid or is this his hobby?” I could only guess at these: the hacker never\ntyped in his age, weight, and occupation.\n\nAll my callers wanted to know about the hacker, even if they hadn’t the\nslightest interest in solving the case. My logbook held the information, but\nwas well over fifty pages. To get out from under these phone calls, I wrote a\nnote describing what I knew about him. By bringing together observations about\nhim, perhaps I could paint a profile of this hacker.\n\nSome of their questions I could answer directly: he targeted the military and\ndefense contractors. He guessed and stole passwords. He’d usually work at\nnights, German time.\n\nOther answers came from indirect observations: he seemed to be in his\ntwenties—his experience in Unix and VMS told me that. Probably out of\ncollege—he worked even when school was out. And only a smoker would choose\nBenson and Hedges as passwords.\n\nI must be watching only one or two people. I inferred this by knowing that he\nhad four purloined accounts on my system, yet he had chosen the same password\nfor all of them. Had there more than a couple people in on the caper, they\nwould have chosen separate passwords.\n\nIn writing this profile, I got an impression of someone methodical and\ndiligent. He’d been active for well over six months—and some of Mitre’s\nrecords indicated almost a year. He didn’t mind spending two hours on Sunday\nnight, slowly trying to guess passwords into military computers. Tedious and\ntiresome work.\n\nThe NSA kept pushing at my conclusions. Zeke asked, “If he’s so methodical,\nhow do you know you’re not just following some computer program?”\n\nThis one threw me for a loop. Zeke had challenged me on a point I hadn’t\nthought of before.\n\nCould I prove that I was following a real person?\n\nI’d once assumed that computer hackers were brilliant geniuses, creatively\nsearching out ways to build new programs. This guy was patient and plodding,\nrepeatedly trying the same tricks. The same sort of behavior you’d expect to\nfind from a computer program.\n\nSuppose someone had programmed a computer to methodically try to log into a\nhundred other computers. All you’d need would be a home computer with a modem:\nthe programming would be fairly easy. It could guess passwords (like “visitor”\nand “guest”) about as well as a human. And it could run all night long,\nwithout anyone nearby.\n\nA momentary panic. Could I prove that I wasn’t following such a machine?\n\nSure. My hacker made mistakes. Occasional typing errors.\n\nI told Zeke, “There’s a human behind that keyboard, all right, who’s not a\nperfect typist.”\n\n“Can you be sure that the hacker’s in the same country as the computer?”\n\nZeke was on top of this, all right. His questions kept me thinking. I was\nwatching someone, and my guts said he was in Germany. But there’s no reason\nwhy he couldn’t be sitting in Australia, connected into a computer in Germany.\n\nMy beeper interrupted my answer. The hacker was back. “Gotta run, Zeke!”\n\nDown the hall again, into the switchyard. There he was, just logging in. I\nstarted calling Tymnet, but by the time Steve White answered, the hacker had\nlogged off. Total connect time: thirty seconds.\n\nDamn. All week long, the hacker had been connecting for a minute or two at a\ntime. Every time, he triggered my beeper and siphoned off my adrenaline. But I\ncouldn’t trace such short connections. Ten minutes, for sure. Five minutes,\nmaybe. But not one minute.\n\nFortunately, Steve didn’t mind my panic calls, and each time would explain a\nnew wrinkle in Tymnet’s switching system. Today, however, Steve mentioned that\nthe Bundespost had talked with the University of Bremen.\n\nAfter a meticulous search, the systems folks at the University of Bremen had\ndiscovered a privileged user: “An expert has created an account for himself,\nand had root privileges. He was last active on December 6, and erased all\naccounting traces.”\n\nSounded familiar. In fact, the more I read it, the more it said. I could infer\nthat Bremen used Unix, rather than the VMS operating system: on Unix\ncomputers, people say “root” access; on VMS, it’s “system” privileges. Same\nconcept, different jargon.\n\nMeanwhile, the German Bundespost had determined the account that the hacker\nused to connect across the Atlantic. They set a trap on that account: the next\ntime someone used that account, they’d trace the call.\n\nThe man at the Bundespost thought the account might be stolen. Instead of\nasking the account owner if he’d authorized the hacker to call America, the\nBundespost would quietly watch what was going on.\n\nThe Germans weren’t sitting around. The University would monitor the\nsuspicious account, and the Bundespost watched the network activity. More and\nmore mouse holes were being watched.\n\nWithin an hour, Steve received one more message from Germany: the University\nof Bremen will be shutting down its computers for the next three weeks.\nChristmas break.\n\nMaybe this was good news. If the hacker didn’t show up during the break, he\nwas likely from Bremen. But if he continued despite the break, he’d have to\npick a different route … one that might lead directly to him.\n\nThe hacker wasn’t more than a few minutes from Berkeley. Now, we were only a\ncouple weeks from him.\n\n\n![](images/Stol_9780307819420_epub_037_r1.jpg) December was time to print\ngreeting cards and my housemates got together for our annual ink splash.\nMartha drew the design and Claudia and I cut the silk screens. We figured that\nwe’d avoid offending our zealot friends by keeping the card astronomical:\nWinter Solstice Greetings!\n\n“We make cards the way you chase hackers,” Martha said.\n\n“Huh?”\n\n“Do it yourself,” she observed. “Not the way professionals would do it, but\nsatisfying anyway.”\n\nI wondered how a real professional would track this hacker. But then, who\n_were_ the professionals? Was anyone dedicated to following people breaking\ninto computers? I hadn’t met them. I’d called every agency I could think of,\nyet nobody had taken over. Nobody had even offered advice.\n\nAll the same, the FBI, CIA, OSI, and NSA were fascinated. A foreigner was\nsiphoning data from U.S. databases. The case was documented—not just by my\nlogbook, but also by massive printouts, phone traces, and network addresses.\nMy monitoring station ran full time—the chances for catching the culprit\nseemed good.\n\nBut not a dime of support. My salary was skimmed from astronomy and physics\ngrants, and lab management leaned on me for systems support, not\ncounterespionage. Eight thousand miles away, a hacker was prying around our\nnetworks. Three thousand miles east, some secret agents were analyzing my\nlatest reports. But two floors up, my bosses wanted to slam the door.\n\n“Cliff, we’ve decided to call it quits,” Roy Kerth said. “I know you’re close\nto finding the hacker, but we can’t afford it anymore.”\n\n“How about another two weeks. Until New Year’s Day?”\n\n“No. Close things up tomorrow. Revoke everyone’s passwords tomorrow\nafternoon.” In other words, slam the door.\n\nDamn. Three, nearly four months work down the tubes. And just when the trace\nseemed promising.\n\nFrustrating. The hacker could hide, but he couldn’t shake me. My management\nwas the only one who could do that. Just as we were zeroing in on the bastard.\n\nDepressing as well. The hacker wouldn’t have any trouble returning to his\nhaunts. He would still roam the networks, breaking in wherever he could.\nNobody cared.\n\nI began planning how to pull every user’s password. It’s easy to do—just\nrebuild the password file. But how do you tell passwords to twelve hundred\nscientists? Bring them together in one room? Call everyone on the phone? Mail\nthem notes?\n\nI was still bummed out when Mike Gibbons called from the FBI.\n\n“Just checking to see where the trace has led.”\n\n“Into Bremen,” I said. “A university there.”\n\n“So it’s a college student, huh?”\n\n“Not necessarily. But we’ll never find out.”\n\n“Why not?”\n\n“LBL is closing its doors. Tomorrow.”\n\n“You can’t do that,” the FBI agent said. “We’re opening an investigation.”\n\n“My boss thinks he can.”\n\n“Tell him that we’re just making contacts in Europe. Whatever you do, don’t\nstop now.”\n\n“You’re talking to the wrong guy, Mike.”\n\n“OK. What’s your boss’s phone number?”\n\nI wasn’t about to draw fire from Roy Kerth by asking for another extension. If\nthe FBI really wanted us to stay open, let them deal with him.\n\nAnyway, nobody was supporting me. All those fancy three-letter agencies ever\nsaid was, “Gimme.” Every agency wanted copies of logs and printouts. Every\ntime we completed a trace, four or five people demanded to know where it led.\n\nThese were the facts of life in dealing with a bureaucracy: everyone wanted to\nknow what we discovered, but nobody would take responsibility. Nobody\nvolunteered to be the contact point, the center for collecting and\ndistributing information. I’d started out in the center of the study, and it\nseemed like I’d stay there.\n\nOn the other hand, since nobody told me what to do, I could take chances—like\nremaining open to a hacker who could wipe out my computer in a couple seconds.\nI could be a one-man band, as in grad school: if it’s worth doing, do it for\nyourself, not to please some funding agency.\n\nIf only I could keep Kerth and company off my back.\n\nThe FBI did that. Mike Gibbons talked to Roy Kerth. I’m not sure what they\nsaid, but half an hour later, Roy told me to remain open for the next few\nweeks.\n\n“They’re finally taking us seriously,” Roy said.\n\n“Serious enough to pay our overhead?”\n\n“Are you kidding?”\n\nRescued from the brink. We’d stay open, though only through the grace of an\ninformal agreement. I had a couple more weeks to catch the hacker.\n\nI might not need much more. Friday, December 19, at 1:38, the hacker showed up\nagain. Stayed around for two hours, fishing on the Milnet.\n\nA pleasant Friday afternoon, trying to guess passwords to the Strategic Air\nCommand, the European Milnet Gateway, the Army’s West Point Geography\nDepartment, and seventy other assorted military computers.\n\nI got to the monitors within a few seconds, and phoned Steve White at Tymnet.\nHe was getting ready to go home when I called.\n\n“The hacker’s on our computer. Tymnet’s logical port number 14.”\n\n“OK,” Steve said. The usual keyboard clatter in the background. Twenty seconds\nelapsed, and he called out, “Got it!”\n\nSteve had traced a connection from California to Germany in less than a\nminute.\n\n“How’d you do that?”\n\nSteve laughed. “Now that I know you’re looking for traces, I’ve automated my\ntracing program. I just have to tell it to fly.”\n\n“Where’s it point to?”\n\n“You’re getting a call from address 2624 DNIC 4511 dash 049136.”\n\n“What’s that mean?”\n\n“We’ll have to ask the Bundespost, but I can tell you a bit about the address.\nThe first digits, 2624, mean Germany.”\n\n“We already know that.”\n\n“The next four digits, 4511, begin with a 4. That means the hacker’s coming\nthrough a public dial-in port.”\n\n“I don’t understand. What’s different from the last time you traced the\nhacker?”\n\n“Last time, we traced him to a computer at the University of Bremen. That\ntime, the digits were 5421. The 5 means that a computer was at the other end.”\n\nOh—the address was coded, like American pay telephones, whose phone numbers\nalways seem to have a fourth digit of 9.\n\n“So the connection isn’t coming from the University of Bremen’s computer?” I\nasked.\n\n“That’s for certain. But we know more than that. We know that the hacker’s\ncoming into a dial-in port. He’s connecting from a local telephone.”\n\n“Do you know his phone number?”\n\n“No, but the Bundespost can determine what telephone number he called.”\n\nSteve’s news brought us one step closer. The hacker couldn’t hide behind the\nUniversity of Bremen.\n\n“So when will we find the location of this electronic address?”\n\n“Should be soon. I asked Wolfgang to look it up.”\n\n“Who’s that?”\n\n“Wolfgang Hoffman. The Datex network manager in Germany.”\n\n“You’re on the phone with him?”\n\n“Of course not,” Steve said. “We’re sending electronic mail to each other.” I\ncould have guessed.\n\n“And he hasn’t decoded today’s address, huh?”\n\n“That’s right. Until the Bundespost decodes the address, we can’t do much …\nhold on, something’s showing up … it’s a message from Germany.” Steve\napparently had a direct line to Europe, and passed notes between countries the\nway I might dash off an interoffice memo.\n\nSteve translated the note. “Wolfgang says the hacker came from a dial-in port.\nHe’s dialed in over a telephone line.”\n\n“We knew that already.”\n\n“Yeah, but he’s not coming from Bremen. Today, he’s dialing from Hannover.”\n\n“So where is he? In Bremen or Hannover?”\n\n“Wolfgang doesn’t know. For all we know, he could be in Paris, calling long\ndistance.”\n\nAnother dash to the library. Their atlas showed the city of Hannover, maybe\nseventy-five miles south of Bremen. Looked like a big city, around half a\nmillion people. Jeez—the stuff that travelogues are made from.\n\nWas some student in Bremen dialing Hannover? Not likely. Even with the\nuniversity closed, he could just call Bremen’s Datex port. A Bremen student\nwouldn’t make a long distance call to Hannover.\n\nAah, but when the university closed up, students go home.\n\nWas I following some sophomore, home on vacation?\n\nBut it didn’t feel like a student. College students don’t have six-month\nattention spans. They’d search for games and academic programs, not military\nkeywords. And wouldn’t a student leave some kind of signature or joke\nbehind—some way of sticking out his tongue at us?\n\nIf this wasn’t a student, then why did he come from two places in Germany?\nMaybe he knew some way to call long distance into Hannover—perhaps from some\nunprotected computer, or with a stolen credit card. Yesterday it was Bremen.\nToday Hannover. Where will he hide tomorrow?\n\nThe only way to find out was to keep watching. Quietly.\n\nI’d waited four months. I could wait a while longer.\n\n\n![](images/Stol_9780307819420_epub_038_r1.jpg) “You need a German search\nwarrant.”\n\nSteve White called back from Tymnet. He’d just received electronic mail from\nWolfgang Hoffman at the German Bundespost. Wolfgang was hot to pursue the\nhacker, but needed legal support to trace their lines.\n\n“How do I get a search warrant in Germany?” I asked Steve.\n\n“I don’t know, but the Bundespost says they’re going to the Hannover courts\ntomorrow to discuss it.”\n\nThis was good news. Somewhere in Germany, Wolfgang Hoffman had started wheels\nturning. With luck, they’d get some court orders, make a couple more traces,\nand arrest the varmint.\n\nSteve White was less optimistic. “When the hacker shows up, the Germans will\nhave to trace the Datex networks, find the phone number that the hacker is\ncalling, and then trace that telephone line.”\n\n“Foo,” I said, remembering my traces in Berkeley and Virginia. Unless Wolfgang\nand his team were patient, competent, and clever, the hacker would evade them.\n\nToo many things could go wrong. The hacker could be from another country. He\ncould be using a phone line from another city, disguised through a wide-area\ntelephone system. The court might not grant the search warrants. Or the hacker\nmight sniff the wind and realize that someone was on his trail.\n\nWolfgang sent another message: “Until the search warrant appears, we will\nrecord the name of the Datex user-identifier.”\n\nSteve explained, “Whenever you use Tymnet or Datex, someone pays for the\nservice. When you use the network, you have to type in your account number and\npassword. The Germans are going to find out who’s paying for the hacker’s\nconnections. When we signal them that the hacker’s around, they’ll not only\ntrace their Datex network, but also find the account name that’s paying for\nthe connection.”\n\nI understood. If the hacker had stolen someone else’s account number and\npassword, he could be charged with theft, and getting a search warrant would\nbe easy. On the other hand, if he was paying for his own connections, it would\nbe easy to find his name, and a court order wouldn’t be necessary. They might\nnot even have to trace his telephone lines.\n\nNo doubt, this guy Wolfgang was sharp. He was looking for shortcuts to avoid\nmaking telephone traces. At the same time, he was building a case against the\nhacker.\n\nSaturday, December 20, Steve called me at home. Martha glared at me for\nletting brunch get cold.\n\nSteve had just received another message from Germany. The Bundespost had\ncontacted the Bremen State Prosecutor, Herr Stattsanwalt Von Vock. (“Now\nthat’s a high-class title,” I thought.)\n\nThe message from Germany read: “The German State Prosecutor needs to contact\nhigh-level U.S. criminal justice persons so as to execute proper search\nwarrants. The Bundespost cannot move until officially notified by a high-level\nU.S. criminal office.”\n\nWhat’s a high-level U.S. criminal office? The Mafia? Whatever they meant, I’d\nbetter get people moving.\n\nI called my boss, Roy Kerth, who crustily observed that it’d taken the Germans\nsix months to discover this problem. “If they were half competent, the hacker\nwould be behind bars by now.”\n\nTo catch this snake, we all had to pull in the same direction. My boss’s\nflames didn’t promote harmony, so how could they promote international\ncooperation? Maybe I’d be better off appealing to our legal counsel.\n\nAletha Owens knew what to do. “I’ll call Germany and talk to them directly.\nThey probably need someone in the FBI, but I’ll start things moving.”\n\n“ _Sprechen Sie Deutsch_?”\n\n“Not in twenty years,” Aletha said. “But I’ll haul out the old Berlitz tapes.”\n\nSunday morning, Aletha called back. “Hey, my German isn’t so bad. A few\nproblems with the future tense, but not bad. Not bad.”\n\n“Yeah, but what did you learn?”\n\n“Well, I learned all sorts of things about reflexive verbs and …”\n\n“What about the hacker?”\n\n“Oh, him. Aah, yes.” Aletha adopted a mock academic tone. “The German State\nProsecutor is a most kindly gentleman who believes in protecting both liberty\nand property. So he needs an official request to open an investigation.”\n\n“Who’s the official?”\n\n“The FBI. We’ve got to ask the FBI to contact their German counterparts. Or\nshould I say, ‘you,’ since I’ll be gone next week.”\n\nIt was on my shoulders to get the FBI to call the Germans to open an\ninvestigation. Great—another chance for them to say ‘go away kid.’ I left a\nmessage for Mike Gibbons at the Alexandria, Virginia, FBI office.\n\nAmazingly, Mike called ten minutes later from Colorado.\n\n“Hi, Cliff. This had better be important.”\n\n“Sorry to bother you, but the German prosecutor needs to talk to someone in\nthe FBI. We’ve traced our troubles into Hannover.”\n\n“Well there’s nothing I can do tonight,” Mike said. “And I don’t have any\ndocumentation here.”\n\nIn theory, the FBI’s representative in Germany would contact his German\ncounterpart, and things would progress from there. Mike said that this guy,\nthe U.S. Legal Attaché, lived in Bonn and handled communications between the\ntwo countries. In a sense, he represents the FBI within Germany.\n\nOver the next few months, I would often hear about the U.S. Legal Attaché. I\nnever learned his name, though plenty of curses were directed his way.\n\nThe next day, Mike fished through the crime laws. “It’s covered by the\ncomputer fraud act. Open and shut case.”\n\n“But the guy has never set foot in the States,” I observed. “How can you get\nsomeone from another country?”\n\n“Well, he probably won’t be extradited, if that’s what you mean. But we can\npress charges and get him thrown into a German prison, especially if the\nGerman law is similar to ours.”\n\n“What’s the likelihood that the FBI will drop the whole thing?”\n\n“Not if I can help it,” Mike said. “We’ll have to work with attorneys at the\nJustice Department, but I don’t see a problem there.”\n\nI still didn’t believe him. The case was obvious to me, but too complex to\ndescribe to a criminal lawyer.\n\n“Is there anything that I can get that will help you?”\n\n“Come to think of it, there is. Could you write up a summary of the hacker?\nYou know, draw up a profile of him and tell us who we’re looking for. Things\nlike when he’s active, what he’s expert in, any idiosyncrasies. Don’t\nspeculate, but try to identify our man.”\n\nHere was a useful project to keep me from pestering Mike for a few days. I\ncombed through my logbook and drew together a profile of my hacker.\n\nCompiling this profile should have kept me out of trouble for a few days. But\ntrouble came from another front.\n\nSomeone at NSA had leaked word of my research to the Department of Energy. In\nturn, they were pissed that they hadn’t heard earlier—and more directly.\n\nRoy Kerth stopped me in the hallway. “DOE is going to reprimand us for not\ntelling them about this incident.”\n\n“But we did tell them,” I objected. “More than two months ago.”\n\n“Prove it.”\n\n“Sure. It’s in my logbook.”\n\nRoy wanted to see it, so we walked over to my Macintosh and brought up the\nlogbook. Sure enough, on November 12th, my logbook said that I’d informed DOE.\nI’d written a summary of our conversation and even included a phone number.\nDOE couldn’t complain—we could prove that we’d informed them.\n\nSaved by my logbook.\n\nJust like observing at a telescope. If you don’t document it, you might as\nwell not have observed it. Sure, you need powerful telescopes and computers.\nBut without a logbook, your observations won’t amount to much.\n\nOn December 30, my beeper woke me up around 5 A.M. By reflex, I called Steve\nat his house. He wasn’t pleased to hear from me.\n\n“The hacker’s on.”\n\n“Aaw, I was just in the middle of a dream. Are you sure it’s him?” His British\naccent didn’t hide his annoyance.\n\n“I’m not sure, but I’ll find out in a minute.”\n\n“OK, I’ll start a trace.” Steve put up with a lot from me.\n\nFrom home, I dialed my Unix computer. Damn. No hacker. The electricians had\ntripped my alarm by shutting off a nearby computer.\n\nSheepishly, I called Steve back.\n\n“Say, Cliff, I can’t find anyone connected to your computer.” His voice was\nstill sleepy.\n\n“Yeah. It’s a false alarm. I’m sorry.”\n\n“No problem. Maybe next time, huh?”\n\nNow here’s a good guy. If someone I’d never met rousted me out of bed to chase\na phantom in a computer.…\n\nLuckily, only Steve had heard me cry wolf. What would happen to my credibility\nif I’d passed the word along to Germany or the FBI? From now on, I’d double-\ncheck every alarm.\n\n\n![](images/Stol_9780307819420_epub_039_r1.jpg) New Year’s Eve found us sitting\naround the fire with friends, sipping eggnog and listening to the explosions\nas neighborhood idiots set off cherry bombs in the street.\n\n“Hey,” said Martha, “we’d better get moving if we’re going to make it to First\nNight.” San Francisco was throwing a city-wide party to welcome in 1987,\nfoster civic pride, and give people an alternative to getting drunk and\nsmashing into each other. There was music, dance, theater, and comedy in a\ndozen locations across town, with cable-car shuttles between events.\n\nSeven of us piled into a beat-up Volvo and inched into San Francisco, trapped\nin a raucous traffic jam. Instead of honking, people blew party horns out\ntheir car windows. Finally we came to the brightly-lit city, ditched the car,\nand headed for a flamenco concert.\n\nWe found our way to the Mission district—the Latin section of town, and\ndiscovered a packed Catholic church with an impatient audience. A sheepish\nface emerged from behind the curtain, explaining, “None of the lights work so\nwe’re delaying the performance.”\n\nAmid the catcalls and boos, Martha stood up and pushed me forward. I still had\nmy electrician’s license, and she’d done tech for many an amateur theatrical.\nWe snuck backstage. The flamenco dancers in their glittering costumes smoked\nand paced the dark stage like caged tigers, tapping their feet and glancing at\nus doubtfully. Martha set about untangling the maze of cables strewn in the\nwings while I located the blown fuse. A quick swap of fuses and, shazam, the\nstage lights lit.\n\nThe dancers stamped and cheered and, as Martha neatly coiled the last cable\nand adjusted the lighting board, the emcee dragged us on stage to thank us.\nAfter we escaped the limelight, we enjoyed the flamenco dancing and _faro_\nsinging; the scowling, nervous creatures we’d seen on the dark stage were\ntransformed into elegant, whirling dancers.\n\nWe ducked outside and found a shuttle bus driven by an old lady who could have\npassed for Tugboat Annie, in appearance and language. She maneuvered the bus\ngamely through the crowded streets, and we found ourselves at the Women’s\nBuilding on Eighteenth Street. There the Wallflower Order danced and told\nstories of feminism and social protest.\n\nOne dance was about the Wu-Shu, a legendary Chinese monkey who defeated the\ngreedy warlords and gave land back to the people. Sitting in the balcony, I\nthought about politically correct monkeys—was I a pawn of the warlords? Or was\nI really a clever monkey, on the side of the people? I couldn’t tell, so I\nforgot about my hacker and enjoyed the dance.\n\nFinally, we wound up dancing wildly to a rhythm and blues band with lead\nsinger Maxine Howard, a sensational blues singer and the sexiest woman in the\nhistory of the world. She was picking people out of the audience to dance with\nher on the stage, and we soon found ourselves hoisting a protesting Martha\nonto the platform. Within a few minutes, she and her fellow victims overcame\ntheir stage fright and formed themselves into a fairly synchronized chorus\nline, doing little hand motions like the Supremes. I was never much for\ndancing, but by two o’clock or so, I found myself jumping and spinning around\nwith Martha, lifting her high in the air …\n\nWe finally had our fill of high culture and cheap thrills, and went to sleep\nat a friend’s house in the Mission district. What felt like moments after my\nhead touched the pillow (though it was actually nine the next morning), my\nbeeper woke me up.\n\nHuh? The hacker was at work on New Year’s Day? Give me a break.\n\nThere wasn’t much I could do. Hacker or not, I wasn’t about to call Steve\nWhite on New Year’s morning. Anyway, I doubted that the German Bundespost\ncould do much about it on a holiday. Most of all, I was ten miles from my\nlaboratory.\n\nI felt caged in while the hacker had free run. If he wanted to tweak my nose,\nhe’d found the way. Just show up when I couldn’t do anything.\n\nWell, I couldn’t do much beyond worry, so I tried to sleep. With Martha’s arm\naround me, rest came easily. “C’mon, sweetie,” she purred. “Give the hacker a\nholiday.” I sank into the pillows. Hacker or not, we would celebrate the New\nYear. We slept the rest of the morning. Around noon, we found our way back\nhome. Claudia greeted us with a violin sonata … she’d spent New Year’s Eve\nplaying at some millionaire’s party.\n\nMartha asked about her job. “You should have seen the canapés!” Claudia\nanswered. “We had to sit and stare at them for _hours_ before they finally saw\nus looking pathetic and brought us some. They had a whole smoked salmon and\ncaviar and strawberries dipped in chocolate and—”\n\nMartha cut in, “I meant what music you played.”\n\n“Oh, we played that Mozart sonata everyone likes that goes diddle dum diddle\nda da da. Then they started making requests for really icky things like ‘My\nWild Irish Rose.’ I thought I’d get sick but after all it was $125 for two\nhours and it was on the way to my Mom’s so I could drop the dog off there, and\ndo some shopping up at Santa Rosa—”\n\nMartha snuck in a word about brunch. We were all in the kitchen mixing waffle\nbatter and making fruit salad when my beeper sounded.\n\nDamn. The hacker again. Martha cursed, but I hardly heard her: I zipped over\nto my Macintosh and dialed the lab.\n\nThere was the hacker, all right, logged in as Sventek. It looked like he was\nusing the Milnet, but I couldn’t be sure until I went to the lab. Meanwhile,\nI’d better call Steve White at Tymnet.\n\nNo time—the hacker disappeared within a minute. He was playing New Year’s\ngames.\n\nThere wasn’t much to do but pick up the pieces. I scarfed down the waffles and\nbiked over to the lab. There, the hacker’s New Year’s celebration was saved on\nmy printers. I scribbled notes on the printouts, next to each of his commands:\n\n![](images/Stol_9780307819420_epub_040_r1.jpg)\n\nWhee! The hacker had entered an Army database and searched for secret Air\nForce projects. Even an astronomer would know better. He caught on quickly,\nthough:\n\n![](images/Stol_9780307819420_epub_041_r1.jpg)\n\nWell, I’d never come across such things. I’d always thought that a theater was\nsomewhere to watch movies, not a place to develop nuclear forces. This hacker\nwasn’t playing games.\n\nAnd he wasn’t satisfied with the titles to these documents—he dumped all\ntwenty-nine over the line printer. Page after page was filled with army\ndouble-talk like:\n\n**TITLE: Nuclear, chemical, and biological national security affairs**\n\n**DESCRIPTION: Documents relating to domestic, foreign, and military police\nfor the  \napplication of atomic energy, utilization of nuclear and chemical weapons, and  \nbiological defense relating to national security and national level crises\nmanagement. Included are studies, actions, and directives of an related to the  \nPresident, National Security Council, Assistant to the President for National\nSecurity Affairs, and interdepartmental groups and committees addressing\nnational security affairs regarding nuclear and chemical warfare and  \nbiological  \ndefense.**\n\nThere, my printer jammed. The old Decwriter had paid its dues for ten years,\nand now needed an adjustment with a sledge hammer. Damn. Right where the\nhacker listed the Army’s plans for nuclear bombs in the Central European\ntheater, there was only an ink blot.\n\nI didn’t know much about movie theaters in Central Europe, so I gave Greg\nFennel a call at the CIA. Amazingly, he answered his phone on New Year’s Day.\n\n“Hi, Greg—what brings you in on New Year’s?”\n\n“You know, the world never sleeps.”\n\n“Hey, what do you know about movie houses in Central Europe?” I asked, playing\nthe fool.\n\n“Oh, a bit. What’s up?”\n\n“Not much. The hacker just broke into some Army computer at the Pentagon.”\n\n“What’s that got to do with movies?”\n\n“I dunno,” I said, “but he seemed especially interested in nuclear force\nstructure developments in Central European theaters.”\n\n“You dunce! That’s Army tactical warfare plans. Jeez. How did he get it?”\n\n“His usual techniques. Guessed the password to the Army Optimis database in\nthe Pentagon. It looks like a bibliography of Army documents.”\n\n“What else did he get?”\n\n“I can’t tell. My printer jammed. But he searched for keywords like ‘SDI,’\n‘Stealth,’ and ‘SAC.’ ”\n\n“Comic book stuff.” I wasn’t sure if Greg was joking or serious. He probably\nthought the same of me.\n\nCome to think of it, how did the spooks know if I was putting them on? For all\nthey knew, I might be inventing everything. Greg had no reason to trust me—I\nhad no clearance, no badge, not even a trench coat. Unless they were spying\nbehind my back, my credibility remained untested.\n\nI had only one defense against this quicksand of distrust—the facts.\n\nBut even if they believed me, they weren’t likely to do anything. Greg\nexplained, “We can’t just send Teejay overseas and bust down someone’s door,\nyou know.”\n\n“But can’t you, well, sorta snoop around there and find out who’s responsible\nfor this?” I imagined spies in trench coats again.\n\nGreg laughed. “That’s not how things work. Trust me—we’re working on it. And\nthis latest news will add fuel to the fire.” So much for the CIA. I just\ncouldn’t tell if they were interested or not.\n\nOn January 2, I called the Alexandria FBI office and tried to leave a message\nfor Mike Gibbons. The duty agent who answered the phone said in a dry voice,\n“Agent Gibbons is no longer working this case. We suggest you contact the\nOakland office.”\n\nSuper. The only FBI agent that knows the difference between a network and a\nnitwit has been pulled off the case. No explanation given.\n\nAnd just when we need the FBI. Wolfgang was still waiting for a warrant from\nthe U.S. Legal Attaché in Bonn. A week of waiting, and it still hadn’t come\nthrough. Time to knock on another door.\n\nNo doubt the National Security Agency would want to know about leaks from a\nPentagon computer. Zeke Hanson at Fort Meade answered.\n\n“Did the Army information go directly to Europe?” Zeke asked.\n\n“Yeah, though I don’t know exactly where,” I said. “Looks like Germany.”\n\n“Do you know which International Record Carrier they used?”\n\n“Sorry, I don’t. But I can fish it out of my records if it’s that important.”\nWhy would NSA want to know who had carried this traffic?\n\nOf course. NSA is rumored to tape record every transatlantic telephone\nconversation. Maybe they’d recorded this session.\n\nBut that’s impossible. How much information crosses the Atlantic everyday? Oh,\nsay there’s ten satellites and a half-dozen transatlantic cables. Each handles\nten thousand telephone calls. So the NSA would need several hundred thousand\ntape recorders running full time. And that’s just to listen to the phone\ntraffic—there are computer messages and television as well. Why, fishing out\nmy particular session would be nearly impossible, even with supercomputers to\nhelp. But there was an easy way to find out. See if NSA could obtain the\nmissing data.\n\n“The New Year’s Day sessions were interrupted by a paper jam,” I told Zeke,\n“so I’m missing an hour of the hacker’s work. Think you could recover it?”\n\nZeke was cagey. “What’s its importance?”\n\n“Well, I can’t quite say, since I haven’t seen it. The session started at 8:47\non New Year’s Day. Why don’t you see if someone in Ft. Meade can find the rest\nof the traffic from this session?”\n\n“Unlikely at best.”\n\nThe NSA was always willing to listen but clammed up tight whenever I asked\nquestions. Still, if they were doing their homework, they’d have to call me\nand see if our results were the same. I waited for someone to ask to see our\nprintout. Nobody did.\n\nCome to think of it, two weeks ago, I’d asked Zeke Hanson at the NSA to find\nout an electronic address. When I first traced a line into Europe, I passed\nthe address to Zeke. I wondered what he’d done with it.\n\n“Did you ever find out where that DNIC address comes from?” I asked.\n\n“Sorry, Cliff, that information is unavailable.” Zeke sounded like one of\nthose Magic-8 balls, the kind that say, “Reply hazy, ask again later.”\n\nFortunately, Tymnet had already figured out the address … it only took Steve\nWhite a couple hours.\n\nPerhaps NSA has lots of electronics wizards and computer geniuses, listening\nto the world’s communications. I wonder. Here, I’d presented them with two\nfairly easy problems—find an address and replay some traffic. Maybe they did,\nbut they never told me a whit. I suspect they do nothing, hiding behind a veil\nof secrecy.\n\nWell, there was one more group to inform. The Air Force OSI. The Air Force\nnarcs couldn’t do much about the hacker, but at least they could figure out\nwhose computer was wide open.\n\nJim Christy’s gravelly voice crackled over the phone lines: “So it’s the Army\nOptimis system, huh? I’ll make a few calls and bang a few heads.” I hoped he\nwas joking.\n\nSo 1987 started on a sour note. The hacker still had the free run of our\ncomputers. The only competent FBI agent had been pulled from the case. The\nspooks wouldn’t say a thing, and NSA seemed uninspired. If we didn’t make some\nheadway soon, I’d give up too.\n\n\n![](images/Stol_9780307819420_epub_042_r1.jpg) Around noon on Sunday, January\n4, Martha and I were stitching a quilt when my beeper sounded. I jumped for\nthe computer, checked that the hacker was around, then called Steve White.\nWithin a minute, he’d started the trace.\n\nI didn’t wait while Steve tracked the call. The hacker was on my computer, so\nI biked up to the lab and watched from there. Another twenty-minute race up\nthe hill, but the hacker took his time: he was still typing when I reached the\nswitchyard.\n\nUnderneath the printer, an inch-thick printout had accumulated. The hacker\nhadn’t been lazy today. The top line showed him masquerading behind Sventek’s\nname. After checking that none of our system managers were around, he went\nback to the Pentagon’s Optimis database. Not today: “You are not authorized to\nlog in today,” was the Army computer’s reply.\n\nWell, hot ziggity! Jim Christy must have bashed the right heads.\n\nScanning the printout, I could see the hacker going fishing on the Milnet. One\nby one, he tried fifteen Air Force computers, at places like Eglin, Kirtland,\nand Bolling Air Force Bases. No luck. He’d connect to each computer, twist the\ndoorknob once or twice, then go on to the next system.\n\nUntil he tried the Air Force Systems Command, Space Division.\n\nHe first twisted on their doorknob by trying their System account, with the\npassword of “Manager.” No luck.\n\nThen Guest, password of “Guest.” No effect.\n\nThen Field, password “Service”:\n\n**Username: FIELD**\n\n**Password: SERVICE**\n\n**WELCOME TO THE AIR FORCE SYSTEM COMMAND—SPACE DIVISION VAX/VMS 4.4**\n\n**IMPORTANT NOTICE**\n\n**Computer System problems should be directed to the Information Systems  \nCustomer Service Section located in building 130, room 2359.  \nPhone 643-2177/AV 833-2177**.\n\n**Last interactive login on Thursday, 11-DEC-1986 19:11**\n\n**Last non-interactive login on Tuesday, 2-DEC-1986 17:30**\n\n**WARNING—Your password has expired; update immediately with SET PASSWORD|**\n\n**$ show process/privilege**\n\n**4-JAN-1987 13:16:37.56** **NTY1:** **User: FIELD**\n\n**Process privileges:**\n\n**BYPASS** | **may bypass all system protections**  \n---|---  \n**CMKRNL** | **may change mode to kernel**  \n**ACNT** | **may suppress accounting messages**  \n**WORLD** | **may affect other processes**  \n**OPER** | **operator privilege**  \n**VOLPRO** | **may override volume protection**  \n**GRPPRV** | **group access via system protection**  \n**READALL** | **may read anything as the owner**  \n**WRITEALL** | **may write anything as the owner**  \n**SECURITY** | **may perform security functions**  \n  \nShazam: the door had swung wide open. He’d logged in as Field Service. Not\njust an ordinary user. A completely privileged account.\n\nThe hacker couldn’t believe his luck. After dozens of attempts, he’d made the\nbig time. System operator.\n\nHis first command was to show what privileges he’d garnered. The Air Force\ncomputer responded automatically: System Privilege, and a slew of other\nrights, including the ability to read, write, or erase any file on the system.\n\nHe was even authorized to run security audits on the Air Force computer.\n\nI could imagine him sitting behind his terminal in Germany, staring in\ndisbelief at the screen. He didn’t just have free run of the Space Command’s\ncomputer; he controlled it.\n\nSomewhere in Southern California, in El Segundo, a big Vax computer was being\ninvaded by a hacker halfway around the world.\n\nHis next moves weren’t surprising: after showing his privileges, he disabled\nthe auditing for his jobs. This way, he left no footprints behind; at least he\nthought not. How could he know that I was watching from Berkeley?\n\nConfident that he was undetected, he probed the nearby computers. In a moment,\nhe’d discovered four on the Air Force network, and a pathway to connect to\nothers. From his high ground, none of these were hidden from him; if their\npasswords weren’t guessable, he could steal them by setting up Trojan horses.\n\nThis wasn’t a little desktop computer he’d broken into. He found thousands of\nfiles on the system, and hundreds of users. Hundreds of users? Yep. The hacker\nlisted them all.\n\nBut his greediness got in his way. He commanded the Air Force computer to list\nthe names of all its files; it went merrily along typing out names like\n“Laser-design-plans” and “Shuttle-launch-manifest.” But he didn’t know how to\nshut off the spigot. For two hours, it poured a Niagara of information onto\nhis terminal.\n\nFinally, at 2:30, he hung up, figuring that he’d just log back into the Air\nForce computer. But he couldn’t get back on. The Air Force computer informed\nhim:\n\n**“Your password has expired. Please contact the system manager.”**\n\nLooking back over the printout, I realized his goof. The air force computer\nhad expired the “field service” password; he’d received a warning when he\nfirst broke in. Probably, the system automatically expired passwords after a\nfew months.\n\nTo stay on the machine, he should have immediately reset his password.\nInstead, he ignored the request. Now the system wouldn’t let him back.\n\nFrom thousands of miles away, I could sense his frustration. He desperately\nwanted to get back into that computer, but he’d been foiled by his own stupid\nmistake.\n\nHe’d stumbled on the keys to a Buick, and locked them in the car.\n\nThe hacker’s mistake solved one problem: what should I tell the Air Force\nSpace Division? Since it was a Sunday, there was nobody to call today. And\nbecause the hacker had locked himself out, he was no longer a danger to the\nAir Force computer. I’d just report the problem to the Air Force narcs, and\nlet them handle it.\n\nWhile the hacker stepped through the Air Force computer, Steve White traced\nTymnet’s lines.\n\n“He’s coming through RCA,” Steve said. “TAT-6.”\n\n“Huh? What’s that mean in English?”\n\n“Oh, nothing really. RCA is one of the international record carriers, and\ntoday the hacker is coming across the number six transatlantic cable.” Steve\ndealt in worldwide communications like a taxi driver in midtown traffic.\n\n“Why isn’t he on a satellite link?”\n\n“Probably because it’s a Sunday—the cable channels are less crowded.”\n\n“You mean that people prefer cable to satellite links?”\n\n“Sure. Every time you connect through a satellite, there’s a quarter second\ndelay. The undersea cables don’t slow down your messages so much.”\n\n“Who would care?”\n\n“People on the telephone, mostly,” Steve said. “Those delays make for jittery\nconversations. You know, where each person tries to speak at the same time,\nthen they both back off.”\n\n“So if the phone companies try to route over the cables, who wants the\nsatellites?”\n\n“Television networks, mostly. TV signals can’t be squeezed into submarine\ncables, so they grab the satellites. But fiber optics will change everything.”\n\nI’d heard of fiber optics. Running communications signals over strands of\nglass, instead of copper wires. But who was running fiber-optic cables under\nthe ocean?\n\n“Everyone wants to,” Steve explained. “There’s a limited number of satellite\nchannels available—you can crowd only so many satellites over Equador. And the\nsatellite channels aren’t private—anyone can listen in. Satellites may be fine\nfor television, but cable’s the way to go for data.”\n\nMy conversations with Steve White began with tracing the hacker, but\ninevitably slipped into other topics. A short talk with Steve usually became a\ntutorial on communications theory.\n\nRealizing that the hacker was still connected, I asked Steve for the details\nof the trace.\n\n“Oh yeah. I checked with Wolfgang Hoffman at the Bundespost. Your visitor is\ncoming from Karlsruhe today. The University of Karlsruhe.”\n\n“Where’s that?”\n\n“I don’t know, but I’d guess the Ruhr valley. Isn’t that along the Rhine?”\n\nThe hacker was still chipping away at the Air Force computer, but after he\nleft, I jogged over to the library. Yes, there’s Karlsruhe. Three hundred\nmiles south of Hannover.\n\nDraped across the floor of the Atlantic Ocean, the TAT-6 cable ties together\nEurope and America. The western end of the connection came through Tymnet,\nthen Lawrence Berkeley Laboratory, across the Milnet, and ended at the Air\nForce Systems Command Space Division.\n\nSomewhere in Germany, the hacker tickled the eastern end of the connection,\nunaware that we were zeroing in on him.\n\nThree different places in Germany. My hacker was moving around. Or maybe he\nwas staying in one place, playing a shell game with the telephone system.\nPerhaps he really was a student, visiting different campuses and showing off\nto his friends. Was I certain that there was only one hacker—or was I watching\nseveral people?\n\nThe solution depended on completing a trace. Not just to a country or a city,\nbut all the way to an individual. But how do I get a phone trace from six\nthousand miles away?\n\nThe search warrant! Had the FBI pushed the warrant into Germany? For that\nmatter, had they really opened an investigation? Time to call Mike Gibbons of\nthe FBI.\n\n“I hear you’ve been pulled off the computer case,” I told Mike. “Is there\nanything I can do?”\n\n“Not to worry,” Mike said. “Let me handle it. Just lay low, and we’ll make\nprogress.”\n\n“Well, is there an open investigation or not?”\n\n“Don’t ask me, because I can’t say. Just be patient, and we’ll work it out.”\n\nMike slipped out of every question. Maybe I could pry some information from\nhim by telling him about the Air Force computer.\n\n“Hey, the hacker broke into an Air Force computer yesterday.”\n\n“Where?”\n\n“Oh, somewhere in Southern California.” I didn’t say that it was at 2400 East\nEl Segundo Boulevard, across from the Los Angeles Airport. He wouldn’t tell me\nwhat was happening, so I’d play coy with him.\n\n“Who runs it?”\n\n“Someone in the Air Force. Sounds like some Buck Rogers place. I dunno.”\n\n“You’d better call the Air Force OSI. They’ll know what to do.”\n\n“Won’t the FBI investigate?”\n\n“I told you. We are investigating. We are making progress. It’s just not for\nyour ears to hear.” So much for extracting information from the FBI.\n\nThe Air Force narcs were a bit more expressive. Jim Christy of the Air Force\nOSI put it succinctly.\n\n“Systems Command? Son of a bitch.”\n\n“Yeah. The guy became system manager there.”\n\n“Systems manager at Systems Command. Amusing. Did he get anything classified?”\n\n“Not that I can tell. He really didn’t get that much, just the names of a few\nthousand files.”\n\n“Damn. We told them. Twice.” I wasn’t sure if I should be listening.\n\n“If it makes any difference, he’s not going to get back on their system. He’s\nlocked himself out.” I told him about the password expiration.\n\n“That’s fine for the Systems Command,” Jim said, “but how many other computers\nare just as wide open? If the Space Division screws up like that, even after\nwe warn them, then how are we ever going to get the word out?”\n\n“You warned them?”\n\n“Damn straight. We’ve been telling systems operators for six months to change\nall their passwords. Don’t you think we’ve been listening to you?”\n\nSmoley hokes! They’d actually heard my message, and were spreading the word.\nIt’s the first time that anyone had even hinted that I’d had any effect.\n\nWell, the Air Force OSI in Washington sent the message out to their agent at\nVandenberg Air Force Base. He, in turn, was to knock heads at the Space\nDivision. They’d make sure that the hole stayed plugged up.\n\nTwo days later, Dave Cleveland and I were sitting in front of his terminal,\nplaying with some broken software. My beeper went off and without saying a\nword, Dave switched the terminal over to the Unix computer. Sventek was just\nlogging on. We looked at the screen, then nodded to each other. I jogged over\nto the switchyard to watch the action live.\n\nThe hacker didn’t bother with my computers, but went straight over the Milnet\nto the Air Force Space Division. I watched him start to log in there as Field\nService, thinking how he would just be booted off again.\n\nBut no! He was welcomed back into their system. Someone at the Air Force base\nhad re-enabled the Field Service account with the same old password. The\nservice technician may have noticed that the account had expired, and asked\nthe system manager to reset the password.\n\nStupid. They’d unlocked the doors and left the keys in the ignition.\n\nThe hacker didn’t waste a minute. He went straight to the authorization\nsoftware and added a new account. No, not a new account. He searched for an\nold, unused account and modified it. Some Air Force officer, Colonel Abrens,\nhad an account, but hadn’t been around this computer in a year.\n\nThe hacker slightly modified Colonel Abrens’ account, giving it system\nprivileges and a new password: AFHACK.\n\nAFHACK—what arrogance. He’s thumbing his nose at the United States Air Force.\n\nFrom now on, he didn’t need the Field Service account. Disguised as an officer\nin the Air Force, he had unlimited access to the Space Division’s computer.\n\nHeavy duty. This guy wasn’t tinkering around. Air Force OSI had left for the\nday. What should I do? Leaving the hacker connected would leak sensitive\ninformation from the Air Force. But disconnecting him would only cause him to\nuse a different route, bypassing my lab’s monitors.\n\nWe’d have to chop him off at the Space Command.\n\nBut first, I wanted him traced. A call to Steve White started things rolling.\nWithin five minutes, he’d traced the connection to Hannover, and called the\nBundespost.\n\nA few minutes of silence. “Cliff, does the connection look like it will be a\nlong one?”\n\n“I can’t tell, but I think so.”\n\n“OK.” Steve was on another telephone; I could only hear an occasional shout.\n\nIn a minute, Steve returned to my line. “Wolfgang is tracing the call in\nHannover. It’s a local call. They’re going to try to trace it all the way.”\n\nHere’s news! A local call in Hannover meant that the hacker’s somewhere in\nHannover.\n\nUnless there’s a computer in Hannover doing his dirty work.\n\nSteve shouted instructions from Wolfgang: “Whatever you do, don’t disconnect\nthe hacker. Keep him on the line if you can!”\n\nBut he’s rifling files at the Air Force base. It was like letting a burglar\nrob your home while you watched. Should I boot him out or let the trace go\nahead? I couldn’t decide.\n\nWell, I ought to call some authority. How about Mike Gibbons of the FBI? He’s\nnot around.\n\nHey—the National Computer Security Center might be a good place to call. Zeke\nHanson will know what to do.\n\nNo luck. Zeke wasn’t in and the voice at the far end of the line explained,\n“I’d like to help you, but we design secure computers. We don’t get involved\nin the operational aspects.” I’d heard that before, thank you.\n\nWell, there wasn’t anyone else to tell but the Air Force. I hooked into the\nMilnet Network Information Center and looked up their phone number. Naturally,\nthey’d changed their phone number. They even listed the wrong area code. By\nthe time I reached the right person, the hacker had thoroughly penetrated\ntheir computer.\n\n“Hi, I’m looking for the system manager of the Space Command’s Vax computer.”\n\n“This is Sergeant Thomas. I’m the manager.”\n\n“Uh, I don’t know how to explain this to you, but there’s a hacker in your\ncomputer.” (Meanwhile, I’m thinking, “He won’t believe me and will want to\nknow who I am.”)\n\n“Huh? Who are you?” Even over the phone, I could feel him giving me the hairy\neyeball.\n\n“I’m an astronomer at Lawrence Berkeley Laboratory.” (First mistake, I think,\nnobody’s gonna believe that.)\n\n“How do you know there’s a hacker?”\n\n“I’m watching him break into your computer over the Milnet.”\n\n“You expect me to believe you?”\n\n“Just look at your system. List out your users.”\n\n“OK.” I hear typing in the background.\n\n“There’s nothing strange here. We’ve got fifty-seven people logged in, and the\nsystem’s behaving normally.”\n\n“Notice anyone new?” I asked.\n\n“Let’s see … No, everything’s normal.” Should I tell him or just beat around\nthe bush?\n\n“Do you know someone named Abrens?”\n\n“Yeah. Colonel Abrens. He’s logged in right now. Hey, what are you getting\nat?”\n\n“Are you sure that Abrens is legit?”\n\n“Hell, yes. He’s a colonel. You don’t mess with the brass.”\n\nI was getting nowhere by asking leading questions. Might as well tell him.\n“Well, a hacker’s stolen Abren’s account. He’s logged on right now, and he’s\ndumping your files.”\n\n“How do you know?”\n\n“I watched him. I’ve got a printout,” I said. “He came in on the Field Service\naccount, then reset Abrens’ password. Right now, he’s got system privileges.”\n\n“That’s impossible. Just yesterday, I reset the password to the Field Service\naccount. It had expired.”\n\n“Yes, I know. You set the password to ‘service.’ The same as it’s been for the\npast year. Hackers know this.”\n\n“Well, I’ll be damned. Hold on.” Over the phone, I hear Sergeant Thomas call\nsomeone over. A couple minutes later, he’s back on the line.\n\n“What do you want us to do?” he asked. “I can shut off my computer right now.”\n\n“No, hold off for a bit,” I said. “We’re tracing the line right now, and we’re\nclosing in on the hacker.” This was no fib: Steve White had just relayed\nWolfgang Hoffman’s request to keep the hacker on the line as long as possible.\nI didn’t want Sergeant Thomas to cut the line before the trace was complete.\n\n“OK, but we’ll call our commanding officer. He’ll make the final decision.” I\ncould hardly blame them. A total stranger calls from Berkeley and tells them\nthat someone’s breaking into their system.\n\nBetween these phone calls, I watched the printer punch out the hacker’s every\ncommand. Today, he didn’t list the names of every file. Quite the contrary: he\nlisted individual files. He already knew the names of the files he was looking\nfor; he didn’t need to scramble around searching for their names.\n\nAah. This was an important clue. Three days ago, the hacker listed the names\nof a thousand files. Today, he went straight to those files that interested\nhim. He must have printed out his entire session. Otherwise, he would have\nforgotten the names of the files.\n\nSo the hacker’s printing out everything he gets. I already knew that he kept a\ndetailed notebook—otherwise, he’d have forgotten some of the seeds that he’d\nplanted months ago. I remembered my meeting with the CIA: Teejay had wondered\nif the hacker kept recordings of his sessions. Now I knew.\n\nAt the far end of the connection, somewhere in Germany, sat a determined and\nmethodical spy. Every printout that came across my monitor was duplicated in\nhis lair.\n\nWhich files did he list? He skipped over all the programs and ignored system\nmanagement guidelines. Instead, he went for operational plans. Documents\ndescribing Air Force payloads for the space shuttle. Test results from\nsatellite detection systems. SDI research proposals. A description of an\nastronaut-operated camera system.\n\nNone of this information had the comment, “classified” on it. It wasn’t\nsecret, top secret, or even confidential. At least, none of the files carried\nthose labels.\n\nNow, no military computer on the Milnet is allowed to carry classified\ninformation. There’s another computer network, completely separate, that\nhandles classified data. So in one sense, the Systems Command’s Space Division\nhad nothing to lose: its computer is unclassified.\n\nBut there’s a deeper problem. Individually, public documents don’t contain\nclassified information. But once you gather many documents together, they may\nreveal secrets. An order from an aircraft manufacturer for a load of titanium\nsure isn’t secret. Nor is the fact that they’re building a new bomber. But\ntaken together, there’s a strong indicator that Boeing’s new bomber is made of\ntitanium, and therefore must fly at supersonic speeds (since ordinary aluminum\ncan’t resist high temperatures).\n\nIn the past, to pull together information from diverse sources you’d spend\nweeks in a library. Now, with computers and networks, you can match up data\nsets in minutes—look at how I manipulated Mitre’s long-distance phone bills to\nfind where the hacker had visited. By analyzing public data with the help of\ncomputers, people can uncover secrets without ever seeing a classified\ndatabase.\n\nBack in 1985 Vice Admiral John Poindexter worried about just this problem. He\ntried to create a new classification of information, “Sensitive but\nunclassified.” Such information fit below the usual levels of Top Secret,\nSecret, and Confidential; but access to it was to be denied to certain\nforeigners.\n\nPoindexter clumsily tried to apply this to academic research—naturally, the\nuniversities refused, and the idea died. Now, standing in front of my monitor,\nwatching the hacker prowl through the Space Command’s system, I realized his\nmeaning. Air Force SDI projects might not be top secret, but they sure were\nsensitive.\n\nWhat? Me agreeing with Vice Admiral Poindexter? The guy that shipped arms to\nIran? How could I have any common ground with Ollie North’s boss? Yet dancing\nacross my screen was just what he’d described: sensitive but unclassified\ndata.\n\nTymnet came back on the line. “I’m sorry, Cliff, but the trace in Germany is\nstymied.”\n\n“Can’t they trace the call?” I asked, unsure of who I meant by “they.”\n\n“Well, the hacker’s line comes from Hannover, all right,” Steve replied. “But\nHannover’s phone lines connect through mechanical switches—noisy, complicated\nwidgets—and these can only be traced by people. You can’t trace the call with\na computer.”\n\nI started to understand. “You mean that someone has to be in the telephone\nexchange to trace the call?”\n\n“That’s it. And since it’s after 10 P.M. in Hannover, there’s nobody around.”\n\n“How long will it take to get someone into the exchange?”\n\n“About three hours.”\n\nTo trace the line, a Bundespost telephone technician would have to visit the\ntelephone exchange and follow the switches and wires. For all I knew, he might\neven have to climb telephone poles. Bad news.\n\nMeanwhile, the hacker was slithering through the Air Force computer. Sergeant\nThomas was still on hold—he’d probably called all sorts of Air Force brass by\nnow.\n\nI popped my phone to the Air Force line. “Well, we can’t trace things any\nfurther today.”\n\n“Gotcha. We’ll cut off the hacker right now.”\n\n“Wait for a second,” I said. “Don’t make it look like you’re just booting him\noff your system. Instead, find a way that he won’t suspect that you’re on to\nhim.”\n\n“Yeah. We figured out a plan,” Sergeant Thomas replied. “We’ll broadcast an\nannouncement to everyone on the system that our computer’s malfunctioning, and\nwill have to be serviced.”\n\nPerfect. The hacker will think the system’s going down for repairs.\n\nI waited for a minute and in the middle of a page of SDI proposals, this\nmessage interrupted the hacker’s screen:\n\n**System going down for maintenance, back up in 2 hours**.\n\nHe saw it right away. The hacker immediately logged off and disappeared into\nthe void.\n\n\n![](images/Stol_9780307819420_epub_043_r1.jpg) Having broken into another\nmilitary base, the hacker wasn’t about to give up. He returned to our lab,\ntrying over and over to get back into the Air Force Systems Command. But none\nof his magic charms worked. He couldn’t get back into their computers.\n\nThey were clever about how they’d locked out the hacker. They didn’t just post\na notice saying, “Hackers stay out”. Instead, they set the hacker’s stolen\naccount so that it almost worked. When the hacker logged into his stolen\naccount, Abrens, the Air Force computer appeared to accept it, but then barfed\nback an error message—as if the hacker had set up his account incorrectly.\n\nI wondered if the hacker realized that he was under my thumb. Every time he\nsucceeded in breaking into a computer, he was detected and booted out.\n\nFrom his viewpoint, everyone except us detected him. In reality, almost nobody\ndetected him.\n\nExcept us.\n\nHe couldn’t know that he was caged in. My alarms, monitors, and electronic\ntripwires were invisible to him. Tymnet’s traces—through satellites and under\nthe ocean—were totally silent. And the Bundespost was now on his scent.\n\nWolfgang’s latest message said that he was arranging to keep a technician at\nthe Hannover telephone exchange until midnight every night. This was\nexpensive, so he needed to coordinate this with us. More important, the\nGermans had still not heard from the FBI.\n\nTime to call Mike Gibbons. “The Germans haven’t received anything from the\nFBI,” I said. “Any idea why?”\n\n“We’re having, er, internal problems here,” Mike replied. “You don’t want to\nknow.”\n\nI did want to know, but there was no use asking. Mike wouldn’t say a thing.\n\n“What should I tell the Bundespost?” I asked. “They’re getting antsy for some\nkind of official notification.”\n\n“Tell them that the FBI’s Legal Attaché in Bonn is handling everything. The\npaperwork will come along.”\n\n“That’s what you said two weeks ago.”\n\n“And that’s what I’m saying now.”\n\nZip. I passed the message back to Steve at Tymnet, who forwarded it to\nWolfgang. The bureaucrats might not be able to communicate with each other,\nbut the technicians sure did.\n\nOur complaints to the FBI should have been filtered through their office, sent\nto the American Legal Attaché in Bonn, then passed to the German FBI, the\nBundeskriminalamt. The BKA probably inspires the same image of truth and\njustice in Germany as the FBI does in America.\n\nBut someone was plugging up the communications downstream of Mike Gibbons.\nAbout all I could do was keep pestering Mike, and stay in close touch with\nTymnet and the Bundespost. Sooner or later, the FBI would reach out to the\nBKA, and the warrants would appear.\n\nMeanwhile, my astronomer buddies needed help. I spent the day trying to\nunderstand the optics of the Keck Observatory’s telescope. Jerry Nelson needed\nmy programs to predict the telescope’s performance; I hadn’t made a whit of\nprogress since I’d started chasing the hacker.\n\nThe other systems programmers were on my case, too. Crusty Wayne Graves leaned\non me to build some disk driver software. (“Screw the hacker. Write some code,\nalready.”) And Dave Cleveland gently reminded me he needed to hookup ten new\ndesktop computers to our lab-wide network.\n\nI told each of them that the hacker would be gone “RSN.” The ubiquitous\nstatement of software developers everywhere. Real Soon Now.\n\nOn my way over to the astronomy group, I ducked into the switchyard for a\nmoment—just long enough to check my monitors. They showed someone working on\nthe Bevatron computer, manipulating the password file.\n\nBizarre. The Bevatron’s one of the lab’s particle accelerators, and their\nprogrammers all worked at our lab. Only a system manager could manipulate the\npassword file. I stood around, watching. Someone was adding several new\naccounts.\n\nWell, there’s one way to find out if this is legit. Call the Bevatron folks.\nChuck McParland answered. “No, I’m the system manager. Ain’t nobody else\nlicensed.”\n\n“Uh, oh. Then you’ve got a problem. Someone’s playing God on your computer.”\n\nChuck typed a few commands and came back to the phone.\n\n“Son of a bitch.”\n\nChuck’s Bevatron particle accelerator used magnets the size of houses to shoot\nfragments of atoms into thin targets. In the sixties, its ammunition was\nprotons. Now, fed from a second accelerator, it zipped heavy ions up to nearly\nthe speed of light.\n\nAfter smashing these atomic particles into thin foils, physicists sift through\nthe debris, looking for fragments which may be the fundamental building blocks\nof the universe. Physicists waited months for time on the beamlines; more\nimportant, cancer patients waited as well.\n\nThe Bevatron can accelerate helium ions to a fraction of the speed of light,\nwhere they’ll acquire about 160 million electron volts of energy. At this\nspeed, they travel a few inches and then dump most of their energy.\n\nIf you position a cancer tumor at just the right distance beyond this\naccelerator, most of the particles’ energy goes into the tumor. The cancer\ncells absorb this energy, and the tumor’s destroyed without affecting the rest\nof the person’s body. Unlike X rays, which irradiate everything in their path,\nthe Bevatron particles deposit the bulk of their energy at one location. This\nworks especially well on brain tumors, which are often surgically inoperable.\n\nChuck’s Bevatron computers calculate that “right distance.” They control the\naccelerator too, so that the correct energy is used.\n\nGet either of these wrong, and you’ll kill the wrong cells.\n\nEvery few seconds, a burst of ions spills out of the beamline. By flipping\nmagnets at the right times, Chuck’s computers send these to either a physics\nexperiment or a cancer patient. A bug in the program is bad news for both.\n\nThe hacker wasn’t just poking around a computer. He was playing with someone’s\nbrain stem.\n\nDid he know? I doubt it. How could he? To him, the Bevatron’s computer was\njust another plaything—a system to exploit. Its programs aren’t labeled,\n“Danger—medical computer. Do not tamper.”\n\nHe wasn’t innocently looking for information. Having found a way to become\nsystem manager, he was fooling with the operating system itself.\n\nOur operating systems are delicate creations. They control how the computer\nbehaves, how their programs will respond. System managers delicately tune\ntheir operating systems, trying to squeeze every bit of performance from the\ncomputer. Is the program too slow because it’s competing with other tasks? Fix\nit by changing the operating system’s scheduler. Or maybe there’s not enough\nroom for twelve programs at once. Then alter the way the operating system\nallocates memory. Screw up, though, and the computer won’t work.\n\nThis hacker didn’t care if he wrecked someone else’s operating system. He just\nwanted to introduce a security hole so that he could reenter whenever he\nwished. Did he know that he might kill someone?\n\nChuck nailed his system shut by changing all the passwords. Another door\nslammed in the hacker’s face.\n\nBut another worry. I’d been chasing someone around the world, yet I couldn’t\nprevent him from breaking into any computer he wished. My only defense was to\nwatch him and warn people who were attacked.\n\nSure, I could still boot him out of my computer, and wash my hands of the\nwhole mess. My earlier fears seemed unjustified: I now knew what security\nholes he exploited, and it didn’t look like he’d planted any time bombs or\nviruses in my computer.\n\nKicking him off my machine would only black out the window that I used to\nwatch him. He’d continue to attack other computers, using different networks.\nI didn’t have much choice but to let this SOB wander around until I could\ncatch him.\n\nBut try explaining that to the FBI. On Thursday, January 8, my local FBI agent\nFred Wyniken stopped over.\n\n“I’m here only as a representative of the Alexandria, Virginia office,” Fred\nsaid.\n\n“I don’t understand,” I said. “Why isn’t the case being handled from the\nOakland office?”\n\n“The FBI’s field offices are pretty much independent of one another,” Fred\nreplied. “What one office thinks is important, another may well ignore.” I\ncould sense in which category he thought my case belonged.\n\nFred explained that he didn’t know the likelihood of prosecution because he\nwasn’t handling the case. “But I’d say it’s pretty slim. You can’t show any\nmonetary loss. There’s no obviously classified data. And your hacker isn’t in\nthe States.”\n\n“So that’s why my local office isn’t handling this case?”\n\n“Remember, Cliff, that the FBI only works cases that the Department of Justice\nwill prosecute. Since no classified information’s been compromised, there’s no\nreason to commit the resources that it’ll take to resolve this.”\n\n“But unless you take action, this hacker will keep hammering on our computers\nuntil he pretty much owns them.”\n\n“Look. Every month we get a half-dozen calls saying, ‘Help! Someone’s breaking\ninto my computer.’ Ninety-five percent of them have no records, no audit\ntrails, and no accounting data.”\n\n“Hold on there. I’ve got records and audit trails. Hell, I’ve got every\nkeystroke that this bastard’s typed.”\n\n“I’m getting to that. In a few cases, and yours is one of them, there’s good\ndocumentation. But that’s not enough. The damage must be sufficient to justify\nour efforts. How much have you lost? Seventy-five cents?”\n\nHere we go again. Yes, our computing costs were small change. But I sensed a\nlarger issue, perhaps one of national importance. My local FBI agent saw only\na six-bit accounting error. No wonder I couldn’t get any interest—let alone\nsupport—from him.\n\nHow much longer before someone noticed? Maybe if a classified military\ncomputer were hit? Or a high-tech medical experiment damaged? What if a\npatient in a hospital were injured?\n\nWell, I gave him printouts from the past couple of weeks (after first signing\nthe back of each copy—something to do with “rules of evidence”) and a floppy\ndisk with the Mitre telephone logs. He’d send it all to Mike Gibbons at the\nAlexandria office. Maybe Mike would find them useful in convincing the FBI to\ntalk to the German BKA.\n\nDiscouraging. The German telephone technicians still didn’t have their\nwarrants, the FBI wasn’t responding, and my boss sent me a curt note asking\nwhen I’d write some software to link up a new printer.\n\nMartha wasn’t happy either. The hacker wasn’t just breaking into computers. By\nway of the beeper, he was invading our home.\n\n“Isn’t the FBI or the CIA doing something,” she asked, “now that there’s\nforeigners and spies? I mean, aren’t they the G-men—Truth, Justice, and the\nAmerican Way?”\n\n“It’s the same old bailiwick problem. The CIA says that the FBI should work\nit. The FBI doesn’t want to touch it.”\n\n“Is the Air Force Office of Something or Another doing anything?”\n\n“Same story. The problem starts in Germany, and someone’s got to call Germany\nto solve it. The Air Force Office of Special Investigations can only bang on\nthe FBI’s door.”\n\n“Then why not punt?” Martha suggested. “Brick up your computer and let the\nhacker roam around theirs. Nobody appointed you official guardian of America’s\ncomputers.”\n\n“Because I want to know what happened. Who’s behind it. What they’re searching\nfor. Research.” Luis Alvarez’s words still rang, months afterward.\n\n“Then think of a way to solve your problem without the FBI. If they won’t get\nthe Germans to trace a call, then find some other way.”\n\n“How? I can’t call the German Bundespost and say, ‘Trace this call!’ ”\n\n“Why not?”\n\n“For one, I wouldn’t know who to call. And they wouldn’t believe me if I did.”\n\n“Then find some other way to home in on the hacker.”\n\n“Yeah, right. Just ask him to tell me his address.”\n\n“Don’t laugh. It might work.”\n\n\n![](images/Stol_9780307819420_epub_044_r1.jpg) “The FBI’s tossing in the\ntowel.”\n\nThis was the message Ann Funk of the Air Force Office of Special\nInvestigations left for me. The day before, I’d called her and she said that\nher group was waiting for the FBI to take action. Now this greeting.\n\nI tried returning Ann’s call, but she’d already left Bolling Air Force Base.\nNot much else to do but call the FBI.\n\nThe raspy voice at the Alexandria FBI office didn’t want to waste time. “Agent\nGibbons is not available right now, but I have a message for you,” the guy\nsaid officiously. “Your case is closed and you are to shut things off.”\n\n“Huh? Who said that?”\n\n“I’m sorry, but that’s the whole message. Agent Gibbons will be back next\nweek.”\n\n“Did Mike say anything more?” After dozens of conversations, wouldn’t he at\nleast tell me in person?\n\n“I told you, that is the entire message.”\n\nGreat. Pester the FBI for five months. Trace a connection around the world.\nProve that the hacker’s breaking into military computers. Just when I most\nneeded the FBI’s help … poof.\n\nAnn Funk called back an hour later. “I just heard that the FBI decided there’s\ninsufficient grounds to continue their investigation.”\n\n“Do the break-ins at the Air Force Space Command make any difference?” I\nasked.\n\n“That’s the Systems Command, Space Division, Cliff. Get it right, or you’ll\nconfuse us.” But Space Command sounds neater. Who’d want to command a system?\n\n“OK, but doesn’t the FBI care about them?”\n\nAnn sighed. “According to the FBI, there’s no evidence of actual espionage.”\n\n“Did Mike Gibbons say that?”\n\n“I doubt it,” she said. “I got the word from a duty officer who said that\nMike’s been taken off the case and can’t talk about it.”\n\n“So who decided?” Mike was the only computer literate FBI agent I’d spoken to.\n\n“Probably some middle management at the FBI,” Ann said. “They can catch\nkidnappers easier than computer hackers.”\n\n“So how do you feel?” I asked her. “Should we close up shop or try to catch\nthe bastard?”\n\n“The FBI says to shut down the hacker’s access ports.”\n\n“That’s not what I asked.”\n\n“… and to change all your passwords …”\n\n“I know what the FBI says. What does the Air Force say?”\n\n“Uh, I don’t know. We’ll talk later on and call you back.”\n\n“Well, unless someone tells us to continue, we’ll close up shop and the hacker\ncan play in your computers all he wants. For five months we’ve been chasing\nthis spy and not one government agency has contributed a dime.” I hung up\nangrily.\n\nA few minutes later, my local FBI agent called. Fred Wyniken left no doubt\nabout their decision. In an official tone of voice, he informed me that the\nFBI felt there was no way to extradite this hacker because of unclassified\nhacking.\n\n“Cliff, if you can show that some classified material has been compromised, or\nthat he’s done significant damage to systems, then the FBI will step in. Until\nthat happens, we’re not going to move.”\n\n“What do you consider damage? If someone rifles my desk drawers and duplicates\nthe plans for a new integrated circuit, is that damage? Who do I turn to?”\n\nFred wouldn’t answer. “If you insist on pursuing this case, the FBI can assist\nunder the domestic police cooperation act. Your lab should contact the\nBerkeley District Attorney and open an investigation. If your local DA will\nextradite the hacker, then the FBI will assist in handling the proper\npaperwork.”\n\n“Huh? After five months you’re bouncing me back to my local District\nAttorney?” I couldn’t believe what I was hearing.\n\n“If you choose to go in that way, the FBI will serve as a conduit between your\nlocal police and the German authorities. The LBL police would be the center of\nthe investigation, and prosecution would be in Berkeley.”\n\n“Fred, you can’t be saying that. This guy’s broken into thirty computers\naround the country, and you’re telling me that it’s a local, Berkeley\nproblem?”\n\n“I’m telling you this much,” my local G-man continued. “The FBI has decided to\ndrop the case. If you want to continue, you’d better handle it though your\nlocal police force.”\n\nNot an hour later, Steve White called from Tymnet. He’d just received the\nfollowing electronic message from the German Bundespost:\n\n“It is most urgent that the U.S. authorities contact the German prosecutor or\nelse the Bundespost will no longer cooperate. We cannot remain hanging,\nwithout any official notification. We will not trace phone lines without the\nproper warrants. You must arrange for the FBI to contact the German BKA\nimmediately.”\n\nOh hell. Spend months building cooperation between agencies, and the FBI backs\nout. Just when we need them.\n\nWell, I didn’t have much of a choice. We could do what we were told and close\nup, toss away five months of tracking, or we could stay open and risk censure\nby the FBI.\n\nClosing down would give the hacker freedom to roam our networks without anyone\nwatching him. Staying open wouldn’t lead us to the hacker, since the\nBundespost wouldn’t trace unless the FBI gave the go-ahead. Either way, the\nhacker wins.\n\nTime to call on my boss. Roy Kerth believed the news right away. “I never did\ntrust the FBI. We’ve practically solved the case for them, yet they won’t\ninvestigate.”\n\n“So what do we do?”\n\n“We don’t work for the FBI. They can’t tell us what to do. We’ll stay open\nuntil the Department of Energy tells us to shut down.”\n\n“Should I call DOE?”\n\n“Leave that to me. We’ve put in a hell of a lot of work, and they’re going to\nhear about it.” Roy mumbled a bit—it didn’t sound like praise for the FBI—then\nstood up and said firmly, “We’ll stay open, all right.”\n\nBut monitoring the hacker in Berkeley wasn’t tracing him in Germany. We needed\nthe FBI, even if they didn’t need us.\n\nWhat’ll the CIA say?\n\n“Hi, it’s Cliff. Our friends at the, uh, ‘F’ entity have lost interest.”\n\n“Who’d ya talk to?” Teejay asked.\n\n“The entity’s local representative and an officer from their East Coast\noffice.” I was learning spookspeak.\n\n“OK. I’ll check into it. Hold still till you hear from me.”\n\nTwo hours later, Teejay called back. “The word is close up shop. Your contact,\nMike, is off the case. His entity is off chasing pickpockets.”\n\n“So what do we do?”\n\n“Just sit still,” the spook said. “We can’t get involved—FCI belongs to Mike’s\nentity. But someone may lean on Mike’s entity. Just wait.”\n\nFCI? Federal Cat Inspector? Federation of Carnivorous Iguanas? I couldn’t\nfigure it out. “Uh, Teejay, what’s FCI?”\n\n“Shhh. Don’t ask questions. Wheels are turning in places you don’t know\nabout.”\n\nI called Maggie Morley—our scrabble whiz and all-knowing librarian. Took her\nthree minutes to find the acronym. “FCI means Foreign Counter-Intelligence,”\nshe said. “Met any spies lately?”\n\nSo the CIA doesn’t handle counterintelligence. The FBI doesn’t want to waste\ntime on this one. And the Deutsche Bundespost wants an official notice from\nthe United States. Whee.\n\nOne other agency might be able to help. Zeke Hanson at the National Security\nAgency was sympathetic—he’d watched every step of progress we’d made, and knew\nhow much we needed the FBI’s support. Could he help out?\n\n“I’d love to help, Cliff, but we’re not able to. The NSA listens rather than\ntalks.”\n\n“But isn’t this what the National Computer Security Center is for? To solve\ncomputer security problems?”\n\n“You know the answer. No and no. We’re trying to secure computers, not catch\nhackers.”\n\n“Can’t you call the FBI and at least encourage them?”\n\n“I’ll spread the word, but don’t hold your breath.”\n\nAt best, NSA’s computer security center tried to set standards and encourage\ncomputer security. They had no interest in serving as a clearing-house for\nproblems like mine. And they certainly couldn’t get a search warrant. NSA had\nno connections with the FBI.\n\nTeejay called back in a couple of days. “We made a grandstand play,” the CIA\nagent said. “Mike’s entity is back on track. Tell me if they give you any more\ntrouble.”\n\n“What’d you do?”\n\n“Oh, talked to a couple friends. Nothing much.” What kind of friends does this\nguy have? To turn the FBI around in two days … who’s he talking to?\n\nIt didn’t take long before Mike Gibbons of the FBI called. He explained German\nlaw to me: hacking into a computer wasn’t a big deal there. As long as you\ndidn’t destroy the computer, breaking into a system wasn’t much worse than\ndouble parking.\n\nThis didn’t make sense to me. If German law was this lenient, why did the\nDeutsche Bundespost take the case so seriously?\n\nMike understood my concerns, and at least agreed to keep working on the case.\n“You should know, though, that last year a German hacker was caught in a\nColorado computer, but couldn’t be prosecuted.”\n\nWould the FBI’s Legal Attache get off his butt?\n\n“I’m working on that,” Mike said. “Tell your friends at the Bundespost that\nthey’ll hear from us soon.”\n\nThat evening, we had another chance to catch the guy. While Martha and I\nwaited in line at the grocery store, my beeper chimed in. I dropped my copy of\nthe _National Enquirer_ (“Alien Visitors from Mars!”) and dashed to the pay\nphone, dialing Steve White.\n\n“Our friend’s on the line,” I told him.\n\n“OK. I’ll call Germany.”\n\nQuick conversation and a quick trace. The hacker was on for only five minutes,\nyet Steve tracked him into DNIC #2624-4511-049136. A public access dialup line\nin Hannover, Germany.\n\nAfterwards, Steve White filled me in on the details. Wolfgang Hoffman,\nawakened at 3 A.M., started tracing that line from Frankfurt. But the\ntelephone engineer assigned to the Hannover exchange had already gone home for\nthe night. Close, but no cigar.\n\nWolfgang had one question for us. The University of Bremen was willing to\ncooperate in catching this guy, but who’s going to pay? The hacker was wasting\nthe University’s money—hundreds of dollars a day. Would we be willing to pay\nfor the hacker?\n\nImpossible. My lab’s paper-clip budget was squeezed—no way would they spring\nfor this. I passed the message back that I’d ask around.\n\nSteve pointed out that someone would have to pay, or the Bundespost will just\nchop the hacker’s access. Now that they knew how he’s ripping off the Datex\nnetwork, the Germans wanted to plug the holes.\n\nYet more news arrived from Germany. A couple of nights ago, the hacker\nconnected into Berkeley for two minutes. Long enough to track him to the\nUniversity of Bremen. Bremen, in turn, tracked him back to Hannover. It seemed\nlike the hacker wasn’t just breaking into our Berkeley laboratory, but snuck\ninto European networks as well.\n\n“Since they had the chance, why didn’t the Germans trace him within Hannover?”\n\nSteve explained the problems in Hannover’s telephone system. “American\ntelephones are computer controlled, so it’s pretty easy to trace them. But\nthey need someone at the exchange to trace the call in Hannover.”\n\n“So we can’t trace him unless the hacker calls during the day or evening?”\n\n“Worse than that. It’ll take an hour or two to make the trace once it’s\nstarted.”\n\n“An hour or two? Are you kidding? Why it takes you ten seconds to trace\nTymnet’s lines from California across a satellite and into Europe. Why can’t\nthey do the same?”\n\n“They would if they could. The hacker’s telephone exchange just isn’t\ncomputerized. So it’ll take a while for the technician to trace it.”\n\nLately, the hacker had been showing up for five minutes at a time. Long enough\nto wake me up, but hardly enough for a two-hour trace. How could I keep him on\nfor a couple of hours?\n\nThe Bundespost couldn’t keep technicians on call forever. In fact, they could\nhardly afford to keep them around for more than a few days. We had one week to\ncomplete the trace. After next Saturday evening, the telephone technicians\nwould call it quits.\n\nI couldn’t make the hacker show up at a convenient time. And I couldn’t\ncontrol how long he hung around. He came and went as he pleased.\n\n\n![](images/Stol_9780307819420_epub_045_r1.jpg) “Wake up, you sloth,” said\nMartha at the obscenely early hour of nine on a Saturday morning. “Today we\nprepare the ground for our tomato plants.”\n\n“It’s just January,” I protested. “Everything is dormant. Bears are\nhibernating. I am hibernating.” I pulled the covers over my head, only to have\nthem snatched away. “Come on outside,” said Martha, taking a vise-like grip on\nmy wrist.\n\nAt first glance, it seemed that I was right. The garden was dead and brown.\n“Look,” Martha said, kneeling beside a rose bush. She touched the swelling\npink buds. She pointed at the plum tree, and looking more closely, I saw a\nmist of tiny green leaves emerging from the bare branches. Those poor\nCalifornia plants—without a winter to sleep through.\n\nMartha gave me a shovel, and we began the yearly cycle; turning over the soil,\nadding fertilizer, planting tiny tomato seedlings in their furrows. Every year\nwe carefully planted several varieties that took different amounts of time to\nripen, and staggered the planting by several weeks, so we would have a steady\nsupply of tomatoes all summer. And every year, every single tomato ripened on\nthe fifteenth of August.\n\nIt was slow, heavy work because the soil was dense with clay and wet from the\nwinter rains. But we finally got the plot spaded, and, dirty and sweaty,\nstopped to take a shower and have brunch.\n\nIn the shower, I felt revived. Martha sudsed my back while I basked in hot\nwater. Maybe the wholesome rustic life wasn’t so bad after all.\n\nMartha was in the midst of shampooing my hair when the nasty whine of my\nbeeper, buried in a pile of clothing, destroyed our peace. Martha groaned and\nstarted to protest: “Don’t you dare.…”\n\nToo late. I jumped out of the shower and ran to the living room, switched on\nmy Macintosh, and called the lab computer. Sventek.\n\nA second later, I’m talking to Steve White at his home. “He’s here, Steve.”\n\n“OK. I’ll trace him and call Frankfurt.”\n\nA moment later, Steve’s back on the line. “He’s gone. The hacker was here a\nmoment ago, but he’s disconnected already. No use calling Germany now.”\n\nDamn. I stood there in utter frustration; stark naked, wet and shivering,\nstanding in a puddle in our dining room, dripping blobs of shampoo onto my\ncomputer’s keyboard.\n\nClaudia had been practicing Beethoven, but startled by the sight of her\nroommate charging, naked, into the living room, she’d put down her violin and\nstared. Then she laughed and played a few bars of a burlesque tune. I tried to\nrespond with a bump and grind, but was too obsessed with the hacker to pull it\noff.\n\nI wandered sheepishly back into the bathroom. Martha glowered at me, then\nrelented and pulled me into the shower again, under the hot water.\n\n“I’m sorry, sweetheart,” I apologized. “It’s our only chance to nail him, and\nhe wasn’t around long enough to catch.”\n\n“Great,” Martha said. “Long enough to drag you out of the shower, but not\nenough time to find out where he is. Maybe he knows you’re watching him, and\nhe’s purposely trying to frustrate you. Somehow, he telepathically knows when\nyou’re in the shower. Or in bed.”\n\n“I’m sorry, sweetheart.” I was, too.\n\n“Honey, we’ve got to do something about this. We can’t let this guy keep\nyanking us around. And all those spooks in suits you keep talking to—what have\nthey ever done to help? Nothing. We have to take this into our own hands.”\n\nShe was right: I’d spent hours on the phone to the FBI, CIA, NSA, OSI, and the\nDOE. Still others, like the BKA, knew about our problem, yet nobody took the\ninitiative.\n\n“But what can we do without the government’s help?” I asked. “We need search\nwarrants and all that. We need official permission to do phone traces.”\n\n“Yeah, but we don’t need anyone’s permission to put stuff in our own\ncomputer.”\n\nSo what?\n\nUnder the steaming water, Martha turned to me with a sly look.\n\n“Boris? Darlink, I hev a plan …” Martha shaped a goatee and mustache out of\nsoap suds on my face.\n\n“Yes, Natasha?”\n\n“Ees time for ze secret plan 35B.”\n\n“Brilliant, Natasha! Zat will vork perfectly! Ah, darlink … vhat is secret\nplan 35B?”\n\n“Ze Operation Showerhead.”\n\n“Yes?”\n\n“Vell, you see, zee spy from Hannover seeks ze secret information, yes?”\nMartha said. “We give him just vhat he vants—secret military spy secrets. Lots\nof zem. Oodles of secrets.”\n\n“Tell me, Natasha dahlink, zees secrets, vhere shall ve get them from? Ve\ndon’t know any military secrets.”\n\n“Ve make zem up, Boris!”\n\nYow! Martha had come up with the obvious solution to our problem. Give the guy\nwhat he’s looking for. Create some files of phony information, laced with\nbogus secret documents. Leave ’em laying around my computer. The hacker\nstumbles on them, and then spends a couple hours lapping it up, copying it\nall.\n\nElegant.\n\nHow much stuff? As I rinsed Martha’s hair, I calculated: we want him on for\ntwo hours. He’s connected over a 1200-baud line, which means he can read about\none hundred twenty characters a second. In two hours, he could scan about one\nhundred fifty thousand words.\n\n“Oh, Natasha, my charming counter-counter-spy, there’s just vun problem. Where\ndo ve find five hundred pages of fake secrets?”\n\n“Simple, dollink. Ze secrets, ve invent. Ze regular data, ve use vhat’s\nalready lying around.”\n\nAs the hot water ran out, we clambered out of the shower. Martha grinned as\nshe explained further. “We can’t invent that much information overnight. But\nwe can create it as we go along, staying just ahead of him. And we can take\nordinary bureaucratic documents, modify them a bit, and give them secret-\nsounding titles. Real secret documents are probably thick with boring,\nbureaucratic jargon …”\n\n“… So we’ll just take a bunch of those unintelligible Department of Energy\ndirectives that are always littering my desk, and change them to look like\nstate secrets.”\n\nMartha continued. “We’ll have to be careful to keep it bland and bureaucratic.\nIf we head a document with ‘CHECK OUT THIS TOP SECRET ULTRA-CLASSIFIED NEAT\nSTUFF,’ then the hacker’s going to get suspicious. Keep it all low-key.\nForbidden enough to keep him interested, but not an obvious trap.”\n\nI rolled her ideas around my mind and realized how to implement them. “Sure.\nWe invent this secretary, see, who works for people doing this secret project.\nAnd we let the hacker stumble onto her word processing files. Lots of rough\ndrafts, repetitive stuff, and interoffice memos.”\n\nClaudia greeted us in the living room, where she had mopped up the pond I’d\nleft behind. She listened to our plan and suggested a new wrinkle: “You know,\nyou could create a form letter in your computer that invites the hacker to\nwrite in for more information. If the hacker fell for it, he might include his\nreturn address.”\n\n“Right,” said Martha, “a letter promising more information, of course!”\n\nThe three of us sat around the kitchen table with devious grins, eating\nomelets and elaborating on our plan. Claudia described how the form letter\nshould work: “I think it ought to be like a prize in a crackerjack box. Write\nto us, and we’ll send you, uh … a secret decoder ring.”\n\n“But come on,” I said, “there’s no way he’ll be stupid enough to send us his\naddress.” Seeing that I had thrown cold water on my coconspirators, I added\nthat it was worth a try, but the main thing is to give him something that’ll\ntake a couple of hours to chew on.\n\nThen I thought of another problem. “We don’t know enough about military stuff\nto make sensible documents.”\n\n“They don’t have to make sense,” Martha grinned diabolically. “Real military\ndocuments don’t make sense either. They’re full of jargon and double-talk. You\nknow, like ‘the procedure for implementing the highly prioritized\nimplementation procedure is hereinafter described in section two, subparagraph\nthree of the procedural implementation plan.’ Eh, Boris?”\n\nWell, Martha and I biked up to the laboratory and logged onto the LBL\ncomputer. There we shoveled through a mound of real government documents and\ndirectives, which were overflowing with far more turgid bureaucratese than we\ncould ever invent, changing them slightly so that they’d look ‘classified.’\n\nOur documents would describe a new Star Wars project. An outsider reading them\nwould believe that Lawrence Berkeley Laboratory had just landed a fat\ngovernment contract to manage a new computer network. The SDI Network.\n\nThis bogus network apparently linked together scores of classified computers\nand extended to military bases around the world. By reading our files, you’d\nfind lieutenants and colonels, scientists and engineers. Here and there, we\ndropped hints of meetings and classified reports.\n\nAnd we invented Barbara Sherwin, the sweet, bumbling secretary trying to\nfigure out her new word processor and to keep track of the endless stream of\ndocuments produced by our newly invented “Strategic Defense Initiative Network\nOffice.” We named our fictitious secretary after an astronomer, Barbara\nSchaefer, and used the astronomer’s real mailing address. I mentioned to the\nreal Barbara to watch for any strange mail addressed to Barb Sherwin.\n\nOur fake memoranda included budget requests ($50 million for communications\ncosts), purchase orders, and technical descriptions of this network. We\ncribbed most of them from files laying around the computer, changing the\naddresses and a few words here and there.\n\nFor a mailing list, I grabbed a copy of the lab newsletter’s list of names and\naddresses. I just flipped every “Mr.” to “Lieutenant,” every “Mrs.” to\n“Captain,” every “Dr.” to “Colonel,” and every “Professor” to “General,” The\naddresses? Just stir in an occasional “Air Force Base” and “Pentagon.” In half\nan hour, my ersatz mailing list looked like a veritable military Who’s Who.\n\nSome of the documents, however, we fabricated completely: correspondence\nbetween managers and petty bureaucrats. An information packet describing the\ntechnical capabilities of this network. And a form letter saying that the\nrecipient could get more information on the SDI Network by writing to the\nproject office.\n\n“Let’s label the account, the ‘Strategic Information Network Group,’ ” I said.\n“It’s got a great acronym: STING.”\n\n“Naw. He might catch on. Keep it bureaucratic,” Martha said. “Use SDINET.\nIt’ll catch his eye, all right.”\n\nWe put all the files under one account, SDINET, and made certain that I was\nthe only one who knew the password. Then I made these files entirely\ninaccessible to everyone except the owner—me.\n\nLarge computers let you make a file world-readable, that is, open to anyone\nwho logs into the system. It’s a bit like leaving an office cabinet\nunlocked—anyone can read the contents when they wish. You might set world-read\non a file containing the scores of the office’s volleyball tournament.\n\nWith a single command, you can make a file readable by only certain people,\nfor example, your co–workers. The latest sales report, or some manufacturing\ndesigns, need to be shared among a few people, but you don’t want everyone to\nscan them.\n\nOr a computer file can be entirely private. Nobody but you can read it. Like\nlocking your desk drawer, this keeps everyone out. Well, almost everyone. The\nsystem manager can bypass the file protections, and read any file.\n\nBy setting our SDI files to be readable only by their owner, I made sure that\nnobody else would find them. Since I was the owner and the system manager,\nnobody else could see them.\n\nExcept, perhaps, a hacker masquerading as system manager.\n\nFor the hacker could still break in and become system manager. It would take\nhim a couple of minutes to hatch his cuckoo’s egg, but he’d then be able to\nread all the files on my system. Including those bogus SDI files.\n\nIf he touched those files, I’d know about it. My monitors saved his every\nmove. Just to make certain, though, I attached an alarm to those SDI network\nfiles. If anyone looked at them—or just caused the computer to try to look at\nthem—I’d find out about it. Right away.\n\nMy snare was baited. If the hacker bit, he’d take two hours to swallow the\nbait. Long enough for the Germans to track him down.\n\nThe next move was the hacker’s.\n\n\n![](images/Stol_9780307819420_epub_046_r1.jpg) I’d screwed up again. Operation\nShowerhead was ready, all right. It might even work. But I’d forgotten an\nimportant detail.\n\nI hadn’t asked anyone’s permission.\n\nNormally, this wouldn’t be a problem, since nobody cared what I did anyway.\nBut bicycling up to the lab, I realized that every organization I’d been in\ncontact with would want to know about our phony SDI files. Each place would\nhave a different opinion, of course, but to go ahead without telling anyone\nwould piss them all off.\n\nBut what if I asked their permission? I didn’t want to think about it. Mostly,\nI worried about my boss. If Roy stood behind me, then the three letter\nagencies couldn’t touch me.\n\nOn January 7, I went straight to his office. We talked about relativistic\nelectrodynamics for a while—which mostly meant my watching the old professor\nat the chalkboard. Say what you will about crusty college professors, there’s\nno better way to learn than to listen to someone who’s paid his dues.\n\n“Say, boss, I’m trying to get out from under this hacker.”\n\n“CIA leaning on you again?” Roy was joking, I hoped.\n\n“No, but the Germans will only trace the line for one more week. After next\nweekend, we might as well call it quits.”\n\n“Good. It’s been too long anyway.”\n\n“Well, I was thinking about planting some misleading data in our computer, to\nuse as bait in catching the hacker.”\n\n“Sounds good to me. It won’t work, of course.”\n\n“Why not?”\n\n“Because the hacker’s too paranoid. Still, go ahead. It’ll be a useful\nexercise.” Hot damn!\n\nMy boss’s approval insulated me from the rest of the world. Still, I ought to\ntell the three letter folks about our plans. I wrote a short proposal, framed\nas a scientific paper:\n\nProposal to Determine the Address of the Hacker\n\nProblem:\n\nA persistent hacker has invaded LBL’s computers. Because he is coming from\nEurope, it takes an hour to trace the phone lines. We would like to learn his\nexact location.\n\nObservations:\n\n1\\. He is persistent\n\n2\\. He confidently works within our computers, unaware that we are watching\nhim.\n\n3\\. He searches for phrases like “sdi,” “stealth,” and “nuclear.”\n\n4\\. He is a competent programmer and is experienced at breaking into networks.\n\nSuggested solution:\n\nProvide fictitious information to keep him connected for more than an hour.\nComplete the phone trace during this time.\n\nMy paper went on and on about History, Methodology, Implementation Details,\nand had footnotes about the chances of actually catching him. As boring as I\ncould make it.\n\nI sent this paper to the usual list of 3 letter agencies: the FBI, CIA, NSA,\nand DOE. I included a note saying that unless someone objected, we’d carry out\nthis plan next week.\n\nA few days later, I called each agency. Mike Gibbons of the FBI understood\nwhat I was getting at, but wouldn’t commit his agency one way or another.\n“What does the CIA have to say about it?”\n\nTeejay at the CIA had also read my proposal, but was equally noncommittal:\n\n“What did the guys at the ‘F’ entity say?”\n\n“Mike said to call you.”\n\n“Well, ain’t that dandy. Have you called the northern entity?” Northern\nentity? What’s north of the CIA?\n\n“Uh, Teejay, who’s the northern entity?”\n\n“You know, the big Fort M.”\n\nOh—Fort Meade in Maryland. The NSA.\n\nYes, I had called Fort Meade, and Zeke Hanson at the NSA’s National Computer\nSecurity Center had read my proposal. He seemed to like it, but he didn’t want\nto have anything to do with it.\n\n“Well, I sure can’t tell you to go ahead,” Zeke said. “Personally, I’d love to\nsee what happens. But if you get into trouble, we don’t have anything to do\nwith it.”\n\n“I’m not looking for someone to take responsibility. I’m wondering if it’s a\nbad idea.” Sounds strange, but that’s just what I was trying to do. Before you\nstart an experiment, get the opinions of people who’ve been there before.\n\n“Sounds good to me. But you really ought to check with the FBI.” That closed\nthe circle—everyone pointed their finger at someone else.\n\nWell, I called the Department of Energy, the Air Force OSI, and a guy at the\nDefense Intelligence Agency. Nobody would take responsibility, of course, yet\nnobody blocked the idea. That’s all I needed.\n\nBy Wednesday, it was too late for anyone to object. I was sold on Martha’s\nidea, and was willing to back it up.\n\nSure enough, Wednesday afternoon, the hacker showed up. I’d been invited to\nlunch at the Cafe Pastorale in Berkeley with Dianne Johnson, the field\nrepresentative of the Department of Energy. Along with Dave Stevens, the\ncomputer center’s math whiz, we enjoyed some fine fettucini, while talking\nabout our progress and plans.\n\nAt 12:53 PST, in the middle of a cup of cappuccino, my beeper went off. The\nmorse code said the hacker was into our Unix-4 computer as Sventek. I didn’t\nsay a word—just ran to the phone booth and called Steve White at Tymnet ($2.25\nin quarters), and he started the trace running. The hacker was on for only\nthree minutes—just long enough to see who was logged onto my computer. I was\nback at the table before the coffee cooled off.\n\nThat spoiled the rest of lunch for me. Why had he stayed around only three\nminutes? Did he sense a trap? I couldn’t tell until I saw the printout up at\nthe lab.\n\nThe monitors showed him logging on as Sventek, listing the names of everyone\ncurrently logged on, and then disappearing. Damn him. He didn’t look around\nlong enough to discover our bogus files.\n\nOh—maybe our bait was too well hidden. The German phone technician would be\naround for only a couple more days, so I’d better make it more obvious.\n\nFrom now on, I’d stay logged on to my computer. I would play sweet Barbara\nSherwin, connected to the computer on the SDINET account. The next time the\nhacker raised his periscope, he’d see SDINET clunking away, trying to edit\nsome file or another. If that didn’t catch his attention, then nothing would.\n\nNaturally, he didn’t show up the next day, Thursday. We were running out of\ntime. Nothing the next morning. I was about to call it quits, when my beeper\nsounded at 5:14 P.M, Friday, January 16. There’s the hacker.\n\nAnd I’m here, working in the SDINET account, playing with a word processing\nprogram. His first command, “who,” listed ten people. I was the seventh on his\nlist:\n\n**who**\n\n**Astro**\n\n**Carter**\n\n**Fermi**\n\n**Meyers**\n\n**Microprobe**\n\n**Oppy5**\n\n**Sdinet**\n\n**Sventek**\n\n**Tumchek**\n\n**Tompkins**\n\nThere’s the bait. Come on, go for it!\n\n**lbl > grep sdinet/etc/passwd** | he’s searching for user “SDINET” in our password file  \n---|---  \n  \n**sdinetsx4sd34xs2:user sdinet files in/u4/sdinet, owner sdi network project**\n\nHa! He swallowed the hook! He’s hunting for information about the user SDINET!\nI knew what he’d do next—he’d search over in the SDINET directory.\n\n**lbl > cd /u4/sdinet** **lbl > ls** | he’s moving over to the SDINET directory and trying to list the file names  \n---|---  \n**file protection violation -- you are not the owner**. | But he can’t see them!  \n  \nOf course he can’t read the SDINET data—I’ve locked everyone out of those\nfiles. But he knows how to evade my lock. Just plant a little egg, using the\nGnu-Emacs software. Become super-user.\n\nNone of my files are hidden from the system manager. And my visitor knows\nexactly how to grab those privileges. It just takes a few minutes. Would he\nreach into the monkey bottle?\n\nThere he goes. He’s checking that the Gnu-Emacs move-mail program hasn’t been\nchanged. Now he’s creating his own false atrun program. Just like the old\ndays. In a couple more minutes, he’ll be system manager.\n\nOnly this time, I’m on the phone to Steve White.\n\n“Steve, call Germany. The hacker’s on, and it’ll be a long session.”\n\n“Spot-on, Cliff. Call you back in ten minutes.”\n\nNow it’s the Germans’ turn. Can they pull the plum from the pie? Let’s see,\nit’s 5:15 P.M. in Berkeley, so in Germany, it’s uh, 2:15 in the morning. Or is\nit 1:15? Either way, it’s sure not ordinary business hours. Sure hope that the\nHannover technicians stayed late tonight.\n\nMeanwhile, the hacker’s not wasting time. Within five minutes, he’d built a\nspecial program to make himself super-user. He twisted the tail of the Gnu-\nEmacs program, moving his special program into the systems area. Any minute\nnow, Unix will discover that program and … yep, there it goes. He’s super-\nuser.\n\nThe hacker went straight for the forbidden SDINET files. (I’m glued to my\nmonitor, thinking, “Come on, guy, wait till you see what’s sitting there for\nyou.”) Sure enough, he first lists the file names:\n\n**lbl > ls**\n\n**Connections**\n\n**Form-Letter**\n\n**Funding**\n\n**Mailing-Labels**\n\n**Pentagon-Request**\n\n**Purchase-Orders**\n\n**Memo-to-Gordon**\n\n**Rhodes-Letter**\n\n**SDI-computers**\n\n**SDI-networks**\n\n**SDI-Network-Proposal**\n\n**User-List**\n\n**World-Wide-Net**\n\n**Visitor-information**\n\nMany of these files aren’t just single memos. Some are file directories—whole\nfile cabinets full of other files.\n\nWhich one will he look at first? That’s easy. All of them.\n\nFor the next forty-five minutes, he dumps out file after file, reading all the\ngarbage that Martha and I created. Boring, tedious ore, with an occasional\nnugget of technical information. For example:\n\n**Dear Major Rhodes:**\n\n**Thank you for your comments concerning access to SDINET. As you know, a\nNetwork User Identifier (NUI) is required for access to both the Classified\nand Unclassified SDINET. Although these NUI’s are distributed from different\nlocations, it is important that users who use both sections of the network\nretain the same NUI**.\n\n**For this reason, your command center should contact the network controllers\ndirectly. At our laboratory in Berkeley, we can easily modify your NUI, but we\nwould prefer that you issue the appropriate request to the network\ncontrollers**.\n\n**Sincerely yours** ,\n\n**Barbara Sherwin**\n\nAah … there’s a pointer in that letter saying that you can reach the SDINET\nfrom Lawrence Berkeley Laboratory. I’ll bet that he’ll spend an hour or two\nsearching for the portal to reach that mythical SDINET.\n\nDid he believe what I’d fed him? There’s an easy way to find out. Just watch\nwhat he does—a disbeliever won’t go hunting for the Holy Grail. The files made\na believer out of him. He interrupted his listing to search for a connection\ninto our SDI network. On my monitor, I watched him patiently scan all our\nlinks to the outside world. Without knowing our system thoroughly, he couldn’t\nsearch exhaustively, but he spent ten minutes checking the system for any\nports labelled “SDI.”\n\nHook, line, and sinker.\n\nHe returned to reading our fake SDINET files, and dumped the file named form-\nletter:\n\n**SDI Network Project  \nLawrence Berkeley Lab  \nMail Stop 50-351  \n1 Cyclotron Road  \nBerkeley, CA 94720**\n\n**name name**\n\n**address address**\n\n**city city, state state, zip zip**\n\n**Dear Sir:**\n\n**Thank you for your inquiry about SDINET. We are happy to comply with your\nrequest for more information about this network. The following documents are\navailable from this office. Please state which documents you wish mailed to\nyou:**\n\n**#37.6 SDINET Overview Description Document 19 pages, revised Sept, 1985**\n\n**#41.7 Strategic Defense Initiative and Computer Networks: Plans and\nimplementations (Conference Notes) 227 pages, revised Sept, 1985**\n\n**#45.2 Strategic Defense Initiative and Computer Networks: Plans and\nimplementations (Conference Notes) 300 pages, June, 1986**\n\n**#47.3 SDINET Connectivity Requirements 65 pages, revised April, 1986**\n\n**#48.8 How to link into the SDINET 25 pages, July 1986**\n\n**#49.1 X.25 and X.75 connections to SDINET (includes Japanese, European, and\nHawaii nodes) 8 pages, December, 1986**\n\n**#55.2 SDINET management plan for 1986 to 1988 47 pages, November 1985**\n\n**#62.7 Unclassified SDINET membership list (includes major Milnet\nconnections) 24 pages, November 1896**\n\n**#65.3 Classified SDINET membership list 9 pages, November, 1986**\n\n**#69.1 Developments in SDINET and Sdi Disnet 28 pages, October, 1986**\n\n**NUI Request Form  \nThis form is available here, but  \nshould be returned to the Network Control Center**\n\n**Other documents are available as well. If you wish to be added to our\nmailing list, please request so**.\n\n**Because of the length of these documents, we must use the postal service**.\n\n**Please send your request to the above address, attention Mrs. Barbara\nSherwin**.\n\n**The next high level review for SDINET is scheduled for 20 February, 1987.\nBecause of this, all requests for documents must be received by us no later\nthan close of business on 11 February, 1987. Requests received later than this\ndate may be delayed**.\n\n**Sincerely yours,  \nMrs. Barbara Sherwin  \nDocuments Secretary  \nSDINET Project**\n\nI wondered how he’d react to this letter. Would he send us his address?\n\nIt didn’t make much difference. Steve White called back from Tymnet. “I’ve\ntraced your connection over to the University of Bremen.”\n\n“Same as usual, huh?”\n\n“Yeah. I guess they’ve reopened for classes,” Steve said. “At any rate, the\nBundespost has traced the Datex line from Bremen into Hannover.”\n\n“OK. Sounds like the hacker’s in Hannover.”\n\n“That’s what the Bundespost says. They’ve traced the Datex line into a dial-in\nport located near downtown Hannover.”\n\n“Keep going, I follow you.”\n\n“Now comes the tough part. Someone has dialed into the Datex system in\nHannover. They’re coming from Hannover, all right—it’s not a long distance\nline.”\n\n“Does the Bundespost know that phone number?”\n\n“Almost. In the past half hour, the technician traced the line and has\nnarrowed it down to one of fifty telephone numbers.”\n\n“Why can’t they get the actual number?”\n\n“Wolfgang’s unclear about that. It sounds like they’ve determined the number\nto be from a group of local phones, but the next time they make a trace,\nthey’ll zero in on the actual telephone. From the sound of Wolfgang’s message,\nthey’re excited about solving this case.”\n\nOne in fifty, huh? The Bundespost is almost there. Next time, they’ll have\nhim.\n\nFriday, January 16, 1987. The cuckoo laid its eggs in the wrong nest.\n\n\n![](images/Stol_9780307819420_epub_047_r1.jpg) The trace almost reached the\nhacker. If he came by once more, we’d have him.\n\nBut the deadline was tomorrow night. Saturday, when the German telephone\ntechnicians would give up the chase. Would he show up?\n\n“Martha, you don’t want to hear this, but I’m sleeping at the lab again. This\nmay be the end of the road, though.”\n\n“That’s the dozenth time you’ve said that.”\n\nProbably was. The chase had been a constant stream of “I’ve almost got him”\nfollowed by “He’s somewhere else.” But this time it felt different. The\nmessages from Germany were confident. They were on the right scent.\n\nThe hacker hadn’t read all our bogus files. In the forty-five minutes that\nhe’d linked into our system, he listed about a third of the data. He knew\nthere was more, so why didn’t he stay around and browse?\n\nAll the more likely that he’d come back soon. So once again, I crawled under\nmy desk and fell asleep to the sound of a computer disk drive whining in the\ndistance.\n\nI woke up, for once, without a beeper squawking in my ear. Just a peaceful\nSaturday morning, alone in a sterile office, staring at the bottom of my desk.\nOh well, I’d tried. Too bad the hacker didn’t show up.\n\nSince nobody else was around, I started to play with an astronomical program,\ntrying to understand how mistakes in mirror-grinding affect images from a\ntelescope. The program was just about working when my beeper called at 8:08\na.m.\n\nA quick jog down the hall, and a glance at the monitor’s screen. There’s the\nhacker, just logging into the Unix-5 computer, on one of his old account\nnames, Mark. No time to figure what he’s doing here, just spread the word\nfast. Call Tymnet, and let them call the Bundespost.\n\n“Hi Steve!”\n\n“The hacker’s back on, eh?” Steve must have heard it in the tone of my voice.\n\n“Yep. Can you start the trace?”\n\n“Here goes.” He was gone for thirty seconds—it couldn’t have been a full\nminute—when he announced, “He’s coming from Bremen this time.”\n\n“Same as yesterday,” I observed.\n\n“I’ll tell Wolfgang at the Bundespost.” Steve hung up while I watched the\nhacker on my screen. Every minute the hacker visited, we were that much closer\nto unmasking him.\n\nYes, there he was, methodically reading our false data files. With every\nbureaucratic memo he read, I felt more satisfied, knowing he was being misled\nin two ways: his information was patently false, and his arrogant strides\nthrough our computer were leading him straight into our arms.\n\nAt 8:40, he left our computer. Steve White called back within a minute.\n\n“The Germans traced him through the University of Bremen again,” he said.\n“From there, into Hannover.”\n\n“Did they make any progress in getting his phone number?”\n\n“Wolfgang says they’ve got all the digits of his phone number except the last\ntwo.”\n\nAll but the last two digits? That didn’t make sense—it meant that they’d\ntraced the call to a group of one hundred phones. “But that’s worse than\nyesterday, when they said they’d isolated him to one of fifty phones.”\n\n“All I can tell you is what I hear.”\n\nDisturbing, but at least they were tracing the lines.\n\nAt 10:17, he came back. By now, Martha had bicycled up to the lab, and the two\nof us were busy inventing new SDI files to feed him. We both ran to the\nmonitors and watched him, expecting him to discover our latest work.\n\nThis time, he wasn’t interested in SDI files. Instead, he went out over the\nMilnet, trying to break into military computers. One by one, trying to guess\nhis way past their password protection.\n\nHe concentrated on Air Force and Army computers, occasionally knocking on the\nNavy’s door. Places I’d never heard of, like the Air Force Weapons Lab, Descom\nHeadquarters, Air Force CC OIS, the CCA-amc. Fifty places, without success.\n\nThen he slid across the Milnet into a computer named Buckner. He got right in\n… didn’t even need a password on the account named “guest.”\n\nMartha and I looked at each other, then at the screen. He’d broken into the\nArmy Communications Center in Building 23, Room 121, of Fort Buckner. That\nmuch was obvious: the computer greeted the hacker with its address. But\nwhere’s Fort Buckner?\n\nAbout all I could tell was that its calendar was wrong. It said today was\nSunday, and I knew it was Saturday. Martha took charge of the monitors, and I\nran to the library, returning with their now familiar atlas.\n\nPaging through the back pages, I found Ft. Buckner listed.\n\n“Hey, Martha, you’re not going to believe this, but the hacker’s broken into a\ncomputer in Japan. Here’s your Fort Buckner,” I said, pointing to an island in\nthe Pacific Ocean. “It’s on Okinawa.”\n\nWhat a connection! From Hannover, Germany, the hacker linked to the University\nof Bremen, across a transatlantic cable into Tymnet, then into my Berkeley\ncomputer, and into the Milnet, finally reaching Okinawa. Jeez.\n\nIf someone in Okinawa had detected him, they’d have to unravel a truly\ndaunting maze.\n\nNot that this worldwide link satisfied him—he wanted Fort Buckner’s database.\nFor half an hour, he probed their system, finding it amazingly barren. A few\nletters here and there, and a list of about seventy-five users. Fort Buckner\nmust be a very trusting place: nobody set passwords on their accounts.\n\nHe didn’t find much on that system, outside of some electronic mail messages\ntalking about when supplies would arrive from Hawaii. A collector of military\nacronyms would love the Fort Buckner computer, but any sane person would be\nbored.\n\n“If he’s so interested in military gobbledegook,” Martha asked, “why not\nenlist?”\n\nWell, this hacker wasn’t bored. He listed as many text files as he could,\nskipping only the programs and Unix utilities. A bit after eleven in the\nmorning, he finally grew tired, and logged off.\n\nWhile he’d circled the globe with his spiderweb of connections, the German\nBundespost had homed in on him.\n\nThe phone rang—had to be Steve White.\n\n“Hi, Cliff,” Steve said. “The trace is complete.”\n\n“The Germans got the guy?”\n\n“They know his phone number.”\n\n“Well, who is he?” I asked.\n\n“They can’t say right now, but you’re supposed to tell the FBI.”\n\n“Just tell me this much,” I told Steve, “is it a computer or a person?”\n\n“A person with a computer at his home. Or should I say, at his business.”\n\nMartha overheard the conversation and was now whistling a tune from the Wizard\nof Oz: “Ding-dong, the witch is dead.…”\n\nAt last, the trace was over. The police would bust him, he’d be arraigned,\nwe’d press charges, and he’d be pacing a jail cell. So I thought.\n\nBut more important, my research was finished. Five months ago, I asked myself,\n“How come my accounts are imbalanced by 75 cents?” That question had led me\nacross the country, under the ocean, through defense contractors and\nuniversities, to Hannover, Germany.\n\nMartha and I biked home, stopping only to pick up a pint of heavy cream. We\npicked the last of our garden’s strawberries and celebrated with homemade\nmilkshakes. No doubt—there’s no substitute for mixing ’em yourself. Toss in\nsome ice cream, a couple bananas, a cup of milk, two eggs, a couple spoonfuls\nof vanilla, and a handful of homegrown strawberries. Thicken it with just\nenough malt. Now that’s a milkshake.\n\nClaudia, Martha, and I danced around the yard for a while—our plans had worked\nout perfectly.\n\n“In a couple days, the police will bust him, and we’ll find out what he was\nafter,” I told them. “Now that someone knows who’s behind this, it can’t be\nlong.”\n\n“Yow, you’ll get your name in the newspaper,” Claudia marveled. “Will you\nstill talk to us?”\n\n“Yeah, I’ll even keep washing the dishes.”\n\nThe rest of the day, Martha and I spent in San Francisco’s Golden Gate Park,\nriding the merry-go-round and roller-skating.\n\nAfter all these months, the problem was solved. We’d thrown a net around the\ncuckoo.\n\n\n![](images/Stol_9780307819420_epub_048_r1.jpg) He stared bleakly at the broken\ngreasy venetian blinds, a cigarette butt dangling from his clammy lips. The\nsickly green glow of the screen reflected on his sallow tired features.\nSilently, deliberately, he invaded the computer.\n\nSix thousand miles away, her longing white arms craved for him. He could feel\nher hot breath on his cheek, as her delicate fingers curled through his long\nbrown hair. Her negligee parted invitingly, he sensed every curve through the\nthin silken gauze. She whispered, “Darling, don’t leave me.…”\n\nSuddenly the night was shattered—that sound again—he froze and stared at the\nnight stand. A red light beckoned across the pitch black room. His beeper sang\nits siren song.\n\nSunday morning, at 6:30, Martha and I were dreaming when the hacker stepped on\nmy electronic tripwire. Damn. Such a great dream, too.\n\nI slid out from under the quilts and called Steve White. He passed the message\nalong to the Bundespost, and five minutes later, the trace was complete.\nHannover again. Same guy.\n\nFrom home, I couldn’t observe him—he might notice me watching him. But only\nyesterday he’d finished reading all our phony SDI files. So why come back now?\n\nIt wasn’t until I biked into work that I saw the hacker’s targets. Milnet\nagain. The printout showed him logging into my Berkeley computer, then\nreaching out over the Milnet, then trying to log onto a system at the Eglin\nAir Force Base.\n\nHe tried account names like guest, system, manager, and field service … all\nhis old tricks. Eglin’s computer didn’t put up with such nonsense: it kicked\nhim out after his fourth try. So, he went on the European Milnet Control\ncomputer, and tried again. Still no luck.\n\nSixty computers later, he still hadn’t gotten into a military computer. But he\nkept trying.\n\nAt 1:39 P.M., he succeeded in logging into the Navy Coastal Systems Center in\nPanama City, Florida. He got into their system by trying the account “Ingres”\nwith the password “Ingres.”\n\nIngres database software lets you quickly search thousands of accounting\nrecords for the one entry you need. You make queries like, “Tell me all the\nquasars that emit X rays,” or “How many Tomahawk missiles are deployed in the\nAtlantic fleet?” Database software is powerful stuff, and the Ingres system is\namong the finest.\n\nBut it’s sold with a backdoor password. When you install Ingres, it comes with\na ready-made account that has an easily guessed password. My hacker knew this.\nThe Navy Coastal Systems Center didn’t.\n\nOnce logged on, he meticulously checked that nobody was watching him. He\nlisted the file structures and searched for links to nearby networks. He then\nlisted the entire encrypted password file.\n\nThere he goes again. That’s the third or fourth time I’d seen him copy the\nwhole password file into his home machine. Something’s strange here—the\npasswords are protected by encryption, so he can’t possibly figure out the\noriginal password. Still, why else would he copy the password file?\n\nAfter an hour inside the navy computer, he grew tired and went back to\nknocking on doors along the Milnet. That, too, lost its excitement after a\nwhile; after fifty or a hundred times, even he tired of seeing the message,\n“Invalid Login—bad password.” So he printed out some SDINET files again,\npretty much the same stuff he’d seen in the past couple of days. Around 2:30\nin the afternoon he called it quits. He’d spent eight hours hacking on the\nmilitary networks.\n\nPlenty of time to trace his call. And time enough to learn that the German\nBundespost has been in close contact with the Public Prosecutor in Bremen,\nGermany. They’re contacting the authorities in Hannover, and they’re also\ntalking to the German BKA. Sounds like someone is about ready to close in on\nthe hacker and make the arrest.\n\nWho should I call about this break-in into the Navy computer?\n\nA week ago, the Air Force OSI warned me not to call the system managers\ndirectly. Jim Christy said, “It’s just runs against military policy.”\n\n“I understand,” I said. “But is there a clearinghouse to report these problems\nto?”\n\n“No, not really,” Jim explained. “You can tell the National Computer Security\nCenter, but they’re pretty much a one-way trap. They listen, all right, but\nthey don’t publicize problems. So if it’s a military computer, call us,” Jim\nsaid. “We’ll go through channels and get the word to the right folks.”\n\nMonday morning brought the hacker again. Time to twist some more doorknobs.\nOne by one, he scanned Milnet computers, ranging from the Rome Air Development\nCenter in New York to someplace called the Naval Electronic Warfare Center. He\ntried fifteen places before he struck pay dirt—the Ramstein Air Force Base\ncomputer. This time, he discovered that the account, “bbncc,” wasn’t\nprotected. No password needed.\n\nRamstein’s computer seemed to be an electronic mail system for officers. He\nstarted listing everyone’s mail. Quickly, it opened my eyes—this was stuff\nthat he shouldn’t be seeing.\n\nOK, what should I do? I couldn’t let him grab this information, yet I didn’t\nwant to tip my hand. Disconnecting him won’t do much good—he’ll just find\nanother pathway. I can’t call the place—I’ve no idea where Ramstein Air Force\nBase is. I can call Air Force OSI, but I’ve got to take action now—not in five\nminutes—before he reads the rest of their data.\n\nI reached for the phone to call Jim Christy of the Air Force OSI. Naturally I\ncan’t remember his phone number. There in my pocket is a key chain. Of course,\nthe old key chain trick. Just add some noise to his connection.\n\nI jangled my keys against the connector, shorting out the hacker’s\ncommunications line. Just enough to appear as noise to the hacker. “Static on\nthe line,” he’d think. Every time he asked for electronic mail from Ramstein,\nI garbled his commands, and Ramstein’s computer misunderstood him.\n\nAfter a few more attempts, he gave up on Ramstein Air Force Base, and went\nback to scanning the Milnet, trying to get into other places.\n\nI finally reached Jim Christy at Air Force OSI. “The hacker’s gotten into\nsomeplace called Ramstein Air Force Base. Wherever it is, you’d better tell\nthem to change all their passwords.”\n\n“Ramstein’s in Germany.”\n\n“Huh?” I asked. I’d thought the occupation of Europe had ended in the ’50s.\n“What’s the U.S. Air Force doing in Germany?”\n\n“Protecting you. But let’s not go into that. I’ll warn them right away. Go\nback to watching the hacker.”\n\nI’d missed ten minutes of the hacker. He was trying to break into more\nmilitary systems, slowly and methodically trying dozens of sites.\n\nThe Milnet addresses seemed to be in alphabetical order; right now he was\nworking near the end of the alphabet. Mostly R’s and S’s. Aha! Yes, that was\nit. He was working from an alphabetized list. Somehow, he’d obtained the\nMilnet directory, and was checking off each site after he tried it.\n\nHe’d made it halfway through the S’s when he tried a computer called\nSeckenheim. Logged right in as “Guest.” No password. This was getting\nembarrassing.\n\nBut though he got into that computer, he didn’t stay long. A few minutes to\nmake a couple scans of their system files, then he logged off. I wondered why.\n\nStill, I’d better do something. Time to call the Air Force.\n\n“Hey, the hacker just got into someplace called Seckenheim. It’s on the\nMilnet, so it must be a military computer. But I’ve never heard of it.”\n\n“Snake in the grass,” Jim growled.\n\n“Huh?”\n\n“Damn. Seckenheim is the Army Material Command in Europe. Near Heidelberg.\nGermany again.”\n\n“Oops. Sorry about that.”\n\n“I’ll take care of it.” The hacker’s success meant problems for the narcs. I\nwondered how many overseas military bases the United States has. The\ntechnology I could handle. It was geography and bureaucracies that tripped me\nup.\n\nAfter having cracked three computers today, the hacker was still not\nsatisfied. He continued to bang away on the Milnet, so I kept watch in the\nswitchyard. One by one, I watched as he tried passwords. At 11:37, he got into\na Vax computer named Stewart. Logged right in there as “Field,” password,\n“Service.” I’d seen it before. Another Vax computer running VMS that hadn’t\nchanged their default passwords.\n\nThe hacker dived right in. The field service account was privileged, and he\nwasted no time taking advantage of this. He first disabled accounting, so that\nhe’d leave no tracks behind. Then he went directly to the _authorize_\nutility—the system software in charge of passwords—and selected one user,\nRita, who hadn’t used the system for the past few months. He modified Rita’s\naccount to give it full system privileges. Then he set a new password.\n“Ulfmerbold.”\n\nWhere had I heard that word? Ulfmerbold. It sounded German. Something to\nfigure out later. Meanwhile, I’ve got to watch my hacker.\n\nFinally, a bit after noon, the hacker left Berkeley. A productive day for him.\n\nThe Stewart computer turned out to belong to Fort Stewart, an army base in\nGeorgia. I called Mike Gibbons of the FBI, and he took care of calling them.\n\n“Mike, have you ever hear of the word, Ulfmerbold?”\n\n“Nope. Sounds German, though.”\n\n“Just checking. Say, the Germans have completed the trace. The Bundespost now\nknows who’s making the calls.”\n\n“Did they tell you?”\n\n“Naw. Nobody ever tells me anything. You know that.”\n\nMike laughed. “That’s the way we operate, all right. But I’ll get the legat on\nthe case right away.”\n\n“Legat?”\n\n“Oh. Legal Attaché. You know, the guy in Bonn that handles our affairs.”\n\n“How soon until they arrest the guy?” I just wanted to know who and why—the\nlast pieces of the puzzle.\n\n“I don’t know. But when it happens, I’ll tell you. Shouldn’t be long now.”\n\nBy chance, around 3 P.M. Teejay called from the CIA. “What’s new?”\n\n“We completed the trace over the weekend.”\n\n“Where is he?”\n\n“In Hannover.”\n\n“Mmmm. Know the guy’s name?”\n\n“No, not yet.”\n\n“Does the ‘F’ entity know?”\n\n“I don’t think so. But call them and find out. They never tell me a thing.” I\ndoubted that the FBI would tell the CIA, and I didn’t want to be squeezed\nbetween the two. It was weird enough to talk to either.\n\n“Any clues to his identity?”\n\n“Hard to say. Ever hear of the word Ulfmerbold?”\n\n“Mmmm. What’s that from?”\n\n“The hacker chose that as a password when he broke into a computer this\nmorning. At Fort Stewart, Georgia.”\n\n“He’s not letting the grass grow, huh?” Teejay still tried to sound\nuninterested, but his voice had a tremor that gave it away.\n\n“Yeah. He got into a couple other places too.”\n\n“Where?”\n\n“Oh,” I said, “no place special. Just a couple military bases in Germany. And\na place called Fort Buckner.”\n\n“Son of a bitch.”\n\n“You know them?”\n\n“Yeah. I used to work at Fort Buckner. Back in my Army days. Lived on base\nwith my wife.” A CIA agent with a wife? I’d never thought of it. Spy novels\nnever mention spouses or kids.\n\nThe hacker had chosen a strange password for his use. Ulfmerbold. Nothing in\nmy dictionary. Not in Cassell’s German-English dictionary. The trusty atlas\nshowed nothing. Yet I’d heard this word before.\n\nMartha hadn’t heard of it. Nor had any of my friends. Not even my sister, the\none who’d risked her life prowling around a high school in McLean, Virginia.\n\nIt took three days, but my boss, Roy Kerth, figured it out. Ulf Merbold is the\nWest German astronaut who’d made astronomical observations from the space\nshuttle.\n\nAnother clue to Germany, unnecessary, now that the evidence was overwhelming.\nBut why pick an astronaut’s name? Hero worship? Or some more sinister motive?\n\nCould this explain why he kept breaking into computers? Could I have been\nfollowing someone obsessed with the U.S. space program—a guy who dreamed about\nbecoming an astronaut and collected information about the space program?\n\nNope. This hacker sought out military computers—not NASA systems. He wanted\nSDI data, not astronomy. You don’t search for the space shuttle on Okinawa.\nYou don’t find an astronaut’s biography by looking up the Army’s nuclear\nwarfare plans for Central Europe.\n\n\n![](images/Stol_9780307819420_epub_049_r1.jpg) Tuesday morning greeted me with\na pile of messages from Tymnet. Steve White read some electronic mail from the\nDeutsche Bundespost. “Since the University of Bremen won’t pay for any more\ninternational calls, you’ll have to carry that cost.”\n\nHe knew that we couldn’t afford it. “Steve, my boss balks at paying my salary,\nlet alone this hacker’s connections.”\n\n“How much time are you putting in on this chase?”\n\n“Oh, about ten hours a day.” I wasn’t kidding. Even a five-minute connection\nby the hacker ballooned into a morning of phone calls. Everyone wanted to hear\nwhat had happened. Nobody offered support.\n\n“Well then, I’ve some good news for you,” Steve said. “Wolfgang Hoffman says\nthere’s a meeting in Hannover tomorrow. Something about coordinating legal,\ntechnical, and law-enforcement activities.”\n\n“Why’s that good news?”\n\n“Because they expect to make an arrest this weekend.”\n\nFinally.\n\n“But there’s a couple problems. The Germans haven’t heard from the FBI yet. So\nthey’re putting things on hold. Wolfgang asks that you pass this message to\nthe FBI.”\n\n“Will do.”\n\nMy next call to the FBI showed the flip side of the coin. Special Agent Mike\nGibbons explained the situation.\n\nHe’d sent telegrams to Bonn telling the FBI’s Legat to contact the German\npolice. At the same time, he shipped by air a folder of information to the\nAttaché. But somewhere, the messages weren’t getting through—Wolfgang still\nhadn’t heard about any warrants from the FBI.\n\n“You see, we can’t talk to anyone except through our Legat,” Mike said.\n“Still, I’ll rattle the cage again, and see that they’re awake in Bonn.”\n\nWell, that FBI agent sure wasn’t dragging his heels. I never did find out much\nabout the Legal Attaché—do they work for the FBI or the State Department? Is\nit one part-time person or a whole staff? What do they really do? Who do they\ntalk to in the German government? What do you have to do to wake them up?\n\nThe CIA wouldn’t leave me alone. Teejay wanted every detail about the past\nweekend. But the juicy stuff—the guy’s name, his motives, and his\nbackers—remained a mystery. All I knew was that he’d been fingered.\n\n“Say, Teejay, if I find out some of this for you, is there any chance you\nmight, uh, trade some gossip?”\n\n“I don’t copy,” the spook said.\n\n“I mean, suppose you figure out who was behind all this. What’ll you tell me\nabout it?” I really wanted to know if he could send some spy over there and\nfind out what this clown was up to.\n\n“Sorry, Cliff. We’re listeners, not talkers.”\n\nSo much for learning anything from the CIA.\n\nWithin a day, however, more news came by way of Tymnet. Having traced the\nhacker’s phone number, they compared his name to that on the German Datex\naccounts.\n\nHmmm. They’re doing their homework!\n\nSeems that the hacker used three different identifiers when he manipulated the\nDatex network. The first identifier belonged to the hacker. Same name, same\naddress. The second one belonged to another person. And the third … well, it\nbelonged to a company. A small company in Hannover that specialized in\ncomputers.\n\nWere these identifiers stolen? It’s as easy to steal a network user identifier\nas it is to steal a telephone credit card number—just watch over someone’s\nshoulder as she makes a call. Perhaps the hacker has ripped off several\npeople’s Datex network account numbers. If they worked for big multinational\nfirms, they might never notice.\n\nOr was this guy in collusion with someone else?\n\nI’d pretty much convinced myself that he was acting alone. If a couple people\nwere working together, they’d have to constantly exchange passwords. Moreover,\nthe hacker had a single personality—patient, methodical, an almost mechanical\ndiligence. Someone else wouldn’t have quite the same style when prowling\naround the Milnet.\n\nA few of his targets weren’t sleeping. The day after he tried to pry their\ndoors open, two of them called me. Grant Kerr, of the Hill Air Force Base in\nUtah, phoned. He was annoyed that one of my users, Sventek, had tried to break\ninto his computer over the past weekend. And Chris McDonald of White Sands\nMissile Range reported the same.\n\nSuper! Some of our military bases keep their eyes open. Thirty-nine in forty\nare asleep. But there are a few system managers who vigilantly analyze their\naudit trails.\n\nFor the next few days, the hacker kept me hopping. He kept scanning my SDINET\nfiles, so every few hours, I’d add a couple more. I wanted the files to\nreflect an active office—a backlog of work and a busy, chatty secretary who\ndidn’t quite know how her computer worked. Pretty soon, I was wasting an hour\na day generating this flimflam, just feeding the hacker.\n\nZeke Hanson of the National Computer Security Center helped with these bogus\nfiles. I knew nothing about military ranks, so he gave me a few hints.\n\n“The military’s just like any other hierarchy. Up at the top, there’s the flag\nofficers. Generals. Below them are colonels, except in the Navy, where there’s\ncaptains. Then there’s lieutenant colonels, then majors and captains …”\n\nThings are easier in grad school. Just call everyone with a tie, “Professor,”\nand anyone with a beard, “Dean.” When in doubt, just say “Doctor.”\n\nWell, every couple days the hacker would log into my system and read the\nSDINET files. If he had any doubts about the validity of this information, he\nnever showed it. In fact, he soon began trying to log into military computers\nusing the account, SDINET.\n\nWhy not? Some of these ersatz files described network links into Milnet\ncomputers. I made sure they were crammed with lots of jargon and technobabble.\n\nStill, feeding the hacker bait wasn’t leading us to an arrest. Every time he\nappeared, we traced him all right, but I kept waiting for a phone call saying,\n“He’s at the police station now.”\n\nNow that the Germans had a suspect in mind, Mike Gibbons met with the U.S.\nattorney in Virginia. The FBI’s news was mixed: if a German citizen is\ninvolved, extradition is unlikely, unless there’s underlying espionage.\n\nBy the end of the week, the hacker had returned for five more sessions, each\nan hour or more. He checked into the Navy and Army computers, making sure that\nthey still let him in. I wondered why they hadn’t closed their holes yet. Then\nhe played around our laboratory computer, again checking over the SDINET\nfiles.\n\nPerhaps he worried that we knew he’d stolen Sventek’s account, for he found\nyet another unused account at our lab, changed its password, and began using\nit for his hacking.\n\nWith all the high-powered computer folks in my department, I worried that one\nof them would post a notice to an electronic bulletin board, or casually leak\nthe story in a conversation. The hacker still searched our system for words\nlike “security” and “hacker,” so he’d stumble onto this news and our bird\nwould fly the coop.\n\nThe Germans had promised a bust this weekend. The hacker had what I hoped was\nhis last fling on Thursday, January 22, when he broke into a computer at Bolt,\nBeranak, and Neumann, in Cambridge, Massachusetts. This computer, called the\nButterfly-vax, was as unprotected as the rest: you just logged in as “guest,”\nwith no password.\n\nI’d heard of BBN—they had built the Milnet. In fact, most of the Milnet would\nsoon be controlled by their Butterfly computers. The hacker had found a\nparticularly sensitive computer—if he planted the right kind of Trojan horse\nin this computer, he might steal all the passwords that ever crossed the\nMilnet. For this was where BBN developed their network software.\n\nStealing passwords at Lawrence Berkeley Labs only gives you access to nearby\ncomputers. The place to booby-trap software is where it’s distributed. Slip a\nlogic bomb into the development software; it’ll be copied along with the valid\nprograms and shipped to the rest of the country. A year later, your\ntreacherous code will infest hundreds of computers.\n\nThe hacker understood this, but probably didn’t realize that he’d stumbled\ninto such a development system. He searched the system and found one glaring\nsecurity hole: the root account needed no password. Anyone could log in as\nsystem manager without so much as a challenge. Whoa!\n\nSomeone was sure to discover such an obvious hole, so he wasted no time in\nexploiting it. He became system manager and created a new, privileged account.\nEven if the original flaw was discovered, he’d added a new backdoor into BBN’s\ncomputer.\n\nHe created an account under the name Langman, with a password of “Bbnhack.” I\nunderstood the password, all right, but why Langman? Could that be his real\nname? The German Bundespost won’t tell me, but maybe the hacker himself did.\nWhat’s the meaning of the name Langman?\n\nNo time to worry about it now. The hacker found a letter on the BBN computer,\nsaying, “Hi, Dick! You can use my account at the University of Rochester. Log\nin as Thomas, with the password ‘trytedj’ …”\n\nIt didn’t take him fifteen seconds to reach into the Rochester computer. He\nthen spent an hour reading information about integrated circuit designs.\nApparently, a graduate student at Rochester designed sub-micron circuits,\nusing an advanced computer-controlled technique. The hacker strarted to grab\neverything, including the programs.\n\nI wouldn’t let him: this would be industrial espionage. Every time he started\nto copy some interesting files, I jingled my keys on the wires. He could look,\nbut he’d better not touch. Finally, at 5:30, he gave up.\n\nMeanwhile, I wondered about the word Langman. Was it someone’s name?\n\nAah—there’s a way to find out. Look it up in the phone book. Maggie Morley,\nour librarian, couldn’t find a Hannover telephone directory, so she ordered\none. A week later, with suitable aplomb, Maggie delivered the Deutschen\nBundespost Telefonbuch, issue number seventeen, covering Ortsnetz and\nHannover, with a rubber-stamp on the side, “Funk-Taxi, 3811.”\n\nMy atlas presented a dry, geographic Hannover. And the tourist guides spoke of\na historic, scenic city, nestled along the river Leine. But the phone book,\nwell, here’s the city: the opticians, the fabric stores, a few dozen\nautohauses, even a perfumerie. And people … I spent an hour just paging\nthrough the white pages, imagining a whole different world. There were\nlistings for Lang, Langhardt, Langheim, and Langheinecke, but not one Langman.\nBum steer.\n\nSteve White relayed a message from Germany. The Germans had been doing their\nhomework. Apparently, when the hacker called a phone, the German police had\nprinted out that phone number. Eventually, they figured out who was involved,\njust by piecing together the web of phone calls centered on the hacker.\n\nWere the German authorities planning a simultaneous bust? Tymnet passed along\na chilling message: “This is not a benign hacker. It is quite serious. The\nscope of the investigation is being extended. Thirty people are now working on\nthis case. Instead of simply breaking into the apartments of one or two\npeople, locksmiths are making keys to the houses of the hackers, and the\narrests will be made when the hackers cannot destroy the evidence. These\nhackers are linked to the shady dealings of a private company.”\n\nNot a benign hacker? Thirty people working on the case? Shady dealings of a\nprivate company? Uh oh.\n\n\n![](images/Stol_9780307819420_epub_050_r1.jpg) If you pester an organization\nlong enough, eventually they’ll hold a meeting. After all my calls to the FBI,\nNSA, CIA, and DOE, it was the Air Force Office of Special Investigations that\ngave in first. On February 4, they invited everyone to Bolling Air Force Base,\nin hopes of resolving the problem.\n\nSuburban Washington’s world is measured by position on the beltway. Bolling\nAir Force Base is somewhere around five o’clock, sort of south by southeast.\nEven with such explicit directions, I got royally lost: bicycling along\nBerkeley side streets isn’t quite the same as driving a car around a DC\nhighway.\n\nAt 11:30, three Department of Energy people met me at a restaurant near the\nAir Force base. Over some tortellini, we talked about DOE’s computer security\npolicies. They worry about atomic bomb secrets. But they’re also painfully\naware that security gets in the way of operations. High security computers are\ndifficult to get onto, and unfriendly to use. Open, friendly systems are\nusually insecure.\n\nThen we went to Bolling. It was the first time I’d ever walked on a military\nbase. The movies are accurate: people salute officers, and some poor guy at\nthe guardhouse spends his day saluting every car that comes through. Nobody\nsaluted me, of course—with long hair, jeans, and a beat up jacket, a Martian\nwould have been less conspicuous.\n\nAbout twenty people showed up, from all the three letter agencies. At last I\ncould hook voices from the telephone to people’s faces. Mike Gibbons actually\ndid look like an FBI agent—thirty years old or so, neatly pressed suit,\nmustache, and probably lifted weights in his spare time. We talked about\nmicrocomputers for a while—he knew the Atari operating system inside and out.\nJim Christy, the Air Force computer crime investigator, was tall, lanky, and\nexuded confidence. And there was Teejay, sitting over in the corner of the\nroom, silent as ever.\n\nBarrel-chested and smiling, Zeke Hanson of the NSA greeted me with a slap on\nthe back. He knew his way around both computers and bureaucracies.\nOccasionally, he whispered interpretations like, “That guy’s important to your\ncause” or “She’s just spouting the party line.” I felt uncomfortable among all\nthe suits, but with Zeke’s encouragement I managed to stand up and talk to the\ngathering.\n\nI babbled for a while, describing the network connections and weak spots, and\nthen the others discussed national policy on computer security. Seems that\nthere wasn’t any.\n\nThrough the whole meeting, people kept asking, “Who’s in charge?” I looked\nover at the contingent from the FBI. Mike Gibbons, the agent handling this\ncase, squirmed in his chair. Sitting next to Mike, George Lane of the FBI\nhandled the questions. “Since we can’t extradite the guy, the FBI isn’t going\nto devote many resources to this case. We’ve already done all we can.”\n\nThe DOE people didn’t let this slide. “We’ve been begging you to call the\nGermans. They’re begging you to contact them. But Bonn still hasn’t seen your\nwarrant.”\n\n“Uh, we’ve had a few problems in our Legat office, but that doesn’t concern us\nhere,” Lane said. “The bottom line is that there’s been no damage done by this\nhacker.”\n\nRuss Mundy, a wiry colonel from the Defense Communication Agency, could take\nit no longer. “No damage! This guy breaks into two dozen military computers\nand it’s no damage? He’s stealing computer time and network connections. Not\nto mention programs, data, and passwords. How long do we have to wait before\nhe gets into something really serious?”\n\n“But no classified data has been compromised,” the FBI agent said. “And how\nmuch money has been lost—75 cents of computer time in Berkeley?”\n\nI listened as the colonel tried a different approach. “We rely on our networks\nfor communications. Not just military people, but engineers, students,\nsecretaries, hell, even astronomers,” he said, gesturing towards me. “This\nbastard is undermining the trust that holds our community together.”\n\nThe FBI saw the hacker as a minor annoyance; perhaps just some kid messing\naround after school. The military people took it as a serious attack on their\ncommunications lines.\n\nThe Department of Justice backed up the FBI. “Germany won’t extradite a German\ncitizen, so why bother? And anyway, the FBI gets a hundred reports like this\nevery year, and we can prosecute only one or two.”\n\nHe went on to say that we already had enough evidence to convict the hacker:\nmy logbook and printouts would stand up at a trial. And according to U.S. law,\nwe didn’t have to catch the hacker _flagrante delicto:_ busting in on him\nwhile he was connected to a foreign computer. “So you really ought to close up\nshop. You’re not strengthening your case, and we already have enough evidence\nto bring him to trial.”\n\nIn the end, the Air Force OSI asked each group for direction. The FBI and\nDepartment of Justice wanted us to close up shop and lock the hacker out of\nour Berkeley computer. Neither Teejay of the CIA nor Zeke of NSA’s National\nComputer Security Center felt there was anything to gain by staying open.\n\nLeon Breault of the Department of Energy stood up. “We’ve got to support the\nguys in the trenches and catch this guy. If the FBI won’t, then we will,” he\nsaid, glaring at the Department of Justice attorney.\n\nThe people being hit by the hacker wanted to keep the monitoring going.\nClosing our monitoring station just meant that the hacker would prowl around\nusing a different, unobserved pathway.\n\nBut who should we turn to for help? The FBI didn’t want to touch the case. The\nmilitary groups had no authority to issue warrants.\n\nWhere was a clearinghouse for reporting problems? This hacker had shown us\nseveral novel computer security problems. Who should we report them to?\n\nWhy, to the National Computer Security Center, of course. But Zeke told me\notherwise: “We set standards for secure computers, and stay away from\noperational problems. All the same, we’re always willing to collect reports\nfrom the field.”\n\n“Yeah, but will you warn me about other’s problems?” I asked. “Will you send\nme a report describing security holes in my computer? Can you call me on the\nphone if someone’s trying to break into my computer?”\n\n“No, we’re an information collection point.” Just what I’d expect from a an\norganization run by NSA. The giant vacuum cleaner that sucks in information,\nyet never says a thing.\n\nSuppose I find a computer security problem, and it’s widespread. Perhaps I\nshould keep my mouth shut, and hope that nobody else figures it out. Fat\nchance.\n\nOr perhaps I should tell the world. Post a notice to lots of electronic\nbulletin boards saying, “Hey, you can break into any Unix computer by …” That\nwould at least wake up the folks who manage the systems. Maybe even prod them\ninto action.\n\nOr should I create a virus, one that takes advantage of this security hole?\n\nIf there were a trusted clearinghouse, I could report to them. They, in turn,\ncould figure out a patch for the problem, and see that systems are fixed. The\nNational Computer Security Center seemed like a logical place for this. After\nall, they specialize in computer security problems.\n\nBut they didn’t want to touch it. The NCSC was too busy designing secure\ncomputers. For the past few years, they’d published an unreadable series of\ndocuments describing what they meant by a secure computer. In the end, to\nprove that a computer was secure, they’d hire a couple programmers to try to\nbreak into the system. Not a very reassuring proof of security. How many holes\ndid the programmers miss?\n\nThe meeting at Bolling Air Force Base broke up with the FBI and Department of\nJustice dead set against our continuing to monitor the hacker. The CIA and NSA\ndidn’t say much, and the military groups and the Department of Energy wanted\nus to stay open. Since DOE paid our bills, we’d stay open, so long as an\narrest seemed likely.\n\nWhile I was around Washington, Zeke Hanson invited me to give a talk at the\nNational Computer Security Center. It’s just down the road from Fort Meade,\nNSA’s headquarters; even so, I got lost trying to find the place. There, under\nthe exhaust of Baltimore Airport, a guard inspected my backpack for floppy\ndisks, tape recorders, and viewgraphs.\n\n“Hey, what can I steal on a viewgraph?”\n\nThe guard scowled. “Them’s our orders. Make trouble and you won’t pass.” He\nhad a pistol on his side. OK.\n\nYou enter the meeting room through a door with a combination lock. Twenty\npeople greeted me, leaving one chair empty, up near the front of the room. Ten\nminutes into my talk, a thin, bearded fellow wandered into the room, sat down\nin front, and interrupted my description of Tymnet’s traces.\n\n“What’s the adiabatic lapse rate on Jupiter?”\n\nHuh? I’m talking about transatlantic networks, and this guy asks me about the\natmosphere of Jupiter? Well, hot dog—I can handle that.\n\n“Oh about two degrees per kilometer, at least until you reach the two hundred\nmillibar level.” By chance, this guy had asked me something straight from my\ndissertation.\n\nWell, I continued my story, and every ten minutes the bearded guy stood up,\nleft the room, and returned. He’d ask questions about the core of the moon,\nthe cratering history of Mars, and orbital resonances among the moons of\nJupiter. Weird. Nobody else seemed to mind, so I dovetailed my talk on the\nhacker with technical responses to this guy’s astronomical interrogation.\n\nAbout quarter to five, I finished up and was walking out of the room (with a\nguard standing nearby). The bearded guy pulled me aside and said to the guard,\n“It’s OK, he’s with me.”\n\n“What are you doing tonight?”\n\n“Oh, going out to dinner with an astronomer friend.”\n\n“Cool it. Tell him you’ll be a couple hours late.”\n\n“Why? Who are you?”\n\n“I’ll tell you later. Call your friend now.”\n\nSo I canceled my Friday evening dinner and was hustled into this guy’s dark\nblue Volvo. What’s happening here? I don’t even know his name and I’m\ntraveling down the road. Some sort of kidnapping, I guess.\n\n“I’m Bob Morris, the chief scientist at the Computer Security Center,” he said\nonce we were on the highway. “We’re going to Fort Meade, where you’ll meet\nHarry Daniels. He’s the assistant director of NSA. Tell him your story.”\n\n“But …”\n\n“Just tell him what happened. I called him out of a congressional meeting in\nWashington to meet you. He’s driving up here right now.”\n\n“But …” This guy wouldn’t let me get a word in.\n\n“Look, the atmosphere of Jupiter is fine—though I’d thought all atmospheres\nwere adiabatic so long as they convected—but we’ve got a serious problem on\nour hands.” Bob chain smoked and kept the windows rolled up. I gasped for\nbreath. He went on. “We’ve got to bring it to the attention of people who can\ndo something about it.”\n\n“Yesterday’s meeting at Bolling was supposed to resolve that.”\n\n“Just tell your story.”\n\nIf security at the Computer Security Center was tough, over at NSA’s\nheadquarters—well, it took ten minutes to clear me through. Bob had no\nproblem: “This badge lets me in anywhere, so long as I’m carrying a classified\ndocument.”\n\nHe entered a password and slid the card through the badge reader; meanwhile\nthe guard fumbled with my viewgraphs. By the time we got to the director’s\noffice, Harry Daniels had just arrived.\n\n“This had better be important,” he said, glaring at Bob. This guy looked\nimpressive—thin and about six-foot-six, he stooped when walking through doors.\n\n“It is. I wouldn’t have called you otherwise,” Bob said. “Cliff, tell him.”\n\nThere was no room on his table—it was covered with cryptography equipment—so I\nspread out a diagram of the hacker’s connections on the floor.\n\nHarry Daniels followed the chart meticulously. “Does he use the German Datex-P\nsystem to access the international record carriers?”\n\nHoly smoke! How does someone this important know communications networks in\nsuch detail? I was impressed. I described the hacker’s break-ins, but the two\nof them wouldn’t let me speak two sentences without interrupting with a\nquestion.\n\nBob Morris nodded and said, “Here’s your smoking gun, Harry.”\n\nThe NSA honcho nodded.\n\nThe two of them talked for a few minutes, while I played with a World War II\nJapanese encryption machine. I wished I’d brought my Captain Midnight Secret\nDecoder Ring to show them.\n\n“Cliff, this is important,” Harry Daniels said. “I’m not sure we can help you,\nbut you can sure help us. We’ve had a real problem convincing various entities\nthat computer security is a problem. We’d like you to talk to the National\nTelecommunications Security Committee. They make national policy, and we’d\nlike them to know about this.”\n\n“Can’t you just tell them?”\n\n“We’ve been telling them for years,” Harry Daniels said. “But this is the\nfirst documented case.”\n\nBob Morris continued. “Mind you, he said, ‘Documented.’ The only difference\nbetween your case and others is that you’ve kept a logbook.”\n\n“So this has been going on before?”\n\n“I wouldn’t have called Harry up from Washington if I didn’t think it was\nserious.”\n\nDriving back from Fort Meade, Bob Morris introduced himself. “I’ve worked on\nUnix security for the past ten years, up at Bell Labs in New Jersey.”\n\nWait a second. This must be the Morris that invented the Unix password\nprotection scheme. I’d read papers by him about securing computers. Of\ncourse—Bob Morris, the violinist. His eccentricity was legendary: I’d heard\nstories of him eating dessert and lying down so a cat could lick the whipped\ncream from his beard.\n\nBob continued. “Next month’s meeting will be for policy making. If we’re ever\ngoing to progress beyond writing standards documents, we’ve got to demonstrate\na danger to these people.” At last—someone at NSA who realized that computer\nsecurity meant more than designing computers. “Any system can be insecure. All\nyou have to do is stupidly manage it.”\n\n“Well, yes, that about sums it up,” I agreed. “Some of the problems are\ngenuine design flaws—like the Gnu-Emacs security hole—but most of them are\nfrom poor administration. The people running our computers don’t know how to\nsecure them.”\n\n“We’ve got to turn this around,” Bob said. “Secure computers might keep the\nbad guys out, but if they’re so balky that nobody will use ’em, it won’t be\nmuch progress.”\n\nTightening one computer was like securing an apartment house. But a network of\ncomputers, all sharing files and interchanging mail, well, this was like\nsecuring a small city. Bob, as chief scientist of the Computer Security\nCenter, directed that effort.\n\nBy the time we’d returned, I’d almost grown accustomed to riding in a smoke-\nfilled car. We started to argue about how planetary orbits interact—a subject\nthat I ought to be able to hold my own in. But this guy knew his celestial\nmechanics. Ouch. I’d been away from astronomy too long if I couldn’t bat off\nhis questions.\n\n\n![](images/Stol_9780307819420_epub_051_r1.jpg) It was neat to talk with Bob\nMorris. Still, I was glad to come back home to Martha. I caught the bus home\nfrom the airport and jaywalked across College Avenue—striking another blow for\nanarchy. My roommate, Claudia, was practicing her violin when I walked in the\ndoor.\n\nClaudia greeted me with a teasing smile. “Where have you been—running around\nwith loose women, I bet!”\n\n“Nope. Meeting dark, handsome spies with trench coats, in dark alleys.”\n\n“Did you bring one home for me?” Claudia was perpetually on the lookout for a\ngood man.\n\nI didn’t have time to get out a clever answer, because Martha caught me from\nbehind in a bear hug, and hoisted me into the air. “I missed you,” she said,\nsetting me down with a kiss. It’s fun, but a little startling, to live with a\nwoman who can beat me in a wrestling match.\n\nI was worried that she’d be mad that I had gone away again, but she shrugged.\n“You’re in time for dinner, so you’re fine. Get in the kitchen and help.”\n\nMartha was making her famous curry, which started with fresh coconut. I was\nout on the back porch whacking a coconut with a hammer when I heard Laurie\npull up on her motorcycle.\n\nLaurie was Martha’s best friend and college roommate. Despite her fierce\nexterior—crew cut, leather jacket, boots and black muscle shirt—she was a\ngentle country girl from New Mexico. She and Martha shared a special bond that\nmade me just slightly jealous. But I guess I passed her test, for she treated\nus both as family.\n\n“Hey, Cliffer,” she greeted me, mussing my hair. Looking hungrily at the\ncoconut, she guessed what we were having. She tromped inside, hugged Martha,\nwinked at Claudia, and scooped up the cat.\n\n“Put that lazy thing down and chop some onions.” Martha was kitchen despot.\n\nAt last, dinner was on the table: a platter of curried rice, and dishes of\nchopped vegetables, nuts, raisins, fruit, and chutney. If it grows, Martha\nwill curry it.\n\n“Hey, where’ve you been for the past couple days?” Laurie asked me.\n\n“Oh, I was summoned to Washington—the Reagans, you know, asked me to dinner,”\nI answered. I didn’t want to say that I’d just talked to a bunch of spies and\nspooks. Laurie hated the government, and I didn’t want to get her started.\n\n“Oh, do tell what Nancy was wearing,” Laurie simpered, taking a third helping\nof curry. “Hey, what’s the latest on that hacker that you were chasing?”\n\n“Oh, we haven’t caught him yet. Maybe never will.”\n\n“Still think he’s a Berkeley student?” I hadn’t talked to Laurie about this\nthing for a couple months.\n\n“Hard to say. For all I know, he’s coming from abroad.” I was getting nervous,\nsurprised at my own reluctance to tell a close friend what I’d been up to. I\nwasn’t ashamed, exactly, but …\n\n“Why are you spending so much time trying to catch some poor computer geek\nwho’s just fooling around?”\n\n“Fooling around? He broke into thirty military computers.” Whoops. Instantly,\nI wanted to unsay that.\n\n“So what? That sounds like a good reason not to chase him,” Laurie said. “For\nall you know, he’s a pacifist from the German Green Party. Maybe he’s trying\nto find out what secret weird things the military is doing, and expose them to\npublic scrutiny.”\n\nI’d thought of that months ago and worried about it then. By now I was certain\nthose weren’t his motives. I had done the obvious experiment: categorize his\ninterests. Back in January, I’d created a variety of different-flavored baits.\nAlongside the bogus SDINET files, I’d placed equally counterfeit files about\nBerkeley’s local politics. Other files appeared to be financial statements,\npayroll accounts, games, and academic computer science topics.\n\nIf he were a peace activist, he might look at those political files. A thief,\ninterested in ripping off our lab’s payroll, would go for the financial\nrecords. And I’d expect a student or computer nerd to reach for the games or\nacademic files. But he wasn’t interested in any of these.\n\nExcept the SDI files.\n\nThis experiment, and a lot of more subtle things about his way of operating,\nconvinced me that he was no idealist. This hacker was a spy.\n\nBut I couldn’t exactly prove that, and even after I explained my experiment to\nLaurie, she wasn’t convinced.\n\nShe still thought of anyone working against the military as one of “us,” and\nin her eyes I was persecuting someone on “our own” side.\n\nHow do I explain that, having been mixed up in this thing so long, I had\nstopped seeing clear political boundaries? All of us had common interests:\nmyself, my lab, the FBI, the CIA, NSA, military groups, and yes, even Laurie.\nEach of us desired security and privacy.\n\nI tried a different tack. “Look, it’s not a question of politics, but simple\nhonesty. This guy violated my privacy and the privacy of all the other users.\nIf someone broke into your house and rifled through your stuff, would you stop\nto ask if they were a fellow socialist?”\n\nThat didn’t work either. “A computer system isn’t private like a house,”\nLaurie responded. “Lots of people use it for many purposes. Just because this\nguy doesn’t have official permission to use it doesn’t necessarily mean he has\nno legitimate purpose in being there.”\n\n“It’s damned well exactly like a house. You don’t want someone poking around\nin your diary, and you sure as hell don’t want them messing with your data.\nBreaking into these systems is trespassing without permission. It’s wrong no\nmatter what your purpose is. And I have a right to ask these government\nagencies to help me get rid of this bastard. That’s their job!”\n\nMy voice had risen, and Martha looked anxiously from my angry face to\nLaurie’s. I realized that I sounded like a shotgun-toting redneck, yelling\nabout law and order. Or worse—was I so blindly patriotic that I thought anyone\nwho had an interest in military secrets was a traitor or a Commie spy?\n\nI felt trapped and confused, and, unfairly, felt it was all Laurie’s fault for\nbeing so simplistic and self-righteous. She hadn’t had to deal with this\nhacker, and hadn’t had to call on the CIA for help, hadn’t talked to them and\nfound they were real people. She thought of them as comic-book villains,\nkilling innocent peasants in Central America. And maybe some of them were. But\ndid that make it wrong to work with them at all?\n\nI couldn’t talk anymore. I got up, rudely pushing away my half-finished plate\nof curry. I stomped off to the garage, to sand some bookcases we were making,\nand sulk in peace.\n\nAfter an hour or so, it got harder to keep up the sulking. I thought of the\nfireplace, pie for dessert, and Laurie’s great back rubs. But, having grown up\nin a large, argumentative family, I was a dedicated, world-class sulker. I\nstayed in the cold garage, sanding furiously.\n\nI suddenly noticed that Laurie was standing quietly by the door. “Cliff,” she\nsaid softly, “I really didn’t mean to give you such a hard time. Martha’s\ncrying in the kitchen. Come on, let’s go inside.”\n\nI thought of how easily I hurt Martha with my temper. I didn’t want to spoil\nthe rest of the evening, so I went inside. We hugged, Martha wiped her face,\nand then served dessert. The rest of the evening, we talked brightly of other\nthings.\n\nBut the questions Laurie had stirred up inside me came back to haunt me\nthrough the night. I lay awake and wondered where all this was leading me, and\nwhat kind of person I was being turned into by this strange chase.\n\nI took flack from all directions, of course. The spooks didn’t trust me—I had\nno security clearance and didn’t work for a defense contractor.\n\nNobody had asked me to do this work, and we ran on zero budget. And how do I\ntell my Berkeley friends that I’d just returned from the CIA?\n\nSince we had neither funding nor authority, the three-letter agencies saw no\nreason to listen to us. I was little more than an annoyance to them. I felt\nlike a grad student again.\n\nA week after I’d returned, Mike Gibbons called from the FBI. “We’re closing\nour end of the investigation. There’s no reason for you to stay open.”\n\n“Mike, is that you speaking, or one of your bosses?”\n\n“It’s the FBI’s official policy,” Mike said, obviously annoyed.\n\n“Has the Legal Attaché ever talked to the Germans?”\n\n“Yes, but there’s confusion. The German federal police—the BKA—aren’t running\nthe phone traces, so not much information filters back to the legat’s office.\nYou might as well close up shop.”\n\n“What’ll that do for the rest of the sites the hacker decides to hit?”\n\n“Let them worry about it. Most of them won’t care anyway.”\n\nMike was right. Some of the places that had been broken into really didn’t\ncare if they’d been hit. The Pentagon’s Optimis database, for example. Mike\nhad notified them that a foreigner was using their computer. They didn’t bat\nan eyelash. Today, for all I know, anyone can read about the Army’s nuclear\nand biological warfare plans by logging onto their computer as _Anonymous_ ,\nwith password _Guest_.\n\nBut though the FBI wanted us to close up, the Department of Energy still\nsupported us. Halfway between, the CIA and NSA didn’t say one way or another.\n\nNo support either. For all that we’d told them, the NSA had never coughed up a\nnickel. And while it might seem fun to rub shoulders with secret agents, it\ndid little for my astronomy, and even less for my reputation.\n\nFor several weeks during February, the hacker evaporated. None of my alarms\nwent off, and his accounts remained dormant. Was he on to us? Had someone\ntipped him off to his impending arrest? Or was he sneaking through other\ncomputers?\n\nWhatever the answer, his disappearance relieved some of the pressure to\ndecide. For three weeks, I had nothing to report, so it made no difference if\nwe stayed open. Without a half dozen agencies on my neck, I managed to\nactually write some software during that time.\n\nThen, routinely scanning my monitor’s printouts, I noticed someone using the\nLawrence Berkeley Lab’s Petvax computer. It looked like they were entering the\nPetvax from a Caltech computer called Cithex.\n\nI’d been warned about Cithex—Dan Kolkowitz at Stanford had noticed German\nhackers using that system to break into his computers. So I looked closely at\nthe traffic from our Petvax to the Cithex computer.\n\nYeah. There it was. Someone had connected into the Caltech machine from the\nPetvax, and was trying to break into a place called Tinker, in Oklahoma.\n\nTinker? I looked it up in the Milnet directory. Tinker Air Force Base. Uh oh.\nA little bit later, there’s a connection into the Optimis database at the\nPentagon. Then he tries the Letterman Army Institute. The Comptroller of the\nArmy at Fort Harrison.\n\nOh hell. If it’s not the same hacker, then someone’s behaving just like him.\nThat’s why the hacker’s been quiet for three weeks. He’s been using a\ndifferent set of computers to get onto the Milnet.\n\nObviously, closing up my laboratory’s security holes won’t keep him off the\nnetworks. This pestilence would have to be eradicated at the source.\n\nThe Petvax, of all computers! An outsider would think it’s a toy—after all, a\npet Vax computer, no?\n\nHardly. Pet is an acronym for Positron Emission Tomography. It’s a medical\ndiagnostic technique to locate where oxygen is consumed in people’s brains. By\ninjecting a patient with an activated isotope, LBL’s scientists create images\nof the brain’s interior. All you need is a particle accelerator to create\nradioactive isotopes, a hypersensitive particle detector, and a powerful\ncomputer.\n\nThat computer is the Petvax. Stored within it are patient records, analysis\nprograms, medical data, and scans of people’s brains.\n\nThis hacker was playing games with medical tools. Break this computer, and\nsomeone’s going to get hurt. A bad diagnosis or a dangerous injection. Or\nwhat?\n\nThe doctors and patients who used this instrument needed it to work perfectly.\nThis was a sensitive medical device, not a plaything for some cyberpunk. Some\npoor computer geek, indeed.\n\nWas it the same hacker? Two minutes after he disconnected from the Petvax, he\nentered my Unix computer, using the name Sventek. Nobody else knew that\npassword.\n\nWe locked up the Petvax, changing its passwords and setting alarms on it. But\nthe incident worried me. How many other computers was this hacker slithering\nthrough?\n\nOn February 27, Tymnet forwarded some electronic mail from Wolfgang Hoffman of\nthe Bundespost. Apparently the German police can only arrest the hackers while\nthey’re connected. There’s no shortage of evidence to bring them to trial, but\nwithout positive identification, the charges won’t stick. We had to catch them\nred-handed.\n\nMeanwhile, one of the LBL computer masters described the whole incident to a\nprogrammer at the Lawrence Livermore Lab. He, in turn, sent out electronic\nmail to several dozen people, saying that he was going to invite me to give a\ntalk on “how we caught the German hackers.” Dumb.\n\nTen minutes after he posted his note, three people called me up, each asking,\n“I thought you were keeping this hush-hush. Why the sudden publicity?”\n\nTerrific. How do I undo this? If the hacker sees the note, it’s all over.\n\nJohn Erlichman observed that once you squeeze the toothpaste tube, it’s tough\nto get the stuff back in. I called Livermore; it took five minutes to convince\nthem to erase the message from all of their systems. But how do we prevent\nthis kind of leak in the future?\n\nWell, I could start by keeping my officemates better informed. From now on,\nevery week I told them what was happening and why we had to keep quiet. It\nworked remarkably well … tell people the truth, and they’ll respect your need\nfor secrecy.\n\nThe hacker showed up occasionally during March. Just often enough to upset my\nlife, but not quite enough to let the Germans nail him.\n\nThursday, March 12, was an overcast Berkeley day. Dry in the morning, so I\nbiked in without a raincoat. At 12:19, the hacker visited his old haunt for a\ncouple minutes. Listed a few of my SDINET files—he found out that Barbara\nSherwin had recently bought a car and that SDINET was expanding overseas. He\nsaw the names of thirty new documents, but he didn’t read them. Why not?\n\nSteve White had shown up in town, passing through to visit Ron Vivier at\nTymnet’s office in Silicon Valley. He and Martha and I had a date at a Thai\nrestaurant, so I had to be home by six.\n\nIt started to rain about four, and I realized that I would get drenched\nbicycling home. Not much choice in the matter, so I insanely biked home—the\nrain turned the bike’s brakes into banana peels. My raincoat wouldn’t have\nbeen much defense against the sheet of water thrown up by an old DeSoto.\nTraffic splashed me from the side, and my bike’s tires got me from below.\n\nBy the time I got home, I was sopping wet. Well, I’ve plenty of dry clothes.\nBut only one pair of shoes. The grungy sneakers I was wearing. And they were\nsoaked. I couldn’t dry ’em out in time, so I looked around. There’s Claudia’s\nnew microwave oven. I wonder …\n\nSo I popped the sneakers into Claudia’s microwave, and pressed a few buttons.\nThe display read “120.” I wondered whether that meant 120 seconds, 120 watts,\n120 degrees, or 120 light-years. I dunno.\n\nIt didn’t make any difference. I’d just watch the sneakers through the window\nand make sure nothing goes wrong. For the first few seconds, no problem. Then\nthe phone rang.\n\nI ran into the front room to answer it. It was Martha.\n\n“I’ll be home in half an hour, honey,” she said. “Don’t forget dinner with\nSteve White.”\n\n“I’m getting ready right now. Uh, Martha, how do I set the microwave oven?”\n\n“You don’t need to. We’re going out for dinner, remember?”\n\n“Suppose I want to dry out my sneakers,” I said. “What should I set on the\nmicrowave?”\n\n“Be serious.”\n\n“I am being serious. My sneakers are wet.”\n\n“Don’t you dare put them in the microwave.”\n\n“Well, theoretically speaking, how long should I hypothetically set the\nmicrowave for?”\n\n“Don’t even think about it. I’ll come home and show you how to dry them out.”\n\n“Well, uh, sweetheart, ” I tried to interrupt.\n\n“No. Don’t touch the microwave,” she said. “Just sit tight. Bye for now.”\n\nAs I hung up the phone, I heard four beeps from the kitchen. Uh oh.\n\nBolling out of the back of Claudia’s new Panasonic microwave oven was an angry\ncloud of thick, black smoke. The kind you see in newsreels, when the oil\nrefinery blows up. And the stench—it smelled like an old tire burning.\n\nI swung open the microwave, and another cloud of smoke belched out. I reached\nin and tried pulling out the sneakers—they still looked like sneakers, but had\nthe texture of hot mozzarella cheese. I tossed them and the glass tray out the\nkitchen window. The tray shattered in the driveway, and the smoldering\nsneakers lay seething next to the plum tree.\n\nNow I’m in deep yogurt. Martha’s due home in half an hour and the kitchen\nsmells like Akron during the tire-burning festival. Time to clean up the mess.\n\nI got out the paper towels and started scrubbing the microwave. Black soot all\nover. Not the kind of soot that washes away, either. Wiping the glop only\nspreads the black plague further.\n\nHalf an hour. How do you get rid of the delicate fragrance of burning rubber?\nI swung open the windows and door, letting the wind blow the stench away. It\ndidn’t do much for the smell, and now the rain was blowing in the windows.\n\nWhen you make a mess, cover it up. I remembered a homemakers’ column: to mask\nhousehold aromas, boil a small amount of vanilla on the stove. Well, it can’t\nmake things worse. I dump a couple of ounces of vanilla in a pan and crank up\nthe heat.\n\nSure enough, in a couple minutes, the vanilla works. The kitchen no longer\nsmells like a burning old blackwall tire. No, now it smells like a burning new\nwhitewall tire.\n\nMeanwhile, I’m cleaning the walls and ceiling. But I forgot the vanilla. The\nvanilla evaporates, the pot burns, and I’ve now screwed up twice. Three times,\nif you count the soggy floor.\n\nFifteen minutes. What to do? Appeasement. I’ll bake her some cookies. Reach\ninto the refrigerator for last night’s cookie dough, and slap lumps of it onto\na cookie pan. Set the oven at 375, just right for chocolate chips.\n\nWell, a third of the cookies slid off the pan and stuck on the bottom of the\noven where they turned to cinders.\n\nMartha walks in, takes one sniff, sees the black welt on the ceiling, and\nsays, “You didn’t.”\n\n“I’m sorry.”\n\n“I told you.”\n\n“I’m sorry twice.”\n\n“But I said …”\n\nThe doorbell rings. Steve White enters, and with British aplomb says, “I say,\nold chap. Is there a tire factory nearby?”\n\n\n![](images/Stol_9780307819420_epub_052_r1.jpg) Through March and early April,\nthe hacker laid low. Occasionally, he’d pop in, just long enough to keep his\naccounts on the active list. But he seemed uninterested in reaching into other\ncomputers, and pretty much ignored my new SDINET files. What was happening to\nthis guy? If he’s been arrested, he wouldn’t show up here. And if he’s busy on\nother projects, why does he just show up for a minute, then disappear?\n\nOn April 14, I was working on the Unix system when I noticed Marv Atchley\nlogged into the system.\n\nOdd. Marv’s upstairs, giving a pep talk to some programmers. I wandered over\nto his cubicle and looked at his terminal. Not even turned on.\n\nWho’s using Marv’s account? I ran over to the switchyard and saw someone\ncoming in through our Tymnet port. They were connected into the system as Marv\nAtchley.\n\nI called Tymnet—Steve traced the line quickly. “It’s from Hannover, Germany.\nAre you sure it’s not the hacker?”\n\n“Hard to say. I’ll call you right back.”\n\nI ran up four flights of stairs and peered into the conference room. Yep,\nthere was Marv Atchley, giving an animated talk to twenty-five programmers.\n\nBy the time I returned to the switchyard, the pseudo-Marv was gone. But I\ncould see that he’d entered the system without any tricks. Otherwise he would\nhave set off my alarms. Whoever it was must know Marv’s password.\n\nWhen the meeting ended, I showed the printout to Marv.\n\n“Damned if I know who it is. I sure never gave my password to anyone.”\n\n“How long since you changed it?”\n\n“Oh, a few weeks ago.”\n\n“And what’s your password?”\n\n“Messiah. I’ll change it right now.”\n\nHow the hell did this hacker get Marv’s password? I would have noticed if he’d\nset a Trojan horse. Could he have guessed the word “Messiah”?\n\nUh oh. There’s a way he could have.\n\nOur passwords are stored encrypted. You can search the entire computer, and\nyou’ll never find the word “Messiah.” You will find it encrypted as\n“p3kqznqiewe.” Our password file was filled with such encrypted gibberish. And\nthere’s no way to reconstruct the avocado from that guacamole.\n\nBut you can guess passwords. Suppose the hacker tried to log in as Marv, then\ntried the password “Aardvark.” My system says, “no good.” The hacker, being\npersistent, then tries again, using the password “Aaron.” Again, no luck.\n\nOne by one, he tries to log on using passwords that he looks up in a\ndictionary. Eventually, he tries the password “Messiah.” The door opens wide.\n\nEach trial takes a couple seconds. His fingers would wear out before he tried\nthe whole dictionary. Such a brute-force method of guessing passwords will\nonly work on a completely mismanaged computer.\n\nBut I saw this hacker copy our password file into his own computer. How could\nhe use a list of our encrypted passwords?\n\nThe Unix password scheme uses an encryption program that’s public. Anyone can\nget a copy of it—it’s posted to bulletin boards. With a hundred thousand Unix\ncomputers in the world, you couldn’t keep the program secret.\n\nThe Unix encryption program works in one direction only: it will encrypt from\nEnglish text into gibberish. You can’t reverse the process to translate\nencrypted passwords into English.\n\nBut with this encryption program, you can encrypt every word in the\ndictionary. Make a list of encrypted English words from your dictionary. Then,\nit’s a simple matter to compare what’s in my password file to your list of\nencrypted passwords. This must be how the hacker is cracking passwords.\n\nOn his computer in Hannover, he’d run the Unix password encryption program.\nHe’d feed it the whole dictionary, and one by one, his program would encrypt\nevery word in the English language. Something like this:\n\nAardvark encrypts to “vi4zkcvlsfz.” Is that the same as “p3kqznqiewe”? No, so\ngo on to the next word in the dictionary.\n\nAaron encrypts to “zzole9cklg8.” Not the same as “p3kqznqiewe,” so go on to\nthe next word in the dictionary.\n\nEventually, his program would discover that Messiah encrypts to “p3kqznqiewe.”\n\nWhen his program found a match, bingo—it would print it out.\n\nMy hacker was cracking passwords using a dictionary. He could find anyone’s\npassword, so long as it was an English word.\n\nThis was serious stuff. It meant that every time I’d seen him copy a password\nfile, he could now figure out legitimate users’ passwords. Bad news. I checked\nmy logbook. He’d copied these files from our Unix computer, the Anniston\nsystem, and the Navy Coastal Systems Command. I wondered if he’d be back in\nthose computers.\n\nHey—I’d proven that he was cracking passwords on his computer. There are\naround a hundred thousand words in an English dictionary. It had been about\nthree weeks since he copied my password file. If his password cracker worked\ncontinually for three weeks, could he have guessed Marv’s password?\n\nWell, on an ordinary Vax computer, it takes about a second to encrypt one\npassword. A hundred thousand words, then, would take around a day. On an IBM\nPC, maybe a month. A Cray supercomputer might take an hour.\n\nBut according to Marv, this guy less did it in three weeks. So he wasn’t using\na little home computer. He must be running the password cracker on a Vax or a\nSun workstation. I had to be careful about this conclusion, though. He might\nuse a faster algorithm or have waited a few days after cracking Marv’s\npassword.\n\nStill, I patted myself on the back. Just by noticing that he’d been cracking\npasswords, I knew what type of computer he was using. Remote-control detective\nwork.\n\nThis explained why he’d always copied our password files to his system. He was\ncracking our passwords in Germany.\n\nEven one guessed password was dangerous. Now, if I erased Sventek’s account,\nhe could sneak in on someone else’s account. Good thing that I’d not closed\nthe door on him. What I’d thought to be bulletproof—my passwords—turned out to\nbe riddled with holes.\n\nPassword cracking. I’d not come across it before, but I suppose that experts\nhad. Well, what do the experts say about it? I called Bob Morris, the big shot\nI’d met at NSA. He’d invented the Unix password encryption system.\n\n“I think the hacker’s cracking my passwords,” I told Bob.\n\n“Eh?” Bob was obviously interested. “Is he using a dictionary or has he\nactually reversed the data encryption algorithm?”\n\n“A dictionary, I think.”\n\n“Big deal. Why, I’ve got three good password cracking programs. One of them\nwill pre-compute the passwords, so it runs a couple hundred times faster. Want\na copy?”\n\nEgads, he was offering me a copy of a password-cracking program! “Uh, no, I\ndon’t think so,” I said. “If I ever need to decrypt passwords, though, I’ll\ncall you. Say, how long have people known about password cracking?”\n\n“This kind of brute force stuff? Oh maybe five or ten years. It’s child’s\nplay.”\n\nCracking passwords as a game? What kind of a guy is this?\n\nBob continued. “Guessing won’t work when you choose good passwords. Our real\nconcern is with the encryption programs. If someone figures out a way to\nreverse that software, we’re in deep trouble.”\n\nI now understood what he meant. The program that translated “Messiah” into\n“p3kqznqiewe” is a one-way street. It needs just a second to encrypt your\npassword. But if someone found a way to crank that sausage machine backwards—a\nway to convert “p3kqznqiewe” into “Messiah,” then they could figure out every\npassword, without guessing.\n\nWell, I’d at least told the NSA. Maybe they’d known these techniques for\nyears, but now they officially knew that someone else was using them. Would\nthey publicize it? Come to think of it, if NSA had known of this for ten\nyears, why hadn’t they publicized it already?\n\nSystems designers needed to know about this problem—to build stronger\noperating systems. Computer managers ought to know, too. And every person who\nused a password should be warned. It’s a simple rule: don’t pick passwords\nthat might show up in a dictionary. Why hadn’t anyone told me?\n\nThe National Computer Security Center didn’t seem interested in real-world\nproblems of thousands of Unix computers out in the field. I wanted to know\nabout weaknesses in my Unix system. What problems had been reported? Before,\nI’d discovered a bug in the Gnu-Emacs editor. A widespread security hole. I’d\ndutifully reported it to the National Computer Security Center. But they never\ntold anyone about it. Now, I’d discovered that passwords that appeared in\ndictionaries weren’t safe.\n\nHow many other security holes were lurking in my system?\n\nThe NCSC might know, but they weren’t saying.\n\nNSA’s motto, “Never Say Anything,” seemed to come into play. Yet by keeping\nsilent about these computer security problems, they hurt us all. I could see\nthat the hackers had long ago discovered and exploited these holes. Why wasn’t\nsomeone telling the good guys?\n\n“It’s not our bailiwick,” Bob Morris said. “We collect this information so as\nto better design future computers.”\n\nSomewhere, somehow, something was wrong here. The guys in black hats knew the\ncombinations to our vaults. But the white hats were silent. Well, forget the\nNSA for now. What more could I do? It was time to prod the other agencies.\n\nBy late April the Bundespost still hadn’t received the proper papers from the\nUnited States. Their traces were based on an official complaint filed by the\nUniversity of Bremen.\n\nBut although the Bundespost had completed several traces, they wouldn’t tell\nme the suspects’ names or phone numbers. German law prohibited this. Sounded\nfamiliar. Briefly, I wondered if my sister Jeannie would be willing to snoop\naround Hannover. She’d been the most responsive investigator so far.\n\nI phoned Mike Gibbons. “We’re no longer handling this as a criminal case,” he\nsaid.\n\n“Why give up when the Germans have traced the line and know the suspects’\nnames?”\n\n“I didn’t say we were giving up. I just said that the FBI isn’t treating this\nas a criminal case.”\n\nWhat did that mean? As usual, Mike clammed up when I asked questions.\n\nHad the Air Force made much progress? They were quietly getting the word out\nthat reptiles were crawling through the Milnet, trying to break into military\ncomputers. One by one, sites were tightening up security.\n\nBut the Air Force relied on the FBI to catch the hacker. Ann Funk and Jim\nChristy wished they could help, but couldn’t.\n\n“Tell me anything except, ‘It’s not my bailiwick,’ ” I said.\n\n“OK,” Ann replied, “it’s not within my command.”\n\n\n![](images/Stol_9780307819420_epub_053_r1.jpg) I didn’t like leaving Berkeley,\npartly because I missed my sweetheart, but also because it left the hacker\nunwatched.\n\nI was to talk to the NTISSIC, a governmental organization whose acronym has\nnever been decoded. Bob Morris said they set policy for telecommunications and\ninformation security, so I could guess some of the letters.\n\n“While you’re in the area,” Teejay said, “how about stopping by our\nheadquarters in Langley?”\n\nMe? Visit the CIA? I’m in way over my head now. Meeting the spooks on their\nown ground. I could just imagine it: hundreds of spies in trench coats,\nskulking around hallways.\n\nThen the NSA invited me to Fort Meade as well. But not quite so informally.\nOver the phone, Zeke Hanson said, “We’d like you to prepare a talk for the X-1\ndepartment. They’ll send you questions in advance.”\n\nDepartment X-1 of the National Security Agency? Yow, now this was cloak-and-\ndagger. As usual, I couldn’t get any more information out of them … Zeke\nwouldn’t even tell me what X-1 stood for.\n\nWell, I arrived at NSA, and Bob Morris greeted me in his office. The three\nchalkboards were covered with Russian writing (“They’re rhyming riddles,” he\nexplained) and a few mathematical equations. Where else but at NSA?\n\nI chalked a short note in Chinese, and Bob hit me with an easy number problem:\nOTTFFSS. “What’s the next letter, Cliff?”\n\nThat was an oldie. One. Two. Three. Four. Five. Six. Seven. “The next letter\nis E for Eight,” I announced.\n\nWell, we fooled around with puzzles and palindromes for a while, until he\nwrote out this series of numbers: 1, 11, 21, 1211, 111221.\n\n“Complete that series, Cliff.”\n\nI looked at it for five minutes and gave up. I’m sure it’s easy, but to this\nday, I still haven’t solved it.\n\nIt was weird. Here I was, hoping to light a fire under NSA’s feet. And here\nwas Bob Morris, their top guru, competing with me in number games. Fun, sure.\nBut disquieting.\n\nWe drove down to Washington, to the Department of Justice. We talked about\ncomputer security, and I pointed out to him that, for all he knew, I could be\nmaking up this whole story.\n\n“You don’t have a way of checking up on me.”\n\n“We don’t need to. NSA is a house of mirrors—each section checks on another\nsection.”\n\n“You mean you spy on yourself?”\n\n“No, no, no. We constantly check our results. For instance, when we solve a\nmathematical problem by theoretical means, we check the result on a computer.\nThen another section might try to solve the same problem with a different\ntechnique. It’s all a matter of abstraction.”\n\n“Think anyone will mind that I don’t have a tie?” I’d worn a clean pair of\njeans, figuring there might be some important people. But I still didn’t own a\nsuit or tie.\n\n“Don’t worry,” Bob said. “At your level of abstraction, it doesn’t make any\ndifference.”\n\nThe meeting was top secret, so I couldn’t listen—someone fetched me when my\nturn came. In a small room, lit only by the viewgraph machine, there were\naround thirty people, most of them in uniforms. Generals and admirals, like\nyou see in the movies.\n\nWell, I talked for half an hour, describing how the hacker was breaking into\nmilitary computers and skipping through our networks. One general in the back\nkept interrupting with questions. Not easy ones, like, “When did you discover\nthis guy?” but toughies, like “How can you prove that electronic mail hasn’t\nbeen forged?” and “Why hasn’t the FBI solved this case?”\n\nWell, the questions didn’t let up for another half hour, when they finally let\nme off the rack. Over cheese sandwiches, Bob Morris explained what had\nhappened.\n\n“I’ve never seen so many brass in one room before. You know, that one guy who\nasked the good questions—he’s one of the junior people in the room. Just a\nMajor General.”\n\nI know as little about the military world as the next person. “I guess I’m\nimpressed, though I’m not sure why,” I said.\n\n“You ought to be,” Bob said. “These are all flag officers. General John Paul\nHyde works at the Joint Chiefs of Staff. And that guy in the front row—he’s a\nbig shot from the FBI. It’s a good thing he heard you.”\n\nI wasn’t so sure. I could imagine a honcho in the FBI having a rough time of\nit: he knows that his agency ought to be doing something, yet something gets\ncorked up. He didn’t need flack from some Berkeley longhair; he needed our\nsupport and cooperation.\n\nI was suddenly queasy. I pressed the replay button in my mind. Did I screw up?\nIt’s a weird feeling of being nervous after you do something. The more I\nthought about it, the more impressed I was with the military people. They’d\nzeroed in on the weak points of my talk, and understood both the details and\nimportance of what I’d said.\n\nHow far I’d come. A year ago, I would have viewed these officers as war-\nmongering puppets of the Wall Street capitalists. This, after all, was what\nI’d learned in college. Now things didn’t seem so black and white. They seemed\nlike smart people handling a serious problem.\n\nThe next morning I was to speak at NSA’s X-1 department. Sure enough, they’d\nprepared a list of questions, and asked me to concentrate on the following\nthemes:\n\n1\\. How was the penetrator tracked?\n\n2\\. What auditing features exist?\n\n3\\. How to audit someone with system-level privilege?\n\n4\\. Supply technical details on how to penetrate computers.\n\n5\\. How were passwords obtained for the Livermore Crays?\n\n6\\. How were super-user privileges obtained?\n\n7\\. Did the penetrator guard against detection?\n\nI stared at these questions, and gulped. Oh, I understood what the NSA folks\nwere asking me, but there was something wrong here.\n\nWas it that the answers to these questions could be used to break into\nsystems? No, that wasn’t my objection. They covered essentially defensive\ntopics.\n\nOr did I object to NSA’s role of gathering information but not sharing it with\nanyone else? No, not really. I had resigned myself to that.\n\nReading them a third time, I sensed that they showed an underlying assumption\nthat I found offensive. I scratched my head, wondering what was annoying me.\n\nFinally I realized what galled me about their questions.\n\nIt wasn’t the content of the question, it was their intrinsic neutrality. They\nassumed an impersonal adversary—a sanitized “penetrator.” They implied that\nthis was an emotionless, technical problem, to be solved by purely technical\nmeans.\n\nSo long as you think of someone ripping you off as a “penetrator,” you’ll\nnever make any progress. As long as they remained impersonal and detached, the\nNSA people would never realize that this wasn’t just a computer being\npenetrated, but was a community being attacked.\n\nAs a scientist, I understood the importance of remaining detached from an\nexperiment. But I’d never solve the problem until I got involved; until I\nworried about the cancer patients who might be injured by this guy; until I\nbecame angry that this hacker was directly threatening all of us.\n\nI rephrased the questions and scribbled a new viewgraph:\n\n1\\. How does this scoundrel break into computers?\n\n2\\. Which systems does he slither into?\n\n3\\. How did this bastard become super-user?\n\n4\\. How did the louse get passwords to the Livermore Cray?\n\n5\\. Did the skunk guard against detection?\n\n6\\. Can you audit a varmint who’s system manager?\n\n7\\. How do you trace an eggsucker back to his roost?\n\nNow _those_ questions, I can answer.\n\nThese NSA spooks spoke in morally null jargon, while I felt genuine outrage.\nOutrage that I was wasting my time following a vandal instead of doing\nastrophysics. Outrage that this spy was grabbing sensitive information with\nimpunity. Outrage that my government didn’t give a damn.\n\nSo how do you pump up a bunch of technocrats when you’re a longhaired\nastronomer without a tie? Or without any security clearance? (There must be\nsome rule like, “No suit, no shoes, no clearance.”) I did my best, but I’m\nafraid that the NSA people were more interested in the technology than any\nethical implications.\n\nAfterwards they showed me a few of their computer systems. It was a bit\ndisconcerting: every room I walked into had a flashing red light on the\nceiling. “It warns everyone not to say anything classified while you’re here,”\nI was told.\n\n“What’s the meaning of section X-1?” I asked my guide.\n\n“Oh, that’s boring,” she replied. “NSA has twenty-four divisions, each with a\nletter. X is the secure software group. We test secure computers. X-1 are the\nmathematical folks who test software theoretically—trying to find holes in its\ndesign. X-2 people sit at the computer, trying to break software once it’s\nwritten.”\n\n“So that’s why you’re interested in computer weaknesses.”\n\n“Yeah. One division of NSA may spend three years building a secure computer.\nX-1 will examine its design and then X-2 will bang on it, searching for holes.\nIf we find any, we’ll return it, but we won’t tell them where the bug is. We\nleave it for them to puzzle out.”\n\nI wondered if they would have picked up the problem with Gnu-Emacs.\n\nAlong the way, I asked several people at NSA if there was any way that they\ncould support our work. Individually, they regretted that our funding came\nentirely out of physics grants. Collectively, though, they offered no help.\n\n“It would be easier if you were a defense contractor,” one spook told me. “NSA\nshies away from academics. There seems to be a kind of mutual distrust.” So\nfar, my total outside support was $85, an honorarium for speaking at the San\nFrancisco Bay Technical Librarians’ Association.\n\nThe tour of NSA lasted well into lunch, so I left Fort Meade late, and got\nplenty lost on my way to the CIA in Langley, Virginia. Around 2 P.M., I found\nthe unmarked turnoff and pulled up to the gatehouse, an hour late.\n\nThe guard stared at me like I’d recently arrived from Mars. “Who are you here\nto see?”\n\n“Teejay.”\n\n“Your last name?”\n\n“Stoll.” The guard looked over her clipboard, handed me a form to fill out,\nand slipped a blue pass on the rental car’s dashboard.\n\nA VIP parking pass from the CIA. That’s gotta be worth $5.00 back in Berkeley.\nMaybe $10.00.\n\nMe? A VIP? At the CIA? Surreal. I dodged a few joggers and bicycles on my way\nto the VIP lot. An armed guard assured me that I didn’t have to lock the car\ndoors. In the background, the seventeen-year locusts were buzzing and a\nmallard quacked. What’s a flock of ducks doing at the portals of the CIA?\n\nTeejay hadn’t said how technical a talk he wanted, so I stuffed my viewgraphs\ninto a grungy envelope. Then, off to the CIA building.\n\n“You’re late,” Teejay called from across the foyer. What do I tell him? That I\nalways get lost on freeways?\n\nIn the middle of the foyer’s floor is a five-foot-diameter seal of the CIA, a\nterrazzo eagle set behind an official seal. I expected everyone to walk around\nthe grey symbol, just as the high school students do in _Rebel Without a\nCause_. No such luck. Everyone walks on top of it, showing the poor bird no\nrespect.\n\nOn the wall, there’s a marble inscription, “The Truth Shall Set You Free.” (I\nwondered why they’d use Caltech’s motto—then I noticed the quote came from the\nBible.) Four-dozen stars were engraved on the opposite wall—I could only guess\nabout the forty-eight lives they represented.\n\nAfter a ritualistic search of my belongings, I received a fluorescent red\nbadge with a V. The visitor tag wasn’t necessary—I was the only guy around\nwithout a tie. Not a trench coat in sight.\n\nThe atmosphere was that of a subdued campus, with people strolling the\nhallway, practicing languages, and arguing around newspapers. Every once in a\nwhile, a couple would wander by, arm in arm. This was a long way from Boris\nand Natasha cartoons.\n\nWell, not exactly like a campus. As Teejay showed me to his first-floor\noffice, I noticed that each door was a different color, but none had cartoons\nor political posters on them. Some, however, had combination locks, almost\nlike bank vaults. Even the electrical boxes had padlocks.\n\n“Because you’re late, we’ve rescheduled the meeting,” Teejay said.\n\n“I’ve got to select viewgraphs,” I said. “How technical a talk should I give?”\n\nTeejay gave me the hairy eyeball and said, “Don’t worry about it. You won’t\nneed viewgraphs.”\n\nI sensed trouble ahead. No escaping this time. While sitting around Teejay’s\ndesk, I discovered that he had a fantastic set of rubber stamps. Real “TOP\nSECRET” stamps, along with things like “CLASSIFIED,” “EYES ONLY,”\n“COMPARTMENTALIZED INTELLEGENCE,” “SHRED AFTER READING,” and “NOFORN.” I\nfigured the last one meant “No Fornicating,” but Teejay set me straight: “No\nForeign Nationals.” I stamped each one on a sheet of paper, and stuffed it in\nmy pack of viewgraphs.\n\nGreg Fennel, the other spook who had visited me in Berkeley, stopped by and\ntook me up to the CIA’s computer room. More like a stadium. In Berkeley, I was\naccustomed to a dozen computers in a big room. Here, there were hundreds of\nmainframe computers packed tightly together in a huge cavern. Greg pointed out\nthat, outside of Fort Meade, it’s the world’s largest computer installation.\n\nAll IBM mainframes.\n\nNow, among Unix aficionados, big IBM systems are throwbacks to the 1960s, when\ncomputing centers were the rage. With desktop workstations, networks, and\npersonal computers, Goliath centralized systems seem antiquated.\n\n“Why all this IBM stuff?” I asked Greg. “Those things are dinosaurs.” I\nsnidely showed my Unix bias.\n\n“Well, we’re changing,” Greg answered. “We’ve got a dedicated artificial\nintelligence group, active robotics researchers, and our image-processing lab\nreally cooks.”\n\nI remembered proudly showing Teejay and Greg through my lab’s computing\nsystem. Suddenly, I felt incredibly embarrassed—our five Vaxes, scientific\nworkhorses to us, seemed mighty puny next to these.\n\nYet our purposes were different. The CIA needs a giant database system—they\nwant to organize and associate lots of diverse data. We needed number\ncrunchers: computers that were fast with math. It’s always tempting to measure\nthe speed of a computer or the size of its disks, and then conclude that “this\none is better.”\n\nThe question isn’t, “Which computer is faster,” no, not even, “Which is\nbetter.” Instead, ask, “Which is more suitable?” or “Which will get your job\ndone?”\n\nAfter touring the CIA’s computing division, Teejay and Greg took me up to the\nseventh floor. The staircase is labeled with the floor numbers in different\nlanguages: I recognized the fifth floor (Chinese) and the sixth floor\n(Russian).\n\nI was shown to an anteroom with a Persian rug on the floor, Impressionist art\non the walls, and a bust of George Washington in the corner. A real mixed bag.\nI settled down into a sofa with Greg and Teejay. Across from us were two other\nguys, each with a picture badge. We talked a bit—one of the guys spoke fluent\nChinese; the other had been a veterinarian before joining the CIA. I wondered\nwhat kind of talk I was expected to give.\n\nThe office door swung wide, and a tall, gray-haired man called us in. “Hi, I’m\nHank Mahoney. Welcome in.”\n\nSo this is the meeting. It turns out that the seventh floor is the hide-out\nfor the CIA’s high-muckity-mucks. Hank Mahoney’s the CIA’s deputy director;\ngrinning nearby was Bill Donneley, the assistant director, and a couple\nothers.\n\n“You mean that you’ve heard about this case?”\n\n“We’ve been following it daily. Of course, this case alone may not seem like\nmuch. But it represents a serious problem for the future. We appreciate your\ntaking the effort to keep us informed.” They presented me with a certificate\nof appreciation—wrapped up like a diploma.\n\nI didn’t know what to say, so I stammered out my thanks and looked at Teejay,\nwho was chuckling. Afterward, he said, “We wanted to keep it a surprise.”\n\nSurprise? Jeez—I’d expected to walk into a room of programmers and give a\nshoptalk on network security. I glanced at the certificate. It was signed by\nWilliam Webster, director of the CIA.\n\nOn my way out, sure enough, the guards searched my stack of view-graphs.\nHalfway down, there was that page of paper with its telltale stamp, “TOP\nSECRET.” Uh oh.\n\nRed alert—visitor caught leaving CIA with document stamped “TOP SECRET”!\nNothing else on the page, of course. Five minutes of explaining and two phone\ncalls later, they let me out. But not without confiscating the rubber stamp\nsampler. And a lecture on how “we take security seriously around here.”\n\nI flew back to Berkeley, sitting next to Greg Fennel, who was flying west for\nsome secret business. Turns out that his background is astronomy—he used to\nrun an observatory. We talked a bit about Space Telescope, the billion-dollar,\nhigh-precision instrument that’s soon to be launched.\n\n“With a ninty-four-inch telescope in space, we’ll be able to see phenomenal\ndetail on planets,” I remarked.\n\n“Just think what you could do if you pointed it at the earth,” Greg said.\n\n“Why bother? All the interesting things are in the sky. And anyway, the Space\nTelescope physically can’t point to the earth. Its sensors will burn out if\nyou try.”\n\n“What if someone made such a telescope and pointed it to the earth. What could\nyou see?”\n\nI fiddled a few numbers in my head. Say, three hundred miles up in orbit, a\nninty-four-inch telescope. The wavelength of light is about four hundred\nnanometers.… “Oh, you could easily see detail of a couple feet across. The\nlimit would be around a couple inches. Not quite good enough to recognize a\nface.”\n\nGreg smiled and said nothing. It took a while, but it eventually sunk in: the\nastronomical Space Telescope wasn’t the only big telescope in orbit. Greg was\nprobably talking about some spy satellite. The secret KH-11, most likely.\n\nI returned home, wondering if I should tell Martha what happened. I didn’t\nfeel any different—I’d still rather be doing astronomy than chasing some\nhacker—but I worried that Martha might not approve of who I’d been rubbing\nshoulders with.\n\n“Have fun?” she asked when I returned.\n\n“Yeah, in a weird way,” I answered. “You don’t want to know who I met.”\n\n“Makes no difference. You’ve been crunched up in an airplane all day. Let me\nrub your back.”\n\nHome sweet home.\n\n\n![](images/Stol_9780307819420_epub_054_r1.jpg) I still seethed with\nfrustration when I thought of the eight months that we’d been stuck to this\ntar baby. My boss wouldn’t let me forget that I was doing nothing useful.\n\nThen on Wednesday, April 22, Mike Gibbons called to say that FBI Headquarters\nhad decided we should keep monitoring the hacker. It seems the German police\nwanted to catch this guy; the only way this could happen was if we notified\nthe Germans immediately when our alarms sounded.\n\nMeanwhile, the FBI had put in an official request for cooperation and speedy\ntelephone traces. They were talking to the administrator of justice in\nGermany, via the U.S. State Department.\n\nWell, yippee. Why this sudden change in policy? Had the NTISSIC committee made\na decision? Or was it due to my constant pestering? Or had the Germans finally\ncontacted the FBI?\n\nAlthough the FBI was only now interested, I’d never disabled my monitoring\nstation. Even when I was away for a couple days, the monitors remained on\nguard. Last week’s printouts showed him on the system from 9:03 to 9:04 A.M.\non Saturday, April 19. Later that day, he appeared again for a couple minutes.\nQuiet for a few days, then he popped up, checked that the SDINET files were\nstill around, and left.\n\nFor the past month, I’d been leaving new bait for the hacker. He saw it—at\nleast he glanced at the names of the files—but he didn’t read any of it. Was\nhe worried that he was being watched? Did he know?\n\nBut if he thought we were watching him, he’d be a fool to show up at all.\nMaybe he couldn’t afford longer connections? No, the Bundespost told us that\nhe was charging these calls to a small company in Hannover.\n\nThroughout the spring, I kept making new bait. To an outsider, the bogus\nSDINET files were the product of a functioning office. My mythical Barbara\nSherwin created memos and letters, requisitions and travel orders. Here and\nthere she sprinkled a few technical articles, explaining how the SDI network\ninterconnected all sorts of classified computers. One or two notes implied\nthat you could use the LBL computers to link into the network.\n\nEveryday, I wasted an hour juggling these SDINET files. My hopes were to keep\nthe hacker occupied here, rather than going out into military systems. At the\nsame time, it gave us an opportunity to trace the hacker.\n\nOn Monday, April 27, I’d biked in late and began writing a program to let our\nUnix system talk to Macintosh computers on people’s desk tops. If I could\nconnect those together, any of our scientists could use the Macintosh’s\nprinter. A fun project.\n\nBy 11:30, I’d fouled up two programs—what had worked an hour ago wasn’t\nworking now—when Barbara Schaefer called from five floors upstairs.\n\n“Hey, Cliff,” the astronomer said, “a letter just arrived for Barbara\nSherwin.”\n\n“Be serious.” For once, it was my turn to say that.\n\n“Really. Come on up and let’s open it.” I had told Barbara about the dummy\nSDINET project and mentioned that I was using her mailbox as a mail drop. But\nI never really expected the hacker to actually send something in the mail.\n\nGood grief! Had this hacker greeted us with a letter?\n\nI ran up the five flights of stairs—the elevator’s too slow. Barb and I looked\nat the letter. Addressed to Mrs. Barbara Sherwin, SDINET project, Mail Stop\n50-351, LBL, Berkeley, CA. Postmarked from Pittsburgh, Pennsylvania.\n\nMy heart was thumping from the run up the stairs, but I felt the adrenaline\nrush when I saw that envelope.\n\nWe carefully slit the envelope and shook out this letter:\n\nTriam International, Inc.  \n6512 Ventura Drive  \nPittsburgh, PA 15236  \nApril 21, 1987\n\nSDI Network Project  \nLBL, Mail Stop 50-351  \n1 Cyclotrov Road  \nBerkley, California 94720  \nATTENTION: Mrs. Barbara\n\nSherwin  \nDocument  \nSecretary\n\nSUBJECT: SDI Network Project\n\nDear Mrs. Sherwin:\n\nI am interested in the following documents. Please send me a price list and an\nupdate on the SDI Network Project. Thank you for your cooperation.\n\nVery truly yours,  \nLaszlo J. Balogh\n\n#37.6 SDI Network Overview Description Document, 19 pages, December 1986\n\n#41.7 SDI Network Functional Requirement Document, 227 pages, Revised\nSeptember 1985\n\n#45.2 Strategic Defense Initiations and Computer Network Plans and\nImplementations of Conference Notes, 300 pages, June 1986\n\n#47.3 SDI Network Connectivity Requirements, 65 pages, Revised April 1986\n\n#48.8 How to Link to SDI Network, 25 pages, July 1986\n\n#49.1 X.25 and X.75 Connection to SDI Network (includes Japanese, European,\nHawaiian, 8 pages, December 1986)\n\n#55.2 SDI Network Management Plan for 1986 to 1988, 47 pages, November\nMembership list (includes major connection, 24 pages, November 1986)\n\n#65.3 List, 9 pages, November 1986\n\nSon of a bitch! Someone had swallowed our bait and was asking for more\ninformation! I could understand it if the letter came from Hannover. But\nPittsburgh? What’s happening here?\n\nI asked Barb Schaeffer to tell this to nobody and called Mike Gibbons at the\nAlexandria FBI office.\n\n“Hey Mike, remember those carrots I left out for bait in January?”\n\n“You mean those SDI files you concocted?”\n\n“Yeah,” I said. “Well, my dear, sweet, nonexistent secretary just received a\nletter.”\n\n“Be serious.”\n\n“Someone in Pittsburgh wants to learn about SDI.”\n\n“And you’ve got that letter?”\n\n“Right in front of me.”\n\n“OK,” Mike said. “Listen up carefully. Don’t touch that letter. Especially,\ndon’t touch around the edges. Go find a glassine envelope. Gently insert the\npaper in the envelope. Then fed-ex it to me. Whatever you do, don’t handle it.\nWear gloves if you must.”\n\n“Well, the real Barb Schaeffer’s already touched it.”\n\n“We may have to fingerprint her, then. Oh, before you put it in the envelope,\ninitial the middle of the back side.”\n\nThis sounded like Dick Tracy’s “Crimestoppers,” but I followed orders. I\nhandled it like an astronomical negative—except that I made a photocopy for\nmyself. I suspected that Mike might forget to return the original.\n\nAfter I’d chased around for an hour (ever hunt for glassine envelopes?) and\nshipped the letter to the FBI, I dug out my logbook.\n\nThe information in that letter showed up in exactly one of my bogus files.\nThat file, named _form-letter_ , had been read only once. On Friday, January\n16, the hacker had read that file.\n\nI could prove that nobody else had seen it. I’d protected that file, _form-\nletter_ , so nobody could read it except the system manager. Or someone who’d\nillegitimately become system manager.\n\nWell, maybe someone else had figured out a way to read that file. Nope.\nWhenever the computer touched that file, for any reason, my alarm sounded and\nI got a printout. Only one person set off that alarm. The hacker.\n\nI compared Laszlo Balogh’s letter from Pittsburgh with my fabricated letter of\nJanuary 16. He’d pretty much asked for everything that the bait mentioned.\n\nIdentical.\n\nExcept he’d carefully deleted the word “classified” when asking for document\n#65.3.\n\nSeveral errors jumped out: it’s Cyclotron, not Cyclotrov. Berkeley, not\nBerkley. I wondered if the writer’s native tongue might not be English—who\nwould say, “Plans and Implementations of Conference Notes”?\n\nStrange. Who’s behind this?\n\nOh—I know what’s happening! This hacker lives in Pittsburgh, Pennsylvania. He\ncalls Hannover, connects to the German telephone system, and then invades my\ncomputer. What a way to hide!\n\nNaw. That one doesn’t hold water. Why wouldn’t he call directly—straight from\nPittsburgh to Berkeley?\n\nI reread my logbook of January 18. On that day, we’d traced the connection all\nthe way back to the hacker’s phone in Hannover. That confirms it. The\nelectronic connection went to someone’s home in Hannover, not Pittsburgh.\n\nInformation had moved from my computer in Berkeley, across Tymnet, into\nHannover, Germany. Three months later, a letter arrives from Pittsburgh.\n\nI scratched my head and looked for a phone number on the letter. None. Maybe\nLaszlo’s listed in the Pittsburgh directory service? Nope. Triam isn’t listed\neither.\n\nThat name, though … I called my sister Jeannie.\n\n“Hey, sister, what kind of name is Balogh?” Jeannie knows this kind of thing.\n\n“Sounds like Central or Southern Europe. Hungary or Bulgaria. Have a first\nname?”\n\n“Laszlo.”\n\n“Hungary for sure. Why, I had a boyfriend, once, whose father …”\n\n“Any chance it’s German?” I interrupted.\n\n“Doesn’t sound like it to me.”\n\nI told her about the letter and the misspellings. “Substituting ‘trov’ for\n‘tron’ sounds like a Hungarian error,” she said. “I’ll bet on Hungary.”\n\n“Ever hear of the name ‘Langman?’ ”\n\n“No, can’t say I have. It means long man in German, if that’s any\nconsolation.”\n\n“The hacker once created an account for T. G. Langman.”\n\n“Sounds like an alias to me,” Jeannie said. “And how do you know this Laszlo\ncharacter is real? Might well be another pseudonym.”\n\nComputer hackers hide behind pseudonyms. In the past seven months, I’d come\nacross Pengo, Hagbard, Frimp, Zombie … but T. G. Langman and Laszlo Balogh?\nMaybe.\n\nA hacker in Hannover, Germany, learns a secret from Berkeley, California.\nThree months later, a Hungarian, living in Pittsburgh, writes us a letter.\nFascinating.\n\nThree months, huh? I thought on this for a while. Suppose two friends were\ncommunicating with each other. News would take a couple of days to move\nbetween them. A week or two, perhaps. But not three months.\n\nSo Laszlo in Pittsburgh probably wasn’t a close friend of the Hannover hacker.\n\nNow suppose that the information was filtered through some third party. How\nmany people were involved? If two or three people meet, make a decision, and\nact, it’ll only take a week or two. But if five or ten people meet, decide,\nand act, it’ll take a month or two.\n\nYet I’m pretty sure that only one person is operating the computer. Nobody\nelse would have such a tedious, methodical, and persistent manner. The German\nBundespost says they’re following two guys and a “company with shady\ndealings.” What’s happening here?\n\nWhatever’s going on, I’m in over my head. They don’t teach you this kind of\nstuff in graduate school. Seemed like the CIA’s bailiwick. I called Teejay and\ngot two sentences into my description.\n\n“Wait a second. Let me call you back on a different line.” A secured phone\nline.\n\nNo doubt, this latest wrinkle hit him where he lived. I had to explain it to\nhim twice—he also wanted an express copy of Laszlo’s letter. News travels fast\nin certain circles: half an hour later, Greg Fennel of the CIA called, asking\nif Laszlo might have logged into my computer. I explained about my alarms and\ntripwires. “No, the only guy that’s seen that file is a hacker in Hannover.”\n\nGreg was quiet on the phone for a second, then said, “A real smoking gun.”\n\nThat reminded me of the NSA guy’s comment. Time to call Bob Morris. I told him\nabout the letter and he seemed mildly interested. “Want me to send you a copy\nby Federal Express?”\n\n“That won’t be necessary. First class is good enough.”\n\nHe seemed more interested in my techniques of setting alarms than the content\nof the letter. In a way, that’s not surprising—he’d already concluded that\nsomething serious was happening.\n\nAir Force OSI sent an investigator over to examine the letter. Their man,\nSteve Shumaker, had the common sense to show up in dungarees and a T-shirt, so\nas not to alarm the natives. He asked for a copy of the letter and the\nprintouts from the Air Force System Command Space Division. They were going to\ndo a postmortem analysis of the hacker’s break-in.\n\n“I’ll give you a copy of the letter—that’s no problem,” I told Shumaker, “but\nI can’t let you have the original printouts. The FBI’s warned me to keep all\nof this locked up since it might be used as evidence.”\n\n“Can you Xerox it?”\n\nAargh. Xerox five hundred pages of computer printout?\n\nWell, we spent an hour in front of the copier, feeding the damned paper\nthrough the machine. I asked the OSI detective what he thought of the letter\nfrom Pittsburgh.\n\n“We’ve been warning everyone that this was bound to happen. Maybe they’ll wake\nup now.”\n\n“What have you been doing so far?”\n\n“We visit sites and try to raise their security awareness,” he said. “We’ve\nformed a team to test their computer security by trying to break into Air\nForce systems. What we found isn’t encouraging.”\n\n“You mean you’re the only ones who test Air Force computers for security?” I\nasked. “You must have thousands of computers.”\n\n“Well, there’s also a group in San Antonio, the Air Force Electronic Security\nCommand, that searches for electronic security breaches,” Shumaker said. “They\nmostly worry about communications security—you know, keeping radio\ntransmissions secret. They’re sharpies over there, all right.”\n\nGibbons of the FBI was a sharpie, too. Finally, now that he was actively\ncommitted, he wanted to know everything. Every time the hacker appeared, Mike\nwanted to know about it immediately. Throughout the day, he called repeatedly,\nasking for my logs and notes, floppy disks and printouts. Descriptions of the\nmonitors. Everything. That’s the way to make progress.\n\nI couldn’t get this letter out of my mind. I kept searching for some innocent\nexplanation, some way that it might be written off as a fluke.\n\nFinally I gave up and admitted victory. I couldn’t explain it any other way:\nthe letter must mean my plan had worked. No, not my plan, it was Claudia’s. My\nsweet, guileless roommate, who didn’t know a computer from a toaster, had\ntrapped this cunning hacker!\n\nCycling home, I swerved suddenly from my usual route, scooted into the Double-\nRainbow ice cream store and the video rental place. Then I hurried home,\nwaving a copy of Laszlo’s letter. Elated at the news, Martha and Claudia\ncackled evilly and dropped into Boris and Natasha accents. Zecret plan 35B vas\na success!\n\nWe crowded into Claudia’s room, munched out on popcorn and ice cream, and\ncheered the monsters in _Godzilla Versus Monster Zero_.\n\n\n![](images/Stol_9780307819420_epub_055_r1.jpg) “Don’t say anything to anyone!”\n\nIt was Mike Gibbons on the phone, telling me not to spread the word to the\nCIA.\n\n“Uh, I’m sorry, Mike, but I’ve already told this guy Teejay.” I wondered if\nMike had heard of Teejay.\n\n“I’ll take care of it, then. This letter you sent us is intriguing. We ran it\nthrough some lab tests.”\n\n“What’d you learn?” Mike was being more communicative than usual, so I might\nas well push my luck.\n\n“Can’t tell you, but we’re not treating this case lightly. Aspects of it are\nquite, well, intriguing.” That’s the second time Mike used that word.\nSomething’s up. “Oh, by the way, could you send me a half-dozen sheets of your\nletterhead?”\n\nThe FBI wants my lab’s letterhead? Sounds like they’re going to reply to\nLaszlo’s letter.\n\nWhat would “I” tell this guy? How about,\n\nDear Mr. Balogh:\n\nYou have been selected as a grand prize winner in the SDINET sweepstakes.…\n\nThe hacker played hide-and-seek for the next few days. He’d show up for three\nminutes, look at our password file, then log out. My bait grew tastier every\nday. Yet he wasn’t nibbling.\n\nMonday morning, May 18, he came into our system at 6:54 A.M. Awakened by an\ninsistent beep, I reached over and whapped the alarm clock. Wrong\nnoisemaker—the beep continued. Three beeps. S for Sventek. It’s the hacker,\nover on the Unix-4 computer.\n\nMechanically I ran to my Macintosh, switched it on, and called Steve White at\nTymnet.\n\n“Steve, someone’s tripped my alarm,” I said, still a bit hazy. “I haven’t\nchecked it out yet, but could you start the trace?”\n\n“Right-o. It’ll be up in ten seconds,” he said. “Here it is. Coming through\nthe Westar satellite. Calling address 2624 DNIC 5421-0421. That’s Bremen. I’ll\nring the Bundespost.”\n\nI copied down the number; by now my home computer was warmed up. Steve had\njust completed an international trace in less than a minute. I dialed my lab’s\nsystem from my pipsqueak home computer and examined the Unix-4 computer. There\nwas Sventek, just leaving.\n\nHe’d been on for four minutes. Long enough to detect him and complete a trace.\nLong enough to ruin my morning. I wouldn’t be able to get back to sleep, so I\nbiked up to the lab. Over in the east, the morning star kept me company.\nVenus.\n\nIn four minutes this hacker had pried at a new part of my operating system. He\nsearched for a program called X-preserve on our Unix computer.\n\nHey—I know what he’s doing. He’s looking for the X-preserve hole in the VI-\neditor. Dave Cleveland and I had patched that almost a year ago. But this\nhacker is only now trying to exploit it.\n\nVI is the Unix screen editor. When Bill Joy wrote it, back in 1980, people\nthought it was the neatest invention around. It let you watch as you moved\nwords around! If you wanted to remove a word in the middle of a paragraph, you\njust moved the blinking box to that word, and presto!\n\nVI was predecessor to hundreds of word processing systems. By now, Unix folks\nsee it as a bit stodgy—it hasn’t the versatility of Gnu-Emacs, nor the\nfriendliness of more modern editors. Despite that, VI shows up on every Unix\nsystem.\n\nWhat happens if you’re writing a long article and the computer hiccups? Say,\nthere’s a power blackout or some moron pulls the plug. Used to be that you’d\nlose everything you had typed in.\n\nThe VI editor uses X-preserve to recover what you’ve done. When the computer\nreturns from the dead, X-preserve will reassemble the pieces of your work.\nIt’ll then ask you where to store this knit-together file. Most people will\nsay, “Oh, put it in my home directory.”\n\nBut X-preserve didn’t check where you stashed that file. You could say, “Stick\nthe file in the systems directory,” and it would do so.\n\nThat’s what the hacker tried. He made a file that said, “Grant system\nprivilege to Sventek.” He fired up the VI-editor, then tripped up the editor\nby feeding it an interrupt character. VI, sensing a problem, stored his file\nin pieces.\n\nThe hacker’s next step? Tell X-preserve to slip that file into the systems\ndirectory. In a couple minutes, Unix would hatch it, and he’d become system\nmanager.\n\nBut the cuckoo’s egg fell out of this nest. We’d fixed the X-preserve program\n… it now checks who you are and won’t let you move a file into the systems\narea.\n\nPoor guy. He must feel crestfallen. A nifty trick to break into systems, but\nit just won’t work here in Berkeley.\n\nOh, I’d left our other holes open. He can still use Gnu-Emacs to plant his\negg-program in the systems nest. And I’ve purposely left two other holes in\nour system waiting around for him to discover. Just to measure his skill. So\nfar, he’s batting one for three.\n\nAll this took three minutes. He entered his program perfectly—not a single\ntyping error. It’s as if he’d done this often. As if he’d practiced breaking\ninto other computers.\n\nHow many other system managers hadn’t yet patched X-preserve? How many other\nholes were still waiting to be discovered? Where would I go to warn people\nabout this? How would I tell the people in the white hats, without tipping off\nthe bad guys?\n\nToo late for that. The guys in the black hats already know.\n\nAlthough this connection lasted only a few minutes in Berkeley, the University\nof Bremen reported that he was connected for forty-five minutes. In turn, the\nBundespost once again traced the entire link back to the same individual in\nHannover.\n\nTurned out that the University of Bremen was also printing the hacker’s\ntraffic. Two of us were now watching this guy. He could run, but he couldn’t\nhide.\n\nFor the past couple months, he’d just nibbled at the SDINET files. He’d seen\nthe names of these files and noticed that everyday I added new memos and\nletters but didn’t read them right off. I’d begun having my doubts whether he\nwas still interested in our creative writing.\n\nOn Wednesday, May 20, my doubts cleared up. He connected at five in the\nmorning and dumped all the SDINET files. Here was one letter asking the\nPentagon for more funding. Another talking about “over-the-horizon radar”—a\ncatch phrase I’d found in an electronics magazine. Yet another note described\ntests of a new supercomputer, complete with parallel processors. I tried to\nconceal my utter lack of knowledge of these subjects by filling the letters\nwith jargon.\n\nHe swallowed them, all right. One by one. I wanted him to ask for each bogus\nmemo by name rather than saying, “Give me all the files.” So I added a few\nringers. Files that were far too long to type out. A few short files that were\nfilled with gibberish—computer guacamole. He couldn’t print these poisoned\nfiles, so he’d have to check each file first. This slowed him down and he\nstayed on the system longer: more time to trace.\n\nNine months? We’d been watching this one skunk for the better part of a year.\nAnd Mitre’s telephone bills said he’d been breaking in for more than a year.\nWhat persistence!\n\nI wondered again, what’s driving this guy? Sure, I’d get a charge out of\nfooling around for a night or two. Might even be fun for a couple weeks. But a\nyear? Night after night, patiently twisting doorknobs to computers? Why, you’d\nhave to pay me.\n\nPaid? Was someone paying this hacker?\n\nThe next few times he showed up, I hadn’t added much more to his SDINET\nfeeding grounds. My puppet secretary, Barbara Sherwin, wrote a word-processed\nmemo asking for a week’s vacation. The hacker read this and should have\nunderstood why there was so little new information.\n\nInstead of pawing through LBL’s files, then, he went out over the Milnet, once\nagain patiently trying to guess passwords. One of my bogus SDINET reports\nmentioned a special project at White Sands Missile Range; sure enough, he\nspent fifteen minutes scratching at their door. White Sands’ computers\nrecorded a dozen attempts to break in, but none were successful.\n\nChris McDonald, White Sands’ computer security ace, called me within the hour.\n“Someone’s setting off alarms inside my WSMR05 computer.”\n\n“I know. It’s the same hacker.”\n\n“Well, he’s trying accounts that don’t exist. Names like SDINET. There’s no\nway he’ll get in that way,” Chris said confidently. “Anyway, that machine\nneeds two passwords, and we changed ’em all last week.” White Sands didn’t\nfool around.\n\nHe wasted his time trying thirty other computers as well. The Korean Advanced\nInstitute of Science and Technology. The Army Safety Center at Fort Rucker.\nStrategic Air Command. The Defense Nuclear Agency at Kirtland Air Force Base.\nThough he still tried account names like “guest” and “system,” he used\n“SDINET” as well. No doubt that he’s a believer.\n\nMostly the hacker’s trips through my system were becoming routine. I still ran\nto the switchyard whenever my beeper called, but I guess I’d become accustomed\nto having this mouse in a cage.\n\nI’d waited eight months, I could wait some more. Around the second week of\nJune, he stopped into my computer from 3:38 until 4:13 in the afternoon. We\ntraced him completely—Hannover again—and stayed in touch with the FBI\nthroughout.\n\nImmediately after logging onto my Berkeley computer, he jumped onto the Milnet\nand tried to log onto some computers at the Unisys Corporation, in Paoli,\nPennsylvania. Systems named “Omega,” “Bigburd,” and “Rosencrantz” (I kept\nwaiting to see Guildenstern, but he never found it). Then he tried the Unisys\nBurdvax system.\n\nHe got in on his first try. Account name Ingres, password, “Ingres.” Not bad …\nhe remembers the Ingres database. Buy why did he just try those Unisys\ncomputers? What brought them to his attention? Maybe someone told him to look\nfor them.\n\nMaybe Laszlo Balogh in Pittsburgh worked in Paoli. The atlas said otherwise.\nPaoli’s a suburb of Philadelphia, hundreds of miles away from Pittsburgh.\n\nAs an Ingres user, the hacker only had limited privileges, but he took what he\ncould find. Most useful to him, he found a way to read the Unisys password\nfile. Copied the whole thing to his home computer. Then he listed several\nfiles which should never be world-readable: the list of phone numbers that the\nUnisys computer knew, and Unisys’s network address file.\n\nI already knew what he’d do with the Unisys password file. He’d decrypt it by\nblasting a dictionary at it. Then he’d log into a more privileged account and\ngarner still more power.\n\nThose other files were just as worrisome. They provided the hacker with phone\nnumbers to nearby computers and a map of the Unisys local network. Now he knew\nhow to connect from the Burdvax into other computers … he didn’t need to\nexplore.\n\nBut even as I watched, he disconnected. Was he scared? No, just patient. He\nwas going to check up on other computers. First, the Fort Buckner system in\nOkinawa. Yes, his password was still good there. Despite our warnings, they\nhadn’t changed a thing.\n\nNext, he tried the Naval Coastal Systems Command in Panama City, Florida. But\nhe couldn’t get in on his old Ingres account. They’d changed the password on\nhim.\n\nDidn’t faze him for an instant. He turned around and logged in as user “Ovca,”\npassword, “Baseball.” This worked perfectly.\n\nAha! More evidence for password cracking. Two months ago, the hacker logged\ninto that naval computer as “Ingres,” and copied their encrypted password\nfile. Now, even though they deleted the Ingres account, he can still log in,\nusing some other account. The fools had only changed one password. And their\npasswords were ordinary English words. Jeez.\n\nWhile he was at it, he checked into his old haunts. Ramstein Air Force Base.\nFort Stewart. University of Rochester. The Pentagon Optimis Data Center.\nFinally he left the network.\n\nToday he’d broken into a new computer at Unisys. Where had I heard that name?\nOf course—they’re a defense contractor that makes computers for the military.\nNot just any computers. Unisys builds secure computers, systems that you can’t\nbreak into.\n\nRight.\n\nWait a second. What other defense contractors had been hit? I scribbled a list\non a pad of paper:\n\nUnisys. Makers of secure computers.\n\nTRW. They make military and space computers.\n\nSRI. They’ve got military contracts to design computer security systems.\n\nMitre. They design high-security computers for the military. They’re the\npeople that test NSA’s secure computers.\n\nBBN. The builders of the Milnet.\n\nWhat’s wrong with this picture? These are the very people that are designing,\nbuilding, and testing secure systems. Yet hackers traipse freely through their\ncomputers.\n\nThese companies don’t have dinky budgets, either. They charge our government\ntens of millions of dollars to develop secure software. No doubt about it: the\nshoemakers’ kids are running around barefoot.\n\nI’d seen this guy break into military computers, defense contractors,\nuniversities, and laboratories. But no banks. Oh—I know why. Their networks\naren’t as public as the Arpanet. But if he got on their networks, I’d bet he’d\nbe about as successful.\n\nFor it doesn’t take brilliance or wizardry to break into computers. Just\npatience. What this hacker lacked in originality, he made up for in\npersistence. A few of the holes he exploited were news to me: the Gnu-Emacs\nproblem, for instance. But mostly, he took advantage of administrators’\nblunders. Leaving accounts protected by obvious passwords. Mailing passwords\nto each other. Not monitoring audit trails.\n\nCome to think of it, was it foolish to remain open? It had been almost ten\nmonths, and he was still free. Despite his breaking into more than thirty\ncomputers, despite Laszlo’s letter from Pittsburgh, despite all these traces,\nthis hacker was still at large. How much longer would this go on?\n\n\n![](images/Stol_9780307819420_epub_056_r1.jpg) It was June—summer in paradise.\nI biked home, enjoying the scene, Berkeley students with Frisbees, sailboards,\nand an occasional convertible top down in the balmy air. Our garden was full\nof roses, marigolds, and tomatoes. The strawberries were thriving, promising\nstill more milkshakes.\n\nInside the house, however, Martha was imprisoned, studying for her bar exam.\nThis last ordeal looked even harder than three years of law school. In summer,\nwhen everyone else can go out and play, you’re stuck in dreary review classes,\ncramming your head with legal rules, counting the days until the exam—a three-\nday ordeal modeled on the Spanish Inquisition.\n\nMartha coped, patiently reading her books, making intricate outlines of each\nsubject with colored pens, meeting with fellow sufferers to quiz each other.\nShe was philosophical about it; she put in exactly ten hours each day, then\nslammed the books shut. Aikido became her salvation—she took out her\nfrustrations by flipping people over her head.\n\nMartha rarely talked about the lurking horror of the exam itself, but it was\nalways there. Watching her go through this brought back memories of my own\ngrad school days.\n\nIn astronomy, you first enjoy three or four years of confusing classes,\nimpossible problem sets, and sneers from the faculty. Having endured that,\nyou’re rewarded with an eight-hour written exam, with questions like: “How do\nyou age-date meteorites using the elements Samarium and Neodymium?” If you\nsurvive, you win the great honor and pleasure of an oral exam by a panel of\nlearned professors.\n\nI remember it vividly. Across a table, five profs. I’m frightened, trying to\nlook casual as sweat drips down my face. But I’m keeping afloat; I’ve managed\nto babble superficially, giving the illusion that I know something. Just a few\nmore questions, I think, and they’ll set me free. Then the examiner over at\nthe end of the table—the guy with the twisted little smile—starts sharpening\nhis pencil with a penknife.\n\n“I’ve got just one question, Cliff,” he says, carving his way through the\nEberhard-Faber. “Why is the sky blue?”\n\nMy mind is absolutely, profoundly blank. I have no idea. I look out the window\nat the sky with the primitive, uncomprehending wonder of a Neanderthal\ncontemplating fire. I force myself to say something—anything. “Scattered\nlight,” I reply. “Uh, yeah, scattered sunlight.”\n\n“Could you be more specific?”\n\nWell, words came from somewhere, out of some deep instinct of self-\npreservation. I babbled about the spectrum of sunlight, the upper atmosphere,\nand how light interacts with molecules of air.\n\n“Could you be more specific?”\n\nI’m describing how air molecules have dipole moments, the wave-particle\nduality of light, scribbling equations on the blackboard, and …\n\n“Could you be more specific?”\n\nAn hour later, I’m sweating hard. His simple question—a five-year-old’s\nquestion—has drawn together oscillator theory, electricity and magnetism,\nthermodynamics, even quantum mechanics. Even in my miserable writhing, I\nadmired the guy.\n\nSo Sunday morning I’m looking at Martha, calmly working on an outline, the\ndining table strewn with books. She’ll pass, all right, but I also know how\nscared she is and how an exam can make anyone feel absolutely stupid and\nhelpless. I can’t make her ordeal easier, but I can at least make breakfast. I\nslip quietly into the kitchen and crack a few eggs …\n\nAt 9:32, the damned hacker steps on my tripwire. The pager beeps. I call Steve\nWhite. He calls Germany. Like the old double play: Tinker to Evers to Chance.\n\nSteve needed a minute to find the hacker coming from address 2624 DNIC 4511\n0199-36. Direct from Hannover. (Or as direct as transatlantic satellite\nconnections can be.)\n\nThe Bundespost was hot. Took them only a few minutes to confirm that they’d\nstarted a trace. Nice. Meanwhile, having started the ball rolling, I pulled on\nsome clothes and biked up to the lab. No time for yard sales this morning.\n\nI arrived with plenty of time to spare. My visitor was still pawing through\nthe bogus SDINET files, carefully copying each one into his own computer. One\nfile described how the Strategic Defense Initiative was to be used in tracking\nsatellites in space. Another file seemed to say that you could connect\ndirectly into several Air Force computers from my laboratory.\n\nThe hacker wanted to try, but couldn’t figure out where we’d installed the\nnetwork software. So he scoured our entire computer, searching for any program\ncontaining the phrase “SDI.” He found quite a few, but none seemed to do the\njob for him.\n\nThen he rifled Dave Cleveland’s mail. Dave had prepared for this—he’d written\na letter talking about how he’d hidden the SDINET access ports. Dave’s letter\ncontained the sentence, “I’ve concealed the SDI network port, and I doubt that\nmany people will discover it.”\n\nThat was enough to set the hacker on an hour-long wild goose chase. He combed\nthrough our system, groping for what he knew was a hidden program that would\nbe his northwestern passage to military computers everywhere.\n\nI sat back, smiling at the screen. He’d been suckered in, all right. He still\nfelt challenged to uncover the SDI network connection and truly believed that\nhe could reach those classified computers.\n\nYet my system looked vanilla. Because it was vanilla. Oh, here and there, I\nsprinkled hints that other people were using the SDI network. One physicist\ncooperated and sent a complaint to the system manager, saying that the SDI\nnetwork wasn’t functioning last Tuesday night. Another wrote a mundane program\nfull of subroutines with names like SDI-link and Copy-SDI.\n\nThough it took hours, the hacker eventually discovered these, and must have\nscratched his head, wondering why others had such an easy time using the\nnetwork. He tried logging into computers named _Sdi_ and _Sdinetwork_. Over\nand over, he sifted through our system, but to no avail.\n\nEventually he gave up and let me go home. Martha wasn’t pleased, of course.\nShe’d been studying all morning, and she was hungry and grouchy. The two eggs\nstared at me from the pan, uncooked, just as I’d left them.\n\nSo I made a brunch of omelets, hot cocoa, and fruit salad; she dumped her\nbooks off the table with a vengeance, and we sat down, enjoying a few moments\nof peace in the quiet sunny room. The more strange life gets, the more\nprecious those times are, with food and friends and the Sunday _Times_\ncrossword puzzle.\n\nMonday morning, Teresa Brecken, the Petvax system manager, reported that\nsomeone had attacked her computer. He couldn’t get into it but had been\nprobing it, searching for weak places. His pounding had set off alarms, and\nTeresa called me.\n\nHe’d come in over her port to the High Energy Physics Network. That didn’t\nmean much—there’s a couple thousand other computers on that net. Moreover, the\nHepnet ties to SPAN, the Space Physics Applications Network, run by NASA.\nAltogether there’s well over ten thousand computers on those networks.\n\nHad the hacker been laughing at me all the time? While I’d been watching the\nTymnet mouse hole, had he been waltzing in through some NASA network?\n\nTeresa’s monitors showed this hacker had come from computer 6.133, the\nNational Severe Storms Data Center’s computer at NASA’s Goddard Spaceflight\nCenter. Not much to do but call them.\n\nI didn’t get very far. They were worried about hackers on their computer and\nhad discovered one or two problems, but couldn’t go much further. I pestered\nthem, and they finally said that this particular connection had originated at\nNASA’s Marshall Spaceflight Center in Huntsville, Alabama. From there, who\nknows? Marshall didn’t keep records.\n\nSame guy? I doubted it. The NASA computers aren’t secret—NASA does civilian\nspace research and has nothing to do with the Strategic Defense Initiative.\nStill, worth remembering the incident: I wrote it down in my logbook.\n\nI called Mike Gibbons again, wondering how much longer we’d have to wait\nbefore the FBI and their German partners began to move.\n\n“Any day now,” Mike replied. “The warrants are in order and we’re just waiting\nfor the right time.”\n\n“Give me a figure, Mike. Do you mean hours, days, weeks, or months?”\n\n“More than days, less than weeks.”\n\nI wondered if the FBI was feeding some false information through Laszlo\nBalogh. “Ever reply to the Pittsburgh letter?” I asked.\n\n“Hey, how about them Yankees winning another game?” As usual, Mike played his\ncards close to his chest.\n\nAlmost every day now, the hacker logged in for a few minutes. Sometimes he’d\ngrab any new files from the SDINET account. Other days he’d try to break into\nmilitary computers. Once he spent half an hour trying to guess the password\nfor our Elxsi computer—I’d dropped a hint that our Elxsi was a central SDINET\ncontroller.\n\nI could embroider fake military documents as fast as he could read them.\nKnowing that he was passing my handiwork to some agent in Pittsburgh, I added\njust a dash of verifiable information: the Pentagon was scheduling a secret\nsatellite to be launched on the _Atlantis_ space shuttle. This was common\nknowledge to anyone reading the newspapers. But I imagined that in his quest\nfor secret information, he’d feel that these nuggets of truth confirmed that\nhe’d struck the mother lode.\n\nSunday, June 21, 1987, at 12:37 P.M., he logged into our Unix computer as\nSventek. For five minutes he checked the system status and listed a few mail\nfiles. This intrusion seemed just like his others.\n\nBut this session was different in one important way.\n\nIt was his last.\n\n\n![](images/Stol_9780307819420_epub_057_r1.jpg) “Hi, Cliff, it’s Steve.” I put\ndown my chocolate chip cookie.\n\n“I just got a message from Wolfgang Hoffman at the German Bundespost. He says\nthat there’ll be a full-time policeman outside the hacker’s apartment on\nMonday through Wednesday of next week. They’ll keep watch continually, and\nthey’ll rush in to make an arrest as soon as he connects to Berkeley.”\n\n“How will the cop know when to bust in?”\n\n“You’ll give the signal, Cliff.”\n\nThe next time the hacker touched my system, I would call the FBI and Tymnet.\nThey’d make the trace, tell the German BKA, and the cops would bust into his\napartment.\n\nFinally, after ten months.\n\nWill he show up? And what if he doesn’t? Will they bust him anyway or give up\non the whole thing? With my luck, they’ll drop the whole thing.\n\nI spent the weekend at home with Martha, arriving at the lab late Sunday\nevening. With the best of luck, the hacker would show up on Sventek’s account,\nI’d call the FBI, and while he was dumping a file of my concocted SDI baloney,\nhe’d be busted. I could imagine him frantically trying to conceal his computer\nas police break down his apartment’s door.\n\nWith dreams like those, I nestled under my desk, wrapped in the quilt that\nMartha and I had made last winter. In case my beeper failed, two personal\ncomputers stood watch, each wired to a bell. After ten months, I wasn’t going\nto miss my big chance.\n\nMonday afternoon, June 22, Wolfgang Hoffman cabled this message: “Arrests\nexpected shortly. Notify us immediately if hacker shows up.”\n\nOK, I’m waiting. Every few minutes, I walk over to the switchyard and\neverything’s quiet. Oh yeah, a couple physicists are using Tymnet to analyze\nsome high-temperature superconductors. But there’s no other traffic. My alarms\nand tripwires are in place, but not a peep.\n\nAnother night under the desk.\n\nTuesday morning, June 23, Mike Gibbons called from the FBI.\n\n“You can close up shop, Cliff.”\n\n“What’s happened?”\n\n“Arrest warrants were issued this morning at 10 A.M.”\n\n“But I didn’t see anyone on my system then.”\n\n“Makes no difference.”\n\n“Anyone arrested?”\n\n“I can’t say.”\n\n“Where are you, Mike?”\n\n“In Pittsburgh.”\n\nSomething was happening. But Mike wouldn’t say what. I’d wait for a while\nbefore closing my doors to this hacker.\n\nA few hours later, Wolfgang Hoffman sent a message: “An apartment and a\ncompany were searched, and nobody was home at the time. Printouts, disks, and\ntapes were seized and will be analyzed in the next few days. Expect no further\nbreak-ins.”\n\nWhat does this mean? I guess the police busted his apartment. Why didn’t they\nwait for our signal? Should I celebrate?\n\nWhatever happened, at last we could seal our doors. I changed our Tymnet\npasswords and patched the hole in the Gnu-Emacs editor. What should we do\nabout everyone’s passwords?\n\nThe only way to guarantee a clean system would be to change every single\npassword overnight. Then certify each user, one by one, the next morning. Easy\nif there’s only a few people on your system. Impossible for our twelve hundred\nscientists.\n\nYet if we didn’t change every password, we couldn’t be sure that some other\nhacker might not have purloined an account. All it takes is one stolen\naccount. In the end we expired everyone’s passwords and asked everyone to pick\na new one. One that’s not in the dictionary.\n\nI set traps on all the hacker’s stolen accounts. If anyone tries to log in as\nSventek, the system will reject the try—but it’ll capture all the information\non where the call originates. Just let him try.\n\nMartha and I couldn’t celebrate in a big way—her bar-exam cram course was a\nball and chain—but we played hooky for a day and escaped to the North Coast.\nWe wandered on the high cliffs covered with wildflowers and watched the waves\ncrash over the rocks a hundred feet below us. We climbed down to an isolated\nlittle cove—our own private beach—and for a few hours all my worries were far\naway, unreal.\n\nWithin the next few days, word filtered back from Germany. Apparently the\nHannover police had simultaneously broken into a company, Focus Computer GmbH\nof Hannover, and the apartment of one of their employees. They seized eighty\ndisks at the computer firm, and twice that at the apartment. Both the manager\nof Focus Computer and the individual were detained; they said nothing. But the\nmanager hinted that they had suspected that they’d been observed.\n\nThe evidence? Shipped to somewhere called Wiesbaden for “analysis by experts.”\nHell, I could analyze it easily enough myself. Just search for the word,\n“SDINET.” As the inventor of that word, I could tell instantly whether their\nprintouts were the real McCoy.\n\nWhat’s the hacker’s name? What was he up to? What’s the connection with\nPittsburgh? What’s happened to him? Time to ask Mike of the FBI.\n\n“Now that it’s all over, can you tell me the guy’s name?” I asked.\n\n“It’s not all over, and no, I can’t tell you his name,” Mike replied, showing\nmore than his usual annoyance at my questions.\n\n“Well, can I find out more about this guy from the Germans?” I knew the\nprosecutor’s name, even if I didn’t know the hacker’s.\n\n“Don’t contact the Germans. This is sensitive, and you’ll bollix things up.”\n\n“Can’t you even tell me if the hacker’s in jail? Or is he wandering the\nstreets of Hannover?”\n\n“It’s not for me to say.”\n\n“Then when will I find out what happened?”\n\n“I’ll tell you at the right time. Meanwhile, keep all your printouts locked\nup.”\n\nLock up the printouts? I looked across my office. Sandwiched between\nbookshelves of computer manuals and astronomy books, were three boxes of the\nhacker’s printouts. My office door doesn’t have a lock, and the building is\nopen twenty-four hours a day. Oh—the janitor’s closet can be locked. I could\nstash the boxes up over the sink, on the shelf next to the ceiling.\n\nWhile he was still on the phone, I asked Mike when I could expect to hear back\non this case.\n\n“Oh, in a few weeks. The hacker will be indicted and brought to trial,” Mike\nsaid. “Meanwhile, keep silent about this. Don’t publicize it and stay away\nfrom reporters.”\n\n“Why not?”\n\n“Any publicity may let him off. The case is tough enough without being tried\nin the newspapers.”\n\n“But surely this is an open-and-shut case,” I protested. “The U.S. Attorney\nsaid that we had more than enough evidence to convict the guy.”\n\n“Look, you don’t know everything that’s going on,” Mike said. “Take my word\nfor it: don’t talk about it.”\n\nThe FBI was happy with their work, as well they should be. Despite several\nfalse starts, Mike had stuck with the investigation. The FBI wouldn’t let him\ntell me anything; there wasn’t much I could do about that. But he couldn’t\nstop me from checking on my own.\n\nTen months ago, Luis Alvarez and Jerry Nelson had told me to treat the hacker\nas a research problem. Well, at last the investigation was complete. Oh, there\nwere a few details to figure out, but the real work was over. Yet the FBI\nwouldn’t let me publish what I’d learned.\n\nWhen you run an experiment, you take notes, think for a while, then publish\nyour results. If you don’t publish, nobody will learn from your experience.\nThe whole idea is to save others from repeating what you’ve done.\n\nIt was time for a change anyway. I spent the rest of the summer making weird\ncomputer pictures of telescopes and teaching a few classes at the computer\ncenter. The pursuit of the German had taught me about how to connect computers\ntogether.\n\nSooner or later, the FBI would let me publish. And when it did, I’d be ready.\nAround the beginning of September, I started writing a dry, scientific paper\nabout the hacker. I just distilled my lab notebook—all 125 pages of it—into a\nboring article and got it ready for some obscure computer journal.\n\nStill, letting go of the hacker project wasn’t entirely easy. For a year, the\nchase had consumed my life. In the course of my quest, I’d written dozens of\nprograms, forsaken the company of my sweetheart, mingled with the FBI, NSA,\nOSI, and CIA, nuked my sneakers, pilfered printers, and made several coast-to-\ncoast flights. I pondered how I would now spend my time, now that my life\nwasn’t scheduled around the whims of some faceless foe from overseas.\n\nMeanwhile, six thousand miles away, someone was wishing that he’d never heard\nof Berkeley.\n\n\n![](images/Stol_9780307819420_epub_058_r1.jpg) A month before the Hannover\nhacker was caught, Darren Griffith had joined our group, having moved up from\nSouthern California. Darren liked punk music, Unix networks, laser typography,\nand friends with spiked haircuts—in that order. Besides the coffeehouses and\nconcerts, Berkeley attracted him because of its hundreds of Unix computers\ntied together with an ethernet, making an intricate maze for Darren to\nexplore.\n\nAt work, our boss set him loose to work in his own rhythm and at whatever\nprojects interested him. After five, when the normal folks left, he cranked up\nthe stereo in his cubicle, and wrote programs to the sound of U2. “The louder\nthe music, the better the code.”\n\nI filled him in on the past year’s hack and figured that he’d be delighted\nwith the hole in Gnu-Emacs, but he just shrugged. “Eeh, anyone could see how\nto exploit that. Anyway, it’s only on a few hundred systems. Now if you want a\ntasty security hole, check out VMS. They’ve got a hole you could drive a truck\nthrough.”\n\n“Huh?”\n\n“Yeah. It’s in every Vax computer from Digital Equipment Corporation that runs\nthe VMS operating system Version 4.5.”\n\n“What’s the problem?”\n\nDarren explained. “Anyone that logs into the system can become system manager\nby running a short program. You can’t stop ’em.”\n\nI hadn’t heard of this problem. “Isn’t DEC doing something about it? After\nall, they sell those systems.”\n\n“Oh, sure, they’re sending out patches. But they’re being real quiet about it.\nThey don’t want their customers to panic.”\n\n“Sounds reasonable.”\n\n“Sure, but nobody’s installing those patches. What would you do—some tape\nshows up in the mail saying, ‘Please install this program or your system may\ndevelop problems’ … you’ll ignore it, because you’ve got better things to do.”\n\n“So all these systems are open to attack?”\n\n“You got it.”\n\n“Wait a second. That operating system was certified by NSA. They tested it and\ncertified it secure.”\n\n“Sure they spent a year testing it. And a month after they verified the\nsystem, DEC modified it slightly. Just a little change in the password\nprogram.” The National Computer Security Center’s verification program had a\nhole in it as well.\n\n“And now fifty thousand computers are insecure.” I couldn’t believe it. If my\nhacker knew, he’d have a field day. Good thing we’d nailed him.\n\nThis problem seemed important, so I called Bob Morris at the National Computer\nSecurity Center. He’d not heard of it before, but he promised to check into\nit. Well, I’d done my job and warned the authorities.\n\nAround the end of July, Darren picked up a message from the network. Roy\nOmond, a system manager in Heidelberg, Germany, had detected a group called\nChaos Computer Club breaking into his Vax computer. They’d used the hole that\nDarren had described. Omond’s message described how these vandals had broken\nin, set up Trojan horses to capture passwords, then erased their trails behind\nthem.\n\nThe Chaos Computer Club, huh? I’d heard rumors that back in 1985, a few German\nhackers banded together to “explore” computer networks. To them the government\nmonopoly only made trouble—they called it the “Bundespest.”* They soon\ndeveloped into a gang that systematically attacked computers in Germany,\nSwitzerland, France, and eventually the United States. Those pseudonyms I’d\nheard of before—Pengo, Zombie, Frimp—were all members … self-styled cyberpunks\nwho prided themselves on how many computers they could break into.\n\nSounded familiar.\n\nBy the end of the summer, the problem had spread. The Chaos gang broke into a\nhundred computers around the world, using the NASA SPAN network. Wait a\nsecond. The Petvax computer! Those alarms in June—I’d traced them back to the\nNASA network. I’ll bet that the connection wended its way all the way back to\nGermany. Uh oh.\n\nPretty soon, I realized what was happening. The Chaos Computer Club had broken\ninto computers at the CERN physics laboratory in Switzerland, and caused\nendless headaches there—they were said to have stolen passwords, destroyed\nsoftware, and crashed experimental systems.\n\nAll for the fun of it.\n\nFrom the Swiss laboratory, Chaos members had stolen passwords to reach into\ncomputers at American physics labs—Fermilab in Illinois, Caltech, and\nStanford. From there, it was a short hop to the NASA network and into NASA’s\ncomputers.\n\nEvery time they entered a computer, they used the bug to become system\nmanager. Then they modified the operating system to let them in with a special\npassword—one known only to them. Now, whenever a Chaos Club member used the\nmagic password on an injured Vax computer, they’d get in … even if the\noriginal hole was fixed!\n\nWhoa! Serious stuff here. Hundreds of computers were at risk. They could\neasily wreck the software on each system. But what to do? NASA’s not\nresponsible for each computer connected to its network. Half of them are at\nuniversities, running scientific experiments. NASA probably doesn’t even have\na list of all the computers attached to its network.\n\nThe NASA network, like the Milnet, is a roadway connecting computers around\nthe country. A burglar will naturally use that road, but that’s hardly the\nfault of the road’s builder. NASA’s only responsible for keeping the road\nintact. The security of each computer rests in the hands of the people running\nit.\n\nThe Chaos Computer Club created headaches for network folks—they were thumbing\ntheir noses at hundreds of system managers and thousands of scientists. If you\nowned a Vax computer, you had to rebuild the system software from scratch.\nThat’s an afternoon’s work. Multiply that by a thousand sites. Or was it fifty\nthousand?\n\nAt last the Chaos Club triumphantly announced their break-ins to the press,\npainting themselves as brilliant programmers. I searched for any mention of my\nlaboratory, of Milnet, or of Hannover. Nothing. It was as if they’d never\nheard of my hacker. Yet what a coincidence: a couple months after I nail a\nGerman hacker breaking into computer networks, a German club goes public,\nsaying that they’ve prowled through NASA’s networks.\n\nCould this be who had broken into my computer? I thought for a while. The\nChaos gang seemed to work with the VMS operating system and knew little about\nUnix. My hacker certainly knew VMS, but he seemed more at home on Unix. And he\nhad no hesitation to exploit any bug in the computer. Hannover is close to\nHamburg, the home of Chaos. Less than a hundred miles.\n\nBut my hacker was arrested on June 29. The Chaos Club was breaking into\nsystems during August.\n\nHmmm. If the LBL hacker from Hannover was in contact with the Chaos Club, his\narrest would send shock waves through the entire club. They’d evaporate as\nsoon as they heard that one of their members had been arrested.\n\nAnother wrinkle … NASA doesn’t have secrets. Oh, perhaps the military shuttle\npayloads are classified. But almost everything else about NASA is public.\nRight down to the design of their rockets. Hell, you can buy the space\nshuttle’s blueprints. Not the place for a spy.\n\nNo, my hacker wasn’t in Chaos. Probably he was loosely tied into their club …\nperhaps he checked into their electronic bulletin board. But they didn’t know\nabout him.\n\nChaos Club members justify their actions with a peculiar set of ethics. They\nclaim that it’s perfectly all right for them to roam through others’\ndatabases, so long as they don’t destroy any information. In other words, they\nbelieve their technicians’ curiosity should take precedence over my personal\nprivacy. They claim the right to peruse any computer they can break into.\n\nInformation in databases? They’ve no qualms, if they can figure out how to get\nit. Suppose it’s a list of AIDS patients? Or your last year’s income tax\nreturn? Or my credit history?\n\nDarren had been great to talk to about all of this, with his knowledge of\nnetworks and sharp eye for holes. But whenever we talked, he seemed amused and\ndistant, looking at the hacker problem purely as an intellectual game. I felt\nthat he looked down at me for getting caught up in it, being out to get the\nhacker.\n\nFinally one afternoon after Darren had patiently listened to my whining about\nthe hacker and my gloomy predictions of future trouble, he fixed me with a\nstare.\n\n“Cliff,” he said, “you’re an old fart. Why do you care so much that someone’s\nfrolicking in your system. That could have been you, in your distant youth.\nWhere’s your appreciation of creative anarchy?”\n\nI tried to defend myself—as I’d tried with Laurie, months ago. I hadn’t set\nout be be a network cop. I’d started with a simple puzzle: why did my\naccounting show a 75-cent error? One thing led to another, and I ended up on\nthe trail of our friend.\n\nAnd I didn’t just blunder around in a blind rage, trying to nab the guy just\nbecause he was there. I learned what our networks are. I had thought of them\nas a complicated technical device, a tangle of wires and circuits. But they’re\nmuch more than that—a fragile community of people, bonded together by trust\nand cooperation. If that trust is broken, the community will vanish forever.\n\nDarren and other programmers sometimes expressed respect for hackers because\nthey test the soundness of systems, reveal holes and weaknesses. I could\nrespect this view—it takes a rigorous, honest mind to feel gratitude to\nsomeone who exposes our mistakes—but I could no longer agree with it. I saw\nthe hacker not as a chess master, teaching us all valuable lessons by\nexploiting the weak points in our defenses, but as a vandal, sowing distrust\nand paranoia.\n\nIn a small town, where people never locked their doors, would we praise the\nfirst burglar for showing the townspeople how foolish it was to leave their\nhouses open? After it happened, the town couldn’t ever go back to open doors.\n\nHacking may mean that computer networks will have to have elaborate locks and\ncheckpoints. Legitimate users will find it harder to communicate freely,\nsharing less information with each other. To use the network, we all might\nhave to identify ourselves and state our purpose—no more logging on casually\njust to gossip, doodle around, see who else is on the net.\n\nThere’s plenty of room for truly “creative anarchy” on the networks as they\nare—nobody is in charge of them, nobody makes the rules—they exist purely out\nof cooperative effort and they evolve freely at the whim of their users. A\nhacker’s abuse of this openness might mean the end of the casual, communal way\nthe networks are run.\n\nI could finally answer Darren. All my buddying up with spooks in suits and\nplaying computer cop _came from_ my appreciation for creative anarchy. To have\nthe networks as our playground, we have to preserve our sense of trust; to do\nthat, we have to take it seriously when people break that trust.\n\nBut though I finally felt like I knew why I’d done it, I still didn’t know\nwhat I had done. What was the guy’s name in Hannover? Who was behind the whole\nthing? Nobody would tell me.\n\nAs the summer stretched on, the case showed every indication of dying out.\nMike Gibbons didn’t call and seldom returned my calls. It was as if nothing\nhad happened.\n\nI understood the technical aspects of the case—the computer’s holes and the\nhacker’s location. Wasn’t that all I’d wanted? But something was wrong. This\nwasn’t satisfying.\n\nI knew the whats and the hows. I wanted to know the who’s and whys.\n\n* In truth, German telephone rates are exorbitant compared to those in North America.\n\n\n![](images/Stol_9780307819420_epub_059_r1.jpg) Who’s behind it? Only one way\nto find out. Do research.\n\nThe FBI wouldn’t tell me anything except, “Be quiet and don’t ask questions.”\nNot helpful.\n\nMaybe my poking around would upset some trial that was going on. But if there\nwas a trial, surely they’d need my cooperation. After all, I had the crucial\nevidence: a couple thousand pages of printouts, all neatly folded into boxes\nand locked up in a janitor’s closet.\n\nWell, even if I couldn’t ask questions, I could still do science. Publishing\nyour results is as much a part of research as investigating a weirdness. In my\ncase probably more important. As rumors of this hacker spread, military people\nbegan to call, asking for more information. What should I tell them?\n\nThe end of August marked a year after we’d first detected this hacker in our\ncomputers, and two months after we finally nailed him in Hannover. The FBI\nstill told me to keep quiet.\n\nOf course, the FBI couldn’t legally prevent me from publishing, or even poking\naround. Martha was adamant: “You’re free to write what you wish. That’s what\nthe First Amendment’s all about.”\n\nShe should know. She was in the midst of studying constitutional law for her\nbar exam. Just three more weeks, and it’d be all over. To take her mind off\nthe exam, we began sewing a quilt. Just a few minutes here and there, but the\ndesign grew and grew, and though I didn’t realize it, something wonderful was\ngrowing with it.\n\nWe split up the work of making the quilt the way we always had. She’d do the\npiecing, I’d sew the squares, and we’d both share the quilting. We’d just\nstarted cutting the pieces when Laurie stopped by for brunch.\n\nMartha showed her the design and explained that the quilt would be called\n“Garden Star.” The central blazing star would be bright yellow and orange,\nlike the peonies in our garden. Surrounding it would be a ring of tulips, and\nthen a border called “snowball,” like the snowball bushes we had, the first\nplants to bloom in spring. Laurie suggested another border, called “flying\ngeese,” to represent the birds in the garden.\n\nListening to Laurie and Martha talk about quilting patterns, each one with its\nancient, romantic name, I felt a deep warmth. Here was my home, my love. The\nquilt we were making now would last our whole lives, in fact, it would outlive\nus and still be there to comfort our grandchildren …\n\nWhoa. I was getting carried away. After all, Martha and I weren’t married or\nanything, just living together, just sharing our lives while it was good for\nboth of us, free to move on if things weren’t working out. Yeah. It was better\nthat way, more open and enlightened. None of this old-fashioned “till death do\nus part” stuff.\n\nYeah, sure.\n\nLaurie startled me, her words somehow picking up on my private thoughts. “This\nshould be your wedding quilt.” Martha and I both stared at her.\n\n“Really. You two are already married—anyone can see it. You’ve been best\nfriends and lovers for almost eight years. So why don’t you make it official\nand celebrate?”\n\nI was completely at a loss. What Laurie had said was so true and obvious that\nI’d been blind not to see it. I had been stuck thinking that we should just go\non, one day at a time, being together “for now,” while things were good. But\nreally, would I leave Martha if we were going through hard times? Would I\nleave her if someone else attracted me more? Was that the kind of person I\nwanted to be, and the way I wanted to live the rest of my life?\n\nAt that moment I realized what to do, and how I wanted to live. I looked at\nMartha, her face calm and still, bent over the bright pieces of calico. There\nwere tears in my eyes, and I couldn’t speak. I looked at Laurie for help, but\nthe moment she saw my face, she vanished into the kitchen to make tea, leaving\nMartha and me alone together.\n\n“Sweetheart?”\n\nShe raised her head and looked at me steadily.\n\n“When do you want to get married?”\n\n“What about next spring, after the rainy season, when there are roses?”\n\nSo it was done. No looking back, no regrets, no glancing around to see if\nsomeone better would come along. Martha and me, for the rest of our lives.\nLaurie poured out the tea, and we all sat together, not saying much, but so\nhappy.\n\nBy October I started thinking about the hacker again. Darren and I argued\nabout whether to publish a paper. “If you don’t say something,” Darren argued,\n“some other hacker will wreck someone else’s computer.”\n\n“But if I do publish, it’ll teach a dozen hackers how.”\n\nThat’s the problem with talking about security problems. If you describe how\nto make a pipe bomb, the next kid that finds some charcoal and saltpeter will\nbecome a terrorist. Yet if you suppress the information, people won’t know the\ndanger.\n\nJanuary marked six months since the hacker had been busted, a year and a half\nsince we’d first detected him. Yet I still didn’t know his name. It was about\ntime to publish my results.\n\nSo I sent the paper to _Communications of the Association of Computer\nMachinery_. Though you won’t find it on newsstands, _Communications_ reaches\nmost computer professionals, and it’s a real scientific journal: every article\nis refereed. Which meant that three other computer scientists checked over my\narticle and made anonymous comments on whether it should be published.\n\nThe paper was to come out in the May issue. Together, the Association for\nComputer Machinery and Lawrence Berkeley Labs scheduled a joint announcement\nfor May first.\n\nMay would be a goofy month. Martha and I planned on getting married at the end\nof the month. We’d reserved the Berkeley Rose Garden, sewn our wedding\nclothes, and invited our friends and relatives. Even without the publicity of\nthe hacker, this month wouldn’t be calm.\n\nWell, we were pretty much all set when the German magazine _Quick_ got there\nfirst. On April 14, they printed a story about how a German hacker had broken\ninto three dozen military computers. Although their reporter had managed to\nmeet the hacker, most of their story came from my logbook.\n\nMy logbook! How did _Quick_ magazine, a cross between _Life_ and the _National\nEnquirer_ , manage to get ahold of my laboratory logbook? I’d kept my logbook\non my computer—it lived on disks, not on paper. Did someone break into my\ncomputer and read my logbook?\n\nImpossible. My logbook was on my Macintosh: I never connected to any network,\nand I hid the disk in my desk every night.\n\nI reread the translation of the article, and realized that someone had leaked\na copy of my logbook from a year ago, January. Before I’d set up the phoney\nSDINET sting. Had I given a copy of that logbook to anyone?\n\nYes, I had. On January 10, I’d sent the logbook to Mike Gibbons at the FBI. He\nmust have forwarded it to the Legal Attaché in Bonn. Who knew where it landed\nnext?\n\nSomeone had leaked it to _Quick_ magazine. And they published the story two\nweeks before I was going to. Damn.\n\nOne year of silence. A year of covert cooperation with the authorities.\nBetrayed to a cheap tabloid in Germany. How ignominious.\n\nEven with a copy of my notebook, _Quick_ was anything but accurate. Not much\nto do but get the facts out ourselves. Damn.\n\nWhatever we did, we’d be late. John Markoff—now at the New York _Times_ —had\nheard about the story and was asking questions. Damn. Only one thing to do: my\nlab announced a press conference. With me at center stage. Damn.\n\nThat evening, at 11 P.M., I was nervous and worried sick. Me? At a press\nconference? A phone call from the NSA didn’t help, either.\n\nSally Knox, an administrator with NSA’s computer security center, was in town.\nShe’d heard about tomorrow’s press conference. “Don’t you dare mention our\nname,” she barked into my ear. “We get enough bad press as it is.”\n\nI look at Martha. She hears this woman’s voice from the phone and rolls her\neyes. I try to soothe the spook’s worries.\n\n“Look, Sally, NSA hasn’t done anything wrong. I’m not about to say that your\nfunding ought to be cut.”\n\n“It doesn’t matter. As soon as the media hears our name, there’ll be trouble.\nThey distort everything about us. They’ll never publish a fair story.”\n\nI look at Martha. She’s motioning me to hang up.\n\n“OK, Sally,” I said. “I’ll make sure that I don’t even mention your agency. If\nanyone asks, I’ll just say, ‘No comment.’ ”\n\n“No, don’t do that. Then those pigs will sniff around and pick up more. Tell\nthem that we had nothing to do with it.”\n\n“Look, I’m not gonna lie, Sally. And anyway, isn’t the National Computer\nSecurity Center a public, unclassified agency?”\n\n“Yes, it is. But that’s no reason to let the press prowl around.”\n\n“Then why don’t you send one of your people to my press conference?”\n\n“None of our employees are authorized to talk to the media.”\n\nWith this attitude, it’s no wonder her agency gets such bad press.\n\nMartha wrote me a note: “Ask her if she’s ever heard of the First Amendment,”\nbut I couldn’t get a word in edgewise. Sally went on about how the Congress\nwas out to get them, the press was out to get them, and I was out to get them.\n\nShe ranted for twenty-five minutes, trying to convince me not to mention NSA\nor the National Computer Security Center.\n\nIt’s 11:30 at night, I’m exhausted, and I can’t take any more. I’ll do\nanything to get off the phone.\n\n“Listen, Sally,” I say, “where do you get off, telling me what I can’t say?”\n\n“I’m not telling you what to say. I’m telling you not to mention the Computer\nSecurity Center.”\n\nI hung up.\n\nMartha rolls over in bed and looks at me. “Are they all like that?”\n\nThe next morning’s press conference was a zoo. I’m accustomed to scientific\nmeetings and technical seminars. You always hear about press conferences, but\nI’d never actually seen one. Now I’m the target of one.\n\nIt was nuts. Along with my boss, Roy Kerth, I spouted for half an hour,\nanswering questions from reporters. The television reporters asked easy ones\n(“How do you feel now that it’s over?”), while the newspaper people asked\njagged, tough questions—“What should be the national policy on computer\nsecurity?” Or “Was Admiral Poindexter justified in clamping down on sensitive\nbut unclassified material?”\n\nNobody asked about the NSA. Not a mention of the National Computer Security\nCenter. Sally had blathered for half an hour in vain.\n\nBeforehand, I’d been pretty jaded on the press. Figured that they’d distort\nwhatever happened. Now here was a technical story, spanning two continents and\na year’s work. How would the American media report it?\n\nAmazingly accurately. My technical article had more details—the Gnu-Emacs\nhole, how the hacker cracked passwords—but I was astounded by how well\nnewspapers conveyed the story. The important stuff was there—the military\ncomputers, the sting, even Operation Showerhead.\n\nAnd these reporters did their homework. They called Germany and somehow dug up\nwhat I had never found: the hacker’s name. They phoned the hacker.\n\n\n![](images/Stol_9780307819420_epub_060_r1.jpg) “Hello, is this Markus Hess in\nHannover?”\n\n“Yes.”\n\n“This is Richard Covey. I’m a reporter here in California. May I talk with\nyou?”\n\n“I cannot talk.”\n\n“About this hacker case—could you tell me if you worked alone or with someone\nelse?”\n\n“I cannot answer that. The case is still running in the German courts.”\n\n“What were your intentions?”\n\n“It was strictly a hobby.”\n\n“Are you a student?”\n\n“Uh, yes. I cannot speak on the phone because I do not trust the lines. They\nmay be tapped.”\n\n“Do you have a lawyer?”\n\n“Yes.”\n\n“What is his name?”\n\nNo answer.\n\n“Do you know Laszlo Balogh in Pittsburgh?”\n\n“No. Never heard of him, except for the newspaper stories.”\n\n“Can you speculate on how Balogh got the false data?”\n\n“I cannot answer that question.”\n\n“Did you work with anyone?”\n\n“I cannot say. I am not comfortable talking. I am not sure that the lines are\nclean.”\n\n“Were you a spy?”\n\n“Ha. Anyone who believes that is ridiculous. I was just curious.”\n\n“Can you guess how the data got to Pittsburgh?”\n\n“No, I cannot guess. I did not show it to anyone. It is dangerous for me to\nsay anything more because I do not know if the telephone lines are clean.”\n\n“Were you paid for your work?”\n\n“I must go now. I cannot talk.” Click Markus Hess. After all this time, my\ncuckoo’s name is Markus Hess.\n\nWell, he speaks English, although without contractions. And he’s as paranoid\non the telephone as he is on the computer—always looking over his shoulder.\nGerman newspapers report that Hess is five foot ten inches, twenty-five years\nold, broad-shouldered, and known to his friends as a solid but not brilliant\nUnix programmer. And he chain-smokes Benson and Hedges.\n\nOnce again, I page through the Hannover telephone directory. There’s his name,\nall right, but who is he? What’s this guy up to? I’ll never find out from\nBerkeley.\n\nMaybe I should call someone in Germany? Who do I know there? A couple students\nat the Max Planck Institute. Some astronomers in Darmstadt. And a college\nbuddy in Hamburg.\n\nAround the end of the summer, a friend of a friend sent a letter to me: “I\nneed a place to stay while visiting San Francisco. Mind if I sleep on your\nfloor?” Seemed it was a high school student visiting from abroad.\n\nMartha, Claudia, and I don’t exactly run a youth hostel, but our door’s always\nopen for visitors. Michael Sperber stayed for a couple nights and kept us\namused with tales of touring the States. Just as interesting to me: his dad,\nJochen Sperber, is a reporter in Northern Germany and could make contact with\nhackers around Hannover.\n\nI struck paydirt. By chance, I’d found someone who was curious, persistent,\nand able to dig up the facts in Germany. Over the next five months, Jochen\nSperber found enough information to piece together what happened at the other\nend of the trail.\n\nWhat really happened? Here’s my estimate, based on interviews, police reports,\nnewspaper accounts, and messages from German computer programmers.\n\nI’d been chasing a shadow. Now I could sketch a portrait.\n\n* * *\n\nIn the early ’80s, the Bundespost expanded the German telephone service to\ninclude data networking. Their Datex service got off to a slow start, but by\n1985 businesses and universities began subscribing. It was a convenient, if\nnot cheap, way to interconnect computers spread across Germany.\n\nAs everywhere, students started to exploit this service. First, discovering\nflaws in the system’s protections; later, finding ways to connect abroad\nthrough the network. The Bundespost had its hands full in starting up Datex,\nand pretty much ignored these hackers.\n\nA dozen hackers started the Chaos Computer Club, whose members specialize in\ncreating viruses, breaking into computers, and serving as a computer\ncounterculture. Some are cyberpunks; a few are extremely proficient in\ncomputing, others little more than novices. Through electronic bulletin boards\nand telephone links, they anonymously exchanged phone numbers of hacked\ncomputers, as well as stolen passwords and credit cards.\n\nMarkus Hess knew of the Chaos Club, although he was never a central figure\nthere. Rather, he kept his distance as a free-lance hacker. During the day, he\nworked at a small software firm in downtown Hannover.\n\nOver a crackling phone connection, Jochen Sperber said, “You see, Hess knew\nHagbard, who kept in touch with other hackers in Germany, like Pengo and\nBresinsky. Hagbard is a pseudonym, of course. His real name is …”\n\nHagbard. I’d heard that name before. After I hung up the phone, I searched my\nlogbook for Hagbard. There he was—he’d broken into Fermilab and Stanford. Yet\nI’d seen it elsewhere. I searched databases at school and asked friends. Not a\npeep. For the next three days, I asked every person I met, in hopes that it\nmight ring a bell with someone.\n\nAt last, at a Berkeley bookstore, the woman behind the counter said, “Why\nsure. Hagbard is the hero of the Illuminati books.” It’s a series of science\nfiction novels, about an international conspiracy that controls the world. The\nIlluminati run—and ruin—everything. Against this age-old secret cult, Hagbard\nleads a small band of anarchists.\n\nSo Hess’s compatriot runs under the alias of Hagbard. He must really believe\nthat there’s a conspiracy out there. And he probably feels that I’m one of the\nsecret Illuminati—out to suppress the good guys!\n\nMaybe he’s right. A couple of my radical friends would agree with him. But I\nsure don’t know any secrets.\n\nWell, Hagbard worked closely with Markus Hess. The two drank beers together at\nHannover bars, and spent evenings behind Hess’s computer.\n\nWho’s Hagbard? According to the German magazine _Der Spiegel_ , Hagbard—Karl\nKoch—was a twenty-three-year-old programmer who needed money to support a\nstiff cocaine habit, not to mention monthly telephone bills for overseas\nhacking adventures.\n\nDuring 1986, some hackers from Berlin and Hannover discussed (over alcohol and\ndrugs) how to raise some money.\n\nPengo—real name Hans Huebner—was an accomplished eighteen-year old programmer\nwho claimed to be in it for the pure technical challenge. He was bored with\nthose computers that he had legal access to, so he started breaking into\nsystems via the international networks. In a message posted to a bulletin\nboard, Pengo said that he was involved with “a circle of persons who tried to\nmake deals with an eastern secret service.”\n\nWhy? Since the software on the systems that he had legal access to “didn’t\nturn me on anymore, I enjoyed the lax security of the systems I had access to\nby using [international] networks.” Computing had become an addiction for\nPengo.\n\nBut why sell the information to the Soviet bloc agents? According to _Der\nSpiegel_ , he needed money to invest in his computing company. So Pengo got\ntogether with a couple others in West Berlin. One of them, Dirk Brezinski, is\na programmer and troubleshooter for the German computer firm Siemens. Another,\nPeter Carl, also in Berlin, is a former croupier who “always had enough\ncocaine.”\n\nThese five worked together to discover new ways to break into computers,\nexploring military networks and sharpening their skills at cracking operating\nsystems. Pengo specialized in Digital’s Vax VMS operating system and\nfrequently talked with Hagbard.\n\nPengo had no scruples about selling information to Soviet bloc agents. He saw\nhimself as ethically neutral—he didn’t want to give the Russians any\nadvantage; he just wanted to have fun on the networks.\n\nAnd pick up some cash along the way.\n\nHess, too, just played around the networks, searching for ways to connect\naround the world. He’d dropped out of the University of Hagen, where he didn’t\nquite finish a degree in mathematics and physics. (Physics? If only he’d\nknown!)\n\nAt first, Hess apparently just played around the networks, searching for ways\nto connect around the world. Like a ham radio operator, he started out a\nhobbyist, trying to reach as far away as possible. At first, he managed to\nconnect to Karlsruhe; later he reached Bremen over the Datex network.\n\nSoon, he discovered that many system managers hadn’t locked their backdoors.\nUsually these were university computers, but Markus Hess began to wonder: how\nmany other systems were wide open? What other ways could you sneak into\ncomputers?\n\nIn early 1986, Hagbard and Pengo were routinely breaking into computers in\nNorth America: mostly high-energy physics labs, but a few NASA sites as well.\nHagbard described his exploits to Hess.\n\nThe challenge was there. Hess began to explore outside of Germany. But he no\nlonger cared about universities and physics labs—he wanted real excitement.\nHess and Hagbard would target the military.\n\nThe leaders of the Chaos Computer Club had issued a warning to their members:\n“Never penetrate a military computer. The security people on the other side\nwill be playing a game with you—almost like chess. Remember that they’ve\npracticed this game for centuries.” Markus Hess wasn’t listening.\n\nHess found his way into an unprotected computer belonging to a German\nsubsidiary of the U.S. defense contractor, Mitre. Once inside that system, he\ncould have discovered detailed instructions to link into Mitre’s computers in\nBedford, Massachusetts, and McLean, Virginia.\n\nWhy not? The system was wide open, and let him call anywhere in America.\n\nBy summer 1986, Hess and Hagbard were operating separately, but frequently\ncomparing notes. They collaborated in methodically twisting all doorknobs as\nthey walked down the streets of the military networks.\n\nMeanwhile, Hess worked in Hannover programming Vax computers and managing\nseveral systems. His supervisor knew of Hess’s moonlighting and approved: his\nexploits apparently fitted in well with their general business plans (even\nnow, I wonder what those could have been!).\n\nHess soon expanded his beachhead at Mitre. He explored their system\ninternally, then sent out tentacles into other American computers. He\ncollected telephone numbers and network addresses, and methodically attacked\nthese systems. On August 20, he struck Lawrence Berkeley Lab.\n\nEven then, Hess was only fooling around. He’d realized that he was privy to\nsecrets, both industrial and national, but kept his mouth shut. Then, around\nthe end of September, in a smoky Hannover beer garden, he described his latest\nexploit to Hagbard.\n\nYou can’t make money by breaking into universities and colleges. Who’s\ninterested in data from physics labs, other than a few grad students?\n\nBut military bases and defense contractors? Hagbard smelled money.\n\nAnd Hagbard sensed who to contact: Pengo, in West Berlin.\n\nPengo, with his contacts to hackers across Germany, knew how to use Hess’s\ninformation. Carrying Hess’s printouts, one of the Berlin hackers crossed into\nEast Berlin and met with agents from the Soviet KGB.\n\nThe deal was made: around 30,000 Deutschmarks—$18,000—for printouts and\npasswords.\n\nThe KGB wasn’t just paying for printouts, though. Hess and company apparently\nsold their techniques as well: how to break into Vax computers; which networks\nto use when crossing the Atlantic; details on how the Milnet operates.\n\nEven more important to the KGB was obtaining research data about Western\ntechnology, including integrated circuit design, computer-aided manufacturing,\nand, especially, operating system software that was under U.S. export control.\nThey offered 250,000 Deutschmarks for copies of Digital Equipment’s VMS\noperating system.\n\nPeter Carl and Dirk Brezinski apparently met with the KGB a dozen times,\nfilling many of their requests: source code to the Unix operating system,\ndesigns for high-speed gallium-arsenide integrated circuits, and computer\nprograms used to engineer computer memory chips.\n\nAlone, the source code to Unix isn’t worth $130,000. Chip designs? Perhaps.\nBut a sophisticated computer design program … well, maybe the KGB did get its\nmoney’s worth.\n\nHagbard wanted more than Deutschmarks. He demanded cocaine. The KGB was a\nwilling supplier.\n\nHagbard passed some of the money (but none of the cocaine) to Hess, in return\nfor printouts, passwords, and network information. Hagbard’s cut went to pay\nhis telephone bill, sometimes running over a thousand dollars a month, as he\ncalled computers around the world.\n\nHess saved everything. He kept a detailed notebook and saved every session on\na floppy disk. This way, after he disconnected from a military computer, he\ncould print out the interesting parts, and pass these along to Hagbard and on\nto the KGB.\n\nAlso the KGB’s wish list was SDI data. As Hess searched for it, I naturally\ndetected SDI showing up in his requests. And Martha’s Operation Showerhead fed\nHess plenty of SDI fodder.\n\nBut could the KGB trust these printouts? How could they be certain that\nHagbard wasn’t inventing all of this to feed his own coke habit?\n\nThe KGB decided to verify the German hacker ring. The mythical Barbara Sherwin\nserved as a perfect way to test the validity of this new form of espionage.\nShe had, after all, invited people to write to her for more information.\n\nBut secret services don’t handle things directly. They use intermediaries. The\nKGB contacted another agency—either the Hungarian or Bulgarian intelligence\nservice. They, in turn, apparently had a professional relationship with a\ncontact in Pittsburgh: Laszlo Balogh.\n\nThe Bulgarian embassy in America probably has a standing agreement with Laszlo\nalong the lines of “We’ll pay you $100 for mailing the following letter …”\n\nLaszlo Balogh didn’t care one way or another. According to the _Pittsburgh\nPost-Gazette_ , Laszlo billed himself as a Hungarian refugee; a draftsman; a\ncredit corporation employee; a trucking company owner; a diamond dealer; a\nworld traveler; a bodyguard for Kuwaiti princesses; a CIA hit man; and an FBI\ninformant.\n\nThe newspaper wrote “Although he has claimed extensive foreign government\ncontacts and driven expensive foreign cars, he once testified that he had\ndifficulty recording an undercover conversation for the FBI because the\nrecorder kept slipping beneath his sweat suit.”\n\nApparently Balogh ran a now-defunct company when a forged check drawn on a\nnonexistent bank was used to obtain a garbage hauling contract. Other times he\nwas involved in schemes to steal $38,000 in diamonds, and to sell computer\nequipment to the Soviets. Indeed, he once claimed to have been held captive at\nthe Soviet embassy.\n\nAs long as the money was green, Laszlo didn’t care where it came from. He knew\nnothing about SDINET, knew nobody in Hannover, and said he didn’t even own a\ncomputer.\n\nHmmm. I looked over Laszlo’s letter. It had been word-processed—not a\ntypewriter, but a word processor. If Laszlo Balogh doesn’t own a computer,\nthen who’d created this letter? The Bulgarian embassy perhaps?\n\nDoes the FBI have enough evidence to indict Laszlo Balogh? They won’t tell me.\nBut the way I see it, Laszlo’s in deep yogurt: the FBI is watching him, and\nwhoever’s pulling his puppet strings isn’t pleased.\n\nThe West German police, though, have plenty of evidence against Markus Hess.\nPrintouts, phone traces, and my logbook. When they broke into his apartment on\nJune 29, 1987, they seized a hundred floppy disks, a computer, and\ndocumentation describing the U.S. Milnet. Not much doubt there.\n\nBut when the police raided Hess’s apartment, nobody was home. Though I was\nwaiting patiently for him to appear on my computer, the German police entered\nhis place when he wasn’t connected.\n\nAt his first trial, Hess got off on appeal. His lawyer argued that since Hess\nwasn’t connected at the moment his apartment was raided, he might not have\ndone the hacking. This, along with a problem in the search warrants, was\nenough to overturn the case against hess on computer theft. But the German\nfederal police continued to investigate.\n\nOn March 2, 1989, German authorities charged five people with espionage:\nPengo, Hagbard, Peter Carl, Dirk Bresinsky, and Markus Hess.\n\nPeter Carl met regularly with KGB agents in East Berlin, selling any data the\nothers could find. When the German BKA caught up with him, he was about to run\noff to Spain. He’s now in jail, awaiting trial, along with Dirk Bresinsky, who\nwas jailed for desertion from the German Army.\n\nPengo is having second thoughts about his years working for the KGB. He says\nthat he hopes he “did the right thing by giving the German police detailed\ninformation about my involvement.” But as long as there’s an active criminal\ncase, he’ll say no more.\n\nAll the same, the publicity hasn’t helped Pengo’s professional life. His\nbusiness partners have shied away from backing him, and several of his\ncomputing projects have been canceled. Outside of his business losses, I’m not\nsure he feels there’s anything wrong in what he did.\n\nToday, Markus Hess is walking the streets of Hannover, free on bail while\nawaiting a trial for espionage. Smoking Benson and Hedges cigarettes. And\nlooking over his shoulder.\n\nHagbard, who hacked with Hess for a year, tried to kick his cocaine habit in\nlate 1988. But not before spending his profits from the KGB: he was deep in\ndebt and without a job. In spring 1989 he found a job at the office of a\npolitical party in Hannover. By cooperating with the police, he and Pengo\navoided prosecution for espionage.\n\nHagbard was last seen alive on May 23, 1989. In an isolated forest outside of\nHannover, police found his charred bones next to a melted can of gasoline. A\nborrowed car was parked nearby, keys still in the ignition.\n\nNo suicide note was found.\n\n\n![](images/Stol_9780307819420_epub_061_r1.jpg) When I began this hunt, I saw\nmyself as someone engaged in mundane tasks. I did what I was assigned to do,\navoided authority, and kept myself peripheral to important issues. I was\napathetic and outside the political sphere. Yeah, I vaguely identified myself\nwith the old ’60s left movement. But I never thought much about how my work\ninteracted with society … maybe I picked astronomy because it has so little to\ndo with earthly problems.\n\nNow, after sliding down this Alice-in-Wonderland hole, I find the political\nleft and right reconciled in their mutual dependency on computers. The right\nsees computer security as necessary to protect national secrets; my leftie\nfriends worry about an invasion of their privacy when prowlers pilfer data\nbanks. Political centrists realize that insecure computers cost money when\ntheir data is exploited by outsiders.\n\nThe computer has become a common denominator that knows no intellectual,\npolitical, or bureaucratic bounds; the Sherwin Williams of necessity that\ncovers the world, spanning all points of view.\n\nRealizing this, I’ve become pro-active—almost rabid—about computer security. I\nworry about protecting our vulnerable data banks. I wonder what happens on\nfinancial networks, where millions of dollars slosh around every minute. I’m\nticked that the Feds don’t seem to be minding the mint. And I’m upset that\nlooters have proliferated.\n\nIt took a lot of crap to make me give a damn. I wish that we lived in a golden\nage, where ethical behavior was assumed; where technically competent\nprogrammers respected the privacy of others; where we didn’t need locks on our\ncomputers.\n\nI’m saddened to find talented programmers devoting their time to breaking into\ncomputers. Instead of developing new ways to help each other, vandals make\nviruses and logic bombs. The result? People blame every software quirk on\nviruses, public-domain software lies underused, and our networks become\nsources of paranoia.\n\nFears for security really do louse up the free flow of information. Science\nand social progress only take place in the open. The paranoia that hackers\nleave in their wake only stifles our work … forcing administrators to\ndisconnect our links to networked communities.\n\nYes, you can make secure computers and networks. Systems that outsiders can’t\neasily break into. But they’re usually difficult to use and unfriendly. And\nslow. And expensive. Computer communications already costs too much—adding\ncryptographic encoding and elaborate authentication schemes will only make it\nworse.\n\nOn the other hand, our networks seem to have become the targets of (and\nchannels for) international espionage. Come to think of it, what would I do if\nI were an intelligence agent? To collect secret information, I might train an\nagent to speak a foreign language, fly her to a distant country, supply her\nwith bribe money, and worry that she might be caught or fed duplicitous\ninformation.\n\nOr I could hire a dishonest computer programmer. Such a spy need never leave\nhis home country. Not much risk of an internationally embarrassing incident.\nIt’s cheap, too—a few small computers and some network connections. And the\ninformation returned is fresh—straight from the target’s word processing\nsystem.\n\nToday there’s only one country that’s not reachable from your telephone:\nAlbania. What does this mean for the future of espionage?\n\nYow! What am I thinking about? I’m not a spy—I’m just an astronomer who’s been\naway from science for too long.\n\nAs I turned off my monitors and wound up the cables, I realized that for a\nyear, I’d been caught in a maze. I’d thought I’d been setting traps; actually,\nI’d been trapped the whole while. While the hacker was searching military\ncomputers, I was exploring different communities—on the networks and in the\ngovernment. His journey took him into thirty or forty computers; mine reached\ninto a dozen organizations.\n\nMy own quest had changed. I thought I was hunting for a hacker. I’d imagined\nthat my work had nothing to do with my home or country … after all, I was just\ndoing my job.\n\nNow, with my computers secured and holes patched, I biked home, picked a few\nstrawberries, and mixed some milkshakes for Martha and Claudia.\n\nCuckoos will lay their eggs in other nests. I’m returning to astronomy.\n\n\n![](images/Stol_9780307819420_epub_062_r1.jpg) While I was desperately trying\nto wrap up the hacker chase, we also had a wedding to plan. It was a hectic\ntime, and I cursed my work (and Hess) for distracting me from my home life. We\nwere going to be married at the end of May, so the April revelations were\nparticularly awkward, Martha ending up with more than her share of the\npreparations.\n\nShe was coping, however, firmly resolved to make the wedding true to who we\nwere. We silk-screened our own invitations, saying that the two of us, along\nwith our families, were doing the inviting. Naturally, the ink on the silk-\nscreen leaked through, and half the invitations had our fingerprints, but\nthat’s a part of the home brew.\n\nMartha decked out in a white dress and veil, and me in a tux? Absurd. And\nLaurie in a bridesmaid’s outfit? Nobody ever made Laurie wear a dress for any\nreason. Somehow we managed. Laurie wore white linen pants and a tailored\njacket, Martha made a simple pale yellow dress, and I sewed my own cotton\nshirt. (Try sewing your own shirt sometime. You’ll learn a new respect for\nshirtmakers, especially after you sew the cuffs on backward.)\n\nSo it rained on our wedding and there wasn’t a place to hide in the rose\ngarden. Claudia’s string quartet unraveled a tarp, protecting their violins\nfrom the downpour. My sister Jeannie showed up, straight from her last class\nat Navy War College—and straight into a political argument with Laurie. Of\ncourse, after the ceremony, we got lost driving to a remote inn by the ocean.\n\nIt was wonderful, all the same. Say what you will about marriage, this was the\nhappiest day of my life.\n\nSure, I could have just stayed living with Martha, never quite committing\nmyself beyond next month’s rent. I’d lived with several other people in this\ncasual way, saying we were in love, but always ready to split if things got\ntough. We dressed it up with talk about openness and freedom from oppressive\nconventions, but for me it was just an excuse. The truth was, I had never\ndared to give myself fully to anyone, committing myself to make it work no\nmatter what. But now I’d found someone I loved and trusted enough to gather my\ncourage and stand by, not just for now but forever.\n\nBut domestic happiness doesn’t solve everything—I still had to figure out what\nto do next. With Hess unmasked, I could return to astronomy, or at least,\ncomputing. Not quite tracking an international spy ring, but then, there’s\nresearch to do everywhere. The best part is not knowing where your science\nwill lead you.\n\nIt wasn’t the same. The computer people felt I’d wasted the past couple years\nrubbing shoulders with spies. The spies didn’t have much use for me—who needs\nan astronomer? And the astronomers knew I’d been away from the field for two\nyears. Where do I go from here?\n\nMartha had passed her bar exam and was clerking for a judge across the bay, in\nSan Francisco. She loved it—taking notes on trials, researching case law,\nhelping to write decisions. A sort of grad school for law.\n\nShe found another clerkship in Boston, starting in August ’88. Over a\nstrawberry milkshake, she described her possibilities:\n\n“I’d clerk for the circuit court in Boston. It’ll be more academic there—no\ntrials, just appeals. Might be fun.”\n\n“And the alternatives?”\n\n“Well, I’m thinking about returning to school, to finish my degree in\njurisprudence. That’ll take a few more years.” Always the academic.\n\nWould I leave Berkeley to follow her to Massachusetts?\n\nSimple decision: I’d follow her anywhere. If she’s going to Boston, I’d dredge\nup a job there. Fortunately, the Harvard Smithsonian Center for Astrophysics\nwas looking for a half-breed astronomer-computer jockey, someone to play with\ntheir X-ray astronomy database.\n\nI can mess up a database as well as the next person, and they didn’t mind my\nhiatus from astronomy. And, being astronomers, they were already accustomed to\npeople showing up late and sleeping under desks.\n\nIt wasn’t easy to leave Berkeley—the strawberries, the street vendors, the\nsunshine—but we signed a nonaggression pact with our roommates: we could visit\nanytime and wouldn’t have to wash the dishes. In return, they could stay at\nour place in Massachusetts, so long as they brought some California kiwi\nfruit.\n\nThe hardest part was leaving our roommate Claudia. I’d grown accustomed to her\nlate-night Mozart practicing (a long way from the Berkeley Grateful Dead\nconcerts!). She hadn’t quite settled down with a mate, although several\npromising musicians were courting her just as we left. The latest gossip? Oh,\nthere’s this handsome orchestra conductor that’s simply lusting after her …\n\nSo, in August 1988, we packed a couple suitcases for a year in Massachusetts.\n\nBeing uprooted and towed to the East Coast had a few advantages. My computer\nnetwork address changed … a good thing, since several hackers had tried to\nbreak into it after I published my article. One or two had threatened me in\nvarious ways—better not to give ’em a standing target. And various three-\nletter agencies stopped calling me, asking for advice, opinions, and rumors.\nNow, in Cambridge, I could concentrate on astronomy, and forget about computer\nsecurity and hackers.\n\nOver the past two years, I’d become an expert on computer security, but hadn’t\nlearned a thing about astronomy. Worse, the physics of X-ray astronomy was\ntotally foreign to me: I’m accustomed to planetary science, and planets don’t\ngive off X-rays.\n\nSo what do X-ray astronomers look at? The sun. Stars and quasars. And\nexploding galaxies.\n\n“Exploding galaxies?” I asked Steve Murray, my new boss at the Center for\nAstrophysics. “Galaxies don’t explode. They just sit there in spirals.”\n\n“Bah. You learned your astronomy in the ’70s,” Steve replied. “Why, we’re\nlooking at stars exploding into supernovas, bursts of X-rays from neutron\nstars, even stuff falling into black holes. Hang around here for a while and\nwe’ll teach you some real astronomy.”\n\nThey didn’t fool around. Within a week, I was settled behind a computer,\nbuilding databases of X-ray observations. Classical computing, but there’s\ngood physics in there. Yow! There really are black holes in the middle of\ngalaxies. I’ve seen the data.\n\nThe Smithsonian Astrophysical Laboratory shares buildings with Harvard\nObservatory. Naturally, everyone’s heard of Harvard Observatory. But the\nSmithsonian? That’s in Washington, isn’t it? Only after I moved to Cambridge\ndid I realize that the Smithsonian had a hot-damn astronomy section, the\nCenter for Astrophysics. Makes no difference to me, so long as they’re doing\ngood astronomy.\n\nCambridge, Massachusetts, might be across the country, but culturally, it’s\njust around the corner from Berkeley. Lots of ’60s hippies, left-wing\npolitics, bookstores, and coffeehouses. There’s street musicians most every\nnight, and you’re serenaded at the downtown subway stations by guitars and\nmandolins. And the neighborhoods—some of these houses are a hundred years old.\nBicycling in Cambridge is sheer excitement—the drivers aim right at you.\nHistory, weird people, good astronomy, cheap pizza … all the ingredients for a\ngood place to live.\n\nMarriage? Except that Martha keeps me away from microwave ovens, it’s been a\nkicker.\n\nWednesday, November 2, 1988, Martha and I stayed up late, reading a novel out\nloud. Around midnight we pulled up the quilt and fell asleep.\n\nI was dreaming about floating through the air on an oak leaf when the phone\nrang. Damn. The glow-in-the-dark clock said 2:25 A.M.\n\n“Hi, Cliff. It’s Gene. Gene Miya at NASA Ames Laboratory. No apologies for\nwaking you up. Our computers are under attack.” The excitement in his voice\nwoke me up.\n\n“Wake up and check your system,” Gene said. “Better yet, stay asleep and check\nit. But call me back if you see anything strange.”\n\nI’d hung up the phone for ten seconds when it rang again. This time, the line\njust beeped. A Morse code beep.\n\nMy computer was calling. It wanted my attention.\n\nOh hell. Can’t hide. I stumbled over to the trusty old Macintosh, dialed into\nHarvard Observatory’s computer, and typed in my account name, Cliff. Then my\nnon-dictionary password, “Robotcat.”\n\nSlow logging in. After five minutes, I gave up. My computer just wasn’t\nresponding. Something was wrong.\n\nWell, as long as I was awake, I might as well see what’s on the West Coast.\nMaybe there’s some electronic mail waiting for me. I connected over Tymnet\ninto Lawrence Berkeley Labs—no long-distance phone calls for me.\n\nThe Unix system at Berkeley was slow, too. Frustratingly slow. But only one\nother guy was using it. Darren Griffiths.\n\nOver the screen, we exchanged a couple notes:\n\n**Hi Darren–It’s Cliff. How’s things :-)**\n\n**Cliff, call me on the phone right away. We’re under attack**.\n\n**OK O-O**\n\nO-O means Over and Out. And the :-) is a crude smiley face. You look at it\nsideways, and it smiles at you.\n\n2:15 A.M. in Massachusetts isn’t yet midnight in Berkeley. Darren was nowhere\nnear asleep.\n\n“Hi, Darren. What’s this attack?”\n\n“Something’s eating our system, starting a lot of processes running. Slowing\nthe system down.”\n\n“A hacker?”\n\n“No. I’d guess a virus, but I can’t tell right now.” Darren spoke slowly as he\ntyped. “I’ve been working on it for ten minutes, so I’m not sure.”\n\nThen I remembered Gene Miya’s call. “NASA Ames Labs says the same thing.”\n\n“Yeah. I bet we’re under attack from the Arpanet,” Darren said. “Yeah, look at\nall these network connections!”\n\nI couldn’t see any—as long as I talked on the phone, my computer was\ndisconnected and I was blind. With a single phone line, either I could speak\non the phone, or my Macintosh could talk to another computer, but not both. I\nhung up and dialed into my Harvard computer, a desktop computer made by Sun.\nSlow. Something was chewing on it.\n\nI looked at the processes running (with a _ps_ command, like the hacker had\ntaught me). There was the virus. But not just running one or two jobs.\nHundreds of connections to other computers.\n\nEach process was trying to talk to some other computer. The connections came\nfrom all over: nearby systems at Harvard, distant computers from the Arpanet.\n\nAs fast as I’d kill one program, another would take its place. I stomped them\nall out at once; not a minute later, one reappeared. Within three minutes,\nthere were a dozen. Holy smoke!\n\nWhat’s crawling around my computer?\n\n\n![](images/Stol_9780307819420_epub_L04_r1.jpg) A biological virus is a\nmolecule which sneaks into a cell and convinces the cell to copy the virus\nmolecule, instead of the cell’s DNA molecules. Once duplicated, the virus then\nbreaks out of the cell to infect other cells.\n\nSimilarly, a computer virus is a program that replicates itself. Like its\nbiological namesake, it enters a system, duplicates itself, and sends copies\nof itself to other systems.\n\nTo the host computer, a virus looks like a series of commands which appear\nperfectly legitimate, yet have dire consequences. Often these commands are\nburied within ordinary programs, hibernating until the program is executed.\nWhen the infected program is run, all seems fine until the virus is executed.\nThen the computer is tricked into copying the virus instructions elsewhere.\n\nWhere? Probably the virus will copy itself into another program on the same\ncomputer, making it tough to eradicate. Or maybe onto another disk, so that\nsomeone will transport it to another computer.\n\nPerhaps the virus will do nothing more than duplicate itself into other\nprograms. A malicious virus maker, however, might throw in a side effect:\n“Copy yourself four times, then erase all the word processing files.”\n\nComputer viruses spread most easily on personal computers: these machines have\nno protections built into their operating systems. At a PC, you can run any\nprogram you wish and change any part of memory. On small computers, it’s hard\nto tell if a program has been changed on a disk.\n\nBigger computers, like Unix systems, are more resistant: their operating\nsystems isolate one user from another, and set limits on how much you can\nmodify. In addition, you can’t change system programs without permission—the\noperating system’s walls seal you out of those sensitive areas.\n\nThe virus writer must carefully tailor the program to a target computer. A\nprogram that runs on your IBM PC won’t work on my Macintosh, or my lab’s Unix\nsystem. Then too, the virus program can’t occupy much space, or it’ll easily\nbe discovered and removed.\n\nA virus is a good place to hide time bombs. It’s easy to design a virus whose\ninstructions work like this:\n\n“Copy me into four other programs.”\n\n“Wait until February 13.”\n\n“Erase all the files on the system.”\n\nThe virus must find a way to propagate. Simply infecting programs on one\ncomputer will only hurt one person. The creator of a malicious virus wants the\nvirus to infect hundreds of systems. How do you pass a program to hundreds of\nothers?\n\nPeople exchange software on disks. Infect one program on a disk, and it’ll\ninfect every system that runs that program. As the disk is passed from office\nto office, dozens of computers can be infected and possibly wiped out.\n\nPublic bulletin boards also exchange software. These dial-in computers are run\nby hobbyists, schools, and a few companies. You dial their number and copy\nprograms from the bulletin board into your home computer. You can just as\neasily copy a program from your home system into the bulletin board. There\nit’ll wait until someone requests it. And if your program has a virus buried\ninside, well, you won’t discover it until it’s too late.\n\nSo computer viruses spread by interchanging programs. Someone brings an\ninfected program—a fun game—into work and runs it on her office machine. The\nvirus copies itself into her word processing program. Later she gives her word\nprocessing disk to a friend. Her friend’s system gets infected. Oh, each\nprogram appears to work properly. But when February 13 rolls around …\n\nThe obvious way to prevent viruses is to avoid exchanging programs. Don’t take\ncandy from strangers—don’t accept untrusted programs. By keeping your computer\nisolated from others, no virus program can infect it.\n\nThis canonical wisdom overlooks our daily needs. Unless we exchange programs\nand data, our computers won’t be much use to us. There’s a wealth of public-\ndomain software—much of it ideal for solving our problems.\n\nViruses and logic bombs poison this communal well. People stop trusting public\nsoftware, and eventually the sources of public software dry up.\n\nBut there’s another way for a virus to propagate: directly over a network.\n\nOur Arpanet interconnects eighty thousand computers across the country. You\ncan send mail to anyone on these computers, send or receive files over the\nArpanet, or (as Markus Hess showed) interactively log into computers connected\nto the Arpanet.\n\nCould a virus propagate over the Arpanet? A program that copies itself from\none computer, out over the network, into another …\n\nI’d thought of this before, but had always dismissed the possiblity. Arpanet\ncomputers have defenses against viruses: you need passwords to log into them.\nHess got around this by guessing passwords. Could a virus guess passwords?\n\nAt 3:30 in the morning, shivering behind my Macintosh at home, I dialed into\nmy observatory’s computer. It’s a Sun workstation, running the popular\nBerkeley flavor of Unix. All those hundreds of jobs were still running … my\nsystem was grossly overloaded. No hacker was logged in. Just me.\n\nSame symptom at Lawrence Berkeley Labs. And NASA Ames. Smells like a virus.\n\nI called Darren Griffiths at LBL. “It’s a virus,” he affirmed. “I can watch it\nreplicate. Try killing the jobs. They’ll come right back.”\n\n“From where?”\n\n“I’m getting connections from five places. Stanford, University of Rochester,\nAerospace Company, the Berkeley campus, and somewhere called BRL.”\n\n“That’s the Army’s Ballistics Research Lab,” I said, remembering a\nconversation with BRL’s Mike Muuss. “How’s the virus getting into your\nsystem?”\n\n“I can’t tell, Cliff. The connections are all from the Arpanet, but it’s not\nthe usual way of logging into the system. Looks like the virus is breaking in\nthrough a hole in the mail system.”\n\nSomeone’s built a virus that exploits a security hole in Unix systems. The\nhole is in the mail system, and the virus spreads over the network. What’s the\nvirus doing? Just copying itself, or does it have a time bomb built in?\n\nIt’s 4 A.M. What to do? I’d better call the Arpanet controllers and warn them.\nThere’s a twenty-four-hour duty officer at the Network Operations Center that\nwatches over the network. This morning, they’ve heard nothing of this virus.\n“Better call around, because it’ll be all over the place by nine this\nmorning.”\n\nThe Networks Operations Center hasn’t heard. The virus is only a few hours\nold. I’m seeing viruses coming from a dozen other sites. Virulent. By morning\nit will have spread to scores or even hundreds of systems. We’ve got a\nproblem. A major problem.\n\nAn epidemic.\n\nWe’ve got to understand this virus and spread the word. For the next thirty-\nsix hours I knocked myself out, trying to understand and defeat this thing. I\nknew I wasn’t alone. At the same time, groups at Berkeley, MIT, and Purdue\nUniversity were already hot on the trail.\n\nHere I’m only describing what I saw, but my struggle was minor compared to the\nwork of Unix wizards across the country. One by one, programmers reacted—gurus\nlike Keith Bostic, Peter Yee, Gene Spafford, Jon Rochlis, Mark Eichin, Donn\nSeeley, Ed Wang, and Mike Muuss. I was but a small part of an unorganized but\ndedicated response to this disaster.\n\nI dig into the code in my system in Cambridge. Right off I can see two\nversions of the virus. One’s customized for Vax computers running Unix. The\nother’s for Sun workstations. Each file is forty-five thousand bytes long. If\nit were English, it would fit in about thirty pages. But it’s not text—I dump\nthe file and it looks like gibberish. It doesn’t even look like machine code.\n\nNow this doesn’t make sense: computer programs _look_ like machine code. This\none doesn’t. There’s no header block information and only a few commands that\nI recognize. The rest is guacamole.\n\nPatiently I try to understand what those few commands do. Suppose I were a Sun\nworkstation, and someone fed those commands to me. How would I respond? With a\npad of paper, hand calculator, and a booklet of machine instructions, I start\nunwinding the virus’s code.\n\nThe first few commands just strip off some encryption from the rest of the\nvirus. That’s why the virus looks strange. The actual commands have been\npurposely obscured.\n\nAha! The virus writer has hidden his virus: he’s tried to prevent other\nprogrammers from understanding his code. Throwing nails on the road to slow\ndown his pursuers.\n\nDiabolical.\n\nTime to call Darren again. It’s 5 A.M. and we’re comparing notes—he’s\ndiscovered the same thing and more: “I’ve unmasked part of the virus, and I\ncan see it’s breaking in through the mail system. Then, it uses _finger_ and\n_telnet_ to spread itself to other computers. It’s decrypting passwords by\nbrute force guessing.”\n\nTogether, over the phone, we pry apart the program. Its whole purpose seems to\nbe to copy itself into other computers. It searches for network\nconnections—nearby computers, distant systems, anything that it can reach.\n\nWhenever the virus program discovers a computer on the network, it tries to\nbreak into it, using several obscure holes in the Unix operating system.\n\nHoles in Unix? Sure.\n\nWhen you send mail from one Unix computer to another, the Unix _Sendmail_\nprogram handles the transfer. A mail message arrives from the network and\n_Sendmail_ forwards it to the addressee. It’s an electronic post office that\npigeonholes mail.\n\n_Sendmail_ has a hole. Normally, a foreign computer sends messages into this\nprogram and everyone’s happy. But if there’s a problem, you can ask the\nprogram to enter debug mode—the program’s backdoor.\n\nWhen you’re in debug, _Sendmail_ lets you issue ordinary Unix commands from a\nforeign computer. Commands like “Execute the following program.”\n\nSo that’s how this virus spawned copies. It mailed copies of itself to other\ncomputers and commanded them to execute the virus program.\n\nAfter the virus program started, it searched for other computers to infect and\nsent mail messages to them.\n\nOn some systems, _Sendmail_ had been fixed. If so, the virus tried yet another\nhole: the finger daemon.\n\nTo see if I’ve been using a Unix system, you can issue the command, _finger\ncliff_. If I’ve been logged in, Unix will respond with my name, phone number,\nand what I’m up to. It works well over the network; often I’ll just finger\nsomeone before calling their telephone.\n\nThe virus invaded through the program that handled finger requests. The finger\ndaemon has room for 512 characters of data; the virus sent 536 characters.\nWhat happened to the extra 24 characters? They got executed as commands to\nUnix.\n\nBy overflowing the finger daemon, the virus found a second way to execute the\ncommand, “Execute the following program,” on someone else’s computer.\n\nIf that wasn’t enough, the virus had a password guesser built in. It tried to\nlog into nearby, trusted computers, using a few hundred common passwords. If\nit guessed a valid password, it copied itself into the computer and started\nall over.\n\nWhew! Any one of these ways would impregnate a lot of computers. Taken\ntogether, they formed a fiendishly effective virus.\n\nLike a sorcerer’s apprentice, the program kept copying itself from one\ncomputer to another. Erase one copy, and a new one would spring into its\nplace. Plug up one hole, and the virus would try a different hole.\n\nDid I say virus?\n\n“You know, Cliff, a virus modifies other programs when it runs. This thing\ndoesn’t change other programs; it just copies itself,” Darren explained. “It’s\nreally not a virus, it’s a network worm.”\n\nA virus copies itself into other programs, changing the program itself. A worm\ncopies itself from one computer to another. Both are contagious; either can\nspread havoc.\n\nViruses usually infect personal computers, spreading through floppy disks and\ncopied programs. Worms strike over networks, spreading through the very\nconnections used for electronic mail and communications.\n\nBut at 5 A.M., all I knew was that my computers were bogged down and it’s the\nfault of this self-replicating program. It’s a cuckoo, laying eggs in other\nbirds’ nests.\n\nWorm or virus, whoever built it has deliberately thrown up roadblocks to\nprevent anyone from understanding it. The code’s encrypted, and it hides its\ninternal tables. It erases any evidence of its parent worm. It feints by\nappearing to send a message to a Berkeley computer, while actually sending\nnothing at all—an attempt to draw attention away from the real source of the\nprogram.\n\nBy 6 A.M., Thursday morning, I’m thinking about the effects of this worm: a\ndisaster’s brewing, and someone needs to be notified. Who?\n\nI’ve called the Arpanet Network Operations Center. They can’t do much—even if\nthey turn off the whole network, the worm will still breed, moving around\nlocal networks. Better call the National Computer Security Center. Who do I\nknow there? Bob Morris, their chief scientist.\n\n\n![](images/Stol_9780307819420_epub_L04_r1.jpg) I knew Bob Morris was on his\ncomputer at 6:30 A.M. Thursday morning. I could see him logged into NSA’s\nDockmaster computer. After posting a message to that machine, I called him on\nthe phone.\n\n“Hi, Bob. We’ve got troubles. A virus is spreading over the Arpanet, and it’s\ninfesting Unix computers.”\n\n“When did it start?”\n\n“Around midnight, I’d guess. Maybe earlier—I just don’t know. I’ve been up all\nnight trying to understand it.”\n\n“How’s it spread?”\n\n“Through a hole in the Unix mail program.”\n\n“You must mean _Sendmail_. Hell, I’ve known about that for years.” Bob Morris\nmight have known, but he had never told me.\n\n“Whoever wrote the virus must be laughing, but it’s going to mean a rough day\nfor everyone.”\n\n“Any ideas who started it?”\n\n“Nope.”\n\n“Don’t worry about it. I’ll look into it and see what I can do.”\n\nWe chatted awhile, then I hung up. Well, I’ve warned the authorities. As chief\nscientist of the National Computer Security Center, Bob had a few hours to\nrouse his troops and begin figuring out what this virus was all about. I\nstared at my computer screen for a while, then, clad in a bathrobe, fell\nasleep on the keyboard.\n\nTwo hours later the phone rang. It’s Don Alvarez from MIT on the line.\n\n“Hey, Cliff,” he says, “something weird is going on. There’s a hundred jobs\nrunning on our computer. Smells like a virus.”\n\n“You’ve got it too, huh?” We compared notes and quickly realized that Unix\nsystems across the country must be infected. There’s not much to do but patch\nthe bugs in the systems.\n\n“There are only two ways to understand this virus,” Don said. “The obvious way\nis to disassemble it. Follow the computer code, step by step, and figure out\nwhat it does.”\n\n“OK,” I said, “I’ve tried that, and it’s not easy. What’s the other way?”\n\n“Treat it as a black box. Watch it send signals to other computers, and\nestimate what’s inside of it.”\n\n“There’s a third way, Don.”\n\n“What’s that?”\n\n“Find out who wrote it.”\n\nI scanned the computer network news: Peter Yee and Keith Bostic of the\nUniversity of California at Berkeley were unraveling the virus; they described\nthe Unix holes and even published a way to patch the software. Well done!\n\nWithin the day, Jon Rochlis, Stan Zanarotti, Ted Ts’o, and Mark Eichin of MIT\nwere dissecting the program, translating the bits and bytes into ideas. By\nThursday evening—less than twenty-four hours after the virus was released—the\nMIT and Berkeley groups had disassembled the code and were well along to\nunderstanding it.\n\nMike Muuss of the Ballistics Research Lab was making progress, too. Within a\nfew hours, he built a test chamber for the virus and used his software tools\nto prod it. From his experiments, he understood how it spread, and which holes\nit used to infest other computers.\n\nBut who wrote it?\n\nAround eleven in the morning, someone from NSA’s National Computer Security\nCenter called me.\n\n“Cliff, we’ve just held a meeting about the virus,” the voice said. “I’ve got\njust one question for you: did you write the virus?”\n\nI was stunned. Me? Write this virus?\n\n“No, damn it, I didn’t write it. I’ve spent the past night trying to\nextinguish it.”\n\n“A couple people at the meeting suggested that you were the most likely\ncreator. I’m just checking.”\n\nYou’ve got to be joking. Me? What could make them think that I had written it?\nThen I realized: I’d posted a message to their computer. I was the first to\ncall them. What paranoia!\n\nTheir call set me to thinking. Who had written the virus? Why? You don’t\naccidentally write a virus. This one had taken weeks to build.\n\nLate Thursday afternoon, I called Bob Morris back. “Any news?” I asked him.\n\n“For once, I’ll tell you the truth,” Bob said. “I know who wrote the virus.”\n\n“Are you going to tell me?”\n\n“No.”\n\nNow that’s efficient. Ten hours after I call them, the National Computer\nSecurity Center has found the culprit.\n\nBut I hadn’t. He’s still a mystery to me, so it’s back to snooping around the\nnetworks. If I could only find the computer that had been first infected. No,\nthat won’t work. There’s thousands out there.\n\nJohn Markoff, a reporter from the New York _Times_ , called. “I heard a rumor\nthat the person who wrote the virus has the initials RTM. Is that any help?”\n\n“Not much, but I’ll check it out.”\n\nHow do you find someone from his initials? Of course … you look him up in the\nnetwork directory.\n\nI log into the Network Information Center and search for anyone with the\ninitials RTM. One guy pops up: Robert T. Morris. Address: Harvard University,\nAiken Laboratory.\n\nAiken. I’ve heard of that. It’s three blocks from my house. I think I’ll\nstroll by.\n\nI pull on a coat and walk along Kirkland Street, then over to Oxford Street,\nwhere the sidewalks are brick. Across the street from Harvard’s Cyclotron\nLaboratory, there’s a lunch truck selling Middle Eastern food. A hundred feet\naway, Aiken Computer Lab—an ugly modern concrete building surrounded by old\nVictorian masterpieces.\n\nI walk up to a secretary. “Hi. I’m looking for Robert Morris.”\n\n“Never heard of him,” she says. “But I’ll check my machine.” She types into\nher terminal,\n\n**Finger Morris**\n\nHer computer responds:\n\n**Login name: rtm** | **In real life: Robert T. Morris**  \n---|---  \n**Phone: 617/498-2247** |   \n**Last login Thu Nov 3 00:25 on ttyp2 from 128.84.254.126**  \n  \nWell—the last time that Robert Morris used the Harvard computer was twenty-\nfive minutes after midnight, on the morning that the virus struck. But he’s\nnot here in Massachusetts. That address, 128.84.254.126, is at Cornell\nUniversity. He entered the Harvard system from a computer at Cornell\nUniversity. Curious.\n\nThe secretary sees the message, looks up, and says, “Oh, he must have once\nbeen a student here. That phone number is in Room 111.\n\nI wander over to room 111 and knock on the door. A student in a T-shirt peers\nout. “Ever hear of Robert Morris?” I ask.\n\nHis face blanches. “Yeah. He’s not here anymore.” And he slams the door in my\nface.\n\nI walk away, think for a moment, then return. “Have you heard about the\nvirus?” I ask the guy at the door.\n\n“Oh, RTM wouldn’t have done that. I’m sure.”\n\nWait a second. I hadn’t even asked if Morris had written the virus and this\nguy’s denying it. There’s an easy way to test this guy’s veracity. “When’s the\nlast time that Morris has used Harvard’s computers?”\n\n“Last year, when he was a student. He’s at Cornell now, and he doesn’t log\ninto our computer anymore.”\n\nThis guy’s story doesn’t jibe with the accounting records of his computer. One\nof ’em’s telling the truth. I’ll bank on the computer.\n\nWe talked for five minutes, and this guy tells me how he’s a good friend of\nMorris, how they were officemates together, and how RTM would never write a\ncomputer virus.\n\n“Yeah, right,” I’m thinking.\n\nI leave, thinking that Morris’s old officemate is covering for him. Morris\nmust be talking to this guy, and they’re both frightened. I’d be scared, too,\nin that squeeze. Half the country’s looking for the creator of this virus.\n\nWhere did the virus start from? I checked other computers in Cambridge,\nsearching for connections to Cornell. One machine, over at MIT’s Artificial\nIntelligence Lab, showed late-night connections from Robert Morris’s computer\nat Cornell.\n\nNow things made sense. The virus was designed and built at Cornell. Then the\ncreator used the Arpanet to connect to MIT and release the virus there. A\nwhile later he panics when he realizes that his creature is out of control. So\nhe logs into the Harvard computer, either to check on the virus’s progress, or\nto ask his friends for help.\n\nThe joke was on me, though. It didn’t occur to me that Robert T. Morris, Jr.,\nwas the son of Bob … er, Robert Morris, Sr. Yeah, son of Bob Morris, who only\nyesterday told me he’d known of the _Sendmail_ hole for years. Bob Morris, the\nhead honcho who’d grilled me on astrophysics, then nearly asphyxiated me with\ncigarette smoke.\n\nSo Bob Morris’ son froze two thousand computers. Why? To impress his dad? As a\nhalloween prank? To show off to a couple thousand computer programmers?\n\nWhatever his purposes were, I don’t believe he was in cahoots with his father.\nRumors have it that he worked with a friend or two at Harvard’s computing\ndepartment (Harvard student Paul Graham sent him mail asking for “Any news on\nthe brilliant project”), but I doubt his father would encourage anyone to\ncreate a virus. As Bob Morris, Sr., said, “This isn’t exactly a good mark for\na career at NSA.”\n\nAfter dissecting the code, MIT’s Jon Rochlis characterized the virus as “not\nvery well written.” It was unique in that it attacked computers through four\npathways: Bugs in the Unix _Sendmail_ and Finger programs, guessing passwords,\nand by exploiting paths of trust between computers. In addition, Morris\ncamouflaged the program in several ways, so as to avoid detection. But he made\nseveral programming mistakes—like setting the wrong replication rate—and the\nworm probably could have been written by many students or programmers.\n\nAll it takes is knowledge of Unix flaws and no sense of responsibility.\n\nOnce you understand how this particular worm-virus infests computers, the cure\nbecomes evident: repair _Sendmail_ and the finger daemon, change the\npasswords, and erase all the copies of the system’s virus. Evident, yes. Easy,\nno.\n\nSpreading the word isn’t easy when everyone’s chopping off their electronic\nmail system. After all, that’s how this worm propagates its children. Slowly,\nusing alternate networks and telephone calls, the word went out. Within a\ncouple days, Morris’s worm was pretty much squashed.\n\nBut how do I protect against other viruses? Things aren’t so hopeful. Since\nviruses masquerade as sections of legitimate programs, they’re tough to\ndetect. Worse, once your system is infected, these are difficult beasts to\nunderstand. A programmer has to decompile the code: a time-consuming, boring\njob.\n\nFortunately, computer viruses are rare. Although it’s become fashionable to\nblame system problems on viruses, they mostly hit people who exchange software\nand use computer bulletin boards. Fortunately, these are usually knowledgeable\npeople who make backup copies of their disks.\n\nA computer virus is specialized: a virus that works on an IBM PC cannot do\nanything to a Macintosh or a Unix computer. Similarly, the Arpanet virus could\nonly strike at systems running Berkeley Unix. Computers running other\noperating systems—like AT&T Unix, VMS, or DOS—were totally immune.\n\nDiversity, then, works against viruses. If all the systems on the Arpanet ran\nBerkeley Unix, the virus would have disabled all fifty thousand of them.\nInstead, it infected only a couple thousand. Biological viruses are just as\nspecialized: we can’t catch the flu from dogs.\n\nBureaucrats and managers will forever urge us to standardize on a single type\nof system: “Let’s only use Sun workstations” or “Only buy IBM systems.” Yet\nsomehow our communities of computers are a diverse population—with Data\nGeneral machines sitting next to Digital Vaxes; IBMs connected to Sonys. Like\nour neighborhoods, electronic communities thrive through diversity.\n\nMeanwhile, how much astronomy was I doing?\n\nNone. For thirty-six hours, I worked on disinfecting our computers. Then came\nmeetings and then papers to write. And a couple copycat virus\nmakers—fortunately, none as clever as the original.\n\nThe last I heard, Robert T. Morris was laying low, avoiding interviews and\nwondering about the chances of an indictment. His father’s still at NSA, still\nthe chief scientist at their computer security center.\n\nHow much damage was done? I surveyed the network, and found that two thousand\ncomputers were infected within fifteen hours. These machines were dead in the\nwater—useless until disinfected. And removing the virus often took two days.\n\nSuppose someone disabled two thousand automobiles, say, by letting the air out\nof their tires. How would you measure the damage? By one measure, there’s been\nno damage at all: the cars are intact, and all you need to do is pump some\nair.\n\nOr you can measure damage by the loss of the cars. Let’s see: how much do you\nlose if your car is disabled for a day? The cost of sending a tow truck out?\nOr the price of a rental car? Or the amount of work that you’ve lost? Hard to\nsay.\n\nPerhaps you’d thank the person who let the air out of your tires—award him a\nmedal for raising your consciousness about automotive security.\n\nHere, someone crippled some two thousand computers for two days.\n\nWhat was lost? Programmers, secretaries, and managers couldn’t work. Data\nwasn’t collected. Projects were delayed.\n\nThe virus writer caused that much damage at least. Deeper damage, too. A while\nafter the virus hit, some astronomers and programmers took a poll. Some of the\ncomputer people felt the virus was a harmless prank—one of the finest jokes\never.\n\nThe astronomers had a different opinion: for two days, they couldn’t work.\nTheir secretaries and grad students weren’t working. Proposals and papers\nweren’t being written. We pay for their network connections out of our\npockets—and this caper made it even more difficult to expand their astronomy\nnetworks.\n\nSome programmers see this virus as a useful exercise in raising consciousness\nabout computer security. The virus writer should be thanked. Yeah, sure. Like\ngoing into a small town and breaking into people’s homes, so as to impress\nupon the townsfolk the need to buy strong locks.\n\nOnce, I too, would have seen no mischief in this virus. But over the past two\nyears, my interest changed from a micro-problem (a 75-cent discrepancy) to\nmacro-issues: the welfare of our networks, a sense of common fair play, legal\nimplications of hacking, the security of defense contractors, commonweal\nethics in computing …\n\nOmigod! Listening to myself talk like this, I realize that I’ve become a\ngrown-up (sob!)—a person who _really has a stake_. My graduate student\nmentality of earlier days let me think of the world as just a research\nproject: to be studied, data extracted, patterns noted. Suddenly there are\nconclusions to be drawn; conclusions that carry moral weight.\n\nI guess I’ve come of age.\n\n\n![](images/Stol_9780307819420_epub_L04_r1.jpg) The greatest B-movie of all\ntime, _The Blob_ , finishes off with the malignant monster being towed off to\nAntarctica: it’s harmless when frozen. Then, the words “The End” flash across\nthe screen, but at the last minute, a blob-shaped question mark appears. The\nmonster isn’t dead, only sleeping.\n\nThat is how I felt when I finally dismantled my monitors, made the last entry\nin my logbook, and said good-bye to midnight chases after Markus Hess.\n\nThe monster is still out there, ready to come alive again. Whenever someone,\ntempted by money, power, or simple curiosity, steals a password and prowls the\nnetworks. Whenever someone forgets that the networks she loves to play on are\nfragile, and can only exist when people trust each other. Whenever a fun-\nloving student breaks into systems as a game (as I might once have done), and\nforgets that he’s invading people’s privacy, endangering data that others have\nsweated over, sowing distrust and paranoia.\n\nNetworks aren’t made of printed circuits, but of people. Right now, as I type,\nthrough my keyboard I can touch countless others: friends, strangers, enemies.\nI can talk to a physicist in Japan, an astronomer in England, a spy in\nWashington. I might gossip with a buddy in Silicon Valley or some professor at\nBerkeley.\n\nMy terminal is a door to countless, intricate pathways, leading to untold\nnumbers of neighbors. Thousands of people trust each other enough to tie their\nsystems together. Hundreds of thousands of people use those systems, never\nrealizing the delicate networks that link their separate worlds.\n\nLike the innocent small town invaded in a monster movie, all those people work\nand play, unaware of how fragile and vulnerable their community is. It could\nbe destroyed outright by a virus, or, worse, it could consume itself with\nmutual suspicion, tangle itself up in locks, security checkpoints, and\nsurveillance; wither away by becoming so inaccessible and bureaucratic that\nnobody would want it anymore.\n\nBut maybe, if Hess was an exception, if enough of us work together to keep the\nnetworks safe and free, this will all be over. I can finally get back to\nastronomy and have time to spend with my long-suffering bride. I don’t want to\nbe a computer cop. I don’t want our networks to need cops.\n\nThe phone’s ringing. It’s Lawrence Livermore Laboratory—a place I’ve stayed\naway from because they design nuclear bombs. A hacker’s breaking into their\ncomputer. They want my help. They think I’m a wizard.\n\n![](images/Stol_9780307819420_epub_066_r1.jpg)\n\n\n# ![](images/Stol_9780307819420_epub_064_r1.jpg)\n\n![](images/Stol_9780307819420_epub_L04_r1.jpg) If you’d like the technical\ndetails behind this book, read my article, “Stalking the Wily Hacker,” in the\nMay 1988 issue of the _Communications of the ACM_. It’s a dry, academic paper\nwhich highlights the techniques that the hacker used to break into computers.\n\nIn addition, I described how to track hackers in “What Do You Feed a Trojan\nHorse?”—found in the _Proceedings of the 10th National Computer Security\nConference_ (September 1987). Because I wrote that paper while the hacker was\nstill actively breaking into computers, it’s about how to trace networks and\ndoesn’t mention our problems.\n\nFor more details about the NSA and a bit about their computer security\nproblems, read _The Puzzle Palace_ by James Bamford. Bamford describes the tug\nof war between the code makers and code breakers—he must have had fun prying\nthose details out of the super-secret agency. David Kahn’s book, _The\nCodebreakers_ , is a fascinating description and history of ciphers, which\nsuggests how computers use cryptography to protect their data. In _Deep Black_\nWilliam E. Burrows writes mostly about secret observations from spy\nsatellites, but also hints at the use of computers in espionage.\n\nFor more mundane, yet valuable descriptions of the problems and techniques of\ncomputer security, read _Defending Secrets, Sharing Data_ , available from the\nU.S. Congress, Office of Technology Assessment, OTA-CIT-310. For a still more\ntechnical discussion, try _Cryptography and Data Security_ by Dorothy Denning.\nThe hacker probably wouldn’t have broken into our system had we read (and\napplied) _Unix System Security_ by Wood and Kochan.\n\nComputer security problems are usually heard first on Internet and Usenet\nnetwork conferences. These are worldwide electronic bulletin boards—this is\noften where first rumors of trouble show up. To hear about the latest computer\nsecurity problems, watch the _Unix-wizards, Info-vax, Security, TCP-IP_ , and\n_Virus-L_ conferences. There’s a lively, moderated discussion on the _Risks-\nforum_ conference, where participants discuss social issues relating to\ncomputers. There are a few private security conferences as well; their\n“invitation only” membership is indicative of the paranoia surrounding the\nfield. There are also anonymous and pirate bulletin boards; these seldom have\nmuch useful information—but they do tell you what one segment of the\npopulation is thinking.\n\n\n# ![](images/Stol_9780307819420_epub_065_r1.jpg)\n\n![](images/Stol_9780307819420_epub_L04_r1.jpg) Clifford Stoll is an astronomer\nby training and a computer security expert by accident. Since catching the\n“Hannover Hacker,” he has become a leading authority on computer security,\ndelivering more lectures on the subject than he cares to admit. He’s given\ntalks at the CIA and NSA, and has appeared before the U.S. Senate. Stoll is\nnow building software for the Harvard-Smithsonian Center for Astrophysics, and\nlives in Cambridge with his wife, Martha Matthews, and two cats he pretends to\ndislike.\n\n",
    "book_id": "the_cuckoos_egg",
    "book_title": "Cuckoo's Egg",
    "book_author": "Clifford Stoll",
    "topic_id": "cybersecurity_history",
    "topic_label": "history",
    "chunk_index": 3
  }
]