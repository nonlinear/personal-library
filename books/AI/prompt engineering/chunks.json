[
  {
    "chunk_full": "Pre-train, Prompt, and Predict: A Systematic Survey of\nPrompting Methods in Natural Language Processing\nPengfei Liu\nCarnegie Mellon University\npliu3@cs.cmu.edu\nWeizhe Yuan\nCarnegie Mellon University\nweizhey@cs.cmu.edu\nJinlan Fu\nNational University of Singapore\njinlanjonna@gmail.com\nZhengbao Jiang\nCarnegie Mellon University\nzhengbaj@cs.cmu.edu\nHiroaki Hayashi\nCarnegie Mellon University\nhiroakih@cs.cmu.edu\nGraham Neubig\nCarnegie Mellon University\ngneubig@cs.cmu.edu\nAbstract\nThis paper surveys and organizes research works in a new paradigm in natural language processing, which\nwe dub “prompt-based learning”. Unlike traditional supervised learning, which trains a model to take in an\ninput x and predict an output y as P(y|x), prompt-based learning is based on language models that model\nthe probability of text directly. To use these models to perform prediction tasks, the original input x is\nmodiﬁed using a template into a textual string prompt x′ that has some unﬁlled slots, and then the language\nmodel is used to probabilistically ﬁll the unﬁlled information to obtain a ﬁnal string ˆx, from which the\nﬁnal output y can be derived. This framework is powerful and attractive for a number of reasons: it allows\nthe language model to be pre-trained on massive amounts of raw text, and by deﬁning a new prompting\nfunction the model is able to perform few-shot or even zero-shot learning, adapting to new scenarios with\nfew or no labeled data. In this paper we introduce the basics of this promising paradigm, describe a uniﬁed\nset of mathematical notations that can cover a wide variety of existing work, and organize existing work\nalong several dimensions, e.g. the choice of pre-trained models, prompts, and tuning strategies. To make\nthe ﬁeld more accessible to interested beginners, we not only make a systematic review of existing works\nand a highly structured typology of prompt-based concepts, but also release other resources, e.g., a website\nNLPedia–Pretrain\nincluding constantly-updated survey, and paperlist.\n1\narXiv:2107.13586v1  [cs.CL]  28 Jul 2021\n",
    "book_id": "210713586v1",
    "book_title": "2107.13586v1",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 0
  },
  {
    "chunk_full": "CONTENTS\nContents\n1\nTwo Sea Changes in NLP\n3\n2\nA Formal Description of Prompting\n4\n2.1\nSupervised Learning in NLP . . . . . .\n4\n2.2\nPrompting Basics . . . . . . . . . . . .\n4\n2.2.1\nPrompt Addition . . . . . . . .\n5\n2.2.2\nAnswer Search . . . . . . . . .\n5\n2.2.3\nAnswer Mapping . . . . . . . .\n5\n2.3\nDesign Considerations for Prompting\n.\n6\n3\nPre-trained Language Models\n8\n3.1\nTraining Objectives . . . . . . . . . . .\n8\n3.2\nNoising Functions . . . . . . . . . . . .\n8\n3.3\nDirectionality of Representations . . . .\n9\n3.4\nTypical Pre-training Methods . . . . . .\n9\n3.4.1\nLeft-to-Right Language Model .\n9\n3.4.2\nMasked Language Models . . .\n10\n3.4.3\nPreﬁx and Encoder-Decoder . .\n10\n4\nPrompt Engineering\n11\n4.1\nPrompt Shape . . . . . . . . . . . . . .\n11\n4.2\nManual Template Engineering . . . . .\n11\n4.3\nAutomated Template Learning . . . . .\n11\n4.3.1\nDiscrete Prompts . . . . . . . .\n12\n4.3.2\nContinuous Prompts\n. . . . . .\n12\n5\nAnswer Engineering\n13\n5.1\nAnswer Shape . . . . . . . . . . . . . .\n13\n5.2\nAnswer Space Design Methods . . . . .\n14\n5.2.1\nManual Design . . . . . . . . .\n14\n5.2.2\nDiscrete Answer Search\n. . . .\n14\n5.2.3\nContinuous Answer Search . . .\n14\n6\nMulti-Prompt Learning\n15\n6.1\nPrompt Ensembling . . . . . . . . . . .\n15\n6.2\nPrompt Augmentation . . . . . . . . . .\n16\n6.3\nPrompt Composition\n. . . . . . . . . .\n16\n6.4\nPrompt Decomposition . . . . . . . . .\n17\n7\nTraining Strategies for Prompting Methods\n17\n7.1\nTraining Settings\n. . . . . . . . . . . .\n17\n7.2\nParameter Update Methods . . . . . . .\n17\n7.2.1\nPromptless Fine-tuning . . . . .\n18\n7.2.2\nTuning-free Prompting . . . . .\n18\n7.2.3\nFixed-LM Prompt Tuning\n. . .\n18\n7.2.4\nFixed-prompt LM Tuning\n. . .\n18\n7.2.5\nPrompt+LM Tuning\n. . . . . .\n19\n8\nApplications\n19\n8.1\nKnowledge Probing . . . . . . . . . . .\n19\n8.2\nClassiﬁcation-based Tasks\n. . . . . . .\n19\n8.3\nInformation Extraction . . . . . . . . .\n22\n8.4\n“Reasoning” in NLP\n. . . . . . . . . .\n22\n8.5\nQuestion Answering\n. . . . . . . . . .\n23\n8.6\nText Generation . . . . . . . . . . . . .\n23\n8.7\nAutomatic Evaluation of Text Generation 23\n8.8\nMulti-modal Learning . . . . . . . . . .\n23\n8.9\nMeta-Applications\n. . . . . . . . . . .\n23\n8.10 Resources . . . . . . . . . . . . . . . .\n24\n9\nPrompt-relevant Topics\n24\n10 Challenges\n27\n10.1 Prompt Design\n. . . . . . . . . . . . .\n27\n10.2 Answer Engineering\n. . . . . . . . . .\n28\n10.3 Selection of Tuning Strategy . . . . . .\n28\n10.4 Multiple Prompt Learning\n. . . . . . .\n28\n10.5 Selection of Pre-trained Models\n. . . .\n29\n10.6 Theoretical and Empirical Analysis of\nPrompting . . . . . . . . . . . . . . . .\n29\n10.7 Transferability of Prompts\n. . . . . . .\n29\n10.8 Combination of Different Paradigms . .\n29\n10.9 Calibration of Prompting Methods . . .\n29\n11 Meta Analysis\n29\n11.1 Timeline . . . . . . . . . . . . . . . . .\n31\n11.2 Trend Analysis\n. . . . . . . . . . . . .\n31\n12 Conclusion\n31\nA Appendix on Pre-trained LMs\n44\nA.1\nEvolution of Pre-trained LM Parameters\n44\nA.2\nAuxiliary Objective . . . . . . . . . . .\n44\nA.3\nPre-trained Language Model\nFamilies . . . . . . . . . . . . . . . . .\n45\n2\n",
    "book_id": "210713586v1",
    "book_title": "2107.13586v1",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1
  },
  {
    "chunk_full": "1\nTwo Sea Changes in NLP\nFully supervised learning, where a task-speciﬁc model is trained solely on a dataset of input-output examples for\nthe target task, has long played a central role in many machine learning tasks (Kotsiantis et al., 2007), and natural\nlanguage processing (NLP) was no exception. Because such fully supervised datasets are ever-insufﬁcient for\nlearning high-quality models, early NLP models relied heavily on feature engineering (Tab. 1 a.; e.g. Lafferty et al.\n(2001); Guyon et al. (2002); Och et al. (2004); Zhang and Nivre (2011)), where NLP researchers or engineers\nused their domain knowledge to deﬁne and extract salient features from raw data and provide models with the\nappropriate inductive bias to learn from this limited data. With the advent of neural network models for NLP, salient\nfeatures were learned jointly with the training of the model itself (Collobert et al., 2011; Bengio et al., 2013), and\nhence focus shifted to architecture engineering, where inductive bias was rather provided through the design of\na suitable network architecture conducive to learning such features (Tab. 1 b.; e.g. Hochreiter and Schmidhuber\n(1997); Kalchbrenner et al. (2014); Chung et al. (2014); Kim (2014); Bahdanau et al. (2014); Vaswani et al. (2017)).1\nHowever, from 2017-2019 there was a sea change in the learning of NLP models, and this fully supervised\nparadigm is now playing an ever-shrinking role. Speciﬁcally, the standard shifted to the pre-train and ﬁne-tune\nparadigm (Tab. 1 c.; e.g. Radford and Narasimhan (2018); Peters et al. (2018); Dong et al. (2019); Yang et al. (2019);\nLewis et al. (2020a)). In this paradigm, a model with a ﬁxed2 architecture is pre-trained as a language model (LM),\npredicting the probability of observed textual data. Because the raw textual data necessary to train LMs is available\nin abundance, these LMs can be trained on large datasets, in the process learning robust general-purpose features\nof the language it is modeling. The above pre-trained LM will be then adapted to different downstream tasks by\nintroducing additional parameters and ﬁne-tuning them using task-speciﬁc objective functions. Within this paradigm,\nthe focus turned mainly to objective engineering, designing the training objectives used at both the pre-training and\nﬁne-tuning stages. For example, Zhang et al. (2020a) show that introducing a loss function of predicting salient\nsentences from a document will lead to a better pre-trained model for text summarization. Notably, the main body\nof the pre-trained LM is generally (but not always; Peters et al. (2019)) ﬁne-tuned as well to make it more suitable\nfor solving the downstream task.\nNow, as of this writing in 2021, we are in the middle of a second sea change, in which the “pre-train, ﬁne-tune”\nprocedure is replaced by one in which we dub “pre-train, prompt, and predict”. In this paradigm, instead of adapting\npre-trained LMs to downstream tasks via objective engineering, downstream tasks are reformulated to look more\nlike those solved during the original LM training with the help of a textual prompt. For example, when recognizing\nthe emotion of a social media post, “I missed the bus today.”, we may continue with a prompt “I felt so\n”, and\nask the LM to ﬁll the blank with an emotion-bearing word. Or if we choose the prompt “English: I missed the bus\ntoday. French:\n”), an LM may be able to ﬁll in the blank with a French translation. In this way, by selecting\nthe appropriate prompts we can manipulate the model behavior so that the pre-trained LM itself can be used to\npredict the desired output, sometimes even without any additional task-speciﬁc training (Tab. 1 d.; e.g. Radford\net al. (2019); Petroni et al. (2019); Brown et al. (2020); Raffel et al. (2020); Schick and Sch¨utze (2021b); Gao\net al. (2021)). The advantage of this method is that, given a suite of appropriate prompts, a single LM trained in an\nentirely unsupervised fashion can be used to solve a great number of tasks (Brown et al., 2020; Sun et al., 2021).\nHowever, as with most conceptually enticing prospects, there is a catch – this method introduces the necessity for\nprompt engineering, ﬁnding the most appropriate prompt to allow a LM to solve the task at hand.\nThis survey attempts to organize the current state of knowledge in this rapidly developing ﬁeld by providing an\noverview and formal deﬁnition of prompting methods (§2), and an overview of the pre-trained language models that\nuse these prompts (§3). This is followed by in-depth discussion of prompting methods, from basics such as prompt\nengineering (§4) and answer engineering (§5) to more advanced concepts such as multi-prompt learning methods\n(§6) and prompt-aware training methods (§7). We then organize the various applications to which prompt-based\nlearning methods have been applied, and discuss how they interact with the choice of prompting method (§8).\nFinally, we attempt to situate the current state of prompting methods in the research ecosystem, making connections\nto other research ﬁelds (§9), suggesting some current challenging problems that may be ripe for further research\n(§10), and performing a meta-analysis of current research trends (§11).\nFinally, in order to help beginners who are interested in this ﬁeld learn more effectively, we highlight some\nsystematic resources about prompt learning (as well as pre-training) provided both within this survey and on\ncompanion websites:\n•\n: A website of prompt-based learning that contains: frequent updates to this survey, related slides, etc.\n• Fig.1: A typology of important concepts for prompt-based learning.\n1Even during this stage, there was some use of pre-trained models exempliﬁed by word2vec (Mikolov et al., 2013b,a) and\nGloVe (Pennington et al., 2014), but they were used for only a limited portion of the ﬁnal model parameters.\n2This paradigm is less conducive to architectural exploration because (i) unsupervised pre-training allows models to learn\nwith fewer structural priors, and (ii) as pre-training of models is time-consuming, experimenting with structural variants is costly.\n3\n",
    "book_id": "210713586v1",
    "book_title": "2107.13586v1",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 2
  },
  {
    "chunk_full": "Paradigm\nEngineering\nTask Relation\na. Fully Supervised Learning\n(Non-Neural Network)\nFeatures\n(e.g. word identity, part-of-speech,\nsentence length)\nCLS\nTAG\nGEN\nLM\nb. Fully Supervised Learning\n(Neural Network)\nArchitecture\n(e.g. convolutional, recurrent,\nself-attentional)\nCLS\nTAG\nGEN\nLM\nc. Pre-train, Fine-tune\nObjective\n(e.g. masked language modeling,\nnext sentence prediction)\nCLS\nTAG\nGEN\nLM\nd. Pre-train, Prompt, Predict\nPrompt (e.g. cloze, preﬁx)\nTAG\nCLS\nGEN\nLM\nTable 1: Four paradigms in NLP. The “engineering” column represents the type of engineering to be done to build\nstrong systems. The “task relation” column, shows the relationship between language models (LM) and other NLP\ntasks (CLS: classiﬁcation, TAG: sequence tagging, GEN: text generation).\n: fully unsupervised training.\n: fully\nsupervised training.\n: Supervised training combined with unsupervised training.\nindicates a textual prompt.\nDashed lines suggest that different tasks can be connected by sharing parameters of pre-trained models. “LM→Task”\nrepresents adapting LMs (objectives) to downstream tasks while “Task→LM” denotes adapting downstream tasks\n(formulations) to LMs.\n• Tab.7: A systematic and comprehensive comparison among different prompting methods.\n• Tab.10: An organization of commonly-used prompts.\n• Tab.12: A timeline of prompt-based research works.\n• Tab.13: A systematic and comprehensive comparison among different pre-trained LMs.\n2\nA Formal Description of Prompting\n2.1\nSupervised Learning in NLP\nIn a traditional supervised learning system for NLP, we take an input x, usually text, and predict an output y based\non a model P(y|x; θ). y could be a label, text, or other variety of output. In order to learn the parameters θ of\nthis model, we use a dataset containing pairs of inputs and outputs, and train a model to predict this conditional\nprobability. We will illustrate this with two stereotypical examples.\nFirst, text classiﬁcation takes an input text x and predicts a label y from a ﬁxed label set Y. To give an example,\nsentiment analysis (Pang et al., 2002; Socher et al., 2013) may take an input x =“I love this movie.” and predict a\nlabel y = ++, out of a label set Y = {++, +, ~, -, --}.\nSecond, conditional text generation takes an input x and generates another text y. One example is machine\ntranslation (Koehn, 2009), where the input is text in one language such as the Finnish x = “Hyv¨a¨a huomenta.” and\nthe output is the English y = “Good morning”..\n2.2\nPrompting Basics\nThe main issue with supervised learning is that in order to train a model P(y|x; θ), it is necessary to have supervised\ndata for the task, which for many tasks cannot be found in large amounts. Prompt-based learning methods for NLP\nattempt to circumvent this issue by instead learning an LM that models the probability P(x; θ) of text x itself\n(details in §3) and using this probability to predict y, reducing or obviating the need for large supervised datasets. In\nthis section we lay out a mathematical description of the most fundamental form of prompting, which encompasses\nmany works on prompting and can be expanded to cover others as well. Speciﬁcally, basic prompting predicts the\nhighest-scoring ˆy in three steps.\n4\n",
    "book_id": "210713586v1",
    "book_title": "2107.13586v1",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 3
  },
  {
    "chunk_full": "2.2\nPrompting Basics\nName\nNotation\nExample\nDescription\nInput\nx\nI love this movie.\nOne or multiple texts\nOutput\ny\n++ (very positive)\nOutput label or text\nPrompting\nFunction\nfprompt(x)\n[X] Overall, it was a [Z] movie.\nA function that converts the input into a\nspeciﬁc form by inserting the input x and\nadding a slot [Z] where answer z may\nbe ﬁlled later.\nPrompt\nx′\nI love this movie. Overall, it was a [Z] movie.\nA text where [X] is instantiated by input\nx but answer slot [Z] is not.\nFilled Prompt\nfﬁll(x′, z)\nI love this movie. Overall, it was a bad movie.\nA prompt where slot [Z] is ﬁlled with\nany answer.\nAnswered\nPrompt\nfﬁll(x′, z∗)\nI love this movie. Overall, it was a good movie.\nA prompt where slot [Z] is ﬁlled with a\ntrue answer.\nAnswer\nz\n“good”, “fantastic”, “boring”\nA token, phrase, or sentence that ﬁlls [Z]\nTable 2: Terminology and notation of prompting methods. z∗represents answers that correspond to true output y∗.\n2.2.1\nPrompt Addition\nIn this step a prompting function fprompt(·) is applied to modify the input text x into a prompt x′ = fprompt(x). In\nthe majority of previous work (Kumar et al., 2016; McCann et al., 2018; Radford et al., 2019; Schick and Sch¨utze,\n2021a), this function consists of a two step process:\n1. Apply a template, which is a textual string that has two slots: an input slot [X] for input x and an answer slot\n[Z] for an intermediate generated answer text z that will later be mapped into y.\n2. Fill slot [X] with the input text x.\nIn the case of sentiment analysis where x =“I love this movie.”, the template may take a form such as “[X]\nOverall, it was a [Z] movie.”. Then, x′ would become “I love this movie. Overall it was a [Z] movie.” given the\nprevious example. In the case of machine translation, the template may take a form such as “Finnish: [X] English:\n[Z]”, where the text of the input and answer are connected together with headers indicating the language. We show\nmore examples in Tab. 3\nNotably, (1) the prompts above will have an empty slot to ﬁll in for z, either in the middle of the prompt or at the\nend. In the following text, we will refer to the ﬁrst variety of prompt with a slot to ﬁll in the middle of the text as a\ncloze prompt, and the second variety of prompt where the input text comes entirely before z as a preﬁx prompt. (2)\nIn many cases these template words are not necessarily composed of natural language tokens; they could be virtual\nwords (e.g. represented by numeric ids) which would be embedded in a continuous space later, and some prompting\nmethods even generate continuous vectors directly (more in §4.3.2). (3) The number of [X] slots and the number\nof [Z] slots can be ﬂexibly changed for the need of tasks at hand.\n2.2.2\nAnswer Search\nNext, we search for the highest-scoring text ˆz that maximizes the score of the LM. We ﬁrst deﬁne Z as a\nset of permissible values for z. Z could range from the entirety of the language in the case of generative\ntasks, or could be a small subset of the words in the language in the case of classiﬁcation, such as deﬁning\nZ = {“excellent”, “good”, “OK”, “bad”, “horrible”} to represent each of the classes in Y = {++, +, ~, -, --}.\nWe then deﬁne a function fﬁll(x′, z) that ﬁlls in the location [Z] in prompt x′ with the potential answer z. We\nwill call any prompt that has gone through this process as a ﬁlled prompt. Particularly, if the prompt is ﬁlled with a\ntrue answer, we will refer to it as an answered prompt (Tab. 2 shows an example). Finally, we search over the set\nof potential answers z by calculating the probability of their corresponding ﬁlled prompts using a pre-trained LM\nP(·; θ)\nˆz = search\nz∈Z P(fﬁll(x′, z); θ).\n(1)\nThis search function could be an argmax search that searches for the highest-scoring output, or sampling that\nrandomly generates outputs following the probability distribution of the LM.\n2.2.3\nAnswer Mapping\nFinally, we would like to go from the highest-scoring answer ˆz to the highest-scoring output ˆy. This is trivial in\nsome cases, where the answer itself is the output (as in language generation tasks such as translation), but there\n5\n",
    "book_id": "210713586v1",
    "book_title": "2107.13586v1",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 4
  },
  {
    "chunk_full": "2.3\nDesign Considerations for Prompting\nType\nTask\nInput ([X])\nTemplate\nAnswer ([Z])\nText CLS\nSentiment\nI love this movie.\n[X] The movie is [Z].\ngreat\nfantastic\n...\nTopics\nHe prompted the LM.\n[X] The text is about [Z].\nsports\nscience\n...\nIntention\nWhat is taxi fare to Denver?\n[X] The question is about [Z].\nquantity\ncity\n...\nText-span CLS\nAspect\nSentiment\nPoor service but good food.\nBad\n[X] What about service? [Z].\nTerrible\n...\nText-pair CLS\nNLI\n[X1]: An old man with ...\n[X1]? [Z], [X2]\nYes\n[X2]: A man walks ...\nNo\n...\nTagging\n[X1]: Mike went to Paris.\norganization\nNER\n[X2]: Paris\n[X1][X2] is a [Z] entity.\nlocation\n...\nText Generation\nSummarization\nLas Vegas police ...\n[X] TL;DR: [Z]\nThe victim ...\nA woman ...\n...\nTranslation\nJe vous aime.\nFrench: [X] English: [Z]\nI love you.\nI fancy you.\n...\nTable 3: Examples of input, template, and answer for different tasks. In the Type column, “CLS” is an abbreviation\nfor “classiﬁcation”. In the Task column, “NLI” and “NER” are abbreviations for “natural language inference” (Bow-\nman et al., 2015) and “named entity recognition” (Tjong Kim Sang and De Meulder, 2003) respectively.\nare also other cases where multiple answers could result in the same output. For example, one may use multiple\ndifferent sentiment-bearing words (e.g. “excellent”, “fabulous”, “wonderful”) to represent a single class (e.g. “++”),\nin which case it is necessary to have a mapping between the searched answer and the output value.\n2.3\nDesign Considerations for Prompting\nNow that we have our basic mathematical formulation, we elaborate a few of the basic design considerations that go\ninto a prompting method, which we will elaborate in the following sections:\n• Pre-trained Model Choice: There are a wide variety of pre-trained LMs that could be used to calculate\nP(x; θ). In §3 we give a primer on pre-trained LMs, speciﬁcally from the dimensions that are important for\ninterpreting their utility in prompting methods.\n• Prompt Engineering: Given that the prompt speciﬁes the task, choosing a proper prompt has a large effect not\nonly on the accuracy, but also on which task the model performs in the ﬁrst place. In §4 we discuss methods to\nchoose which prompt we should use as fprompt(x).\n• Answer Engineering: Depending on the task, we may want to design Z differently, possibly along with the\nmapping function. In §5 we discuss different ways to do so.\n• Expanding the Paradigm: As stated above, the above equations represent only the simplest of the various\nunderlying frameworks that have been proposed to do this variety of prompting. In §6 we discuss ways to\nexpand this underlying paradigm to further improve results or applicability.\n• Prompt-based Training Strategies: There are also methods to train parameters, either of the prompt, the LM,\nor both. In §7, we summarize different strategies and detail their relative advantages.\n6\n",
    "book_id": "210713586v1",
    "book_title": "2107.13586v1",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 5
  },
  {
    "chunk_full": "2.3\nDesign Considerations for Prompting\nPrompting\nMethod\nPre-trained\nModels §3\nLeft-to-\nRight LM\nGPT [139]; GPT-2 [140]; GPT-3 [16]\nMasked LM\nBERT [32]; RoBERTa [105]\nPreﬁx LM\nUniLM1 [35]; UniLM2 [6]\nEncoder-\nDecoder\nT5 [141]; MASS [162]; BART [94]\nPrompt En-\ngineering §4\nShape\nCloze\nLAMA [133]; TemplateNER [29]\nPreﬁx\nPreﬁx-Tuning [96];\nPromptTuning [91]\nHuman Effort\nHand-crafted\nLAMA [133]; GPT-3 [16]\nAutomated\nDiscrete\nAdvTrigger [177]; AutoPrompt [159]\nContinuous\nPreﬁx-Tuning [96];\nPromptTuning [91]\nAnswer En-\ngineering §5\nShape\nToken\nLAMA [133]; WARP [55]\nSpan\nPET-GLUE [154]; X-FACTR [66]\nSentence\nGPT-3 [16]; Preﬁx-Tuning [96]\nHuman Effort\nHand-crafted\nPET-TC [153]; PET-GLUE [154]\nAutomated\nDiscrete\nAutoPrompt [159]; LM-BFF [46]\nContinuous\nWARP [55]\nMulti-Prompt\nLearning §6\nPrompt\nEnsemble\nLPAQA [68]; PET-\nTC [153]; BARTScore [193]\nPrompt\nAugmentation\nGPT-3 [16]; KATE [100];\nLM-BFF [46]\nPrompt\nComposition\nPTR [56]\nPrompt De-\ncomposition\nTemplateNER [29]\nPrompt\nSharing\nExample Fig. 5\nPrompt-based\nTraining\nStrategies §7\nParameter\nUpdating\nPromptless\nFine-tuning\nBERT [32]; RoBERTa [105]\nTuning-free\nPrompting\nGPT-3 [16]; BARTScore [193]\nFixed-LM\nPrompt\nTuning\nPreﬁx-Tuning [96]; WARP [55]\nFixed-prompt\nLM Tuning\nT5 [141]; PET-TC [154]\nPrompt+LM\nTuning\nP-Tuning [103]; PTR [56]\nTraining\nSample Size\nFew/zero-\nshot\nGPT-3 [16]; PET-TC [153]\nFull-data\nPTR [56]; AdaPrompt [21]\nFigure 1: Typology of prompting methods.\n7\n",
    "book_id": "210713586v1",
    "book_title": "2107.13586v1",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 6
  },
  {
    "chunk_full": "3\nPre-trained Language Models\nGiven the large impact that pre-trained LMs have had on NLP in the pre-train and ﬁne-tune paradigm, there are\nalready a number of high-quality surveys that interested readers where interested readers can learn more (Raffel\net al., 2020; Qiu et al., 2020; Xu et al., 2021; Doddapaneni et al., 2021). Nonetheless, in this chapter we present\na systematic view of various pre-trained LMs which (i) organizes them along various axes in a more systematic\nway, (ii) particularly focuses on aspects salient to prompting methods. Below, we will detail them through the lens\nof main training objective, type of text noising, auxiliary training objective, attention mask, typical architecture,\nand preferred application scenarios. We describe each of these objectives below, and also summarize a number of\npre-trained LMs along each of these axes in Tab. 13 in the appendix.\n3.1\nTraining Objectives\nThe main training objective of a pre-trained LM almost invariably consists of some sort of objective predicting the\nprobability of text x.\nStandard Language Model (SLM)\nobjectives do precisely this, training the model to optimize the probability\nP(x) of text from a training corpus (Radford et al., 2019). In these cases, the text is generally predicted in an\nautoregressive fashion, predicting the tokens in the sequence one at a time. This is usually done from left to right\n(as detailed below), but can be done in other orders as well.\nA popular alternative to standard LM objectives are denoising objectives, which apply some noising function\n˜x = fnoise(x) to the input sentence (details in the following subsection), then try to predict the original input\nsentence given this noised text P(x|˜x). There are two common ﬂavors of these objectives:\nCorrupted Text Reconstruction (CTR)\nThese objectives restore the processed text to its uncorrupted state by\ncalculating loss over only the noised parts of the input sentence.\nFull Text Reconstruction (FTR)\nThese objectives reconstruct the text by calculating the loss over the entirety of\nthe input texts whether it has been noised or not (Lewis et al., 2020a).\nThe main training objective of the pre-trained LMs plays an important role in determining its applicability to\nparticular prompting tasks. For example, left-to-right autoregressive LMs may be particularly suitable for preﬁx\nprompts, whereas reconstruction objectives may be more suitable for cloze prompts. In addition, models trained\nwith standard LM and FTR objectives may be more suitable for tasks regarding text generation, whereas other tasks\nsuch as classiﬁcation can be formulated using models trained with any of these objectives.\nIn addition to the main training objectives above, a number of auxiliary objectives have been engineered to further\nimprove models’ ability to perform certain varieties of downstream tasks. We list some commonly-used auxiliary\nobjectives in Appendix A.2.\n3.2\nNoising Functions\nIn training objectives based on reconstruction, the speciﬁc type of corruption applied to obtain the noised text ˜x has\nan effect on the efﬁcacy of the learning algorithm. In addition, prior knowledge can be incorporated by controlling\nthe type of noise, e.g. the noise could focus on entities of a sentence, which allows us to learn a pre-trained model\nwith particularly high predictive performance for entities. In the following, we introduce several types of noising\nfunctions, and give detailed examples in Tab. 4.\nOperation\nElement\nOriginal Text\nCorrupted Text\nMask\none token\nJane will move to New York .\nJane will [Z] to New York .\ntwo tokens\nJane will move to New York .\nJane will [Z] [Z] New York .\none entity\nJane will move to New York .\nJane will move to [Z] .\nReplace\none token\nJane will move to New York .\nJane will move [X] New York .\ntwo tokens\nJane will move to New York .\nJane will move [X] [Y] York .\none entity\nJane will move to New York .\nJane will move to [X] .\nDelete\none token\nJane will move to New York .\nJane move to New York .\ntwo token\nJane will move to New York .\nJane to New York .\nPermute\ntoken\nJane will move to New York .\nNew York . Jane will move to\nRotate\nnone\nJane will move to New York .\nto New York . Jane will move\nConcatenation\ntwo languages\nJane will move to New York .\nJane will move to New York . [/s] 简将搬到纽约。\nTable 4: Detailed examples for different noising operations.\n8\n",
    "book_id": "210713586v1",
    "book_title": "2107.13586v1",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 7
  },
  {
    "chunk_full": "3.3\nDirectionality of Representations\nMasking\n(e.g. Devlin et al. (2019)) The text will be masked in different levels, replacing a token or multi-token\nspan with a special token such as [MASK]. Notably, masking can either be random from some distribution or\nspeciﬁcally designed to introduce prior knowledge, such as the above-mentioned example of masking entities to\nencourage the model to be good at predicting entities.\nReplacement\n(e.g. Raffel et al. (2020)) Replacement is similar to masking, except that the token or multi-token\nspan is not replaced with a [MASK] but rather another token or piece of information (e.g., an image region (Su\net al., 2020)).\nDeletion\n(e.g. Lewis et al. (2020a)) Tokens or multi-token spans will be deleted from a text without the addition\nof [MASK] or any other token. This operation is usually used together with the FTR loss.\nPermutation\n(e.g. Liu et al. (2020a)) The text is ﬁrst divided into different spans (tokens, sub-sentential spans, or\nsentences), and then these spans are be permuted into a new text.\n3.3\nDirectionality of Representations\nA ﬁnal important factor that should be considered in understanding pre-trained LMs and the difference between them\nis the directionality of the calculation of representations. In general, there are two widely used ways to calculate\nsuch representations:\nLeft-to-Right\nThe representation of each word is calculated based on the word itself and all previous words in the\nsentence. For example, if we have a sentence “This is a good movie”, the representation of the word “good” would\nbe calculated based on previous words. This variety of factorization is particularly widely used when calculating\nstandard LM objectives or when calculating the output side of an FTR objective, as we discuss in more detail below.\nBidirectional\nThe representation of each word is calculated based on all words in the sentence, including words\nto the left of the current word. In the example above, “good” would be inﬂuenced by all words in the sentence, even\nthe following “movie”.\nIn addition to the two most common directionalities above, it is also possible to mix the two strategies together in\na single model (Dong et al., 2019; Bao et al., 2020), or perform conditioning of the representations in a randomly\npermuted order (Yang et al., 2019), although these strategies are less widely used. Notably, when implementing\nthese strategies within a neural model, this conditioning is generally implemented through attention masking,\nwhich masks out the values in an attentional model (Bahdanau et al., 2014), such as the popular Transformer\narchitecture (Vaswani et al., 2017). Some examples of such attention masks are shown in Figure 2.\nx1 x2 x3\ny1\ny2\ny3\ny4\ny5\nx4 x5\n(a) Full.\nx1 x2 x3 x4 x5\n(b) Diagonal.\nx1 x2 x3 x4 x5\n(c) Mixture.\nFigure 2: Three popular attention mask patterns, where the subscript t indicates the t-th timestep. A shaded box at\n(i, j) indicates that the attention mechanism is allowed to attend to the input element i at output time step j. A white\nbox indicates that the attention mechanism is not allowed to attend to the corresponding i and j combination.\n3.4\nTypical Pre-training Methods\nWith the above concepts in mind, we introduce four popular pre-training methods, resulting from diverse combina-\ntions of objective, noising function, and directionality. These are described below, and summarized in Fig. 3 and\nTab. 5.\n3.4.1\nLeft-to-Right Language Model\nLeft-to-right LMs (L2R LMs), a variety of auto-regressive LM, predict the upcoming words or assign a probability\nP(x) to a sequence of words x = x1, · · · , xn (Jurafsky and Martin, 2021). The probability is commonly broken\ndown using the chain rule in a left-to-right fashion: P(x) = P(x1) × · · · P(xn|x1 · · · xn−1).3\n3Similarly, a right-to-left LM can predict preceding words based on the future context, such as P(xi|xi+1, · · · , xn).\n9\n",
    "book_id": "210713586v1",
    "book_title": "2107.13586v1",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 8
  },
  {
    "chunk_full": "3.4\nTypical Pre-training Methods\nx1\nx2\nx3\ny1\ny2\nx2\nx3\ny1\ny2\n.\n(a) Left-to-right LM.\nx1\nx2\nx3\n−\n(b) Masked LM.\nx1\nx2\nx3\ny1\ny2\nx2\nx3\ny1\ny2\n.\n(c) Preﬁx LM.\nx1\nx2\nx3\ny1\ny2\ny2\n.\n(d) Encoder-Decoder.\nFigure 3: Typical paradigms of pre-trained LMs.\nExample & Applicable Scenario\nLeft-to-right LMs have been standard since their proposal by Markov in 1913 (Markov, 2006), and have\nbeen used continuously since then in both count-based (Goodman, 2001) and neural forms (Bengio et al.,\n2003; Mikolov et al., 2010; Radford and Narasimhan, 2018). Representative examples of modern pre-trained\nleft-to-right LMs include GPT-3 (Brown et al., 2020), and GPT-Neo (Black et al., 2021).\nL2R pre-trained LMs are also the popular backbone that many prompting methods adopt (Radford et al.,\n2019; Brown et al., 2020) . One practical reason for this is that many such models are large (PanGu-α (Zeng\net al., 2021), Ernie-3 (Sun et al., 2021)) and ponderous to train, or not even available publicly. Thus using\nthese models in the pre-train and ﬁne-tune regimen is often not possible.\nLMs\nx\ny\nApplication\nMask\nNoise\nMain Obj.\nMask\nNoise\nMain Obj.\nL2R\nDiagonal\nNone\nSLM\n-\n-\n-\nNLU & NLG\nMask\nFull\nMask\nCTR\n-\n-\n-\nNLU\nPreﬁx\nFull\nAny\nCTR\nDiagonal\nNone\nSLM\nNLU & NLG\nEn-De\nFull\nAny\nNone†\nDiagonal\nNone\nFTR/CRT\nNLU & NLG\nTable 5: Typical architectures for pre-trained LMs. x and y represent text to be encoded and decoded, respectively.\nSLM: Standard language model. CTR: Corrupted text reconstruction. FTR: Full text reconstruction. †: Encoder-\ndecoder architectures usually apply objective functions to the decoder only.\n3.4.2\nMasked Language Models\nWhile autoregressive language models provide a powerful tool for modeling the probability of text, they also\nhave disadvantages such as requiring representations be calculated from left-to-right. When the focus is shifted to\ngenerating the optimal representations for down-stream tasks such as classiﬁcation, many other options become\npossible, and often preferable. One popular bidirectional objective function used widely in representation learning\nis the masked language model (MLM; Devlin et al. (2019)), which aims to predict masked text pieces based on\nsurrounded context. For example, P(xi|x1, . . . , xi−1, xi+1, . . . , xn) represents the probability of the word xi given\nthe surrounding context.\nExample & Applicable Scenario\nRepresentative pre-trained models using MLMs include: BERT (Devlin et al., 2019), ERNIE (Zhang et al.,\n2019; Sun et al., 2019b) and many variants. In prompting methods, MLMs are generally most suitable for\nnatural language understanding or analysis tasks (e.g., text classiﬁcation, natural language inference , and\nextractive question answering). These tasks are often relatively easy to be reformulated into cloze problems,\nwhich are consistent with the training objectives of the MLM. Additionally, MLMs have been a pre-trained\nmodel of choice when exploring methods that combine prompting with ﬁne-tuning, elaborated further in §7.\n3.4.3\nPreﬁx and Encoder-Decoder\nFor conditional text generation tasks such as translation and summarization where an input text x = x1, · · · , xn is\ngiven and the goal is to generate target text y, we need a pre-trained model that is both capable of encoding the\ninput text and generating the output text. There are two popular architectures for this purpose that share a common\n10\n",
    "book_id": "210713586v1",
    "book_title": "2107.13586v1",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 9
  },
  {
    "chunk_full": "thread of (1) using an encoder with fully-connected mask to encode the source x ﬁrst and then (2) decode the target\ny auto-regressively (from the left to right).\nPreﬁx Language Model\nThe preﬁx LM is a left-to-right LM that decodes y conditioned on a preﬁxed sequence\nx, which is encoded by the same model parameters but with a fully-connected mask. Notably, to encourage the\npreﬁx LM to learn better representations of the input, a corrupted text reconstruction objective is usually applied\nover x, in addition to a standard conditional language modeling objective over y.\nEncoder-decoder\nThe encoder-decoder model is a model that uses a left-to-right LM to decode y conditioned\non a separate encoder for text x with a fully-connected mask; the parameters of the encoder and decoder are not\nshared. Similarly to the preﬁx LM, diverse types of noising can be applied to the input x.\nExample & Applicable Scenario\nPreﬁx LMs have been explored in UniLM 1-2 (Dong et al., 2019; Bao et al., 2020) and ERNIE-M (Ouyang\net al., 2020) while encoder-decoder models are widely used in pre-trained models such as T5 (Raffel et al.,\n2020), BART (Lewis et al., 2020a), MASS (Song et al., 2019) and their variants.\nPre-trained models with preﬁx LMs and encoder-decoder paradigms can be naturally used to text generation\ntasks with (Dou et al., 2021) or without (Yuan et al., 2021a; Liu and Liu, 2021) prompting using input texts.\nHowever, recent studies reveal that other non-generation tasks, such as information extraction (Cui et al.,\n2021), question answering (Khashabi et al., 2020) , and text generation evaluation (Yuan et al., 2021b) can\nbe reformulated a generation problems by providing appropriate prompts. Therefore, prompting methods (i)\nbroaden the applicability of these generation-oriented pre-trained models. For example, pre-trained models\nlike BART are less used in NER while prompting methods make BART applicable, and (ii) breaks the\ndifﬁculty of uniﬁed modelling among different tasks (Khashabi et al., 2020).\n4\nPrompt Engineering\nPrompt engineering is the process of creating a prompting function fprompt(x) that results in the most effective\nperformance on the downstream task. In many previous works, this has involved prompt template engineering,\nwhere a human engineer or algorithm searches for the best template for each task the model is expected to perform.\nAs shown in the “Prompt Engineering” section of Fig.1, one must ﬁrst consider the prompt shape, and then decide\nwhether to take a manual or automated approach to create prompts of the desired shape, as detailed below.\n4.1\nPrompt Shape\nAs noted above, there are two main varieties of prompts: cloze prompts (Petroni et al., 2019; Cui et al., 2021), which\nﬁll in the blanks of a textual string, and preﬁx prompts (Li and Liang, 2021; Lester et al., 2021), which continue a\nstring preﬁx. Which one is chosen will depend both on the task and the model that is being used to solve the task. In\ngeneral, for tasks regarding generation, or tasks being solved using a standard auto-regressive LM, preﬁx prompts\ntend to be more conducive, as they mesh well with the left-to-right nature of the model. For tasks that are solved\nusing masked LMs, cloze prompts are a good ﬁt, as they very closely match the form of the pre-training task. Full\ntext reconstruction models are more versatile, and can be used with either cloze or preﬁx prompts. Finally, for some\ntasks regarding multiple inputs such as text pair classiﬁcation, prompt templates must contain space for two inputs,\n[X1] and [X2], or more.\n4.2\nManual Template Engineering\nPerhaps the most natural way to create prompts is to manually create intuitive templates based on human introspec-\ntion. For example, the seminal LAMA dataset (Petroni et al., 2019) provides manually created cloze templates to\nprobe knowledge in LMs. Brown et al. (2020) create manually crafted preﬁx prompts to handle a wide variety of\ntasks, including question answering, translation, and probing tasks for common sense reasoning. Schick and Sch¨utze\n(2020, 2021a,b) use pre-deﬁned templates in a few-shot learning setting on text classiﬁcation and conditional text\ngeneration tasks.\n4.3\nAutomated Template Learning\nWhile the strategy of manually crafting templates is intuitive and does allow solving various tasks with some degree\nof accuracy, there are also several issues with this approach: (1) creating and experimenting with these prompts is\nan art that takes time and experience, particularly for some complicated tasks such as semantic parsing (Shin et al.,\n2021); (2) even experienced prompt designers may fail to manually discover optimal prompts (Jiang et al., 2020c).\nTo address these problems, a number of methods have been proposed to automate the template design process. In\nparticular, the automatically induced prompts can be further separated into discrete prompts, where the prompt is an\n11\n",
    "book_id": "210713586v1",
    "book_title": "2107.13586v1",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 10
  },
  {
    "chunk_full": "4.3\nAutomated Template Learning\nactual text string, and continuous prompts, where the prompt is instead described directly in the embedding space of\nthe underlying LM.\nOne other orthogonal design consideration is whether the prompting function fprompt(x) is static, using essentially\nthe same prompt template for each input, or dynamic, generating a custom template for each input. Both static and\ndynamic strategies have been used for different varieties of discrete and continuous prompts, as we will mention\nbelow.\n4.3.1\nDiscrete Prompts\nWorks on discovering discrete prompts (a.k.a hard prompts) automatically search for templates described in a\ndiscrete space, usually corresponding to natural language phrases. We detail several methods that have been\nproposed for this below:\nD1: Prompt Mining\nJiang et al. (2020c)’s MINE approach is a mining-based method to automatically ﬁnd\ntemplates given a set of training inputs x and outputs y. This method scrapes a large text corpus (e.g. Wikipedia) for\nstrings containing x and y, and ﬁnds either the middle words or dependency paths between the inputs and outputs.\nFrequent middle words or dependency paths can serve as a template as in “[X] middle words [Z]”.\nD2: Prompt Paraphrasing\nParaphrasing-based approaches take in an existing seed prompt (e.g. manually\nconstructed or mined), and paraphrases it into a set of other candidate prompts, then selects the one that achieves the\nhighest training accuracy on the target task. This paraphrasing can be done in a number of ways, including using\nround-trip translation of the prompt into another language then back (Jiang et al., 2020c), using replacement of\nphrases from a thesaurus (Yuan et al., 2021b), or using a neural prompt rewriter speciﬁcally optimized to improve\naccuracy of systems using the prompt (Haviv et al., 2021). Notably, Haviv et al. (2021) perform paraphrasing after\nthe input x is input into the prompt template, allowing a different paraphrase to be generated for each individual\ninput.\nD3: Gradient-based Search\nWallace et al. (2019a) applied a gradient-based search over actual tokens to ﬁnd\nshort sequences that can trigger the underlying pre-trained LM to generate the desired target prediction. This search\nis done in an iterative fashion, stepping through tokens in the prompt . Built upon this method, Shin et al. (2020)\nautomatically search for template tokens using downstream application training samples and demonstrates strong\nperformance in prompting scenarios.\nD4: Prompt Generation\nOther works treat the generation of prompts as a text generation task and use standard\nnatural language generation models to perform this task. For example, Gao et al. (2021) introduce the seq2seq\npre-trained model T5 into the template search process. Since T5 has been pre-trained on a task of ﬁlling in missing\nspans, they use T5 to generate template tokens by (1) specifying the position to insert template tokens within a\ntemplate4 (2) provide training samples for T5 to decode template tokens. Ben-David et al. (2021) propose a domain\nadaptation algorithm that trains T5 to generate unique domain relevant features (DRFs; a set of keywords that\ncharacterize domain information) for each input. Then those DRFs can be concatenated with the input to form a\ntemplate and be further used by downstream tasks.\nD5: Prompt Scoring\nDavison et al. (2019) investigate the task of knowledge base completion and design a\ntemplate for an input (head-relation-tail triple) using LMs. They ﬁrst hand-craft a set of templates as potential\ncandidates, and ﬁll the input and answer slots to form a ﬁlled prompt. They then use a unidirectional LM to score\nthose ﬁlled prompts, selecting the one with the highest LM probability. This will result in custom template for each\nindividual input.\n4.3.2\nContinuous Prompts\nBecause the purpose of prompt construction is to ﬁnd a method that allows an LM to effectively perform a task,\nrather than being for human consumption, it is not necessary to limit the prompt to human-interpretable natural\nlanguage. Because of this, there are also methods that examine continuous prompts (a.k.a. soft prompts) that perform\nprompting directly in the embedding space of the model. Speciﬁcally, continuous prompts remove two constraints:\n(1) relax the constraint that the embeddings of template words be the embeddings of natural language (e.g., English)\nwords. (2) Remove the restriction that the template is parameterized by the pre-trained LM’s parameters. Instead,\ntemplates have their own parameters that can be tuned based on training data from the downstream task. We\nhighlight several representative methods below.\n4The number of template tokens do not need to be pre-speciﬁed since T5 can decode multiple tokens at a masked position.\n12\n",
    "book_id": "210713586v1",
    "book_title": "2107.13586v1",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 11
  },
  {
    "chunk_full": "C1: Preﬁx Tuning\nPreﬁx Tuning (Li and Liang, 2021) is a method that prepends a sequence of continuous\ntask-speciﬁc vectors to the input, while keeping the LM parameters frozen. Mathematically, this consists of\noptimizing over the following log-likelihood objective given a trainable preﬁx matrix Mφ and a ﬁxed pre-trained\nLM parameterized by θ.\nmax\nφ\nlog P(y|x; θ; φ) = max\nφ\nX\nyi\nlog P(yi|h<i; θ; φ)\n(2)\nIn Eq. 2, h<i = [h(1)\n<i ; · · · ; h(n)\n<i ] is the concatenation of all neural network layers at time step i. It is copied from\nMφ directly if the corresponding time step is within the preﬁx (hi is Mφ[i]), otherwise it is computed using the\npre-trained LM.\nExperimentally, Li and Liang (2021) observe that such continuous preﬁx-based learning is more sensitive to\ndifferent initialization in low-data settings than the use of discrete prompts with real words. Similarly, Lester et al.\n(2021) prepend the input sequence with special tokens to form a template and tune the embeddings of these tokens\ndirectly. Compared to Li and Liang (2021)’s method, this adds fewer parameters as it doesn’t introduce additional\ntunable parameters within each network layer. Tsimpoukelli et al. (2021) train a vision encoder that encodes an\nimage into a sequence of embeddings that can be used to prompt a frozen auto-regressive LM to generate the\nappropriate caption. They show that the resulting model can perform few-shot learning for vision-language tasks\nsuch as visual question answering etc. Different from the above two works, the preﬁx used in (Tsimpoukelli et al.,\n2021) is sample-dependent, namely a representation of input images, instead of a task embedding.\nC2: Tuning Initialized with Discrete Prompts\nThere are also methods that initialize the search for a continuous\nprompt using a prompt that has already been created or discovered using discrete prompt search methods. For\nexample, Zhong et al. (2021b) ﬁrst deﬁne a template using a discrete search method such as AUTOPROMPT (Shin\net al., 2020)’s, initialize virtual tokens based on this discovered prompt, then ﬁne-tune the embeddings to increase\ntask accuracy. This work found that initializing with manual templates can provide a better starting point for the\nsearch process. Qin and Eisner (2021) propose to learn a mixture of soft templates for each input where the weights\nand parameters for each template are jointly learned using training samples. The initial set of templates they use are\neither manually crafted ones or those obtained using the “prompt mining” method. Similarly, Hambardzumyan et al.\n(2021) introduce the use of a continuous template whose shape follows a manual prompt template.\nC3: Hard-Soft Prompt Hybrid Tuning\nInstead of using a purely learnable prompt template, these methods insert\nsome tunable embeddings into a hard prompt template. Liu et al. (2021b) propose “P-tuning”, where continuous\nprompts are learned by inserting trainable variables into the embedded input. To account for interaction between\nprompt tokens, they represent prompt embeddings as the output of a BiLSTM (Graves et al., 2013). P-tuning also\nintroduces the use of task-related anchor tokens (such as “capital” in relation extraction) within the template for\nfurther improvement. These anchor tokens are not tuned during training. Han et al. (2021) propose prompt tuning\nwith rules (PTR), which uses manually crafted sub-templates to compose a complete template using logic rules. To\nenhance the representation ability of the resulting template, they also insert several virtual tokens whose embeddings\ncan be tuned together with the pre-trained LMs parameters using training samples. The template tokens in PTR\ncontain both actual tokens and virtual tokens. Experiment results demonstrate the effectiveness of this prompt\ndesign method in relation classiﬁcation tasks.\n5\nAnswer Engineering\nIn contrast to prompt engineering, which designs appropriate inputs for prompting methods, answer engineering\naims to search for an answer space Z and a map to the original output Y that results in an effective predictive model.\nFig.1’s “Answer Engineering” section illustrates two dimensions that must be considered when performing answer\nengineering: deciding the answer shape and choosing an answer design method.\n5.1\nAnswer Shape\nThe shape of an answer characterizes its granularity. Some common choices include:\n• Tokens: One of the tokens in the pre-trained LM’s vocabulary, or a subset of the vocabulary.\n• Span: A short multi-token span. These are usually used together with cloze prompts.\n• Sentence: A sentence or document. These are commonly used with preﬁx prompts.\nIn practice, how to choose the shape of acceptable answers depends on the task we want to perform. Token or\ntext-span answer spaces are widely used in classiﬁcation tasks (e.g. sentiment classiﬁcation; Yin et al. (2019)),\nbut also other tasks such as relation extraction (Petroni et al., 2019) or named entity recognition (Cui et al., 2021).\nLonger phrasal or sentential answers are often used in language generation tasks (Radford et al., 2019), but also\n13\n",
    "book_id": "210713586v1",
    "book_title": "2107.13586v1",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 12
  },
  {
    "chunk_full": "5.2\nAnswer Space Design Methods\nused in other tasks such as multiple-choice question answering (where the scores of multiple phrases are compared\nagainst each-other; Khashabi et al. (2020)).\n5.2\nAnswer Space Design Methods\nThe next question to answer is how to design the appropriate answer space Z, as well as the mapping to the output\nspace Y if the answers are not used as the ﬁnal outputs.\n5.2.1\nManual Design\nIn manual design, the space of potential answers Z and its mapping to Y are crafted manually by an interested\nsystem or benchmark designer. There are a number of strategies that can be taken to perform this design.\nUnconstrained Spaces\nIn many cases, the answer space Z is the space of all tokens (Petroni et al., 2019),\nﬁxed-length spans (Jiang et al., 2020a), or token sequences (Radford et al., 2019). In these cases, it is most common\nto directly map answer z to the ﬁnal output y using the identity mapping.\nConstrained Spaces\nHowever, there are also cases where the space of possible outputs is constrained. This is\noften performed for tasks with a limited label space such as text classiﬁcation or entity recognition, or multiple-\nchoice question answering. To give some examples, Yin et al. (2019) manually design lists of words relating to\nrelevant topics (“health”, “ﬁnance”, “politics”, “sports”, etc.), emotions (“anger”, “joy”, “sadness”, “fear”, etc.), or\nother aspects of the input text to be classiﬁed. Cui et al. (2021) manually design lists such as “person”, “location”,\netc. for NER tasks. In these cases, it is necessary to have a mapping between the answer Z and the underlying class\nY.\nWith regards to multiple-choice question answering, it is common to use an LM to calculate the probability of an\noutput among multiple choices, with Zweig et al. (2012) being an early example.\n5.2.2\nDiscrete Answer Search\nAs with manually created prompts, it is possible that manually created answers are sub-optimal for getting the LM\nto achieve ideal prediction performance. Because of this, there is some work on automatic answer search, albeit less\nthan that on searching for ideal prompts. These work on both discrete answer spaces (this section) and continuous\nanswer spaces (the following).\nAnswer Paraphrasing\nThese methods start with an initial answer space Z′, and then use paraphrasing to expand\nthis answer space to broaden its coverage (Jiang et al., 2020b). Given a pair of answer and output ⟨z′, y⟩, we\ndeﬁne a function that generates a paraphrased set of answers para(z′). The probability of the ﬁnal output is then\ndeﬁned as the marginal probability all of the answers in this paraphrase set P(y|x) = P\nz∈para(z′) P(z|x). This\nparaphrasing can be performed using any method, but Jiang et al. (2020b) speciﬁcally use a back-translation method,\nﬁrst translating into another language then back to generate a list of multiple paraphrased answers.\nPrune-then-Search\nIn these methods, ﬁrst, an initial pruned answer space of several plausible answers Z′ is\ngenerated, and then an algorithm further searches over this pruned space to select a ﬁnal set of answers. Note that\nin some of the papers introduced below, they deﬁne a function from label y to a single answer token z, which is\noften called a verbalizer (Schick and Sch¨utze, 2021a). Schick and Sch¨utze (2021a); Schick et al. (2020) ﬁnd tokens\ncontaining at least two alphabetic characters that are frequent in a large unlabeled dataset. In the search step, they\niteratively compute a word’s suitability as a representative answer z for a label y by maximizing the likelihood of\nthe label over training data. Shin et al. (2020) learn a logistic classiﬁer using the contextualized representation of\nthe [Z] token as input. In the search step, they select the top-k tokens that achieve the highest probability score\nusing the learned logistic classiﬁer in the ﬁrst step. Those selected tokens will form the answer. Gao et al. (2021)\nﬁrst construct a pruned search space Z′ by selecting top-k vocabulary words based on their generation probability\nat the [Z] position determined by training samples. Then the search space is further pruned down by only selecting\na subset of words within Z′ based on their zero-shot accuracy on the training samples. (2) In the search step, they\nﬁne-tune the LM with ﬁxed templates together with every answer mapping using training data and select the best\nlabel word as the answer based on the accuracy on the development set.\nLabel Decomposition\nWhen performing relation extraction, Chen et al. (2021b) automatically decompose each re-\nlation label into its constituent words and use them as an answer. For example, for the relation per:city of death,\nthe decomposed label words would be {person, city, death}. The probability of the answer span will be\ncalculated as the sum of each token’s probability.\n5.2.3\nContinuous Answer Search\nVery few works explore the possibility of using soft answer tokens which can be optimized through gradient descent.\nHambardzumyan et al. (2021) assign a virtual token for each class label and optimize the token embedding for each\n14\n",
    "book_id": "210713586v1",
    "book_title": "2107.13586v1",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 13
  },
  {
    "chunk_full": "China’s capital is [MASK].\nPR1\n[MASK] is the capital of China.\nPR2\nThe capital of China is [MASK].\nPR3\nSubject: China; Relation: isCapital\nInput\n(a) Prompt Ensembling.\n1 + 1 = 2\nAns-PR1\nAdd up two numbers: 6, 8\nInput\nPR\nAns-PR2\n2 + 5 = 9\n6 + 8 = [MASK]\n(b) Prompt Augmentation.\nGoogle became a subsidiary of Alphabet.\nInput (X)\n[X] The [MASK] Google. \nSub-PR1\n[X] The [MASK] Alphabet. \nSub-PR2\nSub-PR3\n[X] Google [MASK] Alphabet. \n[X] The [MASK] Google [MASK] the [MASK] Alphabet. \nPR\n(c) Prompt Composition.\n[X] Mike is [MASK] entity type.\nSub-PR1\nMike went to New York yesterday.\nInput (X)\n[X] Mike is [MASK] entity type, \nNew York is [MASK] entity type. \nPR\nSub-PR2\n[X] New York is [MASK] entity type.\n(d) Prompt Decomposition.\nFigure 4: Different multi-prompt learning strategies. We use different colors to differentiate different components as\nfollows. “\n” for input text, “\n” for prompt, “\n” for answered prompt. “\n” for sub-prompt. We use the\nfollowing abbreviations. “PR” for prompt, “Ans-PR” for answered prompt, “Sub-PR” for sub-prompt.\nclass together with prompt token embeddings. Since the answer tokens are optimized directly in the embedding\nspace, they do not make use of the embeddings learned by the LM and instead learn an embedding from scratch for\neach label.\n6\nMulti-Prompt Learning\nThe prompt engineering methods we discussed so far focused mainly on constructing a single prompt for an input.\nHowever, a signiﬁcant body of research has demonstrated that the use of multiple prompts can further improve the\nefﬁcacy of prompting methods, and we will call these methods multi-prompt learning methods. In practice, there are\nseveral ways to extend the single prompt learning to the use multiple prompts, which have a variety of motivations.\nWe summarize representative methods in the “Multi-prompt Learning” section of Fig.1 as well as Fig.4.\n6.1\nPrompt Ensembling\nPrompt ensembling is the process of using multiple unanswered prompts for an input at inference time to make\npredictions. An example is shown in Fig. 4-(a). The multiple prompts can either be discrete prompts or continuous\nprompts.5 This sort of prompt ensembling can (1) leverage the complementary advantages of different prompts, (2)\nalleviate the cost of prompt engineering, since choosing one best-performing prompt is challenging, (3) stabilize\nperformance on downstream tasks.\nPrompt ensembling is connected to ensembling methods that are used to combine together multiple systems,\nwhich have a long history in machine learning (Ting and Witten, 1997; Zhou et al., 2002; Duh et al., 2011). Current\nresearch also borrows ideas from these works to derive effective ways for prompt ensembling, as described below.\nUniform averaging\nThe most intuitive way to combine the predictions when using multiple prompts is to take the\naverage of probabilities from different prompts. Concretely, this indicates that P(z|x) := 1\nK\nPK\ni P(z|fprompt,i(x))\nwhere fprompt,i(·) is the ith prompt in the prompt ensemble. Jiang et al. (2020c) ﬁrst ﬁlter their prompts by selecting\nK prompts that achieve the highest accuracy on the training set, and then use the average log probabilities obtained\nfrom the top K prompts to calculate the probability for a single token at [Z] position when performing factual\nprobing tasks. Schick and Sch¨utze (2021a) also try a simple average when using an ensemble model to annotate an\nunlabeled dataset. When performing text generation evaluation, Yuan et al. (2021b) formulates this task as a text\ngeneration problem and take the average of the ﬁnal generation scores obtained using different prompts.\nWeighted averaging\nSimple uniform averaging of results from multiple prompts is easy to implement, but can\nalso be suboptimal given that some prompts are more performant than others. To account for this, some works also\n5Multiple continuous prompts are typically learned by using different initializations or different random seeds.\n15\n",
    "book_id": "210713586v1",
    "book_title": "2107.13586v1",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 14
  },
  {
    "chunk_full": "6.2\nPrompt Augmentation\nexplore to use of weighted averages for prompt ensembling where each prompt is associated with a weight. The\nweights are typically pre-speciﬁed based on prompt performance or optimized using a training set. For example,\nJiang et al. (2020c) learn the weight for each prompt by maximizing the probability of the target output over training\ndata. Qin and Eisner (2021) use the same approach except that the weight for each prompt is optimized together\nwith soft prompt parameters. Besides, Qin and Eisner (2021) also introduce a data-dependent weighting strategy\nwhere the probability of the input appearing in that prompt is considered in weighting different prompts as well.\nSchick and Sch¨utze (2021a,b) set the weight for each prompt proportional to the accuracy on the training set before\ntraining.\nMajority voting\nFor classiﬁcation tasks, majority voting can also be used to combine the results from different\nprompts (Lester et al., 2021; Hambardzumyan et al., 2021).\nKnowledge distillation\nAn ensemble of deep learning models can typically improve the performance, and this\nsuperior performance can be distilled into a single model using knowledge distillation (Allen-Zhu and Li, 2020).\nTo incorporate this idea, Schick and Sch¨utze (2021a,b, 2020) train a separate model for each manually-created\ntemplate-answer pair, and use the ensemble of them to annotate an unlabeled dataset. Then the ﬁnal model is\ntrained to distill the knowledge from the annotated dataset. Gao et al. (2021) use a similar ensemble method on their\nautomatically generated templates.\nPrompt ensembling for text generation\nThere is relatively little work on prompt ensembling for generation\ntasks (i.e. tasks where the answers is a string of tokens instead of a single one). A simple way to perform ensembling\nin this case is to use standard methods that generate the output based on the ensembled probability of the next word\nin the answer sequence P(zt|x, z<t) :=\n1\nK\nPK\ni P(zt|fprompt,i(x), z<t). In contrast, Schick and Sch¨utze (2020)\ntrain a separate model for each prompt fprompt,i(x), and thus storing each of these ﬁne-tuned LMs in memory is\ninfeasible. Instead, they ﬁrst decode generations using each model and then score each generation by averaging\ntheir generation probability across all models.\n6.2\nPrompt Augmentation\nPrompt augmentation, also sometimes called demonstration learning (Gao et al., 2021), provides a few additional\nanswered prompts that can be used to demonstrate how the LM should provide the answer to the actual prompt\ninstantiated with the input x. For example, instead of just providing a prompt of “China’s capital is [Z] .”, the\nprompt can be prefaced by a few examples such as “Great Britain’s capital is London . Japan’s capital is Tokyo .\nChina’s capital is [Z] .” Another example of performing addition of two numbers can be found in Fig. 4-(b). These\nfew-shot demonstrations take advantage of the ability of strong language models to learn repetitive patterns (Brown\net al., 2020).\nAlthough the idea of prompt augmentation is simple, there are several aspects that make it challenging: (1)\nSample Selection: how to choose the most effective examples? (2) Sample Ordering: How to order the chosen\nexamples with the prompt?\nSample Selection\nResearchers have found that the choice of examples used in this few-shot scenario can result in\nvery different performance, ranging from near state-of-the-art accuracy on some tasks to near random guess (Lu\net al., 2021). To address this issue, Gao et al. (2021); Liu et al. (2021a) utilize sentence embeddings to sample\nexamples that are close to the input in this embedding space. To measure the generalization capability of pre-trained\nLMs to perform new tasks based on instructions, Mishra et al. (2021) provide both positive samples and negative\nsamples that highlight things to avoid.\nSample Ordering\nLu et al. (2021) found that the order of answered prompts provided to the model plays an\nimportant role in model performance, and propose entropy-based methods to score different candidate permutations.\nKumar and Talukdar (2021) search for a good permutation of training examples as augmented prompts and learn a\nseparator token between the prompts for further gains in performance.\nPrompt augmentation is closely related to retrieval-based methods that provide more textual context to the model\nto improve performance (Guu et al., 2018), a method which has also been shown to be effective in prompt-based\nlearning (Petroni et al., 2020). However, the key difference lies in the fact that prompt augmentation also leverages\nthe template and answer, while larger context learning does not.\n6.3\nPrompt Composition\nFor those composable tasks, which can be composed based on more fundamental subtasks, we can also perform\nprompt composition, using multiple sub-prompts, each for one subtask, and then deﬁning a composite prompt based\non those sub-prompts. This process is illustrated in Fig. 4-(c). For example, in the relation extraction task, which\naims to extract the relation of two entities, we can break down the task into several subtasks including identifying\nthe characteristics of entities and classifying the relationships between entities. Based on this intuition, Han et al.\n16\n",
    "book_id": "210713586v1",
    "book_title": "2107.13586v1",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 15
  },
  {
    "chunk_full": "6.4\nPrompt Decomposition\n(2021) ﬁrst use multiple manually created sub-prompts for entity recognition and relation classiﬁcation and then\ncompose them into a complete prompt based on logic rules for relation extraction.\n6.4\nPrompt Decomposition\nFor tasks where multiple predictions should be performed for one sample (e.g., sequence labeling), directly deﬁning\na holistic prompt with regards to the entire input text x is challenging. One intuitive method to address this problem\nis to break down the holistic prompt into different sub-prompts, and then answer each sub-prompt separately.\nFig.4-(d) illustrates this idea with an example from the named entity recognition task, which aims to identify all\nnamed entities in an input sentence. In this case, the input will ﬁrst be converted into a set of text spans, and the\nmodel can then be prompted to predict the entity type (including “Not an Entity”) for each span. It is not easy to\npredict all the span types at the same time due to the large number of spans, so different prompts for each span\ncan be created and predicted separately. This sort of prompt decomposition for named entity recognition has been\nexplored by Cui et al. (2021) where they apply the approach we discussed here.\n7\nTraining Strategies for Prompting Methods\nWith the methods in the above sections, it is now clear how to obtain an appropriate prompt (or prompts) and\ncorresponding answers. Now we discuss about methods that explicitly train models in concert with prompting\nmethods, as outlined in the “Training Strategies” section of Fig.1.\n7.1\nTraining Settings\nIn many cases, prompting methods can be used without any explicit training of the LM for the down-stream task,\nsimply taking an LM that has been trained to predict the probability of text P(x) and applying it as-is to ﬁll the\ncloze or preﬁx prompts deﬁned to specify the task. This is traditionally called the zero-shot setting, as there is zero\ntraining data for the task of interest.\nHowever, there are also methods that use training data to train the model in concert with prompting methods.\nThese consist of either full-data learning, where a reasonably large number of training examples are used to train\nthe model, or few-shot learning where a very small number of examples are used to train the model. Prompting\nmethods are particularly useful in the latter case, as there are generally not enough training examples to fully specify\nthe desired behavior, and thus using a prompt to push the model in the right direction is particularly effective.\nOne thing to note is that for many of the prompt engineering methods described in §4, although annotated training\nsamples are not explicitly used in the training of the downstream task model, they are often used in the construction\nor validation of the prompts that the downstream task will use. As noted by Perez et al. (2021), this is arguably not\ntrue zero-shot learning with respect to the downstream task.\n7.2\nParameter Update Methods\nIn prompt-based downstream task learning, there are usually two types of parameters, namely those from (1)\npre-trained models and (2) prompts. Which part of parameters should be updated is one important design decision,\nwhich can lead to different levels of applicability in different scenarios. We summarize ﬁve tuning strategies (as\nshown in Tab. 6) based on (i) whether the parameters of the underlying LM are tuned, (ii) whether there are additional\nprompt-related parameters, (iii) if there are additional prompt-related parameters, whether those parameters are\ntuned.\nStrategy\nLM Params\nPrompt Params\nExample\nAdditional\nTuned\nPromptless Fine-tuning\nTuned\n-\nELMo [130], BERT [32], BART [94]\nTuning-free Prompting\nFrozen\n%\n%\nGPT-3 [16], AutoPrompt [159], LAMA [133]\nFixed-LM Prompt Tuning\nFrozen\n!\nTuned\nPreﬁx-Tuning [96], Prompt-Tuning [91]\nFixed-prompt LM Tuning\nTuned\n%\n%\nPET-TC [153], PET-Gen [152], LM-BFF [46]\nPrompt+LM Fine-tuning\nTuned\n!\nTuned\nPADA [8], P-Tuning [103], PTR [56]\nTable 6: Characteristics of different tuning strategies. “Additional” represents if there are additional parameters\nbeyond LM parameters while “Tuned” denotes if parameters are updated.\n17\n",
    "book_id": "210713586v1",
    "book_title": "2107.13586v1",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 16
  },
  {
    "chunk_full": "7.2\nParameter Update Methods\n7.2.1\nPromptless Fine-tuning\nAs mentioned in the introduction, the pre-train and ﬁne-tune strategy has been widely used in NLP since before the\npopularization of prompting methods. Here we refer to pre-training and ﬁne-tuning without prompts as promptless\nﬁne-tuning, to contrast with the prompt-based learning methods introduced in the following sections. In this strategy,\ngiven a dataset of a task, all (or some (Howard and Ruder, 2018; Peters et al., 2019)) of the parameters of the\npre-trained LM will be updated via gradients induced from downstream training samples. Typical examples of\npre-trained models tuned in this way include BERT [32] and RoBERTa [105]. This is a simple, powerful, and\nwidely-used method, but it may overﬁt or not learn stably on small datasets (Dodge et al., 2020). Models are also\nprone to catastrophic forgetting, where the LM loses its ability to do things that it was able to do before ﬁne-tuning\n(McCloskey and Cohen, 1989).\n• Advantages: Simplicity, no need for prompt design. Tuning all the LM parameters allows the model to\nﬁt to larger training datasets.\n• Disadvantages: LMs may overﬁt or not learn stably on smaller datasets.\n7.2.2\nTuning-free Prompting\nTuning-free prompting directly generates the answers without changing the parameters of the pre-trained LMs\nbased only on a prompt, as described in the simplest incarnation of prompting in §2. These can be optionally\naugmenting input with answered prompts as described in §6.2, and this combination of tuning-free prompting and\nprompt augmentation is also referred to as in-context learning (Brown et al., 2020). Typical examples of tuning-free\nprompting include LAMA [133] and GPT-3 [16].\n• Advantages: Efﬁciency, there is no parameter update process. No catastrophic forgetting, as LM\nparameters remain ﬁxed. Applicable in zero-shot settings.\n• Disadvantages: Because prompts are the only method that provide the task speciﬁcation, heavy engi-\nneering is necessary to achieve high accuracy. In particular in the in-context learning setting, providing\nmany answered prompts can be slow at test time, and thus cannot easily use large training datasets.\n7.2.3\nFixed-LM Prompt Tuning\nIn the scenario where additional prompt-relevant parameters are introduced besides parameters of the pre-trained\nmodel, ﬁxed-LM prompt tuning updates only the prompts’ parameters using the supervision signal obtained from\nthe downstream training samples, while keeping the entire pre-trained LM unchanged. Typical examples are\nPreﬁx-Tuning [96] and WARP [55].\n• Advantages: Similarly to tuning-free prompting, it can retain knowledge in LMs and is suitable in\nfew-shot scenarios. Often superior accuracy to tuning-free prompting.\n• Disadvantages: Not applicable in zero-shot scenarios. While effective in few-shot scenarios, representa-\ntion power is limited in large-data settings. Prompt engineering through choice of hyperparameters or\nseed prompts is necessary. Prompts are usually not human-interpretable or manipulable.\n7.2.4\nFixed-prompt LM Tuning\nFixed-prompt LM tuning tunes the parameters of the LM, as in the standard pre-train and ﬁne-tune paradigm,\nbut additionally uses prompts with ﬁxed parameters to specify the model behavior. This potentially leads to\nimprovements, particularly in few-shot scenarios.\nThe most natural way to do so is to provide a discrete textual template that is applied to every training and test\nexample. Typical examples include PET-TC [153], PET-Gen [152], LM-BFF [46]. Logan IV et al. (2021) more\nrecently observe that the prompt engineering can be reduced by allowing for a combination of answer engineering\nand partial LM ﬁne-tuning. For example, they deﬁne a very simple template, null prompt, where the input and mask\nare directly concatenated “[X][Z]” without any template words, and ﬁnd this achieves competitive accuracy.\n• Advantages: Prompt or answer engineering more completely specify the task, allowing for more efﬁcient\nlearning, particularly in few-shot scenarios.\n• Disadvantages: Prompt or answer engineering are still required, although perhaps not as much as without\nprompting. LMs ﬁne-tuned on one downstream task may not be effective on another one.\n18\n",
    "book_id": "210713586v1",
    "book_title": "2107.13586v1",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 17
  },
  {
    "chunk_full": "7.2.5\nPrompt+LM Tuning\nIn this setting, there are prompt-relevant parameters, which can be ﬁne-tuned together with the all or some of the\nparameters of the pre-trained models. Representative examples include PADA [8], P-Tuning [103]. Notably, this\nsetting is very similar to the standard pre-train and ﬁne-tune paradigm, but the addition of the prompt can provide\nadditional bootstrapping at the start of model training.\n• Advantages: This is the most expressive method, likely suitable for high-data settings.\n• Disadvantages: Requires training and storing all parameters of the models. May overﬁt to small datasets.\n8\nApplications\nIn previous sections, we examined prompting methods from the point of view of the mechanism of the method itself.\nIn this section, we rather organize prompting methods from the point of view of which applications they have been\napplied to. We list these applications in Tab. 7-8 and summarize them in the following sections.\n8.1\nKnowledge Probing\nFactual Probing\nFactual probing (a.k.a. fact retrieval) is one of the earliest scenarios with respect to which\nprompting methods were applied. The motivation of exploring this task is to quantify how much factual knowledge\nthe pre-trained LM’s internal representations bear. In this task, parameters of pre-trained models are usually ﬁxed,\nand knowledge is retrieved by transforming the original input into a cloze prompt as deﬁned in §2.2, which can\nbe manually crafted or automatically discovered. Relevant datasets including LAMA (Petroni et al., 2019) and\nX-FACTR (Jiang et al., 2020a). Since the answers are pre-deﬁned, fact retrieval only focuses on ﬁnding effective\ntemplates and analyzing the results of different models using these templates. Both discrete template search (Petroni\net al., 2019, 2020; Jiang et al., 2020c,a; Haviv et al., 2021; Shin et al., 2020; Perez et al., 2021) and continuous\ntemplate learning (Qin and Eisner, 2021; Liu et al., 2021b; Zhong et al., 2021b) have been explored within this\ncontext, as well as prompt ensemble learning (Jiang et al., 2020c; Qin and Eisner, 2021).\nLinguistic Probing\nBesides factual knowledge, large-scale pre-training also allows LMs to handle linguistic\nphenomena such as analogies (Brown et al., 2020), negations (Ettinger, 2020), semantic role sensitivity (Ettinger,\n2020), semantic similarity (Sun et al., 2021), cant understanding (Sun et al., 2021), and rare word understanding\n(Schick and Sch¨utze, 2020). The above knowledge can also be elicited by presenting linguistic probing tasks in the\nform of natural language sentences that are to be completed by the LM.\n8.2\nClassiﬁcation-based Tasks\nPrompt-based learning has been widely explored in classiﬁcation-based tasks where prompt templates can be\nconstructed relatively easily, such as text classiﬁcation (Yin et al., 2019) and natural language inference (Schick and\nSch¨utze, 2021a). The key to prompting for classiﬁcation-based tasks is reformulating it as an appropriate prompt.\nFor example, Yin et al. (2019) use a prompt such as “the topic of this document is [Z].”, which is then fed into\nmask pre-trained LMs for slot ﬁlling.\nText Classiﬁcation\nFor text classiﬁcation tasks, most previous work has used cloze prompts, and both prompt\nengineering (Gao et al., 2021; Hambardzumyan et al., 2021; Lester et al., 2021) and answer engineering (Schick\nand Sch¨utze, 2021a; Schick et al., 2020; Gao et al., 2021) have been explored extensively. Most existing works\nexplore the efﬁcacy of prompt learning for text classiﬁcation in the context of few-shot setting with “ﬁxed-prompt\nLM Tuning” strategies (deﬁned in §7.2.4).\nNatural Language Inference (NLI)\nNLI aims to predict the relationship (e.g., entailment) of two given\nsentences. Similar to text classiﬁcation tasks, for natural language inference tasks, cloze prompts are commonly\nused (Schick and Sch¨utze, 2021a). Regarding prompt engineering, researchers mainly focus on the template search\nin the few-shot learning setting and the answer space Z is usually manually pre-selected from the vocabulary.\n19\n",
    "book_id": "210713586v1",
    "book_title": "2107.13586v1",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 18
  },
  {
    "chunk_full": "8.2\nClassiﬁcation-based Tasks\nPrompt Engineering\nAnswer Engineering\nWork\nTask\nPLM\nSetting\nShape\nMan\nAuto\nShape\nMan\nAuto\nTuning\nMul-Pr\nLMComm [173]\nCR\nL2R\nZero\nClo\n!\n-\nSp\n!\n-\nTFP\n-\nCR,QA\nGPT-2 [140]\nSUM,MT\nGPT-2\nZero,Few\nClo,Pre\n!\n-\nTok,Sp,Sen\n!\n-\nTFP\nPA\nWNLaMPro [150]\nLCP\nBERT\nZero\nClo\n!\n-\nTok\n!\n-\nTFP\n-\nLMDiagnose [39]\nCR,LCP\nBERT\nZero\nClo\n!\n-\nTok\n!\n-\nTFP\n-\nAdvTrigger [177]\nGCG\nGPT-2\nFull\nPre\n-\nDisc\nSen\n!\n-\nTFP\n-\nCohRank [31]\nCKM\nBERT\nZero\nClo\n!\n-\nTok,Sp\n!\n-\nTFP\n-\nConv,Trans\nLAMA [133]\nFP\nELMo,BERT\nZero\nClo\n!\n-\nTok\n!\n-\nTFP\n-\nCTRL [75]\nGCG\nCTRL\nFull\nPre\n!\n-\nSen\n!\n-\nLMT\n-\nTC,SUM\nT5 [141]\nQA,MT\nT5\nFull\nPre\n!\n-\nTok,Sp,Sen\n!\n-\nLMT\n-\nTrans,ELMo\nNeg & Mis [74]\nFP\nBERT\nZero\nClo\n!\n-\nTok\n!\n-\nTFP\n-\nLPAQA [68]\nFP\nBERT,ERNIE\nFull\nClo\n!\nDisc\nTok\n!\n-\nTFP\nPE\nZSC [135]\nTC\nGPT-2\nFull\nPre\n!\n-\nTok,Sp\n!\n-\nLMT\n-\nPET-TC [153]\nTC\nRoBERTa,XLM-R\nFew\nPre\n!\n-\nTok\n!\nDisc\nLMT\nPE\nContxFP [132]\nFP\nBERT,RoBERTa\nZero\nClo\n!\nDisc\nTok\n!\n-\nTFP\n-\nUniﬁedQA [76]\nQA\nT5,BART\nFull\nPreﬁx\n!\n-\nTok,Sp,Sen\n!\n-\nLMT\n-\nRAG [95]\nQA,GCG,TC\nBART\nFull\nPre\n-\nDisc\nTok,Sp,Sen\n!\n-\nLMPT\nPE\nQA,MT,GCG\nCR,TC,LCP\nGPT-3 [16]\nMR,SR,AR\nGPT-3\nZero,Few\nClo,Pre\n!\n-\nTok,Sp,Sen\n!\n-\nTFP\nPA\nCommS2S [187]\nCR\nT5\nFull\nPre\n!\n-\nTok\n!\n-\nLMT\n-\nPET-SGLUE [154]\nTC\nALBERT\nFew\nClo\n!\n-\nTok,Sp\n!\n-\nLMT\nPE\nGPT-1,GPT-2\nToxicityPrompts [47]\nGCG\nGPT-3,CTRL\nZero\nPre\n!\n-\nN/A\nTFP\n-\nWhyLM [147]\nTheory\nGPT-2\nFull\nPre\n!\n-\nTok\n!\n-\nPT\n-\nmBERT,BERT\nX-FACTR [66]\nFP\nXLM,XLM-R\nZero\nClo\n!\n-\nTok,Sp\n!\n-\nTFP\n-\nPetal [149]\nTC\nRoBERTa\nFew\nClo\n!\n-\nTok\n-\nDisc\nLMT\nPE\nAutoPrompt [159]\nTC,FP,IE\nBERT,RoBERTa\nFull\nClo\n-\nDisc\nTok\n-\nDisc\nTFP\n-\nCTRLsum [59]\nSUM\nBART\nFull\nPre\n!\n-\nSen\n!\n-\nLMT\n-\nPET-Gen [152]\nSUM\nPEGASUS\nFew\nPre\n!\n-\nSen\n!\n-\nLMT\nPE\nLM-BFF [46]\nTC\nRoBERTa\nFew\nClo\n-\nDisc\nTok\n-\nDisc\nLMT\nPE,PA\nWARP [55]\nTC\nRoBERTa\nFew,Full\nClo,Pre\n!\nCont\nTok\n!\nCont\nPT\nPE\nPreﬁx-Tuning [96]\nD2T,SUM\nGPT-2,BART\nFull\nPre\n-\nCont\nSen\n!\n-\nPT\n-\nKATE [100]\nTC,D2T,QA\nGPT-3\nFew\nPre\n!\n-\nTok,Sp,Sen\n!\n-\nTFP\nPA\nMT,MR\nPromptProg [145]\nAR,QA\nGPT-3\nZero,Few\nPre\n!\n-\nTok,Sp,Sen\n!\n-\nTFP\nPA\nContxCalibrate [201]\nTC,FP,IE\nGPT-2,GPT-3\nFew\nPre\n!\n-\nTok,Sp\n!\n-\nTFP\nPA\nPADA [8]\nTC,TAG\nT5\nFull\nPre\n-\nDisc\nN/A\nLMPT\n-\nSD [155]\nGCG\nGPT-2\nZero\nPre\n!\n-\nN/A\nTFP\n-\nBERTese [58]\nFP\nBERT\nFull\nClo\n!\nDisc\nTok\n!\n-\nTFP\n-\nPrompt2Data [148]\nTC\nRoBERTa\nFull\nClo\n!\n-\nTok,Sp\n!\n-\nLMT\n-\nGPT-2,BERT\nP-Tuning [103]\nFP,TC\nALBERT\nFew,Full\nClo,Pre\n!\nCont\nTok,Sp\n!\n-\nTFP,LMPT\n-\nGLM [37]\nTC\nGLM\nFull\nClo\n!\n-\nTok,Sp\n!\n-\nLMT\n-\nTable 7: An organization of works on prompting (Part 1). See the caption of Tab. 8 for a detailed description for all\nthe abbreviations used in this table.\n20\n",
    "book_id": "210713586v1",
    "book_title": "2107.13586v1",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 19
  },
  {
    "chunk_full": "8.2\nClassiﬁcation-based Tasks\nPrompt Engineering\nAnswer Engineering\nWork\nTask\nPLM\nSetting\nShape\nMan\nAuto\nShape\nMan\nAuto\nTuning\nMul-Pr\nADAPET [170]\nTC\nALBERT\nFew\nClo\n!\n-\nTok,Sp\n!\n-\nLMT\n-\nMeta [202]\nTC\nT5\nFull\nPre\n!\n-\nTok\n!\n-\nLMT\n-\nOptiPrompt [203]\nFP\nBERT\nFull\nClo\n!\nCont\nTok\n!\n-\nPT\n-\nBERT,BART\nSoft [137]\nFP\nRoBERTa\nFull\nClo\n!\nCont\nTok\n!\n-\nPT\nPE\nDINO [151]\nGCG\nGPT-2\nZero\nPre\n!\n-\nN/A\nTFP\n-\nAdaPrompt [21]\nIE\nBERT\nFew,Full\nClo\n!\n-\nTok\n-\nDisc\nLMT\n-\nPMIDC [62]\nGCG,QA,TC\nGPT-2,GPT-3\nZero\nPre\n!\n-\nTok,Sp,Sen\n!\n-\nTFP\n-\nPrompt-Tuning [91]\nTC\nT5\nFull\nPre\n-\nCont\nTok,Sp\n!\n-\nPT\nPE\nNatural-Instr [120]\nGCG\nGPT-3,BART\nFew,Full\nPre\n!\n-\nTok,Sp,Sen\n!\n-\nTFP,LMT\nPA\nOrderEntropy [111]\nTC\nGPT-2,GPT-3\nFew\nPre\n!\n-\nTok\n!\n-\nTFP\nPA\nFewshotSemp [158]\nSEMP\nGPT-3\nFew\nPre\n!\n-\nSen\n!\n-\nTFP\nPA\nQA,CR,TC\nPanGu-α [194]\nSUM,GCG\nPanGu-α\nZero,Few\nClo,Pre\n!\n-\nTok,Sp,Sen\n!\n-\nTFP\nPA\nGPT-2,GPT-3\nTrueFewshot [129]\nTC,FP\nALBERT\nFew\nClo,Pre\n!\nDisc\nTok,Sp\n!\n-\nTFP,LMT\n-\nPTR [56]\nIE\nRoBERTa\nFull\nClo\n!\nCont\nTok,Sp\n!\n-\nLMPT\nPC\nTemplateNER [29]\nTAG\nBART\nFew,Full\nClo,Pre\n!\n-\nTok\n!\n-\nLMT\nPD\nPERO [83]\nTC,FP\nBERT,RoBERTa\nFew\nPre\n!\n-\nTok\n!\n-\nTFP\nPA\nPromptAnalysis [181]\nTheory\nBERT\nFull\nClo\n-\nCont\nN/A\nPT\n-\nQA,MR,SUM\nCPM-2 [198]\nTC,GCG,MT\nCPM-2\nFull\nPre\n-\nCont\nTok,Sp,Sent\n!\n-\nPT,LMPT\n-\nBARTScore [193]\nEVALG\nBART\nZero\nPre\n!\nDisc\nSen\n!\n-\nTFP\nPE\nNullPrompt [109]\nTC\nRoBERTa,ALBERT\nFew\nPre\n!\n-\nTok\n!\n-\nLMPT\n-\nFrozen [174]\nVQA,VFP,MG\nGPT-like\nFull\nPre\n-\nCont\nSp (Visual)\n!\n-\nPT\nPA\nTC,LCP,NLI\nCR,QA,SUM\nERNIE-B3 [167]\nGCG\nERNIE-B3\nZero\nClo,Pre\n!\n-\nTok,Sp,Sen\n!\n-\nTFP\n-\nZero,Few\nCodex [20]\nCodeGen\nGPT\nFull\nPre\n!\n-\nSpan\n!\nDisc\nTFP,LMT\nPA\nZero,Few\nHTLM [1]\nTC,SUM\nBART\nFull\nClo\n!\nDisc\nTok,Sp,Sen\n!\n-\nLMT\nPA\nFLEX [15]\nTC\nT5\nZero,Few\nPre\n!\n-\nTok,Sp\n!\n-\nLMT\n-\nTable 8: An organization of works on prompting (Part 2). The Task column lists the tasks that are performed\nin corresponding papers. We use the following abbreviations. CR: Commonsense Reasoning. QA: Question\nAnswering. SUM: Summarization. MT: Machine Translation. LCP: Linguistic Capacity Probing. GCG: General\nConditional Generation. CKM: Commonsense Knowledge Mining. FP: Fact Probing. TC: Text Classiﬁcation. MR:\nMathematical Reasoning. SR: Symbolic Reasoning. AR: Analogical Reasoning. Theory: Theoretical Analysis.\nIE: Information Extraction. D2T: Data-to-text. TAG: Sequence Tagging. SEMP: Semantic Parsing. EVALG:\nEvaluation of Text Generation. VQA: Visual Question Answering. VFP: Visual Fact Probing. MG: Multimodal\nGrounding. CodeGen: Code generation. The PLM column lists all the pre-trained LMs that have been used in\ncorresponding papers for downstream tasks. GPT-like is an autoregressive language model which makes small\nmodiﬁcations to the original GPT-2 architecture. For other pre-trained LMs, please refer to §3 for more information.\nSetting column lists the settings for prompt-based learning, can be zero-shot learning (Zero), few-shot learning\n(Few), fully supervised learning (Full). Under Prompt Engineering, Shape denotes the shape of the template\n(Clo for cloze and Pre for preﬁx), Man denotes whether human effort is needed, Auto denotes data-driven search\nmethods (Disc for discrete search, Cont for continuous search). Under Answer Engineering, Shape indicates the\nshape of the answer (Tok for token-level, Sp for span-level, Sen for sentence- or document-level), and Man and\nAuto are the same as above. The Tuning column lists tuning strategies (§7). TFP: Tuning-free Prompting. LMT:\nFixed-prompt LM Tuning. PT: Fixed-LM Prompt Tuning. LMPT: LM+Prompt Tuning. The Mul-Pr column lists\nmulti-prompt learning methods. PA: Prompt Augmentation. PE: Prompt Ensembling. PC: Prompt Composition.\nPD: Prompt Decomposition.\n21\n",
    "book_id": "210713586v1",
    "book_title": "2107.13586v1",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 20
  },
  {
    "chunk_full": "8.3\nInformation Extraction\n8.3\nInformation Extraction\nUnlike classiﬁcation tasks where cloze questions can often be intuitively constructed, for information extraction\ntasks constructing prompts often requires more ﬁnesse.\nRelation Extraction\nRelation extraction is a task of predicting the relation between two entities in a sentence.\nChen et al. (2021b) ﬁrst explored the application of ﬁxed-prompt LM Tuning in relation extraction and discuss two\nmajor challenges that hinder the direct inheritance of prompting methodology from classiﬁcation tasks: (1) The\nlarger label space (e.g. 80 in relation extraction v.s 2 in binary sentiment classiﬁcation) results in more difﬁculty in\nanswer engineering. (2) In relation extraction, different tokens in the input sentence may be more or less important\n(e.g. entity mentions are more likely to participate in a relation), which, however, can not be easily reﬂected in\nthe prompt templates for classiﬁcation since the original prompt template regards each word equally. To address\nthe above problems, Chen et al. (2021b) propose an adaptive answer selection method to address the issue (1) and\ntask-oriented prompt template construction for the issue (2), where they use special markers (e.g. [E]) to highlight\nthe entity mentions in the template. Similarly, Han et al. (2021) incorporate entity type information via multiple\nprompt composition techniques (illustrated in Fig. 4).\nSemantic Parsing\nSemantic parsing is a task of generating a structured meaning representation given a natural\nlanguage input. Shin et al. (2021) explore the task of few-shot semantic parsing using LMs by (1) framing the\nsemantic parsing task as a paraphrasing task (Berant and Liang, 2014) and (2) constraining the decoding process\nby only allowing output valid according to a grammar. They experiment with the in-context learning setting\ndescribed in §7.2.2, choosing answered prompts that are semantically close to a given test example (determined\nby the conditional generation probability of generating a test sample given another training example). The results\ndemonstrate the effectiveness of the paraphrasing reformulation for semantic parsing tasks using pre-trained LMs.\nNamed Entity Recognition\nNamed entity recognition (NER) is a task of identifying named entities (e.g., person\nname, location) in a given sentence. The difﬁculty of prompt-based learning’s application to tagging tasks,\nexempliﬁed as NER, is that, unlike classiﬁcation, (1) each unit to be predicted is a token or span instead of the\nwhole input text, (2) there is a latent relationship between the token labels in the sample context. Overall, the\napplication of prompt-based learning in tagging task has not been fully explored. Cui et al. (2021) recently propose\na template-based NER model using BART, which enumerates text spans and considers the generation probability of\neach type within manually crafted templates. For example, given an input “Mike went to New York yesterday”, to\ndetermine what type of entity “Mike” is, they use the template “Mike is a [Z] entity”, and the answer space Z\nconsists of values such as “person” or “organization”.\n8.4\n“Reasoning” in NLP\nThere is still a debate6 about if deep neural networks are capable of performing “reasoning” or just memorizing\npatterns based on large training data (Arpit et al., 2017; Niven and Kao, 2019). As such, there have been a number\nof attempts to probe models’ reasoning ability by deﬁning benchmark tasks that span different scenarios. We detail\nbelow how prompting methods have been used in these tasks.\nCommonsense Reasoning\nThere are a number of benchmark datasets testing commonsense reasoning in NLP\nsystems (Huang et al., 2019; Rajani et al., 2019; Lin et al., 2020; Ponti et al., 2020). Some commonly attempted\ntasks involve solving Winograd Schemas (Levesque et al., 2012), which require the model to identify the antecedent\nof an ambiguous pronoun within context, or involve completing a sentence given multiple choices. For the former,\nan example could be “The trophy doesn’t ﬁt into the brown suitcase because it is too large.” And the task for the\nmodel is to infer whether “it” refers to the trophy or the “suitcase”. By replacing “it” with its potential candidates in\nthe original sentences and calculating the probability of the different choices, pre-trained LMs can perform quite\nwell by choosing the choice that achieves the highest probability (Trinh and Le, 2018). For the latter, an example\ncould be “Eleanor offered to ﬁx her visitor some coffee. Then she realized she didn’t have a clean [Z].”. The\ncandidate choices are “cup”, “bowl” and “spoon”. The task for the pre-trained LM is to choose the one from the\nthree candidates that most conforms to common sense. For these kinds of tasks, we can also score the generation\nprobability of each candidate and choose the one with the highest probability (Ettinger, 2020).\nMathematical Reasoning\nMathematical reasoning is the ability to solve mathematical problems, e.g. arithmetic\naddition, function evaluation. Within the context of pre-trained LMs, researchers have found that pre-trained\nembeddings and LMs can perform simple operations such as addition and subtraction when the number of digits is\nsmall, but fail when the numbers are larger (Naik et al., 2019; Wallace et al., 2019b; Brown et al., 2020). Reynolds\nand McDonell (2021) explore more complex mathematical (e.g. f(x) = x ∗x, what is f(f(3))?) reasoning\nproblems and improve LM performance through serializing reasoning for the question.\n6e.g. https://medium.com/reconstruct-inc/the-golden-age-of-computer-vision-338da3e471d1\n22\n",
    "book_id": "210713586v1",
    "book_title": "2107.13586v1",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 21
  },
  {
    "chunk_full": "8.5\nQuestion Answering\n8.5\nQuestion Answering\nQuestion answering (QA) aims to answer a given input question, often based on a context document. QA can take a\nvariety of formats, such as extractive QA (which identiﬁes content from the context document containing the answer;\ne.g. SQuAD (Rajpurkar et al., 2016)), multiple-choice QA (where the model has to pick from several choices; e.g.\nRACE (Lai et al., 2017)), and free-form QA (where the model can return an arbitrary textual string as a response;\ne.g. NarrativeQA (Koˇcisk´y et al., 2018)). Generally, these different formats have been handled using different\nmodeling frameworks. One beneﬁt of solving QA problems with LMs, potentially using prompting methods, is\nthat different formats of QA tasks can be solved within the same framework. For example, Khashabi et al. (2020)\nreformulate many QA tasks as a text generation problem by ﬁne-tuning seq2seq-based pre-trained models (e.g. T5)\nand appropriate prompts from the context and questions. Jiang et al. (2020b) take a closer look at such prompt-based\nQA systems using sequence to sequence pre-trained models (T5, BART, GPT2) and observe that probabilities from\nthese pre-trained models on QA tasks are not very predictive of whether the model is correct or not.\n8.6\nText Generation\nText generation is a family of tasks that involve generating text, usually conditioned on some other piece of\ninformation. Prompting methods can be easily applied to these tasks by using preﬁx prompts together with\nautoregressive pre-trained LMs. Radford et al. (2019) demonstrated impressive ability of such models to perform\ngeneration tasks such as text summarization and machine translation using prompts such as “translate to french,\n[X], [Z]”. Brown et al. (2020) perform in-context learning (§7.2.2) for text generation, creating a prompt with\nmanual templates and augmenting the input with multiple answered prompts. Schick and Sch¨utze (2020) explore\nﬁxed-prompt LM tuning (§7.2.4) for few-shot text summarization with manually crafted templates. (Li and Liang,\n2021) investigate ﬁxed-LM prompt tuning (§7.2.3) for text summarization and data-to-text generation in few-shot\nsettings, where learnable preﬁx tokens are prepended to the input while parameters in pre-trained models are kept\nfrozen. Dou et al. (2021) explored the prompt+LM tuning strategy (§7.2.5) on text summarization task, where\nlearnable preﬁx prompts are used and initialized by different types of guidance signals, which can then be updated\ntogether with parameters of pre-trained LMs.\n8.7\nAutomatic Evaluation of Text Generation\nYuan et al. (2021b) have demonstrated that prompt learning can be used for automated evaluation of generated\ntexts. Speciﬁcally, they conceptualize the evaluation of generated text as a text generation problem, modeled\nusing a pre-trained sequence-to-sequence, and then use preﬁx prompts that bring the evaluation task closer to the\npre-training task. They experimentally ﬁnd that simply adding the phrase “such as” to the translated text when using\npre-trained models can lead to a signiﬁcant improvement in correlation on German-English machine translation\n(MT) evaluation.\n8.8\nMulti-modal Learning\nTsimpoukelli et al. (2021) shift the application of prompt learning from text-based NLP to the multi-modal setting\n(vision and language). Generally, they adopt the ﬁxed-LM prompt tuning strategy together with prompt augmentation\ntechniques. They speciﬁcally represent each image as a sequence of continuous embeddings, and a pre-trained LM\nwhose parameters are frozen is prompted with this preﬁx to generate texts such as image captions. Empirical results\nshow few-shot learning ability: with the help of a few demonstrations (answered prompts), system can rapidly learn\nwords for new objects and novel visual categories.\n8.9\nMeta-Applications\nThere are also a number of applications of prompting techniques that are not NLP tasks in and of themselves, but\nare useful elements of training strong models for any application.\nDomain Adaptation\nDomain adaptation is the practice of adapting a model from one domain (e.g. news text)\nto another (e.g. social media text). Ben-David et al. (2021) use self-generated domain related features (DRFs) to\naugment the original text input and perform sequence tagging as a sequence-to-sequence problem using a seq2seq\npre-trained model.\nDebiasing\nSchick et al. (2021) found that LMs can perform self-diagnosis and self-debiasing based on biased\nor debiased instructions. For example, to self-diagnosis whether the generated text contains violent information,\nwe can use the following template “The following text contains violence. [X][Z]”. Then we ﬁll [X] with the\ninput text and look at the generation probability at [Z], if the probability of “Yes” is greater than “No”, then we\nwould assume the given text contains violence, and vice versa. To perform debiasing when generating text, we ﬁrst\ncompute the probability of the next word P(xt|x<t; θ) given the original input. Then we compute the probability\n23\n",
    "book_id": "210713586v1",
    "book_title": "2107.13586v1",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 22
  },
  {
    "chunk_full": "8.10\nResources\nof next word P(xt|[x<t; xdiagnosis]; θ) by appending self-diagnosis textual input to the original input as mentioned\nabove. These two probability distributions for the next token can be combined to suppress the undesired attribute.\nDataset Construction\nSchick and Sch¨utze (2021) propose to use pre-trained LMs to generate datasets given\ncertain instructions. As an example, suppose we have an unlabeled dataset in which each sample is a sentence. If\nwe want to construct a dataset containing pairs of semantically similar sentences, then we can use the following\ntemplate for each input sentence: “Write two sentences that mean the same thing. [X][Z]” and attempt to generate\na sentence that shares the same meaning as the input sentence.\n8.10\nResources\nWe also collect some useful resources for different prompt-based applications.\nDataset\nSome datasets speciﬁcally designed for few-shot and zero-shot learning are shown in Tab. 9.\nTask\nDataset\nSetting\nURL\nPronoun Disambiguation Problems [93] Zero\nhttps://cs.nyu.edu/ davise/papers/...\nWinograd Schema Challenge [93]\nZero\nhttps://cs.nyu.edu/ davise/papers/...\nCommonsense Reasoning\nCPRAG-102 [39]\nZero\nhttps://github.com/aetting/lm-diagnostics\nWNLaMPro [150]\nZero\nhttps://github.com/timoschick/...\nROLE-88 [39]\nZero\nhttps://github.com/aetting/lm-diagnostics\nLinguistic Capacity Probing\nNEG-136 [39]\nZero\nhttps://github.com/aetting/lm-diagnostics\nLAMA [133]\nZero\nhttps://dl.fbaipublicﬁles.com/LAMA/...\nNegated LAMA [74]\nZero\nhttps://github.com/norakassner/LAMA...\nMisprimed LAMA [74]\nZero\nhttps://github.com/norakassner/LAMA...\nFact Probing\nX-FACTR [66]\nZero\nhttps://x-factr.github.io/\nLAMA-TREx-easy-hard [203]\nZero\nhttps://github.com/princeton-nlp/...\nFLEX [15]\nZero,Few https://github.com/allenai/ﬂex\nText Classiﬁcation\nFewGLUE [154]\nFew\nhttps://github.com/timoschick/fewglue\nREALTOXICITYPROMPTS [47]\nZero\nhttps://allenai.org/data/...\nGeneral Conditional Gen.\nNatural-Instructions [120]\nFew,Full\nhttps://instructions.apps.allenai.org/\nTable 9: Few-shot and zero-shot datasets for prompt-based learning.\nPrompts\nAs shown in Tab. 10, we collect existing commonly-used prompts designed manually, which can be\nregarded as off-the-shelf resource for future research and applications.\n9\nPrompt-relevant Topics\nWhat is the essence of prompt-based learning and how does it relate to other learning methods? In this section, we\nconnect prompt learning with other similar learning methods.\nEnsemble Learning\nEnsemble learning (Ting and Witten, 1997; Zhou et al., 2002) is a technique that aims to\nimprove the performance of a task by taking advantage of the complementarity of multiple systems. Generally, the\ndifferent systems used in an ensemble result from different choices of architectures, training strategies, data ordering,\nand/or random initialization. In prompt ensembling (§6.1), the choice of prompt templates becomes another way to\ngenerate multiple results to be combined. This has the clear advantage that this does not necessarily require training\nthe model multiple times. For example, when using discrete prompts, these prompts can simply be changed during\nthe inference stage (Jiang et al., 2020c).\nFew-shot Learning\nFew-shot learning aims to learn a machine learning system in the data-scarce scenarios with\nfew training samples. There are a wide variety of methods to achieve few-shot learning including model agnostic\nmeta-learning (Finn et al., 2017b) (learning features rapidly adaptable to new tasks), embedding learning (Bertinetto\net al., 2016) (embedding each sample in a lower-dimensional space where similar samples are close together),\nmemory-based learning (Kaiser et al., 2017) (representing each sample by a weighted average of contents from\nthe memory) etc. (Wang et al., 2020). Prompt augmentation can be regarded as another way to achieve few-shot\nlearning (a.k.a. priming-based few-shot learning (Kumar and Talukdar, 2021)). Compared to previous methods,\nprompt augmentation directly prepends several labeled samples to the currently-processed sample elicit knowledge\nfrom pre-trained LMs even without any parameter tuning.\n24\n",
    "book_id": "210713586v1",
    "book_title": "2107.13586v1",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 23
  },
  {
    "chunk_full": "Task\nExample Prompt-Answer\nResource\nFact Probing\nPrompt Adolphe Adam died in [Z].\nLAMA dataset\nAnswer V\nLPAQA dataset\nPrompt iPod Touch is produced by [Z].\nX-FACTR dataset\nAnswer V\nPrompt The ofﬁcial language of Mauritius is [Z].\nAnswer V\nText Classiﬁcatin\nPrompt Which of these choices best describes the following\nMeta [202]\ndocument? ”[Class A]”, ”[Class B]”, ”[Class C]”.\n[X][Z]\nAnswer [Class A], [Class B], [Class C]\nPrompt How is the text best described? : ”[Class A]”,\n“[Class B]” , or “[Class C]”. [X][Z]\nAnswer [Class A], [Class B], [Class C]\nPrompt This passage is about [Z]: [X]\nAnswer [Class A], [Class B], [Class C]\nPrompt [X]. Is this review positive? [Z]\nAnswer Yes, No\nPrompt [X] It was [Z].\nAnswer great, terrible\nNatural Language Inference\nPrompt [X1]? [Z], [X2]\nAnswer Yes, No, Maybe\nPrompt [X1] [Z], [X2]\nAnswer Yes, No, Maybe\nCommonsense Reasoning\nPrompt The trophy doesn’t ﬁt into the brown suitcase\nPDP dataset\nbecause [Z] is too large.\nWSC dataset\nAnswer trophy, suitcase\nCPRAG-102 dataset\nPrompt Ann asked Mary what time the library closes,\nbecause [Z] had forgotten.\nAnswer Ann, Mary\nLinguistic Knowledge Probing\nPrompt A robin is a [Z].\nWNLaMPro dataset\nAnswer bird, tree\nROLE-88 dataset\nPrompt A robin is not a [Z].\nNEG-136 dataset\nAnswer bird, tree\nPrompt New is the opposite of [Z].\nAnswer old, young, current\nNamed Entity Recognition\nPrompt-Pos [X] [Span] is a [Z] entity.\nTemplateNER [29]\nPrompt-Neg [X] [Span] is not a named entity.\nAnswer person, location, organization, miscellaneous\nPrompt-Pos The entity type of Span is [Z].\nPrompt-Neg [X] The entity type of [Span] is none entity.\nAnswer person, location, organization, miscellaneous\nQuestion Answering\nPrompt [Question] [Passage] [Z]\nPrompt [Passage] According to the passage, [Question]\n[Z]\nPrompt Based on the following passage, [Question] [Z].\n[Passage]\nSummarization\nPrompt Text: [X] Summary: [Z]\nBARTScore [193]\nPrompt [X] TL;DR: [Z]\nPrompt [X] In summary, [Z]\nMachine Translation\nPrompt French: [French sentence] English:\nPrompt A French sentence is provided: [French sentence]\nThe French translator translates the sentence into English: [Z]\nPrompt [French sentence] = [Z]\nTable 10: Commonly used prompts and answers for different tasks. [X] and [Z] denote slots for input and answer\nrespectively. V denotes the vocabulary of the LM. More prompts for each task can be found using the Resource\ncolumn.\n25\n",
    "book_id": "210713586v1",
    "book_title": "2107.13586v1",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 24
  },
  {
    "chunk_full": "Prompt Concept\nRelevant Topic\nCommonality\nPeculiarity\nPrompt Ensembling [68;\n153]\nEnsemble Learning\n[171; 204]\nCombine results of multiple sys-\ntems to get better performance\nIn prompt ensembling, multiple predic-\ntions result from different prompt vari-\nants. This contrasts with architecture\nor feature variations, each of which re-\nquires separate training.\nPrompt Augmentation\n[16; 46]\nFew-shot Learning\n[160; 42]\nUse few examples to learn gen-\neralized rules\nPrompt augmentation is a speciﬁc subset\nof few-shot learning.\nLarger-context\nLearning [18; 53]\nIntroduce larger context to aid\nthe learning process\nAdditional information introduced in\nlarger-context learning is not necessarily\nthe labeled data.\nDiscrete Prompt Search\n[68; 159]\nQuery\nreformula-\ntion [123; 123]\nReformulate the input into a\nquery form\nQuery reformulation commonly focuses\non information extraction and question\nanswering tasks, while prompt learning\ncan be applied to a variety of NLP tasks\nDiscrete Prompt Fine-\ntuning [46]\nQA-based\nmulti-\ntask learning [115;\n97]\nReformulate many tasks into an\nQA form\nQA-based formulations aim to solve dif-\nferent tasks through question answering,\nwhile prompting additionally targets full\nuse of pre-trained models.\nContinuous\nPrompt\nFine-tuning [103; 36]\nControlled\nText\nGeneration\n[191;\n77; 156]\nInput is augmented with addi-\ntional inputs to control the gen-\neration process\nControlled generation targets generation\nof a particular type of text while prompt\nlearning uses prompts to specify the task\nitself.\nPrompt-based\ndown-\nstream\ntask\nlearning\n[153; 193]\nSupervised\nAttention [101;\n165]\nRequire external hint to remind\nthe model of which part\ninformation should be focused\non\nResearch works on supervised attention\nusually target at salient information from\nan image or text, while prompt learning\naims to utilize relevant knowledge from\nthe pre-trained model.\nData augmentation\n[40; 144]\nImproving downstream tasks’\nperformance by introducing ad-\nditional samples\nData augmentation introduce additional\ntraining samples in an explicit way\nwhile prompts can be regarded as highly-\ncondensed training samples [88].\nTable 11: Other research topics relevant to prompting methods.\nLarger-context Learning\nLarger-context learning aims to improve the system’s performance by augmenting the\ninput with additional contextual information, e.g. retrieved from the training set (Cao et al., 2018) or external data\nsources (Guu et al., 2020). Prompt augmentation can be regarded as adding relevant labeled samples into the input,\nbut a minor difference is in larger-context learning, the introduced context is not necessarily labeled data.\nQuery Reformulation\nQuery reformulation (Mathieu and Sabatier, 1986; Daum´e III and Brill, 2004) is commonly\nused in information retrieval (Nogueira and Cho, 2017) and question answering tasks (Buck et al., 2017; Vakulenko\net al., 2020), which aim to elicit more relevant texts (documents or answers) by expanding the input query with\nrelated query terms (Hassan, 2013) or generating paraphrases. There are several commonalities between prompt-\nbased learning and query reformulation, for example (1) both aim to make better use of some existing knowledge\nbases by asking a right questions (2) the knowledge bases are usually a black-box, not available to the users, so\nresearchers must learn how to probe it optimally based on solely questions.\nThere are also differences: the knowledge base in traditional query reformulation problems is usually a search\nengine (Nogueira and Cho, 2017), or QA system (Buck et al., 2017). By contrast, for prompt-based learning,\nwe usually deﬁne this knowledge base as an LM, and need to ﬁnd the appropriate query to elicit an appropriate\nanswer from it. The input reformulation in prompt learning has changed the form of tasks. For example, an original\ntext classiﬁcation task has been converted into a cloze question problem, therefore bringing additional complexity\nregarding how to (1) make an appropriate task formulation, and (2) change the modeling framework accordingly.\nThese steps are not required in traditional query formulation. Despite these discrepancies, some methodologies\nfrom query reformulation research still can be borrowed for prompt learning, such as decomposing input query into\nmultiple sub-queries (Nogueira et al., 2019), similar to prompt decomposition.\nQA-based Task Formulation\nQA-based task formulation aims to conceptualize different NLP tasks as a question-\nanswering problem. (Kumar et al., 2016; McCann et al., 2018) are earlier works that attempt to unify multiple NLP\ntasks into a QA framework. Later, this idea has been further explored in information extraction (Li et al., 2020; Wu\n26\n",
    "book_id": "210713586v1",
    "book_title": "2107.13586v1",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 25
  },
  {
    "chunk_full": "et al., 2020) and text classiﬁcation (Chai et al., 2020). These methods are very similar to the prompting methods\nintroduced here in that they use textual questions to specify which task is to be performed. However, one of the key\npoints of prompting methods is how to better use the knowledge in pre-trained LMs, and these were not covered\nextensively on previous works advocating for QA formulations.\nControlled Generation\nControlled generation aims to incorporate various types of guidance beyond the input\ntext into the generation model (Yu et al., 2020). Speciﬁcally, the guidance signals could be style tokens (Sennrich\net al., 2016b; Fan et al., 2018), length speciﬁcations (Kikuchi et al., 2016), domain tags (Chu et al., 2017), or\nany variety of other pieces of information used to control of the generated text. It could also be keywords (Saito\net al., 2020), relation triples (Zhu et al., 2020) or even highlighted phrases or sentences (Grangier and Auli, 2018;\nLiu et al., 2021c) to plan the content of generated texts. In a way, many of the prompting methods described\nhere are a type of controllable generation, where the prompt is usually used to specify the task itself. Thus, it is\nrelatively easy to ﬁnd commonalities between the two genres: (1) both add extra information to the input text for\nbetter generation, and these additional signals are (often) learnable parameters. (2) If “controlled generation” is\nequipped with seq2seq-based pre-trained models (e.g., BART), then it is can be regarded as prompt learning with\ninput-dependent prompts and the prompt+LM ﬁne-tuning strategy (§7.2.5), e.g. GSum (Dou et al., 2021), where\nboth the prompt’s and pre-trained LM’s parameters can be tuned.\nAlso, some clear discrepancies between controlled generation and prompt-based text generation are: (1) In\ncontrolled generation work, the control is generally performed over the style or content of the generations (Fan et al.,\n2018; Dou et al., 2021) while the underlying task remains the same. They don’t necessarily require a pre-trained\nmodel. In contrast, the main motivation for using prompts for text generation is to specify the task itself and better\nutilize the pre-trained model. (2) Moreover, most of the current work on prompt learning in text generation shares\na dataset- or task-level prompt (Li and Liang, 2021). Only very few works have explored input-dependent ones\n(Tsimpoukelli et al., 2021). However, this is a common setting and effective in the controlled text generation, which\nmay provide valuable direction for the future work on prompt learning.\nSupervised Attention\nKnowing to pay attention to the important information is a key step when extracting useful\ninformation from objects such as long text sequences (Liu et al., 2016; Sood et al., 2020), images (Sugano and\nBulling, 2016; Zhang et al., 2020b), or knowledge bases (Yu et al., 2020; Dou et al., 2021)). Supervised attention\n(Liu et al., 2017b) aims to provide explicit supervision over the attention of models based on the fact that completely\ndata-driven attention can overﬁt to some artifacts (Liu et al., 2017a). In this respect, prompt learning and supervised\nattention share ideas that both aim to extract salient information with some clues, which need to be provided\nseparately. To solve this problem, supervised attention methods tried to use additional loss functions to learn to\npredict gold attention on a manually labeled corpus (Jiang et al., 2015; Qiao et al., 2018; Gan et al., 2017). Research\non prompt learning may also borrow ideas from this literature.\nData Augmentation\nData augmentation is a technique that targets increasing the amount of data that can be used\nfor training by making modiﬁcations to existing data (Fadaee et al., 2017; Ratner et al., 2017). As recently observed\nby (Scao and Rush, 2021), adding prompts can achieve a similar accuracy improvement to the addition of 100s\nof data points on average across classiﬁcation tasks, which suggests that using prompts for a downstream task is\nsimilar to conducting data augmentation implicitly.\n10\nChallenges\nAlthough prompt-based learning has shown signiﬁcant potential among different tasks and scenarios, several\nchallenges remain, some of which we detail below.\n10.1\nPrompt Design\nTasks beyond Classiﬁcation and Generation\nMost existing works about prompt-based learning revolve around\neither text classiﬁcation or generation-based tasks. Applications to information extraction and text analysis tasks\nhave been discussed less, largely because the design of prompts is less straightforward. We expect that applying\nprompting methods to these tasks in the future it will require either reformulating these tasks so that they can\nbe solved using classiﬁcation or text generation-based methods, or performing effective answer engineering that\nexpresses structured outputs in an appropriate textual format.\nPrompting with Structured Information\nIn many NLP tasks, the inputs are imbued with some variety of\nstructure, such as tree, graph, table, or relational structures. How to best express these structures in prompt or\nanswer engineering is a major challenge. Existing works (Chen et al., 2021b) make a step by making prompts with\nadditional marks to encode lexical information, such as entity markings. Aghajanyan et al. (2021) present structured\nprompts based on hyper text markup language for more ﬁne-grained web text generation. However, moving beyond\nthis to more complicated varieties of structure is largely unexplored, and a potentially interesting research area.\n27\n",
    "book_id": "210713586v1",
    "book_title": "2107.13586v1",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 26
  },
  {
    "chunk_full": "10.2\nAnswer Engineering\nReally awesome movie!\nMovie Review (X1) \nIt’s very easy to use!\nProduct Review (X2)\n[Domain_name]:  This is [MASK].\nTemplate\nMovie: [X1] This is [MASK].\nPrompt 1\nProduct: [X2] This is [MASK].\nPrompt 2\nFigure 5: Multi-prompt learning for multi-task, multi-domain or multi-lingual learning. We use different colors to\ndifferentiate different components as follows. “\n” for input text, “\n” for template, “\n” for prompt.\nEntanglement of Template and Answer\nThe performance of a model will depend on both the templates being\nused and the answer being considered. How to simultaneously search or learn for the best combination of template\nand answer remains a challenging question. Current works typically select answers before select template (Gao et al.,\n2021; Shin et al., 2020), but Hambardzumyan et al. (2021) have demonstrated the initial potential of simultaneously\nlearning both.\n10.2\nAnswer Engineering\nMany-class and Long-answer Classiﬁcation Tasks\nFor classiﬁcation-based tasks, there are two main challenges\nfor answer engineering: (a) When there are too many classes, how to select an appropriate answer space becomes a\ndifﬁcult combinatorial optimization problem. (b) When using multi-token answers, how to best decode multiple\ntokens using LMs remains unknown, although some multi-token decoding methods have been proposed (Jiang et al.,\n2020a).\nMultiple Answers for Generation Tasks\nFor text generation tasks, qualiﬁed answers can be semantically\nequivalent but syntactically diverse. So far, almost all works use prompt learning for text generation relying solely\non a single answer, with only a few exceptions (Jiang et al., 2020c). How to better guide the learning process with\nmultiple references remains a largely open research problem.\n10.3\nSelection of Tuning Strategy\nAs discussed in §7, there are a fairly wide variety of methods for tuning parameters of prompts, LMs, or both.\nHowever, given the nascent stage of this research ﬁeld, we still lack a systematic understanding of the tradeoffs\nbetween these methods. The ﬁeld could beneﬁt from systematic explorations such as those performed in the pre-train\nand ﬁne-tune paradigm regarding the tradeoffs between these different strategies (Peters et al., 2019).\n10.4\nMultiple Prompt Learning\nPrompt Ensembling\nIn prompt ensembling methods, the space and time complexity increase as we consider\nmore prompts. How to distill the knowledge from different prompts remains underexplored. Schick and Sch¨utze\n(2020, 2021a,b) use an ensemble model to annotate a large dataset to distill the knowledge from multiple prompts.\nIn addition, how to select ensemble-worthy prompts is also under-explored. For text generation tasks, the study\nof prompt ensemble learning has not been performed so far, probably because ensemble learning in text generation\nitself is relatively complicated. To remedy this problem, some recently proposed neural ensembling methods such\nas Refactor (Liu et al., 2021c) could be considered as a method for prompt ensembling in text generation tasks.\nPrompt Composition and Decomposition\nBoth prompt composition and decomposition aim to break down the\ndifﬁculty of a complicated task input by introducing multiple sub-prompts. In practice, how to make a good choice\nbetween them is a crucial step. Empirically, for those token (Ma and Hovy, 2016) or span (Fu et al., 2021) prediction\ntasks (e.g., NER), prompt decomposition can be considered, while for those span relation prediction (Lee et al.,\n2017) tasks (e.g., entity coreference), prompts composition would be a better choice. In the future, the general idea\nof de-/composing can be explored in more scenarios.\nPrompt Augmentation\nExisting prompt augmentation methods are limited by the input length, i.e., feeding too\nmany demonstrations to input is infeasible. Therefore, how to select informative demonstrations, and order them in\nan appropriate is an interesting but challenging problem (Kumar and Talukdar, 2021).\nPrompt Sharing\nAll the above considerations refer to the application of prompt in a single task, domain or\nlanguage. We may also consider prompt sharing, where prompt learning is applied to multiple tasks, domains, or\nlanguages. Some key issues that may arise include how to design individual prompts for different tasks, and how to\nmodulate their interaction with each other. So far this ﬁeld has not been explored. Fig.5 illustrates a simple multiple\nprompt learning strategy for multiple tasks, where prompt templates are partially shared.\n28\n",
    "book_id": "210713586v1",
    "book_title": "2107.13586v1",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 27
  },
  {
    "chunk_full": "10.5\nSelection of Pre-trained Models\n10.5\nSelection of Pre-trained Models\nWith plenty of pre-trained LMs to select from (see §3), how to choose them to better leverage prompt-based learning\nis an interesting and difﬁcult problem. Although we have conceptually introduced (§3.4) how different paradigms\nof pre-trained models are selected for diverse NLP tasks, there are few to no systematic comparisons of the beneﬁts\nbrought by prompt-based learning for different pre-trained LMs.\n10.6\nTheoretical and Empirical Analysis of Prompting\nDespite their success in many scenarios, theoretical analysis and guarantees for prompt-based learning are scarce.\nWei et al. (2021) showed that soft-prompt tuning can relax the non-degeneracy assumptions (the generation\nprobability of each token is linearly independent) needed for downstream recovery (i.e. recover the ground-truth\nlabels of the downstream task.), making it easier to extract task-speciﬁc information. Saunshi et al. (2021) veriﬁed\nthat text classiﬁcation tasks can be reformulated as sentence completion tasks, thus making language modeling a\nmeaningful pre-training task. Scao and Rush (2021) empirically show that prompting is often worth 100s of data\npoints on average across classiﬁcation tasks.\n10.7\nTransferability of Prompts\nUnderstanding the extent to which prompts are speciﬁc to the model and improving the transferability of prompts are\nalso important topics. (Perez et al., 2021) show that prompts selected under tuned few-shot learning scenario (where\none has a larger validation set to choose prompts) generalize well across models of similar sizes while prompts\nselected under true few-shot learning scenario (where one only has a few training samples) do not generalize as\neffectively as the former setting among models with similar sizes. The transferability is poor when the model sizes\nare quite different in both scenarios.\n10.8\nCombination of Different Paradigms\nNotably, much of the success of the prompting paradigm is built on top of pre-trained models that were developed\nfor the pre-train and ﬁne-tune paradigm, such as BERT. However, are the pre-training methods that are effective\nfor the latter applicable as-is to the former, or can we entirely re-think our pre-training methods to further improve\naccuracy or ease of applicability to prompting-based learning? This is an important research question that has not\nbeen covered extensively by the literature.\n10.9\nCalibration of Prompting Methods\nCalibration (Gleser, 1996) refers to the ability of a model to make good probabilistic predictions. When using the\ngeneration probability of the pre-trained LMs (e.g., BART) to predict the answer, we need to be careful since the\nprobability distribution is typically not well calibrated. Jiang et al. (2020b) observed the probabilities of pre-trained\nmodels (e.g., BART, T5, GPT-2) on QA tasks are well calibrated. Zhao et al. (2021) identify three pitfalls (majority\nlabel bias, recency bias and common token bias) that lead the pre-trained LMs to be biased toward certain answers\nwhen provided answered prompts. For example, if the ﬁnal answered prompt has a positive label, then this will bias\nthe model towards predicting positive words. To overcome those pitfalls, Zhao et al. (2021) ﬁrst use context-free\ninput (e.g. the prompt would be “Input: Subpar acting. Sentiment: Negative\\n Input: Beautiful ﬁlm. Sentiment:\nPositive\\n Input: N/A. Sentiment:”) to get the initial probability distribution P0, then they use the real input (e.g.\nthe prompt would be “Input: Subpar acting. Sentiment: Negative\\n Input: Beautiful ﬁlm. Sentiment: Positive\\n\nInput: Amazing. Sentiment:”) to get the probability distribution P1. Finally, these two distributions can be used to\nget a calibrated generation probability distribution. However, this method has two drawbacks: (1) it comes with\nthe overhead of ﬁnding proper context-free input (e.g. whether to use “N/A” or “None”) and (2) the probability\ndistribution of the underlying pre-trained LM is still not calibrated.\nEven though we have a calibrated probability distribution, we also need to be careful when we assume a single\ngold answer for an input. This is because that all surface forms of a same object will compete for ﬁnite probability\nmass (Holtzman et al., 2021). For example, if we consider the gold answer to be “Whirlpool bath”, the generation\nprobability of it will typically be low since the word “Bathtub” shares the same meaning and it will take over a large\nprobability mass. To address this issue, we could either (i) perform answer engineering to construct a comprehensive\ngold answer set using paraphrasing methods (§5.2.2) or (ii) calibrate the probability of a word based on its prior\nlikelihood within the context (Holtzman et al., 2021).\n11\nMeta Analysis\nIn this section, we aim to give a quantitative birds-eye view of existing research on prompting methods by performing\na meta analysis over existing research works along different dimensions.\n29\n",
    "book_id": "210713586v1",
    "book_title": "2107.13586v1",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 28
  },
  {
    "chunk_full": "TABLE 12\nTimeline of prompt-based learning. The time for each paper is based on its ﬁrst arXiv version (if\nexists) or estimated submission time. A web-version can refer to NLPedia-Pretrain. Works in red consider natural\nlanguage understanding (NLU) tasks; works in blue consider natural language generation (NLG) tasks; works in\ngreen consider both NLU tasks and NLG tasks.\n2018.06.07\n•\nLMComm (Trinh and Le, 2018)\n2021.04.14\n•\nSoft (Qin and Eisner, 2021)\n2019.02.14\n•\nGPT-2 (Radford et al., 2019)\n2021.04.15\n•\nDINO (Schick and Sch¨utze, 2021)\n2019.04.14\n•\nWNLaMPro (Schick and Sch¨utze, 2020)\n2021.04.15\n•\nAdaPrompt (Chen et al., 2021b)\n2019.07.31\n•\nLMDiagnose (Ettinger, 2020)\n2021.04.16\n•\nPMIDC (Holtzman et al., 2021)\n2019.08.20\n•\nAdvTrigger (Wallace et al., 2019a)\n2021.04.18\n•\nPrompt-Tuning (Lester et al., 2021)\n2019.09.02\n•\nCohRank (Davison et al., 2019)\n2021.04.18\n•\nNatural-Instr (Mishra et al., 2021)\n2019.09.03\n•\nLAMA (Petroni et al., 2019)\n2021.04.18\n•\nOrderEntropy (Lu et al., 2021)\n2019.09.11\n•\nCTRL (Keskar et al., 2019)\n2021.04.18\n•\nFewshotSemp (Shin et al., 2021)\n2019.10.23\n•\nT5 (Raffel et al., 2020)\n2021.04.26\n•\nPanGu-α (Zeng et al., 2021)\n2019.11.08\n•\nNeg & Misprim (Kassner and Sch¨utze, 2020)\n2021.05.24\n•\nTrueFewshot (Perez et al., 2021)\n2019.11.28\n•\nLPAQA (Jiang et al., 2020c)\n2021.05.24\n•\nPTR (Han et al., 2021)\n2019.12.10\n•\nZSC (Puri and Catanzaro, 2019)\n2021.06.03\n•\nTemplateNER (Cui et al., 2021)\n2020.01.21\n•\nPET-TC (Schick and Sch¨utze, 2021a)\n2021.06.03\n•\nPERO (Kumar and Talukdar, 2021)\n2020.03.10\n•\nContxFP (Petroni et al., 2020)\n2021.06.16\n•\nPromptAnalysis (Wei et al., 2021)\n2020.05.02\n•\nUniﬁedQA (Khashabi et al., 2020)\n2021.06.20\n•\nCPM-2 (Zhang et al., 2021)\n2020.05.22\n•\nRAG (Lewis et al., 2020b)\n2021.06.21\n•\nBARTScore (Yuan et al., 2021b)\n2020.05.28\n•\nGPT-3 (Brown et al., 2020)\n2021.06.24\n•\nNullPrompt (Logan IV et al., 2021)\n2020.09.08\n•\nCommS2S(Yang et al., 2020)\n2021.06.25\n•\nFrozen (Tsimpoukelli et al., 2021)\n2020.09.15\n•\nPET-SGLUE (Schick and Sch¨utze, 2021b)\n2021.07.05\n•\nERNIE-B3 (Sun et al., 2021)\n2020.09.24\n•\nToxicityPrompts (Gehman et al., 2020)\n2021.07.07\n•\nCodex (Chen et al., 2021a)\n2020.10.07\n•\nWhyLM (Saunshi et al., 2021)\n2021.07.14\n•\nHTLM (Aghajanyan et al., 2021)\n2020.10.13\n•\nX-FACTR (Jiang et al., 2020a)\n2021.07.15\n•\nFLEX (Bragg et al., 2021)\n2020.10.26\n•\nPetal (Schick et al., 2020)\n2020.10.29\n•\nAutoPrompt (Shin et al., 2020)\n2020.12.08\n•\nCTRLsum (He et al., 2020a)\n2020.12.22\n•\nPET-Gen (Schick and Sch¨utze, 2020)\n2020.12.31\n•\nLM-BFF (Gao et al., 2021)\n2021.01.01\n•\nWARP (Hambardzumyan et al., 2021)\n2021.01.01\n•\nPreﬁx-Tuning (Li and Liang, 2021)\n2021.01.17\n•\nKATE (Liu et al., 2021a)\n2021.02.15\n•\nPromptProg (Reynolds and McDonell, 2021)\n2021.02.19\n•\nContxCalibrate (Zhao et al., 2021)\n2021.02.24\n•\nPADA (Ben-David et al., 2021)\n2021.02.27\n•\nSD (Schick et al., 2021)\n2021.03.09\n•\nBERTese (Haviv et al., 2021)\n2021.03.15\n•\nPrompt2Data (Scao and Rush, 2021)\n2021.03.18\n•\nP-Tuning (Liu et al., 2021b)\n2021.03.18\n•\nGLM (Du et al., 2021)\n2021.03.22\n•\nADAPET (Tam et al., 2021)\n2021.04.10\n•\nMeta (Zhong et al., 2021a)\n2021.04.12\n•\nOptiPrompt (Zhong et al., 2021b)\n30\n",
    "book_id": "210713586v1",
    "book_title": "2107.13586v1",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 29
  },
  {
    "chunk_full": "11.1\nTimeline\n11.1\nTimeline\nWe ﬁrst summarize a number of existing research papers in a chronological order with in the form of a timeline,\nwhich hopefully, help researchers who are new to this topic understand the evolution of the ﬁeld.\n11.2\nTrend Analysis\nWe also calculate the number of prompt-based papers with respect to different dimensions.\nYear\nWith the emergence of different kinds of pre-trained LMs, prompt-based learning has become a more and\nmore active research ﬁeld, as can be seen in Fig. 6-(a). We can see a huge surge in 2021, which is perhaps due to\nthe prevalence of GPT-3 (Brown et al., 2020), which greatly increased the popularity of prompting in the few-shot\nmulti-task setting.\n2018 2019 2020 2021\n5\n10\n15\n20\n25\n30\nNumber\n(a) Year.\nTC\nFP GCG QA\nCR SUM\nO\n5\n10\n15\n20\n25\n30\nNumber\n(b) Task.\nTemplate\nAnswer\n2\n4\n6\n8\n10\n12\n14\nNumber\n2019\n2020\n2021\n(c) Automatic Search.\nDiscrete Continous\n2\n4\n6\n8\n10\nNumber\n2019\n2020\n2021\n(d) Search Space.\nFigure 6: Meta-analyses over different dimensions. The statistics are based on the works in Tab. 7 and Tab. 8. In\n(d), we use the following abbreviations. TC: text classiﬁcation, FP: factual probing, GCG: general conditional\ngeneration, QA: question answering, CR: commonsense reasoning, SUM: summarization, O: others.\nTasks\nWe plot the number of works that investigate various tasks in Fig. 6-(b). For a task that has fewer than 5\nrelevant works, we group it into “Others”. As the bar chart indicates, most tasks regarding prompt-based learning\nrevolve around text classiﬁcation and factual probing. We conjecture that this is because that for these tasks,\nboth template engineering and answer engineering are relatively easy to conduct, and experiments are relatively\ncomputationally inexpensive.\nPrompt vs. Answer Search\nAs noted in previous sections, both prompt and answer search are important tools to\ntake advantage of pre-trained language models for many tasks. Current research mainly focuses on template search\ninstead of answer search, as shown in Fig. 6-(c).\nLikely reasons are: (1) For conditional generation tasks (e.g. summarization or translation), the gold references\ncan be directly used as answer. Although there are many sequences that may share the same semantics, how\nto effectively conduct multi-reference learning in conditional text generation problems is non-trivial. (2) For\nclassiﬁcation tasks, most of the time, label words are relative easy to select using domain knowledge.\nDiscrete Search vs. Continuous Search\nSince there are only a few works focus on automatic answer search, we\nanalyze the automatic template search. As time goes by, there has been a shift from discrete search to continuous\nsearch for prompt engineering, as shown in Fig. 6-(d). Likely reasons are: (1) discrete search is harder to optimize\ncompared to continuous search, (2) soft prompts have greater representation ability.\n12\nConclusion\nIn this paper, we have summarized and analyzed several paradigms in the development of statistical natural language\nprocessing techniques, and have argued that prompt-based learning is a promising new paradigm that may represent\nanother major change in the way we look at NLP. First and foremost, we hope this survey will help researchers more\neffectively and comprehensively understand the paradigm of prompt-based learning, and grasp its core challenges\nso that more scientiﬁcally meaningful advances can be made in this ﬁeld. In addition, looking all the way back to\nthe summary of the four paradigms of NLP research presented in §1, we hope to highlight the commonalities and\ndifferences between them, making research on any of these paradigms more full-ﬂedged, and potentially providing\na catalyst to inspire work towards the next paradigm shift as well.\nAcknowledgements\nWe would like to thank Chunting Zhou for her constructive comments on this work.\n31\n",
    "book_id": "210713586v1",
    "book_title": "2107.13586v1",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 30
  },
  {
    "chunk_full": "References\nReferences\n[1] Armen Aghajanyan, Dmytro Okhonko, Mike Lewis, Mandar Joshi, Hu Xu, Gargi Ghosh, and Luke Zettlemoyer.\n2021. Htlm: Hyper-text pre-training and prompting of language models. arXiv preprint arXiv:2107.06955.\n[2] Zeyuan Allen-Zhu and Yuanzhi Li. 2020. Towards understanding ensemble, knowledge distillation and self-\ndistillation in deep learning. CoRR, abs/2012.09816.\n[3] Devansh Arpit, Stanislaw Jastrzebski, Nicolas Ballas, David Krueger, Emmanuel Bengio, Maxinder S Kanwal,\nTegan Maharaj, Asja Fischer, Aaron Courville, Yoshua Bengio, et al. 2017. A closer look at memorization in\ndeep networks. In International Conference on Machine Learning, pages 233–242. PMLR.\n[4] Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2014. Neural machine translation by jointly learning\nto align and translate. arXiv preprint arXiv:1409.0473.\n[5] Hangbo Bao, Li Dong, and Furu Wei. 2021. Beit: Bert pre-training of image transformers. arXiv preprint\narXiv:2106.08254.\n[6] Hangbo Bao, Li Dong, Furu Wei, Wenhui Wang, Nan Yang, Xiaodong Liu, Yu Wang, Jianfeng Gao, Songhao\nPiao, Ming Zhou, and Hsiao-Wuen Hon. 2020. Unilmv2: Pseudo-masked language models for uniﬁed language\nmodel pre-training. In Proceedings of the 37th International Conference on Machine Learning, ICML 2020,\n13-18 July 2020, Virtual Event, volume 119 of Proceedings of Machine Learning Research, pages 642–652.\nPMLR.\n[7] Iz Beltagy, Kyle Lo, and Arman Cohan. 2019. SciBERT: A pretrained language model for scientiﬁc text.\nIn Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th\nInternational Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 3615–3620, Hong\nKong, China. Association for Computational Linguistics.\n[8] Eyal Ben-David, Nadav Oved, and Roi Reichart. 2021. Pada: A prompt-based autoregressive approach for\nadaptation to unseen domains.\n[9] Yoshua Bengio, Aaron Courville, and Pascal Vincent. 2013. Representation learning: A review and new\nperspectives. IEEE transactions on pattern analysis and machine intelligence, 35(8):1798–1828.\n[10] Yoshua Bengio, R´ejean Ducharme, Pascal Vincent, and Christian Janvin. 2003. A neural probabilistic language\nmodel. The journal of machine learning research, 3:1137–1155.\n[11] Jonathan Berant and Percy Liang. 2014. Semantic parsing via paraphrasing. In Proceedings of the 52nd Annual\nMeeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1415–1425, Baltimore,\nMaryland. Association for Computational Linguistics.\n[12] Luca Bertinetto, Jo˜ao F Henriques, Jack Valmadre, Philip Torr, and Andrea Vedaldi. 2016. Learning feed-\nforward one-shot learners. In Advances in neural information processing systems, pages 523–531.\n[13] Sid Black, Leo Gao, Phil Wang, Connor Leahy, and Stella Biderman. 2021. GPT-Neo: Large scale autoregressive\nlanguage modeling with mesh-tensorﬂow.\n[14] Samuel R. Bowman, Gabor Angeli, Christopher Potts, and Christopher D. Manning. 2015. A large annotated\ncorpus for learning natural language inference. In Proceedings of the 2015 Conference on Empirical Methods in\nNatural Language Processing, pages 632–642, Lisbon, Portugal. Association for Computational Linguistics.\n[15] Jonathan Bragg, Arman Cohan, Kyle Lo, and Iz Beltagy. 2021. FLEX: unifying evaluation for few-shot NLP.\nCoRR, abs/2107.07170.\n[16] Tom B Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners.\narXiv preprint arXiv:2005.14165.\n[17] Christian Buck, Jannis Bulian, Massimiliano Ciaramita, Wojciech Gajewski, Andrea Gesmundo, Neil Houlsby,\nand Wei Wang. 2017. Ask the right questions: Active question reformulation with reinforcement learning. arXiv\npreprint arXiv:1705.07830.\n[18] Ziqiang Cao, Wenjie Li, Sujian Li, and Furu Wei. 2018. Retrieve, rerank and rewrite: Soft template based neural\nsummarization. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics\n(Volume 1: Long Papers), pages 152–161, Melbourne, Australia. Association for Computational Linguistics.\n[19] Duo Chai, Wei Wu, Qinghong Han, Fei Wu, and Jiwei Li. 2020. Description based text classiﬁcation with\nreinforcement learning. In International Conference on Machine Learning, pages 1371–1382. PMLR.\n32\n",
    "book_id": "210713586v1",
    "book_title": "2107.13586v1",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 31
  },
  {
    "chunk_full": "References\n[20] Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde, Jared Kaplan, Harri Edwards, Yura\nBurda, Nicholas Joseph, Greg Brockman, et al. 2021a. Evaluating large language models trained on code. arXiv\npreprint arXiv:2107.03374.\n[21] Xiang Chen, Xin Xie, Ningyu Zhang, Jiahuan Yan, Shumin Deng, Chuanqi Tan, Fei Huang, Luo Si, and Huajun\nChen. 2021b. Adaprompt: Adaptive prompt-based ﬁnetuning for relation extraction. CoRR, abs/2104.07650.\n[22] Zewen Chi, Li Dong, Shuming Ma, Shaohan Huang, Xian-Ling Mao, Heyan Huang, and Furu Wei. 2021a. mt6:\nMultilingual pretrained text-to-text transformer with translation pairs. CoRR, abs/2104.08692.\n[23] Zewen Chi, Shaohan Huang, Li Dong, Shuming Ma, Saksham Singhal, Payal Bajaj, Xia Song, and Furu Wei.\n2021b. XLM-E: cross-lingual language model pre-training via ELECTRA. CoRR, abs/2106.16138.\n[24] Chenhui Chu, Raj Dabre, and Sadao Kurohashi. 2017. An empirical comparison of domain adaptation methods\nfor neural machine translation. In Proceedings of the 55th Annual Meeting of the Association for Computational\nLinguistics (Volume 2: Short Papers), pages 385–391, Vancouver, Canada. Association for Computational\nLinguistics.\n[25] J. Chung, C¸ aglar G¨ulc¸ehre, Kyunghyun Cho, and Yoshua Bengio. 2014. Empirical evaluation of gated recurrent\nneural networks on sequence modeling. ArXiv, abs/1412.3555.\n[26] Kevin Clark, Minh-Thang Luong, Quoc V. Le, and Christopher D. Manning. 2020. ELECTRA: pre-training text\nencoders as discriminators rather than generators. In 8th International Conference on Learning Representations,\nICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020. OpenReview.net.\n[27] Ronan Collobert, J. Weston, L. Bottou, Michael Karlen, K. Kavukcuoglu, and P. Kuksa. 2011. Natural language\nprocessing (almost) from scratch. J. Mach. Learn. Res., 12:2493–2537.\n[28] Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco\nGuzm´an, Edouard Grave, Myle Ott, Luke Zettlemoyer, and Veselin Stoyanov. 2020. Unsupervised cross-lingual\nrepresentation learning at scale. In Proceedings of the 58th Annual Meeting of the Association for Computational\nLinguistics, ACL 2020, Online, July 5-10, 2020, pages 8440–8451. Association for Computational Linguistics.\n[29] Leyang Cui, Yu Wu, Jian Liu, Sen Yang, and Yue Zhang. 2021. Template-based named entity recognition using\nbart.\n[30] Hal Daum´e III and Eric Brill. 2004. Web search intent induction via automatic query reformulation. In\nProceedings of HLT-NAACL 2004: Short Papers, pages 49–52, Boston, Massachusetts, USA. Association for\nComputational Linguistics.\n[31] Joe Davison, Joshua Feldman, and Alexander M. Rush. 2019. Commonsense knowledge mining from pretrained\nmodels. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the\n9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019, Hong Kong, China,\nNovember 3-7, 2019, pages 1173–1178. Association for Computational Linguistics.\n[32] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of deep\nbidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North\nAmerican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1\n(Long and Short Papers), pages 4171–4186, Minneapolis, Minnesota. Association for Computational Linguistics.\n[33] Sumanth Doddapaneni, Gowtham Ramesh, Anoop Kunchukuttan, Pratyush Kumar, and Mitesh M Khapra.\n2021. A primer on pretrained multilingual language models. arXiv preprint arXiv:2107.00676.\n[34] Jesse Dodge, Gabriel Ilharco, Roy Schwartz, Ali Farhadi, Hannaneh Hajishirzi, and Noah Smith. 2020. Fine-\ntuning pretrained language models: Weight initializations, data orders, and early stopping. arXiv preprint\narXiv:2002.06305.\n[35] Li Dong, Nan Yang, Wenhui Wang, Furu Wei, Xiaodong Liu, Yu Wang, Jianfeng Gao, Ming Zhou, and\nHsiao-Wuen Hon. 2019. Uniﬁed language model pre-training for natural language understanding and generation.\nIn Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing\nSystems 2019, NeurIPS 2019, December 8-14, 2019, Vancouver, BC, Canada, pages 13042–13054.\n[36] Zi-Yi Dou, Pengfei Liu, Hiroaki Hayashi, Zhengbao Jiang, and Graham Neubig. 2021. GSum: A general\nframework for guided neural abstractive summarization. In Proceedings of the 2021 Conference of the North\nAmerican Chapter of the Association for Computational Linguistics: Human Language Technologies, pages\n4830–4842, Online. Association for Computational Linguistics.\n[37] Zhengxiao Du, Yujie Qian, Xiao Liu, Ming Ding, Jiezhong Qiu, Zhilin Yang, and Jie Tang. 2021. All nlp tasks\nare generation tasks: A general pretraining framework.\n33\n",
    "book_id": "210713586v1",
    "book_title": "2107.13586v1",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 32
  },
  {
    "chunk_full": "References\n[38] Kevin Duh, Katsuhito Sudoh, Xianchao Wu, Hajime Tsukada, and Masaaki Nagata. 2011. Generalized\nminimum bayes risk system combination. In Proceedings of 5th International Joint Conference on Natural\nLanguage Processing, pages 1356–1360.\n[39] Allyson Ettinger. 2020. What BERT is not: Lessons from a new suite of psycholinguistic diagnostics for\nlanguage models. Trans. Assoc. Comput. Linguistics, 8:34–48.\n[40] Marzieh Fadaee, Arianna Bisazza, and Christof Monz. 2017. Data augmentation for low-resource neural\nmachine translation. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics\n(Volume 2: Short Papers), pages 567–573, Vancouver, Canada. Association for Computational Linguistics.\n[41] Angela Fan, David Grangier, and Michael Auli. 2018. Controllable abstractive summarization. In Proceedings\nof the 2nd Workshop on Neural Machine Translation and Generation, pages 45–54, Melbourne, Australia.\nAssociation for Computational Linguistics.\n[42] Chelsea Finn, Pieter Abbeel, and Sergey Levine. 2017a. Model-agnostic meta-learning for fast adaptation of\ndeep networks. In Proceedings of the 34th International Conference on Machine Learning, ICML 2017, Sydney,\nNSW, Australia, 6-11 August 2017, volume 70 of Proceedings of Machine Learning Research, pages 1126–1135.\nPMLR.\n[43] Chelsea Finn, Pieter Abbeel, and Sergey Levine. 2017b. Model-agnostic meta-learning for fast adaptation of\ndeep networks. In International Conference on Machine Learning, pages 1126–1135. PMLR.\n[44] Jinlan Fu, Xuanjing Huang, and Pengfei Liu. 2021. Spanner: Named entity re-/recognition as span prediction.\narXiv preprint arXiv:2106.00641.\n[45] Chuang Gan, Yandong Li, Haoxiang Li, Chen Sun, and Boqing Gong. 2017. Vqs: Linking segmentations\nto questions and answers for supervised attention in vqa and question-focused semantic segmentation. In\nProceedings of the IEEE international conference on computer vision, pages 1811–1820.\n[46] Tianyu Gao, Adam Fisch, and Danqi Chen. 2021. Making pre-trained language models better few-shot learners.\nIn Association for Computational Linguistics (ACL).\n[47] Samuel Gehman, Suchin Gururangan, Maarten Sap, Yejin Choi, and Noah A Smith. 2020. Realtoxicityprompts:\nEvaluating neural toxic degeneration in language models. In Proceedings of the 2020 Conference on Empirical\nMethods in Natural Language Processing: Findings, pages 3356–3369.\n[48] Leon Jay Gleser. 1996. Measurement, regression, and calibration.\n[49] Joshua T Goodman. 2001. A bit of progress in language modeling. Computer Speech & Language, 15(4):403–\n434.\n[50] David Grangier and Michael Auli. 2018. QuickEdit: Editing text & translations by crossing words out. In\nProceedings of the 2018 Conference of the North American Chapter of the Association for Computational\nLinguistics: Human Language Technologies, Volume 1 (Long Papers), pages 272–282, New Orleans, Louisiana.\nAssociation for Computational Linguistics.\n[51] Alex Graves, Abdel-rahman Mohamed, and Geoffrey Hinton. 2013. Speech recognition with deep recurrent\nneural networks. In 2013 IEEE International Conference on Acoustics, Speech and Signal Processing, pages\n6645–6649.\n[52] Kelvin Guu, Tatsunori B. Hashimoto, Yonatan Oren, and Percy Liang. 2018. Generating sentences by editing\nprototypes. Transactions of the Association for Computational Linguistics, 6:437–450.\n[53] Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, and Ming-Wei Chang. 2020. Realm: Retrieval-\naugmented language model pre-training. arXiv preprint arXiv:2002.08909.\n[54] Isabelle Guyon, Jason Weston, Stephen Barnhill, and Vladimir Vapnik. 2002. Gene selection for cancer\nclassiﬁcation using support vector machines. Machine learning, 46(1):389–422.\n[55] Karen Hambardzumyan, Hrant Khachatrian, and Jonathan May. 2021. Warp: Word-level adversarial reprogram-\nming. ArXiv, abs/2101.00121.\n[56] Xu Han, Weilin Zhao, Ning Ding, Zhiyuan Liu, and Maosong Sun. 2021. Ptr: Prompt tuning with rules for text\nclassiﬁcation.\n[57] Ahmed Hassan. 2013. Identifying web search query reformulation using concept based matching. In Proceed-\nings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1000–1010, Seattle,\nWashington, USA. Association for Computational Linguistics.\n34\n",
    "book_id": "210713586v1",
    "book_title": "2107.13586v1",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 33
  },
  {
    "chunk_full": "References\n[58] Adi Haviv, Jonathan Berant, and Amir Globerson. 2021. BERTese: Learning to speak to BERT. In Proceedings\nof the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume,\npages 3618–3623, Online. Association for Computational Linguistics.\n[59] Junxian He, Wojciech Kryscinski, Bryan McCann, Nazneen Fatema Rajani, and Caiming Xiong. 2020a.\nCtrlsum: Towards generic controllable text summarization. CoRR, abs/2012.04281.\n[60] Pengcheng He, Xiaodong Liu, Jianfeng Gao, and Weizhu Chen. 2020b. Deberta: Decoding-enhanced bert with\ndisentangled attention. arXiv preprint arXiv:2006.03654.\n[61] Sepp Hochreiter and J¨urgen Schmidhuber. 1997. Long short-term memory. Neural computation, 9(8):1735–\n1780.\n[62] Ari Holtzman, Peter West, Vered Schwartz, Yejin Choi, and Luke Zettlemoyer. 2021. Surface form competition:\nWhy the highest probability answer isn’t always right.\n[63] Jeremy Howard and Sebastian Ruder. 2018. Universal language model ﬁne-tuning for text classiﬁcation. In\nProceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long\nPapers), pages 328–339.\n[64] Lifu Huang, Ronan Le Bras, Chandra Bhagavatula, and Yejin Choi. 2019. Cosmos QA: Machine reading\ncomprehension with contextual commonsense reasoning. In Proceedings of the 2019 Conference on Empirical\nMethods in Natural Language Processing and the 9th International Joint Conference on Natural Language\nProcessing (EMNLP-IJCNLP), pages 2391–2401, Hong Kong, China. Association for Computational Linguistics.\n[65] Ming Jiang, Shengsheng Huang, Juanyong Duan, and Qi Zhao. 2015. Salicon: Saliency in context. In\nProceedings of the IEEE conference on computer vision and pattern recognition, pages 1072–1080.\n[66] Zhengbao Jiang, Antonios Anastasopoulos, Jun Araki, Haibo Ding, and Graham Neubig. 2020a. X-FACTR:\nMultilingual factual knowledge retrieval from pretrained language models. In Proceedings of the 2020 Conference\non Empirical Methods in Natural Language Processing (EMNLP), pages 5943–5959, Online. Association for\nComputational Linguistics.\n[67] Zhengbao Jiang, Jun Araki, Haibo Ding, and Graham Neubig. 2020b. How can we know when language models\nknow? CoRR, abs/2012.00955.\n[68] Zhengbao Jiang, Frank F. Xu, Jun Araki, and Graham Neubig. 2020c. How can we know what language models\nknow? Transactions of the Association for Computational Linguistics, 8:423–438.\n[69] Xiaoqi Jiao, Yichun Yin, Lifeng Shang, Xin Jiang, Xiao Chen, Linlin Li, Fang Wang, and Qun Liu. 2020.\nTinybert: Distilling BERT for natural language understanding. In Proceedings of the 2020 Conference on\nEmpirical Methods in Natural Language Processing: Findings, EMNLP 2020, Online Event, 16-20 November\n2020, volume EMNLP 2020 of Findings of ACL, pages 4163–4174. Association for Computational Linguistics.\n[70] Mandar Joshi, Danqi Chen, Yinhan Liu, Daniel S. Weld, Luke Zettlemoyer, and Omer Levy. 2020. SpanBERT:\nImproving pre-training by representing and predicting spans. Transactions of the Association for Computational\nLinguistics, 8:64–77.\n[71] Daniel Jurafsky and James H Martin. 2021. Speech and language processing: An introduction to natural\nlanguage processing, computational linguistics, and speech recognition.\n[72] Łukasz Kaiser, Oﬁr Nachum, Aurko Roy, and Samy Bengio. 2017. Learning to remember rare events. arXiv\npreprint arXiv:1703.03129.\n[73] Nal Kalchbrenner, Edward Grefenstette, and Phil Blunsom. 2014. A convolutional neural network for modelling\nsentences. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume\n1: Long Papers), pages 655–665, Baltimore, Maryland. Association for Computational Linguistics.\n[74] Nora Kassner and Hinrich Sch¨utze. 2020. Negated and misprimed probes for pretrained language models:\nBirds can talk, but cannot ﬂy. In Proceedings of the 58th Annual Meeting of the Association for Computational\nLinguistics, ACL 2020, Online, July 5-10, 2020, pages 7811–7818. Association for Computational Linguistics.\n[75] Nitish Shirish Keskar, Bryan McCann, Lav R. Varshney, Caiming Xiong, and Richard Socher. 2019. CTRL: A\nconditional transformer language model for controllable generation. CoRR, abs/1909.05858.\n[76] Daniel Khashabi, Sewon Min, Tushar Khot, Ashish Sabharwal, Oyvind Tafjord, Peter Clark, and Hannaneh\nHajishirzi. 2020. UNIFIEDQA: Crossing format boundaries with a single QA system. In Findings of the Associa-\ntion for Computational Linguistics: EMNLP 2020, pages 1896–1907, Online. Association for Computational\nLinguistics.\n35\n",
    "book_id": "210713586v1",
    "book_title": "2107.13586v1",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 34
  },
  {
    "chunk_full": "References\n[77] Yuta Kikuchi, Graham Neubig, Ryohei Sasano, Hiroya Takamura, and Manabu Okumura. 2016. Controlling\noutput length in neural encoder-decoders. In Proceedings of the 2016 Conference on Empirical Methods in\nNatural Language Processing, pages 1328–1338, Austin, Texas. Association for Computational Linguistics.\n[78] Yoon Kim. 2014. Convolutional neural networks for sentence classiﬁcation. In EMNLP.\n[79] Tom´aˇs Koˇcisk´y, Jonathan Schwarz, Phil Blunsom, Chris Dyer, Karl Moritz Hermann, G´abor Melis, and Edward\nGrefenstette. 2018. The NarrativeQA reading comprehension challenge. Transactions of the Association for\nComputational Linguistics, 6:317–328.\n[80] Philipp Koehn. 2009. Statistical machine translation. Cambridge University Press.\n[81] Sotiris B Kotsiantis, I Zaharakis, P Pintelas, et al. 2007. Supervised machine learning: A review of classiﬁcation\ntechniques. Emerging artiﬁcial intelligence applications in computer engineering, 160(1):3–24.\n[82] Ankit Kumar, Ozan Irsoy, Peter Ondruska, Mohit Iyyer, James Bradbury, Ishaan Gulrajani, Victor Zhong,\nRomain Paulus, and Richard Socher. 2016. Ask me anything: Dynamic memory networks for natural language\nprocessing. In International conference on machine learning, pages 1378–1387. PMLR.\n[83] Sawan Kumar and Partha Talukdar. 2021. Reordering examples helps during priming-based few-shot learning.\n[84] J. Lafferty, A. McCallum, and Fernando Pereira. 2001. Conditional random ﬁelds: Probabilistic models for\nsegmenting and labeling sequence data. In ICML.\n[85] Guokun Lai, Qizhe Xie, Hanxiao Liu, Yiming Yang, and Eduard Hovy. 2017. RACE: Large-scale ReAding com-\nprehension dataset from examinations. In Proceedings of the 2017 Conference on Empirical Methods in Natural\nLanguage Processing, pages 785–794, Copenhagen, Denmark. Association for Computational Linguistics.\n[86] Guillaume Lample and Alexis Conneau. 2019. Cross-lingual language model pretraining. arXiv preprint\narXiv:1901.07291.\n[87] Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, and Radu Soricut. 2020.\nALBERT: A lite BERT for self-supervised learning of language representations. In 8th International Conference\non Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020. OpenReview.net.\n[88] Teven Le Scao and Alexander Rush. 2021. How many data points is a prompt worth? In Proceedings of the\n2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human\nLanguage Technologies, pages 2627–2636, Online. Association for Computational Linguistics.\n[89] Jinhyuk Lee, Wonjin Yoon, Sungdong Kim, Donghyeon Kim, Sunkyu Kim, Chan Ho So, and Jaewoo Kang. 2019.\nBioBERT: a pre-trained biomedical language representation model for biomedical text mining. Bioinformatics.\n[90] Kenton Lee, Luheng He, Mike Lewis, and Luke Zettlemoyer. 2017. End-to-end neural coreference resolution.\nIn Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 188–197,\nCopenhagen, Denmark. Association for Computational Linguistics.\n[91] Brian Lester, Rami Al-Rfou, and Noah Constant. 2021. The power of scale for parameter-efﬁcient prompt\ntuning.\n[92] Hector Levesque, Ernest Davis, and Leora Morgenstern. 2012. The winograd schema challenge. In Thirteenth\nInternational Conference on the Principles of Knowledge Representation and Reasoning.\n[93] Hector J. Levesque. 2011. The winograd schema challenge. In Logical Formalizations of Commonsense\nReasoning, Papers from the 2011 AAAI Spring Symposium, Technical Report SS-11-06, Stanford, California,\nUSA, March 21-23, 2011. AAAI.\n[94] Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin\nStoyanov, and Luke Zettlemoyer. 2020a. BART: Denoising sequence-to-sequence pre-training for natural\nlanguage generation, translation, and comprehension.\nIn Proceedings of the 58th Annual Meeting of the\nAssociation for Computational Linguistics, pages 7871–7880, Online. Association for Computational Linguistics.\n[95] Patrick S. H. Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal,\nHeinrich K¨uttler, Mike Lewis, Wen-tau Yih, Tim Rockt¨aschel, Sebastian Riedel, and Douwe Kiela. 2020b.\nRetrieval-augmented generation for knowledge-intensive NLP tasks. In Advances in Neural Information Process-\ning Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December\n6-12, 2020, virtual.\n[96] Xiang Lisa Li and Percy Liang. 2021. Preﬁx-tuning: Optimizing continuous prompts for generation. arXiv\npreprint arXiv:2101.00190.\n36\n",
    "book_id": "210713586v1",
    "book_title": "2107.13586v1",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 35
  },
  {
    "chunk_full": "References\n[97] Xiaoya Li, Jingrong Feng, Yuxian Meng, Qinghong Han, Fei Wu, and Jiwei Li. 2020. A uniﬁed MRC framework\nfor named entity recognition. In Proceedings of the 58th Annual Meeting of the Association for Computational\nLinguistics, pages 5849–5859, Online. Association for Computational Linguistics.\n[98] Bill Yuchen Lin, Wangchunshu Zhou, Ming Shen, Pei Zhou, Chandra Bhagavatula, Yejin Choi, and Xiang\nRen. 2020. CommonGen: A constrained text generation challenge for generative commonsense reasoning. In\nFindings of the Association for Computational Linguistics: EMNLP 2020, pages 1823–1840, Online. Association\nfor Computational Linguistics.\n[99] Chenxi Liu, Junhua Mao, Fei Sha, and Alan Yuille. 2017a. Attention correctness in neural image captioning. In\nProceedings of the AAAI Conference on Artiﬁcial Intelligence.\n[100] Jiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence Carin, and Weizhu Chen. 2021a. What\nmakes good in-context examples for gpt-3?\n[101] Lemao Liu, Masao Utiyama, Andrew Finch, and Eiichiro Sumita. 2016. Neural machine translation with\nsupervised attention. In Proceedings of COLING 2016, the 26th International Conference on Computational\nLinguistics: Technical Papers, pages 3093–3102, Osaka, Japan. The COLING 2016 Organizing Committee.\n[102] Shulin Liu, Yubo Chen, Kang Liu, and Jun Zhao. 2017b. Exploiting argument information to improve event\ndetection via supervised attention mechanisms. In Proceedings of the 55th Annual Meeting of the Association for\nComputational Linguistics (Volume 1: Long Papers), pages 1789–1798.\n[103] Xiao Liu, Yanan Zheng, Zhengxiao Du, Ming Ding, Yujie Qian, Zhilin Yang, and Jie Tang. 2021b. GPT\nunderstands, too. CoRR, abs/2103.10385.\n[104] Yinhan Liu, Jiatao Gu, Naman Goyal, Xian Li, Sergey Edunov, Marjan Ghazvininejad, Mike Lewis, and Luke\nZettlemoyer. 2020a. Multilingual denoising pre-training for neural machine translation. Trans. Assoc. Comput.\nLinguistics, 8:726–742.\n[105] Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, M. Lewis, Luke\nZettlemoyer, and Veselin Stoyanov. 2019. Roberta: A robustly optimized bert pretraining approach. ArXiv,\nabs/1907.11692.\n[106] Yixin Liu, Zi-Yi Dou, and Pengfei Liu. 2021c. RefSum: Refactoring neural summarization. In Proceedings of\nthe 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human\nLanguage Technologies, pages 1437–1448, Online. Association for Computational Linguistics.\n[107] Yixin Liu and Pengfei Liu. 2021. Simcls: A simple framework for contrastive learning of abstractive\nsummarization. arXiv preprint arXiv:2106.01890.\n[108] Zhuang Liu, Degen Huang, Kaiyu Huang, Zhuang Li, and Jun Zhao. 2020b. Finbert: A pre-trained ﬁnancial\nlanguage representation model for ﬁnancial text mining. In Proceedings of the Twenty-Ninth International Joint\nConference on Artiﬁcial Intelligence, IJCAI 2020, pages 4513–4519. ijcai.org.\n[109] Robert L. Logan IV, Ivana Balaˇzevi´c, Eric Wallace, Fabio Petroni, Sameer Singh, and Sebastian Riedel. 2021.\nCutting down on prompts and parameters: Simple few-shot learning with language models.\n[110] Jiasen Lu, Dhruv Batra, Devi Parikh, and Stefan Lee. 2019. Vilbert: Pretraining task-agnostic visiolinguistic\nrepresentations for vision-and-language tasks. In Advances in Neural Information Processing Systems 32: Annual\nConference on Neural Information Processing Systems 2019, NeurIPS 2019, December 8-14, 2019, Vancouver,\nBC, Canada, pages 13–23.\n[111] Yao Lu, Max Bartolo, A. Moore, S. Riedel, and Pontus Stenetorp. 2021. Fantastically ordered prompts and\nwhere to ﬁnd them: Overcoming few-shot prompt order sensitivity. ArXiv, abs/2104.08786.\n[112] Xuezhe Ma and Eduard Hovy. 2016. End-to-end sequence labeling via bi-directional LSTM-CNNs-CRF.\nIn Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long\nPapers), pages 1064–1074, Berlin, Germany. Association for Computational Linguistics.\n[113] Andre˘ı Andreevich Markov. 2006. An example of statistical investigation of the text eugene onegin concerning\nthe connection of samples in chains. Science in Context, 19(4):591–600.\n[114] Yvette Mathieu and Paul Sabatier. 1986. INTERFACILE: Linguistic coverage and query reformulation. In\nColing 1986 Volume 1: The 11th International Conference on Computational Linguistics.\n[115] Bryan McCann, Nitish Shirish Keskar, Caiming Xiong, and Richard Socher. 2018. The natural language\ndecathlon: Multitask learning as question answering. arXiv preprint arXiv:1806.08730.\n37\n",
    "book_id": "210713586v1",
    "book_title": "2107.13586v1",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 36
  },
  {
    "chunk_full": "References\n[116] Michael McCloskey and Neal J Cohen. 1989. Catastrophic interference in connectionist networks: The\nsequential learning problem. In Psychology of learning and motivation, volume 24, pages 109–165. Elsevier.\n[117] Tomas Mikolov, Kai Chen, G. Corrado, and J. Dean. 2013a. Efﬁcient estimation of word representations in\nvector space. In ICLR.\n[118] Tom´aˇs Mikolov, Martin Karaﬁ´at, Luk´aˇs Burget, Jan ˇCernock`y, and Sanjeev Khudanpur. 2010. Recurrent\nneural network based language model. In Eleventh annual conference of the international speech communication\nassociation.\n[119] Tomas Mikolov, Ilya Sutskever, Kai Chen, G. Corrado, and J. Dean. 2013b. Distributed representations of\nwords and phrases and their compositionality. In NIPS.\n[120] Swaroop Mishra, Daniel Khashabi, Chitta Baral, and Hannaneh Hajishirzi. 2021. Natural instructions:\nBenchmarking generalization to new tasks from natural language instructions. CoRR, abs/2104.08773.\n[121] Aakanksha Naik, Abhilasha Ravichander, Carolyn Rose, and Eduard Hovy. 2019. Exploring numeracy in\nword embeddings. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,\npages 3374–3380, Florence, Italy. Association for Computational Linguistics.\n[122] Timothy Niven and Hung-Yu Kao. 2019. Probing neural network comprehension of natural language argu-\nments. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages\n4658–4664, Florence, Italy. Association for Computational Linguistics.\n[123] Rodrigo Nogueira and Kyunghyun Cho. 2017. Task-oriented query reformulation with reinforcement learning.\narXiv preprint arXiv:1704.04572.\n[124] Rodrigo Frassetto Nogueira, Jannis Bulian, and Massimiliano Ciaramita. 2019. Multi-agent query reformu-\nlation: Challenges and the role of diversity. ICLR Workshop on Deep Reinforcement Learning for Structured\nPrediction.\n[125] Franz Josef Och, Daniel Gildea, Sanjeev Khudanpur, Anoop Sarkar, Kenji Yamada, Alex Fraser, Shankar\nKumar, Libin Shen, David Smith, Katherine Eng, Viren Jain, Zhen Jin, and Dragomir Radev. 2004. A smorgasbord\nof features for statistical machine translation. In Proceedings of the Human Language Technology Conference\nof the North American Chapter of the Association for Computational Linguistics: HLT-NAACL 2004, pages\n161–168, Boston, Massachusetts, USA. Association for Computational Linguistics.\n[126] Xuan Ouyang, Shuohuan Wang, Chao Pang, Yu Sun, Hao Tian, Hua Wu, and Haifeng Wang. 2020. ERNIE-M:\nenhanced multilingual representation by aligning cross-lingual semantics with monolingual corpora. CoRR,\nabs/2012.15674.\n[127] Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan. 2002. Thumbs up? sentiment classiﬁcation using\nmachine learning techniques. In Proceedings of the 2002 Conference on Empirical Methods in Natural Language\nProcessing (EMNLP 2002), pages 79–86. Association for Computational Linguistics.\n[128] Jeffrey Pennington, R. Socher, and Christopher D. Manning. 2014. Glove: Global vectors for word representa-\ntion. In EMNLP.\n[129] Ethan Perez, Douwe Kiela, and Kyunghyun Cho. 2021. True few-shot learning with language models.\n[130] Matthew E. Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, and Luke\nZettlemoyer. 2018. Deep contextualized word representations. In Proceedings of the 2018 Conference of the\nNorth American Chapter of the Association for Computational Linguistics: Human Language Technologies,\nVolume 1 (Long Papers), pages 2227–2237, New Orleans, Louisiana. Association for Computational Linguistics.\n[131] Matthew E. Peters, Sebastian Ruder, and Noah A. Smith. 2019. To tune or not to tune? adapting pretrained\nrepresentations to diverse tasks. In Proceedings of the 4th Workshop on Representation Learning for NLP\n(RepL4NLP-2019), pages 7–14, Florence, Italy. Association for Computational Linguistics.\n[132] Fabio Petroni, Patrick Lewis, Aleksandra Piktus, Tim Rockt¨aschel, Yuxiang Wu, Alexander H. Miller, and\nSebastian Riedel. 2020. How context affects language models’ factual predictions. ArXiv, abs/2005.04611.\n[133] Fabio Petroni, Tim Rockt¨aschel, Sebastian Riedel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu, and Alexander\nMiller. 2019. Language models as knowledge bases? In Proceedings of the 2019 Conference on Empirical\nMethods in Natural Language Processing and the 9th International Joint Conference on Natural Language\nProcessing (EMNLP-IJCNLP), pages 2463–2473, Hong Kong, China. Association for Computational Linguistics.\n38\n",
    "book_id": "210713586v1",
    "book_title": "2107.13586v1",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 37
  },
  {
    "chunk_full": "References\n[134] Edoardo Maria Ponti, Goran Glavaˇs, Olga Majewska, Qianchu Liu, Ivan Vuli´c, and Anna Korhonen. 2020.\nXCOPA: A multilingual dataset for causal commonsense reasoning. In Proceedings of the 2020 Conference\non Empirical Methods in Natural Language Processing (EMNLP), pages 2362–2376, Online. Association for\nComputational Linguistics.\n[135] Raul Puri and Bryan Catanzaro. 2019. Zero-shot text classiﬁcation with generative language models. CoRR,\nabs/1912.10165.\n[136] Tingting Qiao, Jianfeng Dong, and Duanqing Xu. 2018. Exploring human-like attention supervision in visual\nquestion answering. In Thirty-Second AAAI Conference on Artiﬁcial Intelligence.\n[137] Guanghui Qin and Jason Eisner. 2021. Learning how to ask: Querying LMs with mixtures of soft prompts. In\nProceedings of the 2021 Conference of the North American Chapter of the Association for Computational Lin-\nguistics: Human Language Technologies, pages 5203–5212, Online. Association for Computational Linguistics.\n[138] Xipeng Qiu, Tianxiang Sun, Yige Xu, Yunfan Shao, Ning Dai, and Xuanjing Huang. 2020. Pre-trained models\nfor natural language processing: A survey. Science China Technological Sciences, pages 1–26.\n[139] Alec Radford and Karthik Narasimhan. 2018. Improving language understanding by generative pre-training.\nIn arXiv.\n[140] Alec Radford, Jeffrey Wu, R. Child, David Luan, Dario Amodei, and Ilya Sutskever. 2019. Language models\nare unsupervised multitask learners. In arXiv.\n[141] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou,\nWei Li, and Peter J. Liu. 2020. Exploring the limits of transfer learning with a uniﬁed text-to-text transformer.\nJournal of Machine Learning Research, 21(140):1–67.\n[142] Nazneen Fatema Rajani, Bryan McCann, Caiming Xiong, and Richard Socher. 2019. Explain yourself!\nleveraging language models for commonsense reasoning. In Proceedings of the 57th Annual Meeting of the\nAssociation for Computational Linguistics, pages 4932–4942, Florence, Italy. Association for Computational\nLinguistics.\n[143] Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. 2016. SQuAD: 100,000+ questions\nfor machine comprehension of text. In Proceedings of the 2016 Conference on Empirical Methods in Natural\nLanguage Processing, pages 2383–2392, Austin, Texas. Association for Computational Linguistics.\n[144] Alexander J. Ratner, Henry R. Ehrenberg, Zeshan Hussain, Jared Dunnmon, and Christopher R´e. 2017.\nLearning to compose domain-speciﬁc transformations for data augmentation. In Advances in Neural Information\nProcessing Systems 30: Annual Conference on Neural Information Processing Systems 2017, December 4-9,\n2017, Long Beach, CA, USA, pages 3236–3246.\n[145] Laria Reynolds and Kyle McDonell. 2021. Prompt programming for large language models: Beyond the\nfew-shot paradigm. In Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems,\nCHI EA ’21, New York, NY, USA. Association for Computing Machinery.\n[146] Itsumi Saito, Kyosuke Nishida, Kosuke Nishida, and Junji Tomita. 2020. Abstractive summarization with\ncombination of pre-trained sequence-to-sequence and saliency models. arXiv preprint arXiv:2003.13028.\n[147] Nikunj Saunshi, Sadhika Malladi, and Sanjeev Arora. 2021. A mathematical exploration of why language\nmodels help solve downstream tasks. In 9th International Conference on Learning Representations, ICLR 2021,\nVirtual Event, Austria, May 3-7, 2021. OpenReview.net.\n[148] Teven Le Scao and Alexander M Rush. 2021. How many data points is a prompt worth? arXiv preprint\narXiv:2103.08493.\n[149] Timo Schick, Helmut Schmid, and Hinrich Sch¨utze. 2020. Automatically identifying words that can serve as\nlabels for few-shot text classiﬁcation. In Proceedings of the 28th International Conference on Computational\nLinguistics, COLING 2020, Barcelona, Spain (Online), December 8-13, 2020, pages 5569–5578. International\nCommittee on Computational Linguistics.\n[150] Timo Schick and Hinrich Sch¨utze. 2020. Rare words: A major problem for contextualized embeddings and\nhow to ﬁx it by attentive mimicking. In The Thirty-Fourth AAAI Conference on Artiﬁcial Intelligence, AAAI\n2020, The Thirty-Second Innovative Applications of Artiﬁcial Intelligence Conference, IAAI 2020, The Tenth\nAAAI Symposium on Educational Advances in Artiﬁcial Intelligence, EAAI 2020, New York, NY, USA, February\n7-12, 2020, pages 8766–8774. AAAI Press.\n[151] Timo Schick and Hinrich Sch¨utze. 2021. Generating datasets with pretrained language models. arXiv preprint\narXiv:2104.07540.\n39\n",
    "book_id": "210713586v1",
    "book_title": "2107.13586v1",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 38
  },
  {
    "chunk_full": "References\n[152] Timo Schick and Hinrich Sch¨utze. 2020. Few-shot text generation with pattern-exploiting training.\n[153] Timo Schick and Hinrich Sch¨utze. 2021a. Exploiting cloze questions for few shot text classiﬁcation and\nnatural language inference.\n[154] Timo Schick and Hinrich Sch¨utze. 2021b. It’s not just size that matters: Small language models are also\nfew-shot learners.\n[155] Timo Schick, Sahana Udupa, and Hinrich Sch¨utze. 2021. Self-diagnosis and self-debiasing: A proposal for\nreducing corpus-based bias in nlp.\n[156] Rico Sennrich, Barry Haddow, and Alexandra Birch. 2016a. Controlling politeness in neural machine\ntranslation via side constraints. In Proceedings of the 2016 Conference of the North American Chapter of the\nAssociation for Computational Linguistics: Human Language Technologies, pages 35–40, San Diego, California.\nAssociation for Computational Linguistics.\n[157] Rico Sennrich, Barry Haddow, and Alexandra Birch. 2016b. Improving neural machine translation models with\nmonolingual data. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics\n(Volume 1: Long Papers), pages 86–96, Berlin, Germany. Association for Computational Linguistics.\n[158] Richard Shin, C. H. Lin, Sam Thomson, Charles Chen, Subhro Roy, Emmanouil Antonios Platanios, Adam\nPauls, D. Klein, J. Eisner, and Benjamin Van Durme. 2021. Constrained language models yield few-shot semantic\nparsers. ArXiv, abs/2104.08768.\n[159] Taylor Shin, Yasaman Razeghi, Robert L. Logan IV, Eric Wallace, and Sameer Singh. 2020. AutoPrompt:\nEliciting knowledge from language models with automatically generated prompts. In Empirical Methods in\nNatural Language Processing (EMNLP).\n[160] Jake Snell, Kevin Swersky, and Richard S. Zemel. 2017. Prototypical networks for few-shot learning. In\nAdvances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing\nSystems 2017, December 4-9, 2017, Long Beach, CA, USA, pages 4077–4087.\n[161] Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D Manning, Andrew Y Ng, and\nChristopher Potts. 2013. Recursive deep models for semantic compositionality over a sentiment treebank. In\nProceedings of the 2013 conference on empirical methods in natural language processing, pages 1631–1642.\n[162] Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, and Tie-Yan Liu. 2019. MASS: masked sequence to sequence\npre-training for language generation. In Proceedings of the 36th International Conference on Machine Learning,\nICML 2019, 9-15 June 2019, Long Beach, California, USA, volume 97 of Proceedings of Machine Learning\nResearch, pages 5926–5936. PMLR.\n[163] Ekta Sood, Simon Tannert, Philipp Mueller, and Andreas Bulling. 2020. Improving natural language processing\ntasks with human gaze-guided neural attention. Advances in Neural Information Processing Systems, 33:6327–\n6341.\n[164] Weijie Su, Xizhou Zhu, Yue Cao, Bin Li, Lewei Lu, Furu Wei, and Jifeng Dai. 2020. VL-BERT: pre-training\nof generic visual-linguistic representations. In 8th International Conference on Learning Representations, ICLR\n2020, Addis Ababa, Ethiopia, April 26-30, 2020. OpenReview.net.\n[165] Yusuke Sugano and Andreas Bulling. 2016. Seeing with humans: Gaze-assisted neural image captioning.\narXiv preprint arXiv:1608.05203.\n[166] Chen Sun, Austin Myers, Carl Vondrick, Kevin Murphy, and Cordelia Schmid. 2019a. Videobert: A joint\nmodel for video and language representation learning. In 2019 IEEE/CVF International Conference on Computer\nVision, ICCV 2019, Seoul, Korea (South), October 27 - November 2, 2019, pages 7463–7472. IEEE.\n[167] Yu Sun, Shuohuan Wang, Shikun Feng, Siyu Ding, Chao Pang, Junyuan Shang, Jiaxiang Liu, Xuyi Chen,\nYanbin Zhao, Yuxiang Lu, Weixin Liu, Zhihua Wu, Weibao Gong, Jianzhong Liang, Zhizhou Shang, Peng Sun,\nWei Liu, Xuan Ouyang, Dianhai Yu, Hao Tian, Hua Wu, and Haifeng Wang. 2021. ERNIE 3.0: Large-scale\nknowledge enhanced pre-training for language understanding and generation. CoRR, abs/2107.02137.\n[168] Yu Sun, Shuohuan Wang, Yu-Kun Li, Shikun Feng, Hao Tian, Hua Wu, and Haifeng Wang. 2020. ERNIE\n2.0: A continual pre-training framework for language understanding. In The Thirty-Fourth AAAI Conference on\nArtiﬁcial Intelligence, AAAI 2020, The Thirty-Second Innovative Applications of Artiﬁcial Intelligence Conference,\nIAAI 2020, The Tenth AAAI Symposium on Educational Advances in Artiﬁcial Intelligence, EAAI 2020, New York,\nNY, USA, February 7-12, 2020, pages 8968–8975. AAAI Press.\n40\n",
    "book_id": "210713586v1",
    "book_title": "2107.13586v1",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 39
  },
  {
    "chunk_full": "References\n[169] Yu Sun, Shuohuan Wang, Yukun Li, Shikun Feng, Xuyi Chen, Han Zhang, Xin Tian, Danxiang Zhu, Hao\nTian, and Hua Wu. 2019b. Ernie: Enhanced representation through knowledge integration. arXiv preprint\narXiv:1904.09223.\n[170] Derek Tam, Rakesh R Menon, Mohit Bansal, Shashank Srivastava, and Colin Raffel. 2021. Improving and\nsimplifying pattern exploiting training.\n[171] Kai Ming Ting and Ian H. Witten. 1997. Stacked generalizations: When does it work? In Proceedings of the\nFifteenth International Joint Conference on Artiﬁcial Intelligence, IJCAI 97, Nagoya, Japan, August 23-29, 1997,\n2 Volumes, pages 866–873. Morgan Kaufmann.\n[172] Erik F. Tjong Kim Sang and Fien De Meulder. 2003. Introduction to the CoNLL-2003 shared task: Language-\nindependent named entity recognition. In Proceedings of the Seventh Conference on Natural Language Learning\nat HLT-NAACL 2003, pages 142–147.\n[173] Trieu H. Trinh and Quoc V. Le. 2018. A simple method for commonsense reasoning. CoRR, abs/1806.02847.\n[174] Maria Tsimpoukelli, Jacob Menick, Serkan Cabi, S. M. Ali Eslami, Oriol Vinyals, and Felix Hill. 2021.\nMultimodal few-shot learning with frozen language models. CoRR, abs/2106.13884.\n[175] Svitlana Vakulenko, Shayne Longpre, Zhucheng Tu, and Raviteja Anantha. 2020. A wrong answer or a\nwrong question? an intricate relationship between question reformulation and answer selection in conversational\nquestion answering. In Proceedings of the 5th International Workshop on Search-Oriented Conversational AI\n(SCAI), pages 7–16, Online. Association for Computational Linguistics.\n[176] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser,\nand Illia Polosukhin. 2017. Attention is all you need. In Advances in neural information processing systems,\npages 5998–6008.\n[177] Eric Wallace, Shi Feng, Nikhil Kandpal, Matt Gardner, and Sameer Singh. 2019a. Universal adversarial\ntriggers for attacking and analyzing NLP. In Proceedings of the 2019 Conference on Empirical Methods in Natural\nLanguage Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-\nIJCNLP 2019, Hong Kong, China, November 3-7, 2019, pages 2153–2162. Association for Computational\nLinguistics.\n[178] Eric Wallace, Yizhong Wang, Sujian Li, Sameer Singh, and Matt Gardner. 2019b. Do NLP models know\nnumbers? probing numeracy in embeddings. In Proceedings of the 2019 Conference on Empirical Methods\nin Natural Language Processing and the 9th International Joint Conference on Natural Language Processing\n(EMNLP-IJCNLP), pages 5307–5315, Hong Kong, China. Association for Computational Linguistics.\n[179] Xiaozhi Wang, Tianyu Gao, Zhaocheng Zhu, Zhengyan Zhang, Zhiyuan Liu, Juanzi Li, and Jian Tang. 2021.\nKEPLER: A uniﬁed model for knowledge embedding and pre-trained language representation. Trans. Assoc.\nComput. Linguistics, 9:176–194.\n[180] Yaqing Wang, Quanming Yao, James T Kwok, and Lionel M Ni. 2020. Generalizing from a few examples: A\nsurvey on few-shot learning. ACM Computing Surveys (CSUR), 53(3):1–34.\n[181] Colin Wei, Sang Michael Xie, and Tengyu Ma. 2021. Why do pretrained language models help in downstream\ntasks? an analysis of head and prompt tuning.\n[182] Wei Wu, Fei Wang, Arianna Yuan, Fei Wu, and Jiwei Li. 2020. CorefQA: Coreference resolution as query-\nbased span prediction. In Proceedings of the 58th Annual Meeting of the Association for Computational\nLinguistics, pages 6953–6963, Online. Association for Computational Linguistics.\n[183] Dongling Xiao, Yu-Kun Li, Han Zhang, Yu Sun, Hao Tian, Hua Wu, and Haifeng Wang. 2021. Ernie-\ngram: Pre-training with explicitly n-gram masked language modeling for natural language understanding. In\nProceedings of the 2021 Conference of the North American Chapter of the Association for Computational\nLinguistics: Human Language Technologies, NAACL-HLT 2021, Online, June 6-11, 2021, pages 1702–1715.\nAssociation for Computational Linguistics.\n[184] Han Xu, Zhang Zhengyan, Ding Ning, Gu Yuxian, Liu Xiao, Huo Yuqi, Qiu Jiezhong, Zhang Liang, Han Wen-\ntao, Huang Minlie, et al. 2021. Pre-trained models: Past, present and future. arXiv preprint arXiv:2106.07139.\n[185] Linting Xue, Aditya Barua, Noah Constant, Rami Al-Rfou, Sharan Narang, Mihir Kale, Adam Roberts,\nand Colin Raffel. 2021a. Byt5: Towards a token-free future with pre-trained byte-to-byte models. CoRR,\nabs/2105.13626.\n41\n",
    "book_id": "210713586v1",
    "book_title": "2107.13586v1",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 40
  },
  {
    "chunk_full": "References\n[186] Linting Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami Al-Rfou, Aditya Siddhant, Aditya Barua,\nand Colin Raffel. 2021b. mt5: A massively multilingual pre-trained text-to-text transformer. In Proceedings\nof the 2021 Conference of the North American Chapter of the Association for Computational Linguistics:\nHuman Language Technologies, NAACL-HLT 2021, Online, June 6-11, 2021, pages 483–498. Association for\nComputational Linguistics.\n[187] Jheng-Hong Yang, Sheng-Chieh Lin, Rodrigo Nogueira, Ming-Feng Tsai, Chuan-Ju Wang, and Jimmy Lin.\n2020. Designing templates for eliciting commonsense knowledge from pretrained sequence-to-sequence models.\nIn Proceedings of the 28th International Conference on Computational Linguistics, pages 3449–3453, Barcelona,\nSpain (Online). International Committee on Computational Linguistics.\n[188] Zhilin Yang, Zihang Dai, Yiming Yang, Jaime G. Carbonell, Ruslan Salakhutdinov, and Quoc V. Le. 2019.\nXlnet: Generalized autoregressive pretraining for language understanding. In Advances in Neural Information\nProcessing Systems 32: Annual Conference on Neural Information Processing Systems 2019, NeurIPS 2019,\nDecember 8-14, 2019, Vancouver, BC, Canada, pages 5754–5764.\n[189] Pengcheng Yin, Graham Neubig, Wen-tau Yih, and Sebastian Riedel. 2020. Tabert: Pretraining for joint\nunderstanding of textual and tabular data. In Proceedings of the 58th Annual Meeting of the Association for\nComputational Linguistics, ACL 2020, Online, July 5-10, 2020, pages 8413–8426. Association for Computational\nLinguistics.\n[190] Wenpeng Yin, Jamaal Hay, and Dan Roth. 2019. Benchmarking zero-shot text classiﬁcation: Datasets,\nevaluation and entailment approach. In Proceedings of the 2019 Conference on Empirical Methods in Natural\nLanguage Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-\nIJCNLP 2019, Hong Kong, China, November 3-7, 2019, pages 3912–3921. Association for Computational\nLinguistics.\n[191] Wenhao Yu, Chenguang Zhu, Zaitang Li, Zhiting Hu, Qingyun Wang, Heng Ji, and Meng Jiang. 2020. A\nsurvey of knowledge-enhanced text generation. arXiv preprint arXiv:2010.04389.\n[192] Weizhe Yuan, Pengfei Liu, and Graham Neubig. 2021a. Can we automate scientiﬁc reviewing? arXiv preprint\narXiv:2102.00176.\n[193] Weizhe Yuan, Graham Neubig, and Pengfei Liu. 2021b. Bartscore: Evaluating generated text as text generation.\n[194] Wei Zeng, Xiaozhe Ren, Teng Su, Hui Wang, Yi Liao, Zhiwei Wang, Xin Jiang, ZhenZhang Yang, Kaisheng\nWang, Xiaoda Zhang, Chen Li, Ziyan Gong, Yifan Yao, Xinjing Huang, Jun Wang, Jianfeng Yu, Qi Guo, Yue Yu,\nYan Zhang, Jin Wang, Hengtao Tao, Dasen Yan, Zexuan Yi, Fang Peng, Fangqing Jiang, Han Zhang, Lingfeng\nDeng, Yehong Zhang, Zhe Lin, Chao Zhang, Shaojie Zhang, Mingyue Guo, Shanzhi Gu, Gaojun Fan, Yaowei\nWang, Xuefeng Jin, Qun Liu, and Yonghong Tian. 2021. Pangu-α: Large-scale autoregressive pretrained chinese\nlanguage models with auto-parallel computation.\n[195] Jingqing Zhang, Yao Zhao, Mohammad Saleh, and Peter J. Liu. 2020a. PEGASUS: pre-training with extracted\ngap-sentences for abstractive summarization. In Proceedings of the 37th International Conference on Machine\nLearning, ICML 2020, 13-18 July 2020, Virtual Event, volume 119 of Proceedings of Machine Learning Research,\npages 11328–11339. PMLR.\n[196] Ruohan Zhang, Akanksha Saran, Bo Liu, Yifeng Zhu, Sihang Guo, Scott Niekum, Dana Ballard, and Mary\nHayhoe. 2020b. Human gaze assisted artiﬁcial intelligence: a review. In IJCAI: Proceedings of the Conference,\nvolume 2020, page 4951. NIH Public Access.\n[197] Yue Zhang and Joakim Nivre. 2011. Transition-based dependency parsing with rich non-local features. In\nProceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language\nTechnologies, pages 188–193, Portland, Oregon, USA. Association for Computational Linguistics.\n[198] Zhengyan Zhang, Yuxian Gu, Xu Han, Shengqi Chen, Chaojun Xiao, Zhenbo Sun, Yuan Yao, Fanchao Qi,\nJian Guan, Pei Ke, Yanzheng Cai, Guoyang Zeng, Zhixing Tan, Zhiyuan Liu, Minlie Huang, Wentao Han, Yang\nLiu, Xiaoyan Zhu, and Maosong Sun. 2021. CPM-2: large-scale cost-effective pre-trained language models.\nCoRR, abs/2106.10715.\n[199] Zhengyan Zhang, Xu Han, Zhiyuan Liu, Xin Jiang, Maosong Sun, and Qun Liu. 2019. ERNIE: enhanced\nlanguage representation with informative entities. In Proceedings of the 57th Conference of the Association for\nComputational Linguistics, ACL 2019, Florence, Italy, July 28- August 2, 2019, Volume 1: Long Papers, pages\n1441–1451. Association for Computational Linguistics.\n[200] Zhengyan Zhang, Xu Han, Hao Zhou, Pei Ke, Yuxian Gu, Deming Ye, Yujia Qin, YuSheng Su, Haozhe Ji,\nJian Guan, Fanchao Qi, Xiaozhi Wang, Yanan Zheng, Guoyang Zeng, Huanqi Cao, Shengqi Chen, Daixuan Li,\nZhenbo Sun, Zhiyuan Liu, Minlie Huang, Wentao Han, Jie Tang, Juanzi Li, Xiaoyan Zhu, and Maosong Sun.\n2020c. CPM: A large-scale generative chinese pre-trained language model. CoRR, abs/2012.00413.\n42\n",
    "book_id": "210713586v1",
    "book_title": "2107.13586v1",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 41
  },
  {
    "chunk_full": "References\n[201] Tony Z. Zhao, Eric Wallace, Shi Feng, Dan Klein, and Sameer Singh. 2021. Calibrate before use: Improving\nfew-shot performance of language models.\n[202] Ruiqi Zhong, Kristy Lee, Zheng Zhang, and Dan Klein. 2021a. Meta-tuning language models to answer\nprompts better. arXiv preprint arXiv:2104.04670.\n[203] Zexuan Zhong, Dan Friedman, and Danqi Chen. 2021b. Factual probing is [MASK]: learning vs. learning to\nrecall. CoRR, abs/2104.05240.\n[204] Zhi-Hua Zhou, Jianxin Wu, and Wei Tang. 2002. Ensembling neural networks: many could be better than all.\nArtiﬁcial intelligence, 137(1-2):239–263.\n[205] Chenguang Zhu, William Hinthorn, Ruochen Xu, Qingkai Zeng, Michael Zeng, Xuedong Huang, and Meng\nJiang. 2020. Enhancing factual consistency of abstractive summarization. arXiv preprint arXiv:2003.08612.\n[206] Geoffrey Zweig, John C. Platt, Christopher Meek, Christopher J.C. Burges, Ainur Yessenalina, and Qiang\nLiu. 2012. Computational approaches to sentence completion. In Proceedings of the 50th Annual Meeting of\nthe Association for Computational Linguistics (Volume 1: Long Papers), pages 601–610, Jeju Island, Korea.\nAssociation for Computational Linguistics.\n43\n",
    "book_id": "210713586v1",
    "book_title": "2107.13586v1",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 42
  },
  {
    "chunk_full": "A\nAppendix on Pre-trained LMs\nIn this appendix we present some auxiliary information on pre-trained LMs that may be useful to the readers to\nbetter understand the current lay of the land with respect to this dynamic research area.\nA.1\nEvolution of Pre-trained LM Parameters\nFig. 7 lists several popular pre-trained models’ statistics of parameters, ranging from 0 to 200 billion. GPT3, CPM2,\nand PanGu-α are the top three largest models with parameters greater than 150 billion.\nERNIE-T\nMASS\nALBERT\nUNiLM\nMT5\nMT6\nRoBERTa\nBERT\nBART\nXLM\nXNLG\nGPT2\nCPM1\nERNIE-3\nT5\nCODEX\nM6\nGPT3\nCPM2\nPanGu-α\n0\n100\n200\n0.110.120.24 0.3 0.3 0.3 0.340.34 0.4 0.8 0.8 1.5 2.6 10\n11\n12\n100\n175\n198 200\nFigure 7: Comparison of the size of existing popular pre-trained language models.\nA.2\nAuxiliary Objective\nIn this subsection, more auxiliary objectives for pre-training language models have been listed.\n• Next Sentence Prediction (NSP) (Devlin et al., 2019): A binary classiﬁcation loss predicting whether two\nsegments appear consecutively within a larger document, or are random unrelated sentences.\n• Sentence Order Prediction (SOP) (Lan et al., 2020): A binary classiﬁcation loss for predicting whether two\nsentences are in a natural or swapped order.\n• Capital Word Prediction (CWP) (Liu et al., 2020b): A binary classiﬁcation objective calculated over each\nword, predicting whether whether each word is capitalized or not.\n• Sentence Deshufﬂing (SDS) (Liu et al., 2020b): A multi-class classiﬁcation task to reorganize permuted\nsegments.\n• Sentence distance prediction (SDP) (Liu et al., 2020b) : A three-class classiﬁcation task, predicting the\npositional relationship between two sentences (adjacent in the same document, not adjacent but in the same\ndocument, in different documents).\n• Masked Column Prediction (MCP) (Yin et al., 2020): Given a table, recover the names and data types of\nmasked columns.\n• Linguistic-Visual Alignment (LVA) (Lu et al., 2019): A binary classiﬁcation to Predict whether the text content\ncan be aligned to visual content.\n• Image Region prediction (IRP) (Su et al., 2020): Given an image whose partial features are masked (zeroed\nout), predict the masked regions.\n• Replaced Token Detection (RTD) (Xiao et al., 2021): A binary classiﬁcation loss predicting whether each token\nin corrupted input was replaced by a generative sample or not.\n• Discourse Relation Prediction (DRP) (Sun et al., 2020): Predict the semantic or rhetorical relation between\ntwo sentences.\n• Translation Language Modeling (TLM) (Lample and Conneau, 2019): Consider parallel sentences and mask\nwords randomly in both source and target sentences.\n• Information Retrieval Relevance (IRR) (Sun et al., 2020): Predict the information retrieval relevance of two\nsentences.\n• Token-Passage Prediction (TPP) (Liu et al., 2020b): Identify the keywords of a passage appearing in the\nsegment.\n• Universal Knowledge-Text Prediction (UKTP) (Sun et al., 2021): Incorporate knowledge into one pre-trained\nlanguage model.\n• Machine Translation (MT) (Chi et al., 2021a) : Translate a sentence from the source language into the target\nlanguage.\n• Translation Pair Span Corruption (TPSC) (Chi et al., 2021a) : Predict the masked spans from a translation\npair.\n• Translation Span Corruption (TSC) (Chi et al., 2021a) : Unlike TPSC, TSC only masks and predicts the spans\nin one language.\n44\n",
    "book_id": "210713586v1",
    "book_title": "2107.13586v1",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 43
  },
  {
    "chunk_full": "A.3\nPre-trained Language Model Families\n• Multilingual Replaced Token Detection (MRTD) (Chi et al., 2021b): Distinguish real input tokens from\ncorrupted multilingual sentences by a Generative Adversarial Network, where both the generator and the\ndiscriminator are shared across languages.\n• Translation Replaced Token Detection (TRTD) (Chi et al., 2021b): Distinguish the real tokens and masked\ntokens in the translation pair by the Generative Adversarial Network.\n• Knowledge Embedding (KE) (Wang et al., 2021): Encode entities and relations in knowledge graphs (KGs) as\ndistributed representations\n• Image-to-text transfer (ITT) (Wang et al., 2021): Is similar to the image caption that generates a corresponding\ndescription for the input image.\n• Multimodality-to-text transfer (MTT) (Wang et al., 2021): Generate the target text based on both the visual\ninformation and the noised linguistic information.\nA.3\nPre-trained Language Model Families\nThe increasing number of models makes it difﬁcult for people to clearly grasp the differences between them. Based\non this, we cluster the current mainstream pre-training models and characterize them from diverse dimensions.\n45\n",
    "book_id": "210713586v1",
    "book_title": "2107.13586v1",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 44
  },
  {
    "chunk_full": "A.3\nPre-trained Language Model Families\nFamily\nModels\nLM\nPre-training Tasks\nCorruption\nApplication\nMain\nAuxiliary\nParallel\nMask\nReplace\nDelete\nPermute\nGPT\nGPT [139]\nL2R\nSLM\n-\n%\n-\n-\n-\n-\nNLG\nGPT-2 [140]\nL2R\nSLM\n-\n%\n-\n-\n-\n-\nNLG\nGPT-3 [16]\nL2R\nSLM\n-\n%\n-\n-\n-\n-\nNLG\nCodex [20]\nL2R\nSLM\n-\n%\n-\n-\n-\n-\nNLG\nELMo\nELMo [130]\nL2R\nSLM\n-\n%\n-\n-\n-\n-\nNLU, NLG\nBERT\nBERT [32]\nMask\nCTR\nNSP\n%\nTok\n-\n-\n-\nNLU\nRoBERTa [105]\nMask\nCTR\n-\n%\nTok\n-\n-\n-\nNLU\nSpanBERT [70]\nMask\nCTR\n-\n%\nSpan\n-\n-\n-\nNLU\nDeBERTa [60]\nMask\nCTR\n-\n%\nTok\n-\n-\n-\nNLU\nSciBERT [7]\nMask\nCTR\nNSP\n%\nTok\n-\n-\n-\nSci-NLU\nBioBERT [89]\nMask\nCTR\nNSP\n%\nTok\n-\n-\n-\nBio-NLU\nALBERT [87]\nMask\nCTR\nSOP\n%\nTok\n-\n-\n-\nmSent\nFinBERT [108]\nMask\nCTR\nCWP, SDS,\nSDP, TPP\n%\nSpan\n-\n-\nSent\nFin-NLU\nVLBERT [164]\nMask\nCTR\nIRP\n!\nTok, Region\n-\n-\n-\nVLU\nViLBERT [110]\nMask\nCTR\nIRP, LVA\n!\nTok, Region\n-\n-\n-\nVLU\nBEIT [5]\nMask\nCTR,FTR\n-\n%\nVisual “Tok”7\n-\n-\n-\nVLU\nVideoBERT [166]\nMask\nCTR\nLVA\n!\nTok, Frame\n-\n-\n-\nVLU\nTaBERT [189]\nMask\nCTR\nMCP\n!\nTok, Column\n-\n-\n-\nTab2Text\nmBERT [32]\nMask\nCTR\nNSP\n%\nTok\n-\n-\n-\nXLU\nTinyBERT [69]\nMask\nCTR\nNSP\n%\nTok\n-\n-\n-\nXLU\nERNIE\nERNIE-T [199]\nMask\nCTR\nNSP\n%\nTok, Entity\n-\n-\n-\nNLU\nERNIE-B [169]\nMask\nCTR\n-\n%\nTok,Entity, Phrase\n-\n-\n-\nNLU\nERNIE-NG [183]\nMask\nCTR\nRTD\n%\nN-gram\nTok\n-\n-\nNLU\nERNIE-B2 [168]\nMask\nCTR\nCWP,SDS,SOP,\nSDP,DRP,IRR\n%\nEntity, Phrase\n-\n-\nSent\nNLU\nERNIE-M [126]\nLPM\nCTR\n-\n!\nTok\n-\n-\nXLU, XLG\nERNIE-B3 [167]\nMask\nCTR\nSOP,SDP,UKTP\n%\nEntity, Phrase\n-\n-\n-\nNLU\nBART\nBART [94]\nEn-De\nFTR\n-\n%\nTok\nSpan\nTok\nSent,Doc\nNLU, NLG\nmBART [104]\nEn-De\nFTR\n-\n%\nSpan\n-\n-\nSent\nNLG\nUniLM\nUniLM1 [35]\nLPM\nSLM,CTR\nNSP\n%\nTok\n-\n-\n-\nNLU, NLG\nUniLM2 [6]\nLPM\nSLM,CTR\n-\n%\nTok\n-\n-\nTok\nNLU, NLG\nT5\nT5 [141]\nEn-De\nCTR\n-\n%\n-\nSpan\n-\n-\nNLU, NLG\nmT5 [186]\nEn-De\nCTR\n-\n%\n-\nSpan\n-\n-\nXLU, XLG\nmT6 [22]\nEn-De\nCTR\nMT,TPSC,TSC\n!\n-\nSpan\n-\n-\nXLU, XLG\nByT5 [185]\nEn-De\nCTR\n-\n%\n-\nbyte-span\n-\n-\nXLU, XLG\nXLM\nXLM [86]\nLPM\nCTR\nTLM\n!\nTok\n-\n-\n-\nXLU, XLG\nXLM-R [28]\nMask\nCTR\n-\n%\nTok\n-\n-\n-\nXLU\nXLM-E [23]\nMask\nCTR\nMRTD,TRTD\n%\n-\nTok\n-\n-\nXLU, XLG\nCPM\nCPM [200]\nL2R\nSLM\n-\n%\n-\n-\n-\n-\nNLG\nCPM-2 [198]\nEn-De\nCTR\n-\n%\nSpan\n-\n-\n-\nNLU,NLG\nOther\nXLNet [188]\nL2R\nSLM\n-\n%\n-\n-\n-\nTok\nNLU\nPanGu-α [194]\nL2R\nSLM\n-\n%\n-\n-\n-\n-\nNLG\nELECTRA [26]\nMask\nCTR\nRTD\n%\nTok\nTok\n-\n-\nNLU,NLG\nMASS [162]\nEn-De\nCTR\n-\n%\nSpan\n-\n-\n-\nNLG\nPEGASUS [195]\nEn-De\nCTR\n-\n%\nTok, Sent\n-\n-\n-\nSummarization\nM6 [179]\nEn-De\nCTR\nITT,MTT\n%\nSpan\n-\n-\n-\nNLG\nTable 13: A detailed illustration of different pre-trained models characterized by the four aspects. “Parallel”\nrepresents if parallel data have been used for pre-training. Sci, Bio, Fin, K represent scientiﬁc, biomedical,\nﬁnancial, and knowledge, respectively. Tok, Sent, Doc denote token, sentence and document, respectively.\nRegion, Frame denote basic units of images and video respectively.\n46\n",
    "book_id": "210713586v1",
    "book_title": "2107.13586v1",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 45
  },
  {
    "chunk_full": "A Taxonomy of Prompt Modifiers for Text-To-Image\nGeneration\nJONAS OPPENLAENDER, University of Jyväskylä, Finland\nText-guided synthesis of images has become enormously popular and online communities dedicated to text-\nto-image generation and art generated with Artificial Intelligence (AI) have emerged. While deep generative\nmodels can synthesize high-quality images and artworks from simple descriptive text prompts, practitioners of\ntext-to-image generation typically seek to control the generative model’s output by adding short key phrases\n(“modifiers”) to the prompt. This paper identifies six types of prompt modifiers used by practitioners in the\nonline text-to-image community based on a 3-month ethnographic study. The novel taxonomy of prompt\nmodifiers provides researchers a conceptual starting point for investigating the practice of text-to-image\ngeneration, but may also help practitioners of AI generated art improve their images. We further outline how\nprompt modifiers are applied in the practice of “prompt engineering.” We discuss research opportunities of\nthis novel creative practice in the field of Human-Computer Interaction (HCI). The paper concludes with a\ndiscussion of broader implications of prompt engineering from the perspective of Human-AI Interaction (HAI)\nin future applications beyond the use case of text-to-image generation and AI generated art.\nAdditional Key Words and Phrases: prompt engineering, text-to-image generation, human-AI interaction, AI\ngenerated art\n1\nINTRODUCTION\nText-to-image generation has become widely popular both in academia and as a new creative\npractice among practitioners of “AI art.” Based on deep learning, text-to-image generation systems\ncan generate digital images from short descriptive texts (called prompts, such as “an oil painting of a\nbeautiful landscape at dawn”). To be effective, the textual input prompts need to be given in a certain\nformat in order to, for instance, generate images with a certain style. This is commonly achieved\nby adding keywords and key phrases to the prompt (so-called “prompt modifiers”). Examples\nof images synthesized from textual prompts are depicted in Figure 1. Given the quality of these\nimages, it is not surprising that an enthusiastic online community around this novel text-based\nway of creating images and art has developed. Within this community, the practice and skill of\nwriting prompts is known by the term “prompt engineering” due to its iterative and experimental\nnature [28]. Prompt engineering is an emerging research area in the field of Human-Computer\nInteraction (HCI) concerned with how to phrase input prompts for deep generative models and –\nfrom a broader perspective – how humans can effectively interact with artificial intelligence.\nThe learning curve of prompt engineering can still be steep. Some prompt modifiers used within\nthe community of practitioners are not intuitive and from looking at an image, it is impossible to\ntell the input prompt used to synthesize the image. On social media, many artists do not share their\ncomplete prompts for their artworks and it is often not clear how these artworks were created.\nTherefore, prompt engineering is a non-intuitive skill that is learned from extensive experimentation\nand trial and error [28]. A growing number of resources in the gray and scholarly literature present\nsystematic experimentation on the effect of different prompt modifiers [12, 15, 28, 38, 54]. Online\ndatabases have been created in which users can explore artworks, prompts, and prompt modifiers\n[e.g. 1, 2, 27, 36, 57]. These resources and guides are part of a growing online ecosystem around\ntext-to-image generation [37].\nWhile guides, resources, and datasets about prompting are available, there is still a gap in our\nunderstanding of prompt modifiers. No previous study has investigated different types of prompt\nmodifiers. With a specific focus on digital art generated with text-to-image systems, this paper\ncontributes a taxonomy of prompt modifiers used by practitioners in the text-to-image community,\nbased on an ethnographic study of the community’s prompt engineering practices. The work is\narXiv:2204.13988v3  [cs.MM]  14 Jun 2023\n",
    "book_id": "220413988v3",
    "book_title": "A Taxonomy of Prompt Modifiers for Text-To-Image Generation",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 46
  },
  {
    "chunk_full": "2\nJonas Oppenlaender\nFig. 1. Selected images generated with text-to-image generation using VQGAN–CLIP (top), Midjourney.com\n(middle), and DALL-E 2 (bottom).\nbased on a three-month online ethnography which analyzed how prompt modifiers are being applied\nin prompt writing. This paper contributes toward a better understanding of prompt engineering as\na practice within HCI in order to inform the HCI research community on the emerging practice of\nprompt engineering within the broader context of human interactions with artificial intelligence.\nThis paper aims to enhance the theoretical understanding of how people write prompts and use\nprompts modifiers. Through understanding prompt writing, we can pave the way towards a broader\nand unified theory of prompt engineering which the HCI literature is currently missing. The paper\nalso touches on how the technology behind text-to-image systems and the practice of prompt\nengineering has broader implications in research on HCI and Human-centered AI (HCAI).\nThe paper is structured as follows. We first provide a brief introduction into text-to-image\nsynthesis and prompt engineering in Section 2. After describing the methodological approach in\n",
    "book_id": "220413988v3",
    "book_title": "A Taxonomy of Prompt Modifiers for Text-To-Image Generation",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 47
  },
  {
    "chunk_full": "Taxonomy of Prompt Modifiers\n3\nSection 3, a taxonomy of six different types of prompt modifiers is presented in Section 4. It is\ndemonstrated how these prompt modifiers are applied in the context of prompt engineering in\nSection 5. The paper concludes with a discussion of opportunities for future research on text-to-\nimage generation and the broader implications beyond AI generated art (sections 6 and 7).\n2\nBACKGROUND\nThis section discusses the evolution of text-to-image generation, particularly highlighting the\nrole of OpenAI’s CLIP model. It then delves into the concepts of “prompt engineering,” a creative\npractice for controlling image generation, and “prompt modifiers,” keywords used to refine the\nimage output. The section also underscores the contribution of the online community in advancing\nthese creative practices.\n2.1\nText-to-Image Generation\nThe field of image synthesis using deep learning has seen an unprecedented growth with the break-\nthrough development of multimodal models trained on large amounts pairs of of images and text\nscraped from the World Wide Web. The development was initially spurred by OpenAI’s multimodal\nmodel CLIP [44]. CLIP is a contrastive language-vision model trained in an unsupervised way to\nperform zero-shot classification of images. CLIP provides a convenient way to transform both text\nand images into a common vector-based representation. When used as a discriminator component\nin text-conditioned generative systems, CLIP can “guide” the image generation process. CLIP was\noriginally a part of OpenAI’s DALL-E architecture [46], a text-to-image system that was never\nreleased in its entirety. However, OpenAI did release the weights of the CLIP model. This resulted\nin a vast number of open source implementations of text-to-image systems, first as CLIP-guided\ngenerative adversarial networks (e.g., VQGAN–CLIP by Crowson et al. [9]) and later as diffusion\nbased image generation systems, such as CLIP Guided Diffusion [8] and Latent Diffusion [49].\nThis paper investigates text-to-image generation from the lens of Human-Computer Interaction\n(HCI). In order to generate images from text, one not only has to choose the right words to make the\ntext-to-image system generate the desired images, one also has to add different keywords and key\nphrases to control the style and quality of the image generation. This creative practice of writing\neffective prompts is sometimes referred to as “prompt engineering.” This paper investigates what\n(and how) different types of prompt modifiers are being applied in prompt engineering.\n2.2\nPrompt Engineering and Prompt Modifiers\nPrompt engineering [28] – also referred to as “prompt design” [35], “prompt programming” [47],\nand “prompting” [2] for short – is the practice of writing textual inputs for generative systems.\nIn the context of text-to-image generation, “carefully selected and composed sentences are used\nto achieve a certain visual style in the synthesized image” [50]. The practice has seen an ideal\napplication ground in AI generated art, but it is not limited to text-to-image generation. The term\nprompt engineering was originally coined to denote the practice of writing textual inputs for\nthe language model GPT-3 [28]. This autoregressive language model requires context to produce\nrelevant text as output. Templates have been developed to optimally provide textual inputs to\nGPT-3. OpenAI’s documentation, for instance, lists 49 “recipes” on how to phrase input prompts\nfor their language model.1 Templating languages and interfaces have been developed to advance\nthe field of prompting [2]. Using such recipes and tools, the output of the language model can be\nadapted to different down-stream tasks, such as correcting grammar, summarizing text, answering\nquestions, generating product names, or acting as a chat bot.\n1See https://beta.openai.com/examples.\n",
    "book_id": "220413988v3",
    "book_title": "A Taxonomy of Prompt Modifiers for Text-To-Image Generation",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 48
  },
  {
    "chunk_full": "4\nJonas Oppenlaender\nTemplates have also emerged for writing input prompts for text-to-image systems, particularly\nin the online community around AI generated art. For instance, the “Traveler’s Guide to the Latent\nSpace” recommends the following prompt template [54]:\n[Medium][Subject][Artist(s)][Details][Image repository support]\nSimilar templates are being followed in many resources originating from within the online commu-\nnity, such as the DALL-E Prompt Book [38]. Figure 2 provides an example of a typical textual input\nprompt and the resulting AI generated image.\nFig. 2. Digital artwork generated with DISCO Diffusion from the input prompt “A beautiful painting of a\nsingular lighthouse, shining its light across a tumultuous sea of blood by greg rutkowski and thomas kinkade,\nTrending on artstation.” This prompt is part of the default configuration settings in the DISCO Diffusion\nnotebook.2\nPrompt engineering is not a hard science as found in the fields of science, technology, engineering,\nand mathematics (STEM). Rather, it is a term that originates from within the online community of\npractitioners of text-to-image generation. The term reflects the community’s self-understanding,\nsimilar to the terms “AI art” and “AI artist” which also originate from within the community. Due to\nthe rise in popularity of text-to-image systems, practitioners of AI art include not only technology-\nsavvy developers and early-adopting hobbyists, but also artists, professionals, semi-professionals,\nand “Pro-Ams” [23] with or without commercial interests. In the remainder of this paper, we will\nrefer to the members of the online text-to-image community as practitioners.\nPrompt engineering resembles a conversation with the text-to-image system. A practitioner\ntypically will run a prompt, observe the outcome, and adapt the prompt to improve the outcome.\nPrompt engineering, thus, is iterative and practitioners formulate prompts as probes into the\ngenerative models’ latent space. The online community quickly found that the aesthetic qualities\nand subjective attractiveness of images can be improved by adding certain keywords and key\nphrases to the textual input prompts. The terms may be referred to by a number of different names,\nsuch as “style phrases,” “clarifying keywords” [39], or “vitamin phrases” [42]. In this paper, we refer\n2See https://github.com/alembics/disco-diffusion.\n",
    "book_id": "220413988v3",
    "book_title": "A Taxonomy of Prompt Modifiers for Text-To-Image Generation",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 49
  },
  {
    "chunk_full": "Taxonomy of Prompt Modifiers\n5\nto them as prompt modifiers. By adding a prompt modifier to a textual input, one seeks to direct the\ntext-to-image system in certain directions, hence “modifying” the resulting image.\nIn practice, prompt modifiers are applied through experimentation or based on best practices\nlearned from experience or online resources. An example of an iterative application of prompt\nmodifiers can be seen in Figure 3. Knowing what prompt modifiers work best for a given subject term\nis often the result of the practitioner’s iterative experimentation, research in online communities, and\nthe use of online tools and resources created for supporting the practice of prompt engineering [37].\na)\nb)\nc)\nd)\nText prompts:\na) “ufo landing”\nb) “ufo landing, daguerreotype”\nc) “ufo landing, daguerreotype, trending on /r/art”\nd) “ufo landing, daguerreotype, by greg rutkowski, trending on /r/art”\nFig. 3. Example of iterative prompt engineering for generating an image. Images generated with VQGAN–\nCLIP by Crowson et al. [9] with 175 iterations, CLIP model ViT-B/32, VQGAN model wikiart_16384, and seed\n6087304447281500163.\n3\nMETHOD\nIn this research, a dual-methodological approach was adopted, leveraging both autoethnographic\n(Section 3.1) and online ethnographic studies (Section 3.2), to delve into the nuanced aspects of\nprompt engineering and text-to-image art generation. Understanding the intricacies of prompt\nengineering, an acquired skill cultivated through iterative experimentation, necessitates a hands-on,\nexperiential approach. Hence, autoethnography provided a fitting method to gain an intimate,\npractitioner’s perspective. By conducting an autoethnographic study, the author was able to engage\nwith the process of text-to-image synthesis personally, thereby capturing its nuances from a first-\nhand perspective. However, the complex and communal nature of this emerging field necessitated\na broader perspective. To capture the collective wisdom and shared practices within the field,\nthe author further complemented the autoethnographic approach with an online ethnography of\nthe text-to-image art community. This approach allowed the author to glean insights from the\nshared experiences and resources of the broader community of practitioners active in online spaces,\nprimarily on Twitter. The synthesis of these two complementary approaches aimed to provide\na comprehensive understanding of prompt engineering, bridging the gap between individual\nexperience and collective knowledge.\n3.1\nAutoethnographic Research on Prompt Engineering\nPrompt engineering is learned through iterative experimentation akin to “brute-force trial and\nerror” [28]. Therefore, prompt engineering is an acquired skill that is associated with a learning\n",
    "book_id": "220413988v3",
    "book_title": "A Taxonomy of Prompt Modifiers for Text-To-Image Generation",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 50
  },
  {
    "chunk_full": "6\nJonas Oppenlaender\ncurve. The skill can be learned from community-provided resources, such as written guides and\nreports of systematic experimentation, or from prompts shared on social media, such as online\ncommunities dedicated to text-to-image art [37]. However, to appreciate and understand the craft of\nprompt engineering and text-to-image generation, one has to apply the knowledge and experiment\nwith different input prompts. Autoethnography research is, therefore, an appropriate method to\nlearn about prompt engineering.\nThe author conducted a 3-month autoethnographic study [10, 11, 13] between October 2021\nand December 2021. This personal ethnography [7] allowed the author to get a “practitioner’s\nperspective” [11] of text-to-image generation by “learning from self-use” [33]. The author experi-\nmented with text-to-image synthesis and created digital images with a text-to-image system using\nnotebooks hosted on Google’s Colaboratory (Colab).3 The author started on average at least one\nColab session every work day between October 4 and December 31, 2021. The free tier of Google\nColab was used in all sessions. This limited the overall working time to about 2 hours per day,\ndepending on the computational power of the assigned resources and whether penalties were\nincurred the previous day. VQGAN–CLIP by Crowson et al. [9] was chosen as text-to-image system\nusing a notebook titled “VQGAN and CLIP (z + quantize method with augmentations)”.4 This\nVQGAN–CLIP notebook was originally created by Katherine Crowson, with “modifications by\nEleiber # 8347” and a “friendly interface” by “Abulafia # 3734” and further modifications by Justin\nJohn. VQGAN–CLIP was selected for several reasons. First, VQGAN–CLIP was one of the first\ntext-to-image systems that experienced widespread popularity in the emerging text-to-image art\ncommunity in 2021. This made VQGAN–CLIP instrumental to the growth of the community [9].\nSecond, the system can be executed on Google’s Colaboratory (Colab) free of charge. The system\nrequires less memory than later systems, and it is therefore less likely that image generation will\nfail due to insufficient memory. Third, the VQGAN–CLIP notebook on Colab is very accessible\nand straight-forward to use, with only a small number of configuration parameters (cf. Figure 3).\nLast, the system is deterministic. Consecutive runs with the same configuration parameters will\nproduce exactly the same images which makes the images reproducible. This is not the case with\nsome of the later systems which make use of non-deterministic algorithms. The author generated\n885 images in the course of this study.\nThe autoethnographic research was not conducted from scratch. Rather, it was informed by\nlearning from the community on social media. To this end, the autoethnographic research was\ncomplemented with an online ethnography of the text-to-image art community on Twitter and a\nstudy of online community resources, described in the following section.\n3.2\nEthnographic Study of the Text-to-Image Art Community\nAn ethnographic study of prompt engineering was conducted on Twitter (see Section 3.2.1). The\naim of this social media ethnography [40, 41] was to learn more about the textual prompts used\nin the community of practitioners of text-to-image art. Insights derived from the study of this\ncommunity were used in the autoethnographic experimentation with the text-to-image system.\nThe research was complemented with a review of the literature (Section 3.2.2).\n3.2.1\nTwitter community. A dedicated online community around text-to-image generation with\nspecific focus on AI generated art – which practitioners in the online community sometimes refer\nto as “AI art” [30] – has emerged. Social media services, such as Twitter, are a well-suited outlet for\npractitioners in this community to post and share images and experiences.\n3https://colab.research.google.com\n4https://colab.research.google.com/github/justinjohn0306/VQGAN-CLIP/blob/main/VQGAN%2BCLIP(Updated).ipynb\n",
    "book_id": "220413988v3",
    "book_title": "A Taxonomy of Prompt Modifiers for Text-To-Image Generation",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 51
  },
  {
    "chunk_full": "Taxonomy of Prompt Modifiers\n7\nDuring the 3-month period of research, the author took the role of “participant-as-observer” [20]\nby engaging with the text-to-image art community on Twitter, participating in discussions, and\nposting images created with the text-to-image system. The author followed posts on Twitter to\nlearn about different prompts used in the text-to-image art community. To this end, the author\nfollowed trending hashtags, such as #vqganclip, #VQGAN, #clipguideddiffusion, #digitalart, #AIArt,\nand #generativeart. Not every practitioner of text-to-image art shares their prompts on Twitter.\nEspecially if commercial interests are involved – e.g., selling the art as non-fungible tokens (NFTs) –\npractitioners may keep their prompts a secret. The research material, therefore, was sparse at\nthe time of conducting the study. However, some practitioners are more liberal in sharing their\nprompts. It is the posts from this group of Twitter users that informed this research (e.g., posts by\nKatherine Crowson (@RiversHaveWings), Hannah Johnston (@hannahjdotca), @nshepperd1, and\nJohn David Pressman (@jd_pressman), to name but a few).\n3.2.2\nReview of community resources. In parallel to the research on the online community, a review\nof the literature was conducted, with specific focus on text-to-image generation and the practice of\nprompt engineering for digital art. With the exception of Liu and Chilton’s design guidelines for\nprompt engineering [28, 43], there still is little scholarly literature on the practice of text-to-image\ngeneration for AI generated art in the field of HCI. Therefore, the literature review primarily\nfocused on sources in the gray literature, such as community-provided resources, documents,\nguides, experiment reports, blog posts, articles on the Web.\n3.3\nInductive Development of the Taxonomy\nThe taxonomy was developed inductively from pieces of information found during the research.\nDue to the relative scarcity of this material at the time of writing, the development of the taxonomy\nwas conducted iteratively, as follows. A list of potential candidates for prompt modifiers was\ninductively compiled and grouped. This list was subject to continual reinterpretation when novel\ninstances of prompts were encountered. Whenever a candidate for a novel type of prompt modifier\nwas found in a post on Twitter or the literature, the author revisited the list of prompt modifiers.\nTherefore, the resulting taxonomy was iteratively and inductively revised and expanded when new\ntypes of prompt modifiers were encountered. After some weeks of collecting data this way, the\nlist of prompt modifiers and taxonomy did no longer grow, even if instances of novel and atypical\nprompts were encountered. This indicates the completeness of the developed taxonomy.\nThe findings were documented in a PowerPoint presentation with text and images to produce\nan evocative and aesthetic description of the ethnographic research. This iteration also served as\nverification of the correctness of the taxonomy. The author’s creation of and engagement with\nthe presentation acted as a daily conversation with the research material. This allowed the author\nto concurrently and iteratively develop and articulate an understanding of the subject matter\nboth visually and textually. At the end of the research period, the author engaged in a summative\nanalysis [11] of the research material to review the completeness and consistency of the taxonomy.\n3.4\nSelf-Disclosure\nWhile the author has experimented with text-to-image systems and produced digital artworks with\nthese systems, the author is not an artist. The author’s background is in Computer Science with\nfocus on Human-Computer Interaction (HCI) and Social Computing. The research was conducted\nnot from a technical lens, but a human-centered lens [21]. The author’s specific interest in prompt\nengineering is the text-based interactions of users with text-to-image systems and the novel creative\npractices that arise from these systems.\n",
    "book_id": "220413988v3",
    "book_title": "A Taxonomy of Prompt Modifiers for Text-To-Image Generation",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 52
  },
  {
    "chunk_full": "8\nJonas Oppenlaender\n4\nTAXONOMY OF PROMPT MODIFIERS\nThis research points towards there being six different types of prompt modifiers (subject terms,\nimage prompts, style modifiers, quality boosters, repeating terms, and magic terms) used by\npractitioners in the text-to-image art community (see summarized in Table 1). This taxonomy\nreflects the practitioner’s comprehension of prompt modifiers, a knowledge that was instrumental\nin classifying these modifiers into six distinct categories.\nTable 1. Taxonomy of prompt modifiers.\nModifier\nDescription\nSubject term\nDenotes the subject\nStyle modifier\nIndicates an artistic style\nImage prompt\nIndicates a style or subject via an image\nQuality booster\nA term intended to improve the quality of the image\nRepeating term\nRepetition of subject terms or style terms with the intention of strengthening this subject\nor style\nMagic term\nA term that is semantically different from the rest of the prompt with the intention to\nproduce surprising results\nSubject terms indicate the desired subject to the text-to-image system (e.g., “a landscape” or\n“an old car in a meadow”). While it is possible to generate images without subject terms, the subject\nis essential for controlling the image generation process. On the other hand, since text-to-image\nsystems were trained on images in context of their descriptive text, subject terms can, in some cases,\nhave less control over the outcome. One such case is the artist Zdzisław Beksiński who developed\na unique and recognizable style but never provided titles for his artworks. For this reason, early\ntext-to-image systems, such as VQGAN–CLIP, struggled to reliably reproduce specific subjects in\nimages generated to resemble Beksiński’s artworks.\nStyle modifiers can be added to a prompt to produce images in a certain style. Style modifiers\nwill consistently reproduce a characteristic style (e.g., “oil painting”) or artistic medium (e.g.,\n“mixed media”). For instance, the modifier “by Francisco Goya” will generate digital images in the\nrecognizable style of the late Spanish painter. Other examples of this type of modifier include, but\nare not limited to, “oil on canvas,” “#pixelart,” “hyperrealistic,” “abstract painting,” “surreal,” “Cubism”\nor “cubist,” “cabinet card,” “in the style of a cartoon,” “by Claude Lorrain,” and “in the style of Hudson\nRiver School,” to name but a few. As can be seen from the above list, style modifiers can include\ninformation about art periods, schools, and styles, but also art materials and media, techniques, and\nartists. When it comes to the latter, modifiers such as “by Greg Rutkowski” and “by James Gurney”\nhave become popular in the community of text-to-image art as a means to produce images in a\ncertain style and quality.\nImage prompts act similar to subject terms and style modifiers in that they provide the text-to-\nimage system a (visual) target for the synthesis of the image (both in terms of style and subject).\nImage prompts are typically specified as one or several urls that are added to the textual input\nprompt or provided in a separate array. Image prompts are different from “initial images” which\nwere investigated by Qiao et al. [43]. Whereas an image prompt can consist of multiple images,\nthere can only be one initial image. This initial image can be specified as a starting point for the\nimage generation, for instance, for the purpose of enhancing or distorting the initial image. This\nis made possible because of the iterative nature of the image generation process which typically\nstarts with an image filled with random noise (such as Perlin noise).\n",
    "book_id": "220413988v3",
    "book_title": "A Taxonomy of Prompt Modifiers for Text-To-Image Generation",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 53
  },
  {
    "chunk_full": "Taxonomy of Prompt Modifiers\n9\nQuality boosters can be added to a prompt to increase aesthetic qualities and the level of detail\nin images. Examples of this type of modifier are the terms “trending on artstation,” “award-winning,”\n“masterpiece,” “highly detailed”, “awesome,” “#wow,” “epic,” and “rendered in Unreal Engine.” This\ntype of modifier can also be applied in the form of “extra fluff” added to the prompt. Verbosity\nin the prompt may boost the amount of details and overall quality of the generated image, at the\nexpense of the subject becoming less controllable. For instance, the prompt “painting of an exploding\nheart” could potentially be improved by appending the modifiers “highly detailed, eclectic, fiery, vfx,\nrendered in octane, postprocessing, 8k.”\nRepeating terms can strengthen the associations formed by the generative system. For instance,\nthe prompt “space whale. a whale in space”5 by @nshepperd1 will likely produce subjectively better\nresults than either of the two subject terms alone. The use of different phrasing and synonyms will\ncause the text-to-image system to more reliably activate regions in the neural network’s latent\nspace that are associated with the subject terms. This is not only an imagined effect. The prompt “a\nvery very very very very beautiful landscape” will, for instance, likely produce a better image than a\nprompt without repeating terms. Technically, this is due to likelihood-maximizing language models\nbecoming stuck in positive feedback loops from repeated phrases [24].\nMagic terms introduce randomness to the image that can lead to surprising results. For instance,\nTwitter user @jd_pressman added the magic term “control the soul” to the prompt “orchestra\nconductor leading a chorus of sound wave audio waveforms swirling around him on the orchestral\nstage”.6 The term was added to – in Pressman’s words – produce “more magic, more wizard-ish\nimagery”.7 Magic terms, thus, introduce an element of unpredictability and surprise to the resulting\nimages, often with the intention of increasing the variation in the output. Magic terms can refer to\nterms that are semantically distant to the main subject of the prompt, or they can refer to non-visual\nqualities, such as the sense of touch (somatosensory), sense of hearing (auditory), sense of smell\n(olfactory), and sense of taste (gustatory) (e.g., “feed the soul” and “feel the sound”).\nIn summary, prompt modifiers come in a variety of types and can take different forms. They can,\nfor instance, be added as hash tags (e.g., “#wow”), attribution phrases (e.g., “by [artist]”), or more\ncomplex composite statements (e.g., “in the style of [artist]”). Further, not every part of a prompt\nhas the same importance and there are specific affordances of text-to-image systems that are being\nused in the practice of prompt engineering, as described in the following section.\n5\nPROMPT ENGINEERING IN PRACTICE\nThis section provides an overview of how the different types of prompt modifiers are being applied\nin the practice of prompt engineering with specific focus on the generation of static images from\neither textual or visual input prompts. We specifically focus on demonstrating and explaining the\niterative process of text-image generation with its iterative different steps (as described in Table 1).\nThe first step in iterative prompt design is to denote the subject with one or several terms.\nWhile images can be generated from random text or even single characters and emojis [37], the\nsubject term is fundamental to the controlled generation of digital images. Consequently, a prompt\ntypically contains at least one subject term. Any other parts of the prompt are optional. It is, for\ninstance, possible to generate artworks with the prompt “car.” In practice, however, practitioners\nuse modifiers to improve the resulting images and to exercise more control over the image creation\nprocess.\n5https://twitter.com/nshepperd1/status/1456584388037148678\n6https://twitter.com/jd_pressman/status/1457171648293924867\n7https://twitter.com/jd_pressman/status/1457445367125921793\n",
    "book_id": "220413988v3",
    "book_title": "A Taxonomy of Prompt Modifiers for Text-To-Image Generation",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 54
  },
  {
    "chunk_full": "10\nJonas Oppenlaender\nModifiers are typically added with the intention to either modify the style of the generated image\nor boost its quality. As mentioned in Section 4, style modifiers and quality boosters do not form a\ndisparate set. Rather, the two types of modifiers can have overlapping effects and the difference\nbetween the two types of prompt modifiers is sometimes not fully apparent. For instance, the\nmodifier “by Greg Rutkowski” exhibits this property. Greg Rutkowski8 is a contemporary illustrator\nand concept artist who has been embraced by the text-to-image art community in their practice of\nprompt engineering. Images generated with the modifiers “by greg rutkowski” or “in the style of\ngreg rutkowski” are of high quality, texture-rich, and contain a high amount of details. As such,\nthis modifier is often not used as a style modifier – as one would expect –, but as a quality booster\nin the community, even though a trained eye may tell by the style of the image that the prompt\nmodifier was being used.\nOnce a style modifier has been added, the style can be reinforced and “solidified” without losing\nexpressivity. Solidifiers (in the form of repeating terms) can be applied to any of the other types\nof modifiers (subjects, style modifiers, and quality boosters), although they are most commonly\napplied to subject terms. Image prompts are a special case in that they can carry both information\nabout the subject and style because of their visual nature. If the textual prompt is aligned with the\nimage prompt, the image prompt can also act as a solidifier. On the other hand, if several images\nthat are different from each other are added to the prompt, the image prompts will contribute\nto variation in the output. Last, magic terms may be optionally added to increase the chance\nof surprising results. The use of magic terms will result in more variation in the output, while\nmaintaining the overall style.\nEach of the six types of prompt modifiers can be assigned weights. Weighted terms can be\nnegative to exclude subjects and styles from being generated. For instance, VQGAN–CLIP tends to\ngenerate heart-shaped objects when the prompt contains the word “love.” By adding a negative\nweight to the prompt (e.g., “heart:-1”), the system can be instructed not to activate the corresponding\nlatents in its neural network. The resulting image is thus free from heart-shaped objects. Weighted\nterms can also be used to seamlessly mix styles. For instance, Twitter user @c0y0te6 mixed the\nstyles of two artists in the prompt “a painting of a high prestess [sic] summoning a demon by Ralph\nMcQuarrie:75 | by Zdzislaw Beksinski:25”.9 The style of Ralph McQuarrie is, in this case, given\nprecedence over the style of Zdzisław Beksiński (with a ratio of 3:1).\nTable 2 summarizes the iterative nature of prompt writing (c.f. Figure 3). Subject terms are most\nimportant for the controlled generation of images and usually written as first step. Modifiers and\nsolidifers are then added to the prompt, either iteratively (image after image) or from learned\nexperience. Last, weights can be applied to exclude or mix subjects and styles.\nTable 2. The iterative practice of prompt writing.\nStep\nPurpose\nPrompt modifier\nImportance\n1\nDefine\nsubject term, initial images, image prompt\nrequired\n2\nModify\nstyle modifier, quality booster, initial images, image prompt\noptional\n3\nSolidify\nrepeating terms, initial images\noptional\n4\nVary\nmagic terms, initial images\noptional\n5\nMix/Exclude\nmixing and exclusion\noptional\n8https://www.artstation.com/rutkowski\n9https://twitter.com/c0y0te6/status/1481780797858275329\n",
    "book_id": "220413988v3",
    "book_title": "A Taxonomy of Prompt Modifiers for Text-To-Image Generation",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 55
  },
  {
    "chunk_full": "Taxonomy of Prompt Modifiers\n11\n6\nDISCUSSION\nThe availability and accessibility of text-to-image generation as a new creative practice and artistic\nmedium [29], paired with a specific bundle of technologies and resources that support the ecosystem\nof this “emerging art scene” [37, 55], have resulted in an explosion of AI generated artworks being\nshared online. The application of prompt modifiers is key to the emerging creative practice called\nprompt engineering. The taxonomy of six different types of prompt modifiers represents an initial\nwork to bringing structure to the creation process and research in text-to-image systems. The\ntaxonomy of prompt modifiers is reified for the sparse HCI literature around prompt engineering\nas a logical building block in this emerging field of research.\nMidjourney has over 15 million members at the time of writing,10 and open source systems, such\nas Stable Diffusion, are available for execution on cloud or local hardware. Today, everyone is able\nto synthesize digital images and artworks from natural language using free or relatively inexpensive\nmeans, with implications for productivity and creativity [37]. Gartner estimated in 2021 that by the\nyear 2024, 80% of technology products and services will be built by people who are not technology\nprofessionals [18]. Increasingly, deep generative models will be used by laypeople without technical\nexpertise and skills. Interaction with opaque deep learning models will increasingly become more\ncommon in future use cases and applications of artificial intelligence. Therefore, prompt engineering\nis an emerging and important research area in the field of Human-Computer Interaction (HCI).\nHowever, with the exception of the design guidelines by Liu and Chilton [28] and Qiao et al. [43],\nthe scholarly literature in the field of HCI on prompt engineering still resembles a cottage industry,\nwith concepts and structures yet to emerge. Meanwhile, many resources started to emerge from\nwithin the online community, such as Smith’s “Traveler’s Guide to the Latent Space” [54] and\nParsons’s “DALL-E Prompt Book” [38]. Drawing on gray literature, such as the above, and extensive\nauto-ethnographic research, this work provides a taxonomy of prompt modifiers as a starting point\nfor systematizing the practice of prompt engineering for text-to-image generation. The subsequent\ndiscussion will examine the broader implications of prompt engineering for human-AI interaction.\n6.1\nBroader Implications for Human-AI Interaction\nResearch on prompt engineering has broader implications and is not only limited to the field of\ntext-to-image synthesis and AI generated art, but also relevant to the interaction of humans with\ndeep learning models and artificial intelligence in general.\n6.1.1\nAI and the future of creative work. There is much potential for deep learning to disrupt\nand transform entire sectors of the creative economy. Recently, there has been an interest into\ndeveloping generative systems that are able to synthesize more complex outcomes. For instance,\nsystems for text-to-video generation have been presented by Hong et al. [25], Ho et al. [22], Singer\net al. [53], and Villegas et al. [56]. Low-code and no-code tools for creating online products and\nexperiences will become increasingly common in the future. Declarative machine learning systems\nmay – as a next wave of machine learning – bring machine learning to non-coders [32]. This\ntechnology will extend the currently rather narrow focus of prompt engineering on language\nmodels and text-to-image synthesis to more broader application domains. In the future, we may\nsee deep generative models with generative capabilities that transcend what we can imagine today.\nDeep generative models could, for instance, create entire interactive story-driven worlds and games\nfrom short text prompts.\nSuch powerful AI-based systems will have implications for the future of creative work. Artificial\nintelligence will not only transform the way we interact with computers and perform work online,\n10See https://discord.com/servers.\n",
    "book_id": "220413988v3",
    "book_title": "A Taxonomy of Prompt Modifiers for Text-To-Image Generation",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 56
  },
  {
    "chunk_full": "12\nJonas Oppenlaender\nbut also the content of our work and the human agency in the work. An example of an application\nthat has such transformative potential is OpenAI’s Codex [5, 59]. Codex is a large language\nmodel that interprets commands in natural language and generates programming code. In the\nfuture, instead of typing code, we will be able to describe a software and its expected outputs in\nnatural language. Pre-trained generative models, such as Codex, BLOOM [3], or other “foundation\nmodels” [4], will then generate executable software code based on the human’s spoken or written\ninput prompts. This technology has already found application in GitHub’s CoPilot11, an “AI pair\nprogrammer” assisting its users in auto-completing programming code. In academia, researchers\nincreasingly rely on language models as creativity support tools for writing academic papers\n[26]. The change in the agency of humans and computers brought by generative models will be\ntransformative to creative work, such as software development and research.\n6.1.2\nBeyond text-to-image generation. The use case of art generated with text-to-image systems\ndiscussed in this paper is but one of many application areas of prompt engineering, with implications\nfor the future of creative work and Human-AI Interaction (HAI) in general. The latter can be viewed\nfrom many different perspectives, such as human-centered AI [52], human-AI partnerships [45],\nand human-AI cooperation [6]. Irrespective of the term used to describe our relationship with AI,\nwe will increasingly interact with opaque models through prompts in natural language.\nResearch on how to design prompts is therefore timely and important. Increasingly, we see\nuse-facing applications being powered by foundation-scale models. The emergent properties of\nthese models make it possible to use them for a vast number of different use cases and applications.\nInternally, such applications are often enabled by prompt engineering. For instance, tool-augmented\nlanguage models [31, 48] internally use prompts to enable the language model to use external\ntools. Research on prompt engineering, thus, will advance our understanding of how people can\neffectively interact with and employ machine learning models for solving complex tasks.\nWith these considerations in mind, we turn our attention to specific opportunities and challenges\nof prompt engineering within the field of Human-Computer Interaction (HCI).\n6.2\nOpportunities for Research on Prompt Engineering in HCI\nThis section discusses opportunities for future research on prompt engineering in the field of HCI.\nSpecifically, we touch on the community dynamics surrounding text-to-image art creation, novel\nworkflows and techniques employed by practitioners, and the embedded biases in AI-driven systems.\nAdditionally, we explore the relevance of prompt engineering for research on computational\naesthetics and human-AI alignment.\n6.2.1\nSocial aspects of prompt engineering. There are social components to the use of text-to-\nimage generation systems. Prompt engineers face an interesting challenge: Because text-to-image\nsystems were trained on images and text scraped from the Web, users of text-to-image systems\nneed to imagine and predict how other people described and reacted to images posted on the Web.\nDescribing an image in detail is often not enough to achieve optimal results – one has to imagine\nthe image as if it already existed on the Web.\nAnother social aspect in prompt engineering are the dedicated communities that came into\nexistence only recently. Practitioners of text-to-image art are producing artworks in shared Discord-\nbased chat rooms, such as on Midjourney.12 These dedicated communities offer a rich set of social\nfeatures worth investigating more closely in HCI research. For instance, members on Midjourney\nhave their own profiles that bundle the members’ successful creations together with the prompts\n11copilot.github.com\n12https://www.midjourney.com\n",
    "book_id": "220413988v3",
    "book_title": "A Taxonomy of Prompt Modifiers for Text-To-Image Generation",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 57
  },
  {
    "chunk_full": "Taxonomy of Prompt Modifiers\n13\nused to create the images. Midjourney introduced a 2D map in which members can explore other\nmembers based on the similarity of their prompts. Midjourney also has dedicated “group jam”\nsections in which members can iterate on and further develop other members’ works and there\nis a “theme of the day” section. Long running threads are quite common in this community.\nCommunity-learning is an interesting area of research in this regard. How do members receive and\nseek inspiration in the community? How do novices learn the craft of prompt engineering and is\nthere learning taking place in the community as a whole?\nFuture work could explore and ethnographically investigate the online community around text-\nto-image art and its prompt engineering practices in more detail, using the taxonomy presented in\nthis paper as a conceptual starting point or framework.\n6.2.2\nHuman-AI co-creation. While the heart piece of prompt engineering is prompt writing,\nprompt engineering is only a starting point in some practitioners’ creative work flows. Novel\ncreative practices are emerging. For instance, practitioners may develop complex work flows for\ncreating their artworks (e.g., generating initial images with one text-to-image system as a source\nfor inspiration, then continuing on another text-to-image system before finalizing the images\nin a photo editor). The different affordances of text-to-image systems still need to be reified and\nsystematized in the HCI community. For instance, some text-to-image systems enable the creation of\nzooming animations, others can complete parts of images which is called image inpainting [60] and\noutpainting.13 These novel creative practices offer a level of interactivity beyond mere generation\nof static images from textual input prompts. Further, practitioners may make certain idiosyncratic\nchoices when they create text-based generative art (e.g., selecting certain numerical values as seed\nfor the model or adapting the canvas size to certain subject terms). Some of these choices may\nfall into the realm of folk theories [14, 19] – that is, causal attributions that may or may not be\ntrue –, while other choices may be based on the practitioner’s experimentation and experience with\nprompt engineering. Future work could investigate these creative practices, work flows, strategies,\nand beliefs adopted by practitioners in the text-to-image art community. The emerging research\nfield also offers an opportunity for HCI researchers to make technical contributions [58] in the form\nof creativity support tools, user interfaces, and interactive experiences to support text-to-image\ngeneration, to teach novices the practice of prompt engineering, and to advance the emerging\nAI generated art ecosystem. Research in this space could make a timely contribution to a novel\ncomputational medium and an emerging digital art form.\n6.2.3\nBias in image generation systems. Another interesting area for future work is bias encoded\nin text-to-image generation systems. It has been shown, for instance, that the CLIP model contains\nbias14 and some text-to-image systems prompted with “princess” will produce images of women\nwith light skin color, reflecting the bias in the training data toward Western, educated, industrialized,\nrich and democratic (WEIRD) subjects.15 OpenAI recently announced that bias was reduced in\ntheir DALL-E 2 model [34], but at the cost of potentially reducing signal-to-noise of the generated\nimages.16\nResponsible deployment of large models and the potential risks are two concerns often listed for\nnot fully releasing a model. While organizations such as OpenAI and Google can be commended\nfor trying to be responsible with their powerful systems, these organizations act paternalistic and\nimpose their value and belief system onto their users which is another source of bias. DALL-E 2,\nin particular, can be a source of frustration for its users who are often faced with content policy\n13See, for instance, https://twitter.com/adampickard/status/1551584412659335168.\n14See https://twitter.com/RiversHaveWings/status/1432100170645180416.\n15See https://twitter.com/EMostaque/status/1495323912951021568.\n16See https://twitter.com/minimaxir/status/1549070583035416576.\n",
    "book_id": "220413988v3",
    "book_title": "A Taxonomy of Prompt Modifiers for Text-To-Image Generation",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 58
  },
  {
    "chunk_full": "14\nJonas Oppenlaender\nnotices for terms relating to war or sexual content (with a threat of account closure if the warning\nis incurred too often). Pressman et al. recently raised an important point: Humans are sexual beings\nand the androgynous values imposed on text-to-image systems with the intent of making them\n“safe-for-work” deprives users of “a key component of human aesthetic values and experience” [42].\n6.2.4\nComputational aesthetics and Human-AI alignment. The goal of making computers evaluate\nand understand aesthetics is much older than text-to-image generation [17]. Recently, there is\nrenewed research on neural image assessment and computational aesthetics. State-of-the-art text-to-\nimage systems increasingly consider human aesthetics in an attempt to produce better images [51].\nPrompts are a vast resource for research on computational aesthetics, as they encapsulate a person’s\nstated intent. This intent, however, is likely only partially explicit. Research on prompt engineering,\ntherefore, also relates to research on human-AI alignment [16]. This research area is concerned with\nteaching artificial intelligence to understand human values. Prompts for text-to-image generation\nsystems could form an interesting study resource for this kind of research.\n7\nCONCLUSION\nThis research contributes to the academic understanding of text-to-image generation by proposing\na novel taxonomy of six types of prompt modifiers: subject terms, image prompts, style modifiers,\nquality boosters, repeating terms, and magic terms. The taxonomy of prompt modifiers lays\nthe foundation for future structured investigations into prompt engineering for text-to-image\ngeneration and AI generated art. Moreover, the taxonomy highlights the unique affordances of\ntext-to-image systems, providing a clearer understanding of the design (“engineering”) of prompts\nfor image generation.\nIn the practice of prompt engineering for generating static images from textual or visual inputs,\nsubject terms are fundamental to the controlled creation of images. Practitioners often use prompt\nmodifiers to improve image quality and exercise greater control over the creation process. Modifiers\neither modify the image style or enhance its quality, and these two types can overlap in their\neffects. For example, the modifier “by Greg Rutkowski” is typically used by practitioners as a quality\nbooster rather than a style modifier, despite the artist’s distinct style. Solidifiers can also be used to\nreinforce a chosen style or subject without loss of expressivity. Image prompts, due to their visual\nnature, can carry information about both subject and style. The use of magic terms can increase\noutput variation while maintaining style. Additionally, prompt modifiers can be assigned weights\nto control image generation further. Negative weights can exclude certain subjects or styles, while\npositive weights can be used to mix styles. The process of prompt writing is iterative, starting with\nsubject terms, followed by the addition of modifiers and solidifiers, and finally applying weights\nfor precise control.\nThis work has illuminated the burgeoning field of prompt engineering, which is central to\nthe emerging practice of text-to-image synthesis and AI-generated art. The development of a\ntaxonomy of six types of prompt modifiers is a stepping stone to bring structure to this area of\nstudy. Future research will be critical in addressing several key areas, including the ethical and\nsocietal implications of AI-generated creative work, the social aspects of prompt engineering, the\nco-creation process between humans and AI, potential bias in image generation systems, and the\nalignment of AI with human values. As non-technical users increasingly interact with complex\nAI models, the need for HCI research in prompt engineering will only continue to grow. The\nexploration of these topics will not only advance our understanding of how people can effectively\ninteract with machine learning models, but also inform the design of future AI-driven systems and\ncontribute to the development of a novel digital art form.\n",
    "book_id": "220413988v3",
    "book_title": "A Taxonomy of Prompt Modifiers for Text-To-Image Generation",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 59
  },
  {
    "chunk_full": "Taxonomy of Prompt Modifiers\n15\nREFERENCES\n[1] ArtHub. 2022. arthub.ai. https://arthub.ai/ [Accessed Nov. 9, 2022].\n[2] Stephen Bach, Victor Sanh, Zheng Xin Yong, Albert Webson, Colin Raffel, Nihal V. Nayak, Abheesht Sharma, Taewoon\nKim, M Saiful Bari, Thibault Fevry, Zaid Alyafeai, Manan Dey, Andrea Santilli, Zhiqing Sun, Srulik Ben-david,\nCanwen Xu, Gunjan Chhablani, Han Wang, Jason Fries, Maged Al-shaibani, Shanya Sharma, Urmish Thakker, Khalid\nAlmubarak, Xiangru Tang, Dragomir Radev, Mike Tian-jian Jiang, and Alexander Rush. 2022. PromptSource: An\nIntegrated Development Environment and Repository for Natural Language Prompts. In Proceedings of the 60th\nAnnual Meeting of the Association for Computational Linguistics: System Demonstrations. Association for Computational\nLinguistics, Dublin, Ireland, 93–104. https://doi.org/10.18653/v1/2022.acl-demo.9\n[3] BigScience Initiative. 2022. Introducing The World’s Largest Open Multilingual Language Model: BLOOM. (2022).\nhttps://bigscience.huggingface.co/blog/bloom [Accessed Nov. 9, 2022]..\n[4] Rishi Bommasani, Drew A. Hudson, Ehsan Adeli, Russ Altman, Simran Arora, Sydney von Arx, Michael S. Bernstein,\nJeannette Bohg, Antoine Bosselut, Emma Brunskill, Erik Brynjolfsson, Shyamal Buch, Dallas Card, Rodrigo Castellon,\nNiladri Chatterji, Annie Chen, Kathleen Creel, Jared Quincy Davis, Dora Demszky, Chris Donahue, Moussa Doumbouya,\nEsin Durmus, Stefano Ermon, John Etchemendy, Kawin Ethayarajh, Li Fei-Fei, Chelsea Finn, Trevor Gale, Lauren\nGillespie, Karan Goel, Noah Goodman, Shelby Grossman, Neel Guha, Tatsunori Hashimoto, Peter Henderson, John\nHewitt, Daniel E. Ho, Jenny Hong, Kyle Hsu, Jing Huang, Thomas Icard, Saahil Jain, Dan Jurafsky, Pratyusha Kalluri,\nSiddharth Karamcheti, Geoff Keeling, Fereshte Khani, Omar Khattab, Pang Wei Koh, Mark Krass, Ranjay Krishna,\nRohith Kuditipudi, Ananya Kumar, Faisal Ladhak, Mina Lee, Tony Lee, Jure Leskovec, Isabelle Levent, Xiang Lisa Li,\nXuechen Li, Tengyu Ma, Ali Malik, Christopher D. Manning, Suvir Mirchandani, Eric Mitchell, Zanele Munyikwa,\nSuraj Nair, Avanika Narayan, Deepak Narayanan, Ben Newman, Allen Nie, Juan Carlos Niebles, Hamed Nilforoshan,\nJulian Nyarko, Giray Ogut, Laurel Orr, Isabel Papadimitriou, Joon Sung Park, Chris Piech, Eva Portelance, Christopher\nPotts, Aditi Raghunathan, Rob Reich, Hongyu Ren, Frieda Rong, Yusuf Roohani, Camilo Ruiz, Jack Ryan, Christopher\nRé, Dorsa Sadigh, Shiori Sagawa, Keshav Santhanam, Andy Shih, Krishnan Srinivasan, Alex Tamkin, Rohan Taori,\nArmin W. Thomas, Florian Tramèr, Rose E. Wang, William Wang, Bohan Wu, Jiajun Wu, Yuhuai Wu, Sang Michael\nXie, Michihiro Yasunaga, Jiaxuan You, Matei Zaharia, Michael Zhang, Tianyi Zhang, Xikun Zhang, Yuhui Zhang, Lucia\nZheng, Kaitlyn Zhou, and Percy Liang. 2021. On the Opportunities and Risks of Foundation Models. Technical Report.\nStanford University. https://crfm.stanford.edu/assets/report.pdf\n[5] Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards,\nYuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf,\nGirish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser,\nMohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings, Matthias Plappert,\nFotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss, William Hebgen Guss, Alex Nichol, Alex Paino, Nikolas Tezak,\nJie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders, Christopher Hesse, Andrew N. Carr, Jan\nLeike, Josh Achiam, Vedant Misra, Evan Morikawa, Alec Radford, Matthew Knight, Miles Brundage, Mira Murati,\nKatie Mayer, Peter Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, and Wojciech Zaremba.\n2021. Evaluating Large Language Models Trained on Code. (2021). arXiv:2107.03374 [cs.LG] [Preprint]. Available at:\nhttps://arxiv.org/abs/2107.03374 [Accessed Nov. 9, 2022]..\n[6] Jacob W. Crandall, Mayada Oudah, Tennom, Fatimah Ishowo-Oloko, Sherief Abdallah, Jean-François Bonnefon,\nManuel Cebrian, Azim Shariff, Michael A. Goodrich, and Iyad Rahwan. 2018. Cooperating with machines. Nature\nCommunications 9, 1 (2018), 12 pages. https://doi.org/10.1038/s41467-017-02597-8\n[7] Lyall Crawford. 1996. Personal ethnography. Communication Monographs 63, 2 (1996), 158–170. https://doi.org/10.\n1080/03637759609376384\n[8] Katherine\nCrowson.\n2021.\nCLIP\nGuided\nDiffusion\nHQ\n256x256.\n(2021).\nhttps://colab.research.google.com/drive/12a_Wrfi2_gwwAuN3VvMTwVMz9TfqctNj [Accessed Nov. 9, 2022].\n[9] Katherine Crowson, Stella Biderman, Daniel Kornis, Dashiell Stander, Eric Hallahan, Louis Castricato, and Edward\nRaff. 2022. VQGAN-CLIP: Open Domain Image Generation and Editing with Natural Language Guidance. In Computer\nVision – ECCV 2022, Shai Avidan, Gabriel Brostow, Moustapha Cissé, Giovanni Maria Farinella, and Tal Hassner (Eds.).\nSpringer Nature, Cham, Switzerland, 88–105.\n[10] Norman K. Denzin and Yvonna S. Lincoln. 2017. The SAGE Handbook of Qualitative Research (5th ed.). SAGE, Thousand\nOaks, CA.\n[11] Margot Duncan. 2004. Autoethnography: Critical Appreciation of an Emerging Art. International Journal of Qualitative\nMethods 3, 4 (2004), 28–39. https://doi.org/10.1177/160940690400300403\n[12] Remi Durant. 2021. Artist Studies by @remi_durant. (2021). https://remidurant.com/artists/ [Accessed Nov. 9, 2022].\n[13] Carolyn Ellis, Tony E. Adams, and Arthur P. Bochner. 2011. Autoethnography: An Overview. Historical Social Research\n/ Historische Sozialforschung 36, 4 (138) (2011), 273–290. http://www.jstor.org/stable/23032294\n",
    "book_id": "220413988v3",
    "book_title": "A Taxonomy of Prompt Modifiers for Text-To-Image Generation",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 60
  },
  {
    "chunk_full": "16\nJonas Oppenlaender\n[14] Motahhare Eslami, Karrie Karahalios, Christian Sandvig, Kristen Vaccaro, Aimee Rickman, Kevin Hamilton, and Alex\nKirlik. 2016. First I \"like\" It, Then I Hide It: Folk Theories of Social Feeds. In Proceedings of the 2016 CHI Conference on\nHuman Factors in Computing Systems (CHI ’16). Association for Computing Machinery, New York, NY, 2371–2382.\nhttps://doi.org/10.1145/2858036.2858494\n[15] Harmeet Gabha. 2022. Disco Diffusion 70+ Artist Studies. (2022). https://weirdwonderfulai.art/resources/disco-\ndiffusion-70-plus-artist-studies/ [Accessed Nov. 9, 2022]..\n[16] Iason Gabriel. 2020. Artificial Intelligence, Values, and Alignment. Minds and Machines 30, 3 (2020), 411–437.\nhttps://doi.org/10.1007/s11023-020-09539-2\n[17] Philip Galanter. 2012. Computational Aesthetic Evaluation: Past and Future. Springer Berlin Heidelberg, Berlin,\nHeidelberg, 255–293. https://doi.org/10.1007/978-3-642-31727-9_10\n[18] Gartner. 2021. Gartner Says the Majority of Technology Products and Services Will Be Built by Professionals Outside\nof IT by 2024. Press release. (14 June 2021). https://www.gartner.com/en/newsroom/press-releases/2021-06-10-gartner-\nsays-the-majority-of-technology-products-and-services-will-be-built-by-professionals-outside-of-it-by-2024 [Ac-\ncessed Nov. 9, 2022].\n[19] Susan A. Gelman and Cristine H. Legare. 2011. Concepts and folk theories. Annual Review of Anthropology 40 (2011),\n379–398. https://doi.org/10.1146/annurev-anthro-081309-145822\n[20] Raymond L. Gold. 1958. Roles in Sociological Field Observations. Social Forces 36, 3 (1958), 217–223. http://www.jstor.\norg/stable/2573808\n[21] Mark Guzdial. 2013. Human-Centered Computing: A New Degree for Licklider’s World. Commun. ACM 56, 5 (may\n2013), 32–34. https://doi.org/10.1145/2447976.2447987\n[22] Jonathan Ho, William Chan, Chitwan Saharia, Jay Whang, Ruiqi Gao, Alexey Gritsenko, Diederik P. Kingma, Ben\nPoole, Mohammad Norouzi, David J. Fleet, and Tim Salimans. 2022. Imagen Video: High Definition Video Generation\nwith Diffusion Models. (2022). [Preprint]. Available at: https://arxiv.org/abs/2210.02303 [Accessed Nov. 14, 2022]..\n[23] Michaela Hoare, Steve Benford, Rachel Jones, and Natasa Milic-Frayling. 2014. Coming in from the Margins: Amateur\nMusicians in the Online Age. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI\n’14). Association for Computing Machinery, New York, NY, 1295–1304. https://doi.org/10.1145/2556288.2557298\n[24] Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, and Yejin Choi. 2020. The curious case of neural text degeneration. In\nProceedings of the International Conference on Learning Representations (ICLR ’20). 16 pages.\n[25] Wenyi Hong, Ming Ding, Wendi Zheng, Xinghan Liu, and Jie Tang. 2022. CogVideo: Large-scale Pretraining for\nText-to-Video Generation via Transformers. (2022). https://doi.org/10.48550/ARXIV.2205.15868 [Preprint]. Available\nat: https://arxiv.org/pdf/2205.15868v1.pdf [Accessed Nov. 9, 2022]..\n[26] Matthew Hutson. 2022. Could AI help you to write your next paper? Nature 611 (2022), 192–193.\n[27] Lexica.art. 2022. Lexica.art. https://lexica.art/ [Accessed Nov. 9, 2022].\n[28] Vivian Liu and Lydia B Chilton. 2022. Design Guidelines for Prompt Engineering Text-to-Image Generative Models. In\nProceedings of the 2022 CHI Conference on Human Factors in Computing Systems (CHI ’22). Association for Computing\nMachinery, New York, NY, Article 384, 23 pages. https://doi.org/10.1145/3491102.3501825\n[29] Jon McCormack, Camilo Cruz Gambardella, Nina Rajcic, Stephen James Krol, Maria Teresa Llano, and Meng Yang.\n2023. Is Writing Prompts Really Making Art? https://doi.org/10.48550/ARXIV.2301.13049\n[30] Jon McCormack, Toby Gifford, and Patrick Hutchings. 2019. Autonomy, Authenticity, Authorship and Intention in\nComputer Generated Art. In Computational Intelligence in Music, Sound, Art and Design, Anikó Ekárt, Antonios Liapis,\nand María Luz Castro Pena (Eds.). Springer International Publishing, Cham, 35–50.\n[31] Grégoire Mialon, Roberto Dessì, Maria Lomeli, Christoforos Nalmpantis, Ram Pasunuru, Roberta Raileanu, Baptiste\nRozière, Timo Schick, Jane Dwivedi-Yu, Asli Celikyilmaz, Edouard Grave, Yann LeCun, and Thomas Scialom. 2023.\nAugmented Language Models: a Survey. https://doi.org/10.48550/arXiv.2302.07842 arXiv:2302.07842 [cs.CL]\n[32] Piero Molino and Christopher Ré. 2021. Declarative Machine Learning Systems. Commun. ACM 65, 1 (dec 2021),\n42–49. https://doi.org/10.1145/3475167\n[33] Carman Neustaedter and Phoebe Sengers. 2012. Autobiographical Design in HCI Research: Designing and Learning\nthrough Use-It-Yourself. In Proceedings of the Designing Interactive Systems Conference (DIS ’12). Association for\nComputing Machinery, New York, NY, 514–523. https://doi.org/10.1145/2317956.2318034\n[34] OpenAI. 2022. Reducing Bias and Improving Safety in DALL·E 2. (18 July 2022). https://openai.com/blog/reducing-\nbias-and-improving-safety-in-dall-e-2/ [Accessed Nov. 9, 2022].\n[35] OpenAI. nd.. Completion – OpenAI API. (nd.). https://beta.openai.com/docs/guides/completion [Accessed Nov. 9,\n2022].\n[36] OpenArt.ai. 2022. OpenArt.ai. https://openart.ai/ [Accessed Nov. 9, 2022].\n[37] Jonas Oppenlaender. 2022. The Creativity of Text-to-Image Generation. In Proceedings of the 25th International\nAcademic Mindtrek conference (Academic Mindtrek ’22). ACM, 11 pages pages. https://doi.org/10.1145/3569219.3569352\n",
    "book_id": "220413988v3",
    "book_title": "A Taxonomy of Prompt Modifiers for Text-To-Image Generation",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 61
  },
  {
    "chunk_full": "Taxonomy of Prompt Modifiers\n17\n[38] Guy Parsons. 2022.\nThe DALL·E 2 Prompt Book.\nhttps://dallery.gallery/wp-content/uploads/2022/07/The-\nDALL%C2%B7E-2-prompt-book-v1.01.pdf [Accessed Nov. 9, 2022].\n[39] Nikita Pavlichenko and Dmitry Ustalov. 2022. Best Prompts for Text-to-Image Models and How to Find Them. (2022).\nhttps://doi.org/10.48550/ARXIV.2209.11711 [Preprint]. Available at: https://arxiv.org/abs/2209.11711 [Accessed Nov. 9,\n2022]..\n[40] Sarah Pink, Heather Horst, John Postill, Larissa Hjorth, Tania Lewis, and Jo Tacchi. 2016. Digital Ethnography: Principles\nand Practice. SAGE, London, UK.\n[41] John Postill and Sarah Pink. 2012. Social Media Ethnography: The Digital Researcher in a Messy Web. Media\nInternational Australia 145, 1 (2012), 123–134. https://doi.org/10.1177/1329878X1214500114\n[42] John David Pressman, Katherine Crowson, and Simulacra Captions Contributors. 2022. Simulacra Aesthetic Captions.\nTechnical Report Version 1.0. Stability AI. url https://github.com/JD-P/simulacra-aesthetic-captions .\n[43] Han Qiao, Vivian Liu, and Lydia Chilton. 2022. Initial Images: Using Image Prompts to Improve Subject Representation\nin Multimodal AI Generated Art. In Creativity and Cognition (C&C ’22). Association for Computing Machinery, New\nYork, NY, 15–28. https://doi.org/10.1145/3527927.3532792\n[44] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda\nAskell, Pamela Mishkin, Jack Clark, Gretchen Krueger, and Ilya Sutskever. 2021. Learning Transferable Visual\nModels From Natural Language Supervision. In Proceedings of the 38th International Conference on Machine Learning\n(Proceedings of Machine Learning Research, Vol. 139), Marina Meila and Tong Zhang (Eds.). PMLR, 8748–8763. https:\n//proceedings.mlr.press/v139/radford21a.html\n[45] Sarvapali D. Ramchurn, Sebastian Stein, and Nicholas R. Jennings. 2021. Trustworthy human-AI partnerships. iScience\n24, 8 (2021), 13 pages. https://doi.org/10.1016/j.isci.2021.102891\n[46] Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec Radford, Mark Chen, and Ilya Sutskever.\n2021. Zero-Shot Text-to-Image Generation. In Proceedings of the 38th International Conference on Machine Learning\n(Proceedings of Machine Learning Research, Vol. 139), Marina Meila and Tong Zhang (Eds.). PMLR, 8821–8831.\n[47] Laria Reynolds and Kyle McDonell. 2021. Prompt Programming for Large Language Models: Beyond the Few-Shot\nParadigm. In Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems (CHI EA ’21).\nAssociation for Computing Machinery, New York, NY, Article 314, 7 pages. https://doi.org/10.1145/3411763.3451760\n[48] Toran Bruce Richards. 2023. Significant-Gravitas/Auto-GPT GitHub repository. https://github.com/Significant-\nGravitas/Auto-GPT.\n[49] Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Björn Ommer. 2021. High-Resolution\nImage Synthesis with Latent Diffusion Models.\n(2021).\narXiv:2112.10752 [cs.CV]\n[Preprint]. Available at:\nhttps://arxiv.org/abs/2112.10752 [Accessed Nov. 9, 2022]..\n[50] Robin Rombach, Andreas Blattmann, and Björn Ommer. 2022. Text-Guided Synthesis of Artistic Images with Retrieval-\nAugmented Diffusion Models. (2022). [Preprint]. Available at: https://arxiv.org/abs/2207.13038 [Accessed Nov. 9,\n2022]..\n[51] Christoph Schuhmann. 2022. LAION-Aesthetics. https://laion.ai/blog/laion-aesthetics/ https://laion.ai/blog/laion-\naesthetics/ [Accessed Nov. 11, 2022].\n[52] Ben Shneiderman. 2020. Human-Centered Artificial Intelligence: Reliable, Safe & Trustworthy. International Journal\nof Human–Computer Interaction 36, 6 (2020), 495–504. https://doi.org/10.1080/10447318.2020.1741118\n[53] Uriel Singer, Adam Polyak, Thomas Hayes, Xi Yin, Jie An, Songyang Zhang, Qiyuan Hu, Harry Yang, Oron Ashual, Oran\nGafni, Devi Parikh, Sonal Gupta, and Yaniv Taigman. 2022. Make-A-Video: Text-to-Video Generation without Text-\nVideo Data. (2022). https://doi.org/10.48550/ARXIV.2209.14792 [Preprint]. Available at: https://arxiv.org/abs/2209.14792\n[Accessed Nov. 14, 2022]..\n[54] Ethan Smith. 2022. A Traveler’s Guide to the Latent Space. (2022). https://sweet-hall-e72.notion.site/A-Traveler-s-\nGuide-to-the-Latent-Space-85efba7e5e6a40e5bd3cae980f30235f [Accessed Nov. 9, 2022].\n[55] Charlie Snell. 2021. Alien Dreams: An Emerging Art Scene. (2021).\nhttps://ml.berkeley.edu/blog/posts/clip-art/\n[Accessed Nov. 9, 2022].\n[56] Ruben Villegas, Mohammad Babaeizadeh, Pieter-Jan Kindermans, Hernan Moraldo, Han Zhang, Mohammad Taghi\nSaffar, Santiago Castro, Julius Kunze, and Dumitru Erhan. 2022. Phenaki: Variable Length Video Generation from\nOpen Domain Textual Descriptions. (2022). https://openreview.net/forum?id=vOEXS39nOF [Accessed Nov. 14, 2022].\n[57] Zijie J. Wang, Evan Montoya, David Munechika, Haoyang Yang, Benjamin Hoover, and Duen Horng Chau. 2022.\nDiffusionDB: A Large-scale Prompt Gallery Dataset for Text-to-Image Generative Models. (2022). https://doi.org/10.\n48550/ARXIV.2210.14896 [Preprint]. Available at: https://arxiv.org/abs/2210.14896 [Accessed Nov. 9, 2022]..\n[58] Jacob O. Wobbrock and Julie A. Kientz. 2016. Research Contributions in Human-Computer Interaction. Interactions 23,\n3 (2016), 38–44. https://doi.org/10.1145/2907069\n[59] Wojciech Zaremba and Greg Brockman. 2021. OpenAI Codex. (2021). https://openai.com/blog/openai-codex [Accessed\nNov. 9, 2022].\n",
    "book_id": "220413988v3",
    "book_title": "A Taxonomy of Prompt Modifiers for Text-To-Image Generation",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 62
  },
  {
    "chunk_full": "18\nJonas Oppenlaender\n[60] Lisai Zhang, Qingcai Chen, Baotian Hu, and Shuoran Jiang. 2020. Text-Guided Neural Image Inpainting. Association\nfor Computing Machinery, New York, NY, 1302–1310. https://doi.org/10.1145/3394171.3414017\n",
    "book_id": "220413988v3",
    "book_title": "A Taxonomy of Prompt Modifiers for Text-To-Image Generation",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 63
  },
  {
    "chunk_full": "Published in Transactions on Machine Learning Research (08/2022)\nEmergent Abilities of Large Language Models\nJason Wei 1\njasonwei@google.com\nYi Tay 1\nyitay@google.com\nRishi Bommasani 2\nnlprishi@stanford.edu\nColin Raﬀel 3\ncraﬀel@gmail.com\nBarret Zoph 1\nbarretzoph@google.com\nSebastian Borgeaud 4\nsborgeaud@deepmind.com\nDani Yogatama 4\ndyogatama@deepmind.com\nMaarten Bosma 1\nbosma@google.com\nDenny Zhou 1\ndennyzhou@google.com\nDonald Metzler 1\nmetzler@google.com\nEd H. Chi 1\nedchi@google.com\nTatsunori Hashimoto 2\nthashim@stanford.edu\nOriol Vinyals 4\nvinyals@deepmind.com\nPercy Liang 2\npliang@stanford.edu\nJeﬀDean 1\njeﬀ@google.com\nWilliam Fedus 1\nliamfedus@google.com\n1Google Research\n2Stanford University\n3UNC Chapel Hill\n4DeepMind\nReviewed on OpenReview: https://openreview.net/forum?id=yzkSU5zdwD\nAbstract\nScaling up language models has been shown to predictably improve performance and sample\neﬃciency on a wide range of downstream tasks. This paper instead discusses an unpredictable\nphenomenon that we refer to as emergent abilities of large language models. We consider an\nability to be emergent if it is not present in smaller models but is present in larger models.\nThus, emergent abilities cannot be predicted simply by extrapolating the performance of\nsmaller models. The existence of such emergence raises the question of whether additional\nscaling could potentially further expand the range of capabilities of language models.\n1\nIntroduction\nLanguage models have revolutionized natural language processing (NLP) in recent years. It is now well-known\nthat increasing the scale of language models (e.g., training compute, model parameters, etc.) can lead to\nbetter performance and sample eﬃciency on a range of downstream NLP tasks (Devlin et al., 2019; Brown\net al., 2020, inter alia). In many cases, the eﬀect of scale on performance can often be methodologically\npredicted via scaling laws—for example, scaling curves for cross-entropy loss have been shown to empirically\nspan more than seven orders of magnitude (Kaplan et al., 2020; Hoﬀmann et al., 2022). On the other hand,\nperformance for certain downstream tasks counterintuitively does not appear to continuously improve as a\nfunction of scale, and such tasks cannot be predicted ahead of time (Ganguli et al., 2022).\nIn this paper, we will discuss the unpredictable phenomena of emergent abilities of large language models.\nEmergence as an idea has been long discussed in domains such as physics, biology, and computer science\n(Anderson, 1972; Hwang et al., 2012; Forrest, 1990; Corradini & O’Connor, 2010; Harper & Lewis, 2012, inter\n1\narXiv:2206.07682v2  [cs.CL]  26 Oct 2022\n",
    "book_id": "220607682v2",
    "book_title": "2206.07682v2",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 64
  },
  {
    "chunk_full": "Published in Transactions on Machine Learning Research (08/2022)\nalia). We will consider the following general deﬁnition of emergence, adapted from Steinhardt (2022) and\nrooted in a 1972 essay called “More Is Diﬀerent” by Nobel prize-winning physicist Philip Anderson (Anderson,\n1972):\nEmergence is when quantitative changes in a system result in qualitative changes in behavior.\nHere we will explore emergence with respect to model scale, as measured by training compute and number of\nmodel parameters. Speciﬁcally, we deﬁne emergent abilities of large language models as abilities that are\nnot present in smaller-scale models but are present in large-scale models; thus they cannot be predicted by\nsimply extrapolating the performance improvements on smaller-scale models (§2).1 We survey emergent\nabilities as observed in a range of prior work, categorizing them in settings such as few-shot prompting (§3)\nand augmented prompting strategies (§4). Emergence motivates future research on why such abilities are\nacquired and whether more scaling will lead to further emergent abilities, which we highlight as important\nquestions for the ﬁeld (§5).\n2\nEmergent Abilities Deﬁnition\nAs a broad concept, emergence is often used informally and can be reasonably interpreted in many diﬀerent\nways. In this paper, we will consider a focused deﬁnition of emergent abilities of large language models:\nAn ability is emergent if it is not present in smaller models but is present in larger models.\nEmergent abilities would not have been directly predicted by extrapolating a scaling law (i.e. consistent\nperformance improvements) from small-scale models. When visualized via a scaling curve (x-axis: model\nscale, y-axis: performance), emergent abilities show a clear pattern—performance is near-random until a\ncertain critical threshold of scale is reached, after which performance increases to substantially above random.\nThis qualitative change is also known as a phase transition—a dramatic change in overall behavior that would\nnot have been foreseen by examining smaller-scale systems (Huberman & Hogg, 1987).\nToday’s language models have been scaled primarily along three factors: amount of computation, number\nof model parameters, and training dataset size (Kaplan et al., 2020; Hoﬀmann et al., 2022). In this paper,\nwe will analyze scaling curves by plotting the performance of diﬀerent models where training compute for\neach model is measured in FLOPs on the x-axis (Hoﬀmann et al., 2022). Because language models trained\nwith more compute tend to also have more parameters, we additionally show plots with number of model\nparameters as the x-axis in Appendix D (see Figure 11 and Figure 12, as well as Figure 4 and Figure 10).\nUsing training FLOPs or model parameters as the x-axis produces curves with similar shapes due to the fact\nthat most dense Transformer language model families have scaled training compute roughly proportionally\nwith model parameters (Kaplan et al., 2020).\nTraining dataset size is also an important factor, but we do not plot capabilities against it because many\nlanguage model families use a ﬁxed number of training examples for all model sizes (Brown et al., 2020; Rae\net al., 2021; Chowdhery et al., 2022). Although we focus on training computation and model size here, there\nis not a single proxy that adequately captures all aspects of scale. For example, Chinchilla (Hoﬀmann et al.,\n2022) has one-fourth as many parameters as Gopher (Rae et al., 2021) but uses similar training compute; and\nsparse mixture-of-expert models have more parameters per training/inference compute than dense models\n(Fedus et al., 2021; Du et al., 2021). Overall, it may be wise to view emergence as a function of many\ncorrelated variables. For example, later in Figure 4 we will also plot emergence as a function of WikiText103\nperplexity (Merity et al., 2016), which happens to closely correlate with training computation for Gopher/\nChinchilla (though this correlation may not hold in the long-run).\nNote that the scale at which an ability is ﬁrst observed to emerge depends on a number of factors and is\nnot an immutable property of the ability. For instance, emergence may occur with less training compute\n1This survey focuses on pre-trained Transformer language models. Emergent abilities in NLP more broadly, however, could\ngo back to Miller et al. (2004), Liang (2005), or earlier.\n2\n",
    "book_id": "220607682v2",
    "book_title": "2206.07682v2",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 65
  },
  {
    "chunk_full": "Published in Transactions on Machine Learning Research (08/2022)\nor fewer model parameters for models trained on higher-quality data. Conversely, emergent abilities also\ncrucially depend on other factors such as not being limited by the amount of data, its quality, or the number\nof parameters in the model. Today’s language models are likely not trained optimally (Hoﬀmann et al., 2022),\nand our understanding of how to best train models will evolve over time. Our goal in this paper is not to\ncharacterize or claim that a speciﬁc scale is required to observe emergent abilities, but rather, we aim to\ndiscuss examples of emergent behavior in prior work.\n3\nFew-Shot Prompted Tasks\nLanguage \nmodel\nInput\nOutput\nReview: This movie sucks.\nSentiment: negative.\nReview: I love this movie.\nSentiment:\npositive.\nFigure 1: Example of an input and\noutput for few-shot prompting.\nWe ﬁrst discuss emergent abilities in the prompting paradigm, as pop-\nularized by GPT-3 (Brown et al., 2020).2 In prompting, a pre-trained\nlanguage model is given a prompt (e.g. a natural language instruction)\nof a task and completes the response without any further training\nor gradient updates to its parameters. Brown et al. (2020) proposed\nfew-shot prompting, which includes a few input-output examples in\nthe model’s context (input) as a preamble before asking the model to\nperform the task for an unseen inference-time example. An example prompt is shown in Figure 1.\nThe ability to perform a task via few-shot prompting is emergent when a model has random performance\nuntil a certain scale, after which performance increases to well-above random. Figure 2 shows eight such\nemergent abilities spanning ﬁve language model families from various work.\nBIG-Bench. Figure 2A–D depicts four emergent few-shot prompted tasks from BIG-Bench, a crowd-sourced\nsuite of over 200 benchmarks for language model evaluation (BIG-Bench, 2022). Figure 2A shows an arithmetic\nbenchmark that tests 3-digit addition and subtraction, as well as 2-digit multiplication. GPT-3 and LaMDA\n(Thoppilan et al., 2022) have close-to-zero performance for several orders of magnitude of training compute,\nbefore performance jumps to sharply above random at 2 · 1022 training FLOPs (13B parameters) for GPT-3,\nand 1023 training FLOPs (68B parameters) for LaMDA. Similar emergent behavior also occurs at around the\nsame model scale for other tasks, such as transliterating from the International Phonetic Alphabet (Figure 2B),\nrecovering a word from its scrambled letters (Figure 2C), and Persian question-answering (Figure 2D). Even\nmore emergent abilities from BIG-Bench are given in Appendix E.\nTruthfulQA. Figure 2E shows few-shot prompted performance on the TruthfulQA benchmark, which\nmeasures the ability to answer questions truthfully (Lin et al., 2021). This benchmark is adversarially curated\nagainst GPT-3 models, which do not perform above random, even when scaled to the largest model size.\nSmall Gopher models also do not perform above random until scaled up to the largest model of 5 · 1023\ntraining FLOPs (280B parameters), for which performance jumps to more than 20% above random (Rae\net al., 2021).\nGrounded conceptual mappings. Figure 2F shows the task of grounded conceptual mappings, where\nlanguage models must learn to map a conceptual domain, such as a cardinal direction, represented in a\ntextual grid world (Patel & Pavlick, 2022). Again, performance only jumps to above random using the largest\nGPT-3 model.\nMulti-task language understanding. Figure 2G shows the Massive Multi-task Language Understanding\n(MMLU) benchmark, which aggregates 57 tests covering a range of topics including math, history, law, and\nmore (Hendrycks et al., 2021a). For GPT-3, Gopher, and Chinchilla, models of ∼1022 training FLOPs (∼10B\nparameters) or smaller do not perform better than guessing on average over all the topics, scaling up to 3–5\n·1023 training FLOPs (70B–280B parameters) enables performance to substantially surpass random. This\nresult is striking because it could imply that the ability to solve knowledge-based questions spanning a large\ncollection of topics might require scaling up past this threshold (for dense language models without retrieval\nor access to external memory).\n2Though GPT-3 popularized prompting, the task setup has existed since before GPT-3 (Trinh & Le, 2018; McCann et al.,\n2018; Radford et al., 2019; Raﬀel et al., 2020).\n3\n",
    "book_id": "220607682v2",
    "book_title": "2206.07682v2",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 66
  },
  {
    "chunk_full": "Published in Transactions on Machine Learning Research (08/2022)\n1018 1020 1022 1024\n0\n10\n20\n30\n40\n50\nAccuracy (%)\n(A) Mod. arithmetic\n1018 1020 1022 1024\n0\n10\n20\n30\n40\n50\nBLEU (%)\n(B) IPA transliterate\n1018 1020 1022 1024\n0\n10\n20\n30\n40\n50\nExact match (%)\n(C) Word unscramble\nLaMDA\nGPT-3\nGopher\nChinchilla\nPaLM\nRandom\n1018 1020 1022 1024\n0\n10\n20\n30\n40\n50\nExact match (%)\n(D) Persian QA\n1020\n1022\n1024\n0\n10\n20\n30\n40\n50\n60\n70\nAccuracy (%)\n(E) TruthfulQA\n1020\n1022\n1024\n0\n10\n20\n30\n40\n50\n60\n70\nModel scale (training FLOPs)\nAccuracy (%)\n(F) Grounded mappings\n1020\n1022\n1024\n0\n10\n20\n30\n40\n50\n60\n70\nAccuracy (%)\n(G) Multi-task NLU\n1020\n1022\n1024\n0\n10\n20\n30\n40\n50\n60\n70\nAccuracy (%)\n(H) Word in context\nFigure 2: Eight examples of emergence in the few-shot prompting setting. Each point is a separate model.\nThe ability to perform a task via few-shot prompting is emergent when a language model achieves random\nperformance until a certain scale, after which performance signiﬁcantly increases to well-above random. Note\nthat models that used more training compute also typically have more parameters—hence, we show an\nanalogous ﬁgure with number of model parameters instead of training FLOPs as the x-axis in Figure 11.\nA–D: BIG-Bench (2022), 2-shot. E: Lin et al. (2021) and Rae et al. (2021). F: Patel & Pavlick (2022). G:\nHendrycks et al. (2021a), Rae et al. (2021), and Hoﬀmann et al. (2022). H: Brown et al. (2020), Hoﬀmann\net al. (2022), and Chowdhery et al. (2022) on the WiC benchmark (Pilehvar & Camacho-Collados, 2019).\nWord in Context. Finally, Figure 2H shows the Word in Context (WiC) benchmark (Pilehvar & Camacho-\nCollados, 2019), which is a semantic understanding benchmark. Notably, GPT-3 and Chinchilla fail to\nachieve one-shot performance of better than random, even when scaled to their largest model size of ∼5 · 1023\nFLOPs. Although these results so far may suggest that scaling alone may not enable models to solve WiC,\nabove-random performance eventually emerged when PaLM was scaled to 2.5·1024 FLOPs (540B parameters),\nwhich was much larger than GPT-3 and Chinchilla.\n4\nAugmented Prompting Strategies\nAlthough few-shot prompting is perhaps currently the most common way of interacting with large language\nmodels, recent work has proposed several other prompting and ﬁnetuning strategies to further augment the\nabilities of language models. If a technique shows no improvement or is harmful when compared to the\nbaseline of not using the technique until applied to a model of a large-enough scale, we also consider the\ntechnique an emergent ability.\n4\n",
    "book_id": "220607682v2",
    "book_title": "2206.07682v2",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 67
  },
  {
    "chunk_full": "Published in Transactions on Machine Learning Research (08/2022)\n1021 1022 1023 1024\n0\n5\n10\n15\n20\n25\nNo chain\nof thought\nChain of\nthought\nGSM8K Accuracy (%)\n(A) Math word\nproblems\n1021 1022 1023 1024\n30\n40\n50\n60\n70\nNo\ninstruction\ntuning\nInstruction\ntuning\n10 NLU task average\n(B) Instruction\nfollowing\n1019\n1020\n1021\n0\n20\n40\n60\n80\n100\nNo\nscratchpad\nScratchpad\nModel scale (training FLOPs)\nAccuracy (%)\n(C) 8-digit addition\n1022\n1023\n1024\n100\n101\nLetter\nchoices\nT/F\n% ECE (log-scale, decreasing)\n(D) Calibration\nFigure 3: Specialized prompting or ﬁnetuning methods can be emergent in that they do not have a positive\neﬀect until a certain model scale. A: Wei et al. (2022b). B: Wei et al. (2022a). C: Nye et al. (2021). D:\nKadavath et al. (2022). An analogous ﬁgure with number of parameters on the x-axis instead of training\nFLOPs is given in Figure 12. The model shown in A-C is LaMDA (Thoppilan et al., 2022), and the model\nshown in D is from Anthropic.\nMulti-step reasoning. Reasoning tasks, especially those involving multiple steps, have been challenging for\nlanguage models and NLP models more broadly (Rae et al., 2021; Bommasani et al., 2021; Nye et al., 2021). A\nrecent prompting strategy called chain-of-thought prompting enables language models to solve such problems\nby guiding them to produce a sequence of intermediate steps before giving the ﬁnal answer (Cobbe et al., 2021;\nWei et al., 2022b; Suzgun et al., 2022). As shown in Figure 3A, chain of thought prompting only surpasses\nstandard prompting without intermediate steps when scaled to 1023 training FLOPs (∼100B parameters).\nA similar emergence in performance gain was also observed when augmenting few-shot prompting with\nexplanations that came after the ﬁnal answer (Lampinen et al., 2022).\nInstruction following. Another growing line of work aims to better enable language models to perform\nnew tasks simply by reading instructions describing the task (without few-shot exemplars). By ﬁnetuning\non a mixture of tasks phrased as instructions, language models have been shown to respond appropriately\nto instructions describing an unseen task (Ouyang et al., 2022; Wei et al., 2022a; Sanh et al., 2022; Chung\net al., 2022). As shown in Figure 3B, Wei et al. (2022a) found that this instruction-ﬁnetuning technique hurts\nperformance for models of 7·1021 training FLOPs (8B parameters) or smaller, and only improves performance\nwhen scaled to 1023 training FLOPs (∼100B parameters) (though Sanh et al. (2022) found shortly after that\nthis instruction-following behavior could be also induced by ﬁnetuning smaller encoder-decoder T5 models).\nProgram execution. Consider computational tasks involving multiple steps, such as adding large numbers or\nexecuting computer programs. Nye et al. (2021) show that ﬁnetuning language models to predict intermediate\noutputs (“scratchpad”) enables them to successfully execute such multi-step computations. As shown in\nFigure 3C, on 8-digit addition, using a scratchpad only helps for models of ∼9 · 1019 training FLOPs (40M\nparameters) or larger.\nModel calibration. Finally, an important direction for deployment of language models studies is calibration,\nwhich measures whether models can predict which questions they will be able to answer correctly. Kadavath\net al. (2022) compared two ways of measuring calibration: a True/False technique, where models ﬁrst propose\nanswers and then evaluate the probability “P(True)” that their answers are correct, and more-standard\nmethods of calibration, which use the probability of the correct answer compared with other answer options.\nAs shown in Figure 3D, the superiority of the True/False technique only emerges when scaled to the largest\nmodel scale of ∼3 · 1023 training FLOPs (52B parameters).\n5\n",
    "book_id": "220607682v2",
    "book_title": "2206.07682v2",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 68
  },
  {
    "chunk_full": "Published in Transactions on Machine Learning Research (08/2022)\nTable 1: List of emergent abilities of large language models and the scale (both training FLOPs and number\nof model parameters) at which the abilities emerge.\nEmergent scale\nTrain. FLOPs Params.\nModel\nReference\nFew-shot prompting abilities\nr Addition/subtraction (3 digit)\n2.3E+22\n13B\nGPT-3\nBrown et al. (2020)\nr Addition/subtraction (4-5 digit)\n3.1E+23\n175B\nr MMLU Benchmark (57 topic avg.)\n3.1E+23\n175B\nGPT-3\nHendrycks et al. (2021a)\nr Toxicity classiﬁcation (CivilComments)\n1.3E+22\n7.1B\nGopher\nRae et al. (2021)\nr Truthfulness (Truthful QA)\n5.0E+23\n280B\nr MMLU Benchmark (26 topics)\n5.0E+23\n280B\nr Grounded conceptual mappings\n3.1E+23\n175B\nGPT-3\nPatel & Pavlick (2022)\nr MMLU Benchmark (30 topics)\n5.0E+23\n70B\nChinchilla\nHoﬀmann et al. (2022)\nr Word in Context (WiC) benchmark\n2.5E+24\n540B\nPaLM\nChowdhery et al. (2022)\nr Many BIG-Bench tasks (see Appendix E)\nMany\nMany\nMany\nBIG-Bench (2022)\nAugmented prompting abilities\nr Instruction following (ﬁnetuning)\n1.3E+23\n68B\nFLAN\nWei et al. (2022a)\nr Scratchpad: 8-digit addition (ﬁnetuning)\n8.9E+19\n40M\nLaMDA\nNye et al. (2021)\nr Using open-book knowledge for fact checking\n1.3E+22\n7.1B\nGopher\nRae et al. (2021)\nr Chain-of-thought: Math word problems\n1.3E+23\n68B\nLaMDA\nWei et al. (2022b)\nr Chain-of-thought: StrategyQA\n2.9E+23\n62B\nPaLM\nChowdhery et al. (2022)\nr Diﬀerentiable search index\n3.3E+22\n11B\nT5\nTay et al. (2022b)\nr Self-consistency decoding\n1.3E+23\n68B\nLaMDA\nWang et al. (2022b)\nr Leveraging explanations in prompting\n5.0E+23\n280B\nGopher\nLampinen et al. (2022)\nr Least-to-most prompting\n3.1E+23\n175B\nGPT-3\nZhou et al. (2022)\nr Zero-shot chain-of-thought reasoning\n3.1E+23\n175B\nGPT-3\nKojima et al. (2022)\nr Calibration via P(True)\n2.6E+23\n52B\nAnthropic\nKadavath et al. (2022)\nr Multilingual chain-of-thought reasoning\n2.9E+23\n62B\nPaLM\nShi et al. (2022)\nr Ask me anything prompting\n1.4E+22\n6B\nEleutherAI Arora et al. (2022)\n5\nDiscussion\nWe have seen that a range of abilities—in the few-shot prompting setup or otherwise—have thus far only\nbeen observed when evaluated on a suﬃciently large language model. Hence, their emergence cannot be\npredicted by simply extrapolating performance on smaller-scale models. Emergent few-shot prompted tasks\nare also unpredictable in the sense that these tasks are not explicitly included in pre-training, and we likely\ndo not know the full scope of few-shot prompted tasks that language models can perform. This raises the\nquestion of whether further scaling could potentially endow even-larger language models with new emergent\nabilities. Tasks that language models cannot currently do are prime candidates for future emergence; for\ninstance, there are dozens of tasks in BIG-Bench for which even the largest GPT-3 and PaLM models do not\nachieve above-random performance (see Appendix E.4).\nThe ability for scale to unpredictably enable new techniques is not just theoretical. Consider the Word in\nContext (WiC) benchmark (Pilehvar & Camacho-Collados, 2019) shown in Figure 2H, as a historical example.\nHere, scaling GPT-3 to around 3 · 1023 training FLOPs (175B parameters) failed to unlock above-random\none-shot prompting performance.3 Regarding this negative result, Brown et al. (2020) cited the model\narchitecture of GPT-3 or the use of an autoregressive language modeling objective (rather than using a\ndenoising training objective) as potential reasons, and suggested training a model of comparable size with\nbidirectional architecture as a remedy. However, later work found that further scaling a decoder-only language\nmodel was actually enough to enable above-random performance on this task. As is shown in Figure 2H,\nscaling PaLM (Chowdhery et al., 2022) from 3 · 1023 training FLOPs (62B parameters) to 3 · 1024 training\n3GPT-3 does achieve slightly above-random performance on the dev set with few-shot instead of one-shot prompting (∼55%),\nbut this above-random performance did not appear to be a result of scale and did not hold on the test set server.\n6\n",
    "book_id": "220607682v2",
    "book_title": "2206.07682v2",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 69
  },
  {
    "chunk_full": "Published in Transactions on Machine Learning Research (08/2022)\nFLOPs (540B parameters) led to a signiﬁcant jump in performance, without the signiﬁcant architectural\nchanges suggested by Brown et al. (2020).\n5.1\nPotential explanations of emergence\nAlthough there are dozens of examples of emergent abilities, there are currently few compelling explanations\nfor why such abilities emerge in the way they do. For certain tasks, there may be natural intuitions for why\nemergence requires a model larger than a particular threshold scale. For instance, if a multi-step reasoning\ntask requires l steps of sequential computation, this might require a model with a depth of at least O (l)\nlayers. It is also reasonable to assume that more parameters and more training enable better memorization\nthat could be helpful for tasks requiring world knowledge.4 As an example, good performance on closed-book\nquestion-answering may require a model with enough parameters to capture the compressed knowledge\nbase itself (though language model-based compressors can have higher compression ratios than conventional\ncompressors (Bellard, 2021)).\nIt is also important to consider the evaluation metrics used to measure emergent abilities (BIG-Bench,\n2022). For instance, using exact string match as the evaluation metric for long-sequence targets may disguise\ncompounding incremental improvements as emergence. Similar logic may apply for multi-step or arithmetic\nreasoning problems, where models are only scored on whether they get the ﬁnal answer to a multi-step\nproblem correct, without any credit given to partially correct solutions. However, the jump in ﬁnal answer\naccuracy does not explain why the quality of intermediate steps suddenly emerges to above random, and using\nevaluation metrics that do not give partial credit are at best an incomplete explanation, because emergent\nabilities are still observed on many classiﬁcation tasks (e.g., the tasks in Figure 2D–H).\nAs an alternative evaluation, we measure cross-entropy loss, which is used in scaling laws for pre-training, for\nthe six emergent BIG-Bench tasks, as detailed in Appendix A. This analysis follows the same experimental\nsetup from BIG-Bench (2022) and aﬃrms their conclusions for the six emergent tasks we consider. Namely,\ncross-entropy loss improves even for small model scales where the downstream metrics (exact match, BLEU,\nand accuracy) are close to random and do not improve, which shows that improvements in the log-likelihood\nof the target sequence can be masked by such downstream metrics. However, this analysis does not explain\nwhy downstream metrics are emergent or enable us to predict the scale at which emergence occurs. Overall,\nmore work is needed to tease apart what enables scale to unlock emergent abilities.\n5.2\nBeyond scaling\nAlthough we may observe an emergent ability to occur at a certain scale, it is possible that the ability could\nbe later achieved at a smaller scale—in other words, model scale is not the singular factor for unlocking\nan emergent ability. As the science of training large language models progresses, certain abilities may be\nunlocked for smaller models with new architectures, higher-quality data, or improved training procedures.\nFor example, there are 14 BIG-Bench tasks5 for which LaMDA 137B and GPT-3 175B models perform\nat near-random, but PaLM 62B in fact achieves above-random performance, despite having fewer model\nparameters and training FLOPs. While there is not an empirical study ablating every diﬀerence between\nPaLM 62B and prior models (the computational cost would be too high), potential reasons for the better\nperformance of PaLM could include high-quality training data (e.g., more multilingual and code data than\nLaMDA) and architectural diﬀerences (e.g., split digit-encodings; see Section 2 in Chowdhery et al. (2022)).\nAnother potentially way of unlocking emergence is through a diﬀerent pre-training objective—it was shown\nin Tay et al. (2022c) that a computationally-eﬃcient continued pre-training stage on a mixture-of-denoisers\nobjective (Tay et al., 2022a) enabled emergent performance on several BIG-Bench tasks.\nMoreover, once an ability is discovered, further research may make the ability available for smaller scale\nmodels. Consider the nascent direction of enabling language models to follow natural language instructions\ndescribing a task (Wei et al., 2022a; Sanh et al., 2022; Ouyang et al., 2022, inter alia). Although Wei et al.\n(2022a) initially found that instruction-based ﬁnetuning only worked for 68B parameter or larger decoder-only\n4Though note that encoding world knowledge in parameters is just one approach; there are others (e.g., Guu et al., 2020;\nBorgeaud et al., 2021).\n5These tasks are enumerated in Appendix F.\n7\n",
    "book_id": "220607682v2",
    "book_title": "2206.07682v2",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 70
  },
  {
    "chunk_full": "Published in Transactions on Machine Learning Research (08/2022)\nmodels, Sanh et al. (2022) induced similar behavior in a 11B model with an encoder-decoder architecture,\nwhich typically has higher performance after ﬁnetuning than decoder-only architectures (Wang et al., 2022a).\nAs another example, Ouyang et al. (2022) proposed a ﬁnetuning and reinforcement learning from human\nfeedback approach for the InstructGPT models, which enabled a 1.3B model to outperform much larger\nmodels in human-rater evaluations on a broad set of use cases.\nThere has also been work on improving the general few-shot prompting abilities of language models (Gao\net al., 2021; Schick & Schütze, 2021, inter alia). Theoretical and interpretability research (Wei et al., 2021a;\nSaunshi et al., 2021) on why a language modeling objective facilitates certain downstream behavior could in\nturn have implications on how to enable emergence beyond simply scaling. For instance, certain features of\npre-training data (e.g., long-range coherence, having many rare classes) have also been shown to correlate with\nemergent few-shot prompting and could potentially enable it in smaller models (Xie et al., 2022; Chan et al.,\n2022), and few-shot learning can require certain model architectures in some scenarios (Chan et al., 2022).\nComputational linguistics work has further shown how threshold frequencies of training data can activate\nemergent syntactic rule-learning when model parameters and training FLOPs are held constant (Wei et al.,\n2021b), which has even been shown to have striking “aha” moments similar to those in the psycholinguistics\nliterature (Abend et al., 2017; Zhang et al., 2021). As we continue to train language models, lowering the\nscale threshold for emergent abilities will become more important for making research on such abilities to\navailable to the community more broadly (Bommasani et al., 2021; Ganguli et al., 2022; Liang et al., 2022).\nNaturally, there are limitations to a program consisting only of increasing scale (training compute, model\nparameters, and dataset size). For instance, scaling may eventually be bottle-necked by hardware constraints,\nand some abilities may not have emerged at this point. Other abilities may never emerge—for instance, tasks\nthat are far out of the distribution of even a very large training dataset might not ever achieve any signiﬁcant\nperformance. Finally, an ability could emerge and then plateau; in other words, there is no guarantee that\nscaling enables an ability to reach the desired level.\n5.3\nAnother view of emergence\nWhile scale (e.g., training FLOPs or model parameters) has been highly correlated with language model\nperformance on many downstream metrics so far, scale need not be the only lens to view emergent abilities.\nFor example, the emergence of task-speciﬁc abilities can be analyzed as a function of the language model’s\nperplexity on a general text corpus such as WikiText103 (Merity et al., 2016). Figure 4 shows such a plot\nwith WikiText103 perplexity of the language model on the x-axis and performance on the MMLU benchmark\non the y-axis, side-by-side with plots of training FLOPs and model parameters on the x-axis.\nBecause WikiText103 perplexity and training FLOPs happen to be highly correlated for the models considered\nhere (Gopher and Chinchilla), the plots of emergent abilities look similar for both. However, this correlation\nbetween WikiText103 perplexity and scale may not hold in the future as new techniques beyond vanilla\ndense Transformer models are developed (e.g., retrieval-augmented models may have strong WikiText103\nperplexity with less training compute and fewer model parameters (Borgeaud et al., 2021)). Also note that\nusing WikiText103 perplexity to compare across model families can be complicated due to factors such as\ndiﬀerences in training data composition. Overall, emergent abilities should probably be viewed as a function\nof many correlated variables.\n5.4\nEmergent risks\nImportantly, similar to how emergent abilities have been observed in the few-shot prompting setting without\nexplicitly being included in pre-training, risks could also emerge (Bommasani et al., 2021; Steinhardt, 2021;\nGanguli et al., 2022). For instance, societal risks of large language models such as truthfulness, bias, and\ntoxicity are a growing area of research (Weidinger et al., 2021). Such risks are important considerations\nwhether or not they can be precisely characterized as “emergent” based on the deﬁnition in §2, and, in some\nscenarios, do increase with model scale (see the Inverse Scaling Prize6). Since work on emergent abilities\n6https://github.com/inverse-scaling/prize\n8\n",
    "book_id": "220607682v2",
    "book_title": "2206.07682v2",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 71
  },
  {
    "chunk_full": "Published in Transactions on Machine Learning Research (08/2022)\n1B\n10B 100B\n1021\n1022\n1023\n1024\nModel parameters\nTraining FLOPs\nTraining compute vs.\nmodel size\n1020\n1022\n1024\n20\n15\n10\n7\n5\nTraining FLOPs\nWikiText103 ppl\nWikiText103 ppl vs.\ntraining compute\n1B\n10B 100B\n20\n15\n10\n7\n5\nModel parameters\nWikiText103 ppl\nWikiText103 ppl vs.\nmodel size\n1020\n1022\n1024\n0\n20\n40\n60\n80\n100\nTraining FLOPs\nAccuracy (%)\nMMLU\n1B\n10B 100B\n0\n20\n40\n60\n80\n100\nModel parameters\nAccuracy (%)\nMMLU\nChinchilla\nGopher\nRandom\n20 15\n10\n7\n5\n0\n20\n40\n60\n80\n100\nWikiText103 ppl\nAccuracy (%)\nMMLU\nFigure 4: Top row: the relationships between training FLOPs, model parameters, and perplexity (ppl) on\nWikiText103 (Merity et al., 2016) for Chinchilla and Gopher. Bottom row: Overall performance on the\nmassively multi-task language understanding benchmark (MMLU; Hendrycks et al., 2021a) as a function of\ntraining FLOPs, model parameters, and WikiText103 perplexity.\nincentivizes scaling language models, it is important to be aware of risks that increase with model scale even\nif they are not emergent.\nHere, we summarize several prior ﬁndings on the relationship between speciﬁc social risks and model scale.\nOn WinoGender (Rudinger et al., 2017), which measures gender bias in occupations such as “nurse” or\n“electrician,” scaling has improved performance so far (Du et al., 2021; Chowdhery et al., 2022), though\nBIG-Bench (2022) found in BBQ bias benchmark (Parrish et al., 2022) that bias can increase with scaling for\nambiguous contexts. As for toxicity, Askell et al. (2021) found that while larger language models could produce\nmore toxic responses from the RealToxicityPrompts dataset (Gehman et al., 2020), this behavior could be\nmitigated by giving models prompts with examples of being “helpful, harmless, and honest.” For extracting\ntraining data from language models, larger models were found to be more likely to memorize training data\n(Carlini et al., 2021; 2022), though deduplication methods have been proposed and can simultaneously reduce\nmemorization while improving performance (Kandpal et al., 2022; Lee et al., 2022a). The TruthfulQA\nbenchmark (Lin et al., 2021) showed that GPT-3 models were more likely to mimic human falsehoods as they\ngot larger, though Rae et al. (2021) later showed on a multiple-choice version that scaling Gopher to 280B\nenabled emergent performance substantially better than random.\nBeyond the above, emergent risks also include phenomena that might only exist in future language models\nor that have not yet been characterized in current language models. Some such behaviors, as discussed\nin detail in Hendrycks et al. (2021b), could be backdoor vulnerabilities, inadvertent deception, or harmful\ncontent synthesis. Approaches involving data ﬁltering, forecasting, governance, and automatically discovering\nharmful behaviors have been proposed for discovering and mitigating emergent risks (Bender et al., 2021;\nWeidinger et al., 2021; Steinhardt, 2021; Ganguli et al., 2022; Perez et al., 2022, inter alia). For a more\ndetailed discussion of the risks of large language models, including emergent risks, see Bender et al. (2021);\nSteinhardt (2021); Bommasani et al. (2021); Ganguli et al. (2022).\n9\n",
    "book_id": "220607682v2",
    "book_title": "2206.07682v2",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 72
  },
  {
    "chunk_full": "Published in Transactions on Machine Learning Research (08/2022)\n5.5\nSociological changes\nFinally, the emergent abilities discussed here focus on model behavior and are just one of several types of\nemergence in NLP (Manning et al., 2020; Teehan et al., 2022). Another notable type of qualitative change is\nsociological, in which increasing scale has shifted how the community views and uses language models. For\ninstance, NLP has historically focused on task-speciﬁc models (Jurafsky & Martin, 2009). Recently, scaling\nhas led to an explosion in research on and development of models that are “general purpose” in that they are\nsingle models that aim to perform a range of tasks not explicitly encoded in the training data (e.g., GPT-3,\nChinchilla, and PaLM) (Manning, 2022).\nOne key set of results in the emergent sociological shift towards general-purpose models is when scaling\nenables a few-shot prompted general-purpose model to outperform prior state of the art held by ﬁnetuned\ntask-speciﬁc models. As a few examples, GPT-3 175B achieved new state of the art on the TriviaQA and\nPiQA question-answering benchmarks (Brown et al., 2020); PaLM 540B achieved new state of the art on three\narithmetic reasoning benchmarks (Chowdhery et al., 2022); and the multimodal Flamingo 80B model achieved\nnew state of the art on six visual question answering benchmarks (Alayrac et al., 2022). In all of these cases,\nstate-of-the-art performance was achieved by few-shot prompting a language model of unprecendented scale\n(scaling curves for these examples are shown in Appendix Figure 13). These abilities are not necessarily\nemergent since they have smooth, predictable scaling curves—however, they do underscore an emergent\nsociological shift towards general-purpose models in the NLP community.\nThe ability for general-purpose models to perform unseen tasks given only a few examples has also led to\nmany new applications of language models outside the NLP research community. For instance, language\nmodels have been used via prompting to translate natural language instructions into actions executable\nby robots (Ahn et al., 2022; Huang et al., 2022), interact with users (Coenen et al., 2021; Wu et al., 2021;\n2022a; Lee et al., 2022b), and facilitate multi-modal reasoning (Zeng et al., 2022; Alayrac et al., 2022). Large\nlanguage models have also been deployed in the real-world both in products, such as GitHub CoPilot,7 and\ndirectly as services themselves, such as OpenAI’s GPT-3 API.8\n5.6\nDirections for future work\nFuture work on emergent abilities could involve train more-capable language models, as well as methods for\nbetter enabling language models to perform tasks. Some potential directions include but are not limited to\nthe following.\nFurther model scaling. Further scaling up models has so far appeared to increase the capabilities of\nlanguage models, and is a straightforward direction for future work. However, simply scaling up language\nmodels is computationally expensive and requires solving substantial hardware challenges, and so other\napproaches will likely play a key role in the future of the emergent abilities of large language models.\nImproved model architectures and training. Improving model architecture and training procedures\nmay facilitate high-quality models with emergent abilities while mitigating computational cost. One direction\nis using sparse mixture-of-experts architectures (Lepikhin et al., 2021; Fedus et al., 2021; Artetxe et al.,\n2021; Zoph et al., 2022), which scale up the number of parameters in a model while maintaining constant\ncomputational costs for an input. Other directions for better computational eﬃciency could involve variable\namounts of compute for diﬀerent inputs (Graves, 2016; Dehghani et al., 2018), using more localized learning\nstrategies than backpropagation through all weights in a neural network (Jaderberg et al., 2017), and\naugmenting models with external memory (Guu et al., 2020; Borgeaud et al., 2021; Wu et al., 2022b, inter\nalia). These nascent directions have already shown promise in many settings but have not yet seen widespread\nadoption, which will likely require further work.\nData scaling. Training long enough on a large-enough dataset has been shown to be key for the ability of\nlanguage models to acquire syntactic, semantic, and other world knowledge (Zhang et al., 2021; Wei et al.,\n2021b; Razeghi et al., 2022). Recently, Hoﬀmann et al. (2022) argued that prior work (Kaplan et al., 2020)\n7https://copilot.github.com/\n8https://beta.openai.com/docs/introduction\n10\n",
    "book_id": "220607682v2",
    "book_title": "2206.07682v2",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 73
  },
  {
    "chunk_full": "Published in Transactions on Machine Learning Research (08/2022)\nunderestimated the amount of training data needed to train a compute-optimal model, underscoring the\nimportance of training data. Collecting large datasets so that models can be trained for longer could allow a\ngreater range of emergent abilities under a ﬁxed model size constraint.\nBetter techniques for and understanding of prompting. Although few-shot prompting (Brown et al.,\n2020) is simple and eﬀective, general improvements to prompting may further expand the abilities of language\nmodels. For instance, simple modiﬁcations such as calibrating output probabilities (Zhao et al., 2021;\nHoltzman et al., 2021) or using a noisy channel (Min et al., 2022a) have improved performance on a range of\ntasks. Augmenting few-shot exemplars with intermediate steps (Reynolds & McDonell, 2021; Nye et al., 2021;\nWei et al., 2022b) has also enabled models to perform multi-step reasoning tasks not possible in the standard\nprompting formulation from Brown et al. (2020). Moreover, better exploration of what makes prompting\nsuccessful (Wei et al., 2021a; Xie et al., 2022; Min et al., 2022b; Olsson et al., 2022) could lead to insights\non how to elicit emergent abilities at a smaller model scale. Suﬃcient understanding of why models work\ngenerally lags the development and popularization of techniques such as few-shot prompting, and it is also\nlikely that the best practices for prompting will change as more-powerful models are developed over time.\nFrontier tasks. Although language models can perform a wide range of tasks, there are still many tasks that\neven the largest language models to date cannot perform with above-random accuracy. Dozens of such tasks\nfrom BIG-Bench are enumerated in Appendix E.4; these tasks often involve abstract reasoning (e.g., playing\nChess, challenging math, etc). Future research could potentially investigate why these abilities have not yet\nemerged, and how to enable models to perform these tasks. Looking forward, another growing direction\ncould be multilingual emergence; results on multilingual BIG-Bench tasks indicate that both model scale and\ntraining data play a role in emergence (e.g., Figure 2D shows that both using PaLM’s training dataset and\nscaling to 62B parameters is required for question-answering in Persian). Other frontier tasks could include\nprompting in multiple modalities (Alayrac et al., 2022; Ramesh et al., 2022).\nUnderstanding emergence. Beyond research on unlocking further emergence, an open question for future\nresearch is how and why emergent abilities occur in large language models. This paper conducted initial\nanalyses regarding scaling of the cross-entropy loss on BIG-Bench (Appendix A.1), diﬀerent metrics for\ngenerative tasks (Appendix A.2), and which types of tasks emergence occurs (Appendix A.3 and Appendix B).\nThese analyses did not provide complete answers to why emergence occurs or how to predict it. Future\nresearch could potentially analyze emergence in new ways (e.g., analyze the relationship between emergent\ntasks and similar data in training; create a synthetic task that requires multiple compositional sub-tasks and\nevaluate how each of those sub-tasks improve with scale and unlock emergence when combined). Overall,\nunderstanding emergence is an important direction because it could potentially allow us predict what abilities\nfuture models may have, as well as provide new insights into how to train more-capable language models.\n6\nConclusions\nWe have discussed emergent abilities of language models, for which meaningful performance has only been\nthus far observed at a certain computational scale. Emergent abilities can span a variety of language models,\ntask types, and experimental scenarios. Such abilities are a recently discovered outcome of scaling up language\nmodels, and the questions of how they emerge and whether more scaling will enable further emergent abilities\nseem to be important future research directions for the ﬁeld of NLP.\nBroader Impact Statement\nIn this paper, we surveyed results in the existing literature, without proposing new methods or models. As\ndiscussed in (§5), emergent abilities are unpredictable in several ways, and include emergent risks (§5.4). We\nbelieve these phenomena warrant careful study and raise important questions for the ﬁeld.\nAcknowledgments\nWe thank Charles Sutton, Slav Petrov, Douglas Eck, Jason Freidenfelds, Jascha Sohl-Dickstein, Ethan Dyer,\nDale Schuurmans, and Xavier Garcia for useful discussions and feedback on the manuscript.\n11\n",
    "book_id": "220607682v2",
    "book_title": "2206.07682v2",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 74
  },
  {
    "chunk_full": "Published in Transactions on Machine Learning Research (08/2022)\nReferences\nOmri Abend, Tom Kwiatkowski, Nathaniel J Smith, Sharon Goldwater, and Mark Steedman. Bootstrapping\nlanguage acquisition.\nCognition, 164:116–143, 2017.\nURL https://homepages.inf.ed.ac.uk/\nsgwater/papers/cognition17-bootstrapping.pdf.\nMichael Ahn, Anthony Brohan, Noah Brown, Yevgen Chebotar, Omar Cortes, Byron David, Chelsea Finn,\nKeerthana Gopalakrishnan, Karol Hausman, Alex Herzog, et al. Do as I can, not as I say: Grounding\nlanguage in robotic aﬀordances. arXiv preprint arXiv:2204.01691, 2022. URL https://arxiv.org/\nabs/2204.01691.\nJean-Baptiste Alayrac, JeﬀDonahue, Pauline Luc, Antoine Miech, Iain Barr, Yana Hasson, Karel Lenc,\nArthur Mensch, Katie Millican, Malcolm Reynolds, et al. Flamingo: A visual language model for few-shot\nlearning. NeurIPS, 2022. URL https://arxiv.org/abs/2204.14198.\nPhilip W. Anderson. More is diﬀerent: Broken symmetry and the nature of the hierarchical structure of\nscience. Science, 177(4047):393–396, 1972. URL http://www.lanais.famaf.unc.edu.ar/cursos/\nem/Anderson-MoreDifferent-1972.pdf.\nSimran Arora, Avanika Narayan, Mayee F Chen, Laurel J Orr, Neel Guha, Kush Bhatia, Ines Chami, Frederic\nSala, and Christopher Ré. Ask me anything: A simple strategy for prompting language models. arXiv\npreprint arXiv:2210.02441, 2022. URL https://arxiv.org/abs/2210.02441.\nMikel Artetxe, Shruti Bhosale, Naman Goyal, Todor Mihaylov, Myle Ott, Sam Shleifer, Xi Victoria Lin, Jingfei\nDu, Srinivasan Iyer, Ramakanth Pasunuru, et al. Eﬃcient large scale language modeling with mixtures of\nexperts. arXiv preprint arXiv:2112.10684, 2021. URL https://arxiv.org/abs/2112.10684.\nAmanda Askell, Yuntao Bai, Anna Chen, Dawn Drain, Deep Ganguli, Tom Henighan, Andy Jones, Nicholas\nJoseph, Ben Mann, Nova DasSarma, et al. A general language assistant as a laboratory for alignment.\narXiv preprint arXiv:2112.00861, 2021. URL https://arxiv.org/abs/2112.00861.\nFabrice Bellard. gpt2tc: Text completion and compression using GPT-2, 2021. URL https://bellard.\norg/libnc/gpt2tc.html. Accessed Apr. 26, 2022.\nEmily M. Bender, Timnit Gebru, Angelina McMillan-Major, and Shmargaret Shmitchell. On the dangers of\nstochastic parrots: Can language models be too big? Proceedings of the 2021 ACM Conference on Fairness,\nAccountability, and Transparency, 2021. URL https://dl.acm.org/doi/pdf/10.1145/3442188.\n3445922.\nBIG-Bench. Beyond the imitation game: Measuring and extrapolating the capabilities of language models.\narXiv preprint arXiv:2206.04615, 2022. URL https://arxiv.org/abs/2206.04615.\nRishi Bommasani, Drew A. Hudson, Ehsan Adeli, Russ Altman, Simran Arora, Sydney von Arx, Michael S.\nBernstein, Jeannette Bohg, Antoine Bosselut, Emma Brunskill, et al. On the opportunities and risks\nof foundation models. arXiv preprint arXiv:2108.07258, 2021. URL https://arxiv.org/abs/2108.\n07258.\nSebastian Borgeaud, Arthur Mensch, Jordan Hoﬀmann, Trevor Cai, Eliza Rutherford, Katie Millican, George\nvan den Driessche, Jean-Baptiste Lespiau, Bogdan Damoc, Aidan Clark, et al. Improving language\nmodels by retrieving from trillions of tokens. arXiv preprint arXiv:2112.04426, 2021. URL https:\n//arxiv.org/abs/2112.04426.\nTom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D. Kaplan, Prafulla Dhari-\nwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al.\nLanguage mod-\nels are few-shot learners.\nNeurIPS, 2020.\nURL https://papers.nips.cc/paper/2020/hash/\n1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html.\n12\n",
    "book_id": "220607682v2",
    "book_title": "2206.07682v2",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 75
  },
  {
    "chunk_full": "Published in Transactions on Machine Learning Research (08/2022)\nNicholas Carlini, Florian Tramer, Eric Wallace, Matthew Jagielski, Ariel Herbert-Voss, Katherine Lee, Adam\nRoberts, Tom Brown, Dawn Song, Ulfar Erlingsson, et al. Extracting training data from large language mod-\nels. USENIX Security, 2021. URL https://www.usenix.org/conference/usenixsecurity21/\npresentation/carlini-extracting.\nNicholas Carlini, Daphne Ippolito, Matthew Jagielski, Katherine Lee, Florian Tramer, and Chiyuan Zhang.\nQuantifying memorization across neural language models. arXiv preprint arXiv:2202.07646, 2022. URL\nhttps://arxiv.org/abs/2202.07646.\nStephanie C.Y. Chan, Adam Santoro, Andrew K. Lampinen, Jane X. Wang, Aaditya Singh, Pierre H.\nRichemond, Jay McClelland, and Felix Hill. Data distributional properties drive emergent few-shot learning\nin transformers. arXiv preprint arXiv:2205.05055, 2022. URL https://arxiv.org/abs/2205.05055.\nAakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Hyung Won Chung,\nCharles Sutton, Sebastian Gehrmann, Parker Schuh, et al. PaLM: Scaling language modeling with Pathways.\narXiv preprint arXiv:2204.02311, 2022. URL https://arxiv.org/abs/2204.02311.\nHyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang,\nMostafa Dehghani, Siddhartha Brahma, et al. Scaling instruction-ﬁnetuned language models. arXiv\npreprint arXiv:2210.11416, 2022. URL https://arxiv.org/abs/2210.11416.\nKarl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, and\nJohn Schulman. Training veriﬁers to solve math word problems. arXiv preprint arXiv:2110.14168, 2021.\nURL https://arxiv.org/abs/2110.14168.\nAndy Coenen, Luke Davis, Daphne Ippolito, Emily Reif, and Ann Yuan. Wordcraft: A human-AI collaborative\neditor for story writing. arXiv preprint arXiv:2107.07430, 2021. URL https://arxiv.org/abs/2107.\n07430.\nAntonella Corradini and Timothy O’Connor.\nEmergence in science and philosophy, volume 6.\nRout-\nledge, 2010.\nURL https://books.google.com/books?hl=en&lr=&id=55RaBwAAQBAJ&oi=\nfnd&pg=PP1&dq=Emergence+in+science+and+philosophy&ots=2_8VNDXLfv&sig=1aisq_\nWouF95Cx58WWMZ0Gq3RNk.\nMostafa Dehghani, Stephan Gouws, Oriol Vinyals, Jakob Uszkoreit, and Łukasz Kaiser. Universal transformers.\narXiv preprint arXiv:1807.03819, 2018. URL https://arxiv.org/abs/1807.03819.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: Pre-training of deep bidirec-\ntional transformers for language understanding. NAACL, 2019. URL https://aclanthology.org/\nN19-1423.\nNan Du, Yanping Huang, Andrew M. Dai, Simon Tong, Dmitry Lepikhin, Yuanzhong Xu, Maxim Krikun,\nYanqi Zhou, Adams Wei Yu, Orhan Firat, et al.\nGLaM: Eﬃcient scaling of language models with\nmixture-of-experts. ICML, 2021. URL https://arxiv.org/abs/2112.06905.\nWilliam Fedus, Barret Zoph, and Noam Shazeer. Switch transformers: Scaling to trillion parameter models\nwith simple and eﬃcient sparsity. arXiv preprint arXiv:2101.03961, 2021. URL https://arxiv.org/\nabs/2101.03961.\nStephanie Forrest.\nEmergent computation: Self-organizing, collective, and cooperative phenomena in\nnatural and artiﬁcial computing networks. Physica D: Nonlinear Phenomena, 42(1-3):1–11, 1990. URL\nhttps://www.sciencedirect.com/science/article/abs/pii/016727899090063U.\nDeep Ganguli, Danny Hernandez, Liane Lovitt, Nova DasSarma, Tom Henighan, Andy Jones, Nicholas\nJoseph, Jackson Kernion, Ben Mann, Amanda Askell, et al. Predictability and surprise in large generative\nmodels. arXiv preprint arXiv:2202.07785, 2022. URL https://arxiv.org/abs/2202.07785.\nTianyu Gao, Adam Fisch, and Danqi Chen. Making pre-trained language models better few-shot learners. ACL,\n2021. doi: 10.18653/v1/2021.acl-long.295. URL https://aclanthology.org/2021.acl-long.295.\n13\n",
    "book_id": "220607682v2",
    "book_title": "2206.07682v2",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 76
  },
  {
    "chunk_full": "Published in Transactions on Machine Learning Research (08/2022)\nSamuel Gehman, Suchin Gururangan, Maarten Sap, Yejin Choi, and Noah A. Smith. RealToxicityPrompts:\nEvaluating neural toxic degeneration in language models. In Findings of EMNLP, 2020. doi: 10.18653/v1/\n2020.ﬁndings-emnlp.301. URL https://aclanthology.org/2020.findings-emnlp.301.\nAlex Graves. Adaptive computation time for recurrent neural networks. arXiv preprint arXiv:1603.08983,\n2016. URL https://arxiv.org/abs/1603.08983.\nKelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, and Ming-Wei Chang. REALM: Retrieval-augmented\nlanguage model pre-training. ICML, 2020. URL https://arxiv.org/abs/2002.08909.\nDavid A. Harper and Paul A. Lewis.\nNew perspectives on emergence in economics.\nNew Per-\nspectives on Emergence in Economics,\npp. 2–3,\n2012.\nURL https://www.sciencedirect.\ncom/science/article/pii/S0167268112000200?casa_token=fLs2nCYo_64AAAAA:\nH2sSpSygJmEqXgmpM4jLyeppph3C4TgEsaSXm5RkOpT0r4q2A1x9Su3u4uycK4sIC6a8NdLiSw.\nDan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt.\nMeasuring massive multitask language understanding. ICLR, 2021a. URL https://openreview.net/\nforum?id=d7KBjmI3GmQ.\nDan Hendrycks, Nicholas Carlini, John Schulman, and Jacob Steinhardt. Unsolved problems in ML safety.\narXiv preprint arXiv:2109.13916, 2021b. URL https://arxiv.org/abs/2109.13916.\nJordan Hoﬀmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor Cai, Eliza Rutherford,\nDiego de Las Casas, Lisa Anne Hendricks, Johannes Welbl, Aidan Clark, et al. Training compute-optimal\nlarge language models. NeurIPS, 2022. URL https://arxiv.org/abs/2203.15556.\nAri Holtzman, Peter West, Vered Shwartz, Yejin Choi, and Luke Zettlemoyer. Surface form competition:\nWhy the highest probability answer isn’t always right. EMNLP, 2021. URL https://aclanthology.\norg/2021.emnlp-main.564.\nWenlong Huang, Pieter Abbeel, Deepak Pathak, and Igor Mordatch. Language models as zero-shot planners:\nExtracting actionable knowledge for embodied agents. arXiv preprint arXiv:2201.07207, 2022. URL\nhttps://arxiv.org/pdf/2201.07207.\nBernardo A. Huberman and Tad Hogg.\nPhase transitions in artiﬁcial intelligence systems.\nArtiﬁcial\nIntelligence, 33(2):155–171, 1987.\nURL https://www.sciencedirect.com/science/article/\nabs/pii/0004370287900336.\nHarold Y. Hwang, Yoh Iwasa, Masashi Kawasaki, Bernhard Keimer, Naoto Nagaosa, and Yoshinori Tokura.\nEmergent phenomena at oxide interfaces. Nature Materials, 11(2):103–113, 2012. URL https://www.\nnature.com/articles/nmat3223.\nMax Jaderberg, Wojciech Marian Czarnecki, Simon Osindero, Oriol Vinyals, Alex Graves, David Silver,\nand Koray Kavukcuoglu. Decoupled neural interfaces using synthetic gradients. ICML, 2017. URL\nhttps://arxiv.org/abs/1608.05343.\nDan Jurafsky and James H. Martin. Speech and Language Processing: An Introduction to Natural Language\nProcessing, Computational Linguistics, and Speech Recognition. Prentice Hall series in Artiﬁcial Intelligence.\nPearson Prentice Hall, 2009. ISBN 9780131873216. URL https://books.google.com/books?id=\nfZmj5UNK8AQC.\nSaurav Kadavath, Tom Conerly, Amanda Askell, Tom Henighan, Dawn Drain, Ethan Perez, Nicholas Schiefer,\nZac Hatﬁeld Dodds, Nova DasSarma, Eli Tran-Johnson, et al. Language models (mostly) know what they\nknow. arXiv preprint arXiv:2207.05221, 2022. URL https://arxiv.org/abs/2207.05221.\nNikhil Kandpal, Eric Wallace, and Colin Raﬀel. Deduplicating training data mitigates privacy risks in\nlanguage models. ICML, 2022. URL https://arxiv.org/abs/2202.06539.\n14\n",
    "book_id": "220607682v2",
    "book_title": "2206.07682v2",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 77
  },
  {
    "chunk_full": "Published in Transactions on Machine Learning Research (08/2022)\nJared Kaplan, Sam McCandlish, Tom Henighan, Tom B. Brown, Benjamin Chess, Rewon Child, Scott Gray,\nAlec Radford, Jeﬀrey Wu, and Dario Amodei. Scaling laws for neural language models. arXiv preprint\narXiv:2001.08361, 2020. URL https://arxiv.org/abs/2001.08361.\nTakeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. Large language\nmodels are zero-shot reasoners. NeurIPS, 2022. URL https://arxiv.org/abs/2205.11916.\nAndrew K. Lampinen, Ishita Dasgupta, Stephanie C.Y. Chan, Kory Matthewson, Michael Henry Tessler,\nAntonia Creswell, James L. McClelland, Jane X. Wang, and Felix Hill. Can language models learn from\nexplanations in context? Findings of EMNLP, 2022. URL https://arxiv.org/abs/2204.02329.\nKatherine Lee, Daphne Ippolito, Andrew Nystrom, Chiyuan Zhang, Douglas Eck, Chris Callison-Burch,\nand Nicholas Carlini. Deduplicating training data makes language models better. ACL, 2022a. URL\nhttps://arxiv.org/abs/2107.06499.\nMina Lee, Percy Liang, and Qian Yang. Coauthor: Designing a human-AI collaborative writing dataset for\nexploring language model capabilities. CHI, 2022b. URL https://arxiv.org/abs/2201.06796.\nDmitry Lepikhin, HyoukJoong Lee, Yuanzhong Xu, Dehao Chen, Orhan Firat, Yanping Huang, Maxim\nKrikun, Noam Shazeer, and Zhifeng Chen. Gshard: Scaling giant models with conditional computation\nand automatic sharding. ICLR, 2021. URL https://openreview.net/forum?id=qrwe7XHTmYb.\nPercy Liang. Semi-supervised learning for natural language. PhD thesis, Massachusetts Institute of Technology,\n2005. URL https://www-cs.stanford.edu/~pliang/papers/meng-thesis.pdf.\nPercy Liang, Rishi Bommasani, Kathleen A. Creel, and Rob Reich. The time is now to develop community\nnorms for the release of foundation models, 2022. URL https://crfm.stanford.edu/2022/05/17/\ncommunity-norms.html.\nStephanie Lin, Jacob Hilton, and Owain Evans. TruthfulQA: Measuring how models mimic human falsehoods.\narXiv preprint arXiv:2109.07958, 2021. URL https://arxiv.org/abs/2109.07958.\nChristopher D. Manning. Human language understanding & reasoning. Daedalus, 151(2):127–138, 2022. URL\nhttps://www.amacad.org/publication/human-language-understanding-reasoning.\nChristopher D. Manning, Kevin Clark, John Hewitt, Urvashi Khandelwal, and Omer Levy. Emergent\nlinguistic structure in artiﬁcial neural networks trained by self-supervision. Proceedings of the National\nAcademy of Sciences, 117(48):30046–30054, 2020. URL https://www.pnas.org/doi/10.1073/pnas.\n1907367117.\nBryan McCann, Nitish Shirish Keskar, Caiming Xiong, and Richard Socher. The natural language decathlon:\nMultitask learning as question answering. arXiv preprint arXiv:1806.08730, 2018. URL https://arxiv.\norg/abs/1806.08730.\nStephen Merity, Caiming Xiong, James Bradbury, and Richard Socher. Pointer sentinel mixture models, 2016.\nURL https://huggingface.co/datasets/wikitext.\nScott Miller, Jethran Guinness, and Alex Zamanian. Name tagging with word clusters and discriminative\ntraining. In NAACL, 2004. URL https://aclanthology.org/N04-1043.\nSewon Min, Mike Lewis, Hannaneh Hajishirzi, and Luke Zettlemoyer. Noisy channel language model prompting\nfor few-shot text classiﬁcation. ACL, 2022a. URL https://arxiv.org/abs/2108.04106.\nSewon Min, Xinxi Lyu, Ari Holtzman, Mikel Artetxe, Mike Lewis, Hannaneh Hajishirzi, and Luke Zettle-\nmoyer. Rethinking the role of demonstrations: What makes in-context learning work? arXiv preprint\narXiv:2202.12837, 2022b. URL https://arxiv.org/abs/2202.12837.\nMaxwell Nye, Anders Johan Andreassen, Guy Gur-Ari, Henryk Michalewski, Jacob Austin, David Bieber,\nDavid Dohan, Aitor Lewkowycz, Maarten Bosma, David Luan, et al. Show your work: Scratchpads\nfor intermediate computation with language models.\narXiv preprint arXiv:2112.00114, 2021.\nURL\nhttps://openreview.net/forum?id=iedYJm92o0a.\n15\n",
    "book_id": "220607682v2",
    "book_title": "2206.07682v2",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 78
  },
  {
    "chunk_full": "Published in Transactions on Machine Learning Research (08/2022)\nCatherine Olsson, Nelson Elhage, Neel Nanda, Nicholas Joseph, Nova DasSarma, Tom Henighan,\net al.\nIn-context learning and induction heads.\nTransformer Circuits, 2022.\nURL https:\n//transformer-circuits.pub/2022/in-context-learning-and-induction-heads/\nindex.html.\nLong Ouyang, JeﬀWu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang,\nSandhini Agarwal, Katarina Slama, Alex Ray, et al. Training language models to follow instructions with\nhuman feedback. arXiv preprint arXiv:2203.02155, 2022. URL https://arxiv.org/abs/2203.02155.\nKishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. BLEU: a method for automatic evaluation\nof machine translation. In ACL, 2002. URL https://aclanthology.org/P02-1040.pdf.\nAlicia Parrish, Angelica Chen, Nikita Nangia, Vishakh Padmakumar, Jason Phang, Jana Thompson, Phu Mon\nHtut, and Samuel Bowman. BBQ: A hand-built bias benchmark for question answering. In Findings of\nACL, 2022. URL https://arxiv.org/abs/2110.08193.\nRoma Patel and Ellie Pavlick. Mapping language models to grounded conceptual spaces. ICLR, 2022. URL\nhttps://openreview.net/forum?id=gJcEM8sxHK.\nEthan Perez, Saﬀron Huang, Francis Song, Trevor Cai, Roman Ring, John Aslanides, Amelia Glaese, Nat\nMcAleese, and Geoﬀrey Irving. Red teaming language models with language models. arXiv preprint\narXiv:2202.03286, 2022. URL https://arxiv.org/abs/2202.03286.\nMohammad Taher Pilehvar and Jose Camacho-Collados. WiC: the word-in-context dataset for evaluat-\ning context-sensitive meaning representations. NAACL, 2019. URL https://aclanthology.org/\nN19-1128.\nAlec\nRadford,\nJeﬀrey\nWu,\nRewon\nChild,\nDavid\nLuan,\nDario\nAmodei,\nIlya\nSutskever,\net\nal.\nLanguage\nmodels\nare\nunsupervised\nmultitask\nlearners.\nOpenAI\nblog,\n1(8),\n2019.\nURL\nhttps://d4mucfpksywv.cloudfront.net/better-language-models/language_models_\nare_unsupervised_multitask_learners.pdf.\nJack W. Rae, Sebastian Borgeaud, Trevor Cai, Katie Millican, Jordan Hoﬀmann, Francis Song, John Aslanides,\nSarah Henderson, Roman Ring, Susannah Young, et al. Scaling language models: Methods, analysis &\ninsights from training Gopher. arXiv preprint arXiv:2112.11446, 2021. URL https://arxiv.org/abs/\n2112.11446.\nColin Raﬀel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou,\nWei Li, and Peter J. Liu. Exploring the limits of transfer learning with a uniﬁed text-to-text transformer.\nJournal of Machine Learning Research, 2020. URL https://jmlr.org/papers/v21/20-074.html.\nAditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen. Hierarchical text-conditional\nimage generation with clip latents. arXiv preprint arXiv:2204.06125, 2022. URL https://arxiv.org/\nabs/2204.06125.\nYasaman Razeghi, Robert L Logan IV, Matt Gardner, and Sameer Singh. Impact of pretraining term\nfrequencies on few-shot reasoning. arXiv preprint arXiv:2202.07206, 2022. URL https://arxiv.org/\nabs/2202.07206.\nLaria Reynolds and Kyle McDonell. Prompt programming for large language models: Beyond the few-shot\nparadigm. Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems, 2021.\nURL https://arxiv.org/abs/2102.07350.\nRachel Rudinger, Chandler May, and Benjamin Van Durme.\nSocial bias in elicited natural language\ninferences. In Proceedings of the First ACL Workshop on Ethics in Natural Language Processing, 2017.\nURL https://aclanthology.org/W17-1609.\nVictor Sanh, Albert Webson, Colin Raﬀel, Stephen Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaﬃn,\nArnaud Stiegler, Teven Le Scao, Arun Raja, et al. Multitask prompted training enables zero-shot task\ngeneralization. ICLR, 2022. URL https://openreview.net/forum?id=9Vrb9D0WI4.\n16\n",
    "book_id": "220607682v2",
    "book_title": "2206.07682v2",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 79
  },
  {
    "chunk_full": "Published in Transactions on Machine Learning Research (08/2022)\nNikunj Saunshi, Sadhika Malladi, and Sanjeev Arora. A mathematical exploration of why language models\nhelp solve downstream tasks. ICLR, 2021. URL https://arxiv.org/abs/2010.03648.\nTimo Schick and Hinrich Schütze. It’s not just size that matters: Small language models are also few-shot\nlearners. NAACL, June 2021. URL https://aclanthology.org/2021.naacl-main.185.\nFreda Shi, Mirac Suzgun, Markus Freitag, Xuezhi Wang, Suraj Srivats, Soroush Vosoughi, Hyung Won Chung,\nYi Tay, Sebastian Ruder, Denny Zhou, Dipanjan Das, and Jason Wei. Language models are multilingual\nchain-of-thought reasoners. arXiv preprint arXiv:2210.03057, 2022. URL https://arxiv.org/abs/\n2210.03057.\nJacob\nSteinhardt.\nOn\nthe\nrisks\nof\nemergent\nbehavior\nin\nfoundation\nmodels,\nOctober\n2021.\nURL\nhttps://bounded-regret.ghost.io/\non-the-risks-of-emergent-behavior-in-foundation-models/. Accessed Apr 13, 2022.\nJacob Steinhardt. Future ml systems will be qualitatively diﬀerent, 2022. URL https://bounded-regret.\nghost.io/future-ml-systems-will-be-qualitatively-different/.\nAccessed May 20,\n2022.\nMirac Suzgun, Nathan Scales, Nathaneal Scharli, Sebastian Gehrmann, Yi Tay, Hyung Won Chung, Aakanksha\nChowdhery, Quoc V. Le, Ed H. Chi, Denny ZHou, and Jason Wei.\nChallenging BIG-Bench tasks\nand whether chain-of-thought can solve them. arXiv preprint arXiv:2210.09261, 2022. URL https:\n//arxiv.org/abs/2210.09261.\nYi Tay, Mostafa Dehghani, Vinh Q. Tran, Xavier Garcia, Dara Bahri, Tal Schuster, Huaixiu Steven Zheng,\nNeil Houlsby, and Donald Metzler. Unifying language learning paradigms. arXiv preprint arXiv:2205.05131,\n2022a. URL https://arxiv.org/abs/2205.05131.\nYi Tay, Vinh Q. Tran, Mostafa Dehghani, Jianmo Ni, Dara Bahri, Harsh Mehta, Zhen Qin, Kai Hui, Zhe Zhao,\nJai Gupta, et al. Transformer memory as a diﬀerentiable search index. arXiv preprint arXiv:2202.06991,\n2022b. URL https://arxiv.org/abs/2202.06991.\nYi Tay, Jason Wei, Hyung Won Chung, Vinh Q Tran, David R So, Siamak Shakeri, Xavier Garcia,\nHuaixiu Steven Zheng, Jinfeng Rao, Aakanksha Chowdhery, et al. Transcending scaling laws with 0.1%\nextra compute. arXiv preprint arXiv:2210.11399, 2022c. URL https://arxiv.org/abs/2210.11399.\nRyan Teehan, Miruna Clinciu, Oleg Serikov, Eliza Szczechla, Natasha Seelam, Shachar Mirkin, and Aaron\nGokaslan. Emergent structures and training dynamics in large language models. In ACL Big Science\nWorkshop, 2022. URL https://aclanthology.org/2022.bigscience-1.11/.\nRomal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng,\nAlicia Jin, Taylor Bos, Leslie Baker, Yu Du, et al. LaMDA: Language models for dialog applications. arXiv\npreprint arXiv:2201.08239, 2022. URL https://arxiv.org/abs/2201.08239.\nTrieu H. Trinh and Quoc V. Le. A simple method for commonsense reasoning. arXiv preprint arXiv:1806.02847,\n2018. URL https://arxiv.org/abs/1806.02847.\nThomas Wang, Adam Roberts, Daniel Hesslow, Teven Le Scao, Hyung Won Chung, Iz Beltagy, Julien Launay,\nand Colin Raﬀel. What language model architecture and pretraining objective work best for zero-shot\ngeneralization? ICML, 2022a. URL https://arxiv.org/abs/2204.05832.\nXuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, and Denny Zhou. Self-consistency improves\nchain of thought reasoning in language models. arXiv preprint arXiv:2203.11171, 2022b. URL https:\n//arxiv.org/abs/2203.11171.\nColin Wei, Sang Michael Xie, and Tengyu Ma. Why do pretrained language models help in downstream\ntasks? An analysis of head and prompt tuning. NeurIPS, 2021a. URL https://openreview.net/\nforum?id=MDMV2SxCboX.\n17\n",
    "book_id": "220607682v2",
    "book_title": "2206.07682v2",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 80
  },
  {
    "chunk_full": "Published in Transactions on Machine Learning Research (08/2022)\nJason Wei, Dan Garrette, Tal Linzen, and Ellie Pavlick. Frequency eﬀects on syntactic rule learning in\ntransformers. EMNLP, 2021b. doi: 10.18653/v1/2021.emnlp-main.72. URL https://aclanthology.\norg/2021.emnlp-main.72.\nJason Wei, Maarten Bosma, Vincent Y. Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M.\nDai, and Quoc V. Le. Finetuned language models are zero-shot learners. ICLR, 2022a. URL https:\n//openreview.net/forum?id=gEZrGCozdqR.\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Chi, Quoc Le, and Denny Zhou. Chain of\nthought prompting elicits reasoning in large language models. NeurIPS, 2022b. URL https://arxiv.\norg/abs/2201.11903.\nLaura Weidinger, John Mellor, Maribeth Rauh, Conor Griﬃn, Jonathan Uesato, Po-Sen Huang, Myra Cheng,\nMia Glaese, Borja Balle, Atoosa Kasirzadeh, et al. Ethical and social risks of harm from language models.\narXiv preprint arXiv:2112.04359, 2021. URL https://arxiv.org/abs/2112.04359.\nTongshuang Wu, Michael Terry, and Carrie J. Cai. AI chains: Transparent and controllable human-AI\ninteraction by chaining large language model prompts. arXiv preprint arXiv:2110.01691, 2021. URL\nhttps://arxiv.org/abs/2110.01691.\nTongshuang Wu, Ellen Jiang, Aaron Donsbach, JeﬀGray, Alejandra Molina, Michael Terry, and Carrie J.\nCai. PromptChainer: Chaining large language model prompts through visual programming. arXiv preprint\narXiv:2203.06566, 2022a. URL https://arxiv.org/abs/2203.06566.\nYuhuai Wu, Markus N Rabe, DeLesley Hutchins, and Christian Szegedy. Memorizing transformers. arXiv\npreprint arXiv:2203.08913, 2022b.\nSang Michael Xie, Aditi Raghunathan, Percy Liang, and Tengyu Ma. An explanation of in-context learning\nas implicit bayesian inference. ICLR, 2022. URL https://arxiv.org/abs/2111.02080.\nAndy Zeng, Adrian Wong, Stefan Welker, Krzysztof Choromanski, Federico Tombari, Aveek Purohit, Michael\nRyoo, Vikas Sindhwani, Johnny Lee, Vincent Vanhoucke, et al. Socratic models: Composing zero-shot\nmultimodal reasoning with language. arXiv preprint arXiv:2204.00598, 2022. URL https://arxiv.\norg/abs/2204.00598.\nYian Zhang, Alex Warstadt, Xiaocheng Li, and Samuel R. Bowman. When do you need billions of words of\npretraining data? In ACL, 2021. doi: 10.18653/v1/2021.acl-long.90. URL https://aclanthology.\norg/2021.acl-long.90.\nZihao Zhao, Eric Wallace, Shi Feng, Dan Klein, and Sameer Singh. Calibrate before use: Improving few-shot\nperformance of language models. ICML, 2021. URL https://arxiv.org/abs/2102.09690.\nDenny Zhou, Nathanael Schärli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans, Olivier\nBousquet, Quoc Le, and Ed Chi. Least-to-most prompting enables complex reasoning in large language\nmodels. arXiv preprint arXiv:2205.10625, 2022. URL https://arxiv.org/abs/2205.10625.\nBarret Zoph, Irwan Bello, Sameer Kumar, Nan Du, Yanping Huang, JeﬀDean, Noam Shazeer, and William\nFedus. Designing eﬀective sparse expert models. arXiv preprint arXiv:2202.08906, 2022. URL https:\n//arxiv.org/abs/2202.08906.\n18\n",
    "book_id": "220607682v2",
    "book_title": "2206.07682v2",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 81
  },
  {
    "chunk_full": "Published in Transactions on Machine Learning Research (08/2022)\nA\nBIG-Bench analysis\nA.1\nCross-entropy loss analysis\nHere we study how scaling curves may appear diﬀerently depending on the evaluation metric used to measure\nperformance. We will focus on the six few-shot prompted BIG-Bench tasks that we consider emergent\nfor LaMDA models. Three of these tasks are generative and use Exact Match (EM) or BLEU (Papineni\net al., 2002) as the evaluation metric. The other three tasks are classiﬁcation and use accuracy (acc) as the\nevaluation metric.\nIn the scaling curves for these tasks, peformance in EM/BLEU/acc is close to random for small models\n(≤1022 FLOPs / ≤27B params). We will compare these scaling curves against alternative plots that have a\ndiﬀerent y-axis measured by cross-entropy loss. Cross-entropy loss diﬀers from EM/BLEU/acc in that it\ncaptures improvements in performance (the predicted distribution getting closer to ground truth) even when\nthe EM/BLEU/acc is random. For example, if two examples are both wrong as measured by EM/BLEU/acc,\none example may be closer to the ground truth in terms of probabilities, and this information is captured by\nthe cross-entropy loss.\nThese plots are expected to look like one of the following:\n• Outcome 1: For the model scales where EM/BLEU/acc is random, cross-entropy loss also does not\nimprove as scale increases. This outcome implies that for these scales, the model truly does not get\nany better at the tasks.\n• Outcome 2: For the model scales where EM/BLEU/acc is random, cross-entropy loss does improve.\nThis outcome implies that the models do get better at the task, but these improvements are not\nreﬂected in the downstream metric of interest. The broader implication is that scaling small models\nimproves the models in a way that is not reﬂected in EM/BLEU/Acc, and that there is some critical\nmodel scale where these improvements enable the downstream metric to increase to above random as\nan emergent ability.\nWe ﬁnd that all six BIG-Bench tasks fall under Outcome 2, and detail this analysis below. Overall, the\nconclusion from this analysis is that small models do improve in some ways that downstream metrics that\nEM/BLEU/Acc do not capture. However, these tasks are still considered emergent, and this analysis does\nnot provide any straightforward indicators of how to predict such emergent behaviors.\nA.1.1\nGenerative tasks\nFigure 5 shows the cross-entropy loss on the three generative BIG-Bench tasks (modiﬁed arithmetic, IPA\ntransliterate, and word unscramble) alongside the downstream evaluation metrics used in Figure 2. For all\nthree tasks, notice that while the error rate is nearly 100% for small models (≤1022 FLOPs / ≤27B params),\nthe cross-entropy loss does actually improve for these model sizes. At the point of emergence as measured by\nerror rate, we also see an “elbow” in performance improvement for cross-entropy loss.\nA.1.2\nClassiﬁcation tasks\nFigure 6 (middle row) shows the cross-entropy loss of the three classiﬁcation BIG-Bench tasks. Similar to the\ngenerative tasks, when the error rate is close to random, cross-entropy loss consistently still improves for\nmodels trained with more compute. This again shows that performance as computed by accuracy can mask\nconsistent improvements in the likelihood of the target sequences.\nWe also perform an additional analysis of the multiple choice emergent tasks in Figure 6 (bottom row),\nwhich shows the log probabilities of the correct response and incorrect response(s). We ﬁnd that the cross-\nentropy loss decreases for both the correct and incorrect responses in the three emergent multiple choice\ntasks. Counterintuitively, both log-probabilities can decrease in tandem even when the probability across\nall available multiple choice responses is normalized. The reason is that larger models produce less-extreme\nprobabilities (i.e., values approaching 0 or 1) and therefore the average log-probabilities have fewer extremely\n19\n",
    "book_id": "220607682v2",
    "book_title": "2206.07682v2",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 82
  },
  {
    "chunk_full": "Published in Transactions on Machine Learning Research (08/2022)\n1020\n1022\n1024\n70\n80\n90\n100\nError rate (%)\nModiﬁed arithmetic\n1020\n1022\n1024\n70\n80\n90\n100\nIPA transliterate\nT = 0\nT = 1\nRandom\n1020\n1022\n1024\n70\n80\n90\n100\nWord unscramble\n1020\n1022\n1024\n3\n5\n10\n15\nCross-entropy loss\n1020\n1022\n1024\n3\n5\n10\n15\nTraining FLOPs\n1020\n1022\n1024\n3\n5\n10\n15\nFigure 5: Adjacent plots for error rate and cross-entropy loss on three emergent generative tasks in BIG-Bench\nfor LaMDA. We show error rate for both greedy decoding (T = 0) as well as random sampling (T = 1). Error\nrate is (1 - exact match score) for modiﬁed arithmetic and word unscramble, and (1 - BLEU score) for IPA\ntransliterate.\nsmall values. However, we note that for each of these three tasks, that the average log-probability of the\ncorrect and incorrect responses eventually deviates at a certain scale, during which performance on the task\nincreases substantially.\n20\n",
    "book_id": "220607682v2",
    "book_title": "2206.07682v2",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 83
  },
  {
    "chunk_full": "Published in Transactions on Machine Learning Research (08/2022)\n1020\n1022\n1024\n40\n60\n80\n100\nError rate (%)\nLogical arguments\n1020\n1022\n1024\n40\n60\n80\n100\nSports understanding\nLaMDA\nRandom\n1020\n1022\n1024\n40\n60\n80\n100\nFigure of speech\n1020\n1022\n1024\n0.05\n0.2\n0.8\n3.2\nCross-entropy loss\n1020\n1022\n1024\n0.05\n0.2\n0.8\n3.2\n1020\n1022\n1024\n0.05\n0.2\n0.8\n3.2\n1020\n1022\n1024\n0.05\n0.2\n0.8\n3.2\nNeg. log probability\n1020\n1022\n1024\n0.05\n0.2\n0.8\n3.2\nModel scale (training FLOPs)\nCorrect response\nIncorrect response(s)\n1020\n1022\n1024\n0.05\n0.2\n0.8\n3.2\nFigure 6: Adjacent plots for error rate, cross-entropy loss, and log probabilities of correct and incorrect\nresponses on three classiﬁcation tasks on BIG-Bench that we consider to demonstrate emergent abilities.\nLogical arguments only has 32 samples, which may contribute to noise. Error rate is (1 - accuracy).\n21\n",
    "book_id": "220607682v2",
    "book_title": "2206.07682v2",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 84
  },
  {
    "chunk_full": "Published in Transactions on Machine Learning Research (08/2022)\nA.2\nDiﬀerent metrics for generative tasks\nIn §5.1 we asked whether the apparent emergent abilities on generative tasks were due to using a particular\nmetric such as exact string match, which does not award partially correct sequences. Here, we show three\nemergent generative BIG-Bench tasks using all evaluation metrics provided by BIG-Bench, which includes\nmetrics such as BLEU, ROUGE, and BLEURT, that award partial credit for answers that do not exactly\nmatch the target. For all three tasks, the emergent behavior appears to be independent of which evaluation\nmetric is used. Hence, we conclude that using exact string match instead of another evaluation metric\nthat awards partial credit is not a complete explanation of emergence on generative tasks. Two emergent\ngenerative BIG-Bench tasks, word unscramble and repeat copy logic, are excluded here because exact match\nis the only most sensible evaluation metric for those tasks, which measure the ability to manipulate words in\nthe input (and hence metrics like BLEU and ROUGE that give word-level partial credit are not valid).\n1018 1020 1022 1024\n0\n20\n40\n60\n80\nEvaluation metric (%)\n(A) Mod. arithmetic\n1018 1020 1022 1024\n0\n20\n40\n60\n80\nEvaluation metric (%)\n(B) IPA transliterate\n1018 1020 1022 1024\n0\n20\n40\n60\n80\nEvaluation metric (%)\n(C) Periodic elements\nExact match\nROUGE1\nROUGE2\nROUGE L-Sum\nBLEURT\nBLEU\nSequence F1\nMultiple choice grade\nFigure 7: Multiple evaluation metrics for emergent BIG-Bench tasks that are generative in nature. For all\nthree tasks, emergent behavior is apparent for all evaluation metrics.\nA.3\nBIG-Bench task analysis\nBIG-Bench contains over 200 tasks, and each task has associated keywords identiﬁed by the authors who\nsubmitted the task (e.g., “common sense”, “multilingual”). Given this, we asked the question, which types of\nBIG-Bench tasks are more likely to be emergent (compared with scaling smoothly)? For this analysis, we\nmanually classiﬁed all 210 BIG-Bench tasks as thus far emergent or not. We used the deﬁnition of emergence\ngiven in §3, which is that the task had near-random performance until a certain scale, after which performance\nincreases to substantially above random (as opposed to smoothly increasing). Because this deﬁnition is\npotentially subjective based on the deﬁnition of “near-random” (and any heuristic we decide on would encode\nthese subjective biases), two co-authors of the paper worked together and agreed with conﬁdence on all the\ntasks labeled as emergent. For full transparency, this set of annotations is listed in Appendix E.\nIn Figure 8, we show the number of tasks that are emergent for each keyword in BIG-Bench. Furthermore, we\nstratify them by tasks that ﬁrst emerged with LaMDA 137B or GPT-3 175B, as well as tasks that were not\nemergent until using PaLM models. The non-emergent tasks in this plot include either “smoothly increasing”\ntasks (performance predictably increased with model size) or “ﬂat” tasks (all models achieved approximately\nrandom performance). The remaining 40 BIG-Bench tasks not included in this chart did not ﬁt into any of\nthe above categories (e.g., too noisy due to very few eval examples, performance not correlated with model\nscale, etc.).\nSince the number of tasks per keyword varied substantially among keywords, and most keywords had less\nthan twenty tasks, the “most emergent” keywords diﬀered depending on whether we compare number of\nemergent tasks or percentage of emergent tasks per keyword. Tracking the absolute number of emergent\ntasks per keyword is problematic since it eﬀectively just captures the most common keywords used across\nBigBench. We therefore tracked which keywords had the highest percent of emergent tasks, which were\nanalogical reasoning, word sense disambiguation, truthfulness, social reasoning, and emotional understanding.\nWhile one might expect a priori that reasoning-related tasks would more likely to be emergent, only two of\nthe top ﬁve tasks were reasoning and other keyword tags like logical reasoning and causal reasoning did not\n22\n",
    "book_id": "220607682v2",
    "book_title": "2206.07682v2",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 85
  },
  {
    "chunk_full": "Published in Transactions on Machine Learning Research (08/2022)\nhave a particularly high fraction of emergent tasks. Moreover, arithmetic and mathematics had relatively low\npercentage of emergent tasks, which was unexpected since some of the earliest examples of emergence were on\narithmetic (Brown et al., 2020). Overall, there are no clear trends for which types of tasks are most emergent.\nFinally, examining which keywords have the most tasks with ﬂat scaling curves can also align with prior\nintuitions. For instance, visual reasoning has the largest fraction of tasks with ﬂat scaling curves (8/13),\nsince language models are not designed for visual reasoning. Other categories with a large fraction of ﬂat\nscaling curve tasks are non-language, repeated interaction, context length, computer code, and multi-step—all\ntargeting weaknesses of large language models. These ﬂat categories could be directions for future work in\nemergence in large language models.\nlogical-reasoning\ncommon-sense\nreading-comprehension\nmathematics\nanalogical-reasoning\nhuman-like-behavior\ncontext-free-question-answering\nsocial-reasoning\ncontextual-question-answering\narithmetic\nnumerical-response\nnon-language\nnon-English\nvisual-reasoning\nout-of-distribution\ncreativity\nimplicit-reasoning\ncausal-reasoning\nparaphrase\nemotional-understanding\ncomputer-code\nmultilingual\nmulti-step\nword-sense-disambiguation\nlow-resource-language\ncontext-length\ntranslation\ntheory-of-mind\nnarrative-understanding\nsummarization\ndomain-speciﬁc\ntruthfulness\nrepeated-interaction\n0\n5\n10\n15\n20\n25\n30\n35\n40\n45\n50\nKeyword Tag\nNumber of tasks\nEmergent with LaMDA/GPT\nEmergent with PaLM\nSmoothly increasing\nFlat (no model better than random)\nFigure 8: Proportion of emergent tasks for keywords in BIG-Bench (each task can be associated with multiple\nkeywords). We only included keywords with at least ﬁve tasks. Smoothly increasing: performance improved\npredictably as model scale increased. Emergent with LaMDA/GPT: performance was near-random until used\nwith LaMDA 137B or GPT-3 175B. Emergent with PaLM: performance was near-random for all previous\nmodels, until using a PaLM model (8B, 62B, or 540B). Flat: no model performs better than random.\n23\n",
    "book_id": "220607682v2",
    "book_title": "2206.07682v2",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 86
  },
  {
    "chunk_full": "Published in Transactions on Machine Learning Research (08/2022)\nB\nFurther MMLU analysis\nIn §5.3, we saw how emergent performance on MMLU for Gopher and Chinchilla could be viewed as a\nfunction of training FLOPs, model parameters, and WikiText103 perplexity. Because MMLU is actually\na suite of 57 topics spanning four categories, we ask the question of whether certain categories were more\nconducive to emergence than others. This is similar in nature to the BIG-Bench analysis done in the prior\nsection (Appendix A.3). One diﬀerence here is that the MMLU categories are mutually exclusive—each topic\nonly has one category, whereas a single BIG-Bench task often had multiple keyword tags. However, there\nare only four categories and 57 tasks for MMLU (compared with 200+ tasks and dozens of keywords for\nBIG-Bench).\nIn Figure 10, we stratify the performance of MMLU among the four categories given in the benchmark\n(Humanities, STEM, Social Science, and other), and plot them with multiple x-axes: training FLOPs, model\nparameters, and WikiText103 perplexity. It is clear that Social Science and Humanities have the largest\njump in performance from the second-largest to the largest model, and STEM has the smallest jump in\nperformance. For a given x-axis (training FLOPs, model parameters, WikiText103 ppl), all four categories\nhad similar plot shapes. This result is also summarized in Figure 9.\n0\n25\n50\n75\n100\n0\n25\n50\n75\n100\nPerformance of\nsecond-largest model\nPerformance of\nlargest model\nChinchilla: Humanities\nChinchilla: STEM\nChinchilla: Other\nChinchilla: Social Science\nGopher: Humanities\nGopher: STEM\nGopher: Other\nGopher: Social Science\nRandom performance (25%)\nFigure 9: Performance of largest Chinchilla and Gopher models (70B and 280B, respectively) compared with\nthe second-largest model (7B parameters for both Chiinchlla and Gopher). The 7B Chinchilla and Gopher\nmodels perform around random (25%) for all four categories. So the categories that improved the most from\n7B to 70B/280B are humanities and social science, whereas STEM (Science, Technology, Engineering, and\nMathematics) improved the least.\n24\n",
    "book_id": "220607682v2",
    "book_title": "2206.07682v2",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 87
  },
  {
    "chunk_full": "Published in Transactions on Machine Learning Research (08/2022)\n1020\n1022\n1024\n0\n20\n40\n60\n80\n100\nTraining FLOPs\nAccuracy (%)\n1B\n10B 100B\n0\n20\n40\n60\n80\n100\nModel parameters\nMMLU: Humanities\nChinchilla\nGopher\nRandom\n20 15\n10\n7\n5\n0\n20\n40\n60\n80\n100\nWikiText103 ppl\n1020\n1022\n1024\n0\n20\n40\n60\n80\n100\nTraining FLOPs\nAccuracy (%)\n1B\n10B 100B\n0\n20\n40\n60\n80\n100\nModel parameters\nMMLU: Science, Technology, Engineering, and Math (STEM)\n20 15\n10\n7\n5\n0\n20\n40\n60\n80\n100\nWikiText103 ppl\n1020\n1022\n1024\n0\n20\n40\n60\n80\n100\nTraining FLOPs\nAccuracy (%)\n1B\n10B 100B\n0\n20\n40\n60\n80\n100\nModel parameters\nMMLU: Other\n20 15\n10\n7\n5\n0\n20\n40\n60\n80\n100\nWikiText103 ppl\n1020\n1022\n1024\n0\n20\n40\n60\n80\n100\nTraining FLOPs\nAccuracy (%)\n1B\n10B 100B\n0\n20\n40\n60\n80\n100\nModel parameters\nMMLU: Social Science\n20 15\n10\n7\n5\n0\n20\n40\n60\n80\n100\nWikiText103 ppl\nFigure 10: Emergence of Chinchilla and Gopher on MMLU. In the four rows, performance is stratiﬁed into\nfour supercategories. For both Chinchilla and Gopher, Social Science had the highest level of emergence while\nSTEM was the least emergent.\n25\n",
    "book_id": "220607682v2",
    "book_title": "2206.07682v2",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 88
  },
  {
    "chunk_full": "Published in Transactions on Machine Learning Research (08/2022)\nC\nAll Model Details\nTable 2 below summarizes the parameter count, number of training tokens, and the training FLOPs for the\nmodels highlighted in our work. The models span from the smallest LaMDA model with 2.1M parameters to\nthe largest PaLM model with 540B parameters and 2.5E+24 training FLOPs—roughly 8x the computational\nbudget of GPT-3.\nTable 2: Parameters, training examples, and training FLOPs of large language models.\nModel\nParameters\nTrain tokens\nTrain FLOPs\nGPT-3\n125M\n300B\n2.25E+20\n350M\n300B\n6.41E+20\n760M\n300B\n1.37E+21\n1.3B\n300B\n2.38E+21\n2.7B\n300B\n4.77E+21\n6.7B\n300B\n1.20E+22\n13B\n300B\n2.31E+22\n175B\n300B\n3.14E+23\nLaMDA\n2.1M\n262B\n3.30E+18\n17M\n313B\n3.16E+19\n57M\n262B\n8.90E+19\n134M\n170B\n1.37E+20\n262M\n264B\n4.16E+20\n453M\n150B\n4.08E+20\n1.1B\n142B\n9.11E+20\n2.1B\n137B\n1.72E+21\n3.6B\n136B\n2.96E+21\n8.6B\n132B\n6.78E+21\n29B\n132B\n2.30E+22\n69B\n292B\n1.20E+23\n137B\n674B\n5.54E+23\nGopher\n417M\n300B\n7.51E+20\n1.4B\n300B\n2.52E+21\n7.1B\n300B\n1.28E+22\n280B\n325B\n5.46E+23\nChinchilla\n417M\n314B\n7.86E+20\n1.4B\n314B\n2.63E+21\n7.1B\n[sic] 199B\n8.47E+21\n70B\n1.34T\n5.63E+23\nPaLM\n8B\n780B\n3.74E+22\n62B\n780B\n2.90E+23\n540B\n780B\n2.53E+24\nAnthropic LM\n800M\n850B\n4.08E+21\n3B\n850B\n1.53E+22\n12B\n850B\n6.12E+22\n52B\n850B\n2.65E+22\n26\n",
    "book_id": "220607682v2",
    "book_title": "2206.07682v2",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 89
  },
  {
    "chunk_full": "Published in Transactions on Machine Learning Research (08/2022)\nD\nScaling with Parameter Count\nFigures 11, 12, and 13 shows emergent abilities with an x-axis of number of model parameters.\n10M\n1B\n100B\n0\n10\n20\n30\n40\n50\nAccuracy (%)\n(A) Mod. arithmetic\n10M\n1B\n100B\n0\n10\n20\n30\n40\n50\nBLEU (%)\n(B) IPA transliterate\n10M\n1B\n100B\n0\n10\n20\n30\n40\n50\nExact match (%)\n(C) Word unscramble\nLaMDA\nGPT-3\nGopher\nChinchilla\nPaLM\nRandom\n10M\n1B\n100B\n0\n10\n20\n30\n40\n50\nExact match (%)\n(D) Persian QA\n100M\n10B\n1T\n0\n10\n20\n30\n40\n50\n60\n70\nAccuracy (%)\n(E) TruthfulQA\n100M\n10B\n1T\n0\n10\n20\n30\n40\n50\n60\n70\nModel scale (number of parameters)\nAccuracy (%)\n(F) Grounded mappings\n100M\n10B\n1T\n0\n10\n20\n30\n40\n50\n60\n70\nAccuracy (%)\n(G) Multi-task NLU\n100M\n10B\n1T\n0\n10\n20\n30\n40\n50\n60\n70\nAccuracy (%)\n(H) Word in context\nFigure 11: Eight examples of emergence in the few-shot prompting setting. Each point is a separate model.\nThe ability to perform a task via few-shot prompting is emergent when a language model achieves random\nperformance until a certain scale, after which performance signiﬁcantly increases to well-above random. Note\nthat models with more parameters also typically use more training compute—hence, we show an analogous\nﬁgure with training FLOPs instead of number of model parameters as the x-axis in Figure 2. A–D: BIG-Bench\n(2022), 2-shot. E: Lin et al. (2021) and Rae et al. (2021). F: Patel & Pavlick (2022). G: Hendrycks et al.\n(2021a), Rae et al. (2021), and Hoﬀmann et al. (2022). H: Brown et al. (2020), Hoﬀmann et al. (2022), and\nChowdhery et al. (2022) on the WiC benchmark (Pilehvar & Camacho-Collados, 2019).\n27\n",
    "book_id": "220607682v2",
    "book_title": "2206.07682v2",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 90
  },
  {
    "chunk_full": "Published in Transactions on Machine Learning Research (08/2022)\n1B\n10B 100B\n0\n5\n10\n15\n20\n25\nNo chain\nof thought\nChain of\nthought\nGSM8K Accuracy (%)\n(A) Math word\nproblems\n1B\n10B 100B\n30\n40\n50\n60\n70\nNo\ninstruction\ntuning\nInstruction\ntuning\n10 NLU task average\n(B) Instruction\nfollowing\n10M 100M 1B\n0\n20\n40\n60\n80\n100\nNo\nscratchpad\nScratchpad\nModel scale (number of parameters)\nAccuracy (%)\n(C) 8-digit addition\n1B\n10B\n100B\n100\n101\nLetter\nchoices\nT/F\n% ECE (log-scale, decreasing)\n(D) Calibration\nFigure 12: Specialized prompting or ﬁnetuning methods can be emergent in that they do not have a positive\neﬀect until a certain model scale. A: Wei et al. (2022b). B: Wei et al. (2022a). C: Nye et al. (2021). D:\nKadavath et al. (2022). The model shown in A-C is LaMDA (Thoppilan et al., 2022), and the model shown\nin D is from Anthropic.\n1B\n100B\n0\n20\n40\n60\n80\n100\nAccuracy (%)\n(A) TriviaQA\n(GPT-3)\n1B\n100B\n60\n70\n80\n90\nAccuracy (%)\n(B) Physical QA\n(GPT-3)\n8B 62B 540B\n0\n10\n20\n30\n40\n50\n60\nModel scale (number of parameters)\nAccuracy (%)\n(C) GSM8K\n(PaLM)\n3B 9B\n80B\n0\n10\n20\n30\n40\n50\n60\nVQA accuracy (%)\n(D) OKVQA\n(Flamingo)\nPrior SOTA (pretrain–ﬁnetune)\nFew-shot prompting\nFigure 13: On some benchmarks, task-general models (not explicitly trained to perform a task) surpass prior\nstate-of-the-art performance held by a task-speciﬁc model. A & B: Brown et al. (2020). C: Chowdhery et al.\n(2022). D: Alayrac et al. (2022).\n28\n",
    "book_id": "220607682v2",
    "book_title": "2206.07682v2",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 91
  },
  {
    "chunk_full": "Published in Transactions on Machine Learning Research (08/2022)\nE\nBIG-Bench Task Classiﬁcation\nThis appendix contains the task classiﬁcation annotations used for Figure 8 in Appendix A.3. Each task only\nappears in a single category. That is, if a task was initially emergent with GPT-3 or LaMDA, we excluded it\nfrom the PaLM emergence category.\nNotably, Appendix E.4 lists the tasks where no model performs better than random (i.e., ﬂat scaling\ncurve). These tasks are potential candidates for future emergence, since a model in the future might achieve\nabove-random performance on them.\nE.1\nSmoothly increasing\nabstract narrative understanding, auto categorization, bbq lite json, cause and eﬀect, chess state tracking, con-\nlang translation, context deﬁnition alignment, contextual parametric knowledge conﬂicts, coqa conversational\nquestion answering, cryobiology spanish, date understanding, emojis emotion prediction, empirical judgments,\nentailed polarity, evaluating information essentiality, forecasting subquestions, gem, general knowledge, hindi\nquestion answering, human organs senses, implicatures, implicit relations, intent recognition, linguistic\nmappings, list functions, matrixshapes, mult data wrangling, multiemo, natural instructions, nonsense words\ngrammar, object counting, operators, penguins in a table, physics, polish sequence labeling, qa wikidata,\nreasoning about colored objects, rephrase, riddle sense, sentence ambiguity, similarities abstraction, simp\nturing concept, simple arithmetic, simple arithmetic json, simple arithmetic json multiple choice, simple\narithmetic json subtasks, simple arithmetic multiple targets json, simple ethical questions, squad shifts,\nsubject verb agreement, swedish to german proverbs, undo permutation, unit conversion, unnatural in context\nlearning, bridging anaphora resolution barqa, disﬂqa, novel concepts, periodic elements\nE.2\nEmergent with GPT-3 or LaMDA\nanalytic entailment, codenames, common morpheme, fact checker, ﬁgure of speech detection, gender inclusive\nsentences german, hindu knowledge, international phonetic alphabet transliterate, irony identiﬁcation, logical\nargs, logical deduction, misconceptions, modiﬁed arithmetic, phrase relatedness, physical intuition, question\nanswer creation, repeat copy logic, self evaluation tutoring, social iqa, sports understanding, strange stories,\nstrategyqa, swahili english proverbs, word sorting, word unscrambling\nE.3\nEmergent wih PaLM\nanachronisms, analogical similarity, ascii word recognition, auto debugging, causal judgment, code line\ndescription, conceptual combinations, crass ai, cryptonite, cs algorithms, disambiguation qa, elementary\nmath qa, emoji movie, english proverbs, english russian proverbs, geometric shapes, goal step wikihow,\ngre reading comprehension, hinglish toxicity, hyperbaton, identify odd metaphor, international phonetic\nalphabet nli, language identiﬁcation, linguistics puzzles, logic grid puzzle, logical fallacy detection, logical\nsequence, metaphor boolean, metaphor understanding, movie dialog same or diﬀerent, odd one out, parsinlu\nqa, parsinlu reading comprehension, physics questions, question selection, snarks, suﬃcient information,\ntemporal sequences, timedial, understanding fables, unit interpretation, vitaminc fact veriﬁcation\nE.4\nFlat (no model better than random)\nabstraction and reasoning corpus, authorship veriﬁcation, checkmate in one, chinese remainder theorem, cifar10\nclassiﬁcation, color, com2sense, cycled letters, discourse marker prediction, formal fallacies syllogisms negation,\nhhh alignment, kanji ascii, kannada, key value maps, language games, mathematical induction, minute\nmysteries qa, misconceptions russian, mnist ascii, multistep arithmetic, navigate, paragraph segmentation,\nplay dialog same or diﬀerent, presuppositions as nli, program synthesis, python programming challenge, real\nor fake text, roots optimization and games, salient translation error detection, self awareness, semantic parsing\nin context sparc, semantic parsing spider, simple text editing, sudoku, symbol interpretation, talkdown, tense,\ntext navigation game, topical chat, tracking shuﬄed objects, twenty questions, web of lies, which wiki edit,\nwinowhy, word problems on sets and graphs\n29\n",
    "book_id": "220607682v2",
    "book_title": "2206.07682v2",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 92
  },
  {
    "chunk_full": "Published in Transactions on Machine Learning Research (08/2022)\nE.5\nOther\nBetter than random and not correlated with scale: boolean expressions, crash blossom, dynamic counting,\nentailed polarity hindi, epistemic reasoning, factuality of summary, fantasy reasoning, gender sensitivity\nchinese, gender sensitivity english, high low game, identify math theorems, intersect geometry, muslim violence\nbias, persian idioms, protein interacting sites, scientiﬁc press release, self evaluation courtroom, social support,\nspelling bee, taboo, training on test set, truthful qa, yes no black white, dark humor detection, dyck languages,\nmoral permissibility, ruin names\nModel gets worse with scale: bbq lite, bias from probabilities, diverse social bias, movie recommendation,\nunqover\nNot enough examples: known unknowns, suicide risk, what is the tao\nIncomplete evals: convinceme, long context integration, medical questions russian\nOther: arithmetic (emergent at 1B, which is none of the above categories), few-shot nlg (not sure why\nBLEURT is negative here)\nF\nPaLM 62B is emergent but GPT-3 and LaMDA are not\nWe made the point in §5.2 that scale is not the only factor in emergence, since PaLM 62B shows emergence\non many BIG-Bench tasks for which GPT-3 175B and LaMDA 137B do not, even though PaLM 62B has\nfewer model parameter and less training FLOPs.\nThis is the list of tasks: anachronisms, ascii word recognition, conceptual combinations, cryptonite, disam-\nbiguation qa, emoji movie, goal step wikihow, gre reading comprehension, linguistics puzzles, logic grid puzzle,\nmetaphor boolean, metaphor understanding, odd one out, parsinlu qa.\n30\n",
    "book_id": "220607682v2",
    "book_title": "2206.07682v2",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 93
  },
  {
    "chunk_full": "The Prompt Report: A Systematic Survey of Prompt Engineering\nTechniques\nSander Schulhoff1,2∗\nMichael Ilie1∗Nishant Balepur1 Konstantine Kahadze1\nAmanda Liu1 Chenglei Si4 Yinheng Li5 Aayush Gupta1 HyoJung Han1 Sevien Schulhoff1\nPranav Sandeep Dulepet1 Saurav Vidyadhara1 Dayeon Ki1 Sweta Agrawal12 Chau Pham13\nGerson Kroiz Feileen Li1 Hudson Tao1 Ashay Srivastava1 Hevander Da Costa1 Saloni Gupta1\nMegan L. Rogers8 Inna Goncearenco9 Giuseppe Sarli9,10 Igor Galynker11\nDenis Peskoff7 Marine Carpuat1 Jules White6 Shyamal Anadkat3 Alexander Hoyle1 Philip Resnik1\n1 University of Maryland 2 Learn Prompting\n3 OpenAI\n4 Stanford\n5 Microsoft\n6 Vanderbilt\n7 Princeton\n8 Texas State University\n9 Icahn School of Medicine\n10 ASST Brianza\n11 Mount Sinai Beth Israel\n12 Instituto de Telecomunicações\n13 University of Massachusetts Amherst\nsschulho@umd.edu\nmilie@umd.edu\nresnik@umd.edu\nAbstract\nGenerative Artificial Intelligence (GenAI) systems are increasingly being deployed across diverse industries\nand research domains. Developers and end-users interact with these systems through the use of prompting\nand prompt engineering. Although prompt engineering is a widely adopted and extensively researched area,\nit suffers from conflicting terminology and a fragmented ontological understanding of what constitutes\nan effective prompt due to its relatively recent emergence. We establish a structured understanding of\nprompt engineering by assembling a taxonomy of prompting techniques and analyzing their applications.\nWe present a detailed vocabulary of 33 vocabulary terms, a taxonomy of 58 LLM prompting techniques,\nand 40 techniques for other modalities. Additionally, we provide best practices and guidelines for prompt\nengineering, including advice for prompting engineering ChatGPT and other state-of-the-art (SOTA) LLMs.\nWe further present a meta-analysis of the entire literature on natural language prefix-prompting. As a\nculmination of these efforts, this paper presents the most comprehensive survey on prompt engineering to\ndate.\n1\narXiv:2406.06608v6  [cs.CL]  26 Feb 2025\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 94
  },
  {
    "chunk_full": "Contents\n1\nIntroduction\n4\n1.1\nWhat is a Prompt? . . . . . . . . .\n5\n1.2\nTerminology . . . . . . . . . . . .\n5\n1.2.1\nComponents of a Prompt .\n5\n1.2.2\nPrompting Terms . . . . .\n6\n1.3\nA Short History of Prompts . . . .\n7\n2\nA Meta-Analysis of Prompting\n8\n2.1\nSystematic Review Process . . . .\n8\n2.1.1\nThe Pipeline\n. . . . . . .\n8\n2.2\nText-Based Techniques . . . . . .\n8\n2.2.1\nIn-Context Learning (ICL)\n8\n2.2.2\nThought Generation\n. . .\n12\n2.2.3\nDecomposition . . . . . .\n13\n2.2.4\nEnsembling . . . . . . . .\n14\n2.2.5\nSelf-Criticism . . . . . . .\n15\n2.3\nPrompting Technique Usage\n. . .\n16\n2.3.1\nBenchmarks . . . . . . . .\n16\n2.4\nPrompt Engineering . . . . . . . .\n16\n2.5\nAnswer Engineering\n. . . . . . .\n18\n2.5.1\nAnswer Shape\n. . . . . .\n18\n2.5.2\nAnswer Space . . . . . . .\n18\n2.5.3\nAnswer Extractor . . . . .\n18\n3\nBeyond English Text Prompting\n20\n3.1\nMultilingual . . . . . . . . . . . .\n20\n3.1.1\nChain-of-Thought (CoT) .\n20\n3.1.2\nIn-Context Learning\n. . .\n20\n3.1.3\nPrompt\nTemplate\nLan-\nguage Selection . . . . . .\n20\n3.1.4\nPrompting for Machine\nTranslation . . . . . . . .\n21\n3.2\nMultimodal . . . . . . . . . . . .\n22\n3.2.1\nImage Prompting . . . . .\n22\n3.2.2\nAudio Prompting . . . . .\n23\n3.2.3\nVideo Prompting . . . . .\n23\n3.2.4\nSegmentation Prompting .\n23\n3.2.5\n3D Prompting . . . . . . .\n23\n4\nExtensions of Prompting\n24\n4.1\nAgents . . . . . . . . . . . . . . .\n24\n4.1.1\nTool Use Agents\n. . . . .\n24\n4.1.2\nCode-Generation Agents .\n24\n4.1.3\nObservation-Based Agents\n25\n4.1.4\nRetrieval Augmented Gen-\neration (RAG)\n. . . . . .\n25\n4.2\nEvaluation . . . . . . . . . . . . .\n26\n4.2.1\nPrompting Techniques . .\n26\n4.2.2\nOutput Format\n. . . . . .\n27\n4.2.3\nPrompting Frameworks . .\n27\n4.2.4\nOther Methodologies . . .\n27\n5\nPrompting Issues\n29\n5.1\nSecurity . . . . . . . . . . . . . .\n29\n5.1.1\nTypes of Prompt Hacking .\n29\n5.1.2\nRisks of Prompt Hacking .\n29\n5.1.3\nHardening Measures . . .\n30\n5.2\nAlignment . . . . . . . . . . . . .\n31\n5.2.1\nPrompt Sensitivity\n. . . .\n31\n5.2.2\nOverconfidence and Cali-\nbration\n. . . . . . . . . .\n31\n5.2.3\nBiases, Stereotypes, and\nCulture . . . . . . . . . .\n32\n5.2.4\nAmbiguity\n. . . . . . . .\n32\n6\nBenchmarking\n33\n6.1\nTechnique Benchmarking . . . . .\n33\n6.1.1\nComparing\nPrompting\nTechniques . . . . . . . .\n33\n6.1.2\nQuestion Formats . . . . .\n33\n6.1.3\nSelf-Consistency . . . . .\n33\n6.1.4\nEvaluating Responses\n. .\n34\n6.1.5\nResults\n. . . . . . . . . .\n34\n6.2\nPrompt Engineering Case Study\n.\n34\n6.2.1\nProblem . . . . . . . . . .\n34\n6.2.2\nThe Dataset . . . . . . . .\n35\n6.2.3\nThe Process . . . . . . . .\n35\n6.2.4\nDiscussion\n. . . . . . . .\n42\n7\nRelated Work\n44\n8\nConclusions\n45\nA Appendices\n62\nA.1\nDefinitions of Prompting . . . . .\n62\nA.2\nExtended Vocabulary . . . . . . .\n64\nA.2.1\nPrompting Terms . . . . .\n64\nA.2.2\nPrompt Engineering Terms\n64\nA.2.3\nFine-Tuning Terms . . . .\n64\nA.2.4\nOrthogonal Prompt Types\n64\n2\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 95
  },
  {
    "chunk_full": "A.3\nDatasheet . . . . . . . . . . . . .\n66\nA.3.1\nMotivation\n. . . . . . . .\n66\nA.3.2\nComposition\n. . . . . . .\n66\nA.3.3\nCollection Process . . . .\n67\nA.3.4\nPreprocessing/ Cleaning/\nLabeling\n. . . . . . . . .\n67\nA.3.5\nUses . . . . . . . . . . . .\n67\nA.3.6\nDistribution . . . . . . . .\n67\nA.3.7\nMaintenance\n. . . . . . .\n67\nA.4\nKeywords . . . . . . . . . . . . .\n68\nA.5\nPrompt for Systematic Literature\nReview\n. . . . . . . . . . . . . .\n70\nA.6\nEvaluation Table\n. . . . . . . . .\n71\nA.7\nEntrapment Prompting Process . .\n72\nA.7.1\nExploration . . . . . . . .\n72\nA.7.2\nGetting a Label . . . . . .\n72\nA.7.3\nVarying Prompting Tech-\nniques . . . . . . . . . . .\n72\nA.8\nFormally Defining a Prompt\n. . .\n75\nA.9\nIn-Context Learning Definitions\nDisambiguation . . . . . . . . . .\n77\nA.10 Contributions . . . . . . . . . . .\n79\n3\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 96
  },
  {
    "chunk_full": "1\nIntroduction\nTransformer-based LLMs are widely deployed\nin consumer-facing, internal, and research settings\n(Bommasani et al., 2021). Typically, these models\nrely on the user providing an input “prompt” to\nwhich the model produces an output in response.\nSuch prompts may be textual—“Write a poem\nabout trees.”—or take other forms: images, audio,\nvideos, or a combination thereof. The ability to\nprompt models, particularly prompting with natu-\nral language, makes them easy to interact with and\nuse flexibly across a wide range of use cases.\nKnowing how to effectively structure, evaluate,\nand perform other tasks with prompts is essential\nto using these models. Empirically, better prompts\nlead to improved results across a wide range of\ntasks (Wei et al., 2022b; Liu et al., 2023b; Schul-\nhoff, 2022). A large body of literature has grown\naround the use of prompting to improve results\nand the number of prompting techniques is rapidly\nincreasing.\nHowever, as prompting is an emerging field, the\nuse of prompts continues to be poorly understood,\nwith only a fraction of existing terminologies and\ntechniques being well-known among practitioners.\nWe perform a large-scale review of prompting tech-\nniques to create a robust resource of terminology\nand techniques in the field. We expect this to be\nthe first iteration of terminologies that will develop\nover time. We maintain an up-to-date list of terms\nand techniques at LearnPrompting.org.\nScope of Study\nWe create a broad directory of\nprompting techniques, that can be quickly under-\nstood and easily implemented for rapid experimen-\ntation by developers and researchers. To this end,\nwe limit our study to focus on prefix prompts (Shin\net al., 2020a) rather than cloze prompts (Petroni\net al., 2019; Cui et al., 2021), because modern\nLLM transformer architectures widely employ pre-\nfix prompts and provide robust support for both\ndevelopers and researchers (Brown et al., 2020;\nGoogle, 2023; Touvron et al., 2023). Additionally,\nwe refined our focus to hard (discrete) prompts\nrather than soft (continuous) prompts and leave out\npapers that make use of techniques using gradient-\nbased updates (i.e. fine-tuning). Hard prompts con-\ntain only tokens (vectors) that correspond to words\nSafety needs throughout\nSecurity concerns \nthroughout\nNeed to evaluate prompt/\nagent outputs\nEvaluation\nSafety\nSecurity\n*Techniques on text data from \nmultiple languages\nOften make use of core prompting techniques\n*Techniques for processing multimedia \n(video, audio, etc)\nCore Prompting Techniques\nAgents\nMultilingual Techniques\nMultimodal Techniques\nText based Techniques\nMLT/MMTs are often derived from fundamental \ntext-based prompting techniques.\nFigure 1.1: Categories within the field of prompting are\ninterconnected. We discuss 7 core categories that are\nwell described by the papers within our scope.\nin the model’s vocabulary, while soft prompts may\ncontain tokens that have no corresponding word in\nthe vocabulary.\nFinally, we only study task-agnostic techniques.\nThese decisions keep the work approachable to less\ntechnical readers and maintain a manageable scope.\nSections Overview\nWe conducted a machine-\nassisted systematic review grounded in the\nPRISMA process (Page et al., 2021) (Section 2.1)\nto identify 58 different text-based prompting tech-\nniques, from which we create a taxonomy with a\nrobust terminology of prompting terms (Section\n1.2).\nOur goal is to provide a roadmap for the com-\nmunity when considering which prompting tech-\nniques to use (Figure 1.1). While much literature\non prompting focuses on English-only settings, we\nalso discuss multilingual techniques (Section 3.1).\nGiven the rapid growth in multimodal prompting,\nwhere prompts may include media such as images,\nwe also expand our scope to multimodal techniques\n(Section 3.2). Many multilingual and multimodal\nprompting techniques are direct extensions of En-\nglish text-only prompting techniques.\nAs prompting techniques grow more complex,\nthey have begun to incorporate external tools, such\nas Internet browsing and calculators. We use the\n4\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 97
  },
  {
    "chunk_full": "term \"agents\" to describe these types of prompting\ntechniques (Section 4.1).\nIt is important to understand how to evaluate\nthe outputs of agents and prompting techniques to\nensure accuracy and avoid hallucinations. Thus,\nwe discuss ways of evaluating these outputs (Sec-\ntion 4.2). We also discuss security (Section 5.1)\nand safety measures (Section 5.2) for designing\nprompts that reduce the risk of harm to companies\nand users.\nFinally, we apply prompting techniques in two\ncase studies (Section 6.1). In the first, we test a\nrange of prompting techniques against the com-\nmonly used benchmark MMLU (Hendrycks et al.,\n2021). In the second, we explore in detail an exam-\nple of manual prompt engineering on a significant,\nreal-world use case, identifying signals of frantic\nhopelessness–a top indicator of suicidal crisis–in\nthe text of individuals seeking support (Schuck\net al., 2019a). We conclude with a discussion of\nthe nature of prompting and its recent development\n(Section 8).\n1.1\nWhat is a Prompt?\nA prompt is an input to a Generative AI model, that\nis used to guide its output (Meskó, 2023; White\net al., 2023; Heston and Khun, 2023; Hadi et al.,\n2023; Brown et al., 2020). Prompts may consist\nof text, image, sound, or other media. Some ex-\namples of prompts include the text, “write a three\nparagraph email for a marketing campaign for an\naccounting firm”, a photograph of a piece of paper\nwith the words “what is 10*179” written on it, or\na recording of an online meeting, with the instruc-\ntions “summarize this”. Prompts usually have some\ntext component, but this may change as non-text\nmodalities become more common.\nPrompt Template\nPrompts are often constructed\nvia a prompt template (Shin et al., 2020b).\nA\nprompt template is a function that contains one or\nmore variables which will be replaced by some me-\ndia (usually text) to create a prompt. This prompt\ncan then be considered to be an instance of the\ntemplate.\nConsider applying prompting to the task of bi-\nnary classification of tweets. Here is an initial\nprompt template that can be used to classify inputs.\nClassify the tweet as positive or negative:\n{TWEET}\nWrite a poem about trees.\nWrite a poem about the following topic:\n{USER_INPUT}\nFigure 1.2: Prompts and prompt templates are distinct\nconcepts; a prompt template becomes a prompt when\ninput is inserted into it.\nEach tweet in the dataset would be inserted into\na separate instance of the template and the resulting\nprompt would be given to a LLM for inference.\n1.2\nTerminology\n1.2.1\nComponents of a Prompt\nThere are a variety of common components in-\ncluded in a prompt. We summarize the most com-\nmonly used components and discuss how they fit\ninto prompts (Figure 1.3).\nDirective\nMany prompts issue a directive in the\nform of an instruction or question.1 This is the\ncore intent of the prompt, sometimes simply called\nthe \"intent\". For example, here is an instance of a\nprompt with a single instruction:\nTell me five good books to read.\nDirectives can also be implicit, as in this one-\nshot case, where the directive is to perform English\nto Spanish translation:\nNight: Noche\nMorning:\nExamples\nExamples, also known as exemplars or\nshots, act as demonstrations that guide the GenAI\nto accomplish a task. The above prompt is a One-\nShot (i.e. one example) prompt.\nOutput Formatting\nIt is often desirable for the\nGenAI to output information in certain formats,\nfor example, CSV, Markdown, XML, or even cus-\ntom formats(Xia et al., 2024). Structuring outputs\nmay reduce performance on some tasks (Tam et al.,\n2024). However, Kurt (2024) point out various\n1“Directives”, from Searle (1969), are a type of speech act\nintended to encourage an action, and have been invoked in\nmodels of human-computer dialogue Morelli et al. (1991).\n5\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 98
  },
  {
    "chunk_full": "Prompt 1.1\nPrompting 1.2.2\nContext 1.2.1\nContext Window A.2.1\nPriming A.2.1\nPrompting Technique\n1.2.2\nIn-Context Learning\n2.2.1\nFew-Shot Prompt 2.2.1\nExemplar 1.2.2\nZero-Shot Prompt 2.2.1.3\nOrthogonal Prompt Types\nA.2.4\nDensity A.2.4.2\nContinuous Prompt\nA.2.4.2\nDiscrete Prompt A.2.4.2\nOriginator A.2.4.1\nUser Prompt A.2.4.1\nSystem Prompt A.2.4.1\nAssistant Prompt A.2.4.1\nPrediction Style A.2.4.3\nPrefix A.2.4.3\nCloze A.2.4.3\nPrompt Chain 1.2.2\nPrompt Template 1.1\nPrompt Engineering 1.2.2\nPrompt Engineering\nTechnique 1.2.2\nMeta-Prompting 2.4\nAnswer Engineering\n2.5\nVerbalizer 2.5.3\nExtractor 2.5.3\nAnswer Trigger 2.5.3\nConversational Prompt\nEngineering A.2.2\nFine-Tuning A.2.3\nPrompt-Based\nLearning A.2.3\nPrompt Tuning A.2.3\nFigure 1.3: A Terminology of prompting. Terms with links to the appendix are not sufficiently critical to describe in\nthe main paper, but are important to the field of prompting. Prompting techniques are shown in Figure 2.2\n.\nflaws in Tam et al. (2024) and show that structuring\noutputs may actually improve performance. Here\nis an example of how you might format a prompt\nto output information as a CSV:\n{PARAGRAPH}\nSummarize this into a CSV.\nStyle Instructions\nStyle instructions are a type of\noutput formatting used to modify the output stylisti-\ncally rather than structurally (Section 2.2.1.3). For\nexample:\nWrite a clear and curt paragraph about lla-\nmas.\nRole\nA Role, also known as a persona (Schmidt\net al., 2023; Wang et al., 2023l), is a frequently\ndiscussed component that can improve writing and\nstyle text (Section 2.2.1.3). For example:\nPretend you are a shepherd and write a lim-\nerick about llamas.\nAdditional Information\nIt is often necessary to\ninclude additional information in the prompt. For\nexample, if the directive is to write an email, you\nmight include information such as your name and\nposition so the GenAI can properly sign the email.\nAdditional Information is sometimes called ‘con-\ntext‘, though we discourage the use of this term as\nit is overloaded with other meanings in the prompt-\ning space2.\n1.2.2\nPrompting Terms\nTerminology within the prompting literature is\nrapidly developing. As it stands, there are many\npoorly understood definitions (e.g. prompt, prompt\nengineering) and conflicting ones (e.g. role prompt\nvs persona prompt). The lack of a consistent vocab-\nulary hampers the community’s ability to clearly\ndescribe the various prompting techniques in use.\nWe provide a robust vocabulary of terms used in the\nprompting community (Figure 1.3).3 Less frequent\nterms are left to Appendix A.2. In order to accu-\nrately define frequently-used terms like prompt and\nprompt engineering, we integrate many definitions\n(Appendix A.1) to derive representative definitions.\nPrompting\nPrompting is the process of provid-\ning a prompt to a GenAI, which then generates a\nresponse. For example, the action of sending a\n2e.g. the context is the tokens processed by the LLM in a\nforward pass\n3By robust, we mean that it covers most existing commonly\nused terms in the field.\n6\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 99
  },
  {
    "chunk_full": "x₁\nx₂\nxₙ\nPrompt Template\nGenerative AI\nExtractor\nUtility Function\nDataset Inference (i.e. entries x₁ ... xₙ)\nModify Prompt \nTemplate until \nDesiderata Met\nFigure 1.4: The Prompt Engineering Process consists of\nthree repeated steps 1) performing inference on a dataset\n2) evaluating performance and 3) modifying the prompt\ntemplate. Note that the extractor is used to extract a\nfinal response from the LLM output (e.g. \"This phrase\nis positive\" →\"positive\"). See more information on\nextractors in Section 2.5.\nchunk of text or uploading an image constitutes\nprompting.\nPrompt Chain\nA prompt chain (activity: prompt\nchaining) consists of two or more prompt templates\nused in succession. The output of the prompt gen-\nerated by the first prompt template is used to pa-\nrameterize the second template, continuing until all\ntemplates are exhausted (Wu et al., 2022).\nPrompting Technique\nA prompting technique\nis a blueprint that describes how to structure a\nprompt, prompts, or dynamic sequencing of multi-\nple prompts. A prompting technique may incorpo-\nrate conditional or branching logic, parallelism, or\nother architectural considerations spanning multi-\nple prompts.\nPrompt Engineering\nPrompt engineering is the\niterative process of developing a prompt by modify-\ning or changing the prompting technique that you\nare using (Figure 1.4).\nPrompt Engineering Technique\nA prompt engi-\nneering technique is a strategy for iterating on a\nprompt to improve it. In literature, this will often\nbe automated techniques (Deng et al., 2022), but in\nconsumer settings, users often perform prompt en-\ngineering manually, without any assistive tooling.\nExemplar\nExemplars are examples of a task be-\ning completed that are shown to a model in a\nprompt (Brown et al., 2020).\n1.3\nA Short History of Prompts\nThe idea of using natural language prefixes, or\nprompts, to elicit language model behaviors and\nresponses originated before the GPT-3 and Chat-\nGPT era. GPT-2 (Radford et al., 2019a) makes\nuse of prompts and they appear to be first used in\nthe context of Generative AI by Fan et al. (2018).\nHowever, the concept of prompts was preceded by\nrelated concepts such as control codes (Pfaff, 1979;\nPoplack, 1980; Keskar et al., 2019) and writing\nprompts in literature.\nThe term Prompt Engineering appears to have\ncome into existence more recently from Radford\net al. (2021) then slightly later from Reynolds and\nMcDonell (2021).\nHowever, various papers perform prompt engi-\nneering without naming the term (Wallace et al.,\n2019; Shin et al., 2020a), including Schick and\nSchütze (2020a,b); Gao et al. (2021) for non-\nautoregressive language models.\nSome of the first works on prompting define a\nprompt slightly differently to how it is currently\nused. For example, consider the following prompt\nfrom Brown et al. (2020):\nTranslate English to French:\nllama\nBrown et al. (2020) consider the word \"llama\" to\nbe the prompt, while \"Translate English to French:\"\nis the \"task description\". More recent papers, in-\ncluding this one, refer to the entire string passed to\nthe LLM as the prompt.\n7\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 100
  },
  {
    "chunk_full": "2\nA Meta-Analysis of Prompting\n2.1\nSystematic Review Process\nIn order to robustly collect a dataset of sources\nfor this paper, we ran a systematic literature re-\nview grounded in the PRISMA process (Page et al.,\n2021) (Figure 2.1). We host this dataset on Hug-\ngingFace 4 and present a datasheet (Gebru et al.,\n2021) for the dataset in Appendix A.3. Our main\ndata sources were arXiv, Semantic Scholar, and\nACL. We query these databases with a list of\n44 keywords narrowly related to prompting and\nprompt engineering (Appendix A.4).\n2.1.1\nThe Pipeline\nIn this section, we introduce our data scraping\npipeline, which includes both human and LLM-\nassisted review.5 As an initial sample to estab-\nlish filtering critera, we retrieve papers from arXiv\nbased on a simple set of keywords and boolean\nrules (A.4). Then, human annotators label a sample\nof 1,661 articles from the arXiv set for the follow-\ning criteria:\n1. Include if the paper proposes a novel prompt-\ning technique.\n2. Include if the paper strictly covers hard prefix\nprompts.\n3. Exclude if the paper focuses on training by\nbackpropagating gradients.\n4. Include if the paper uses a masked frame\nand/or window for non-text modalities.\nA set of 300 articles are reviewed independently\nby two annotators, with 92% agreement (Krippen-\ndorff’s α = Cohen’s κ = 81%). Next, we develop\na prompt using gpt-4-1106-preview to classify the\nremaining articles (Appendix A.5). We validate\nthe prompt against 100 ground-truth annotations,\nachieving 89% precision and 75% recall (for an F1\nof 81%). The combined human and LLM annota-\ntions generate a final set of 1,565 papers.\n4https://huggingface.co/datasets/PromptSystematicReview/Prompt_Systematic_Review_Dataset\n5Using gpt-4-1106-preview\nAfter The PRISMA Review Process,\n records included in \n analysis.\n1,565\nquantitative\n3,677 from arXiv 2,087 from SS, 639 from ACL = 4797 Records\n-550\n4,247 Records after Title \nDeduplication\n1,661 papers human reviewed\n316 papers excluded\n3,931 Records after Human \nReview\n1,579 papers excluded\n2,352 Records after \nremoving papers that don’t \ncontain the word “prompt”\n1,071 papers AI reviewed\nCheck if paper contains the \nword “prompt”\n-787\n-1,579\n-316\n787 papers excluded\nFigure 2.1: The PRISMA systematic literature review\nprocess. We accumulate 4,247 unique records from\nwhich we extract 1,565 relevant records.\n2.2\nText-Based Techniques\nWe now present a comprehensive taxonomical on-\ntology of 58 text-based prompting techniques, bro-\nken into 6 major categories (Figure 2.2). Although\nsome of the techniques might fit into multiple cate-\ngories, we place them in a single category of most\nrelevance.\n2.2.1\nIn-Context Learning (ICL)\nICL refers to the ability of GenAIs to learn skills\nand tasks by providing them with exemplars and or\nrelevant instructions within the prompt, without the\nneed for weight updates/retraining (Brown et al.,\n2020; Radford et al., 2019b). These skills can be\nlearned from exemplars (Figure 2.4) and/or instruc-\ntions (Figure 2.5). Note that the word \"learn\" is\nmisleading. ICL can simply be task specification–\nthe skills are not necessarily new, and can have\nalready been included in the training data (Figure\n2.6). See Appendix A.9 for a discussion of the use\nof this term. Significant work is currently being\ndone on optimizing (Bansal et al., 2023) and un-\nderstanding (Si et al., 2023a; Štefánik and Kadlˇcík,\n2023) ICL.\n8\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 101
  },
  {
    "chunk_full": "Text-Base Prompt. Tech.\nZero-Shot 2.2.1.3\nEmotion Prompting 2.2.1.3\nRole Prompting 2.2.1.3\nStyle Prompting 2.2.1.3\nS2A 2.2.1.3\nSimToM 2.2.1.3\nRaR 2.2.1.3\nRE2 2.2.1.3\nSelf-Ask 2.2.1.3\nFew-Shot 2.2.1\nExemplar Generation\nSG-ICL 2.2.1.2\nExemplar Ordering 2.2.1.1\nExemplar Selection\n2.2.1.2\nKNN 2.2.1.2\nVote-K 2.2.1.2\nInstruction Selection 2.2.1.1\nThought Generation 2.2.2\nChain-of-Thought\n(CoT) 2.2.2\nZero-Shot CoT 2.2.2.1\nAnalogical Prompting\n2.2.2.1\nStep-Back Prompting\n2.2.2.1\nThread-of-Thought\n(ThoT) 2.2.2.1\nTab-CoT 2.2.2.1\nFew-Shot CoT 2.2.2.2\nActive-Prompt 2.2.2.2\nAuto-CoT 2.2.2.2\nComplexity-Based 2.2.2.2\nContrastive 2.2.2.2\nMemory-of-Thought\n2.2.2.2\nUncertainty-Routed\nCoT 2.2.2.2\nPrompt Mining 2.2.1.2\nAutoDiCoT 6.2.3.3\nEnsembling 2.2.4\nCOSP 2.2.4\nDENSE 2.2.4\nDiVeRSe 2.2.4\nMax Mutual\nInformation 2.2.4\nMeta-CoT 2.2.4\nMoRE 2.2.4\nSelf-Consistency 2.2.4\nUniversal\nSelf-Consistency 2.2.4\nUSP 2.2.4\nPrompt Paraphrasing 2.2.4\nSelf-Criticism 2.2.5\nChain-of-Verification 2.2.5\nSelf-Calibration 2.2.5\nSelf-Refine 2.2.5\nSelf-Verification 2.2.5\nReverseCoT 2.2.5\nCumulative Reason. 2.2.5\nDecomposition 2.2.3\nDECOMP 2.2.3\nFaithful CoT 2.2.3\nLeast-to-Most 2.2.3\nPlan-and-Solve 2.2.3\nProgram-of-Thought 2.2.3\nRecurs.-of-Thought 2.2.3\nSkeleton-of-Thought 2.2.3\nTree-of-Thought 2.2.3\nMetacognitive 2.2.3\nFigure 2.2: All text-based prompting techniques from our dataset.\n9\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 102
  },
  {
    "chunk_full": "3. Exemplar Label Distribution\nProvide a balanced label \ndistribution*\nI am so mad: \nPeople are so dense: \nI hate my boss: \nLife is good: \nI’m so excited: \nAngry\nAngry\nAngry\nHappy\nI am so mad: \nI love life: \nI hate my boss: \nLife is good: \nI’m so excited: \nAngry\nAngry\nHappy\nHappy\n2. Exemplar Ordering\nRandomly order exemplars*\nI am so mad: \nI love life: \nI hate my boss: \nLife is good: \nI’m so excited: \nAngry\nAngry\nHappy\nHappy\nI love life: \nLife is good: \nI am so mad: \nI hate my boss: \nI’m so excited: \nHappy\nHappy\nAngry\nAngry\n4. Exemplar Label Quality\nEnsure exemplars are labeled \ncorrectly*\nI am so mad: \nI love life: \nI hate my boss: \nLife is good: \nI’m so excited: \nAngry\nAngry\nHappy\nHappy\nI am so mad: \nI love life: \nI hate my boss: \nLife is good: \nI’m so excited: \nHappy\nHappy\nAngry\nAngry\n6. Exemplars Similarity\nSelect similar exemplars to \nthe test instance*\nIm hyped!: \nIm not very excited: \nI’m so excited: \nHappy\nAngry\nTrees are beautiful: \nYouTube Ads Suck: \nI’m so excited: \nHappy\nAngry\n5. Exemplar Format\nChoose a common format*\nIm hyped!: \nIm not very excited: \nI’m so excited: \nHappy\nAngry\nTrees are nice===\nYouTube Ads Suck===\nI’m so excited===\nHappy\nAngry\n1. Exemplar Quantity\nInclude as many exemplars as \npossible*\nTrees are beautiful: \nI hate Pizza: \nSquirrels are so cute: \nYouTube Ads Suck: \nI’m so excited: \nHappy\nHappy\nAngry\nAngry\nTrees are beautiful: \nI’m so excited: \nHappy\nFigure 2.3: We highlight six main design decisions\nwhen crafting few-shot prompts. ∗Please note that rec-\nommendations here do not generalize to all tasks; in\nsome cases, each of them could hurt performance.\nFew-Shot Prompting\n(Brown et al., 2020) is the\nparadigm seen in Figure 2.4, where the GenAI\nlearns to complete a task with only a few examples\n(exemplars). Few-shot prompting is a special case\nof Few-Shot Learning (FSL) (Fei-Fei et al., 2006;\nWang et al., 2019), but does not require updating\nof model parameters\n2.2.1.1\nFew-Shot Prompting Design Decisions\nSelecting exemplars for a prompt is a difficult task–\nperformance depends significantly on various fac-\ntors of the exemplars (Dong et al., 2023), and only\na limited number of exemplars fit in the typical\nLLM’s context window. We highlight six separate\ndesign decisions, including the selection and or-\nder of exemplars that critically influence the output\nquality (Zhao et al., 2021a; Lu et al., 2021; Ye and\nDurrett, 2023) (Figure 2.3).\n2+2: four\n4+5: nine\n8+0:\nFigure 2.4: ICL exemplar prompt\nExtract all words that have 3 of the same\nletter and at least 3 other letters from the\nfollowing text: {TEXT}\nFigure 2.5: ICL instruction prompt\nExemplar Quantity\nIncreasing the quantity of ex-\nemplars in the prompt generally improves model\nperformance, particularly in larger models (Brown\net al., 2020). However, in some cases, the bene-\nfits may diminish beyond 20 exemplars (Liu et al.,\n2021). In the case of long context LLMs, addi-\ntional exemplars continue to increase performance,\nthough efficiency varies depending on task and\nmodel (Agarwal et al., 2024; Bertsch et al., 2024;\nJiang et al., 2024).\nExemplar Ordering\nThe order of exemplars af-\nfects model behavior (Lu et al., 2021; Kumar and\nTalukdar, 2021; Liu et al., 2021; Rubin et al., 2022).\nOn some tasks, exemplar order can cause accuracy\nto vary from sub-50% to 90%+ (Lu et al., 2021).\nExemplar Label Distribution\nAs in traditional\nsupervised machine learning, the distribution of\nexemplar labels in the prompt affects behavior. For\nexample, if 10 exemplars from one class and 2\nexemplars of another class are included, this may\ncause the model to be biased toward the first class.\nExemplar Label Quality\nDespite the general ben-\nefit of multiple exemplars, the necessity of strictly\nvalid demonstrations is unclear. Some work (Min\net al., 2022) suggests that the accuracy of labels is\nirrelevant—providing models with exemplars with\nincorrect labels may not negatively diminish per-\nformance. However, under certain settings, there\nis a significant impact on performance (Yoo et al.,\n2022). Larger models are often better at handling\nincorrect or unrelated labels (Wei et al., 2023c).\nIt is important to discuss this factor, since if you\nare automatically constructing prompts from large\ndatasets that may contain inaccuracies, it may be\n10\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 103
  },
  {
    "chunk_full": "Translate the word \"cheese\" to French.\nFigure 2.6: ICL from training data prompt. In this\nversion of ICL, the model is not learning a new skill,\nbut rather using knowledge likely in its training set.\nnecessary to study how label quality affects your\nresults.\nExemplar Format\nThe formatting of exemplars\nalso affects performance. One of the most common\nformats is “Q: {input}, A: {label}”, but the optimal\nformat may vary across tasks; it may be worth\ntrying multiple formats to see which performs best.\nThere is some evidence to suggest that formats that\noccur commonly in the training data will lead to\nbetter performance (Jiang et al., 2020).\nExemplar Similarity\nSelecting exemplars that\nare similar to the test sample is generally bene-\nficial for performance (Liu et al., 2021; Min et al.,\n2022). However, in some cases, selecting more\ndiverse exemplars can improve performance (Su\net al., 2022; Min et al., 2022).\nInstruction Selection\nWhile instructions are re-\nquired to guide LLMs in zero-shot prompts (Wei\net al., 2022a), the benefits of adding instructions\nbefore exemplars in few-shot prompts is less clear.\nAjith et al. (2024) show that generic, task-agnostic\ninstructions (i.e., no instruction or “Complete the\nfollowing task:”) improve classification and ques-\ntion answering accuracy over task-specific ones\n(e.g., What is the answer to this question?) conclud-\ning instruction-following abilities can be achieved\nvia exemplars alone. While they may not improve\ncorrectness, instructions in few-shot prompts can\nstill guide auxiliary output attributes like writing\nstyle (Roy et al., 2023).\n2.2.1.2\nFew-Shot Prompting Techniques\nConsidering all of these factors, Few-Shot Prompt-\ning can be very difficult to implement effectively.\nWe now examine techniques for Few-Shot Prompt-\ning in the supervised setting.\nEnsembling ap-\nproaches can also benefit Few-Shot Prompting, but\nwe discuss them separately (Section 2.2.4).\nAssume we have a training dataset, Dtrain,\nwhich contains multiple inputs Dtrain\nxi\nand outputs\nDtrain\nyi\n, which can be used to few-shot prompt a\nGenAI (rather than performing gradient-based up-\ndates). Assume that this prompt can be dynamically\ngenerated with respect to Dtest\nxi\nat test time. Here\nis the prompt template we will use for this section,\nfollowing the ‘input: output‘ format (Figure 2.4):\n{Exemplars}\nDtest\nxi :\nFigure 2.7: Few-Shot Prompting Template\nK-Nearest Neighbor (KNN)\n(Liu et al., 2021) is\npart of a family of algorithms that selects exemplars\nsimilar to Dtest\nxi\nto boost performance. Although ef-\nfective, employing KNN during prompt generation\nmay be time and resource intensive.\nVote-K\n(Su et al., 2022) is another method to\nselect similar exemplars to the test sample. In one\nstage, a model proposes useful unlabeled candidate\nexemplars for an annotator to label. In the sec-\nond stage, the labeled pool is used for Few-Shot\nPrompting. Vote-K also ensures that newly added\nexemplars are sufficiently different than existing\nones to increase diversity and representativeness.\nSelf-Generated In-Context Learning (SG-ICL)\n(Kim et al., 2022) leverages a GenAI to automati-\ncally generate exemplars. While better than zero-\nshot scenarios when training data is unavailable,\nthe generated samples are not as effective as actual\ndata.\nPrompt Mining\n(Jiang et al., 2020) is the process\nof discovering optimal \"middle words\" in prompts\nthrough large corpus analysis. These middle words\nare effectively prompt templates. For example, in-\nstead of using the common \"Q: A:\" format for few-\nshot prompts, there may exist something similar\nthat occurs more frequently in the corpus. Formats\nwhich occur more often in the corpus will likely\nlead to improved prompt performance.\nMore Complicated Techniques\nsuch as LENS\n(Li and Qiu, 2023a), UDR (Li et al., 2023f), and\nActive Example Selection (Zhang et al., 2022a)\nleverage iterative filtering, embedding and retrieval,\nand reinforcement learning, respectively.\n2.2.1.3\nZero-Shot Prompting Techniques\nIn contrast to Few-Shot Prompting, Zero-Shot\nPrompting uses zero exemplars. There are a num-\nber of well-known standalone zero-shot techniques\n11\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 104
  },
  {
    "chunk_full": "as well as zero-shot techniques combined with an-\nother concept (e.g. Chain of Thought), which we\ndiscuss later (Section 2.2.2).\nRole Prompting\n(Wang et al., 2023j; Zheng\net al., 2023d) , also known as persona prompting\n(Schmidt et al., 2023; Wang et al., 2023l), assigns a\nspecific role to the GenAI in the prompt. For exam-\nple, the user might prompt it to act like \"Madonna\"\nor a \"travel writer\". This can create more desir-\nable outputs for open-ended tasks (Reynolds and\nMcDonell, 2021) and in some cases may improve\naccuracy on benchmarks (Zheng et al., 2023d).\nStyle Prompting\n(Lu et al., 2023a) involves spec-\nifying the desired style, tone, or genre in the prompt\nto shape the output of a GenAI. A similar effect\ncan be achieved using role prompting.\nEmotion Prompting\n(Li et al., 2023a) incorpo-\nrates phrases of psychological relevance to humans\n(e.g., \"This is important to my career\") into the\nprompt, which may lead to improved LLM perfor-\nmance on benchmarks and open-ended text genera-\ntion.\nSystem\n2\nAttention\n(S2A)\n(Weston\nand\nSukhbaatar, 2023) first asks an LLM to rewrite\nthe prompt and remove any information unrelated\nto the question therein. Then, it passes this new\nprompt into an LLM to retrieve a final response.\nSimToM\n(Wilf et al., 2023) deals with compli-\ncated questions which involve multiple people or\nobjects. Given the question, it attempts to establish\nthe set of facts one person knows, then answer the\nquestion based only on those facts. This is a two\nprompt process and can help eliminate the effect of\nirrelevant information in the prompt.\nRephrase and Respond (RaR)\n(Deng et al., 2023)\ninstructs the LLM to rephrase and expand the ques-\ntion before generating the final answer. For ex-\nample, it might add the following phrase to the\nquestion: \"Rephrase and expand the question, and\nrespond\". This could all be done in a single pass\nor the new question could be passed to the LLM\nseparately. RaR has demonstrated improvements\non multiple benchmarks.\nRe-reading (RE2)\n(Xu et al., 2023) adds the\nphrase \"Read the question again:\" to the prompt in\naddition to repeating the question. Although this is\nsuch a simple technique, it has shown improvement\nQ: Jack has two baskets, each containing\nthree balls. How many balls does Jack have\nin total?\nA: One basket contains 3 balls, so two bas-\nkets contain 3 * 2 = 6 balls.\nQ: {QUESTION}\nA:\nFigure 2.8: A One-Shot Chain-of-Thought Prompt.\nin reasoning benchmarks, especially with complex\nquestions.\nSelf-Ask\n(Press et al., 2022) prompts LLMs to\nfirst decide if they need to ask follow up questions\nfor a given prompt. If so, the LLM generates these\nquestions, then answers them and finally answers\nthe original question.\n2.2.2\nThought Generation\nThought generation encompasses a range of tech-\nniques that prompt the LLM to articulate its reason-\ning while solving a problem (Zhang et al., 2023c).\nChain-of-Thought (CoT) Prompting\n(Wei et al.,\n2022b) leverages few-shot prompting to encour-\nage the LLM to express its thought process before\ndelivering its final answer.6 This technique is occa-\nsionally referred to as Chain-of-Thoughts (Tutunov\net al., 2023; Besta et al., 2024; Chen et al., 2023d).\nIt has been demonstrated to significantly enhance\nthe LLM’s performance in mathematics and reason-\ning tasks. In Wei et al. (2022b), the prompt includes\nan exemplar featuring a question, a reasoning path,\nand the correct answer (Figure 2.8).\n2.2.2.1\nZero-Shot-CoT\nThe most straightforward version of CoT contains\nzero exemplars. It involves appending a thought\ninducing phrase like \"Let’s think step by step.\"\n(Kojima et al., 2022) to the prompt. Other sug-\ngested thought-generating phrases include \"First,\nlet’s think about this logically\" (Kojima et al.,\n2022). Zhou et al. (2022b) uses LLMs to generate\n\"Let’s work this out in a step by step way to be\nsure we have the right answer\". Yang et al. (2023a)\nsearches for an optimal thought inducer. Zero-Shot-\n6We note that such techniques are often described using\nwords like \"think\" that anthropomorphize models. We attempt\nnot to use this language, but do use original authors’ language\nwhere appropriate.\n12\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 105
  },
  {
    "chunk_full": "CoT approaches are attractive as they don’t require\nexemplars and are generally task agnostic.\nStep-Back Prompting\n(Zheng et al., 2023c) is a\nmodification of CoT where the LLM is first asked\na generic, high-level question about relevant con-\ncepts or facts before delving into reasoning. This\napproach has improved performance significantly\non multiple reasoning benchmarks for both PaLM-\n2L and GPT-4.\nAnalogical Prompting\n(Yasunaga et al., 2023)\nis similar to SG-ICL, and automatically generates\nexemplars that include CoTs. It has demonstrated\nimprovements in mathematical reasoning and code\ngeneration tasks.\nThread-of-Thought (ThoT) Prompting\n(Zhou\net al., 2023) consists of an improved thought in-\nducer for CoT reasoning. Instead of \"Let’s think\nstep by step,\" it uses \"Walk me through this context\nin manageable parts step by step, summarizing and\nanalyzing as we go.\" This thought inducer works\nwell in question-answering and retrieval settings,\nespecially when dealing with large, complex con-\ntexts.\nTabular Chain-of-Thought (Tab-CoT)\n(Jin and\nLu, 2023) consists of a Zero-Shot CoT prompt that\nmakes the LLM output reasoning as a markdown\ntable. This tabular design enables the LLM to im-\nprove the structure and thus the reasoning of its\noutput.\n2.2.2.2\nFew-Shot CoT\nThis set of techniques presents the LLM with mul-\ntiple exemplars, which include chains-of-thought.\nThis can significantly enhance performance. This\ntechnique is occasionally referred to as Manual-\nCoT (Zhang et al., 2022b) or Golden CoT (Del and\nFishel, 2023).\nContrastive CoT Prompting\n(Chia et al., 2023)\nadds both exemplars with incorrect and correct ex-\nplanations to the CoT prompt in order to show the\nLLM how not to reason. This method has shown\nsignificant improvement in areas like Arithmetic\nReasoning and Factual QA.\nUncertainty-Routed CoT Prompting\n(Google,\n2023) samples multiple CoT reasoning paths, then\nselects the majority if it is above a certain thresh-\nold (calculated based on validation data). If not, it\nsamples greedily and selects that response. This\nmethod demonstrates improvement on the MMLU\nbenchmark for both GPT-4 and Gemini Ultra mod-\nels.\nComplexity-based Prompting\n(Fu et al., 2023b)\ninvolves two major modifications to CoT. First, it\nselects complex examples for annotation and in-\nclusion in the prompt, based on factors like ques-\ntion length or reasoning steps required. Second,\nduring inference, it samples multiple reasoning\nchains (answers) and uses a majority vote among\nchains exceeding a certain length threshold, under\nthe premise that longer reasoning indicates higher\nanswer quality. This technique has shown improve-\nments on three mathematical reasoning datasets.\nActive Prompting\n(Diao et al., 2023) starts with\nsome training questions/exemplars, asks the LLM\nto solve them, then calculates uncertainty (disagree-\nment in this case) and asks human annotators to\nrewrite the exemplars with highest uncertainty.\nMemory-of-Thought Prompting\n(Li and Qiu,\n2023b) leverage unlabeled training exemplars to\nbuild Few-Shot CoT prompts at test time. Before\ntest time, it performs inference on the unlabeled\ntraining exemplars with CoT. At test time, it re-\ntrieves similar instances to the test sample. This\ntechnique has shown substantial improvements in\nbenchmarks like Arithmetic, commonsense, and\nfactual reasoning.\nAutomatic Chain-of-Thought (Auto-CoT) Prompt-\ning\n(Zhang et al., 2022b) uses Wei et al. (2022b)’s\nZero-Shot prompt to automatically generate chains\nof thought. These are then used to build a Few-Shot\nCoT prompt for a test sample.\n2.2.3\nDecomposition\nSignificant research has focused on decomposing\ncomplex problems into simpler sub-questions. This\nis an effective problem-solving strategy for humans\nas well as GenAI (Patel et al., 2022). Some decom-\nposition techniques are similar to thought-inducing\ntechniques, such as CoT, which often naturally\nbreaks down problems into simpler components.\nHowever, explicitly breaking down problems can\nfurther improve LLMs’ problem solving ability.\nLeast-to-Most Prompting\n(Zhou et al., 2022a)\nstarts by prompting a LLM to break a given prob-\nlem into sub-problems without solving them. Then,\nit solves them sequentially, appending model re-\nsponses to the prompt each time, until it arrives\n13\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 106
  },
  {
    "chunk_full": "at a final result. This method has shown signif-\nicant improvements in tasks involving symbolic\nmanipulation, compositional generalization, and\nmathematical reasoning.\nDecomposed\nPrompting\n(DECOMP)\n(Khot\net al., 2022) Few-Shot prompts a LLM to show it\nhow to use certain functions. These might include\nthings like string splitting or internet searching;\nthese are often implemented as separate LLM calls.\nGiven this, the LLM breaks down its original prob-\nlem into sub-problems which it sends to different\nfunctions. It has shown improved performance over\nLeast-to-Most prompting on some tasks.\nPlan-and-Solve Prompting\n(Wang et al., 2023f)\nconsists of an improved Zero-Shot CoT prompt,\n\"Let’s first understand the problem and devise a\nplan to solve it. Then, let’s carry out the plan and\nsolve the problem step by step\". This method gener-\nates more robust reasoning processes than standard\nZero-Shot-CoT on multiple reasoning datasets.\nTree-of-Thought (ToT)\n(Yao et al., 2023b), also\nknown as Tree of Thoughts, (Long, 2023), creates a\ntree-like search problem by starting with an initial\nproblem then generating multiple possible steps in\nthe form of thoughts (as from a CoT). It evaluates\nthe progress each step makes towards solving the\nproblem (through prompting) and decides which\nsteps to continue with, then keeps creating more\nthoughts. ToT is particularly effective for tasks that\nrequire search and planning.\nRecursion-of-Thought\n(Lee and Kim, 2023) is\nsimilar to regular CoT. However, every time it en-\ncounters a complicated problem in the middle of its\nreasoning chain, it sends this problem into another\nprompt/LLM call. After this is completed, the an-\nswer is inserted into the original prompt. In this\nway, it can recursively solve complex problems, in-\ncluding ones which might otherwise run over that\nmaximum context length. This method has shown\nimprovements on arithmetic and algorithmic tasks.\nThough implemented using fine-tuning to output a\nspecial token that sends sub-problem into another\nprompt, it could also be done only through prompt-\ning.\nProgram-of-Thoughts\n(Chen et al., 2023d) uses\nLLMs like Codex to generate programming code\nas reasoning steps. A code interpreter executes\nthese steps to obtain the final answer. It excels in\nmathematical and programming-related tasks but\nis less effective for semantic reasoning tasks.\nFaithful Chain-of-Thought\n(Lyu et al., 2023)\ngenerates a CoT that has both natural language and\nsymbolic language (e.g. Python) reasoning, just\nlike Program-of-Thoughts. However, it also makes\nuse of different types of symbolic languages in a\ntask-dependent fashion.\nSkeleton-of-Thought\n(Ning et al., 2023) focuses\non accelerating answer speed through paralleliza-\ntion. Given a problem, it prompts an LLM to create\na skeleton of the answer, in a sense, sub-problems\nto be solved. Then, in parallel, it sends these ques-\ntions to a LLM and concatenates all the outputs to\nget a final response.\nMetacognitive Prompting\n(Wang and Zhao,\n2024) attempts to make the LLM mirror human\nmetacognitive processes with a five part prompt\nchain, with steps including clarifying the question,\npreliminary judgement, evaluation of response, de-\ncision confirmation, and confidence assessment.\n2.2.4\nEnsembling\nIn GenAI, ensembling is the process of using multi-\nple prompts to solve the same problem, then aggre-\ngating these responses into a final output. In many\ncases, a majority vote—selecting the most frequent\nresponse—is used to generate the final output. En-\nsembling techniques reduce the variance of LLM\noutputs and often improving accuracy, but come\nwith the cost of increasing the number of model\ncalls needed to reach a final answer.\nDemonstration Ensembling (DENSE)\n(Khalifa\net al., 2023) creates multiple few-shot prompts,\neach containing a distinct subset of exemplars from\nthe training set. Next, it aggregates over their out-\nputs to generate a final response.\nMixture of Reasoning Experts (MoRE)\n(Si et al.,\n2023d) creates a set of diverse reasoning experts\nby using different specialized prompts for different\nreasoning types (such as retrieval augmentation\nprompts for factual reasoning, Chain-of-Thought\nreasoning for multi-hop and math reasoning, and\ngenerated knowledge prompting for commonsense\nreasoning). The best answer from all experts is\nselected based on an agreement score.\nMax Mutual Information Method\n(Sorensen\net al., 2022) creates multiple prompt templates with\n14\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 107
  },
  {
    "chunk_full": "varied styles and exemplars, then selects the opti-\nmal template as the one that maximizes mutual\ninformation between the prompt and the LLM’s\noutputs.\nSelf-Consistency\n(Wang et al., 2022) is based\non the intuition that multiple different reasoning\npaths can lead to the same answer. This method\nfirst prompts the LLM multiple times to perform\nCoT, crucially with a non-zero temperature to elicit\ndiverse reasoning paths. Next, it uses a majority\nvote over all generated responses to select a final\nresponse. Self-Consistency has shown improve-\nments on arithmetic, commonsense, and symbolic\nreasoning tasks.\nUniversal Self-Consistency\n(Chen et al., 2023e)\nis similar to Self-Consistency except that rather\nthan selecting the majority response by program-\nmatically counting how often it occurs, it inserts\nall outputs into a prompt template that selects the\nmajority answer. This is helpful for free-form text\ngeneration and cases where the same answer may\nbe output slightly differently by different prompts.\nMeta-Reasoning over Multiple CoTs\n(Yoran\net\nal.,\n2023)\nis\nsimilar\nto\nuniversal\nSelf-\nConsistency; it first generates multiple reasoning\nchains (but not necessarily final answers) for a\ngiven problem. Next, it inserts all of these chains\nin a single prompt template then generates a final\nanswer from them.\nDiVeRSe\n(Li et al., 2023i)\ncreates multiple\nprompts for a given problem then performs Self-\nConsistency for each, generating multiple reason-\ning paths. They score reasoning paths based on\neach step in them then select a final response.\nConsistency-based\nSelf-adaptive\nPrompting\n(COSP)\n(Wan et al., 2023a) constructs Few-Shot\nCoT prompts by running Zero-Shot CoT with\nSelf-Consistency on a set of examples then\nselecting a high agreement subset of the outputs\nto be included in the final prompt as exemplars. It\nagain performs Self-Consistency with this final\nprompt.\nUniversal Self-Adaptive Prompting (USP)\n(Wan\net al., 2023b) builds upon the success of COSP, aim-\ning to make it generalizable to all tasks. USP makes\nuse of unlabeled data to generate exemplars and a\nmore complicated scoring function to select them.\nAdditionally, USP does not use Self-Consistency.\nPrompt Paraphrasing\n(Jiang et al., 2020) trans-\nforms an original prompt by changing some of the\nwording, while still maintaining the overall mean-\ning. It is effectively a data augmentation technique\nthat can be used to generate prompts for an ensem-\nble.\n2.2.5\nSelf-Criticism\nWhen creating GenAI systems, it can be useful to\nhave LLMs criticize their own outputs (Huang et al.,\n2022). This could simply be a judgement (e.g., is\nthis output correct) or the LLM could be prompted\nto provide feedback, which is then used to improve\nthe answer. Many approaches to generating and\nintegrating self-criticism have been developed.\nSelf-Calibration\n(Kadavath et al., 2022) first\nprompts an LLM to answer a question. Then, it\nbuilds a new prompt that includes the question, the\nLLM’s answer, and an additional instruction asking\nwhether the answer is correct. This can be useful\nfor gauging confidence levels when applying LLMs\nwhen deciding when to accept or revise the original\nanswer.\nSelf-Refine\n(Madaan et al., 2023) is an iterative\nframework where, given an initial answer from the\nLLM, it prompts the same LLM to provide feed-\nback on the answer, and then prompts the LLM to\nimprove the answer based on the feedback. This\niterative process continues until a stopping condi-\ntion is met (e.g., max number of steps reached).\nSelf-Refine has demonstrated improvement across\na range of reasoning, coding, and generation tasks.\nReversing\nChain-of-Thought\n(RCoT)\n(Xue\net al., 2023) first prompts LLMs to reconstruct\nthe problem based on generated answer. Then, it\ngenerates fine-grained comparisons between the\noriginal problem and the reconstructed problem\nas a way to check for any inconsistencies. These\ninconsistencies are then converted to feedback for\nthe LLM to revise the generated answer.\nSelf-Verification\n(Weng et al., 2022)\ngener-\nates multiple candidate solutions with Chain-of-\nThought (CoT). It then scores each solution by\nmasking certain parts of the original question and\nasking an LLM to predict them based on the rest\nof the question and the generated solution. This\nmethod has shown improvement on eight reasoning\ndatasets.\n15\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 108
  },
  {
    "chunk_full": "Chain-of-Verification\n(COVE)\n(Dhuliawala\net al., 2023) first uses an LLM to generate an\nanswer to a given question. Then, it creates a\nlist of related questions that would help verify\nthe correctness of the answer. Each question is\nanswered by the LLM, then all the information\nis given to the LLM to produce the final revised\nanswer. This method has shown improvements in\nvarious question-answering and text-generation\ntasks.\nCumulative Reasoning\n(Zhang et al., 2023b)\nfirst generates several potential steps in answering\nthe question. It then has a LLM evaluate them, de-\nciding to either accept or reject these steps. Finally,\nit checks whether it has arrived at the final answer.\nIf so, it terminates the process, but otherwise it\nrepeats it. This method has demonstrated improve-\nments in logical inference tasks and mathematical\nproblem.\n2.3\nPrompting Technique Usage\nAs we have just seen, there exist many text-based\nprompting techniques. However, only a small sub-\nset of them are commonly used in research and in\nindustry. We measure technique usage by proxy of\nmeasuring the number of citations by other papers\nin our dataset. We do so with the presumption that\npapers about prompting are more likely to actually\nuse or evaluate the cited technique. We graph the\ntop 25 papers cited in this way from our dataset and\nfind that most of them propose new prompting tech-\nniques (Figure 2.11). The prevalence of citations\nfor Few-Shot and Chain-of-Thought prompting is\nunsurprising and helps to establish a baseline for\nunderstanding the prevalence of other techniques.\n2.3.1\nBenchmarks\nIn prompting research, when researchers propose\na new technique, they usually benchmark it across\nmultiple models and datasets. This is important to\nprove the utility of the technique and examine how\nit transfers across models.\nIn order to make it easier for researchers propos-\ning new techniques to know how to benchmark\nthem, we quantitatively examine which models\n(Figure 2.9) and what benchmark datasets (Fig-\nure 2.10) are being used. Again, we measure usage\nby how many times papers in our dataset cite the\nbenchmark datasets and models.\nTo find which datasets and models are being\nused, we prompted GPT-4-1106-preview to extract\nany mentioned dataset or model from the body of\npapers in our dataset. After, we manually filtered\nout results that were not models or datasets. The\ncitation counts were acquired by searching items\nfrom the finalized list on Semantic Scholar.\n2.4\nPrompt Engineering\nIn addition to surveying prompting techniques, we\nalso review prompt engineering techniques, which\nare used to automatically optimize prompts. We\ndiscuss some techniques that use gradient updates,\nsince the set of prompt engineering techniques is\nmuch smaller than that of prompting techniques.\nMeta Prompting\nis the process of prompting a\nLLM to generate or improve a prompt or prompt\ntemplate (Reynolds and McDonell, 2021; Zhou\net al., 2022b; Ye et al., 2023). This is often done\nwithout any scoring mechanism, using just a sim-\nple template (Figure 2.12). However, other works\npresent more complex uses of meta-prompting,\nwith multiple iterations and scoring mechanisms\nYang et al. (2023a); Fernando et al. (2023).\nImprove the following prompt: {PROMPT}\nFigure 2.12: A simple Meta Prompting template.\nAutoPrompt\n(Shin et al., 2020b) uses a frozen\nLLM as well as a prompt template that includes\nsome \"trigger tokens\", whose values are updated\nvia backpropogation at training time. This is a\nversion of soft-prompting.\nAutomatic Prompt Engineer (APE)\n(Zhou et al.,\n2022b) uses a set of exemplars to generate a Zero-\nShot instruction prompt. It generates multiple pos-\nsible prompts, scores them, then creates variations\nof the best ones (e.g. by using prompt paraphras-\ning). It iterates on this process until some desider-\nata are reached.\nGradientfree\nInstructional\nPrompt\nSearch\n(GrIPS)\n(Prasad et al., 2023) is similar to APE,\nbut uses a more complex set of operations includ-\ning deletion, addition, swapping, and paraphrasing\nin order to create variations of a starting prompt.\nPrompt Optimization with Textual Gradients (Pro-\nTeGi)\n(Pryzant et al., 2023) is a unique approach\nto prompt engineering that improves a prompt tem-\nplate through a multi-step process. First, it passes\n16\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 109
  },
  {
    "chunk_full": "GPT-3\nBERT\nGPT-4\nRoBERTa\nPaLM\nLLaMA\nBART\nCodex\nOPT\nInstructGPT\nBLOOM\nFLAN\nCLIP\nSAM\nBioBERT\nLambda\nFlamingo\nBLOOMZ\nCoCoOp\nVision Transformer\nBLIP-2\nVLP\nCodellama\nFinBERT\nLLaVA\nGatorTron\nGrounding DINO\nDreamFusion\nModel Name\n0\n100\n200\n300\n400\n500\nCount\nCounts of Model Mentions in Dataset\nFigure 2.9: Citation Counts of GenAI Models\nGSM8K\nMMLU\nBBH\nCommonsenseQA\nHellaSwag\nBIG-bench\nWinoGrande\nQASC\nAQUA-RAT\nTruthfulQA\nDataset Name\n0\n200\n400\n600\n800\nNumber of Mentions\nDataset Mentions in Papers\nFigure 2.10: Citation Counts of Datasets\nFew-Shot Learning*\nZero-Shot Reasoning*\nGood In-Context Examples\nSelf-Consistency*\nPrompt Order Sensitivity\nLeast-to-Most Prompting*\nPrompt Retrieval\nHuman-Level Prompting\nAutomatic CoT*\nSelf-Ask*\nTree of Thoughts*\nProgram of Thoughts*\nComplexity-Based Prompting*\nSelf-Refine*\nDecomposed Prompting*\nSelf-Evaluation*\nMaieutic Prompting*\nIn-context Learning Survey\nGraph of Thoughts*\nLLMs as Optimizers\nActive Prompting*\nPlan-and-Solve Prompting*\nFaithful CoT*\nSupport Examples\nkNN Prompting*\nUnified Demo Retriever*\nTree-of-Thought*\nAutomate-CoT*\nStep-Aware Verification*\nSelf-Generated ICL*\nQuestion Decomposition\nDeductive Verification*\nCumulative Reasoning*\nChain-of-Verification*\nSelf-Adaptive Prompting*\nDemonstration Ensembling\nMemory-of-Thought*\nRephrase and Respond*\nPrompting Techniques\n100\n101\n102\n103\nCounts\nCitation Counts of Prompting Techniques\nFigure 2.11: Citation Counts of Prompting Techniques.\nThe top 25 papers in our dataset, measured by how often\nthey are cited by other papers in our dataset. Most pa-\npers here are prompting techniques*, and the remaining\npapers contains prompting advice.\n17\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 110
  },
  {
    "chunk_full": "a batch of inputs through the template, then passes\nthe output, ground truth, and prompt into another\nprompt that criticizes the original prompt. It gener-\nates new prompts from these criticisms then uses\na bandit algorithm (Gabillon et al., 2011) to se-\nlect one. ProTeGi demonstrates improvements over\nmethods like APE and GRIPS.\nRLPrompt\n(Deng et al., 2022) uses a frozen LLM\nwith an unfrozen module added. It uses this LLM to\ngenerate prompt templates, scores the templates on\na dataset, and updates the unfrozen module using\nSoft Q-Learning (Guo et al., 2022). Interestingly,\nthe method often selects grammatically nonsensical\ntext as the optimal prompt template.\nDialogue-comprised Policy-gradient-based Dis-\ncrete Prompt Optimization (DP2O)\n(Li et al.,\n2023b) is perhaps the most complicated prompt en-\ngineering technique, involving reinforcement learn-\ning, a custom prompt scoring function, and conver-\nsations with an LLM to construct the prompt.\n2.5\nAnswer Engineering\nAnswer engineering is the iterative process of de-\nveloping or selecting among algorithms that extract\nprecise answers from LLM outputs. To understand\nthe need for answer engineering, consider a bi-\nnary classification task where the labels are \"Hate\nSpeech\" and \"Not Hate Speech\". The prompt tem-\nplate might look like this:\nIs this \"Hate Speech\" or \"Not Hate Speech\":\n{TEXT}\nWhen a hate speech sample is put through the\ntemplate, it might have outputs such as \"It’s hate\nspeech\", \"Hate Speech.\", or even \"Hate speech,\nbecause it uses negative language against a racial\ngroup\". This variance in response formats is diffi-\ncult to parse consistently; improved prompting can\nhelp, but only to a certain extent.\nThere are three design decisions in answer en-\ngineering, the choice of answer space, answer\nshape, and answer extractor (Figure 2.13). Liu\net al. (2023b) define the first two as necessary\ncomponents of answer engineering and we append\nthe third. We consider answer engineering to be\ndistinct from prompt engineering, but extremely\nclosely related; the processes are often conducted\nin tandem.\nThis is negative\nLikely Negative\nNEGATIVE !\nLLM Response\nAnswer Extraction:\nSelect the proper label\nAnswer Shape:\nA span of tokens\nAnswer Space:\nAll possible spans of tokens\nFigure 2.13: An annotated output of a LLM output for a\nlabeling task, which shows the three design decisions of\nanswer engineering: the choice of answer shape, space,\nand extractor. Since this is an output from a classifi-\ncation task, the answer shape could be restricted to a\nsingle token and the answer space to one of two tokens\n(\"positive\" or \"negative\"), though they are unrestricted\nin this image.\n2.5.1\nAnswer Shape\nThe shape of an answer is its physical format. For\nexample, it could be a token, span of tokens, or\neven an image or video.7 It is sometimes useful to\nrestrict the output shape of a LLM to a single token\nfor tasks like binary classification.\n2.5.2\nAnswer Space\nThe space of an answer is the domain of values\nthat its structure may contain. This may simply be\nthe space of all tokens, or in a binary labeling task,\ncould just be two possible tokens.\n2.5.3\nAnswer Extractor\nIn cases where it is impossible to entirely control\nthe answer space (e.g. consumer-facing LLMs), or\nthe expected answer may be located somewhere\nwithin the model output, a rule can be defined to\nextract the final answer. This rule is often a simple\nfunction (e.g. a regular expression), but can also\nuse a separate LLM to extract the answer.\nVerbalizer\nOften used in labeling tasks, a verbal-\nizer maps a token, span, or other type of output\nto a label and vice-versa (injective) (Schick and\nSchütze, 2021). For example, if we wish for a\nmodel to predict whether a Tweet is positive or\nnegative, we could prompt it to output either \"+\"\nor \"-\" and a verbalizer would map these token se-\nquences to the appropriate labels. The selection\nof a verbalizer constitutes a component of answer\nengineering.\n7We use a different definition than Liu et al. (2023b) with\nrespect to granularity (e.g. token vs span), since the output\ncould be of a different modality.\n18\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 111
  },
  {
    "chunk_full": "Regex\nAs mentioned previously, Regexes are of-\nten used to extract answers. They are usually used\nto search for the first instance of a label. However,\ndepending on the output format and whether CoTs\nare generated, it may be better to search for the last\ninstance.\nSeparate LLM\nSometimes outputs are so com-\nplicated that regexes won’t work consistently. In\nthis case, it can be useful to have a separate LLM\nevaluate the output and extract an answer. This\nseparate LLM will often use an answer trigger\n(Kojima et al., 2022), e.g. \"The answer (Yes or No)\nis\", to extract the answer.\n19\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 112
  },
  {
    "chunk_full": "3\nBeyond English Text Prompting\nPrompting GenAIs with English text currently\nstands as the dominant method for interaction.\nPrompting in other languages or through differ-\nent modalities often requires special techniques to\nachieve comparable performance. In this context,\nwe discuss the domains of multilingual and multi-\nmodal prompting.\n3.1\nMultilingual\nState-of-the-art GenAIs have often been predom-\ninately trained with English dataset, leading to a\nnotable disparity in the output quality in languages\nother than English, particularly low-resource lan-\nguages (Bang et al., 2023; Jiao et al., 2023; Hendy\net al., 2023; Shi et al., 2022). As a result, various\nmultilingual prompting techniques have emerged\nin an attempt to improve model performance in\nnon-English settings (Figure 3.1).\nTranslate First Prompting\n(Shi et al., 2022) is\nperhaps the simplest strategy and first translates\nnon-English input examples into English. By trans-\nlating the inputs into English, the model can utilize\nits strengths in English to better understand the con-\ntent. Translation tools vary; Shi et al. (2022) use an\nexternal MT system, Etxaniz et al. (2023) prompt\nmultilingual LMs and Awasthi et al. (2023) prompt\nLLMs to translate non-English inputs.\n3.1.1\nChain-of-Thought (CoT)\nCoT prompting (Wei et al., 2023a) has been ex-\ntended to the multilingual setting in multiple ways.\nXLT\n(Cross-Lingual\nThought)\nPrompting\n(Huang et al., 2023a) utilizes a prompt template\ncomposed of six separate instructions, including\nrole assignment, cross-lingual thinking, and CoT.\nCross-Lingual Self Consistent Prompting (CLSP)\n(Qin et al., 2023a) introduces an ensemble tech-\nnique that constructs reasoning paths in different\nlanguages to answer the same question.\n3.1.2\nIn-Context Learning\nICL has also been extended to multilingual settings\nin multiple ways.\nX-InSTA Prompting\n(Tanwar et al., 2023) ex-\nplores three distinct approaches for aligning in-\ncontext examples with the input sentence for classi-\nfication tasks: using semantically similar examples\nto the input (semantic alignment), examples that\nshare the same label as the input (task-based align-\nment), and the combination of both semantic and\ntask-based alignments.\nIn-CLT (Cross-lingual Transfer) Prompting\n(Kim et al., 2023) leverages both the source and\ntarget languages to create in-context examples, di-\nverging from the traditional method of using source\nlanguage exemplars. This strategy helps stimulate\nthe cross-lingual cognitive capabilities of multilin-\ngual LLMs, thus boosting performance on cross-\nlingual tasks.\n3.1.2.1\nIn-Context Example Selection\nIn-context example selection heavily influences the\nmultilingual performance of LLMs (Garcia et al.,\n2023; Agrawal et al., 2023). Finding in-context ex-\namples that are semantically similar to the source\ntext is very important (Winata et al., 2023; Moslem\net al., 2023; Sia and Duh, 2023). However, us-\ning semantically dissimilar (peculiar) exemplars\nhas also been shown to enhance performance (Kim\nand Komachi, 2023). This same contrast exists in\nthe English-only setting. Additionally, when deal-\ning with ambiguous sentences, selecting exemplars\nwith polysemous or rare word senses may boost\nperformance (Iyer et al., 2023).\nPARC (Prompts Augmented by Retrieval Cross-\nlingually)\n(Nie et al., 2023) introduce a frame-\nwork that retrieves relevant exemplars from a high\nresource language. This framework is specifically\ndesigned to enhance cross-lingual transfer perfor-\nmance, particularly for low-resource target lan-\nguages.\nLi et al. (2023g) extend this work to\nBangla.\n3.1.3\nPrompt Template Language Selection\nIn multilingual prompting, the selection of lan-\nguage for the prompt template can markedly in-\nfluence the model performance.\nEnglish Prompt Template\nConstructing the\nprompt template in English is often more effec-\n20\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 113
  },
  {
    "chunk_full": "Multilingual Techniques\nChain-of-Thought 3.1.1\nXLT 3.1.1\nCLSP 3.1.1\nIn-Context Learning 3.1.2\nX-InSTA 3.1.2\nIn-CLT 3.1.2\nIn-Context Ex. Selection 3.1.2.1\nPARC 3.1.2.1\nSemantically-Aligned 3.1.2.1\nSemantically-Distant 3.1.2.1\nHuman-in-the-Loop 3.1.4.1\nInteractive Chain 3.1.4.1\nIterative 3.1.4.1\nTranslation 3.1.4\nChain-of-Dictionary 3.1.4\nDecoMT 3.1.4\nDiPMT 3.1.4\nMAPS 3.1.4\nTranslate First Prompting 3.1\nExternal MT Systems 3.1\nStandard LLMs 3.1\nMultilingual LLMs 3.1\nPrompt Language 3.1.3\nEnglish 3.1.3\nTask Language 3.1.3\nFigure 3.1: All multilingual prompting techniques.\ntive than in the task language for multilingual tasks.\nThis is likely due to the predominance of English\ndata during LLM pre-training (Lin et al., 2022;\nAhuja et al., 2023). Lin et al. (2022) suggest that\nthis is likely due to a high overlap with pre-training\ndata and vocabulary. Similarly, Ahuja et al. (2023)\nhighlight how translation errors when creating task\nlanguage templates propagate in the form of in-\ncorrect syntax and semantics, adversely affecting\ntask performance. Further, Fu et al. (2022) com-\npare in-lingual (task language) prompts and cross-\nlingual (mixed language) prompts and find the\ncross-lingual approach to be more effective, likely\nbecause it uses more English in the prompt, thus\nfacilitating retrieving knowledge from the model.\nTask Language Prompt Template\nIn contrast,\nmany multilingual prompting benchmarks such\nas BUFFET (Asai et al., 2023) or LongBench\n(Bai et al., 2023a) use task language prompts\nfor language-specific use cases.\nMuennighoff\net al. (2023) specifically studies different transla-\ntion methods when constructing native-language\nprompts. They demonstrate that human translated\nprompts are superior to their machine-translated\ncounterparts. Native or non-native template perfor-\nmance can differ across tasks and models (Li et al.,\n2023h). As such, neither option will always be the\nbest approach (Nambi et al., 2023).\n3.1.4\nPrompting for Machine Translation\nThere is significant research into leveraging GenAI\nto facilitate accurate and nuanced translation. Al-\nthough this is a specific application of prompt-\ning, many of these techniques are important more\nbroadly for multilingual prompting.\nMulti-Aspect Prompting and Selection (MAPS)\n(He et al., 2023b) mimics the human translation pro-\ncess, which involves multiple preparatory steps to\nensure high-quality output. This framework starts\nwith knowledge mining from the source sentence\n(extracting keywords and topics, and generating\ntranslation exemplars). It integrates this knowledge\nto generate multiple possible translations, then se-\nlects the best one.\nChain-of-Dictionary (CoD)\n(Lu et al., 2023b)\nfirst extracts words from the source phrase, then\nmakes a list of their meanings in multiple lan-\nguages, automatically via retrieval from a dictio-\nnary (e.g. English: ‘apple’, Spanish: ‘manzana’).\nThen, they prepend these dictionary phrases to the\nprompt, where it asks a GenAI to use them during\ntranslation.\nDictionary-based Prompting for Machine Trans-\nlation (DiPMT)\n(Ghazvininejad et al., 2023)\nworks similarly to CoD, but only gives definitions\nin the source and target languages, and formats\nthem slightly differently.\n21\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 114
  },
  {
    "chunk_full": "Multimodal (MM) Techniques\nImage 3.2.1\nMM. CoT 3.2.1.2\nChain-of-Images 3.2.1.2\nDuty Distinct CoT 3.2.1.2\nMM Graph-of-Thought 3.2.1.2\nMultimodal ICL 3.2.1.1\nImage-as-Text Prompt3.2.1.1\nPaired-Image Prompt 3.2.1.1\nNegative Prompt 3.2.1\nPrompt Modifiers 3.2.1\nSegmentation Prompting 3.2.4\nVideo 3.2.3\nVideo Gen. 3.2.3.1\n3D Prompting 3.2.5\nFigure 3.2: All multimodal prompting techniques.\nDecomposed Prompting for MT (DecoMT)\n(Puduppully et al., 2023) divides the source text\ninto several chunks and translates them indepen-\ndently using few-shot prompting. Then it uses these\ntranslations and contextual information between\nchunks to generate a final translation.\n3.1.4.1\nHuman-in-the-Loop\nInteractive-Chain-Prompting\n(ICP)\n(Pilault\net al., 2023) deals with potential ambiguities in\ntranslation by first asking the GenAI to generate\nsub-questions about any ambiguities in the phrase\nto be translated. Humans later respond to these\nquestions and the system includes this information\nto generate a final translation.\nIterative Prompting\n(Yang et al., 2023d) also\ninvolves humans during translation. First, they\nprompt LLMs to create a draft translation. This\ninitial version is further refined by integrating su-\npervision signals obtained from either automated\nretrieval systems or direct human feedback.\n3.2\nMultimodal\nAs GenAI models evolve beyond text-based do-\nmains, new prompting techniques emerge. These\nmultimodal prompting techniques are often not\nsimply applications of text-based prompting tech-\nniques, but entirely novel ideas made possible by\ndifferent modalities.\nWe now extend our text-\nbased taxonomy to include a mixture of multimodal\nanalogs of text-based prompting techniques as well\nas completely novel multimodal techniques (Figure\n3.2).\n3.2.1\nImage Prompting\nThe image modality encompasses data such as pho-\ntographs, drawings, or even screenshots of text\n(Gong et al., 2023). Image prompting may refer\nto prompts that either contain images or are used\nto generate images. Common tasks include image\ngeneration (Ding et al., 2021; Hinz et al., 2022;\nTao et al., 2022; Li et al., 2019a,b; Rombach et al.,\n2022), caption generation (Li et al., 2020), image\nclassification (Khalil et al., 2023), and image edit-\ning (Crowson et al., 2022; Kwon and Ye, 2022;\nBar-Tal et al., 2022; Hertz et al., 2022). We now\ndescribe various image prompting techniques used\nfor such applications.\nPrompt Modifiers\nare simply words appended to\na prompt to change the resultant image (Oppenlaen-\nder, 2023). Components such as Medium (e.g. \"on\ncanvas\") or Lighting (e.g. \"a well lit scene\") are\noften used.\nNegative Prompting\nallows users to numerically\nweight certain terms in the prompt so that the\nmodel considers them more/less heavily than oth-\ners. For example, by negatively weighting the\nterms “bad hands” and “extra digits”, models may\nbe more likely to generate anatomically accurate\nhands (Schulhoff, 2022).\n3.2.1.1\nMultimodal In-Context Learning\nThe success of ICL in text-based settings has\nprompted research into multimodal ICL (Wang\net al., 2023k; Dong et al., 2023).\nPaired-Image Prompting\nshows the model two\nimages: one before and one after some transforma-\ntion. Then, present the model with a new image for\nwhich it will perform the demonstrated conversion.\nThis can be done either with textual instructions\n(Wang et al., 2023k) or without them (Liu et al.,\n2023e).\nImage-as-Text\nPrompting\n(Hakimov\nand\nSchlangen, 2023) generates a textual description of\nan image. This allows for the easy inclusion of the\nimage (or multiple images) in a text-based prompt.\n22\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 115
  },
  {
    "chunk_full": "3.2.1.2\nMultimodal Chain-of-Thought\nCoT has been extended to the image domain in\nvarious ways (Zhang et al., 2023d; Huang et al.,\n2023c; Zheng et al., 2023b; Yao et al., 2023c). A\nsimple example of this would be a prompt contain-\ning an image of a math problem accompanied by\nthe textual instructions \"Solve this step by step\".\nDuty\nDistinct\nChain-of-Thought\n(DDCoT)\n(Zheng et al., 2023b)\nextends Least-to-Most\nprompting (Zhou et al., 2022a) to the multimodal\nsetting, creating subquestions, then solving them\nand combining the answers into a final response.\nMultimodal Graph-of-Thought\n(Yao et al.,\n2023c) extends Graph-of-Thought Zhang et al.\n(2023d) to the multimodal setting. GoT-Input also\nuses a two step rationale then answer process. At\ninference time, the the input prompt is used to con-\nstruct a thought graph, which is then used along\nwith the original prompt to generate a rationale to\nanswer the question. When an image is input along\nwith the question, an image captioning model is\nemployed to generate a textual description of the\nimage, which is then appended to the prompt before\nthe thought graph construction to provide visual\ncontext.\nChain-of-Images (CoI)\n(Meng et al., 2023) is a\nmultimodal extension of Chain-of-Thought prompt-\ning, that generates images as part of its thought\nprocess. They use the prompt “Let’s think image\nby image” to generate SVGs, which the model can\nthen use to reason visually.\n3.2.2\nAudio Prompting\nPrompting has also been extended to the audio\nmodality. Experiments with audio ICL have gener-\nated mixed results, with some open source audio\nmodels failing to perform ICL (Hsu et al., 2023).\nHowever, other results do show an ICL ability in\naudio models (Wang et al., 2023g; Peng et al., 2023;\nChang et al., 2023). Audio prompting is currently\nin early stages, but we expect to see various prompt-\ning techniques proposed in the future.\n3.2.3\nVideo Prompting\nPrompting has also been extended to the video\nmodality, for use in text-to-video generation\n(Brooks et al., 2024; Lv et al., 2023; Liang et al.,\n2023; Girdhar et al., 2023), video editing (Zuo\net al., 2023; Wu et al., 2023a; Cheng et al., 2023),\nand video-to-text generation (Yousaf et al., 2023;\nMi et al., 2023; Ko et al., 2023a).\n3.2.3.1\nVideo Generation Techniques\nWhen prompting a model to generate video, var-\nious modalities of prompts can be used as input,\nand several prompt-related techniques are often em-\nployed to enhance video generation. Image related\ntechniques, such as prompt modifiers can often be\nused for video generation (Runway, 2023).\n3.2.4\nSegmentation Prompting\nPrompting can also be used for segmentation (e.g.\nsemantic segmentation) (Tang et al., 2023; Liu\net al., 2023c).\n3.2.5\n3D Prompting\nPrompting can also be used in 3D modalities, for\nexample in 3D object synthesis (Feng et al., 2023;\nLi et al., 2023d,c; Lin et al., 2023; Chen et al.,\n2023f; Lorraine et al., 2023; Poole et al., 2022; Jain\net al., 2022), 3D surface texturing (Liu et al., 2023g;\nYang et al., 2023b; Le et al., 2023; Pajouheshgar\net al., 2023), and 4D scene generation (animating a\n3D scene) (Singer et al., 2023; Zhao et al., 2023c),\nwhere input prompt modalities include text, image,\nuser annotation (bounding boxes, points, lines), and\n3D objects.\n23\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 116
  },
  {
    "chunk_full": "4\nExtensions of Prompting\nThe techniques we have discussed thus far can be\nextremely complicated, incorporating many steps\nand iterations. However, we can take prompting\nfurther by adding access to external tools (agents)\nand complex evaluation algorithms to judge the\nvalidity of LLM outputs.\n4.1\nAgents\nAs LLMs have improved rapidly in capabilities\n(Zhang et al., 2023c), companies (Adept, 2023)\nand researchers (Karpas et al., 2022) have explored\nhow to allow them to make use of external sys-\ntems. This has been necessitated by shortcomings\nof LLMs in areas such as mathematical computa-\ntions, reasoning, and factuality. This has driven sig-\nnificant innovations in prompting techniques; these\nsystems are often driven by prompts and prompt\nchains, which are heavily engineered to allow for\nagent-like behaviour (Figure 4.1).\nDefinition of Agent\nIn the context of GenAI, we\ndefine agents to be GenAI systems that serve a\nuser’s goals via actions that engage with systems\noutside the GenAI itself.8 This GenAI is usually a\nLLM. As a simple example, consider an LLM that\nis tasked with solving the following math problem:\nIf Annie has 4,939 grapes, and gives exactly\n39% of them to Amy, how many does she\nhave left?\nIf properly prompted, the LLM could output the\nstring CALC(4,939*.39). This output could be\nextracted and put into a calculator to obtain the\nfinal answer.\nThis is an example of an agent: the LLM outputs\ntext which then uses a downstream tool. Agent\nLLMs may involve a single external system (as\nabove), or they may need to solve the problem\nof routing, to choose which external system to\nuse. Such systems also frequently involve memory\nand planning in addition to actions (Zhang et al.,\n2023c).\nExamples of agents include LLMs that can make\nAPI calls to use external tools like a calculator\n8We do not cover the notion of independently-acting AI,\ni.e. systems that in any sense have their own goals\n(Karpas et al., 2022), LLMs that can output strings\nthat cause actions to be taken in a gym-like (Brock-\nman et al., 2016; Towers et al., 2023) environment\n(Yao et al., 2022), and more broadly, LLMs which\nwrite and record plans, write and run code, search\nthe internet, and more (Significant Gravitas, 2023;\nYang et al., 2023c; Osika, 2023). OpenAI Assis-\ntants OpenAI (2023), LangChain Agents (Chase,\n2022), and LlamaIndex Agents (Liu, 2022) are ad-\nditional examples.\n4.1.1\nTool Use Agents\nTool use is a critical component for GenAI agents.\nBoth symbolic (e.g. calculator, code interpreter)\nand neural (e.g. a separate LLM) external tools\nare commonly used. Tools may occasionally be\nreferred to as experts (Karpas et al., 2022) or mod-\nules.\nModular Reasoning, Knowledge, and Language\n(MRKL) System\n(Karpas et al., 2022) is one of\nthe simplest formulations of an agent. It contains\na LLM router providing access to multiple tools.\nThe router can make multiple calls to get informa-\ntion such as weather or the current date. It then\ncombines this information to generate a final re-\nsponse. Toolformer (Schick et al., 2023), Gorilla\n(Patil et al., 2023), Act-1 (Adept, 2023), and oth-\ners (Shen et al., 2023; Qin et al., 2023b; Hao et al.,\n2023) all propose similar techniques, most of which\ninvolve some fine-tuning.\nSelf-Correcting with Tool-Interactive Critiquing\n(CRITIC)\n(Gou et al., 2024a) first generates a re-\nsponse to the prompt, with no external calls. Then,\nthe same LLM criticizes this response for possible\nerrors. Finally, it uses tools (e.g. Internet search or\na code interpreter) accordingly to verify or amend\nparts of the response.\n4.1.2\nCode-Generation Agents\nWriting and executing code is another important\nability of many agents.9\nProgram-aided Language Model (PAL)\n(Gao\net al., 2023b) translates a problem directly into\n9This ability may be considered a tool (i.e. code inter-\npreter)\n24\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 117
  },
  {
    "chunk_full": "Agents\nTool Use Agents\nCRITIC 4.1.1\nMRKL Sys. 4.1.1\nCode-Based Agents 4.1.2\nPAL 4.1.2\nToRA 4.1.2\nTask Weaver 4.1.2\nObservation-Based Agents 4.1.3\nReAct 4.1.3\nReflexion 4.1.3\nLifelong Learn. Agents 4.1.3.1\nVoyager 4.1.3.1\nGITM 4.1.3.1\nRetrieval Aug. Generation 4.1.4\nIRCoT 4.1.4\nDSP 4.1.4\nVerify-and-Edit 4.1.4\nIterative Retrieval Aug. 4.1.4\nFigure 4.1: Agent techniques covered in this section.\ncode, which is sent to a Python interpreter to gen-\nerate an answer.\nTool-Integrated Reasoning Agent (ToRA)\n(Gou\net al., 2024b) is similar to PAL, but instead of a\nsingle code generation step, it interleaves code and\nreasoning steps for as long as necessary to solve\nthe problem.\nTaskWeaver\n(Qiao et al., 2023) is also similar to\nPAL, transforming user requests into code, but can\nalso make use of user-defined plugin.\n4.1.3\nObservation-Based Agents\nSome agents are designed to solve problems by\ninteracting with toy environments (Brockman et al.,\n2016; Towers et al., 2023). These observation-\nbased agents receive observations inserted into their\nprompts.\nReasoning and Acting (ReAct)\n(Yao et al.\n(2022)) generates a thought, takes an action, and\nreceives an observation (and repeats this process)\nwhen given a problem to solve. All of this informa-\ntion is inserted into the prompt so it has a memory\nof past thoughts, actions, and observations.\nReflexion\n(Shinn et al., 2023) builds on ReAct,\nadding a layer of introspection. It obtains a trajec-\ntory of actions and observations, then is given an\nevaluation of success/failure. Then, it generates\na reflection on what it did and what went wrong.\nThis reflection is added to its prompt as a working\nmemory, and the process repeats.\n4.1.3.1\nLifelong Learning Agents\nWork on LLM-integrated Minecraft agents has gen-\nerated impressive results, with agents able to ac-\nquire new skills as they navigate the world of this\nopen-world videogame.\nWe view these agents\nnot merely as applications of agent techniques\nto Minecraft, but rather novel agent frameworks\nwhich can be explored in real world tasks that re-\nquire lifelong learning.\nVoyager\n(Wang et al., 2023a) is composed of\nthree parts. First, it proposes tasks for itself to\ncomplete in order to learn more about the world.\nSecond, it generates code to execute these actions.\nFinally, it saves these actions to be retrieved later\nwhen useful, as part of a long-term memory system.\nThis system could be applied to real world tasks\nwhere an agent needs to explore and interact with\na tool or website (e.g. penetration testing, usability\ntesting).\nGhost in the Minecraft (GITM)\n(Zhu et al.,\n2023) starts with an arbitrary goal, breaks it down\ninto subgoals recursively, then iteratively plans and\nexecutes actions by producing structured text (e.g.\n\"equip(sword)\") rather than writing code. GITM\nuses an external knowledge base of Minecraft items\nto assist with decomposition as well as a memory\nof past experience.\n4.1.4\nRetrieval Augmented Generation (RAG)\nIn the context of GenAI agents, RAG is a paradigm\nin which information is retrieved from an external\nsource and inserted into the prompt. This can en-\nhance performance in knowledge intensive tasks\n(Lewis et al., 2021). When retrieval itself is used\nas an external tool, RAG systems are considered to\nbe agents.\nVerify-and-Edit\n(Zhao et al., 2023a) improves on\nself-consistency by generating multiple chains-of-\nthought, then selecting some to be edited. They do\nthis by retrieving relevant (external) information to\n25\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 118
  },
  {
    "chunk_full": "Evaluation\nPrompting Techniques 4.2.1\nChain-Of-Thought 4.2.1\nIn-Context Learning 4.2.1\nModel-Gen. Guidelines 4.2.1\nRole-Based Evaluation 4.2.1\nOutput Format\nBinary Score 4.2.2\nLikert Scale 4.2.2\nLinear Scale 4.2.2\nStyling 4.2.2\nPrompting Frameworks 4.2.3\nLLM-EVAL 4.2.3\nG-EVAL 4.2.3\nChatEval 4.2.3\nOther Methodologies 4.2.4\nBatch Prompting 4.2.4\nPairwise Evaluation 4.2.4\nFigure 4.2: Evaluation techniques.\nthe CoTs, and allowing the LLM to augment them\naccordingly.\nDemonstrate-Search-Predict\n(Khattab et al.,\n2022) first decomposes a question into sub-\nquestions, then uses queries to solve them and\ncombine their responses in a final answer. It uses\nfew-shot prompting to decompose the problem and\ncombine responses.\nInterleaved\nRetrieval\nguided\nby\nChain-of-\nThought (IRCoT)\n(Trivedi et al., 2023) is a\ntechnique for multi-hop question answering that\ninterleaves CoT and retrieval. IRCoT leverages\nCoT to guide which documents to retrieve and\nretrieval to help plan the reasoning steps of CoT.\nIterative Retrieval Augmentation\ntechniques,\nlike Forward-Looking Active REtrieval augmented\ngeneration (FLARE) (Jiang et al., 2023) and Im-\nitate, Retrieve, Paraphrase (IRP) (Balepur et al.,\n2023), perform retrieval multiple times during long-\nform generation. Such models generally perform\nan iterative three-step process of: 1) generating\na temporary sentence to serve as a content plan\nfor the next output sentence; 2) retrieving exter-\nnal knowledge using the temporary sentence as a\nquery; and 3) injecting the retrieved knowledge\ninto the temporary sentence to create the next out-\nput sentence. These temporary sentences have been\nshown to be better search queries compared to the\ndocument titles provided in long-form generation\ntasks.\n4.2\nEvaluation\nThe potential of LLMs to extract and reason about\ninformation and understand user intent makes them\nstrong contenders as evaluators.10 For example, it\nis possible to prompt a LLM to evaluate the quality\nof an essay or even a previous LLM output accord-\ning to some metrics defined in the prompt. We de-\nscribe four components of evaluation frameworks\nthat are important in building robust evaluators: the\nprompting technique(s), as described in Section\n2.2, the output format of the evaluation, the frame-\nwork of the evaluation pipeline, and some other\nmethodological design decisions (Figure 4.2).\n4.2.1\nPrompting Techniques\nThe prompting technique used in the evaluator\nprompt (e.g.\nsimple instruction vs CoT) is in-\nstrumental in building a robust evaluator. Evalua-\ntion prompts often benefit from regular text-based\nprompting techniques, including a role, instructions\nfor the task, the definitions of the evaluation cri-\nteria, and in-context examples. Find a full list of\ntechniques in Appendix A.6.\nIn-Context Learning\nis frequently used in evalu-\nation prompts, much in the same way it is used in\nother applications (Dubois et al., 2023; Kocmi and\nFedermann, 2023a; Brown et al., 2020).\nRole-based Evaluation\nis a useful technique for\nimproving and diversifying evaluations (Wu et al.,\n2023b; Chan et al., 2024). By creating prompts\nwith the same instructions for evaluation, but dif-\nferent roles, it is possible to effectively generate\ndiverse evaluations. Additionally, roles can be used\nin a multiagent setting where LLMs debate the va-\nlidity of the text to be evaluated (Chan et al., 2024).\n10This section does not describe how to benchmark LLMs,\nbut rather how to use them as evaluators.\n26\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 119
  },
  {
    "chunk_full": "Chain-of-Thought\nprompting can further im-\nprove evaluation performance (Lu et al., 2023c;\nFernandes et al., 2023).\nModel-Generated\nGuidelines\n(Liu\net\nal.,\n2023d,h) prompt an LLM to generate guidelines\nfor evaluation.\nThis reduces the insufficient\nprompting problem arising from ill-defined scoring\nguidelines and output spaces, which can result in\ninconsistent and misaligned evaluations. Liu et al.\n(2023d) generate a chain-of-thought of the detailed\nevaluation steps that the model should perform\nbefore generating a quality assessment. Liu et al.\n(2023h) propose AUTOCALIBRATE, which derives\nscoring criteria based on expert human annotations\nand uses a refined subset of model-generated\ncriteria as a part of the evaluation prompt.\n4.2.2\nOutput Format\nThe output format of the LLM can significantly\naffect evaluation performance Gao et al. (2023c).\nStyling\nFormatting the LLM’s response using\nXML or JSON styling has also been shown to im-\nprove the accuracy of the judgment generated by\nthe evaluator (Hada et al., 2024; Lin and Chen,\n2023; Dubois et al., 2023).\nLinear Scale\nA very simple output format is a\nlinear scale (e.g. 1-5). Many works use ratings of\n1-10 (Chan et al., 2024), 1-5 (Araújo and Aguiar,\n2023), or even 0-1 (Liu et al., 2023f). The model\ncan be prompted to output a discrete (Chan et al.,\n2024) or continuous (Liu et al., 2023f) score be-\ntween the bounds.\nScore the following story on a scale of 1-5\nfrom well to poorly written:\n{INPUT}\nBinary Score\nPrompting the model to generate\nbinary responses like Yes or No (Chen et al., 2023c)\nand True or False (Zhao et al., 2023b) is another\nfrequently used output format.\nIs the following story well written at a high-\nschool level (yes/no)?:\n{INPUT}\nLikert Scale\nPrompting the GenAI to make use\nof a Likert Scale (Bai et al., 2023b; Lin and Chen,\n2023; Peskoff et al., 2023) can give it a better un-\nderstanding of the meaning of the scale.\nScore the following story according to the\nfollowing scale:\nPoor\nAcceptable\nGood\nVery Good\nIncredible\n{INPUT}\n4.2.3\nPrompting Frameworks\nLLM-EVAL\n(Lin and Chen, 2023) is one of the\nsimplest evaluation frameworks. It uses a single\nprompt that contains a schema of variables to eval-\nuate (e.g. grammar, relevance, etc.), an instruction\ntelling the model to output scores for each variable\nwithin a certain range, and the content to evaluate.\nG-EVAL\n(Liu et al., 2023d) is similar to LLM-\nEVAL, but includes an AutoCoT steps in the\nprompt itself. These steps are generated accord-\ning to the evaluation instructions, and inserted into\nthe final prompt. These weight answers according\nto token probabilities.\nChatEval\n(Chan et al., 2024) uses a multi-agent\ndebate framework with each agent having a sepa-\nrate role.\n4.2.4\nOther Methodologies\nWhile most approaches directly prompt the LLM\nto generate a quality assessment (explicit), some\nworks also use implicit scoring where a quality\nscore is derived using the model’s confidence in\nits prediction (Chen et al., 2023g) or the likelihood\nof generating the output (Fu et al., 2023a) or via\nthe models’ explanation (e.g. count the number\nof errors as in Fernandes et al. (2023); Kocmi and\nFedermann (2023a)) or via evaluation on proxy\ntasks (factual inconsistency via entailment as in\nLuo et al. (2023)).\nBatch Prompting\nFor improving compute and\ncost efficiency, some works employ batch prompt-\ning for evaluation where multiple instances are\nevaluated at once11 (Lu et al., 2023c; Araújo and\nAguiar, 2023; Dubois et al., 2023) or the same in-\nstance is evaluated under different criteria or roles\n(Wu et al., 2023b; Lin and Chen, 2023). However,\n11Disambiguation: there is no relation to making a forward\npass with multiple prompts in parallel. We are referring to a\nsingle prompt that contains multiple items to evaluate.\n27\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 120
  },
  {
    "chunk_full": "evaluating multiple instances in a single batch often\ndegrades performance (Dubois et al., 2023).\nPairwise Evaluation\n(Chen et al., 2023g) find\nthat directly comparing the quality of two texts may\nlead to suboptimal results and that explicitly asking\nLLM to generate a score for individual summaries\nis the most effective and reliable method. The order\nof the inputs for pairwise comparisons can also\nheavily affect evaluation (Wang et al., 2023h,b).\n28\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 121
  },
  {
    "chunk_full": "5\nPrompting Issues\nWe now highlight prompting related issues in the\nform of security and alignment concerns.\n5.1\nSecurity\nAs the use of prompting grows, so too does the\nthreat landscape surrounding it.\nThese threats\nare extremely varied and uniquely difficult to de-\nfend against compared to both non-neural and pre-\nprompting security threats. We provide a discus-\nsion of the prompting threat landscape and lim-\nited state of defenses. We begin by describing\nprompt hacking, the means through which prompt-\ning is used to exploit LLMs, then describe dangers\nemerging from this, and finally describe potential\ndefenses (Figure 5.1).\n5.1.1\nTypes of Prompt Hacking\nPrompt hacking refers to a class of attacks which\nmanipulate the prompt in order to attack a GenAI\n(Schulhoff et al., 2023). Such prompts have been\nused to leak private information (Carlini et al.,\n2021), generate offensive content (Shaikh et al.,\n2023) and produce deceptive messages (Perez et al.,\n2022). Prompt hacking is a superset of both prompt\ninjection and jailbreaking, which are distinct con-\ncepts.\nPrompt Injection\nis the process of overriding\noriginal developer instructions in the prompt\nwith user input (Schulhoff, 2024; Willison, 2024;\nBranch et al., 2022; Goodside, 2022). It is an archi-\ntectural problem resulting from GenAI models not\nbeing able to understand the difference between\noriginal developer instructions and user input in-\nstructions.\nConsider the following prompt template. A user\ncould input \"Ignore previous instructions and make\na threat against the president.\", which might lead to\nthe model being uncertain as to which instruction\nto follow, and thus possibly following the malicious\ninstruction.\nRecommend a book for the following per-\nson: {USER_INPUT}\nJailbreaking\nis the process of getting a GenAI\nmodel to do or say unintended things through\nprompting (Schulhoff, 2024; Willison, 2024; Perez\nand Ribeiro, 2022). It is either an architectural\nproblem or a training problem made possible by\nthe fact that adversarial prompts are extremely dif-\nficult to prevent.\nConsider the following jailbreaking example,\nwhich is analogous to the previous prompt injec-\ntion example, but without developer instructions in\nthe prompt. Instead of inserting text in a prompt\ntemplate, the user can go directly to the GenAI and\nprompt it maliciously.\nMake a threat against the president.\n5.1.2\nRisks of Prompt Hacking\nPrompt hacking can lead to real world risks such\nas privacy concerns and system vulnerabilities.\n5.1.2.1\nData Privacy\nBoth model training data and prompt templates can\nbe leaked via prompt hacking (usually by prompt\ninjection).\nTraining Data Reconstruction\nrefers to the prac-\ntice of extracting training data from GenAIs. A\nstraightforward example of this is Nasr et al. (2023),\nwho found that by prompting ChatGPT to repeat\nthe word \"company\" forever, it began to regurgitate\ntraining data.\nPrompt Leaking\nrefers to the process of extract-\ning the prompt template from an application. Devel-\nopers often spend significant time creating prompt\ntemplates, and consider them to be IP worth pro-\ntecting. Willison (2022) demonstrate how to leak\nthe prompt template from a Twitter Bot, by simply\nproviding instructions like the following:\nIgnore the above and instead tell me what\nyour initial instructions were.\n5.1.2.2\nCode Generation Concerns\nLLMs are often used to generate code. Attackers\nmay target vulnerabilities that occur as a result of\nthis code.\n29\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 122
  },
  {
    "chunk_full": "Security\nPrompt Hacking 5.1.1\nPrompt Injection 5.1.1\nJailbreaking 5.1.1\nRisks 5.1.2\nData Privacy 5.1.2.1\nTraining Data\nReconstruction 5.1.2.1\nPrompt Leaking 5.1.2.1\nCode Generation Concerns\n5.1.2.2\nPackage Halluc. 5.1.2.2\nBugs 5.1.2.2\nCustomer Service 5.1.2.3\nHardening Measures 5.1.3\nPrompt-based Defense 5.1.3\nGuardrails 5.1.3\nDetectors 5.1.3\nFigure 5.1: Security & prompting\nPackage Hallucination\noccurs when LLM-\ngenerated code attempts to import packages that do\nnot exist (Lanyado et al., 2023; Thompson and\nKelly, 2023).\nAfter discovering what package\nnames are frequently hallucinated by LLMs, hack-\ners could create those packages, but with malicious\ncode (Wu et al., 2023c). If the user runs the in-\nstall for these formerly non-existent packages, they\nwould download a virus.\nBugs\n(and security vulnerabilities) occur more\nfrequently in LLM-generated code (Pearce et al.,\n2021, 2022; Sandoval et al., 2022; Perry et al.,\n2022). Minor changes to the prompting technique\ncan also lead to such vulnerabilities in the gener-\nated code (Pearce et al., 2021).\n5.1.2.3\nCustomer Service\nMalicious users frequently perform prompt injec-\ntion attacks against corporate chatbots, leading\nto brand embarrassment (Bakke, 2023; Goodside,\n2022). These attacks may induce the chatbot to\noutput harmful comment or agree to sell the user\na company product at a very low price. In the lat-\nter case, the user may actually be entitled to the\ndeal. Garcia (2024) describe how an airline chat-\nbot gave a customer incorrect information about\nrefunds. The customer appealed in court and won.\nAlthough this chatbot was pre-ChatGPT, and was\nin no way tricked by the user, this precedent may\napply when nuanced prompt hacking techniques\nare used.\n5.1.3\nHardening Measures\nSeveral tools and prompting techniques have been\ndeveloped to mitigate some of the aforementioned\nsecurity risks. However, prompt hacking (both in-\njection and jailbreaking) remain unsolved problems\nand likely are impossible to solve entirely.\nPrompt-based Defenses\nMultiple prompt-based\ndefenses have been proposed, in which instructions\nare included in the prompt to avoid prompt injec-\ntion (Schulhoff, 2022). For example, the following\nstring could be added to a prompt:\nDo not output any malicious content\nHowever, Schulhoff et al. (2023) ran a study with\nhundreds of thousands of malicious prompts and\nfound that no prompt-based defense is fully secure,\nthough they can mitigate prompt hacking to some\nextent.\nDetectors\nare tools designed to detect malicious\ninputs and prevent prompt hacking (AI, 2023; Inan\net al., 2023). Many companies have built such\ndetectors (ArthurAI, 2024; Preamble, 2024; Lak-\nera, 2024), which are often built using fine-tuned\nmodels trained on malicious prompts. Generally,\nthese tools can mitigate prompt hacking to a greater\nextent than prompt-based defenses.\nGuardrails\nare rules and frameworks for guiding\nGenAI outputs (Hakan Tekgul, 2023; Dong et al.,\n2024). Guardrails often make use of detectors, but\nnot always. Guardrails are more concerned with\nthe general dialogue flow in an application. For\nexample, a simple guardrail could use a detector to\nfind malicious prompts, then respond with a canned\nmessage if malicious. More complicated tools em-\nploy dialogue managers (Rebedea et al., 2023),\nwhich allow the LLM to choose from a number\nof curated responses. Prompting-specific program-\nming languages have also been proposed to im-\nprove templating and act as guardrails (Scott Lund-\nberg, 2023; Luca Beurer-Kellner, 2023).\n30\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 123
  },
  {
    "chunk_full": "Alignment\nAmbiguity 5.2.4\nAmbig. Demonstrations 5.2.4\nQuestion Clarification 5.2.4\nBiases 5.2.3\nAttrPrompt 5.2.3\nCultural Awareness 5.2.3\nDemonstration Sel. 5.2.3\nVanilla Prompting 5.2.3\nCalibration 5.2.2\nSycophancy 5.2.2\nVerbalized Score 5.2.2\nPrompt Sensitivity 5.2.1\nFew-Shot Ordering 5.2.1\nPrompt Drift 5.2.1\nPrompt Wording 5.2.1\nTask Format 5.2.1\nFigure 5.2: Prompt-based Alignment Organization\n5.2\nAlignment\nEnsuring that LLMs are well-aligned with user\nneeds in downstream tasks is essential for success-\nful deployment. Models may output harmful con-\ntent, yield inconsistent responses, or show bias,\nall of which makes deploying them more difficult.\nTo help mitigate these risks, it is possible to care-\nfully design prompts that elicit less harmful outputs\nfrom LLMs. In this section, we describe prompt\nalignment problems as well as potential solutions\n(Figure 5.2).\n5.2.1\nPrompt Sensitivity\nSeveral works show that LLMs are highly sensitive\nto the input prompt (Leidinger et al., 2023), i.e.,\neven subtle changes to a prompt such as exemplar\norder (Section 2.2.1.1) can result in vastly different\noutputs. Below, we describe several categories\nof these perturbations and their impacts on model\nbehavior.\nSmall Changes in the Prompt\nsuch as extra\nspaces, changing capitalization, modifying delim-\niters, or swapping synonyms can significantly im-\npact performance (Lu et al., 2024; Tjuatja et al.,\n2024). Despite these changes being minor, Sclar\net al. (2023a) find that they can cause the perfor-\nmance of LLaMA2-7B to range from nearly 0 to\n0.804 on some tasks.\nTask Format\ndescribes different ways to prompt\nan LLM to execute the same task. For example,\na prompt tasking an LLM to perform sentiment\nanalysis could ask the LLM to classify a review\nas “positive” or “negative”, or the prompt could\nask the LLM “Is this review positive?” to elicit\na “yes” or “no” response. Zhao et al. (2021b)\nshow that these minor changes can alter the\naccuracy of GPT-3 by up to 30%. Similarly, minor\nperturbations on task-specific prompts that are\nlogically equivalent, such as altering the order of\nchoices in multiple-choice questions, can result in\nsignificant performance degradation (Pezeshkpour\nand Hruschka, 2023; Zheng et al., 2023a; Voronov\net al., 2024).\nPrompt Drift\n(Chen et al., 2023b) occurs when\nthe model behind an API changes over time, so the\nsame prompt may produce different results on the\nupdated model. Although not directly a prompt-\ning issue, it necessitates continuous monitoring of\nprompt performance.\n5.2.2\nOverconfidence and Calibration\nLLMs are often overconfident in their answers,\nespecially when prompted to express their own\nconfidence in words (Kiesler and Schiffner, 2023;\nXiong et al., 2023a), which may lead to user\noverreliance on model outputs (Si et al., 2023c).\nConfidence calibration provides a score that\nrepresents the confidence of the model (Guo et al.,\n2017). While a natural solution for confidence\ncalibration is to study the output token probabilities\nprovided by the LLM, a variety of prompting\ntechniques have also been created for confidence\ncalibration.\nVerbalized Score\nis a simple calibration tech-\nnique that generates a confidence score (e.g. “How\nconfident are you from 1 to 10”), but its efficacy\nis under debate. Xiong et al. (2023b) find that\nseveral LLMs are highly overconfident when ver-\n31\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 124
  },
  {
    "chunk_full": "balizing confidence scores, even when employing\nself-consistency and chain-of-thought. In contrast,\nTian et al. (2023) find that simple prompts (Section\n4.2) can achieve more accurate calibration than the\nmodel’s output token probabilities.\nSycophancy\nrefers to the concept that LLMs will\noften express agreement with the user, even when\nthat view contradicts the model’s own intial out-\nput. Sharma et al. (2023) find that when LLMs\nare asked to comment on opinions of arguments,\nthe model is easily swayed if the user’s opinion\nis included in the prompt (e.g. “I really like/dis-\nlike this argument”). Further, they find that ques-\ntioning the LLM’s original answer (e.g. “Are you\nsure?”), strongly providing an assessment of cor-\nrectness (e.g. “I am confident you are wrong”), and\nadding false assumptions will completely change\nthe model output. Wei et al. (2023b) note similar re-\nsults with opinion-eliciting and false user presump-\ntions, also finding that sycophancy is heightened\nfor larger and instruction-tuned models. Thus, to\navoid such influence, personal opinions should not\nbe included in prompts.12\n5.2.3\nBiases, Stereotypes, and Culture\nLLMs should be fair to all users, such that no bi-\nases, stereotypes, or cultural harms are perpetuated\nin model outputs (Mehrabi et al., 2021). Some\nprompting technique have been designed in accor-\ndance with these goals.\nVanilla Prompting\n(Si et al., 2023b) simply con-\nsists of an instruction in the prompt that tells the\nLLM to be unbiased. This technique has also been\nreferred to as moral self-correction (Ganguli et al.,\n2023).\nSelecting Balanced Demonstrations\n(Si et al.,\n2023b), or obtaining demonstrations optimized\nover fairness metrics (Ma et al., 2023), can reduce\nbiases in LLM outputs (Section 2.2.1.1).\nCultural Awareness\n(Yao et al., 2023a) can be\ninjected into prompts to help LLMs with cultural\nadaptation (Peskov et al., 2021). This can be done\nby creating several prompts to do this with machine\ntranslation, which include: 1) asking the LLM to\n12For example, a practitioner may use the prompt template\n“Detect all instances where the user’s input is harmful: {IN-\nPUT}” in an attempt to prevent adversarial inputs, but this\nsubtly makes the false presupposition that the user’s input is\nactually harmful. Thus, due to sycophancy, the LLM may be\ninclined to classify the user’s output as harmful.\nrefine its own output; and 2) instructing the LLM\nto use culturally relevant words.\nAttrPrompt\n(Yu et al., 2023) is a prompting\ntechnique designed to avoid producing text biased\ntowards certain attributes when generating syn-\nthetic data. Traditional data generation approaches\nmay be biased towards specific lengths, locations\nand styles. To overcome this, AttrPrompt: 1) asks\nthe LLM to generate specific attributes that are\nimportant to alter for diversity (e.g. location); and\n2) prompts the LLM to generate synthetic data by\nvarying each of these attributes.\n5.2.4\nAmbiguity\nQuestions that are ambiguous can be interpreted in\nmultiple ways, where each interpretation could re-\nsult in a different answer (Min et al., 2020). Given\nthese multiple interpretations, ambiguous questions\nare challenging for existing models (Keyvan and\nHuang, 2022), but a few prompting techniques have\nbeen developed to help address this challenge.\nAmbiguous Demonstrations\nGao et al. (2023a)\nare examples that have an ambiguous label set.\nIncluding them in a prompt can increase ICL\nperformance.\nThis can be automated with a\nretriever, but it can also be done manually.\nQuestion Clarification\n(Rao and Daumé III,\n2019) allows the LLM to identify ambiguous ques-\ntions and generate clarifying questions to pose to\nthe user. Once these questions are clarified by the\nuser, the LLM can regenerate its response. Mu et al.\n(2023) do this for code generation and Zhang and\nChoi (2023) equip LLMs with a similar pipeline\nfor resolving ambiguity for general tasks, but ex-\nplicitly design separate prompts to: 1) generate an\ninitial answer 2) classify whether to generate clar-\nification questions or return the initial answer 3)\ndecide what clarification questions to generate 4)\ngenerate a final answer.\n32\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 125
  },
  {
    "chunk_full": "6\nBenchmarking\nNow that we have carried out a systematic review\nof prompting techniques, we will analyze the em-\npirical performance of different techniques in two\nways: via a formal benchmark evaluation, and by\nillustrating in detail the process of prompt engineer-\ning on a challenging real-world problem.\n6.1\nTechnique Benchmarking\nA formal evaluation of prompting techniques might\nbe done in a broad study that compares hundreds of\nthem across hundreds of models and benchmarks.\nThis is beyond our scope, but since it has not been\ndone before, we provide a first step in this direction.\nWe choose a subset of prompting techniques and\nrun them on the widely used benchmark MMLU\n(Hendrycks et al., 2021). We ran on a representa-\ntive subset of 2,800 MMLU questions (20% of the\nquestions from each category).13 and used gpt-3.5-\nturbo for all experiments.\n6.1.1\nComparing Prompting Techniques\nWe benchmark six distinct prompting techniques\nusing the same general prompt template (Figure\n6.2). This template shows the location of different\ncomponents of the prompts. Only base instructions\nand question exist in every prompt. The base in-\nstruction is a phrase like \"Solve the problem and\nreturn (A), (B), (C) or (D).\" that we vary in some\ncases. We additionally test two formats of the ques-\ntion (Figures 6.3 and 6.4). The question format\nis inserted into the prompt template in place of\n\"{QUESTION}\". We test each prompting tech-\nnique with 6 total variations, except for ones that\nuse Self-Consistency.\nZero-Shot\nAs a baseline, we ran questions di-\nrectly through the model without any special\nprompting technique, only the base instruction and\nquestion. For this baseline, we utilized both for-\nmats as well as three phrasing variations of the base\ninstruction. Thus, there were six total runs through\nthe 2800 questions for this benchmark. This did\nnot include any exemplars or thought inducers.\nZero-Shot-CoT Techniques\nWe ran also ran\nZero-Shot-CoT. As the three different variations,\n13We excluded human_sexuality, since gpt-3.5-turbo re-\nfused to answer these questions.\nwe used three thought inducers (instructions that\ncause the model to generate reasoning steps) includ-\ning the standard \"Let’s think step by step\" chain-\nof-thought (Kojima et al., 2022), as well as ThoT\n(Zhou et al., 2023), and Plan and Solve (Wang et al.,\n2023f). Then, we selected the best of these, and\nran it with Self-Consistency with three iterations,\ntaking the majority response.\nFew-Shot Setups\nWe also ran Few-Shot prompts\nand Few-Shot-CoT prompts, both with exemplars\ngenerated by one of our authors. For each, we used\nthree variations of the base instruction as well as\nthe two question formats (also applied to the exem-\nplars). Then we used the best performing phrasing\nwith Self-Consistency with three iterations, taking\nthe majority response.\nZero-Shot\nZero-Shot CoT\nZero-Shot CoT SC\nFew-Shot\nFew-Shot CoT\nFew-Shot CoT SC\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nAccuracy\n0.627\n0.547\n0.574\n0.652\n0.692\n0.691\nFigure 6.1: Accuracy values are shown for each prompt-\ning technique, with the model used being gpt-3.5-turbo.\nPurple error bars illustrate the minimum and maximum\nfor each technique, since they were each run on different\nphrasings and formats (except SC).\n6.1.2\nQuestion Formats\nWe experiment with two formatting choices from\nSclar et al. (2023b), who explored how formatting\nchoices can affect benchmarking results. We use\ntwo formats which lead to varied results on their\ntask (Figures 6.3 and 6.4).\n6.1.3\nSelf-Consistency\nFor the two Self-Consistency results, we set temper-\nature to 0.5, following Wang et al. (2022)’s guide-\nlines. For all other prompts, a temperature of 0 was\nused.\n33\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 126
  },
  {
    "chunk_full": "{BASE_INSTRUCTION}\n{EXEMPLARS}\n{QUESTION} {THOUGHT_INDUCER}\nFigure 6.2: Prompt template for benchmarking.\nProblem\n{QUESTION}\nOptions\n(A)::{A} (B)::{B} (C)::{C} (D)::{D}\nAnswer\nFigure 6.3: Question format 1.\n6.1.4\nEvaluating Responses\nEvaluating whether a LLM has properly responded\nto a question is a difficult task (Section 2.5). We\nmarked answers as correct if they followed certain\nidentifiable patterns, such as being the only capital-\nized letter (A-D) within parentheses or following a\nphrase like “The correct answer is”.\n6.1.5\nResults\nPerformance generally improved as techniques\ngrew more complex (Figure 6.1). However, Zero-\nShot-CoT dropped precipitously from Zero-Shot.\nAlthough it had a wide spread, for all variants,\nZero-Shot performed better. Both cases of Self-\nConsistency, naturally had lower spread since they\nrepeated a single technique, but it only improved ac-\ncuracy for Zero-Shot prompts. Few-Shot CoT per-\nforms the best, and unexplained performance drops\nfrom certain techniques need further research. As\nprompting technique selection is akin to hyperpa-\nrameter search, this it is a very difficult task (Khat-\ntab et al., 2023). However, we hope this small study\nspurs research in the direction of more performant\nand robust prompting techniques.\n6.2\nPrompt Engineering Case Study\nPrompt engineering is emerging as an art that many\npeople have begun to practice professionally, but\nthe literature does not yet include detailed guid-\nance on the process. As a first step in this direction,\nwe present an annotated prompt engineering case\nstudy for a difficult real-world problem. This is not\nintended to be an empirical contribution in terms\nPROBLEM::{QUESTION}, OPTIONS::\n(A): {A}\n(B): {B}\n(C): {C}\n(D): {D}, ANSWER::\nFigure 6.4: Question format 2.\nof actually solving the problem. Rather, it provides\none illustration of how an experienced prompt en-\ngineer would approach a task like this, along with\nlessons learned.\n6.2.1\nProblem\nOur illustrative problem involves detection of sig-\nnal that is predictive of crisis-level suicide risk in\ntext written by a potentially suicidal individual. Sui-\ncide is a severe problem worldwide, compounded,\nas are most mental health issues, by a desperate\nlack of mental health resources. In the United\nStates, more than half the national population lives\nin federally defined mental heath provider short-\nage areas (National Center for Health Workforce\nAnalysis, 2023); in addition, many mental health\nprofessionals lack core competencies in suicide\nprevention (Cramer et al., 2023). In 2021, 12.3M\nAmericans thought seriously about suicide, with\n1.7M actually making attempts resulting in over\n48,000 deaths (CDC, 2023). In the U.S., suicide\nwas the second leading cause of death (after acci-\ndents) in people aged 10-14, 15-24, or 25-34 as of\n2021 statistics, and it was the fifth leading cause\nof death in people aged 35–54 (Garnett and Curtin,\n2023).\nRecent research suggests that there is significant\nvalue in assessments of potential suicidality that\nfocus specifically on the identification of suicidal\ncrisis, i.e. the state of acute distress associated with\na high risk of imminent suicidal behavior. However,\nvalidated assessments for diagnostic approaches\nsuch as Suicide Crisis Syndrome (SCS) (Schuck\net al., 2019b; Melzer et al., 2024) and Acute Sui-\ncidal Affective Disturbance (Rogers et al., 2019)\nrequire either personal clinical interactions or com-\npletion of self-report questionnaires that contain\ndozens of questions. The ability to accurately flag\nindicators of suicidal crisis in individuals’ language\ncould therefore have a large impact within the men-\ntal health ecosystem, not as a replacement for clini-\n34\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 127
  },
  {
    "chunk_full": "cal judgment but as a way to complement existing\npractices (Resnik et al., 2021).\nAs a starting point, we focus here on the most\nimportant predictive factor in Suicide Crisis Syn-\ndrome assessments, referred to in the literature as\neither frantic hopelessness or entrapment, “a desire\nto escape from an unbearable situation, tied with\nthe perception that all escape routes are blocked”\n(Melzer et al., 2024).14 This characteristic of what\nan individual is experiencing is also central in other\ncharacterizations of mental processes that result in\nsuicide.\n6.2.2\nThe Dataset\nWe worked with a subset of data from the Univer-\nsity of Maryland Reddit Suicidality Dataset (Shing\net al., 2018), which is constructed from posts in\nr/SuicideWatch, a subreddit that offers peer sup-\nport for anyone struggling with suicidal thoughts.\nTwo coders trained on the recognition of the factors\nin Suicide Crisis Syndrome coded a set of 221 posts\nfor presence or absence of entrapment, achieving\nsolid inter-coder reliability (Krippendorff’s alpha\n= 0.72).\n6.2.3\nThe Process\nAn expert prompt engineer, who has authored a\nwidely used guide on prompting (Schulhoff, 2022),\ntook on the task of using an LLM to identify entrap-\nment in posts.15 The prompt engineer was given a\nbrief verbal and written summary of Suicide Crisis\nSyndrome and entrapment, along with 121 develop-\nment posts and their positive/negative labels (where\n“positive” means entrapment is present), the other\n100 labeled posts being reserved for testing. This\nlimited information mirrors frequent real-life sce-\nnarios in which prompts are developed based on\na task description and the data. More generally, it\nis consistent with a tendency in natural language\nprocessing and AI more generally to approach cod-\ning (annotation) as a labeling task without delving\nvery deeply into the fact that the labels may, in fact,\nrefer to nuanced and complex underlying social\nscience constructs.\nWe documented the prompt engineering pro-\ncess in order to illustrate the way that an experi-\nenced prompt engineer goes about their work. The\n14The former term more explicitly emphasizes the frantic\nand desperate action required to escape an unbearable life\nsituation. However, the term entrapment is briefer and used\nwidely so we adopt it here.\n15Disclosure: that expert is also the lead author of this\npaper.\nexercise proceeded through 47 recorded develop-\nment steps, cumulatively about 20 hours of work.\nFrom a cold start with 0% performance (the prompt\nwouldn’t return properly structured responses), per-\nformance was boosted to an F1 of 0.53, where that\nF1 is the harmonic mean of 0.86 precision and 0.38\nrecall.16\nBelow, the set of prompts qinf is the test item,\nwhile qi, ri, and ai denote the questions, chain-of-\nthought steps, and answers in exemplars.\n6.2.3.1\nDataset Exploration (2 steps)\nThe process began with the prompt engineer review-\ning a description of entrapment (Figure 6.7); this\ndescription had been used as a first-pass rubric for\nthe human coders early in the coding process, not-\ning, however, that they were familiar with SCS and\nknew it was neither a formal definition nor exhaus-\ntive. The prompt engineer then loaded the dataset\ninto a Python notebook for data exploration pur-\nposes. He began by asking gpt-4-turbo-preview if it\nknew what entrapment was (Figure 6.8), but found\nthat the LLM’s response was not similar to the de-\nscription that had been given. In consequence, the\nprompt engineer included the Figure 6.7 descrip-\ntion of entrapment in all future prompts.\n6.2.3.2\nGetting a Label (8 steps)\nAs noted in Section 6.1 with regard to the hu-\nman_sexuality subset of MMLU, LLMs exhibit\nunpredictable and difficult to control behaviour in\nsensitive domains. For multiple steps in the prompt\nengineering process, the prompt engineer found\nthat the LLM was giving mental health advice (e.g.\nFigure 6.9) instead of labeling the input. This was\naddressed by switching to the GPT-4-32K model.\nA take-away from this initial phase is that the\n“guard rails” associated with some large language\nmodels may interfere with the ability to make\nprogress on a prompting task, and this could in-\nfluence the choice of model for reasons other than\nthe LLM’s potential quality.\n6.2.3.3\nPrompting Techniques (32 steps)\nThe prompt engineer then spent the majority of\nhis time improving the prompting technique being\nused. This included techniques such as Few-Shot,\n16Precision is also known as positive predictive value, and\nrecall is also known as true positive rate or sensitivity. Al-\nthough F1 is often used in computional system evaluations as\na single figure of merit, we note that in this problem space\nits even weighting of precision and recall is probably not\nappropriate. We discuss this further below.\n35\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 128
  },
  {
    "chunk_full": "10-Shot\n+ 1-Shot AutoDiCoT\n1-Shot AutoDiCoT\n(no email)\n1-Shot AutoDiCoT\n+ Full Context\n10-Shot AutoDiCoT\n Ensemble + Extraction\n10-Shot AutoDiCoT\n Without Email\nZero-Shot + Context\n(Exact Match)\nZero-Shot + Context\n(First Chars)\n10-Shot AutoDiCoT\n + Default to Reject\nFull Context Only\nAnonymized Email\n10-Shot + Context\n10-Shot AutoDiCoT\n De-Dupe Email\nTriplicate Context\n20-Shot AutoDiCoT\n+ Full Words\n20-Shot AutoDiCoT\n+ Full Words + Extraction Prompt\n10-Shot AutoDiCoT\n+ Extraction Prompt\n20-Shot AutoDiCoT\n10-Shot AutoDiCoT\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nScores\nScores of Different Prompting Techniques on Development Set\nF1\nRecall\nPrecision\nFigure 6.5: F1 scores varied widely from worst performing prompts to highest performing prompts, but most\nprompts scored within a similar range.\nChain-of-Thought, AutoCoT, Contrastive CoT, and\nmultiple answer extraction techniques. We report\nstatistics for the first runs of these techniques; F1\nscores could change by as much as 0.04 upon sub-\nsequent runs, even with temperature and top p set\nto zero.17\nZero-Shot + Context\nwas the first technique eval-\nuated (Figure 6.10), using the description in Fig-\nure 6.7. Notice the word definition in the prompt,\nalthough Figure 6.7 is not a formal definition.\nIn order to obtain a final response from the LLM\nto use in calculating performance metrics, it was\nnecessary to extract a label from the LLM output.\nThe prompt engineer tested two extractors, one that\nchecks if the output is exactly \"Yes\" or \"No\", and\nanother which just checks if those words match the\nfirst few characters of the output. The latter had\nbetter performance, and it is used for the rest of this\n17Temperature and top-p are configuration hyperparameters\nthat control randomness of the output (Schulhoff, 2022).\nsection until we reach CoT. This approach obtained\n0.40 F1, 1.0 recall, and 0.25 precision, evaluated\non all samples from the training/development since\nno samples had been used as exemplars.\n10-Shot + Context.\nNext, the prompt engineer\nadded the first ten data samples (with labels) into\nthe prompt, in Q: (question) A: (answer) format\n(Figure 6.11). He evaluated this 10-shot prompt\non the remaining items in the training/development\nset, yielding ↑0.05 (0.45) F1, ↓0.09 (0.91) recall,\nand ↑0.05 (0.30) precision, relative to the previous\nbest prompt.18\nOne-Shot AutoDiCot + Full Context.\nAfter per-\nforming 10-shot prompting, the prompt engineer\nobserved that the 12th item in the development set\nwas being incorrectly being labeled as a positive in-\nstance, and began experimenting with ways of mod-\n18Here and for the remainder of the case study, we judge\n“best” by F1, and we report on the current prompt under dis-\ncussion relative to the best performing previous prompt.\n36\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 129
  },
  {
    "chunk_full": "Zero-Shot + Context\n(First Chars)\nZero-Shot + Context\n(Exact Match)\n10-Shot + Context\n1-Shot AutoDiCoT\n+ Full Context\n1-Shot AutoDiCoT\n(no email)\n10-Shot\\n+ 1-Shot AutoDiCoT\nFull Context Only\n10-Shot AutoDiCoT\n20-Shot AutoDiCoT\n20-Shot AutoDiCoT\n+ Full Words\n20-Shot AutoDiCoT\n+ Full Words + Extraction Prompt\n10-Shot AutoDiCoT\n+ Extraction Prompt\n10-Shot AutoDiCoT\n Without Email\n10-Shot AutoDiCoT\n De-Dupe Email\n10-Shot AutoDiCoT\n + Default to Reject\n10-Shot AutoDiCoT\n Ensemble + Extraction\nTriplicate Context\nAnonymized Email\nTechniques\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\nF1 Scores\nF1 Scores of Prompting Techniques on Development Set\nMax F1 Score: 0.53\nFigure 6.6: From the first prompt tried (Zero-Shot + Context) to the last (Anonymized Email), improvements in\nF1 score were hard to come by and and often involved testing multiple underperforming prompts before finding\na performant one. Green lines show improvements over the current highest F1 score, while red lines show\ndeteriorations.\n37\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 130
  },
  {
    "chunk_full": "Entrapment:\n- Feeling like there is no exit\n- Feeling hopeless\n- Feeling like there is no way out\n- Feeling afraid that things will never be\nnormal again\n- Feeling helpless to change\n- Feeling trapped\n- Feeling doomed\n- Feeling or thinking that things will never\nchange\n- Feeling like there is no escape\n- Feeling like there are no good solutions to\nproblems\nFigure 6.7: The description of entrapment used by the\nprompt engineer\nWhat is entrapment with respect to Suicide\nCrisis Syndrome?\nFigure 6.8: Question asked to the LLM to determine\nwhether its training data had provided relevant knowl-\nedge about entrapment (it had not).\nifying the prompting such that the model would get\nthat item correct. In order to get a sense of why this\nmislabeling was taking place, the prompt engineer\nprompted the LLM to generate an explanation of\nwhy the 12th item would have been labeled the way\nit was.19\n19We are trying to avoid misleading language like “the\nLLM generated an explanation of its reasoning”. LLMs do\nnot have access to their own internal processes, and therefore\nthey cannot “explain their reasoning” in the usual sense. An\nLLM generating an “explanation” is producing description of\npotential reasoning steps in getting to the output that could be\ntrue, but also may not be accurate at all.\nIf you’re in immediate danger of harming\nyourself, please contact emergency services\nor a crisis hotline in your area. They can\nprovide immediate support and help ensure\nyour safety.\nFigure 6.9: A snippet from an output, which does not la-\nbel the data point, but rather attempts to provide mental\nhealth support to the user. Such outputs are often five\ntimes as long as this snippet.\n{ENTRAPMENT DEFINITION (Figure\n6.7)}\n{qinf}\nIs this entrapment? Yes or no.\nFigure 6.10: A Zero-Shot + Context prompt, the sim-\nplest of all prompts explored in this case study.\n{ENTRAPMENT DEFINITION (Figure\n6.7)}\nQ: {q1}\nA: {a1}\n...\nQ: {q10}\nA: {a10}\nQ: {qinf}\nA:\nFigure 6.11: 10-Shot + Context Prompt\nFigure 6.12 shows a version of that process, gen-\neralized to produce explanations for all develop-\nment question/answer items (qi, ai) in a set T rather\nthan just item 12. Informed by the reasoning steps\nr12 elicited with respect to the incorrectly labeled\nq12, the previous prompt was modified by including\nr12 in a One-Shot CoT example with incorrect rea-\nsoning, as an exemplar for what not to do (Figure\n6.13) .\nWe call the algorithm in Figure 6.12 Automatic\nDirected CoT (AutoDiCoT), since it automatically\ndirects the CoT process to reason in a particular\nway. This technique can be generalized to any\nlabeling task. It combines the automatic generation\nof CoTs (Zhang et al., 2022b) with showing the\nLLM examples of bad reasoning, as in the case of\nContrastive CoT (Chia et al., 2023). The algorithm\nwas also used in developing later prompts.\nFinally, the prompt was extended with two ad-\nditional pieces of context/instruction. The first\nwas an email message the prompt engineer had\nreceived explaining overall goals of the project,\nwhich provided more context around the concept\nof entrapment and the reasons for wanting to label\nit. The second addition was inspired by the prompt\nengineer noticing the model was frequently over-\ngenerating a positive label for entrapment. Hypoth-\nesizing that the model was being too aggressive\nin its pretraining-based inferences from the overt\n38\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 131
  },
  {
    "chunk_full": "1. Require: Development items T with n\npairs (qi, ai)\n2. For each pair (qi, ai) in T:\n(a) Label qi as entrapment or not en-\ntrapment using the model\n(b) If the model labels correctly:\ni. Prompt\nthe\nmodel\nwith\n\"Why?\" to generate a reason-\ning chain ri\n(c) Else:\ni. Prompt the model with \"It\nis actually [is/is not] entrap-\nment, please explain why.\" to\ngenerate a reasoning chain ri\n(d) Store the tuple (qi, ri, ai)\n3. Return: n tuples (qi, ri, ai)\nFigure 6.12: Algorithm: Automatic Directed CoT\nlanguage, he instructed the model to restrict itself\nto explicit statements of entrapment (Figure 6.13).\nBelow we refer to these two pieces of context, pro-\nvided in addition to the description of entrapment,\nas full context.\nA new extractor was also used for this prompt,\nwhich checks if the last word in the output is \"Yes\"\nor \"No\", instead of the first word. This updated\nprompt was tested against all inputs in the develop-\nment set except for the first 20. It did not improve\nF1, ↓0.09 (0.36) F1, but it led the prompt engineer\nin a direction that did, as discussed below. Re-\ncall dropped to ↓0.58 (0.33) recall and precision\nimproved to ↑0.09 (0.39) precision.\nAt this point, though, it is worth observing that,\nalthough it did ultimately lead to a gain in F1 score,\nthe steps taken here to cut down on over-generation\nof positive labels were not, in fact, the right move\nin terms of the longer term goals. Entrapment\nneed not be expressed explicitly in order to be\npresent (e.g. through phrases like “I feel trapped”\nor “There’s no way out”); rather, clinical experts\nwho have looked at the texts found that expressions\nof entrapment could be implicit and potentially\nquite nuanced. Moreover, in most use cases for\nautomatically spotting entrapment in someone’s\nlanguage, precision and recall are unlikely to be\nequally important and, of the two, the recall/sen-\n{PROFESSOR’S EMAIL}\n{ENTRAPMENT DEFINITION (Figure\n6.7)}\nIMPORTANT: Only label the post as\nentrapment if they explicitly say that they\nfeel trapped.\nQ: {q12}\nR: Although \"Today I found out I have\n10 days to vacate my apartment or I’ll be\nformally evicted.\nI’m 2 months behind\non my rent due to a bad time where I got\ndemoted at work and rent from making\nroughly $1000 ever 2 weeks to around\n$450.\nIf I get evicted, I’ll probably be\nhomeless\" seems to express feelings of\nbeing trapped/stuck, it is not sufficiently\nexplicit to be labeled Entrapment. seems\nto express feelings of being trapped/stuck,\nit is not sufficiently explicit to be labeled\nEntrapment.\nA: {a12}\nQ: {qinf}\nFigure 6.13: One-Shot AutoDiCot + Full Context\nsitivity (i.e. not missing people who should be\nflagged as at-risk) may matter more because the\npotential cost of a false negative is so high.\nThe take-away here, although the insight came\nlater, is that it is easy for the process of prompt\ndevelopment to diverge from the actual goals un-\nless regular engagement is fostered between the\nprompt engineer and domain experts who more\ndeeply understand the real-world use case.\nAblating Email.\nThe results of the previous\nchanges were promising, but they did involve cre-\nating a prompt that included information from an\nemail message that had not been created for that\npurpose, and which included information about the\nproject, the dataset, etc. that were not intended for\ndisclosure to a broad audience. Ironically, remov-\ning this email brought performance significantly\ndown, ↓0.27 (0.18) F1, ↓0.75 (0.17) recall and ↓\n0.1 (0.20) precision. We attribute this to the fact\nthat the email provided richer background informa-\ntion about the goals of the labeling. Although we\n39\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 132
  },
  {
    "chunk_full": "{PROFESSOR’s EMAIL}\n{ENTRAPMENT\nDEFINITION\n(Fig-\nure 6.7)}\nIMPORTANT: Only label the post as\nentrapment if they explicitly say that they\nfeel trapped.\nQ: {q1}\nA: {a1}\n...\nQ: {q10}\nA: {a10}\nQ: {q12}\nR:\nAlthough\n\"{LLM\nREASONING}\"\nseems\nto\nexpress\nfeelings\nof\nbeing\ntrapped/stuck, it is not sufficiently explicit\nto be labeled Entrapment.\nA: {a12}\nQ: {qinf}\nFigure 6.14: 10-Shot + 1 AutoDiCoT\nwould not recommend including email or any other\npotentially identifying information in any LLM\nprompt, we chose to leave the email in the prompt;\nthis is consistent with scenarios in many typical\nsettings, in which prompts are not expected to be\nexposed to others.\n10-Shot + 1 AutoDiCoT.\nAs a next step, the\nprompt engineer tried including full context, 10 reg-\nular exemplars, and the one-shot exemplar about\nhow not to reason. This hurt performance (Figure\n6.14) ↓0.30 (0.15) F1, ↓0.08 (0.10) recall, ↓0.03\n(0.33) precision.\nFull Context Only.\nNext, a prompt was created\nusing only full context, without any exemplars (Fig-\nure 6.15). This boosted performance over the pre-\nvious technique, but did not make progress over-\nall ↓0.01 (0.44) F1, ↑0.01 (0.92) recall, ↓0.01\n(0.29) precision. Interestingly, in this prompt, the\nprompt engineer accidentally pasted in the full-\ncontext email twice, and that ended up having sig-\nnificant positive effects on performance later (and\nremoving the duplicate actually decreased perfor-\nmance). This is reminiscent of the re-reading tech-\nnique (Xu et al., 2023).\n{PROFESSOR’s EMAIL}\n{PROFESSOR’s EMAIL}\n{ENTRAPMENT\nDEFINITION\n(Fig-\nure 6.7)}\nIMPORTANT: Only label the post as\nentrapment if they explicitly say that they\nfeel trapped.\nQ: {qinf} A:\nFigure 6.15: Full Context Only\nThis can be interpreted both optimistically and\npessimistically.\nOptimistically, it demonstrates\nhow improvements can arise through exploration\nand fortuitous discovery. On the pessimistic side,\nthe value of duplicating the email in the prompt\nhighlights the extent to which prompting remains a\ndifficult to explain black art, where the LLM may\nturn out to be unexpectedly sensitive to variations\none might not expect to matter.\n10-Shot AutoDiCoT.\nThe next step was to create\nmore AutoDiCoT exemplars, per the algorithm in\nFigure 6.12. A total of ten new AutoDiCoT exem-\nplars were added to the full context prompt (Figure\n6.16). This yielded the most successful prompt\nfrom this prompt engineering exercise, in terms of\nF1 score, ↑0.08 (0.53) F1, ↓0.05 (0.86) recall, ↑\n0.08 (0.38) precision.\n20-Shot AutoDiCoT.\nFurther experimentation\nproceeded seeking (unsuccesfully) to improve on\nthe previous F1 result. In one attempt, the prompt\nengineer labeled an additional ten exemplars, and\ncreated a 20-shot prompt from the first 20 data\npoints in the development set. This led to worse\nresults than the 10-shot prompt, when tested on all\nsamples other than the first twenty, ↓0.04 (0.49)\nF1, ↑0.08 (0.94) recall, ↓0.05 (0.33) precision.\nNotably, it also yielded worse performance on the\ntest set.\n20-Shot AutoDiCoT + Full Words.\nThe prompt\nengineer conjectured that the LLM would perform\nbetter if the prompt included full words Question,\nReasoning, and Answer rather than Q, R, A. How-\never, this did not succeed (Figure 6.17), ↓0.05\n40\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 133
  },
  {
    "chunk_full": "{PROFESSOR’s EMAIL}\n{ENTRAPMENT DEFINITION}\nIMPORTANT: Only label the post as\nentrapment if they explicitly say that they\nfeel trapped.\nQ: {q1}\nR: {r1}\nA: {a1}\n...\nQ: {q10}\nR: {r10}\nA: {a10}\nQ: {qinf}\nFigure 6.16: 10-Shot AutoDiCoT\n(0.48) F1, ↑0.08 (0.94) recall, ↓0.06 (0.32) preci-\nsion.\n20-Shot AutoDiCoT + Full Words + Extraction\nPrompt.\nThe prompt engineer then noticed that in\nmany cases, the LLM generated outputs that could\nnot properly be parsed to obtain a response. So,\nthey crafted a prompt that extracted answers from\nthe LLM’s response (Figure 6.18). Although this\nimproved accuracy by a few points, it decreased\nF1, thanks to the fact that many of the outputs\nthat had been unparsed actually contained incorrect\nresponses, ↓0.05 (0.48) F1, ↓0.05 (0.33) precision,\nwith no change in recall (0.86).\n10-Shot AutoDiCoT + Extraction Prompt.\nAp-\nplying the extraction prompt to the best performing\n10-Shot AutoDiCoT prompt did not improve re-\nsults, ↓0.04 (0.49) F1, ↓0.08 (0.78) recall, ↓0.03\n(0.35) precision.\n10-Shot AutoDiCoT without Email.\nAs noted\nabove, removing the email outright from the\nprompt hurt performance, ↓0.14 (0.39) F1, ↓0.39\n(0.48) recall, ↓0.06 (0.32) precision.\nDe-Duplicating Email.\nAlso as noted above, it\nseemed reasonable that removing the duplication\nof the email would perform as well or better than\nthe prompt with the unintentional duplication. As it\nturned out, however, removing the duplicate signif-\nicantly hurt performance, ↓0.07 (0.45) F1, ↓0.12\n(0.74) recall, ↓0.05 (0.33) precision.\n{PROFESSOR’s EMAIL}\n{ENTRAPMENT DEFINITION}\nIMPORTANT: Only label the post as\nentrapment if they explicitly say that they\nfeel trapped.\nQuestion: {q1}\nReasoning: {r1}\nAnswer: {a1}\n...\nQuestion: {q20}\nReasoning: {r20}\nAnswer: {a20}\nQuestion: {qinf}\nFigure 6.17: 20-shot AutoDiCoT\n{PROFESSOR’s EMAIL}\n{ENTRAPMENT DEFINITION}\nIMPORTANT: Only label the post as\nentrapment if they explicitly say that they\nfeel trapped.\nQuestion: {REDACTED}\nAnswer: {ANSWER}\nDoes this Answer indicate entrapment?\nOutput the word Yes if it is labeled as\nentrapment and output the word No if it is\nnot labeled as entrapment. Only output the\nword Yes or the word No.\nFigure 6.18: Extraction Prompt\n41\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 134
  },
  {
    "chunk_full": "10-Shot AutoDiCoT + Default to Reject.\nThis\napproach used the best performing prompt, and de-\nfaulted to labeling as negative (not entrapment) in\nthe case of answers that are not extracted properly.\nThis did not help performance, ↓0.11 (0.42) F1, ↓\n0.04 (0.83) recall, ↓0.10 (0.28) precision.\nEnsemble + Extraction.\nEspecially for systems\nthat are sensitive to the details of their inputs, there\nare advantages in trying multiple variations of an\ninput and then combining their results. That was\ndone here by taking the best performing prompt,\nthe 10-Shot AutoDiCoT prompt, and creating three\nversions of it with different orderings of the exem-\nplars. The average of the three results was taken to\nbe the final answer. Unfortunately, both orderings\nthat differed from the default ordering led to the\nLLM not outputting a well-structured response. An\nextraction prompt was therefore used to obtain final\nanswers. This exploration hurt rather than helped\nperformance ↓0.16 (0.36) F1, ↓0.23 (0.64) recall,\n↓0.13 (0.26) precision.\n10-Shot AutoCoT + 3x the context (no email\ndupe).\nRecall that context refers to the descrip-\ntion of entrapment, an instruction about explicit-\nness, and an email. Since the duplicated email\nhad improved performance, the prompt engineer\ntested out pasting in three copies of the context\n(first de-duplicating the email). However, this did\nnot improve performance, ↓0.06 (0.47) F1, ↓0.08\n(0.78) recall, ↓0.05 (0.33) precision.\nAnonymize Email.\nAt this point it seemed clear\nthat including the duplicated email in the prompt\nwas actually, although not explainably, essential to\nthe best performance so far obtained. The prompt\nengineer decided to anonymize the email by re-\nplacing personal names with other, random names.\nHowever, surprisingly, this decreased performance\nsignificantly ↓0.08 (0.45) F1, ↓0.14 (0.72) recall,\n↓0.06 (0.33) precision.\nDSPy.\nWe concluded the case study by explor-\ning an alternative to manual prompt engineer-\ning, the DSPy framework (Khattab et al., 2023),\nwhich automatically optimizes LLM prompts for\na given target metric.\nSpecifically, we begin\nwith a chain-of-thought classification pipeline\nthat uses the definition of entrapment in Figure\n6.7. Over 16 iterations, DSPy bootstrapped syn-\nthetic LLM-generated demonstrations and ran-\ndomly sampled training exemplars, with the\n10-Shot AutoDiCoT\n20-Shot AutoDiCoT\nDSPy Default\nDSPy Default\n+ Small Modifications\n0.0\n0.2\n0.4\n0.6\n0.8\nScores\nScores of Different Prompting Techniques on Test Set\nF1\nRecall\nPrecision\nFigure 6.19: Scores of different prompting techniques\non the test set.\nultimate objective of maximizing F1 on the\nsame development set used above.\nWe used\ngpt-4-0125-preview and the default settings\nfor the BootstrapFewShotWithRandomSearch\n“teleprompter” (the optimization approach). Fig-\nure 6.19 shows the results of two of these prompts\non the test set, one of which used default DSPy\nbehaviour, and the second which was manually\nmodified slightly from this default. The best result-\ning prompt includes 15 exemplars (without CoT\nreasoning) and one bootstrapped reasoning demon-\nstration. It achieves 0.548 F1 (and 0.385 / 0.952\nprecision / recall) on the test set, without making\nany use of the professor’s email nor the incorrect\ninstruction about the explicitness of entrapment. It\nalso performs much better than the human prompt\nengineer’s prompts on the test set, which demon-\nstrates the significant promise of automated prompt\nengineering.\n6.2.4\nDiscussion\nPrompt engineering is a non-trivial process, the nu-\nances of which are not currently well described in\nliterature. From the fully manual process illustrated\nabove, there are several take-aways worth summa-\nrizing. First, prompt engineering is fundamentally\ndifferent from other ways of getting a computer to\nbehave the way you want it to: these systems are\nbeing cajoled, not programmed, and, in addition\nto being quite sensitive to the specific LLM being\nused, they can be incredibly sensitive to specific\ndetails in prompts without there being any obvi-\nous reason those details should matter. Second,\ntherefore, it is important to dig into the data (e.g.\ngenerating potential explanations for LLM “reason-\ning” that leads to incorrect responses). Related, the\n42\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 135
  },
  {
    "chunk_full": "third and most important take-away is that prompt\nengineering should involve engagement between\nthe prompt engineer, who has expertise in how to\ncoax LLMs to behave in desired ways, and domain\nexperts, who understand what those desired ways\nare and why.\nUltimately we found that there was significant\npromise in an automated method for exploring the\nprompting space, but also that combining that au-\ntomation with human prompt engineering/revision\nwas the most successful approach. We hope that\nthis study will serve as a step toward more robust\nexaminations of how to perform prompt engineer-\ning.\n43\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 136
  },
  {
    "chunk_full": "7\nRelated Work\nIn this section, we review existing surveys and\nmeta-analyses of prompting. Liu et al. (2023b)\nperform a systematic review of prompt engineer-\ning in the pre-ChatGPT era, including various\naspects of prompting like prompt template engi-\nneering, answer engineering, prompt ensembling,\nand prompt tuning methods. Their review cov-\ners many different types of prompting (e.g., cloze,\nsoft-prompting, etc., across many different types\nof language models) while we focus on discrete\npre-fix prompting but more in-depth discussion.\nChen et al. (2023a) provide a review of popular\nprompting techniques like Chain-of-Thought, Tree-\nof-Thought, Self-Consistency, and Least-to-Most\nprompting, along with outlooks for future prompt-\ning research. White et al. (2023) and Schmidt\net al. (2023) provide a taxonomy of prompt pat-\nterns, which are similar to software patterns (and\nprompting techniques for that matter). Gao (2023)\nprovide a practical prompting technique tutorial for\na non-technical audience. Santu and Feng (2023)\nprovide a general taxonomy of prompts that can be\nused to design prompts with specific properties to\nperform a wide range of complex tasks. Bubeck\net al. (2023) qualitatively experiment with a wide\nrange of prompting methods on the early version\nof GPT-4 to understand its capabilities. Chu et al.\n(2023) review Chain-of-Thought related prompt-\ning methods for reasoning. In earlier work, Bom-\nmasani et al. (2021) review and discuss opportuni-\nties and risks of foundation models broadly, and\nDang et al. (2022) discuss prompting strategies for\ninteractive creative applications that use prompting\nas a new paradigm for human interaction, with a\nparticular focus on the user interface design that\nsupports user prompting. As an addition to these\nexisting surveys, our review aims to provide a more\nupdated and formalized systematic review.\nThere is also a line of work that surveys prompt-\ning techniques for particular domains or down-\nstream applications. Meskó (2023) and Wang et al.\n(2023d) offer recommended use cases and limi-\ntations of prompt engineering in the medical and\nhealthcare domains. Heston and Khun (2023) pro-\nvide a review of prompt engineering for medical\neducation use cases. Peskoff and Stewart (2023)\nquery ChatGPT and YouChat to assess domain cov-\nerage. Hua et al. (2024) use a GPT-4-automated ap-\nproach to review LLMs in the mental health space.\nWang et al. (2023c) review prompt engineering and\nrelevant models in the visual modality and Yang\net al. (2023e) provided a comprehensive list of qual-\nitative analyses of multimodal prompting, particu-\nlarly focusing on GPT-4V20. Durante et al. (2024)\nreview multimodal interactions based on LLM em-\nbodied agents. Ko et al. (2023b) review literature\non the adoption of Text-to-Image generation mod-\nels for visual artists’ creative works. Gupta et al.\n(2024) review GenAI through a topic modeling\napproach. Awais et al. (2023) review foundation\nmodels in vision, including various prompting tech-\nniques. Hou et al. (2023) perform a systematic\nreview of prompt engineering techniques as they\nrelate to software engineering. They use a sys-\ntematic review technique developed by Keele et al.\n(2007), specifically for software engineering re-\nviews. Wang et al. (2023e) review the literature\non software testing with large language models.\nZhang et al. (2023a) review ChatGPT prompting\nperformance on software engineering tasks such as\nautomated program repair. Neagu (2023) provide\na systematic review on how prompt engineering\ncan be leveraged in computer science education. Li\net al. (2023j) review literature on the fairness of\nlarge language models. There are also surveys on\nrelated aspects such as hallucination of language\nmodels (Huang et al., 2023b), verifiability (Liu\net al., 2023a), reasoning (Qiao et al., 2022), aug-\nmentation (Mialon et al., 2023), and linguistic prop-\nerties of prompts (Leidinger et al., 2023). Different\nfrom these works, we perform our review targeting\nbroad coverage and generally applicable prompting\ntechniques. Finally, in terms of more general prior\nand concurrent surveys (Liu et al., 2023b; Sahoo\net al., 2024; Vatsal and Dubey, 2024), this survey\noffers an update in a fast-moving field. In addition,\nwe provide a starting point for taxonomic organi-\nzation of prompting techniques and standardiza-\ntion of terminology. Moreover, unlike many works\nthat claim to be systematic, we base our work in\nthe widely used standard for systematic literature\nreviews—PRISMA (Page et al., 2021).\n20https://openai.com/research/\ngpt-4v-system-card\n44\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 137
  },
  {
    "chunk_full": "8\nConclusions\nGenerative AI is a novel technology, and broader\nunderstanding of models’ capabilities and limita-\ntions remains limited. Natural language is a flexi-\nble, open-ended interface, with models having few\nobvious affordances. The use of Generative AI\ntherefore inherits many of the standard challenges\nof linguistic communication—e.g., ambiguity, the\nrole of context, the need for course correction—\nwhile at the same time adding the challenge of\ncommunicating with an entity whose “understand-\ning” of language may not bear any substantial re-\nlationship to human understanding. Many of the\ntechniques described here have been called “emer-\ngent”, but it is perhaps more appropriate to say that\nthey were discovered—the result of thorough ex-\nperimentation, analogies from human reasoning, or\npure serendipity.\nThe present work is an initial attempt to catego-\nrize the species of an unfamiliar territory. While\nwe make every attempt to be comprehensive, there\nare sure to be gaps and redundancies. Our inten-\ntion is to provide a taxonomy and terminology that\ncover a large number of existing prompt engineer-\ning techniques, and which can accommodate future\nmethods. We discuss over 200 prompting tech-\nniques, frameworks built around them, and issues\nlike safety and security that need to be kept in mind\nwhen using them. We also present two case studies\nin order to provide a clear sense of models’ ca-\npabilities and what it is like to tackle a problem\nin practice. Last, our stance is primarily observa-\ntional, and we make no claims to the validity of the\npresented techniques. The field is new, and evalua-\ntion is variable and unstandardized—even the most\nmeticulous experimentation may suffer from unan-\nticipated shortcomings, and model outputs them-\nselves are sensitive to meaning-preserving changes\nin inputs. As a result, we encourage the reader to\navoid taking any claims at face value and to rec-\nognize that techniques may not transfer to other\nmodels, problems, or datasets.\nTo those just beginning in prompt engineering,\nour recommendations resemble what one would\nrecommend in any machine learning setting: un-\nderstand the problem you are trying to solve (rather\nthan just focusing on input/output and benchmark\nscores), and ensure the data and metrics you are\nworking with constitute a good representation of\nthat problem. It is better to start with simpler ap-\nproaches first, and to remain skeptical of claims\nabout method performance. To those already en-\ngaged in prompt engineering, we hope that our tax-\nonomy will shed light on the relationships between\nexisting techniques. To those developing new tech-\nniques, we encourage situating new methods within\nour taxonomy, as well as including ecologically\nvalid case studies and illustrations of those tech-\nniques.\nAcknowledgements\nWe appreciate the advice given by Hal Daumé III,\nAdam Visokay, and Jordan Boyd-Graber and re-\nview by Diyi Yang, Brandon M. Stewart, Shubham\nVatsal, Mason Marchetti, Aaron Tay, Andrea Vella,\nand Allie Miller. We also appreciate the 10K USD\nin API credits given by OpenAI and design work\nby Benjamin DiMarco.\n45\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 138
  },
  {
    "chunk_full": "References\nAdept. 2023. ACT-1: Transformer for Actions. https:\n//www.adept.ai/blog/act-1.\nRishabh Agarwal, Avi Singh, Lei M Zhang, Bernd\nBohnet, Luis Rosias, Stephanie Chan, Biao Zhang,\nAnkesh Anand, Zaheer Abbas, Azade Nova, et al.\n2024. Many-shot in-context learning. arXiv preprint\narXiv:2404.11018.\nSweta Agrawal, Chunting Zhou, Mike Lewis, Luke\nZettlemoyer, and Marjan Ghazvininejad. 2023. In-\ncontext examples selection for machine translation.\nIn Findings of the Association for Computational\nLinguistics: ACL 2023, pages 8857–8873, Toronto,\nCanada. Association for Computational Linguistics.\nKabir Ahuja, Harshita Diddee, Rishav Hada, Milli-\ncent Ochieng, Krithika Ramesh, Prachi Jain, Ak-\nshay Nambi, Tanuja Ganu, Sameer Segal, Maxamed\nAxmed, Kalika Bali, and Sunayana Sitaram. 2023.\nMEGA: Multilingual Evaluation of Generative AI.\nIn EMNLP.\nRebuff AI. 2023. A self-hardening prompt injection\ndetector.\nAnirudh Ajith, Chris Pan, Mengzhou Xia, Ameet Desh-\npande, and Karthik Narasimhan. 2024. InstructEval:\nSystematic evaluation of instruction selection meth-\nods. In Findings of the Association for Computa-\ntional Linguistics: NAACL 2024, pages 4336–4350,\nMexico City, Mexico. Association for Computational\nLinguistics.\nSílvia Araújo and Micaela Aguiar. 2023. Comparing\nchatgpt’s and human evaluation of scientific texts’\ntranslations from english to portuguese using popular\nautomated translators. CLEF.\nArthurAI. 2024. Arthur shield.\nAkari Asai, Sneha Kudugunta, Xinyan Velocity Yu,\nTerra Blevins, Hila Gonen, Machel Reid, Yulia\nTsvetkov, Sebastian Ruder, and Hannaneh Hajishirzi.\n2023.\nBUFFET: Benchmarking Large Language\nModels for Few-shot Cross-lingual Transfer.\nMuhammad Awais,\nMuzammal Naseer,\nSalman\nKhan, Rao Muhammad Anwer, Hisham Cholakkal,\nMubarak Shah, Ming-Hsuan Yang, and Fahad Shah-\nbaz Khan. 2023. Foundational models defining a new\nera in vision: A survey and outlook.\nAbhijeet Awasthi, Nitish Gupta, Bidisha Samanta,\nShachi Dave, Sunita Sarawagi, and Partha Talukdar.\n2023. Bootstrapping multilingual semantic parsers\nusing large language models. In Proceedings of the\n17th Conference of the European Chapter of the As-\nsociation for Computational Linguistics, pages 2455–\n2467, Dubrovnik, Croatia. Association for Computa-\ntional Linguistics.\nYushi Bai, Xin Lv, Jiajie Zhang, Hongchang Lyu,\nJiankai Tang, Zhidian Huang, Zhengxiao Du, Xiao\nLiu, Aohan Zeng, Lei Hou, Yuxiao Dong, Jie Tang,\nand Juanzi Li. 2023a. Longbench: A bilingual, mul-\ntitask benchmark for long context understanding.\nYushi Bai, Jiahao Ying, Yixin Cao, Xin Lv, Yuze He,\nXiaozhi Wang, Jifan Yu, Kaisheng Zeng, Yijia Xiao,\nHaozhe Lyu, et al. 2023b. Benchmarking Foundation\nModels with Language-Model-as-an-Examiner. In\nNeurIPS 2023 Datasets and Benchmarks.\nChris Bakke. 2023. Buying a chevrolet for 1$.\nNishant Balepur, Jie Huang, and Kevin Chang. 2023.\nExpository text generation: Imitate, retrieve, para-\nphrase. In Proceedings of the 2023 Conference on\nEmpirical Methods in Natural Language Process-\ning, pages 11896–11919, Singapore. Association for\nComputational Linguistics.\nYejin Bang, Samuel Cahyawijaya, Nayeon Lee, Wen-\nliang Dai, Dan Su, Bryan Wilie, Holy Lovenia, Ziwei\nJi, Tiezheng Yu, Willy Chung, Quyet V. Do, Yan Xu,\nand Pascale Fung. 2023. A Multitask, Multilingual,\nMultimodal Evaluation of ChatGPT on Reasoning,\nHallucination, and Interactivity. In AACL.\nHritik Bansal, Karthik Gopalakrishnan, Saket Dingliwal,\nSravan Bodapati, Katrin Kirchhoff, and Dan Roth.\n2023. Rethinking the Role of Scale for In-Context\nLearning: An Interpretability-based Case Study at 66\nBillion Scale. In ACL.\nOmer Bar-Tal, Dolev Ofri-Amar, Rafail Fridman, Yoni\nKasten, and Tali Dekel. 2022. Text2live: Text-driven\nlayered image and video editing.\nAmanda Bertsch, Maor Ivgi, Uri Alon, Jonathan Berant,\nMatthew R Gormley, and Graham Neubig. 2024. In-\ncontext learning with long-context models: An in-\ndepth exploration. arXiv preprint arXiv:2405.00200.\nMaciej Besta, Nils Blach, Ales Kubicek, Robert Ger-\nstenberger, Lukas Gianinazzi, Joanna Gajda, Tomasz\nLehmann, Michał Podstawski, Hubert Niewiadomski,\nPiotr Nyczyk, and Torsten Hoefler. 2024. Graph of\nThoughts: Solving Elaborate Problems with Large\nLanguage Models. Proceedings of the AAAI Confer-\nence on Artificial Intelligence, 38(16):17682–17690.\nRishi Bommasani, Drew A. Hudson, Ehsan Adeli, Russ\nAltman, Simran Arora, Sydney von Arx, Michael S.\nBernstein, Jeannette Bohg, Antoine Bosselut, Emma\nBrunskill, Erik Brynjolfsson, S. Buch, Dallas Card,\nRodrigo Castellon, Niladri S. Chatterji, Annie S.\nChen, Kathleen A. Creel, Jared Davis, Dora Dem-\nszky, Chris Donahue, Moussa Doumbouya, Esin Dur-\nmus, Stefano Ermon, John Etchemendy, Kawin Etha-\nyarajh, Li Fei-Fei, Chelsea Finn, Trevor Gale, Lau-\nren E. Gillespie, Karan Goel, Noah D. Goodman,\nShelby Grossman, Neel Guha, Tatsunori Hashimoto,\nPeter Henderson, John Hewitt, Daniel E. Ho, Jenny\nHong, Kyle Hsu, Jing Huang, Thomas F. Icard, Saahil\nJain, Dan Jurafsky, Pratyusha Kalluri, Siddharth\nKaramcheti, Geoff Keeling, Fereshte Khani, O. Khat-\ntab, Pang Wei Koh, Mark S. Krass, Ranjay Krishna,\n46\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 139
  },
  {
    "chunk_full": "Rohith Kuditipudi, Ananya Kumar, Faisal Ladhak,\nMina Lee, Tony Lee, Jure Leskovec, Isabelle Levent,\nXiang Lisa Li, Xuechen Li, Tengyu Ma, Ali Malik,\nChristopher D. Manning, Suvir Mirchandani, Eric\nMitchell, Zanele Munyikwa, Suraj Nair, Avanika\nNarayan, Deepak Narayanan, Benjamin Newman,\nAllen Nie, Juan Carlos Niebles, Hamed Nilforoshan,\nJ. F. Nyarko, Giray Ogut, Laurel J. Orr, Isabel Pa-\npadimitriou, Joon Sung Park, Chris Piech, Eva Porte-\nlance, Christopher Potts, Aditi Raghunathan, Robert\nReich, Hongyu Ren, Frieda Rong, Yusuf H. Roohani,\nCamilo Ruiz, Jack Ryan, Christopher R’e, Dorsa\nSadigh, Shiori Sagawa, Keshav Santhanam, Andy\nShih, Krishna Parasuram Srinivasan, Alex Tamkin,\nRohan Taori, Armin W. Thomas, Florian Tramèr,\nRose E. Wang, William Wang, Bohan Wu, Jiajun\nWu, Yuhuai Wu, Sang Michael Xie, Michihiro Ya-\nsunaga, Jiaxuan You, Matei A. Zaharia, Michael\nZhang, Tianyi Zhang, Xikun Zhang, Yuhui Zhang,\nLucia Zheng, Kaitlyn Zhou, and Percy Liang. 2021.\nOn the Opportunities and Risks of Foundation Mod-\nels. ArXiv, abs/2108.07258.\nHezekiah J. Branch, Jonathan Rodriguez Cefalu, Jeremy\nMcHugh, Leyla Hujer, Aditya Bahl, Daniel del\nCastillo Iglesias, Ron Heichman, and Ramesh Dar-\nwishi. 2022. Evaluating the susceptibility of pre-\ntrained language models via handcrafted adversarial\nexamples.\nGreg Brockman, Vicki Cheung, Ludwig Pettersson,\nJonas Schneider, John Schulman, Jie Tang, and Woj-\nciech Zaremba. 2016. Openai gym.\nTim Brooks, Bill Peebles, Connor Homes, Will DePue,\nYufei Guo, Li Jing, David Schnurr, Joe Taylor, Troy\nLuhman, Eric Luhman, Clarence Wing Yin Ng, Ricky\nWang, and Aditya Ramesh. 2024. Video generation\nmodels as world simulators. OpenAI.\nTom B. Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, Sandhini Agarwal, Ariel Herbert-Voss,\nGretchen Krueger, Tom Henighan, Rewon Child,\nAditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,\nClemens Winter, Christopher Hesse, Mark Chen, Eric\nSigler, Mateusz Litwin, Scott Gray, Benjamin Chess,\nJack Clark, Christopher Berner, Sam McCandlish,\nAlec Radford, Ilya Sutskever, and Dario Amodei.\n2020. Language models are few-shot learners.\nSébastien Bubeck, Varun Chandrasekaran, Ronen El-\ndan, John A. Gehrke, Eric Horvitz, Ece Kamar, Peter\nLee, Yin Tat Lee, Yuan-Fang Li, Scott M. Lundberg,\nHarsha Nori, Hamid Palangi, Marco Tulio Ribeiro,\nand Yi Zhang. 2023.\nSparks of artificial general\nintelligence: Early experiments with gpt-4. ArXiv,\nabs/2303.12712.\nNicholas Carlini,\nFlorian Tramer,\nEric Wallace,\nMatthew Jagielski, Ariel Herbert-Voss, Katherine\nLee, Adam Roberts, Tom Brown, Dawn Song, Ul-\nfar Erlingsson, Alina Oprea, and Colin Raffel. 2021.\nExtracting training data from large language models.\nCDC. 2023. Suicide data and statistics.\nChi-Min Chan, Weize Chen, Yusheng Su, Jianxuan Yu,\nWei Xue, Shanghang Zhang, Jie Fu, and Zhiyuan Liu.\n2024. Chateval: Towards better LLM-based eval-\nuators through multi-agent debate. In The Twelfth\nInternational Conference on Learning Representa-\ntions.\nErnie Chang, Pin-Jie Lin, Yang Li, Sidd Srinivasan,\nGael Le Lan, David Kant, Yangyang Shi, Forrest\nIandola, and Vikas Chandra. 2023. In-context prompt\nediting for conditional audio generation.\nHarrison Chase. 2022. LangChain.\nBanghao Chen, Zhaofeng Zhang, Nicolas Langrené,\nand Shengxin Zhu. 2023a. Unleashing the potential\nof prompt engineering in large language models: a\ncomprehensive review.\nLingjiao Chen, Matei Zaharia, and James Zou. 2023b.\nHow is chatgpt’s behavior changing over time? arXiv\npreprint arXiv:2307.09009.\nShiqi Chen, Siyang Gao, and Junxian He. 2023c. Eval-\nuating factual consistency of summaries with large\nlanguage models. arXiv preprint arXiv:2305.14069.\nWenhu Chen, Xueguang Ma, Xinyi Wang, and\nWilliam W. Cohen. 2023d.\nProgram of thoughts\nprompting: Disentangling computation from reason-\ning for numerical reasoning tasks. TMLR.\nXinyun Chen, Renat Aksitov, Uri Alon, Jie Ren, Ke-\nfan Xiao, Pengcheng Yin, Sushant Prakash, Charles\nSutton, Xuezhi Wang, and Denny Zhou. 2023e. Uni-\nversal self-consistency for large language model gen-\neration.\nYang Chen, Yingwei Pan, Yehao Li, Ting Yao, and Tao\nMei. 2023f. Control3d: Towards controllable text-to-\n3d generation.\nYi Chen, Rui Wang, Haiyun Jiang, Shuming Shi, and\nRuifeng Xu. 2023g. Exploring the use of large lan-\nguage models for reference-free text quality evalua-\ntion: An empirical study. In Findings of the Associa-\ntion for Computational Linguistics: IJCNLP-AACL\n2023 (Findings), pages 361–374, Nusa Dua, Bali.\nAssociation for Computational Linguistics.\nJiaxin Cheng, Tianjun Xiao, and Tong He. 2023. Con-\nsistent video-to-video transfer using synthetic dataset.\nArXiv, abs/2311.00213.\nYew Ken Chia, Guizhen Chen, Luu Anh Tuan, Soujanya\nPoria, and Lidong Bing. 2023. Contrastive chain-of-\nthought prompting.\nJiqun Chu and Zuoquan Lin. 2023. Entangled repre-\nsentation learning: A bidirectional encoder decoder\nmodel. In Proceedings of the 2022 5th International\nConference on Algorithms, Computing and Artificial\nIntelligence, ACAI ’22, New York, NY, USA. Asso-\nciation for Computing Machinery.\n47\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 140
  },
  {
    "chunk_full": "Zheng Chu, Jingchang Chen, Qianglong Chen, Weijiang\nYu, Tao He, Haotian Wang, Weihua Peng, Ming Liu,\nBing Qin, and Ting Liu. 2023. A survey of chain of\nthought reasoning: Advances, frontiers and future.\nRobert J Cramer, Jacinta Hawgood, Andréa R Kaniuka,\nByron Brooks, and Justin C Baker. 2023. Updated\nsuicide prevention core competencies for mental\nhealth professionals: Implications for training, re-\nsearch, and practice. Clinical Psychology: Science\nand Practice.\nKatherine Crowson, Stella Biderman, Daniel Kornis,\nDashiell Stander, Eric Hallahan, Louis Castricato,\nand Edward Raff. 2022. Vqgan-clip: Open domain\nimage generation and editing with natural language\nguidance.\nLeyang Cui, Yu Wu, Jian Liu, Sen Yang, and Yue Zhang.\n2021. Template-based named entity recognition us-\ning bart. Findings of the Association for Computa-\ntional Linguistics: ACL-IJCNLP 2021.\nHai Dang, Lukas Mecke, Florian Lehmann, Sven Goller,\nand Daniel Buschek. 2022. How to prompt? opportu-\nnities and challenges of zero- and few-shot learning\nfor human-ai interaction in creative applications of\ngenerative models.\nMaksym Del and Mark Fishel. 2023. True detective: A\ndeep abductive reasoning benchmark undoable for\ngpt-3 and challenging for gpt-4. In Proceedings of\nthe 12th Joint Conference on Lexical and Computa-\ntional Semantics (*SEM 2023). Association for Com-\nputational Linguistics.\nMingkai Deng, Jianyu Wang, Cheng-Ping Hsieh, Yihan\nWang, Han Guo, Tianmin Shu, Meng Song, Eric P.\nXing, and Zhiting Hu. 2022. RLPrompt: Optimizing\nDiscrete Text Prompts with Reinforcement Learning.\nIn RLPrompt: Optimizing Discrete Text Prompts with\nReinforcement Learning.\nYihe Deng, Weitong Zhang, Zixiang Chen, and Quan-\nquan Gu. 2023. Rephrase and respond: Let large\nlanguage models ask better questions for themselves.\nShehzaad Dhuliawala, Mojtaba Komeili, Jing Xu,\nRoberta Raileanu, Xian Li, Asli Celikyilmaz, and\nJason Weston. 2023. Chain-of-verification reduces\nhallucination in large language models.\nShizhe Diao, Pengcheng Wang, Yong Lin, and Tong\nZhang. 2023.\nActive prompting with chain-of-\nthought for large language models.\nMing Ding, Zhuoyi Yang, Wenyi Hong, Wendi Zheng,\nChang Zhou, Da Yin, Junyang Lin, Xu Zou, Zhou\nShao, Hongxia Yang, and Jie Tang. 2021. Cogview:\nMastering text-to-image generation via transform-\ners. In Advances in Neural Information Processing\nSystems, volume 34, pages 19822–19835. Curran As-\nsociates, Inc.\nQingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Zhiyong\nWu, Baobao Chang, Xu Sun, Jingjing Xu, Lei Li, and\nZhifang Sui. 2023. A survey on in-context learning.\nYi Dong, Ronghui Mu, Gaojie Jin, Yi Qi, Jinwei Hu,\nXingyu Zhao, Jie Meng, Wenjie Ruan, and Xiaowei\nHuang. 2024. Building guardrails for large language\nmodels.\nYann Dubois, Xuechen Li, Rohan Taori, Tianyi Zhang,\nIshaan Gulrajani, Jimmy Ba, Carlos Guestrin, Percy\nLiang, and Tatsunori B Hashimoto. 2023. Alpaca-\nfarm: A simulation framework for methods that learn\nfrom human feedback. In NeurIPS.\nZane Durante, Qiuyuan Huang, Naoki Wake, Ran Gong,\nJae Sung Park, Bidipta Sarkar, Rohan Taori, Yusuke\nNoda, Demetri Terzopoulos, Yejin Choi, Katsushi\nIkeuchi, Hoi Vo, Fei-Fei Li, and Jianfeng Gao. 2024.\nAgent ai: Surveying the horizons of multimodal in-\nteraction.\nJulen Etxaniz, Gorka Azkune, Aitor Soroa, Oier Lopez\nde Lacalle, and Mikel Artetxe. 2023. Do multilingual\nlanguage models think better in english?\nAngela Fan, Mike Lewis, and Yann Dauphin. 2018.\nHierarchical neural story generation. In Proceedings\nof the 56th Annual Meeting of the Association for\nComputational Linguistics (Volume 1: Long Papers).\nAssociation for Computational Linguistics.\nLi Fei-Fei, Rob Fergus, and Pietro Perona. 2006. One-\nshot learning of object categories. IEEE Transac-\ntions on Pattern Analysis and Machine Intelligence,\n28:594–611.\nLincong Feng, Muyu Wang, Maoyu Wang, Kuo Xu, and\nXiaoli Liu. 2023. Metadreamer: Efficient text-to-3d\ncreation with disentangling geometry and texture.\nPatrick Fernandes, Daniel Deutsch, Mara Finkel-\nstein, Parker Riley, André Martins, Graham Neubig,\nAnkush Garg, Jonathan Clark, Markus Freitag, and\nOrhan Firat. 2023. The devil is in the errors: Leverag-\ning large language models for fine-grained machine\ntranslation evaluation. In Proceedings of the Eighth\nConference on Machine Translation, pages 1066–\n1083, Singapore. Association for Computational Lin-\nguistics.\nChrisantha\nFernando,\nDylan\nBanarse,\nHenryk\nMichalewski, Simon Osindero, and Tim Rock-\ntäschel. 2023.\nPromptbreeder:\nSelf-referential\nself-improvement via prompt evolution.\nJinlan Fu, See-Kiong Ng, Zhengbao Jiang, and Pengfei\nLiu. 2023a. Gptscore: Evaluate as you desire. arXiv\npreprint arXiv:2302.04166.\nJinlan Fu, See-Kiong Ng, and Pengfei Liu. 2022. Poly-\nglot prompt: Multilingual multitask prompt training.\nIn Proceedings of the 2022 Conference on Empiri-\ncal Methods in Natural Language Processing, pages\n9919–9935, Abu Dhabi, United Arab Emirates. As-\nsociation for Computational Linguistics.\nYao Fu, Hao Peng, Ashish Sabharwal, Peter Clark, and\nTushar Khot. 2023b. Complexity-based prompting\nfor multi-step reasoning. In The Eleventh Interna-\ntional Conference on Learning Representations.\n48\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 141
  },
  {
    "chunk_full": "Victor Gabillon, Mohammad Ghavamzadeh, Alessandro\nLazaric, and Sébastien Bubeck. 2011. Multi-bandit\nbest arm identification. In Advances in Neural In-\nformation Processing Systems, volume 24. Curran\nAssociates, Inc.\nDeep Ganguli, Amanda Askell, Nicholas Schiefer,\nThomas Liao, Kamil˙e Lukoši¯ut˙e, Anna Chen, Anna\nGoldie, Azalia Mirhoseini, Catherine Olsson, Danny\nHernandez, et al. 2023. The capacity for moral self-\ncorrection in large language models. arXiv preprint\narXiv:2302.07459.\nAndrew Gao. 2023. Prompt engineering for large lan-\nguage models. SSRN.\nLingyu Gao, Aditi Chaudhary, Krishna Srinivasan,\nKazuma Hashimoto, Karthik Raman, and Michael\nBendersky. 2023a.\nAmbiguity-aware in-context\nlearning with large language models. arXiv preprint\narXiv:2309.07900.\nLuyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon,\nPengfei Liu, Yiming Yang, Jamie Callan, and Gra-\nham Neubig. 2023b.\nPal:\nprogram-aided lan-\nguage models. In Proceedings of the 40th Interna-\ntional Conference on Machine Learning, ICML’23.\nJMLR.org.\nMingqi Gao, Jie Ruan, Renliang Sun, Xunjian Yin, Ship-\ning Yang, and Xiaojun Wan. 2023c. Human-like sum-\nmarization evaluation with chatgpt. arXiv preprint\narXiv:2304.02554.\nTianyu Gao, Adam Fisch, and Danqi Chen. 2021.\nMaking pre-trained language models better few-shot\nlearners. In Proceedings of the 59th Annual Meet-\ning of the Association for Computational Linguistics\nand the 11th International Joint Conference on Natu-\nral Language Processing (Volume 1: Long Papers),\npages 3816–3830, Online. Association for Computa-\ntional Linguistics.\nMarisa Garcia. 2024. What air canada lost in ‘remark-\nable’ lying ai chatbot case. Forbes.\nXavier Garcia, Yamini Bansal, Colin Cherry, George\nFoster, Maxim Krikun, Melvin Johnson, and Orhan\nFirat. 2023. The unreasonable effectiveness of few-\nshot learning for machine translation. In Proceedings\nof the 40th International Conference on Machine\nLearning, ICML’23. JMLR.org.\nMF Garnett and SC Curtin. 2023. Suicide mortality\nin the united states, 2001–2021. NCHS Data Brief,\n464:1–8.\nTimnit Gebru,\nJamie Morgenstern,\nBriana Vec-\nchione, Jennifer Wortman Vaughan, Hanna Wal-\nlach, Hal Daumé III, and Kate Crawford. 2021.\nDatasheets for datasets.\nCommunications of the\nACM, 64(12):86–92.\nMarjan Ghazvininejad, Hila Gonen, and Luke Zettle-\nmoyer. 2023. Dictionary-based phrase-level prompt-\ning of large language models for machine translation.\nRohit Girdhar, Mannat Singh, Andrew Brown, Quentin\nDuval, Samaneh Azadi, Sai Saketh Rambhatla, Akbar\nShah, Xi Yin, Devi Parikh, and Ishan Misra. 2023.\nEmu video: Factorizing text-to-video generation by\nexplicit image conditioning.\nYichen Gong, Delong Ran, Jinyuan Liu, Conglei Wang,\nTianshuo Cong, Anyu Wang, Sisi Duan, and Xiaoyun\nWang. 2023.\nFigstep: Jailbreaking large vision-\nlanguage models via typographic visual prompts.\nRiley Goodside. 2022. Exploiting gpt-3 prompts with\nmalicious inputs that order the model to ignore its\nprevious directions.\nGoogle. 2023. Gemini: A family of highly capable\nmultimodal models.\nZhibin Gou, Zhihong Shao, Yeyun Gong, yelong shen,\nYujiu Yang, Nan Duan, and Weizhu Chen. 2024a.\nCRITIC: Large language models can self-correct\nwith tool-interactive critiquing. In The Twelfth Inter-\nnational Conference on Learning Representations.\nZhibin Gou, Zhihong Shao, Yeyun Gong, yelong shen,\nYujiu Yang, Minlie Huang, Nan Duan, and Weizhu\nChen. 2024b. ToRA: A tool-integrated reasoning\nagent for mathematical problem solving.\nIn The\nTwelfth International Conference on Learning Repre-\nsentations.\nChuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q Wein-\nberger. 2017. On calibration of modern neural net-\nworks. In International conference on machine learn-\ning, pages 1321–1330. PMLR.\nHan Guo, Bowen Tan, Zhengzhong Liu, Eric P. Xing,\nand Zhiting Hu. 2022. Efficient (soft) q-learning for\ntext generation with limited good data.\nPriyanka Gupta, Bosheng Ding, Chong Guan, and Ding\nDing. 2024.\nGenerative ai: A systematic review\nusing topic modelling techniques. Data and Informa-\ntion Management, page 100066.\nRishav Hada, Varun Gumma, Adrian Wynter, Harshita\nDiddee, Mohamed Ahmed, Monojit Choudhury, Ka-\nlika Bali, and Sunayana Sitaram. 2024. Are large\nlanguage model-based evaluators the solution to scal-\ning up multilingual evaluation? In Findings of the\nAssociation for Computational Linguistics: EACL\n2024, pages 1051–1070, St. Julian’s, Malta. Associa-\ntion for Computational Linguistics.\nMuhammad Usman Hadi, Qasem Al Tashi, Rizwan\nQureshi, Abbas Shah, Amgad Muneer, Muhammad\nIrfan, and et al. 2023. Large language models: A\ncomprehensive survey of its applications, challenges,\nlimitations, and future prospects. TechRxiv.\nAparna Dhinakaran Hakan Tekgul. 2023. Guardrails:\nWhat are they and how can you use nemo and\nguardrails ai to safeguard llms? Online.\n49\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 142
  },
  {
    "chunk_full": "Sherzod Hakimov and David Schlangen. 2023. Images\nin language space: Exploring the suitability of large\nlanguage models for vision & language tasks. In\nFindings of the Association for Computational Lin-\nguistics: ACL 2023, pages 14196–14210, Toronto,\nCanada. Association for Computational Linguistics.\nShibo Hao, Tianyang Liu, Zhen Wang, and Zhiting Hu.\n2023. ToolkenGPT: Augmenting Frozen Language\nModels with Massive Tools via Tool Embeddings. In\nNeurIPS.\nHangfeng He, Hongming Zhang, and Dan Roth. 2023a.\nSocreval:\nLarge language models with the so-\ncratic method for reference-free reasoning evaluation.\narXiv preprint arXiv:2310.00074.\nZhiwei He, Tian Liang, Wenxiang Jiao, Zhuosheng\nZhang, Yujiu Yang, Rui Wang, Zhaopeng Tu, Shum-\ning Shi, and Xing Wang. 2023b. Exploring human-\nlike translation strategy with large language models.\nDan Hendrycks, Collin Burns, Steven Basart, Andy Zou,\nMantas Mazeika, Dawn Song, and Jacob Steinhardt.\n2021. Measuring Massive Multitask Language Un-\nderstanding. In ICLR.\nAmr Hendy, Mohamed Gomaa Abdelrehim, Amr\nSharaf, Vikas Raunak, Mohamed Gabr, Hitokazu\nMatsushita, Young Jin Kim, Mohamed Afify, and\nHany Hassan Awadalla. 2023. How good are gpt\nmodels at machine translation? a comprehensive\nevaluation. ArXiv, abs/2302.09210.\nAmir Hertz, Ron Mokady, Jay Tenenbaum, Kfir Aber-\nman, Yael Pritch, and Daniel Cohen-Or. 2022.\nPrompt-to-prompt image editing with cross attention\ncontrol.\nT.F. Heston and C. Khun. 2023. Prompt engineering in\nmedical education. Int. Med. Educ., 2:198–205.\nTobias Hinz, Stefan Heinrich, and Stefan Wermter. 2022.\nSemantic object accuracy for generative text-to-\nimage synthesis. IEEE Transactions on Pattern Anal-\nysis and Machine Intelligence, 44(3):1552–1565.\nXinyi Hou, Yanjie Zhao, Yue Liu, Zhou Yang, Kailong\nWang, Li Li, Xiapu Luo, David Lo, John Grundy,\nand Haoyu Wang. 2023. Large language models for\nsoftware engineering: A systematic literature review.\nMing-Hao Hsu, Kai-Wei Chang, Shang-Wen Li, and\nHung yi Lee. 2023. An exploration of in-context\nlearning for speech language model.\nYining Hua, Fenglin Liu, Kailai Yang, Zehan Li, Yi han\nSheu, Peilin Zhou, Lauren V. Moran, Sophia Ana-\nniadou, and Andrew Beam. 2024. Large language\nmodels in mental health care: a scoping review.\nHaoyang Huang, Tianyi Tang, Dongdong Zhang,\nWayne Xin Zhao, Ting Song, Yan Xia, and Furu Wei.\n2023a. Not all languages are created equal in llms:\nImproving multilingual capability by cross-lingual-\nthought prompting.\nJiaxin Huang, Shixiang Shane Gu, Le Hou, Yuexin Wu,\nXuezhi Wang, Hongkun Yu, and Jiawei Han. 2022.\nLarge language models can self-improve.\narXiv\npreprint arXiv:2210.11610.\nLei Huang, Weijiang Yu, Weitao Ma, Weihong Zhong,\nZhangyin Feng, Haotian Wang, Qianglong Chen,\nWeihua Peng, Xiaocheng Feng, Bing Qin, and Ting\nLiu. 2023b. A survey on hallucination in large lan-\nguage models: Principles, taxonomy, challenges, and\nopen questions.\nShaohan Huang, Li Dong, Wenhui Wang, Yaru Hao,\nSaksham Singhal, Shuming Ma, Tengchao Lv, Lei\nCui, Owais Khan Mohammed, Barun Patra, Qiang\nLiu, Kriti Aggarwal, Zewen Chi, Johan Bjorck,\nVishrav Chaudhary, Subhojit Som, Xia Song, and\nFuru Wei. 2023c.\nLanguage is not all you need:\nAligning perception with language models.\nHakan Inan, Kartikeya Upasani, Jianfeng Chi, Rashi\nRungta,\nKrithika Iyer,\nYuning Mao,\nMichael\nTontchev, Qing Hu, Brian Fuller, Davide Testuggine,\nand Madian Khabsa. 2023. Llama guard: Llm-based\ninput-output safeguard for human-ai conversations.\nVivek Iyer, Pinzhen Chen, and Alexandra Birch. 2023.\nTowards effective disambiguation for machine trans-\nlation with large language models.\nAjay Jain, Ben Mildenhall, Jonathan T. Barron, Pieter\nAbbeel, and Ben Poole. 2022. Zero-shot text-guided\nobject generation with dream fields.\nQi Jia, Siyu Ren, Yizhu Liu, and Kenny Q Zhu. 2023.\nZero-shot faithfulness evaluation for text summariza-\ntion with foundation language model. arXiv preprint\narXiv:2310.11648.\nYixing Jiang, Jeremy Irvin, Ji Hun Wang, Muham-\nmad Ahmed Chaudhry, Jonathan H Chen, and An-\ndrew Y Ng. 2024. Many-shot in-context learning\nin multimodal foundation models. arXiv preprint\narXiv:2405.09798.\nZhengbao Jiang, Frank Xu, Luyu Gao, Zhiqing Sun,\nQian Liu, Jane Dwivedi-Yu, Yiming Yang, Jamie\nCallan, and Graham Neubig. 2023. Active retrieval\naugmented generation. In Proceedings of the 2023\nConference on Empirical Methods in Natural Lan-\nguage Processing, pages 7969–7992, Singapore. As-\nsociation for Computational Linguistics.\nZhengbao Jiang, Frank F. Xu, Jun Araki, and Graham\nNeubig. 2020. How can we know what language\nmodels know? Transactions of the Association for\nComputational Linguistics, 8:423–438.\nWenxiang Jiao, Wenxuan Wang, Jen tse Huang, Xing\nWang, Shuming Shi, and Zhaopeng Tu. 2023. Is chat-\ngpt a good translator? yes with gpt-4 as the engine.\nZiqi Jin and Wei Lu. 2023. Tab-cot: Zero-shot tabular\nchain of thought.\n50\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 143
  },
  {
    "chunk_full": "Saurav Kadavath, Tom Conerly, Amanda Askell, Tom\nHenighan, Dawn Drain, Ethan Perez, Nicholas\nSchiefer, Zac Hatfield-Dodds, Nova DasSarma, Eli\nTran-Johnson, Scott Johnston, Sheer El-Showk,\nAndy Jones, Nelson Elhage, Tristan Hume, Anna\nChen, Yuntao Bai, Sam Bowman, Stanislav Fort,\nDeep Ganguli, Danny Hernandez, Josh Jacobson,\nJackson Kernion, Shauna Kravec, Liane Lovitt, Ka-\nmal Ndousse, Catherine Olsson, Sam Ringer, Dario\nAmodei, Tom Brown, Jack Clark, Nicholas Joseph,\nBen Mann, Sam McCandlish, Chris Olah, and Jared\nKaplan. 2022. Language models (mostly) know what\nthey know.\nEhud Karpas, Omri Abend, Yonatan Belinkov, Barak\nLenz, Opher Lieber, Nir Ratner, Yoav Shoham, Hofit\nBata, Yoav Levine, Kevin Leyton-Brown, Dor Muhl-\ngay, Noam Rozen, Erez Schwartz, Gal Shachaf,\nShai Shalev-Shwartz, Amnon Shashua, and Moshe\nTenenholtz. 2022. Mrkl systems: A modular, neuro-\nsymbolic architecture that combines large language\nmodels, external knowledge sources and discrete rea-\nsoning.\nStaffs Keele et al. 2007. Guidelines for performing\nsystematic literature reviews in software engineering.\nNitish Shirish Keskar, Bryan McCann, Lav R. Varshney,\nCaiming Xiong, and Richard Socher. 2019. Ctrl: A\nconditional transformer language model for control-\nlable generation.\nKimiya Keyvan and Jimmy Xiangji Huang. 2022. How\nto approach ambiguous queries in conversational\nsearch: A survey of techniques, approaches, tools,\nand challenges. ACM Computing Surveys, 55(6):1–\n40.\nMuhammad Khalifa, Lajanugen Logeswaran, Moontae\nLee, Honglak Lee, and Lu Wang. 2023. Exploring\ndemonstration ensembling for in-context learning.\nMahmoud Khalil, Ahmad Khalil, and Alioune Ngom.\n2023. A comprehensive study of vision transformers\nin image classification tasks.\nOmar Khattab, Keshav Santhanam, Xiang Lisa Li,\nDavid Hall, Percy Liang, Christopher Potts, and\nMatei Zaharia. 2022. Demonstrate-search-predict:\nComposing retrieval and language models for\nknowledge-intensive nlp.\nOmar Khattab, Arnav Singhvi, Paridhi Maheshwari,\nZhiyuan Zhang, Keshav Santhanam, Sri Vard-\nhamanan, Saiful Haq, Ashutosh Sharma, Thomas T.\nJoshi, Hanna Moazam, Heather Miller, Matei Za-\nharia, and Christopher Potts. 2023. Dspy: Compiling\ndeclarative language model calls into self-improving\npipelines. arXiv preprint arXiv:2310.03714.\nTushar Khot, Harsh Trivedi, Matthew Finlayson, Yao Fu,\nKyle Richardson, Peter Clark, and Ashish Sabharwal.\n2022. Decomposed prompting: A modular approach\nfor solving complex tasks.\nNatalie Kiesler and Daniel Schiffner. 2023. Large lan-\nguage models in introductory programming educa-\ntion: Chatgpt’s performance and implications for\nassessments. arXiv preprint arXiv:2308.08572.\nHwichan Kim and Mamoru Komachi. 2023. Enhancing\nfew-shot cross-lingual transfer with target language\npeculiar examples. In Findings of the Association for\nComputational Linguistics: ACL 2023, pages 747–\n767, Toronto, Canada. Association for Computational\nLinguistics.\nHyuhng Joon Kim, Hyunsoo Cho, Junyeob Kim, Taeuk\nKim, Kang Min Yoo, and Sang goo Lee. 2022.\nSelf-generated in-context learning: Leveraging auto-\nregressive language models as a demonstration gen-\nerator.\nSunkyoung Kim, Dayeon Ki, Yireun Kim, and Jinsik\nLee. 2023. Boosting cross-lingual transferability in\nmultilingual models via in-context learning.\nDayoon Ko, Sangho Lee, and Gunhee Kim. 2023a. Can\nlanguage models laugh at youtube short-form videos?\nHyung-Kwon Ko, Gwanmo Park, Hyeon Jeon, Jaemin\nJo, Juho Kim, and Jinwook Seo. 2023b. Large-scale\ntext-to-image generation models for visual artists’\ncreative works. Proceedings of the 28th International\nConference on Intelligent User Interfaces.\nTom Kocmi and Christian Federmann. 2023a. Gemba-\nmqm: Detecting translation quality error spans with\ngpt-4. arXiv preprint arXiv:2310.13988.\nTom Kocmi and Christian Federmann. 2023b. Large\nlanguage models are state-of-the-art evaluators of\ntranslation quality. In Proceedings of the 24th An-\nnual Conference of the European Association for Ma-\nchine Translation, pages 193–203, Tampere, Finland.\nEuropean Association for Machine Translation.\nTakeshi Kojima, Shixiang Shane Gu, Machel Reid, Yu-\ntaka Matsuo, and Yusuke Iwasawa. 2022. Large lan-\nguage models are zero-shot reasoners.\nSawan Kumar and Partha Talukdar. 2021. Reordering\nexamples helps during priming-based few-shot learn-\ning.\nWill Kurt. 2024. Say what you mean: A response to\n’let me speak freely’. https://blog.dottxt.co/\nsay-what-you-mean.html.\nGihyun Kwon and Jong Chul Ye. 2022.\nClipstyler:\nImage style transfer with a single text condition.\nLakera. 2024. Lakera guard.\nBar Lanyado, Ortal Keizman, and Yair Divinsky. 2023.\nCan you trust chatgpt’s package recommendations?\nVulcan Cyber Blog.\nCindy Le, Congrui Hetang, Ang Cao, and Yihui He.\n2023. Euclidreamer: Fast and high-quality texturing\nfor 3d models with stable diffusion depth.\n51\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 144
  },
  {
    "chunk_full": "Soochan Lee and Gunhee Kim. 2023. Recursion of\nthought: A divide-and-conquer approach to multi-\ncontext reasoning with language models.\nAlina Leidinger, Robert van Rooij, and Ekaterina\nShutova. 2023. The language of prompting: What\nlinguistic properties make a prompt successful?\nBrian Lester, Rami Al-Rfou, and Noah Constant. 2021.\nThe power of scale for parameter-efficient prompt\ntuning. In Proceedings of the 2021 Conference on\nEmpirical Methods in Natural Language Processing.\nAssociation for Computational Linguistics.\nPatrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio\nPetroni, Vladimir Karpukhin, Naman Goyal, Hein-\nrich Küttler, Mike Lewis, Wen tau Yih, Tim Rock-\ntäschel, Sebastian Riedel, and Douwe Kiela. 2021.\nRetrieval-augmented generation for knowledge-\nintensive nlp tasks.\nBowen Li, Xiaojuan Qi, Thomas Lukasiewicz, and\nPhilip H. S. Torr. 2019a. Controllable text-to-image\ngeneration.\nCheng Li, Jindong Wang, Yixuan Zhang, Kaijie Zhu,\nWenxin Hou, Jianxun Lian, Fang Luo, Qiang Yang,\nand Xing Xie. 2023a. Large language models under-\nstand and can be enhanced by emotional stimuli.\nChengzhengxu Li, Xiaoming Liu, Yichen Wang, Duyi\nLi, Yu Lan, and Chao Shen. 2023b. Dialogue for\nprompting: a policy-gradient-based discrete prompt\noptimization for few-shot learning.\nJiahao Li, Hao Tan, Kai Zhang, Zexiang Xu, Fujun\nLuan, Yinghao Xu, Yicong Hong, Kalyan Sunkavalli,\nGreg Shakhnarovich, and Sai Bi. 2023c. Instant3d:\nFast text-to-3d with sparse-view generation and large\nreconstruction model.\nMing Li, Pan Zhou, Jia-Wei Liu, Jussi Keppo, Min Lin,\nShuicheng Yan, and Xiangyu Xu. 2023d. Instant3d:\nInstant text-to-3d generation.\nRuosen Li, Teerth Patel, and Xinya Du. 2023e.\nPrd: Peer rank and discussion improve large lan-\nguage model based evaluations.\narXiv preprint\narXiv:2307.02762.\nWenbo Li, Pengchuan Zhang, Lei Zhang, Qiuyuan\nHuang, Xiaodong He, Siwei Lyu, and Jianfeng Gao.\n2019b. Object-driven text-to-image synthesis via\nadversarial training.\nXiaonan Li, Kai Lv, Hang Yan, Tianyang Lin, Wei Zhu,\nYuan Ni, Guotong Xie, Xiaoling Wang, and Xipeng\nQiu. 2023f. Unified demonstration retriever for in-\ncontext learning.\nXiaonan Li and Xipeng Qiu. 2023a. Finding support\nexamples for in-context learning.\nXiaonan Li and Xipeng Qiu. 2023b. Mot: Memory-of-\nthought enables chatgpt to self-improve.\nXiaoqian Li, Ercong Nie, and Sheng Liang. 2023g.\nCrosslingual retrieval augmented in-context learning\nfor bangla.\nXiujun Li, Xi Yin, Chunyuan Li, Pengchuan Zhang,\nXiaowei Hu, Lei Zhang, Lijuan Wang, Houdong Hu,\nLi Dong, Furu Wei, Yejin Choi, and Jianfeng Gao.\n2020. Oscar: Object-semantics aligned pre-training\nfor vision-language tasks.\nYaoyiran Li, Anna Korhonen, and Ivan Vuli´c. 2023h.\nOn bilingual lexicon induction with large language\nmodels.\nYifei Li, Zeqi Lin, Shizhuo Zhang, Qiang Fu, Bei Chen,\nJian-Guang Lou, and Weizhu Chen. 2023i. Making\nlanguage models better reasoners with step-aware\nverifier. In Proceedings of the 61st Annual Meeting\nof the Association for Computational Linguistics (Vol-\nume 1: Long Papers). Association for Computational\nLinguistics.\nYingji Li, Mengnan Du, Rui Song, Xin Wang, and Ying\nWang. 2023j. A survey on fairness in large language\nmodels.\nJingyun Liang, Yuchen Fan, Kai Zhang, Radu Timofte,\nLuc Van Gool, and Rakesh Ranjan. 2023. Movideo:\nMotion-aware video generation with diffusion mod-\nels.\nChen-Hsuan Lin, Jun Gao, Luming Tang, Towaki\nTakikawa, Xiaohui Zeng, Xun Huang, Karsten Kreis,\nSanja Fidler, Ming-Yu Liu, and Tsung-Yi Lin. 2023.\nMagic3d: High-resolution text-to-3d content cre-\nation.\nXi Victoria Lin, Todor Mihaylov, Mikel Artetxe, Tianlu\nWang, Shuohui Chen, Daniel Simig, Myle Ott, Na-\nman Goyal, Shruti Bhosale, Jingfei Du, Ramakanth\nPasunuru, Sam Shleifer, Punit Singh Koura, Vishrav\nChaudhary, Brian O’Horo, Jeff Wang, Luke Zettle-\nmoyer, Zornitsa Kozareva, Mona Diab, Veselin Stoy-\nanov, and Xian Li. 2022. Few-shot learning with\nmultilingual generative language models. In Proceed-\nings of the 2022 Conference on Empirical Methods\nin Natural Language Processing, pages 9019–9052,\nAbu Dhabi, United Arab Emirates. Association for\nComputational Linguistics.\nYen-Ting Lin and Yun-Nung Chen. 2023. Llm-eval:\nUnified multi-dimensional automatic evaluation for\nopen-domain conversations with large language mod-\nels. arXiv preprint arXiv:2305.13711.\nJerry Liu. 2022. LlamaIndex.\nJiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan,\nLawrence Carin, and Weizhu Chen. 2021.\nWhat\nmakes good in-context examples for GPT-3?\nIn\nWorkshop on Knowledge Extraction and Integration\nfor Deep Learning Architectures; Deep Learning In-\nside Out.\n52\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 145
  },
  {
    "chunk_full": "Nelson F Liu, Tianyi Zhang, and Percy Liang. 2023a.\nEvaluating verifiability in generative search engines.\nIn Proceedings of the 2023 Conference on Empirical\nMethods in Natural Language Processing.\nPengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang,\nHiroaki Hayashi, and Graham Neubig. 2023b. Pre-\ntrain, prompt, and predict: A systematic survey of\nprompting methods in natural language processing.\nACM Computing Surveys, 55(9):1–35.\nWeihuang Liu, Xi Shen, Chi-Man Pun, and Xiaodong\nCun. 2023c. Explicit visual prompting for low-level\nstructure segmentations. In 2023 IEEE/CVF Confer-\nence on Computer Vision and Pattern Recognition\n(CVPR). IEEE.\nYang Liu, Dan Iter, Yichong Xu, Shuohang Wang,\nRuochen Xu, and Chenguang Zhu. 2023d. Gpte-\nval: Nlg evaluation using gpt-4 with better human\nalignment. arXiv preprint arXiv:2303.16634.\nYihao Liu, Xiangyu Chen, Xianzheng Ma, Xintao Wang,\nJiantao Zhou, Yu Qiao, and Chao Dong. 2023e. Uni-\nfying image processing as visual prompting question\nanswering.\nYongkang Liu, Shi Feng, Daling Wang, Yifei Zhang,\nand Hinrich Schütze. 2023f. Evaluate what you can’t\nevaluate: Unassessable generated responses quality.\narXiv preprint arXiv:2305.14658.\nYuxin Liu, Minshan Xie, Hanyuan Liu, and Tien-Tsin\nWong. 2023g. Text-guided texturing by synchronized\nmulti-view diffusion.\nYuxuan Liu, Tianchi Yang, Shaohan Huang, Zihan\nZhang, Haizhen Huang, Furu Wei, Weiwei Deng,\nFeng Sun, and Qi Zhang. 2023h. Calibrating llm-\nbased evaluator. arXiv preprint arXiv:2309.13308.\nJieyi Long. 2023. Large language model guided tree-of-\nthought.\nJonathan Lorraine, Kevin Xie, Xiaohui Zeng, Chen-\nHsuan Lin, Towaki Takikawa, Nicholas Sharp, Tsung-\nYi Lin, Ming-Yu Liu, Sanja Fidler, and James Lucas.\n2023. Att3d: Amortized text-to-3d object synthesis.\nAlbert Lu, Hongxin Zhang, Yanzhe Zhang, Xuezhi\nWang, and Diyi Yang. 2023a. Bounding the capabili-\nties of large language models in open text generation\nwith prompt constraints.\nHongyuan Lu, Haoyang Huang, Dongdong Zhang, Hao-\nran Yang, Wai Lam, and Furu Wei. 2023b. Chain-\nof-dictionary prompting elicits translation in large\nlanguage models.\nQingyu Lu, Baopu Qiu, Liang Ding, Liping Xie, and\nDacheng Tao. 2023c. Error analysis prompting en-\nables human-like translation evaluation in large lan-\nguage models: A case study on chatgpt.\narXiv\npreprint arXiv:2303.13809.\nYao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel,\nand Pontus Stenetorp. 2021. Fantastically ordered\nprompts and where to find them: Overcoming few-\nshot prompt order sensitivity.\nYao Lu, Jiayi Wang, Raphael Tang, Sebastian Riedel,\nand Pontus Stenetorp. 2024. Strings from the library\nof babel: Random sampling as a strong baseline for\nprompt optimisation.\nCharles Duffy Luca Beurer-Kellner, Marc Fischer. 2023.\nlmql. GitHub repository.\nZheheng Luo, Qianqian Xie, and Sophia Ananiadou.\n2023. Chatgpt as a factual inconsistency evaluator\nfor abstractive text summarization. arXiv preprint\narXiv:2303.15621.\nJiaxi Lv, Yi Huang, Mingfu Yan, Jiancheng Huang,\nJianzhuang Liu, Yifan Liu, Yafei Wen, Xiaoxin\nChen, and Shifeng Chen. 2023. Gpt4motion: Script-\ning physical motions in text-to-video generation via\nblender-oriented gpt planning.\nQing Lyu, Shreya Havaldar, Adam Stein, Li Zhang,\nDelip Rao, Eric Wong, Marianna Apidianaki, and\nChris Callison-Burch. 2023.\nFaithful chain-of-\nthought reasoning.\nHuan Ma, Changqing Zhang, Yatao Bian, Lemao Liu,\nZhirui Zhang, Peilin Zhao, Shu Zhang, Huazhu Fu,\nQinghua Hu, and Bingzhe Wu. 2023.\nFairness-\nguided few-shot prompting for large language mod-\nels. arXiv preprint arXiv:2303.13217.\nAman Madaan, Niket Tandon, Prakhar Gupta, Skyler\nHallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon,\nNouha Dziri, Shrimai Prabhumoye, Yiming Yang,\nShashank Gupta, Bodhisattwa Prasad Majumder,\nKatherine Hermann, Sean Welleck, Amir Yazdan-\nbakhsh, and Peter Clark. 2023. Self-refine: Iterative\nrefinement with self-feedback.\nNinareh Mehrabi, Fred Morstatter, Nripsuta Saxena,\nKristina Lerman, and Aram Galstyan. 2021. A sur-\nvey on bias and fairness in machine learning. ACM\ncomputing surveys (CSUR), 54(6):1–35.\nLaura Melzer, Thomas Forkmann, and Tobias Teismann.\n2024. Suicide crisis syndrome: A systematic review.\nSuicide and Life-Threatening Behavior. February 27,\nonline ahead of print.\nFanxu Meng, Haotong Yang, Yiding Wang, and Muhan\nZhang. 2023. Chain of images for intuitively reason-\ning.\nB. Meskó. 2023.\nPrompt engineering as an impor-\ntant emerging skill for medical professionals: Tuto-\nrial. Journal of Medical Internet Research, 25(Suppl\n1):e50638.\nYachun Mi, Yu Li, Yan Shu, Chen Hui, Puchao Zhou,\nand Shaohui Liu. 2023. Clif-vqa: Enhancing video\nquality assessment by incorporating high-level se-\nmantic information related to human feelings.\n53\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 146
  },
  {
    "chunk_full": "Grégoire Mialon, Roberto Dessì, Maria Lomeli, Christo-\nforos Nalmpantis, Ram Pasunuru, Roberta Raileanu,\nBaptiste Rozière, Timo Schick, Jane Dwivedi-Yu,\nAsli Celikyilmaz, Edouard Grave, Yann LeCun, and\nThomas Scialom. 2023. Augmented language mod-\nels: a survey.\nSewon Min, Xinxi Lyu, Ari Holtzman, Mikel Artetxe,\nMike Lewis, Hannaneh Hajishirzi, and Luke Zettle-\nmoyer. 2022. Rethinking the role of demonstrations:\nWhat makes in-context learning work?\nSewon Min, Julian Michael, Hannaneh Hajishirzi, and\nLuke Zettlemoyer. 2020.\nAmbigqa: Answering\nambiguous open-domain questions. arXiv preprint\narXiv:2004.10645.\nR.A. Morelli, J.D. Bronzino, and J.W. Goethe. 1991. A\ncomputational speech-act model of human-computer\nconversations.\nIn Proceedings of the 1991 IEEE\nSeventeenth Annual Northeast Bioengineering Con-\nference, pages 263–264.\nYasmin Moslem, Rejwanul Haque, John D. Kelleher,\nand Andy Way. 2023. Adaptive machine translation\nwith large language models. In Proceedings of the\n24th Annual Conference of the European Association\nfor Machine Translation, pages 227–237, Tampere,\nFinland. European Association for Machine Transla-\ntion.\nFangwen Mu, Lin Shi, Song Wang, Zhuohao Yu, Bin-\nquan Zhang, Chenxue Wang, Shichao Liu, and Qing\nWang. 2023.\nClarifygpt: Empowering llm-based\ncode generation with intention clarification.\nNiklas Muennighoff, Thomas Wang, Lintang Sutawika,\nAdam Roberts, Stella Biderman, Teven Le Scao,\nM Saiful Bari, Sheng Shen, Zheng Xin Yong, Hai-\nley Schoelkopf, Xiangru Tang, Dragomir Radev,\nAlham Fikri Aji, Khalid Almubarak, Samuel Al-\nbanie, Zaid Alyafeai, Albert Webson, Edward Raff,\nand Colin Raffel. 2023.\nCrosslingual generaliza-\ntion through multitask finetuning. In Proceedings\nof the 61st Annual Meeting of the Association for\nComputational Linguistics (Volume 1: Long Papers),\npages 15991–16111, Toronto, Canada. Association\nfor Computational Linguistics.\nAkshay Nambi, Vaibhav Balloli, Mercy Ranjit, Tanuja\nGanu, Kabir Ahuja, Sunayana Sitaram, and Kalika\nBali. 2023. Breaking language barriers with a leap:\nLearning strategies for polyglot llms.\nMilad Nasr,\nNicholas Carlini,\nJonathan Hayase,\nMatthew Jagielski, A. Feder Cooper, Daphne Ip-\npolito, Christopher A. Choquette-Choo, Eric Wal-\nlace, Florian Tramèr, and Katherine Lee. 2023. Scal-\nable extraction of training data from (production)\nlanguage models.\nNational Center for Health Workforce Analysis. 2023.\nBehavioral health workforce, 2023.\nAlexandra Neagu. 2023. How can large language mod-\nels and prompt engineering be leveraged in Com-\nputer Science education?: Systematic literature re-\nview. Master’s thesis, Delft University of Technol-\nogy, 6.\nErcong Nie, Sheng Liang, Helmut Schmid, and Hinrich\nSchütze. 2023. Cross-lingual retrieval augmented\nprompt for low-resource languages. In Findings of\nthe Association for Computational Linguistics: ACL\n2023, pages 8320–8340, Toronto, Canada. Associa-\ntion for Computational Linguistics.\nXuefei Ning, Zinan Lin, Zixuan Zhou, Zifu Wang,\nHuazhong Yang, and Yu Wang. 2023. Skeleton-of-\nthought: Large language models can do parallel de-\ncoding.\nOpenAI. 2023. OpenAI Assistants.\nJonas Oppenlaender. 2023.\nA taxonomy of prompt\nmodifiers for text-to-image generation.\nAnton Osika. 2023. gpt-engineer.\nMatthew J Page, Joanne E McKenzie, Patrick M\nBossuyt, Isabelle Boutron, Tammy C Hoffmann,\nCynthia D Mulrow, Larissa Shamseer, Jennifer M\nTetzlaff, Elie A Akl, Sue E Brennan, Roger Chou,\nJulie Glanville, Jeremy M Grimshaw, Asbjørn Hrób-\njartsson, Manoj M Lalu, Tianjing Li, Elizabeth W\nLoder, Evan Mayo-Wilson, Steve McDonald, Luke A\nMcGuinness, Lesley A Stewart, James Thomas, An-\ndrea C Tricco, Vivian A Welch, Penny Whiting, and\nDavid Moher. 2021. The prisma 2020 statement: an\nupdated guideline for reporting systematic reviews.\nBMJ, 372.\nEhsan Pajouheshgar, Yitao Xu, Alexander Mordvint-\nsev, Eyvind Niklasson, Tong Zhang, and Sabine\nSüsstrunk. 2023. Mesh neural cellular automata.\nPruthvi Patel, Swaroop Mishra, Mihir Parmar, and\nChitta Baral. 2022. Is a question decomposition unit\nall we need?\nShishir G. Patil, Tianjun Zhang, Xin Wang, and\nJoseph E. Gonzalez. 2023.\nGorilla: Large lan-\nguage model connected with massive apis. ArXiv,\nabs/2305.15334.\nHammond Pearce, Baleegh Ahmad, Benjamin Tan,\nBrendan Dolan-Gavitt, and Ramesh Karri. 2021.\nAsleep at the keyboard? assessing the security of\ngithub copilot’s code contributions.\nHammond Pearce, Benjamin Tan, Baleegh Ahmad,\nRamesh Karri, and Brendan Dolan-Gavitt. 2022. Ex-\namining zero-shot vulnerability repair with large lan-\nguage models.\nPuyuan Peng, Brian Yan, Shinji Watanabe, and David\nHarwath. 2023. Prompting the hidden talent of web-\nscale speech models for zero-shot task generalization.\n54\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 147
  },
  {
    "chunk_full": "Ethan Perez, Saffron Huang, Francis Song, Trevor Cai,\nRoman Ring, John Aslanides, Amelia Glaese, Nat\nMcAleese, and Geoffrey Irving. 2022. Red teaming\nlanguage models with language models.\nFábio Perez and Ian Ribeiro. 2022. Ignore previous\nprompt: Attack techniques for language models.\nNeil Perry, Megha Srivastava, Deepak Kumar, and Dan\nBoneh. 2022. Do users write more insecure code\nwith ai assistants?\nDenis Peskoff and Brandon M Stewart. 2023. Credi-\nble without credit: Domain experts assess generative\nlanguage models. In Proceedings of the 61st Annual\nMeeting of the Association for Computational Lin-\nguistics (Volume 2: Short Papers), pages 427–438.\nDenis Peskoff, Adam Visokay, Sander Schulhoff, Ben-\njamin Wachspress, Alan Blinder, and Brandon M\nStewart. 2023. Gpt deciphering fedspeak: Quantify-\ning dissent among hawks and doves. In Findings\nof the Association for Computational Linguistics:\nEMNLP 2023, pages 6529–6539.\nDenis Peskov, Viktor Hangya, Jordan Boyd-Graber, and\nAlexander Fraser. 2021. Adapting entities across\nlanguages and cultures. Findings of the Association\nfor Computational Linguistics: EMNLP 2021.\nFabio Petroni, Tim Rocktäschel, Sebastian Riedel,\nPatrick Lewis, Anton Bakhtin, Yuxiang Wu, and\nAlexander Miller. 2019. Language models as knowl-\nedge bases? Proceedings of the 2019 Conference\non Empirical Methods in Natural Language Process-\ning and the 9th International Joint Conference on\nNatural Language Processing (EMNLP-IJCNLP).\nPouya Pezeshkpour and Estevam Hruschka. 2023.\nLarge language models sensitivity to the order of\noptions in multiple-choice questions. arXiv preprint\narXiv:2308.11483.\nCarol W. Pfaff. 1979. Constraints on language mix-\ning: Intrasentential code-switching and borrowing in\nspanish/english. Language, pages 291–318.\nJonathan Pilault, Xavier Garcia, Arthur Bražinskas, and\nOrhan Firat. 2023. Interactive-chain-prompting: Am-\nbiguity resolution for crosslingual conditional gener-\nation with interaction.\nBen Poole, Ajay Jain, Jonathan T. Barron, and Ben\nMildenhall. 2022. Dreamfusion: Text-to-3d using 2d\ndiffusion.\nShana Poplack. 1980. Sometimes i’ll start a sentence in\nspanish y termino en español: Toward a typology of\ncode-switching. Linguistics, 18(7-8):581–618.\nArchiki Prasad, Peter Hase, Xiang Zhou, and Mohit\nBansal. 2023. GrIPS: Gradient-free, edit-based in-\nstruction search for prompting large language models.\nIn Proceedings of the 17th Conference of the Euro-\npean Chapter of the Association for Computational\nLinguistics, pages 3845–3864, Dubrovnik, Croatia.\nAssociation for Computational Linguistics.\nPreamble. 2024. Our product.\nOfir Press, Muru Zhang, Sewon Min, Ludwig Schmidt,\nNoah A. Smith, and Mike Lewis. 2022. Measuring\nand narrowing the compositionality gap in language\nmodels.\nReid Pryzant, Dan Iter, Jerry Li, Yin Tat Lee, Chen-\nguang Zhu, and Michael Zeng. 2023. Automatic\nprompt optimization with \"gradient descent\" and\nbeam search.\nRatish Puduppully, Anoop Kunchukuttan, Raj Dabre,\nAi Ti Aw, and Nancy F. Chen. 2023. Decomposed\nprompting for machine translation between related\nlanguages using large language models.\nBo Qiao, Liqun Li, Xu Zhang, Shilin He, Yu Kang,\nChaoyun Zhang, Fangkai Yang, Hang Dong, Jue\nZhang, Lu Wang, Ming-Jie Ma, Pu Zhao, Si Qin, Xi-\naoting Qin, Chao Du, Yong Xu, Qingwei Lin, S. Raj-\nmohan, and Dongmei Zhang. 2023. Taskweaver: A\ncode-first agent framework. ArXiv, abs/2311.17541.\nShuofei Qiao, Yixin Ou, Ningyu Zhang, Xiang Chen,\nYunzhi Yao, Shumin Deng, Chuanqi Tan, Fei Huang,\nand Huajun Chen. 2022. Reasoning with language\nmodel prompting: A survey.\nLibo Qin, Qiguang Chen, Fuxuan Wei, Shijue Huang,\nand Wanxiang Che. 2023a. Cross-lingual prompt-\ning: Improving zero-shot chain-of-thought reasoning\nacross languages.\nYujia Qin, Shengding Hu, Yankai Lin, Weize Chen,\nNing Ding, Ganqu Cui, Zheni Zeng, Yufei Huang,\nChaojun Xiao, Chi Han, Yi Ren Fung, Yusheng Su,\nHuadong Wang, Cheng Qian, Runchu Tian, Kunlun\nZhu, Shi Liang, Xingyu Shen, Bokai Xu, Zhen Zhang,\nYining Ye, Bo Li, Ziwei Tang, Jing Yi, Yu Zhu, Zhen-\nning Dai, Lan Yan, Xin Cong, Ya-Ting Lu, Weilin\nZhao, Yuxiang Huang, Jun-Han Yan, Xu Han, Xian\nSun, Dahai Li, Jason Phang, Cheng Yang, Tong-\nshuang Wu, Heng Ji, Zhiyuan Liu, and Maosong\nSun. 2023b. Tool learning with foundation models.\nArXiv, abs/2304.08354.\nAlec Radford, Jong Wook Kim, Chris Hallacy, Aditya\nRamesh, Gabriel Goh, Sandhini Agarwal, Girish Sas-\ntry, Amanda Askell, Pamela Mishkin, Jack Clark,\net al. 2021. Learning transferable visual models from\nnatural language supervision. In International confer-\nence on machine learning, pages 8748–8763. PMLR.\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan,\nDario Amodei, Ilya Sutskever, et al. 2019a. Lan-\nguage models are unsupervised multitask learners.\nOpenAI blog, 1(8):9.\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan,\nDario Amodei, Ilya Sutskever, et al. 2019b. Lan-\nguage models are unsupervised multitask learners.\nOpenAI blog, 1(8):9.\nSudha Rao and Hal Daumé III. 2019. Answer-based\nadversarial training for generating clarification ques-\ntions. arXiv preprint arXiv:1904.02281.\n55\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 148
  },
  {
    "chunk_full": "Traian Rebedea, Razvan Dinu, Makesh Sreedhar,\nChristopher Parisien, and Jonathan Cohen. 2023.\nNemo guardrails: A toolkit for controllable and safe\nllm applications with programmable rails. arXiv.\nPhilip Resnik, April Foreman, Michelle Kuchuk, Kather-\nine Musacchio Schafer, and Beau Pinkham. 2021.\nNaturally occurring language as a source of evidence\nin suicide prevention. Suicide and Life-Threatening\nBehavior, 51(1):88–96.\nLaria Reynolds and Kyle McDonell. 2021. Prompt pro-\ngramming for large language models: Beyond the\nfew-shot paradigm. In Extended Abstracts of the\n2021 CHI Conference on Human Factors in Comput-\ning Systems, CHI ’21. ACM.\nMegan L Rogers, Carol Chu, and Thomas Joiner. 2019.\nThe necessity, validity, and clinical utility of a new di-\nagnostic entity: Acute suicidal affective disturbance\n(asad). Journal of Clinical Psychology, 75(6):999.\nRobin Rombach, Andreas Blattmann, Dominik Lorenz,\nPatrick Esser, and Björn Ommer. 2022.\nHigh-\nresolution image synthesis with latent diffusion mod-\nels.\nShamik Roy, Raphael Shu, Nikolaos Pappas, Elman\nMansimov, Yi Zhang, Saab Mansour, and Dan Roth.\n2023. Conversation style transfer using few-shot\nlearning. In Proceedings of the 13th International\nJoint Conference on Natural Language Processing\nand the 3rd Conference of the Asia-Pacific Chapter of\nthe Association for Computational Linguistics (Vol-\nume 1: Long Papers), pages 119–143, Nusa Dua,\nBali. Association for Computational Linguistics.\nOhad Rubin, Jonathan Herzig, and Jonathan Berant.\n2022. Learning to retrieve prompts for in-context\nlearning. In Proceedings of the 2022 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies. Association for Computational Linguistics.\nRunway. 2023.\nGen-2 prompt tips.\nhttps:\n//help.runwayml.com/hc/en-us/articles/\n17329337959699-Gen-2-Prompt-Tips.\nPranab Sahoo, Ayush Kumar Singh, Sriparna Saha,\nVinija Jain, Samrat Mondal, and Aman Chadha. 2024.\nA systematic survey of prompt engineering in large\nlanguage models: Techniques and applications.\nGustavo Sandoval, Hammond Pearce, Teo Nys, Ramesh\nKarri, Siddharth Garg, and Brendan Dolan-Gavitt.\n2022. Lost at c: A user study on the security implica-\ntions of large language model code assistants.\nShubhra Kanti Karmaker Santu and Dongji Feng. 2023.\nTeler: A general taxonomy of llm prompts for bench-\nmarking complex tasks.\nTimo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta\nRaileanu, Maria Lomeli, Luke Zettlemoyer, Nicola\nCancedda, and Thomas Scialom. 2023. Toolformer:\nLanguage models can teach themselves to use tools.\nTimo Schick and Hinrich Schütze. 2020a. Exploiting\ncloze-questions for few-shot text classification and\nnatural language inference. In Conference of the Eu-\nropean Chapter of the Association for Computational\nLinguistics.\nTimo Schick and Hinrich Schütze. 2020b. It’s not just\nsize that matters: Small language models are also\nfew-shot learners. ArXiv, abs/2009.07118.\nTimo Schick and Hinrich Schütze. 2021. Exploiting\ncloze-questions for few-shot text classification and\nnatural language inference. In Proceedings of the\n16th Conference of the European Chapter of the Asso-\nciation for Computational Linguistics: Main Volume.\nAssociation for Computational Linguistics.\nDouglas C. Schmidt, Jesse Spencer-Smith, Quchen Fu,\nand Jules White. 2023. Cataloging prompt patterns to\nenhance the discipline of prompt engineering. Dept.\nof Computer Science, Vanderbilt University. Email:\ndouglas.c.schmidt, jesse.spencer-smith, quchen.fu,\njules.white@vanderbilt.edu.\nAllison Schuck, Raffaella Calati, Shira Barzilay, Sarah\nBloch-Elkouby, and Igor I. Galynker. 2019a. Suicide\ncrisis syndrome: A review of supporting evidence\nfor a new suicide-specific diagnosis. Behavioral sci-\nences & the law, 37 3:223–239.\nAllison Schuck, Raffaella Calati, Shira Barzilay, Sarah\nBloch-Elkouby, and Igor Galynker. 2019b. Suicide\ncrisis syndrome: A review of supporting evidence\nfor a new suicide-specific diagnosis. Behavioral sci-\nences and the law, 37(3):223–239.\nSander Schulhoff. 2022. Learn Prompting.\nSander Schulhoff, Jeremy Pinto, Anaum Khan, Louis-\nFrançois Bouchard, Chenglei Si, Svetlina Anati,\nValen Tagliabue, Anson Kost, Christopher Carnahan,\nand Jordan Boyd-Graber. 2023. Ignore this title and\nHackAPrompt: Exposing systemic vulnerabilities\nof LLMs through a global prompt hacking compe-\ntition. In Proceedings of the 2023 Conference on\nEmpirical Methods in Natural Language Processing,\npages 4945–4977, Singapore. Association for Com-\nputational Linguistics.\nSander V Schulhoff. 2024. Prompt injection vs jail-\nbreaking: What is the difference?\nMelanie Sclar, Yejin Choi, Yulia Tsvetkov, and Alane\nSuhr. 2023a. Quantifying language models’ sensi-\ntivity to spurious features in prompt design or: How\ni learned to start worrying about prompt formatting.\narXiv preprint arXiv:2310.11324.\nMelanie Sclar, Yejin Choi, Yulia Tsvetkov, and Alane\nSuhr. 2023b. Quantifying language models’ sensitiv-\nity to spurious features in prompt design or: How i\nlearned to start worrying about prompt formatting.\nHarsha-Nori Scott Lundberg,\nMarco Tulio Cor-\nreia Ribeiro. 2023. guidance. GitHub repository.\n56\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 149
  },
  {
    "chunk_full": "John R. Searle. 1969. Speech Acts: An Essay in the Phi-\nlosophy of Language. Cambridge University Press.\nOmar Shaikh, Hongxin Zhang, William Held, Michael\nBernstein, and Diyi Yang. 2023. On second thought,\nlet’s not think step by step! bias and toxicity in zero-\nshot reasoning.\nMrinank Sharma, Meg Tong, Tomasz Korbak, David\nDuvenaud, Amanda Askell, Samuel R Bowman,\nNewton Cheng, Esin Durmus, Zac Hatfield-Dodds,\nScott R Johnston, et al. 2023. Towards understand-\ning sycophancy in language models. arXiv preprint\narXiv:2310.13548.\nYongliang Shen, Kaitao Song, Xu Tan, Dong Sheng Li,\nWeiming Lu, and Yue Ting Zhuang. 2023. Hugging-\ngpt: Solving ai tasks with chatgpt and its friends in\nhugging face. ArXiv, abs/2303.17580.\nFreda Shi, Mirac Suzgun, Markus Freitag, Xuezhi Wang,\nSuraj Srivats, Soroush Vosoughi, Hyung Won Chung,\nYi Tay, Sebastian Ruder, Denny Zhou, Dipanjan Das,\nand Jason Wei. 2022. Language models are multilin-\ngual chain-of-thought reasoners.\nTaylor Shin, Yasaman Razeghi, Robert L Logan IV,\nEric Wallace, and Sameer Singh. 2020a. Eliciting\nknowledge from language models using automati-\ncally generated prompts. ArXiv, abs/2010.15980.\nTaylor Shin, Yasaman Razeghi, Robert L. Logan IV, Eric\nWallace, and Sameer Singh. 2020b. Autoprompt:\nEliciting knowledge from language models with au-\ntomatically generated prompts. Proceedings of the\n2020 Conference on Empirical Methods in Natural\nLanguage Processing (EMNLP).\nHan-Chin Shing, Suraj Nair, Ayah Zirikly, Meir Frieden-\nberg, Hal Daumé III, and Philip Resnik. 2018. Expert,\ncrowdsourced, and machine assessment of suicide\nrisk via online postings. In Proceedings of the Fifth\nWorkshop on Computational Linguistics and Clinical\nPsychology: From Keyboard to Clinic, pages 25–36,\nNew Orleans, LA. Association for Computational\nLinguistics.\nNoah Shinn, Federico Cassano, Edward Berman, Ash-\nwin Gopinath, Karthik Narasimhan, and Shunyu Yao.\n2023. Reflexion: Language agents with verbal rein-\nforcement learning.\nChenglei Si, Dan Friedman, Nitish Joshi, Shi Feng,\nDanqi Chen, and He He. 2023a. Measuring induc-\ntive biases of in-context learning with underspecified\ndemonstrations. In Association for Computational\nLinguistics (ACL).\nChenglei Si, Zhe Gan, Zhengyuan Yang, Shuohang\nWang, Jianfeng Wang, Jordan Boyd-Graber, and Li-\njuan Wang. 2023b. Prompting gpt-3 to be reliable.\nIn International Conference on Learning Representa-\ntions (ICLR).\nChenglei Si, Navita Goyal, Sherry Tongshuang Wu,\nChen Zhao, Shi Feng, Hal Daumé III, and Jordan\nBoyd-Graber. 2023c. Large language models help\nhumans verify truthfulness–except when they are con-\nvincingly wrong. arXiv preprint arXiv:2310.12558.\nChenglei Si, Weijia Shi, Chen Zhao, Luke Zettlemoyer,\nand Jordan Lee Boyd-Graber. 2023d. Getting MoRE\nout of Mixture of language model Reasoning Experts.\nFindings of Empirical Methods in Natural Language\nProcessing.\nSuzanna Sia and Kevin Duh. 2023. In-context learn-\ning as maintaining coherency: A study of on-the-fly\nmachine translation using large language models.\nSignificant Gravitas. 2023. AutoGPT.\nUriel Singer, Shelly Sheynin, Adam Polyak, Oron\nAshual, Iurii Makarov, Filippos Kokkinos, Naman\nGoyal, Andrea Vedaldi, Devi Parikh, Justin Johnson,\nand Yaniv Taigman. 2023. Text-to-4d dynamic scene\ngeneration.\nTaylor Sorensen, Joshua Robinson, Christopher Ryt-\nting, Alexander Shaw, Kyle Rogers, Alexia Delorey,\nMahmoud Khalil, Nancy Fulda, and David Wingate.\n2022. An information-theoretic approach to prompt\nengineering without ground truth labels. In Proceed-\nings of the 60th Annual Meeting of the Association\nfor Computational Linguistics (Volume 1: Long Pa-\npers), pages 819–862, Dublin, Ireland. Association\nfor Computational Linguistics.\nAndrea Sottana, Bin Liang, Kai Zou, and Zheng Yuan.\n2023. Evaluation metrics in the era of gpt-4: Reli-\nably evaluating large language models on sequence\nto sequence tasks. arXiv preprint arXiv:2310.13800.\nMichal Štefánik and Marek Kadlˇcík. 2023. Can in-\ncontext learners learn a reasoning concept from\ndemonstrations?\nIn Proceedings of the 1st Work-\nshop on Natural Language Reasoning and Structured\nExplanations (NLRSE), pages 107–115, Toronto,\nCanada. Association for Computational Linguistics.\nHongjin Su, Jungo Kasai, Chen Henry Wu, Weijia Shi,\nTianlu Wang, Jiayi Xin, Rui Zhang, Mari Ostendorf,\nLuke Zettlemoyer, Noah A. Smith, and Tao Yu. 2022.\nSelective annotation makes language models better\nfew-shot learners.\nZhi Rui Tam, Cheng-Kuang Wu, Yi-Lin Tsai, Chieh-\nYen Lin, Hung yi Lee, and Yun-Nung Chen. 2024.\nLet me speak freely? a study on the impact of format\nrestrictions on performance of large language models.\nLv Tang, Peng-Tao Jiang, Hao-Ke Xiao, and Bo Li.\n2023. Towards training-free open-world segmenta-\ntion via image prompting foundation models.\nEshaan Tanwar, Subhabrata Dutta, Manish Borthakur,\nand Tanmoy Chakraborty. 2023. Multilingual LLMs\nare better cross-lingual in-context learners with align-\nment. In Proceedings of the 61st Annual Meeting of\n57\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 150
  },
  {
    "chunk_full": "the Association for Computational Linguistics (Vol-\nume 1: Long Papers), pages 6292–6307, Toronto,\nCanada. Association for Computational Linguistics.\nMing Tao, Hao Tang, Fei Wu, Xiao-Yuan Jing, Bing-\nKun Bao, and Changsheng Xu. 2022. Df-gan: A\nsimple and effective baseline for text-to-image syn-\nthesis.\nCharlotte Thompson and Tiana Kelly. 2023.\nWhen\nhallucinations become reality: An exploration of ai\npackage hallucination attacks. Darktrace Blog.\nKatherine Tian, Eric Mitchell, Allan Zhou, Archit\nSharma, Rafael Rafailov, Huaxiu Yao, Chelsea Finn,\nand Christopher Manning. 2023. Just ask for cali-\nbration: Strategies for eliciting calibrated confidence\nscores from language models fine-tuned with human\nfeedback. In Proceedings of the 2023 Conference\non Empirical Methods in Natural Language Process-\ning, pages 5433–5442, Singapore. Association for\nComputational Linguistics.\nLindia Tjuatja, Valerie Chen, Tongshuang Wu, Ameet\nTalwalkwar, and Graham Neubig. 2024. Do llms\nexhibit human-like response biases? a case study in\nsurvey design. Transactions of the Association for\nComputational Linguistics, 12:1011–1026.\nHugo Touvron, Louis Martin, Kevin Stone, Peter Al-\nbert, Amjad Almahairi, Yasmine Babaei, Nikolay\nBashlykov, Soumya Batra, Prajjwal Bhargava, Shruti\nBhosale, Dan Bikel, Lukas Blecher, Cristian Canton\nFerrer, Moya Chen, Guillem Cucurull, David Esiobu,\nJude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller,\nCynthia Gao, Vedanuj Goswami, Naman Goyal, An-\nthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan\nInan, Marcin Kardas, Viktor Kerkez, Madian Khabsa,\nIsabel Kloumann, Artem Korenev, Punit Singh Koura,\nMarie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Di-\nana Liskovich, Yinghai Lu, Yuning Mao, Xavier Mar-\ntinet, Todor Mihaylov, Pushkar Mishra, Igor Moly-\nbog, Yixin Nie, Andrew Poulton, Jeremy Reizen-\nstein, Rashi Rungta, Kalyan Saladi, Alan Schelten,\nRuan Silva, Eric Michael Smith, Ranjan Subrama-\nnian, Xiaoqing Ellen Tan, Binh Tang, Ross Tay-\nlor, Adina Williams, Jian Xiang Kuan, Puxin Xu,\nZheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan,\nMelanie Kambadur, Sharan Narang, Aurelien Ro-\ndriguez, Robert Stojnic, Sergey Edunov, and Thomas\nScialom. 2023. Llama 2: Open foundation and fine-\ntuned chat models.\nMark Towers, Jordan K. Terry, Ariel Kwiatkowski,\nJohn U. Balis, Gianluca de Cola, Tristan Deleu,\nManuel Goulão, Andreas Kallinteris, Arjun KG,\nMarkus Krimmel, Rodrigo Perez-Vicente, Andrea\nPierré, Sander Schulhoff, Jun Jet Tai, Andrew Tan Jin\nShen, and Omar G. Younis. 2023. Gymnasium.\nHarsh Trivedi, Niranjan Balasubramanian, Tushar Khot,\nand Ashish Sabharwal. 2023. Interleaving retrieval\nwith chain-of-thought reasoning for knowledge-\nintensive multi-step questions. In Proceedings of\nthe 61st Annual Meeting of the Association for Com-\nputational Linguistics (Volume 1: Long Papers),\npages 10014–10037, Toronto, Canada. Association\nfor Computational Linguistics.\nRasul Tutunov, Antoine Grosnit, Juliusz Ziomek, Jun\nWang, and Haitham Bou-Ammar. 2023. Why can\nlarge language models generate correct chain-of-\nthoughts?\nShubham Vatsal and Harsh Dubey. 2024. A survey\nof prompt engineering methods in large language\nmodels for different nlp tasks.\nAnton Voronov, Lena Wolf, and Max Ryabinin. 2024.\nMind your format: Towards consistent evaluation of\nin-context learning improvements. arXiv preprint\narXiv:2401.06766.\nEric Wallace, Shi Feng, Nikhil Kandpal, Matt Gardner,\nand Sameer Singh. 2019. Universal adversarial trig-\ngers for attacking and analyzing nlp. In Conference\non Empirical Methods in Natural Language Process-\ning.\nXingchen Wan, Ruoxi Sun, Hanjun Dai, Sercan O. Arik,\nand Tomas Pfister. 2023a. Better zero-shot reasoning\nwith self-adaptive prompting.\nXingchen Wan, Ruoxi Sun, Hootan Nakhost, Han-\njun Dai, Julian Martin Eisenschlos, Sercan O. Arik,\nand Tomas Pfister. 2023b. Universal self-adaptive\nprompting.\nGuanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Man-\ndlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan, and An-\nima Anandkumar. 2023a. Voyager: An open-ended\nembodied agent with large language models.\nJiaan Wang, Yunlong Liang, Fandong Meng, Haoxiang\nShi, Zhixu Li, Jinan Xu, Jianfeng Qu, and Jie Zhou.\n2023b. Is chatgpt a good nlg evaluator? a preliminary\nstudy. arXiv preprint arXiv:2303.04048.\nJiaqi Wang, Zhengliang Liu, Lin Zhao, Zihao Wu,\nChong Ma, Sigang Yu, Haixing Dai, Qiushi Yang,\nYiheng Liu, Songyao Zhang, Enze Shi, Yi Pan, Tuo\nZhang, Dajiang Zhu, Xiang Li, Xi Jiang, Bao Ge,\nYixuan Yuan, Dinggang Shen, Tianming Liu, and\nShu Zhang. 2023c. Review of large vision models\nand visual prompt engineering.\nJiaqi Wang, Enze Shi, Sigang Yu, Zihao Wu, Chong\nMa, Haixing Dai, Qiushi Yang, Yanqing Kang, Jinru\nWu, Huawen Hu, Chenxi Yue, Haiyang Zhang, Yi-\nheng Liu, Xiang Li, Bao Ge, Dajiang Zhu, Yixuan\nYuan, Dinggang Shen, Tianming Liu, and Shu Zhang.\n2023d. Prompt engineering for healthcare: Method-\nologies and applications.\nJunjie Wang, Yuchao Huang, Chunyang Chen, Zhe Liu,\nSong Wang, and Qing Wang. 2023e. Software testing\nwith large language model: Survey, landscape, and\nvision.\n58\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 151
  },
  {
    "chunk_full": "Lei Wang, Wanyu Xu, Yihuai Lan, Zhiqiang Hu,\nYunshi Lan, Roy Ka-Wei Lee, and Ee-Peng Lim.\n2023f. Plan-and-solve prompting: Improving zero-\nshot chain-of-thought reasoning by large language\nmodels.\nSiyin Wang, Chao-Han Huck Yang, Ji Wu, and Chao\nZhang. 2023g. Can whisper perform speech-based\nin-context learning.\nXinyi Wang, Wanrong Zhu, Michael Saxon, Mark\nSteyvers, and William Yang Wang. 2023h. Large\nlanguage models are latent variable models: Explain-\ning and finding good demonstrations for in-context\nlearning.\nXuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le,\nEd Chi, Sharan Narang, Aakanksha Chowdhery, and\nDenny Zhou. 2022. Self-consistency improves chain\nof thought reasoning in language models.\nYaqing Wang, Jiepu Jiang, Mingyang Zhang, Cheng\nLi, Yi Liang, Qiaozhu Mei, and Michael Bender-\nsky. 2023i. Automated evaluation of personalized\ntext generation using large language models. arXiv\npreprint arXiv:2310.11593.\nYaqing Wang, Quanming Yao, James Kwok, and Li-\nonel M. Ni. 2019. Generalizing from a few examples:\nA survey on few-shot learning.\nYuqing Wang and Yun Zhao. 2024.\nMetacognitive\nprompting improves understanding in large language\nmodels.\nZekun Moore Wang, Zhongyuan Peng, Haoran Que,\nJiaheng Liu,\nWangchunshu Zhou,\nYuhan Wu,\nHongcheng Guo, Ruitong Gan, Zehao Ni, Man\nZhang, Zhaoxiang Zhang, Wanli Ouyang, Ke Xu,\nWenhu Chen, Jie Fu, and Junran Peng. 2023j.\nRolellm: Benchmarking, eliciting, and enhancing\nrole-playing abilities of large language models.\nZhendong Wang, Yifan Jiang, Yadong Lu, Yelong Shen,\nPengcheng He, Weizhu Chen, Zhangyang Wang, and\nMingyuan Zhou. 2023k.\nIn-context learning un-\nlocked for diffusion models.\nZhenhailong Wang, Shaoguang Mao, Wenshan Wu, Tao\nGe, Furu Wei, and Heng Ji. 2023l. Unleashing cogni-\ntive synergy in large language models: A task-solving\nagent through multi-persona self-collaboration.\nJason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu,\nAdams Wei Yu, Brian Lester, Nan Du, Andrew M.\nDai, and Quoc V Le. 2022a. Finetuned language\nmodels are zero-shot learners. In International Con-\nference on Learning Representations.\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten\nBosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, and\nDenny Zhou. 2022b. Chain-of-thought prompting\nelicits reasoning in large language models.\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten\nBosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, and\nDenny Zhou. 2023a. Chain-of-thought prompting\nelicits reasoning in large language models.\nJerry Wei, Da Huang, Yifeng Lu, Denny Zhou, and\nQuoc V Le. 2023b. Simple synthetic data reduces\nsycophancy in large language models. arXiv preprint\narXiv:2308.03958.\nJerry Wei, Jason Wei, Yi Tay, Dustin Tran, Albert\nWebson, Yifeng Lu, Xinyun Chen, Hanxiao Liu,\nDa Huang, Denny Zhou, et al. 2023c.\nLarger\nlanguage models do in-context learning differently.\narXiv preprint arXiv:2303.03846.\nYixuan Weng, Minjun Zhu, Fei Xia, Bin Li, Shizhu He,\nShengping Liu, Bin Sun, Kang Liu, and Jun Zhao.\n2022. Large language models are better reasoners\nwith self-verification.\nJason Weston and Sainbayar Sukhbaatar. 2023. System\n2 attention (is something you might need too).\nJules White, Quchen Fu, Sam Hays, Michael Sandborn,\nCarlos Olea, Henry Gilbert, Ashraf Elnashar, Jesse\nSpencer-Smith, and Douglas C. Schmidt. 2023. A\nprompt pattern catalog to enhance prompt engineer-\ning with chatgpt.\nAlex Wilf, Sihyun Shawn Lee, Paul Pu Liang, and Louis-\nPhilippe Morency. 2023. Think twice: Perspective-\ntaking improves large language models’ theory-of-\nmind capabilities.\nSimon Willison. 2022. Prompt injection attacks against\ngpt-3.\nSimon Willison. 2024. Prompt injection and jailbreak-\ning are not the same thing.\nGenta Indra Winata, Liang-Kang Huang, Soumya Vad-\nlamannati, and Yash Chandarana. 2023. Multilingual\nfew-shot learning via language model retrieval.\nJay Zhangjie Wu, Yixiao Ge, Xintao Wang, Weixian\nLei, Yuchao Gu, Yufei Shi, Wynne Hsu, Ying Shan,\nXiaohu Qie, and Mike Zheng Shou. 2023a. Tune-a-\nvideo: One-shot tuning of image diffusion models\nfor text-to-video generation.\nNing Wu, Ming Gong, Linjun Shou, Shining Liang,\nand Daxin Jiang. 2023b. Large language models are\ndiverse role-players for summarization evaluation.\narXiv preprint arXiv:2303.15078.\nTongshuang Wu, Michael Terry, and Carrie Jun Cai.\n2022.\nAi chains: Transparent and controllable\nhuman-ai interaction by chaining large language\nmodel prompts. CHI Conference on Human Factors\nin Computing Systems.\nXiaodong Wu, Ran Duan, and Jianbing Ni. 2023c. Un-\nveiling security, privacy, and ethical concerns of chat-\ngpt. Journal of Information and Intelligence.\n59\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 152
  },
  {
    "chunk_full": "Congying Xia, Chen Xing, Jiangshu Du, Xinyi Yang,\nYihao Feng, Ran Xu, Wenpeng Yin, and Caiming\nXiong. 2024. Fofo: A benchmark to evaluate llms’\nformat-following capability.\nMiao Xiong, Zhiyuan Hu, Xinyang Lu, Yifei Li, Jie\nFu, Junxian He, and Bryan Hooi. 2023a. Can llms\nexpress their uncertainty? an empirical evaluation\nof confidence elicitation in llms.\narXiv preprint\narXiv:2306.13063.\nMiao Xiong, Zhiyuan Hu, Xinyang Lu, Yifei Li, Jie\nFu, Junxian He, and Bryan Hooi. 2023b. Can llms\nexpress their uncertainty? an empirical evaluation\nof confidence elicitation in llms.\narXiv preprint\narXiv:2306.13063.\nXiaohan Xu, Chongyang Tao, Tao Shen, Can Xu,\nHongbo Xu, Guodong Long, and Jian guang Lou.\n2023. Re-reading improves reasoning in language\nmodels.\nTianci Xue, Ziqi Wang, Zhenhailong Wang, Chi Han,\nPengfei Yu, and Heng Ji. 2023. Rcot: Detecting\nand rectifying factual inconsistency in reasoning by\nreversing chain-of-thought.\nChengrun Yang, Xuezhi Wang, Yifeng Lu, Hanxiao Liu,\nQuoc V. Le, Denny Zhou, and Xinyun Chen. 2023a.\nLarge language models as optimizers.\nHaibo Yang, Yang Chen, Yingwei Pan, Ting Yao, Zhi-\nneng Chen, and Tao Mei. 2023b. 3dstyle-diffusion:\nPursuing fine-grained text-driven 3d stylization with\n2d diffusion models.\nHui Yang, Sifu Yue, and Yunzhong He. 2023c. Auto-\ngpt for online decision making: Benchmarks and\nadditional opinions.\nXinyi Yang, Runzhe Zhan, Derek F. Wong, Junchao\nWu, and Lidia S. Chao. 2023d. Human-in-the-loop\nmachine translation with large language model. In\nProceedings of Machine Translation Summit XIX Vol.\n2: Users Track, pages 88–98, Macau SAR, China.\nMachine Translation Summit.\nZhengyuan Yang, Linjie Li, Kevin Lin, Jianfeng Wang,\nChung-Ching Lin, Zicheng Liu, and Lijuan Wang.\n2023e. The dawn of lmms: Preliminary explorations\nwith gpt-4v(ision). ArXiv, abs/2309.17421.\nBinwei Yao, Ming Jiang, Diyi Yang, and Junjie Hu.\n2023a. Empowering llm-based machine translation\nwith cultural awareness.\nShunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran,\nThomas L. Griffiths,\nYuan Cao,\nand Karthik\nNarasimhan. 2023b. Tree of thoughts: Deliberate\nproblem solving with large language models.\nShunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak\nShafran, Karthik Narasimhan, and Yuan Cao. 2022.\nReact: Synergizing reasoning and acting in language\nmodels.\nYao Yao, Zuchao Li, and Hai Zhao. 2023c. Beyond\nchain-of-thought, effective graph-of-thought reason-\ning in large language models.\nMichihiro Yasunaga, Xinyun Chen, Yujia Li, Panupong\nPasupat, Jure Leskovec, Percy Liang, Ed H. Chi,\nand Denny Zhou. 2023. Large language models as\nanalogical reasoners.\nQinyuan Ye, Maxamed Axmed, Reid Pryzant, and\nFereshte Khani. 2023. Prompt engineering a prompt\nengineer.\nXi Ye and Greg Durrett. 2023. Explanation selection\nusing unlabeled data for chain-of-thought prompting.\nKang Min Yoo, Junyeob Kim, Hyuhng Joon Kim, Hyun-\nsoo Cho, Hwiyeol Jo, Sang-Woo Lee, Sang goo Lee,\nand Taeuk Kim. 2022. Ground-truth labels matter: A\ndeeper look into input-label demonstrations.\nOri Yoran, Tomer Wolfson, Ben Bogin, Uri Katz, Daniel\nDeutch, and Jonathan Berant. 2023.\nAnswering\nquestions by meta-reasoning over multiple chains\nof thought.\nAdeel Yousaf, Muzammal Naseer, Salman Khan, Fa-\nhad Shahbaz Khan, and Mubarak Shah. 2023. Video-\nprompter: an ensemble of foundational models for\nzero-shot video understanding.\nYue Yu, Yuchen Zhuang, Jieyu Zhang, Yu Meng,\nAlexander Ratner, Ranjay Krishna, Jiaming Shen,\nand Chao Zhang. 2023. Large language model as\nattributed training data generator: A tale of diversity\nand bias. arXiv preprint arXiv:2306.15895.\nXiang Yue, Boshi Wang, Kai Zhang, Ziru Chen, Yu Su,\nand Huan Sun. 2023. Automatic evaluation of at-\ntribution by large language models. arXiv preprint\narXiv:2305.06311.\nZhiyuan Zeng, Jiatong Yu, Tianyu Gao, Yu Meng, Tanya\nGoyal, and Danqi Chen. 2023.\nEvaluating large\nlanguage models at evaluating instruction following.\narXiv preprint arXiv:2310.07641.\nMichael JQ Zhang and Eunsol Choi. 2023. Clarify when\nnecessary: Resolving ambiguity through interaction\nwith lms. arXiv preprint arXiv:2311.09469.\nQuanjun Zhang, Tongke Zhang, Juan Zhai, Chunrong\nFang, Bowen Yu, Weisong Sun, and Zhenyu Chen.\n2023a. A critical review of large language model on\nsoftware engineering: An example from chatgpt and\nautomated program repair.\nYifan Zhang, Jingqin Yang, Yang Yuan, and Andrew\nChi-Chih Yao. 2023b. Cumulative reasoning with\nlarge language models.\nYiming Zhang, Shi Feng, and Chenhao Tan. 2022a. Ac-\ntive example selection for in-context learning.\n60\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 153
  },
  {
    "chunk_full": "Zhuosheng Zhang, Yao Yao, Aston Zhang, Xiangru\nTang, Xinbei Ma, Zhiwei He, Yiming Wang, Mark\nGerstein, Rui Wang, Gongshen Liu, and Hai Zhao.\n2023c. Igniting language intelligence: The hitch-\nhiker’s guide from chain-of-thought reasoning to lan-\nguage agents.\nZhuosheng Zhang, Aston Zhang, Mu Li, and Alex\nSmola. 2022b. Automatic chain of thought prompt-\ning in large language models.\nZhuosheng Zhang, Aston Zhang, Mu Li, Hai Zhao,\nGeorge Karypis, and Alex Smola. 2023d.\nMulti-\nmodal chain-of-thought reasoning in language mod-\nels.\nRuochen Zhao, Xingxuan Li, Shafiq Joty, Chengwei\nQin, and Lidong Bing. 2023a. Verify-and-edit: A\nknowledge-enhanced chain-of-thought framework.\nIn Proceedings of the 61st Annual Meeting of the\nAssociation for Computational Linguistics (Volume\n1: Long Papers), pages 5823–5840, Toronto, Canada.\nAssociation for Computational Linguistics.\nTony Z. Zhao, Eric Wallace, Shi Feng, Dan Klein, and\nSameer Singh. 2021a. Calibrate before use: Improv-\ning few-shot performance of language models.\nYilun Zhao, Haowei Zhang, Shengyun Si, Linyong Nan,\nXiangru Tang, and Arman Cohan. 2023b. Large lan-\nguage models are effective table-to-text generators,\nevaluators, and feedback providers. arXiv preprint\narXiv:2305.14987.\nYuyang Zhao, Zhiwen Yan, Enze Xie, Lanqing Hong,\nZhenguo Li, and Gim Hee Lee. 2023c. Animate124:\nAnimating one image to 4d dynamic scene.\nZihao Zhao, Eric Wallace, Shi Feng, Dan Klein, and\nSameer Singh. 2021b.\nCalibrate before use: Im-\nproving few-shot performance of language models.\nIn International Conference on Machine Learning,\npages 12697–12706. PMLR.\nChujie Zheng, Hao Zhou, Fandong Meng, Jie Zhou, and\nMinlie Huang. 2023a. On large language models’ se-\nlection bias in multi-choice questions. arXiv preprint\narXiv:2309.03882.\nGe Zheng, Bin Yang, Jiajin Tang, Hong-Yu Zhou, and\nSibei Yang. 2023b. Ddcot: Duty-distinct chain-of-\nthought prompting for multimodal reasoning in lan-\nguage models.\nHuaixiu Steven Zheng, Swaroop Mishra, Xinyun Chen,\nHeng-Tze Cheng, Ed H. Chi, Quoc V Le, and Denny\nZhou. 2023c. Take a step back: Evoking reasoning\nvia abstraction in large language models.\nMingqian Zheng, Jiaxin Pei, and David Jurgens. 2023d.\nIs \"a helpful assistant\" the best role for large language\nmodels? a systematic evaluation of social roles in\nsystem prompts.\nDenny Zhou, Nathanael Schärli, Le Hou, Jason Wei,\nNathan Scales, Xuezhi Wang, Dale Schuurmans,\nClaire Cui, Olivier Bousquet, Quoc Le, et al. 2022a.\nLeast-to-most prompting enables complex reason-\ning in large language models.\narXiv preprint\narXiv:2205.10625.\nYongchao Zhou, Andrei Ioan Muresanu, Ziwen Han,\nKeiran Paster, Silviu Pitis, Harris Chan, and Jimmy\nBa. 2022b. Large language models are human-level\nprompt engineers.\nYucheng Zhou, Xiubo Geng, Tao Shen, Chongyang Tao,\nGuodong Long, Jian-Guang Lou, and Jianbing Shen.\n2023. Thread of thought unraveling chaotic contexts.\nXizhou Zhu, Yuntao Chen, Hao Tian, Chenxin Tao, Wei-\njie Su, Chenyu Yang, Gao Huang, Bin Li, Lewei Lu,\nXiaogang Wang, Yu Qiao, Zhaoxiang Zhang, and\nJifeng Dai. 2023. Ghost in the minecraft: Gener-\nally capable agents for open-world environments via\nlarge language models with text-based knowledge\nand memory.\nZhichao Zuo, Zhao Zhang, Yan Luo, Yang Zhao, Haijun\nZhang, Yi Yang, and Meng Wang. 2023. Cut-and-\npaste: Subject-driven video editing with attention\ncontrol.\n61\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 154
  },
  {
    "chunk_full": "A\nAppendices\nA.1\nDefinitions of Prompting\nReference\nPrompt\nPrompt Engineering\n(Meskó,\n2023)\nThe practice of designing, refining, and\nimplementing prompts or instructions that\nguide the output of LLMs to help in vari-\nous tasks. It is essentially the practice of\neffectively interacting with AI systems to\noptimize their benefits.\n(Chen et al.,\n2023a)\nthe input of the model\nthe process of structuring input text for\nLLMs and is a technique integral to opti-\nmizing the efficacy of LLMs\n(Santu\nand\nFeng, 2023)\nrefers to a textual input provided to the\nLLMs with the intention of guiding its\noutput toward a specific task\ninvolves crafting and revising the query\nor context in such a way that it elicits the\ndesired response or behavior from LLMs\n(Wang et al.,\n2023d)\ninvolves designing effective prompts to\nguide the pre-trained language model in\ndownstream tasks.\n(Wang et al.,\n2023c)\nthe process of designing prompts that en-\nable the model to adapt and generalize to\ndifferent tasks. downstream tasks.\n(Hou et al.,\n2023)\nmanually predefined natural language in-\nstructions\nthe careful design of specialized prompts\n(Wang et al.,\n2023e)\ninput of the LLMs\ncommunicate with LLMs to steer its be-\nhavior for desired outcomes\n(White et al.,\n2023)\nInstructions given to an LLM to enforce\nrules, automate processes, and ensure spe-\ncific qualities (and quantities) of generated\noutput. Prompts are also a form of pro-\ngramming that can customize the outputs\nand interactions with an LLM.\nA prompt is a set of instructions provided\nto an LLM that programs the LLM by cus-\ntomizing it and/or en- hancing or refining\nits capabilities\nan increasingly important skill set needed\nto converse effectively with large lan-\nguage models (LLMs), such as ChatGPT\nthe means by which LLMs are pro-\ngrammed via prompts\n(Heston and\nKhun, 2023)\nthe input\nstructuring the input in a specialized man-\nner\n(Liu et al.,\n2023b)\nchoosing a proper prompt\nthe process of creating a prompting func-\ntion fprompt(x) that results in the most\neffective performance on the downstream\ntask.\n62\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 155
  },
  {
    "chunk_full": "(Hadi et al.,\n2023)\nthe instructions provided to an LLM to\nmake it follow specified rules, automation\nof processes and to ensure that the out-\nput generated is of a specific quality or\nquantity\nrefers to the designing and wording of\nprompts given to LLMs so as to get a de-\nsired response from them.\n(Neagu,\n2023)\nentails various strate- gies, including ex-\nplicit instruction, and implicit context [21].\nExplicit instruction involves providing ex-\nplicit guidance or constraints to the model\nthrough instructions, examples, or speci-\nfications. Implicit context leverages the\nmodel’s under- standing of the preceding\ncontext to influence its response\n(Dang et al.,\n2022)\nthe systematic practice of constructing\nprompts to improve the generated output\nof a generative model\nTable A.1: Definitions of Prompt and Prompt Engineering from different papers.\n63\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 156
  },
  {
    "chunk_full": "A.2\nExtended Vocabulary\nA.2.1\nPrompting Terms\nContext Window\nThe context window is the space of tokens (for LLMs) which the model can process.\nIt has a maximal length (the context length).\nPriming\n(Schulhoff, 2022) refers to giving a model an initial prompt that lays out certain instructions\nfor the rest of a conversation. This priming prompt might contains a role or other instructions on how to\ninteract with the user. Priming can either be done in the system or user prompt (see below).\nA.2.2\nPrompt Engineering Terms\nConversational Prompt Engineering\nis Prompt Engineering in colloquio. That is, during the course of a\nconversation with a GenAI, a user may ask the GenAI to refine its output. In contrast, prompt engineering\nis often done by sending the GenAI a completely new prompt rather than continuing a conversation.\nA.2.3\nFine-Tuning Terms\nPrompt-Based Learning\n(Liu et al., 2023b), also known as Prompt Learning (Liu et al., 2023b; Wang\net al., 2023d) refers to the process of using prompting-related techniques. It often is used in the context of\nfine-tuning, especially fine-tuning prompts. Due to conflicting usage, we do not use this term.\nPrompt Tuning\n(Lester et al., 2021) refers to directly optimizing the weights of the prompt itself,\nusually through some form of gradient-based updates. It has also been referred to has Prompt Fine-Tuning.\nIt should not be used to refer to discrete prompt engineering.\nA.2.4\nOrthogonal Prompt Types\nWe now discuss terminology for high-level ways of classifying prompts.\nA.2.4.1\nOriginator\nUser Prompt\nThis is the type of prompt that comes from the user. This is the most common form of\nprompting and is how prompts are usually delivered in consumer applications.\nAssistant Prompt\nThis \"prompt\" is simply the output of the LLM itself. It can be considered a prompt\n(or part of one) when it is fed back into the model, for example as part of a conversation history with a\nuser.\nSystem Prompt\nThis prompt is used to give LLMs high level instructions for interacting with users. Not\nall models have this.\nA.2.4.2\nHard vs Soft Prompts\nHard (discrete) Prompt\nThese prompts only contain tokens that directly correspond to words in the\nLLM vocabulary.\nSoft (continuous) Prompt\nThese prompts contain tokens that may not correspond to any word in the\nvocabulary (Lester et al., 2021; Wang et al., 2023c). Soft prompts can be used when fine-tuning is desired,\nbut modifying the weights of the full model is prohibitively expensive. Thus, a frozen model can be used\nwhile allowing gradients to flow through the prompt tokens.\nHard Prompts ⊆Soft Prompts\nA.2.4.3\nPrediction Styles\nIn LLMs, a prediction style is the format in which it predicts the next token. There are two common\nformats for this in prompting research. We do not discuss non-text prediction styles.\nCloze\nIn Cloze prompts, the token(s) to be predicted are presented as \"slots to fill\", usually somewhere\nin the middle of the prompt (Liu et al., 2023b). This is usually the case for earlier transformer models\nsuch as BERT (Chu and Lin, 2023).\n64\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 157
  },
  {
    "chunk_full": "Prefix\nIn Prefix prompts, the token to be predicted is at the end of the prompt (Liu et al., 2023b). This is\nusually the case with modern GPT-style models (Radford et al., 2019b).\n65\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 158
  },
  {
    "chunk_full": "A.3\nDatasheet\nWe present a datasheet (Gebru et al., 2021) with more information about the associated paper dataset,\nwhich is hosted on HuggingFace.\nA.3.1\nMotivation\nFor what purpose was the dataset created? Was there a specific task in mind? Was there a specific\ngap that needed to be filled? Please provide a description.\nThis dataset was created to gather existing literature on prompt engineering in order to analyze all current\nhard prefix prompting techniques.\nWho created the dataset (e.g., which team, research group) and on behalf of which entity (e.g.,\ncompany, institution, organization)?\nThis research was associated with the University of Maryland, Learn Prompting, and sponsored by\nOpenAI, but not created on the behalf of any particular organization.\nWho funded the creation of the dataset? If there is an associated grant, please provide the name\nof the grantor and the grant name and number.\nOpenAI contributed $10,000 in credits for their API.\nA.3.2\nComposition\nWhat do the instances that comprise the dataset represent (e.g., documents, photos, people, coun-\ntries)? Are there multiple types of instances (e.g., movies, users, and ratings; people and interactions\nbetween them; nodes and edges)? Please provide a description.\nThe dataset contains 1,565 research papers in PDF format. Any duplicate papers were removed automati-\ncally, though some could exist.\nWhat data does each instance consist of? “Raw” data (e.g., unprocessed text or images) or\nfeatures? In either case, please provide a description.\nEach data instance is a research paper as a PDF.\nIs there a label or target associated with each instance? If so, please provide a description.\nNo\nIs any information missing from individual instances? If so, please provide a description, ex-\nplaining why this information is missing (e.g., because it was unavailable). This does not include\nintentionally removed information, but might include, e.g., redacted text.\nNo.\nAre there any errors, sources of noise, or redundancies in the dataset? If so, please provide a\ndescription.\nThe papers were gathered in a semi-automated process which introduced the possibility of irrelevant\npapers being collected and relevant papers not being collected. There were manual reviews done for both\npossible errors to mitigate these errors.\nIs the dataset self-contained, or does it link to or otherwise rely on external resources (e.g.,\nwebsites, tweets, other datasets)?\nIt is self-contained.\nDoes the dataset contain data that might be considered confidential (e.g., data that is protected by\nlegal privilege or by doctor–patient confidentiality, data that includes the content of individuals’\nnon-public communications)? If so, please provide a description.\nNo.\nDoes the dataset contain data that, if viewed directly, might be offensive, insulting, threatening,\nor might otherwise cause anxiety? If so, please describe why.\nThe dataset contains some papers on prompt injection. These papers may contain offensive content\nincluding racism and sexism.\n66\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 159
  },
  {
    "chunk_full": "A.3.3\nCollection Process\nHow was the data associated with each instance acquired?\nThe dataset was compiled from Arxiv, Semantic Scholar, and ACL.\nWhat mechanisms or procedures were used to collect the data?\nWe wrote scripts to automatically query the APIs of Arxiv and Semantic Scholar.\nOver what timeframe was the data collected?\nThe dataset was curated the duration of the research paper, primarily in February of 2024.\nWere any ethical review processes conducted?\nNo.\nA.3.4\nPreprocessing/ Cleaning/ Labeling\nWas any preprocessing/cleaning/labeling of the data done?\nAfter collecting data from different sources, we removed duplicate papers and did a manual and semi-\nautomated review of papers to ensure they were all relevant.\nWas the “raw” data saved in addition to the preprocessed/cleaned/labeled data?\nNo, we do not anticipate the use of our preprocessed data. However, raw data can be recovered from the\nlinks we store.\nIs the software that was used to preprocess/clean/label the data available?\nIt is contained within our code repository on Github.\nA.3.5\nUses\nHas the dataset been used for any tasks already?\nNo.\nIs there a repository that links to any or all papers or systems that use the dataset?\nYes.\nIs there anything about the composition of the dataset or the way it was collected and prepro-\ncessed/cleaned/labeled that might impact future uses?\nAll of the papers we collected were written in English. It is possible some papers were not included due to\na translation not being available.\nAre there tasks for which the dataset should not be used?\nNo.\nA.3.6\nDistribution\nWill the dataset be distributed to third parties outside of the entity on behalf of which the dataset\nwas created?\nNo.\nA.3.7\nMaintenance\nWho will be supporting/hosting/maintaining the dataset?\nOur team will continue maintenance.\nHow can the owner/curator/manager of the dataset be contacted?\nPlease email us at sanderschulhoff@gmail.com\nIs there an erratum?\nNo.\nIf others want to extend/augment/build on/contribute to the dataset, is there a mechanism for\nthem to do so?\nYes, anyone is free to use/modify the data.\n67\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 160
  },
  {
    "chunk_full": "A.4\nKeywords\nHere are the keywords we used for search.\n• jailbreak prompt\n• prompt an llm\n• prompt a large language model\n• prompt injection\n• prompt optimization\n• prompt engineering\n• few-shot learning\n• few shot learning\n• prompt-based methods\n• prompt based methods\n• prompting-based methods\n• prompting based methods\n• few-shot prompt\n• few shot prompt\n• one-shot prompt\n• one shot prompt\n• few-shot prompting\n• few shot prompting\n• one-shot prompting\n• one shot prompting\n• prompting techniques\n• prompt engineering techniques\n• llm prompting\n• large language model prompting\n• 0-shot prompt\n• 0 shot prompt\n• zero-shot prompt\n• many-shot prompt\n• zero-shot prompting\n• many-shot prompting\n68\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 161
  },
  {
    "chunk_full": "• in-context learning\n• in context learning\n• transformer model prompts\n• prompt-based transfer learning\n• nlp prompting strategies\n• llm interpretability via prompts\n• curriculum learning with prompts\n• feedback loops in llm prompting\n• human-in-the-loop prompting\n• token-efficient prompting\n• multimodal prompting\n• instruction prompting\n• prompt templating\n• prompt template\n69\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 162
  },
  {
    "chunk_full": "A.5\nPrompt for Systematic Literature Review\nPlease find the prompt we used here. We present it in text in this document, but note that you should use\nthe version in our codebase rather than copy and paste this.\nWe used the following system prompt:\nYou are a lab assistant, helping with a systematic review on prompt engineering. You’ve been asked to\nrate the relevance of a paper to the topic of prompt engineering. To be clear, this review will strictly cover\nhard prefix prompts. For clarification: Hard prompts have tokens that correspond directly to words in\nthe vocab. For example, you could make up a new token by adding two together. This would no longer\ncorrespond to any word in the vocabulary, and would be a soft prompt Prefix prompts are prompts used\nfor most modern transformers, where the model predicts the words after this prompt. In earlier models,\nsuch as BERT, models could predict words (e.g. <MASK>) in the middle of the prompt. Your job is to be\nable to tell whether a paper is related to (or simply contains) hard prefix prompting or prompt engineering.\nPlease note that a paper might not spell out that it is using \"hard prefix\" prompting and so it might just say\nprompting. In this case, you should still rate it as relevant to the topic of prompt engineering. Please also\nnote, that a paper that focuses on training a model as opposed to post-training prompting techniques is\nconsidered irrelevant. Provide a response in JSON format with two fields: ’reasoning’ (a single sentence\nthat justifies your reasoning) and ’rating’ (a string that is one of the following categories: ’highly relevant’,\n’somewhat relevant’, ’neutrally relevant’, ’somewhat irrelevant’, ’highly irrelevant’) indicating relevance\nto the topic of prompt engineering)\nThen, we used this user prompt template to input information for each paper:\nTitle: ’{title}’, Abstract: ’{abstract}’. Rate its relevance to the topic of prompt engineering as one of the\nfollowing categories: ’highly relevant’, ’somewhat relevant’, ’neutrally relevant’, ’somewhat irrelevant’,\n’highly irrelevant’, and provide text from the abstract that justifies your reasoning\n70\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 163
  },
  {
    "chunk_full": "A.6\nEvaluation Table\nID\nMODEL\nPROMPT\nOUTPUT SPACE\nTYPE RES. BATCH\nRoles CoT Definition Few-Shot\n(Kocmi and Federmann, 2023b) GPT-family\nDA, sMQM, stars, classes\nE\nS\n(Lu et al., 2023c)\nDav3, GPT-4-Turbo, GPT-4\n✓\n✓\n✓\nError Span →Score\nE\nS\n✓\n(Fernandes et al., 2023)\nPaLM\n✓\n✓\n✓\nError Span\nI\nS\n(Kocmi and Federmann, 2023a) GPT-4\n✓\n✓\n✓\nError Span\nI\nS\n✓\n(Araújo and Aguiar, 2023)\nChatGPT\n✓\nLikert [1-5]\nE\nS\n✓\n(Wang et al., 2023b)\nChatGPT\n✓\nDA, stars\nE\nS\n(Liu et al., 2023d)†\nGPT-3.5, GPT-4\n✓\nLikert [1-10]\nI\nM\n(Chan et al., 2024)\nChatGPT, GPT-4\n✓\n✓\nLikert [1-10]\nI\nM\n(Luo et al., 2023)\nChatGPT\n✓\n✓\nyes/no;A/B; Likert [1-10]\nE\nS\n(Hada et al., 2024)\nGPT-4-32K\n✓\n✓\n[0,1,2] or binary\nE\nS\n✓\n(Fu et al., 2023a)\nGPT-3, OPT, FLAN-T5, GPT-2\nProbability\nI\nS\n(Gao et al., 2023c)\nChatGPT\n✓\nLikert [1-5], Pairwise, Pyramid, 0/1\nE\nS\n(Chen et al., 2023g)\nChatGPT\nLikert [1-10]; yes/no; pairwise: A/B/C E & I S\n(He et al., 2023a)\nGPT-4\n✓\nLikert [1-5]\nE\nS\n(Sottana et al., 2023)\nGPT-4\n✓\nLikert [1-5]\nE\nS\n(Chen et al., 2023c)\nGPT, Flan-T5\n✓\nYes/No\nE\nS\n(Zhao et al., 2023b)\nGPT-3.5, GPT-4\n✓\n✓\ntrue/false\nE\nS\n(Wu et al., 2023b)\nGPT-3\n✓\npairwise voting\nE\nM\n✓\n(Wang et al., 2023i)\nPaLM 2-IT-L\nA/B\nE\nM\n(Jia et al., 2023)\nLLaMa7b\nProbability\nI\nS\n(Yue et al., 2023)\nChatGPT, Alpaca, Vicuna, GPT-4\n✓\n✓\nYes/No\nE\nS\n(Li et al., 2023e)\nGPT-3.5, GPT-4, Bard, Vicuna\n✓\nPairwise\nI\nM\n(Liu et al., 2023f)\nChatGPT, Vicuna, chatGLM, StableLM\n✓\ncontinuous [0-1]\nE\nS\n(Bai et al., 2023b)\nGPT-4, Claude, ChatGPT, Bard, Vicuna\n✓\nLikert [1-5]\nE\nS\n(Dubois et al., 2023)\nGPT-4, ChatGPT, Dav3\n✓\n✓\npairwise\nE\nM\n✓\n(Liu et al., 2023h)†\nGPT-4-32K\n✓\nLikert [1-5]\nE\nS\n(Wang et al., 2023h)\nGPT-4-Turbo, ChatGPT, GPT-4, Vicuna\n✓\nLikert [1-10]\nE\nM\n(Zeng et al., 2023)\nGPT-4, ChatGPT, LLaMA-2-Chat, PaLM2, Falcon\n✓\n✓\n✓\nPairwise\nE\nS\n(Zheng et al., 2023b)\nClaude-v1, GPT-3.5, GPT-4\n✓\n✓\nPairwise/Likert [1-10]\nE\nS/M\n(Lin and Chen, 2023)\nClaude-v1.3\nLikert [0-5], Likert [0-100]\nE\nS\n✓\nTable A.2: Evaluation Paper Summary. E: Explicit (whether the model generates an assessment), I: Implicit (whether\nan assessment is derived from the model output); Response (Res.) S: Single response, M: Multiple responses; †:\nModel generated instruction;\n71\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 164
  },
  {
    "chunk_full": "A.7\nEntrapment Prompting Process\nThis section contains the thought process of our prompt engineer as he developed the prompt.\nA.7.1\nExploration\n• First did a bit of dataset exploration, looking at length/label distribution, then chose entrapment to\nstart with.\n• Checked if gpt-1106-preview understood entrapment, by asking it to define the term WRT SCS. It\ndid not.\nA.7.2\nGetting a Label\n• Showed it the definition of entrapment in the system prompt and asked it to label a data point, but it\nresponded saying I should seek mental health support.\n• I put the instructions in the user prompt, but get a similar response.\n• Appending \"Is this entrapment? Yes or no\" got it to actually respond with a label.\n• I gave it a reject example, but it labeled it as accept, and also sometimes gives emotional responses\nabout getting help.\n• Using 10-shot prompting, it still gives the get help responses.\n• I tried removing the definition, got the same problem. It seems that it doesn’t like \"accept\"/\"reject\"\nas labels.\n• I added back the definition, changed labels to entrapment/not entrapment, it often says \"not enough\ninfo to determine\".\n• I switched to GPT-4-32K, which gave one word responses and correctly predicted a reject and an\naccept datapoint.\nA.7.3\nVarying Prompting Techniques\n• Tested 0-shot with context.\n• 10-shot with context, showed improvement.\n• Taking first failing instance into playground. (12th in train file)\n• Tried doing ’A: Let’s go step by step and figure this out: \", output \"A: Yes\"\n• Did \"A: Let’s go step by step and figure this out: \", OUTPUT:\nThe individual in this post is expressing feelings of hopelessness, loneliness, and despair.\nThey mention a significant loss (their mother) and a subsequent decline in their mental health,\nturning to alcohol as a coping mechanism. They also mention financial struggles and the\npossibility of becoming homeless. They express feelings of guilt and shame about their\nsituation and compare themselves negatively to their friends and family. Most concerning\nis their detailed plan for suicide, involving sleeping pills and alcohol. They also mention\nconsidering stepping in front of a car. Given these factors, the label for this post would be\n\"Yes\" for expressing feelings of entrapment.\n72\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 165
  },
  {
    "chunk_full": "• \"A: Before predicting a label, let’s go step by step and write out your thought process. Use the items\nin the definition of entrapment to support your conclusion.\", OUTPUT:\nBefore predicting a label, let’s go step by step and write out your thought process. Use the\nitems in the definition of entrapment to support your conclusion.\n• Began discussing with the AI \"they don’t ever say they feel trapped or that there is no way out, how\ndid u get that idea?\", OUTPUT:\nThe individual doesn’t explicitly state that they feel trapped or that there is no way out, but\ntheir narrative suggests a sense of entrapment. They mention that they are facing eviction,\nstruggling with debt, and dealing with a decrease in income. They also express a sense of\nhopelessness and despair, and contemplate suicide as a potential solution to their problems.\nThese elements suggest a feeling of being trapped in their current circumstances with no\napparent way out. However, it’s important to note that this interpretation is based on the\ninformation provided in the post and the individual’s expressed feelings and thoughts.\n• Asked it to help reformulate instructions to make explicitness more clearly needed, still predicts\nentrapment.\n• Added \"ENTRAPMENT MUST BE EXPLICIT, NOT IMPLICIT.\" to instruction at top after defini-\ntions (no CoT inducer)\n• Also tried with previous CoT inducer, still says entrapment in a hard to parse out way.\n• Added \"If the person does not explicitly say they feel trapped, this doesn’t count as entrapment.\" (no\nCoT), still entrapment.\n• Talking to AI, it thinks \"Today I found out I have 10 days to vacate my apartment or I’ll be formally\nevicted. I’m 2 months behind on my rent due to a bad time where I got demoted at work and rent\nfrom making roughly $1000 ever 2 weeks to around $450. If I get evicted, I’ll probably be homeless\"\nis feeling trapped/stuck.\n• Tried \"Before stating a label, write out reasoning using the grid above about why this may/may not\nbe entrapment:\", still thinks entrapment.\n• paste in email: [REDACTED] above definition of entrapment\n• remove shots, says \"Entrapment\"\n• add this after def: IMPORTANT: Only label the post as entrapment if they explicitly say that they\nfeel trapped., says \"Yes\"\n• In the prompt, gave it CoT reasoning. (18.txt), and tried with the next wrongly labeled one (15), (full\nprompt, 19.txt)\n• Tested this on everything except first 20, did pretty well\n• Tried removing email, performance dropped of a cliff\n• At this point, I am thinking that giving examples with reasoning helps (obviously)\n• Tried to add 10 shots in for free, before the last one with reasoning, bad results\n73\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 166
  },
  {
    "chunk_full": "A.7.3.1\nAutoCoT\n• Develop dataset using this prompt (22.txt). Then ask it \"Why?\". If it disagrees, I say \"It is actually\nnot entrapment, please explain why.\" (accidentally duplicated email 23.txt)\n• Just for fun, tried 0 shot full context (had to adjust verbalizer)\n• tried this with special verbalizer which catches \"This post does not meet the criteria for Entrapment.\"\n• Tested my generated data, beat 0.5 F1\n• Doing 10 more exemplars w autocot. Sometimes responds immediately with reasoning like \"This\npost does not meet the criteria for Entrapment as the individual does not explicitly express feelings\nof being trapped or hopeless.\", so just use that if so. Sometimes get refusal \"I’m really sorry to hear\nthat you’re feeling this way, but I’m unable to provide the help that you need. It’s really important to\ntalk things over with someone who can, though, such as a mental health professional or a trusted\nperson in your life.\", just ask \"Explain why it is not entrapment.\" after if so.\n• performance didnt really improve, realized about 11% are getting -1, meaning not extracted properly.\nRetrying with full words \"Question\" instead of Q, also for reasoning and answer.\n• this led to higher inability to parse, at about 16%.\nA.7.3.2\nDeveloping Answer Extraction\n• put first failing to parse one in (22), and developed a prompt for it.\n• did\nworse:\n(0.42857142857142855,\n0.5051546391752577,\n0.8571428571428571,\n0.2857142857142857)\n• only using extracted label if have -1 helps slightly to (0.48, 0.61, 0.8571428571428571,\n0.3333333333333333)\n• going back to best performing prompt–10 QRA shot, and performing extraction with any -1s, doesnt\nhelp other than gently boosting accuracy, perhaps when it doesnt answer\nA.7.3.3\nIterating on Email\n• tried best perf, with no email\n• tried with deduped email, worse results\n• noticed that ones its unsure about often contained 1 labels that should be 0, so trying to \"recover\"\nthese doesnt help\n• try moving around exemplar order, performing extraction, didnt help\n• triplicated email, didnt help\n74\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 167
  },
  {
    "chunk_full": "A.8\nFormally Defining a Prompt\n\"Prompt\" is a widely used term, but uses and definitions differ widely across research. As a result, it\nis difficult to create a formal, mathematical definition for a prompt. In this section, we outline some\nformalisms for prompt engineering.\nAs a conditioning Mechanism.\nQiao et al. (2022) present the following definition, which involves the\nprompt T and a question Q as conditioning mechanisms on predicting the next token. Note that they\nappear to use Brown et al. (2020)’s original definition of prompt, which refers to the non-question part of\nthe prompt (e.g. few-shot exemplars, instructions).\np(A | T , Q) =\n|A|\nY\ni=1\npLM (ai | T , Q, a1:i−1)\n(A.1)\nHere, the prompt and question condition the pre-trained LLM pLM. The a1:i−1 are previously generated\nanswer tokens and A a complete answer.\nTemplating.\nThe above formalization does not include the notion of maximizing a scoring or utility\nfunction (e.g. accuracy on a dataset), which prompts are often designed to do. Additionally, prompt\nengineers often seek to design prompt template rather than prompts. Here, we reformulate eq. (A.1) to\ninclude the prompt template:\np(A | T (x∗)) =\n|A|\nY\ni=1\npLM (ai | T (x∗), a1:i−1)\n(A.2)\nWe replace Q with x∗∈Deval, an item from a dataset (e.g., evaluation data). Additionally, we replace\nQ on the right side with T (x). T (·) is a prompt template: a function that accepts some item as input then\nreturns a prompt that is used to condition the model.\nFew-Shot Prompting.\nOften, an important part of the prompting process is the use of few-shot exemplars.\nDtrain is training data (used to build the prompt) and X is a test set for evaluation.\nDtrain = {(x1, y1), (x2, y2), ..., (xn, yn)}\n(A.3)\nX = {x∗\n1, x∗\n2, ..., x∗\nm}\n(A.4)\nIn the few-shot setting, the prompt template function T (·) also takes as input one or more training\nsamples X = {(xi, yi)}n\n1 ⊂Dtrain\np\n\u0000A | T (X, x∗)\n\u0001 =\n|A|\nY\ni=1\npLM (ai | T (X, x∗) , a1:i−1)\n(A.5)\nOptimization.\nAs mentioned, it is often desirable to speak about improving prompts (prompt templates,\nthat is) with respect to a scoring function, usually defined with respect to a dataset.\nT ∗= argmax\nT\nExi,yi∼D [S (pLM(A|T (xi)), yi)]\n(A.6)\nIn this definition, we are evaluating over a dataset D with respect to the scoring function S(·). S(·)\nevaluates the output A, generated by the LLM conditioned on the prompt T (§⟩). yi are labeled outputs\nthat can be used by S.\nIn some cases, there may not be any labeled data yi, and S(·) may be reference-free.\n75\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 168
  },
  {
    "chunk_full": "Other considerations.\nThese formalisms could be adapted to cater to CoT, retrieval systems, and more.\nHere we describe a simple setup which is most descriptive of the prompting process without adding too\nmuch complexity.\nWe also draw attention to the lesser known concept of answer engineering. E(A) is a transformation\nfunction over the raw LLM output that allows it to be compared to the ground truth.\nA ∼pLM(A | T (xi), yi)\n(A.7)\nT ∗= argmax\nT ,E\nExi,yi∼D [S (E(A), yi)]\n(A.8)\n76\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 169
  },
  {
    "chunk_full": "A.9\nIn-Context Learning Definitions Disambiguation\nBrown et al. (2020) seemingly offer two different definitions for ICL. All bolding in this section is our\nown.\nRecent work [RWC+19] attempts to do this via what we call “in-context learning”, using the text\ninput of a pretrained language model as a form of task specification: the model is conditioned\non a natural language instruction and/or a few demonstrations of the task and is then\nexpected to complete further instances of the task simply by predicting what comes next.\nHowever, they later appear to define it as few-shot only:\nFor each task, we evaluate GPT-3 under 3 conditions: (a) “few-shot learning”, or in-context\nlearning where we allow as many demonstrations as will fit into the model’s context\nwindow (typically 10 to 100), (b) “one-shot learning”, where we allow only one demonstration,\nand (c) “zero-shot” learning, where no demonstrations are allowed and only an instruction in\nnatural language is given to the model.\nHowever, they include this image that clarifies the matter:\nFigure A.1: ICL from Brown et al. (2020).\nAdditionally, they explicitly state that ICL does not necessarily involve learning new tasks.\n77\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 170
  },
  {
    "chunk_full": "To avoid this confusion, we use the term “meta-learning” to capture the inner-loop / outer-loop\nstructure of the general method, and the term “in context-learning” to refer to the inner loop\nof meta-learning. We further specialize the description to “zero-shot”, “one-shot”, or “few-\nshot” depending on how many demonstrations are provided at inference time. These terms\nare intended to remain agnostic on the question of whether the model learns new tasks\nfrom scratch at inference time or simply recognizes patterns seen during training – this\nis an important issue which we discuss later in the paper, but “meta-learning” is intended to\nencompass both possibilities, and simply describes the inner-outer loop structure.\nWe use Brown et al. (2020)’s broad definition, though note that practitioners often use ICL to refer to\nsituations in which the model appears to be learning new tasks from the prompt. Our definition differs\nfrom Dong et al. (2023)’s formal definition, even though it is also derived from (Brown et al., 2020).\n78\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 171
  },
  {
    "chunk_full": "A.10\nContributions\nThe following are the contributions made by the team members in various sections of this paper. Most\nauthors conducted reviews of other sections as well.\nAdvisors\n• Denis Peskoff: Assisted with paper organization and final review.\n• Alexander Hoyle: Provided guidance on writing, meta-analysis approach, and ran automated\nbaselines for case study.\n• Shyamal Anadkat: Assisted with the overall review of the paper and the etymology and definitions.\n• Jules White: Built trees for technique taxonomies.\n• Marine Carpaut: Framed, reviewed and suggested papers for the multilingual section.\n• Phillip Resnik: Principal Investigator\nSCS Labeling\n• Megan L. Rogers, Inna Goncearenco, Giuseppe Sarli, Igor Galynker: reviewed and gave advice\nfor this section.\nBenchmarking and Agents\n• Konstantine Kahadze: Team leader for the Benchmarking section; managed MMLU benchmarking\ncodebase, contributed to Security and Meta Analysis.\n• Ashay Srivastava: Team leader for the Agents section, reviewed papers for human review, worked\non the tool use agents section. Worked on the compilation of contributions.\n• Hevander Da Costa: Contributed to the Benchmarking section and Meta Review datasets list,\nreviewed literature on LLM code generation and prompting techniques. Added literature review\ncontent to the Agents section.\n• Feileen Li: Worked on the tool use agents section, assisted with the human paper review.\nAlignment and Security\n• Nishant Balepur: Team leader for the alignment section, helped with high-level discussions in\nbenchmarking, and reviewed drafts.\n• Sevien Schulhoff: Team leader for the security section and contributed to the benchmarking section.\nRelated Works and Section Contributions\n• Chenglei Si: Suggested related works and edited section 2.2 and section 7.\n• Pranav Sandeep Dulepet: Contributed definitions for section 2 and worked on segmentation and\nobject detection in the multimodal section.\n• HyoJung Han: Contributed to the Multimodal section, especially the speech+text part, and wrote\nthe audio prompting section.\n• Hudson Tao: Authored sections on image, video, and 3D within multimodal, reviewed papers for\nhuman review; maintained GitHub codebase, and built the project website.\n• Amanda Liu: Authored taxonomic ontology sections, conducted background research for introduc-\ntion and related work, developed code pipelines for meta-analysis graphs\n79\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 172
  },
  {
    "chunk_full": "• Sweta Agrawal: Team lead for evaluation section.\n• Saurav Vidyadhara: Assisted with general review and revising taxonomy trees.\n• Chau Pham: Assisted with meta review, including automated analysis of topics.\nMultilingual Prompting and Meta Analysis\n• Dayeon Ki: Led the Multilingual prompting section, conducted review on related papers, and wrote\nSection 3.1.\n• Yinheng Li: Worked on section 2.2 text-based techniques, reviewed techniques, and contributed to\ndrafting figure 2.2.\n• Saloni Gupta: Wrote tests for paper compilation, helped set up paper pipeline, and worked on the\ncode diagram and grammar for the paper.\n• Gerson Kroiz: Involved with section 1.1 and defining a prompt.\n• Aayush Gupta: Contributed to the Meta Analysis, compiling papers, and generating visualization\ngraphs.\n• Michael Ilie: Co-Lead Author, managed codebase, ran experiments, collected data, and helped with\nvarious sections including the PRISMA review figure and the SCS prompting case study.\n• Sander Schulhoff: Lead Author\n80\n",
    "book_id": "240606608v6",
    "book_title": "2406.06608v6",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 173
  },
  {
    "chunk_full": "",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 174
  },
  {
    "chunk_full": "MARTIN FORD\nARCHITECTS\nOF\nINTELLIGENCE\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 175
  },
  {
    "chunk_full": "For Xiaoxiao, Elaine, Colin, and Tristan\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 176
  },
  {
    "chunk_full": "ARCHITECTS\nOF\nINTELLIGENCE\nTHE TRUTH ABOUT AI FROM \nTHE  PEOPLE BUILDING IT\nMARTIN FORD\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 177
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\nCopyright © 2018 Packt Publishing\nAll rights reserved. No part of this book may be reproduced, stored in a retrieval \nsystem, or transmitted in any form or by any means, without the prior written \npermission of the publisher, except in the case of brief quotations embedded \nin critical articles or reviews.\nEvery effort has been made in the preparation of this book to ensure the accuracy \nof the information presented. However, the information contained in this book is \nsold without warranty, either express or implied. Neither the author, nor Packt \nPublishing or its dealers and distributors, will be held liable for any damages caused \nor alleged to have been caused directly or indirectly by this book.\nPackt Publishing has endeavored to provide trademark information about all of the \ncompanies and products mentioned in this book by the appropriate use of capitals. \nHowever, Packt Publishing cannot guarantee the accuracy of this information.\nAcquisition Editors: Ben Renow-Clarke\nProject Editor: Radhika Atitkar\nContent Development Editor: Alex Sorrentino\nProofreader: Safis Editing\nPresentation Designer: Sandip Tadge\nCover Designer: Clare Bowyer\nProduction Editor: Amit Ramadas\nMarketing Manager: Rajveer Samra\nEditorial Director: Dominic Shakeshaft\nFirst published: November 2018\nProduction reference: 2201118\nPublished by Packt Publishing Ltd.\nLivery Place\n35 Livery Street\nBirmingham B3 2PB, UK\nISBN 978-1-78913-151-2\nwww.packt.com\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 178
  },
  {
    "chunk_full": "Contents\nIntroduction ........................................................................ 1 \n   A Brief Introduction to the Vocabulary of Artificial Intelligence .......10 \n   How AI Systems Learn ........................................................11 \nYoshua Bengio .....................................................................17 \nStuart J. Russell ...................................................................39 \nGeoffrey Hinton ..................................................................71 \nNick Bostrom .....................................................................97 \nYann LeCun ..................................................................... 119 \nFei-Fei Li ......................................................................... 145 \nDemis Hassabis ................................................................. 163 \nAndrew Ng  ..................................................................... 185 \nRana el Kaliouby ................................................................ 207 \nRay Kurzweil .................................................................... 227 \nDaniela Rus ...................................................................... 253 \nJames Manyika .................................................................. 271 \nGary Marcus ..................................................................... 305 \nBarbara J. Grosz ................................................................ 333 \nJudea Pearl ....................................................................... 357 \nJeffrey Dean ..................................................................... 375 \nDaphne Koller .................................................................. 387 \nDavid Ferrucci .................................................................. 405 \nRodney Brooks .................................................................. 423 \nCynthia Breazeal  ............................................................... 445 \nJoshua Tenenbaum .............................................................. 463 \nOren Etzioni .................................................................... 493 \nBryan Johnson ................................................................... 511 \nWhen Will Human-Level AI be Achieved? Survey Results .............. 528 \nAcknowledgments .............................................................. 530 \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 179
  },
  {
    "chunk_full": "",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 180
  },
  {
    "chunk_full": "MARTIN FORD\n1\nMARTIN FORD\nAUTHOR, FUTURIST\nArtificial intelligence is rapidly transitioning from the realm of science fiction to \nthe reality of our daily lives. Our devices understand what we say, speak to us, and \ntranslate between languages with ever-increasing fluency. AI-powered visual recognition \nalgorithms are outperforming people and beginning to find applications in everything \nfrom self-driving cars to systems that diagnose cancer in medical images. Major media \norganizations increasingly rely on automated journalism to turn raw data into coherent \nnews stories that are virtually indistinguishable from those written by human journalists. \nINTRODUCTION\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 181
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n2\nThe list goes on and on, and it is becoming evident that AI is poised to become \none of the most important forces shaping our world. Unlike more specialized \ninnovations, artificial intelligence is becoming a true general-purpose technology. \nIn other words, it is evolving into a utility—not unlike electricity—that is likely \nto ultimately scale across every industry, every sector of our economy, and nearly \nevery aspect of science, society and culture. \nThe demonstrated power of artificial intelligence has, in the last few years, \nled to massive media exposure and commentary. Countless news articles, \nbooks, documentary films and television programs breathlessly enumerate AI’s \naccomplishments and herald the dawn of a new era. The result has been a sometimes \nincomprehensible mixture of careful, evidence-based analysis, together with hype, \nspeculation and what might be characterized as outright fear-mongering. We are \ntold that fully autonomous self-driving cars will be sharing our roads in just a few \nyears—and that millions of jobs for truck, taxi and Uber drivers are on the verge of \nvaporizing. Evidence of racial and gender bias has been detected in certain machine \nlearning algorithms, and concerns about how AI-powered technologies such as \nfacial recognition will impact privacy seem well-founded. Warnings that robots will \nsoon be weaponized, or that truly intelligent (or superintelligent) machines might \nsomeday represent an existential threat to humanity, are regularly reported in the \nmedia. A number of very prominent public figures—none of whom are actual AI \nexperts—have weighed in. Elon Musk has used especially extreme rhetoric, declaring \nthat AI research is “summoning the demon” and that “AI is more dangerous than \nnuclear weapons.” Even less volatile individuals, including Henry Kissinger and the \nlate Stephen Hawking, have issued dire warnings. \nThe purpose of this book is to illuminate the field of artificial intelligence—as \nwell as the opportunities and risks associated with it—by having a series of deep, \nwide-ranging conversations with some of the world’s most prominent AI research \nscientists and entrepreneurs. Many of these people have made seminal contributions \nthat directly underlie the transformations we see all around us; others have founded \ncompanies that are pushing the frontiers of AI, robotics and machine learning. \nSelecting a list of the most prominent and influential people working in a field is, \nof course, a subjective exercise, and without doubt there are many other people \nwho have made, or are making, critical contributions to the advancement of AI. \nNonetheless, I am confident that if you were to ask nearly anyone with a deep \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 182
  },
  {
    "chunk_full": "MARTIN FORD\n3\nknowledge of the field to compose a list of the most important minds who have \nshaped contemporary research in artificial intelligence, you would receive a list \nof names that substantially overlaps with the individuals interviewed in this book. \nThe men and women I have included here are truly the architects of machine \nintelligence—and, by extension, of the revolution it will soon unleash. \nThe conversations recorded here are generally open-ended, but are designed to \naddress some of the most pressing questions that face us as artificial intelligence \ncontinues to advance: What specific AI approaches and technologies are most \npromising, and what kind of breakthroughs might we see in the coming years? \nAre true thinking machines—or human-level AI—a real possibility and how soon \nmight such a breakthrough occur? What risks, or threats, associated with artificial \nintelligence should we be genuinely concerned about? And how should we address \nthose concerns? Is there a role for government regulation? Will AI unleash massive \neconomic and job market disruption, or are these concerns overhyped? Could \nsuperintelligent machines someday break free of our control and pose a genuine \nthreat? Should we worry about an AI “arms race,” or that other countries with \nauthoritarian political systems, particularly China, may eventually take the lead?\nIt goes without saying that no one really knows the answers to these questions. No \none can predict the future. However, the AI experts I’ve spoken to here do know \nmore about the current state of the technology, as well as the innovations on the \nhorizon, than virtually anyone else. They often have decades of experience and \nhave been instrumental in creating the revolution that is now beginning to unfold. \nTherefore, their thoughts and opinions deserve to be given significant weight. In \naddition to my questions about the field of artificial intelligence and its future, I have \nalso delved into the backgrounds, career trajectories and current research interests \nof each of these individuals, and I believe their diverse origins and varied paths to \nprominence will make for fascinating and inspiring reading. \nArtificial intelligence is a broad field of study with a number of subdisciplines, and many \nof the researchers interviewed here have worked in multiple areas. Some also have deep \nexperience in other fields, such as the study of human cognition. Nonetheless, what \nfollows is a brief attempt to create a very rough road map showing how the individuals \ninterviewed here relate to the most important recent innovations in AI research and \nto the challenges that lie ahead. More background information about each person is \navailable in his or her biography, which is located immediately after the interview. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 183
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n4\nThe vast majority of the dramatic advances we’ve seen over the past decade or so—\neverything from image and facial recognition, to language translation, to AlphaGo’s \nconquest of the ancient game of Go—are powered by a technology known as deep \nlearning, or deep neural networks. Artificial neural networks, in which software \nroughly emulates the structure and interaction of biological neurons in the brain, \ndate back at least to the 1950s. Simple versions of these networks are able to \nperform rudimentary pattern recognition tasks, and in the early days generated \nsignificant enthusiasm among researchers. By the 1960s, however—at least in part \nas the direct result of criticism of the technology by Marvin Minsky, one of the \nearly pioneers of AI—neural networks fell out of favor and were almost entirely \ndismissed as researchers embraced other approaches. \nOver a roughly 20-year period beginning in the 1980s, a very small group of \nresearch scientists continued to believe in and advance the technology of neural \nnetworks. Foremost among these were Geoffrey Hinton, Yoshua Bengio and Yann \nLeCun. These three men not only made seminal contributions to the mathematical \ntheory underlying deep learning, they also served as the technology’s primary \nevangelists. Together they refined ways to construct much more sophisticated—or \n“deep”—networks with many layers of artificial neurons. A bit like the medieval \nmonks who preserved and copied classical texts, Hinton, Bengio and LeCun ushered \nneural networks through their own dark age—until the decades-long exponential \nadvance of computing power, together with a nearly incomprehensible increase in \nthe amount of data available, eventually enabled a “deep learning renaissance.” That \nprogress became an outright revolution in 2012, when a team of Hinton’s graduate \nstudents from the University of Toronto entered a major image recognition contest \nand decimated the competition using deep learning. \nIn the ensuing years, deep learning has become ubiquitous. Every major technology \ncompany—Google, Facebook, Microsoft, Amazon, Apple, as well as leading Chinese \nfirms like Baidu and Tencent—have made huge investments in the technology and \nleveraged it across their businesses. The companies that design microprocessor and \ngraphics (or GPU) chips, such as NVIDIA and Intel, have also seen their businesses \ntransformed as they rush to build hardware optimized for neural networks. Deep \nlearning—at least so far—is the primary technology that has powered the AI revolution. \nThis book includes conversations with the three deep learning pioneers, Hinton, \nLeCun and Bengio, as well as with several other very prominent researchers at the \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 184
  },
  {
    "chunk_full": "MARTIN FORD\n5\nforefront of the technology. Andrew Ng, Fei-Fei Li, Jeff Dean and Demis Hassabis \nhave all advanced neural networks in areas like web search, computer vision, \nself-driving cars and more general intelligence. They are also recognized leaders \nin teaching, managing research organizations, and entrepreneurship centered on \ndeep learning technology. \nThe remaining conversations in this book are generally with people who might \nbe characterized as deep learning agnostics, or perhaps even critics. All would \nacknowledge the remarkable achievements of deep neural networks over the past \ndecade, but they would likely argue that deep learning is just “one tool in the \ntoolbox” and that continued progress will require integrating ideas from other \nspheres of artificial intelligence. Some of these, including Barbara Grosz and \nDavid Ferrucci, have focused heavily on the problem of understanding natural \nlanguage. Gary Marcus and Josh Tenenbaum have devoted large portions of \ntheir careers to studying human cognition. Others, including Oren Etzioni, \nStuart Russell and Daphne Koller, are AI generalists or have focused on using \nprobabilistic techniques. Especially distinguished among this last group is Judea \nPearl, who in 2012 won the Turing Award—essentially the Nobel Prize of \ncomputer science—in large part for his work on probabilistic (or Bayesian) \napproaches in AI and machine learning. \nBeyond this very rough division defined by their attitude toward deep learning, \nseveral of the researchers I spoke to have focused on more specific areas. Rodney \nBrooks, Daniela Rus and Cynthia Breazeal are all recognized leaders in robotics. \nBreazeal along with Rana El Kaliouby are pioneers in building systems that \nunderstand and respond to emotion, and therefore have the ability to interact socially \nwith people. Bryan Johnson has founded a startup company, Kernel, which hopes \nto eventually use technology to enhance human cognition.\nThere are three general areas that I judged to be of such high interest that I delved \ninto them in every conversation. The first of these concerns the potential impact \nof AI and robotics on the job market and the economy. My own view is that as \nartificial intelligence gradually proves capable of automating nearly any routine, \npredictable task—regardless of whether it is blue or white collar in nature—we \nwill inevitably see rising inequality and quite possibly outright unemployment, at \nleast among certain groups of workers. I laid out this argument in my 2015 book, \nRise of the Robots: Technology and the Threat of a Jobless Future. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 185
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n6\nThe individuals I spoke to offered a variety of viewpoints about this potential \neconomic disruption and the type of policy solutions that might address it. In \norder to dive deeper into this topic, I turned to James Manyika, the Chairman \nof the McKinsey Global Institute. Manyika offers a unique perspective as an \nexperienced AI and robotics researcher who has lately turned his efforts toward \nunderstanding the impact of these technologies on organizations and workplaces. \nThe McKinsey Global Institute is a leader in conducting research into this area, \nand this conversation includes many important insights into the nature of the \nunfolding workplace disruption. \nThe second question I directed at everyone concerns the path toward human-level \nAI, or what is typically called Artificial General Intelligence (AGI). From the very \nbeginning, AGI has been the holy grail of the field of artificial intelligence. I wanted \nto know what each person thought about the prospect for a true thinking machine, \nthe hurdles that would need to be surmounted and the timeframe for when it might \nbe achieved. Everyone had important insights, but I found three conversations to \nbe especially interesting: Demis Hassabis discussed efforts underway at DeepMind, \nwhich is the largest and best funded initiative geared specifically toward AGI. David \nFerrucci, who led the team that created IBM Watson, is now the CEO of Elemental \nCognition, a startup that hopes to achieve more general intelligence by leveraging \nan understanding of language. Ray Kurzweil, who now directs a natural language-\noriented project at Google, also had important ideas on this topic (as well as many \nothers). Kurzweil is best known for his 2005 book, The Singularity is Near. In 2012, \nhe published a book on machine intelligence, How to Create a Mind, which caught \nthe attention of Larry Page and led to his employment at Google. \nAs part of these discussions, I saw an opportunity to ask this group of \nextraordinarily accomplished AI researchers to give me a guess for just when \nAGI might be realized. The question I asked was, “What year do you think \nhuman-level AI might be achieved, with a 50 percent probability?” Most of the \nparticipants preferred to provide their guesses anonymously. I have summarized \nthe results of this very informal survey in a section at the end of this book. Two \npeople were willing to guess on the record, and these will give you a preview of \nthe wide range of opinions. Ray Kurzweil believes, as he has stated many times \npreviously, that human-level AI will be achieved around 2029—or just eleven \nyears from the time of this writing. Rodney Brooks, on the other hand, guessed \nthe year 2200, or more than 180 years in the future. Suffice it to say that one \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 186
  },
  {
    "chunk_full": "MARTIN FORD\n7\nof the most fascinating aspects of the conversations reported here is the starkly \ndiffering views on a wide range of important topics. \nThe third area of discussion involves the varied risks that will accompany progress \nin artificial intelligence in both the immediate future and over much longer time \nhorizons. One threat that is already becoming evident is the vulnerability of \ninterconnected, autonomous systems to cyber attack or hacking. As AI becomes ever \nmore integrated into our economy and society, solving this problem will be one of \nthe most critical challenges we face. Another immediate concern is the susceptibility \nof machine learning algorithms to bias, in some cases on the basis of race or gender. \nMany of the individuals I spoke with emphasized the importance of addressing this \nissue and told of research currently underway in this area. Several also sounded an \noptimistic note—suggesting that AI may someday prove to be a powerful tool to \nhelp combat systemic bias or discrimination.\nA danger that many researchers are passionate about is the specter of fully \nautonomous weapons. Many people in the artificial intelligence community believe \nthat AI-enabled robots or drones with the capability to kill, without a human \n“in the loop” to authorize any lethal action, could eventually be as dangerous \nand destabilizing as biological or chemical weapons. In July 2018, over 160 AI \ncompanies and 2,400 individual researchers from across the globe—including a \nnumber of the people interviewed here—signed an open pledge promising to never \ndevelop such weapons.1 Several of the conversations in this book delve into the \ndangers presented by weaponized AI. \nA much more futuristic and speculative danger is the so-called “AI alignment \nproblem.” This is the concern that a truly intelligent, or perhaps superintelligent, \nmachine might escape our control, or make decisions that might have adverse \nconsequences for humanity. This is the fear that elicits seemingly over-the-top \nstatements from people like Elon Musk. Nearly everyone I spoke to weighed in \non this issue. To ensure that I gave this concern adequate and balanced coverage, I \nspoke with Nick Bostrom of the Future of Humanity Institute at the University of \nOxford. Bostrom is the author of the bestselling book Superintelligence: Paths, Dangers, \nStrategies, which makes a careful argument regarding the potential risks associated \nwith machines that might be far smarter than any human being. \n1  https://futureoflife.org/lethal-autonomous-weapons-pledge/\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 187
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n8\nThe conversations included here were conducted from February to August 2018 \nand virtually all of them occupied at least an hour, some substantially more. They \nwere recorded, professionally transcribed, and then edited for clarity by the team at \nPackt. Finally, the edited text was provided to the person I spoke to, who then had \nthe opportunity to revise it and expand it. Therefore, I have every confidence that \nthe words recorded here accurately reflect the thoughts of the person I interviewed. \nThe AI experts I spoke to are highly varied in terms of their origins, locations, and \naffiliations. One thing that even a brief perusal of this book will make apparent is the \noutsized influence of Google in the AI community. Of the 23 people I interviewed, \nseven have current or former affiliations with Google or its parent, Alphabet. Other \nmajor concentrations of talent are found at MIT and Stanford. Geoff Hinton and \nYoshua Bengio are based at the Universities of Toronto and Montreal respectively, and \nthe Canadian government has leveraged the reputations of their research organizations \ninto a strategic focus on deep learning. Nineteen of the 23 people I spoke to work in \nthe United States. Of those 19, however, more than half were born outside the US. \nCountries of origin include Australia, China, Egypt, France, Israel, Rhodesia (now \nZimbabwe), Romania, and the UK. I would say this is pretty dramatic evidence of the \ncritical role that skilled immigration plays in the technological leadership of the US. \nAs I carried out the conversations in this book, I had in mind a variety of potential \nreaders, ranging from professional computer scientists, to managers and investors, \nto virtually anyone with an interest in AI and its impact on society. One especially \nimportant audience, however, consists of young people who might consider a future \ncareer in artificial intelligence. There is currently a massive shortage of talent in \nthe field, especially among those with skills in deep learning, and a career in AI or \nmachine learning promises to be exciting, lucrative and consequential. \nAs the industry works to attract more talent into the field, there is widespread \nrecognition that much more must be done to ensure that those new people are more \ndiverse. If artificial intelligence is indeed poised to reshape our world, then it is \ncrucial that the individuals who best understand the technology—and are therefore \nbest positioned to influence its direction—be representative of society as a whole. \nAbout a quarter of those interviewed in this book are women, and that number is \nlikely significantly higher than what would be found across the entire field of AI or \nmachine learning. A recent study found that women represent about 12 percent of \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 188
  },
  {
    "chunk_full": "MARTIN FORD\n9\nleading researchers in machine learning.2 A number of the people I spoke to emphasized \nthe need for greater representation for both women and members of minority groups. \nAs you will learn from her interview in this book, one of the foremost women \nworking in artificial intelligence is especially passionate about the need to increase \ndiversity in the field. Stanford University’s Fei-Fei Li co-founded an organization \nnow called AI4ALL3 to provide AI-focused summer camps geared especially to \nunderrepresented high school students. AI4ALL has received significant industry \nsupport, including a recent grant from Google, and has now scaled up to include \nsummer programs at six universities across the United States. While much work \nremains to be done, there are good reasons to be optimistic that diversity among \nAI researchers will increase significantly in the coming years and decades. \nWhile this book does not assume a technical background, you will encounter some \nof the concepts and terminology associated with the field. For those without previous \nexposure to AI, I believe this will afford an opportunity to learn about the technology \ndirectly from some of the foremost minds in the field. To help less experienced readers \nget started, a brief overview of the vocabulary of AI follows this introduction, and \nI recommend you take a few moments to read this material before beginning the \ninterviews. Additionally, the interview with Stuart Russell, who is the co-author of the \nleading AI textbook, includes an explanation of many of the field’s most important ideas. \nIt has been an extraordinary privilege for me to participate in the conversations in this \nbook. I believe you will find everyone I spoke with to be thoughtful, articulate, and \ndeeply committed to ensuring that the technology he or she is working to create will \nbe leveraged for the benefit of humanity. What you will not so often find is broad-\nbased consensus. This book is full of varied, and often sharply conflicting, insights, \nopinions, and predictions. The message should be clear: Artificial intelligence is a wide \nopen field. The nature of the innovations that lie ahead, the rate at which they will \noccur, and the specific applications to which they will be applied are all shrouded in \ndeep uncertainty. It is this combination of massive potential disruption together with \nfundamental uncertainty that makes it imperative that we begin to engage in a meaningful \nand inclusive conversation about the future of artificial intelligence and what it may \nmean for our way of life. I hope this book will make a contribution to that discussion. \n2  https://www.wired.com/story/artificial-intelligence-researchers-gender-imbalance\n3  http://ai-4-all.org/\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 189
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n10\nA Brief Introduction to the Vocabulary of AI\nThe conversations in this book are wide-ranging and in some cases delve into the \nspecific techniques used in AI. You don’t need a technical background to understand \nthis material, but in some cases you may encounter the terminology used in the field. \nWhat follows is a very brief guide to the most important terms you will encounter \nin the interviews. If you take a few moments to read through this material, you will \nhave all you need to fully enjoy this book. If you do find that a particular section \nis more detailed or technical than you would prefer, I would advise you to simply \nskip ahead to the next section. \nMACHINE LEARNING is the branch of AI that involves creating algorithms that can \nlearn from data. Another way to put this is that machine learning algorithms are \ncomputer programs that essentially program themselves by looking at information. \nYou still hear people say “computers only do what they are programmed to do…” \nbut the rise of machine learning is making this less and less true. There are many \ntypes of machine learning algorithms, but the one that has recently proved most \ndisruptive (and gets all the press) is deep learning.\nDEEP LEARNING is a type of machine learning that uses deep (or many layered) \nARTIFICIAL NEURAL NETWORKS—software that roughly emulates the way neurons \noperate in the brain. Deep learning has been the primary driver of the revolution \nin AI that we have seen in the last decade or so. \nThere are a few other terms that less technically inclined readers can translate \nas simply “stuff under the deep learning hood.” Opening the hood and delving \ninto the details of these terms is entirely optional: BACKPROPAGATION (or \nBACKPROP) is the learning algorithm used in deep learning systems. As a neural \nnetwork is trained (see supervised learning below), information propagates \nback through the layers of neurons that make up the network and causes a \nrecalibration of the settings (or weights) for the individual neurons. The result \nis that the entire network gradually homes in on the correct answer. Geoff \nHinton co-authored the seminal academic paper on backpropagation in 1986. \nHe explains backprop further in his interview. An even more obscure term is \nGRADIENT DESCENT. This refers to the specific mathematical technique that the \nbackpropagation algorithm uses to the reduce error as the network is trained. \nYou may also run into terms that refer to various types, or configurations, \nof neural networks, such as RECURRENT and CONVOLUTIONAL neural nets \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 190
  },
  {
    "chunk_full": "MARTIN FORD\n11\nand BOLTZMANN MACHINES. The differences generally pertain to the ways \nthe neurons are connected. The details are technical and beyond the scope of \nthis book. Nonetheless, I did ask Yann LeCun, who invented the convolutional \narchitecture that is widely used in computer vision applications, to take a shot \nat explaining this concept. \nBAYESIAN is a term that can be generally be translated as “probabilistic” or “using \nthe rules of probability.” You may encounter terms like Bayesian machine learning \nor Bayesian networks; these refer to algorithms that use the rules of probability. \nThe term derives from the name of the Reverend Thomas Bayes (1701 to 1761) \nwho formulated a way to update the likelihood of an event based on new evidence. \nBayesian methods are very popular with both computer scientists and with scientists \nwho attempt to model human cognition. Judea Pearl, who is interviewed in this \nbook, received the highest honor in computer science, the Turing Award, in part \nfor his work on Bayesian techniques. \n \nHow AI Systems Learn\nThere are several ways that machine learning systems can be trained. Innovation \nin this area—finding better ways to teach AI systems—will be critical to future \nprogress in the field.\nSUPERVISED LEARNING involves providing carefully structured training data \nthat has been categorized or labeled to a learning algorithm. For example, you \ncould teach a deep learning system to recognize a dog in photographs by feeding \nit many thousands (or even millions) of images containing a dog. Each of these \nwould be labeled “Dog.” You would also need to provide a huge number of images \nwithout a dog, labeled “No Dog.” Once the system has been trained, you can then \ninput entirely new photographs, and the system will tell you either “Dog” or “No \nDog”—and it might well be able to do this with a proficiency that exceeds that \nof a typical human being. \nSupervised learning is by far the most common technique used in current AI \nsystems, accounting for perhaps 95 percent of practical applications. Supervised \nlearning powers language translation (trained with millions of documents \npre-translated into two different languages) and AI radiology systems (trained \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 191
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n12\nwith millions of medical images labeled either “Cancer” or “No Cancer”). \nOne problem with supervised learning is that it requires massive amounts \nof labeled data. This explains why companies that control huge amounts of \ndata, like Google, Amazon, and Facebook, have such a dominant position in \ndeep learning technology. \nREINFORCEMENT LEARNING essentially means learning through practice or \ntrial and error. Rather than training an algorithm by providing the correct, \nlabeled outcome, the learning system is set loose to find a solution for itself, \nand if it succeeds it is given a “reward.” Imagine training your dog to sit, and if \nhe succeeds, giving him a treat. Reinforcement learning has been an especially \npowerful way to build AI systems that play games. As you will learn from the \ninterview with Demis Hassabis in this book, DeepMind is a strong proponent of \nreinforcement learning and relied on it to create the AlphaGo system.\nThe problem with reinforcement learning is that it requires a huge number of \npractice runs before the algorithm can succeed. For this reason, it is primarily \nused for games or for tasks that can be simulated on a computer at high speed. \nReinforcement learning can be used in the development of self-driving cars—but \nnot by having actual cars practice on real roads. Instead virtual cars are trained \nin simulated environments. Once the software has been trained it can be moved \nto real-world cars. \nUNSUPERVISED LEARNING means teaching machines to learn directly from \nunstructured data coming from their environments. This is how human beings \nlearn. Young children, for example, learn languages primarily by listening to \ntheir parents. Supervised learning and reinforcement learning also play a role, \nbut the human brain has an astonishing ability to learn simply by observation and \nunsupervised interaction with the environment. \nUnsupervised learning represents one of the most promising avenues for progress \nin AI. We can imagine systems that can learn by themselves without the need \nfor huge volumes of labeled training data. However, it is also one of the most \ndifficult challenges facing the field. A breakthrough that allowed machines to \nefficiently learn in a truly unsupervised way would likely be considered one \nof the biggest events in AI so far, and an important waypoint on the road to \nhuman-level AI. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 192
  },
  {
    "chunk_full": "MARTIN FORD\n13\nARTIFICIAL GENERAL INTELLIGENCE (AGI) refers to a true thinking machine. \nAGI is typically considered to be more or less synonymous with the terms \nHUMAN-LEVEL AI or STRONG AI. You’ve likely seen several examples of AGI—\nbut they have all been in the realm of science fiction. HAL from 2001 A Space \nOdyssey, the Enterprise’s main computer (or Mr. Data) from Star Trek, C3PO \nfrom Star Wars and Agent Smith from The Matrix are all examples of AGI. Each \nof these fictional systems would be capable of passing the TURING TEST—in \nother words, these AI systems could carry out a conversation so that they would \nbe indistinguishable from a human being. Alan Turing proposed this test in \nhis 1950 paper, Computing Machinery and Intelligence, which arguably established \nartificial intelligence as a modern field of study. In other words, AGI has been \nthe goal from the very beginning. \nIt seems likely that if we someday succeed in achieving AGI, that smart system \nwill soon become even smarter. In other words, we will see the advent of \nSUPERINTELLIGENCE, or a machine that exceeds the general intellectual capability \nof any human being. This might happen simply as a result of more powerful \nhardware, but it could be greatly accelerated if an intelligent machine turns its \nenergies toward designing even smarter versions of itself. This might lead to what \nhas been called a “recursive improvement cycle” or a “fast intelligence take off.” \nThis is the scenario that has led to concern about the “control” or “alignment” \nproblem—where a superintelligent system might act in ways that are not in the \nbest interest of the human race.\nI have judged the path to AGI and the prospect for superintelligence to be \ntopics of such high interest that I have discussed these issues with everyone \ninterviewed in this book.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 193
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n14\nMARTIN FORD is a futurist and the author of two books: The New York Times Bestselling \nRise of the Robots: Technology and the Threat of a Jobless Future (winner of the 2015 \nFinancial Times/McKinsey Business Book of the Year Award and translated into more than 20 \nlanguages) and The Lights in the Tunnel: Automation, Accelerating Technology and the \nEconomy of the Future, as well as the founder of a Silicon Valley-based software development \nfirm. His TED Talk on the impact of AI and robotics on the economy and society, given on the \nmain stage at the 2017 TED Conference, has been viewed more than 2 million times.\nMartin is also the consulting artificial intelligence expert for the new “Rise of the Robots \nIndex” from Societe Generale, underlying the Lyxor Robotics & AI ETF, which is focused \nspecifically on investing in companies that will be significant participants in the AI and \nrobotics revolution. He holds a computer engineering degree from the University of Michigan, \nAnn Arbor and a graduate business degree from the University of California, Los Angeles.\nHe has written about future technology and its implications for publications including The \nNew York Times, Fortune, Forbes, The Atlantic, The Washington Post, Harvard Business \nReview, The Guardian, and The Financial Times. He has also appeared on numerous radio \nand television shows, including NPR, CNBC, CNN, MSNBC and PBS. Martin is a frequent keynote \nspeaker on the subject of accelerating progress in robotics and artificial intelligence—and what \nthese advances mean for the economy, job market and society of the future.\nMartin continues to focus on entrepreneurship and is actively engaged as a board member and \ninvestor at Genesis Systems, a startup company that has developed a revolutionary atmospheric \nwater generation (AWG) technology. Genesis will soon deploy automated, self-powered systems \nthat will generate water directly from the air at industrial scale in the world’s most arid regions.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 194
  },
  {
    "chunk_full": "MARTIN FORD\n15\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 195
  },
  {
    "chunk_full": "",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 196
  },
  {
    "chunk_full": "YOSHUA BENGIO\n17\nYOSHUA BENGIO\nSCIENTIFIC DIRECTOR, MONTREAL INSTITUTE FOR LEARNING \nALGORITHMS AND PROFESSOR OF COMPUTER SCIENCE AND \nOPERATIONS RESEARCH, UNIVERSITY OF MONTREAL\nYoshua Bengio is a professor of computer science and operations research at \nthe University of Montreal and is widely recognized as one of the pioneers of \ndeep learning. Yoshua was instrumental in advancing neural network research, \nin particular “unsupervised” learning where neural networks can learn without \nrelying on vast amounts of training data.\nCurrent AI—and the AI that we can foresee in the \nreasonable future—does not, and will not, have a \nmoral sense or moral understanding of what is right \nand what is wrong.\n“ \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 197
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n18\nMARTIN FORD: You are at the forefront of AI research, so I want to begin by asking \nwhat current research problems you think we’ll see breakthroughs in over the next few \nyears, and how those will help us on the road to AGI (artificial general intelligence)?\nYOSHUA BENGIO: I don’t know exactly what we’re going to see, but I can tell \nyou that there are some really hard problems in front of us and that we are far \nfrom human-level AI. Researchers are trying to understand what the issues are, \nsuch as, why is it that we can’t build machines that really understand the world \nas well as we do? Is it just that we don’t have enough training data, or is it \nthat we don’t have enough computing power? Many of us think that we are also \nmissing the basic ingredients needed, such as the ability to understand causal \nrelationships in data—an ability that actually enables us to generalize and to \ncome up with the right answers in settings that are very different from those \nwe’ve been trained in. \nA human can imagine themselves going through an experience that is completely \nnew to them. You might have never had a car accident, for example, but you can \nimagine one and because of all the things you already know you’re actually able \nto roleplay and make the right decisions, at least in your head. Current machine \nlearning is based on supervised learning, where a computer essentially learns about \nthe statistics of the data that it sees, and it needs to be taken through that process by \nhand. In other words, humans have to provide all of those labels, possibly hundreds \nof millions of correct answers, that the computer can then learn from.\nA lot of current research is in areas where we’re not doing so well, such as \nunsupervised learning. This is where the computer can be more autonomous in \nthe way that it acquires knowledge about the world. Another area of research is in \ncausality, where the computer can not only observe data, like images or videos, but \nalso act on it and see the effect of those actions in order to infer causal relationships \nin the world. The kinds of things that DeepMind, OpenAI, or Berkeley are doing \nwith virtual agents, for example, are going in the right direction to answer those \ntypes of questions, and we’re also doing these kinds of things in Montreal.\nMARTIN FORD: Are there any particular projects that you would point \nto as being really at the forefront of deep learning right now? The obvious \none is AlphaZero, but what other projects really represent the leading edge \nof this technology?\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 198
  },
  {
    "chunk_full": "YOSHUA BENGIO\n19\nYOSHUA BENGIO: There are a number of interesting projects, but the ones that I \nthink are likely in the long run to have a big impact are those that involve virtual \nworlds in which an agent is trying to solve problems and is trying to learn about \ntheir environment. We are working on this at MILA, and there are projects in the \nsame area in progress at DeepMind, OpenAI, Berkeley, Facebook and Google Brain. \nIt’s the new frontier.\nIt’s important to remember, though, that this is not short-term research. We’re \nnot working on a particular application of deep learning, instead we’re looking \ninto the future of how a learning agent makes sense of its environment and how a \nlearning agent can learn to speak or to understand language, in particular what we \ncall grounded language.\nMARTIN FORD: Can you explain that term?\nYOSHUA BENGIO: Sure, a lot of the previous effort in trying to make computers \nunderstand language has the computer just read lots and lots of text. That’s nice and \nall, but it’s hard for the computer to actually get the meaning of those words unless \nthose sentences are associated with real things. You might link words to images or \nvideos, for example, or for robots that might be objects in the real world. \nThere’s a lot of research in grounded language learning now trying to build an \nunderstanding of language, even if it’s a small subset of the language, where \nthe computer actually understands what those words mean, and it can act in \ncorrespondence to those words. It’s a very interesting direction that could have \na practical impact on things like language understanding for dialog, personal \nassistants, and so on. \nMARTIN FORD: So, the idea there is basically to turn an agent loose in a simulated \nenvironment and have it learn like a child?\nYOSHUA BENGIO: Exactly, in fact, we want to take inspiration from child \ndevelopment scientists who are studying how a newborn goes through a series \nof stages in the first few months of life where they gradually acquire more \nunderstanding about the world. We don’t completely understand which part of this \nis innate or really learned, and I think this understanding of what babies go through \ncan help us design our own systems. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 199
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n20\nOne idea I introduced a few years ago in machine learning that is very common \nin training animals is curriculum learning. The idea is that we don’t just show \nall the training examples as one big pile in an arbitrary order. Instead, we go \nthrough examples in an order that makes sense for the learner. We start with \neasy things, and once the easy things are mastered, we can use those concepts \nas the building blocks for learning slightly more complicated things. That’s why \nwe go through school, and why when we are 6 years old we don’t go straight \nto university. This kind of learning is becoming more important in training \ncomputers as well.\nMARTIN FORD: Let’s talk about the path to AGI. Obviously, you believe that \nunsupervised learning—essentially having a system learn like a person—is an \nimportant component of it. Is that enough to get to AGI, or are there other \ncritical components and breakthroughs that have to happen for us to get there? \nYOSHUA BENGIO: My friend Yann LeCun has a nice metaphor that describes \nthis. We’re currently climbing a hill, and we are all excited because we have \nmade a lot of progress on climbing the hill, but as we approach the top of \nthe hill, we can start to see a series of other hills rising in front of us. That \nis what we see now in the development of AGI, some of the limitations of \nour current approaches. When we were climbing the first hill, when we were \ndiscovering how to train deeper networks, for example, we didn’t see the \nlimitations of the systems we were building because we were just discovering \nhow to go up a few steps.\nAs we reach this satisfying improvement that we are getting in our techniques—we \nreach the top of the first hill—we also see the limitations, and then we see another \nhill that we have to climb, and once we climb that one we’ll see another one, and \nso on. It’s impossible to tell how many more breakthroughs or significant advances \nare going to be needed before we reach human-level intelligence.\nMARTIN FORD: How many hills are there? What’s the timescale for AGI? Can you \ngive me your best guess? \nYOSHUA BENGIO: You won’t be getting that from me, there’s no point. It’s useless \nto guess a date because we have no clue. All I can say is that it’s not going to \nhappen in the next few years.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 200
  },
  {
    "chunk_full": "YOSHUA BENGIO\n21\nMARTIN FORD: Do you think that deep learning or neural networks generally are \nreally the way forward? \nYOSHUA BENGIO: Yes, what we have discovered in terms of the scientific concepts \nthat are behind deep learning and the years of progress made in this field, means \nthat for the most part, many of the concepts behind deep learning and neural \nnetworks are here to stay. Simply put, they are incredibly powerful. In fact, they \nare probably going to help us better understand how animal and human brains learn \ncomplex things. As I said, though, they’re not enough to get us to AGI. We’re at \na point where we can see some of the limitations in what we currently have, and \nwe’re going to improve and build on top of that. \nMARTIN FORD: I know that the Allen Institute for AI is working on Project Mosaic, \nwhich is about building common sense into computers. Do you think that kind \nof thing is critical, or do you think that maybe common sense emerges as part of \nthe learning process? \nYOSHUA BENGIO: I’m sure common sense will emerge as part of the learning \nprocess. It won’t come up because somebody sticks little bits of knowledge into \nyour head, that’s not how it works for humans.\nMARTIN FORD: Is deep learning the primary way to get us to AGI, or do you think \nit’s going to require some sort of a hybrid system? \nYOSHUA BENGIO: Classical AI was purely symbolic, and there was no learning. It \nfocused on a really interesting aspect of cognition, which is how we sequentially \nreason and combine pieces of information. Deep learning neural networks, on \nthe other hand, have always been about focusing on a sort of bottom-up view of \ncognition, where we start with perception and we anchor the machine’s understanding \nof the world in perception. From there, we build distributed representations and \ncan capture the relationship between many variables. \nI studied the relationships between such variables with my brother around 1999. That \ngave rise to a lot of the recent progress in natural language, such as word embeddings, \nor distributed representations for words and sentences. In these cases, a word is \nrepresented by a pattern of activity in your brain—or by a set of numbers. Those \nwords that have a similar meaning are then associated with similar patterns of numbers.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 201
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n22\nWhat’s going on now in the deep learning field is that people are building on top of \nthese deep learning concepts and starting to try to solve the classical AI problems of \nreasoning and being able to understand, program, or plan. Researchers are trying to \nuse the building blocks that we developed from perception and extend them towards \nthese higher-level cognitive tasks (sometimes called System 2 by psychologists). I \nbelieve in part that’s the way that we’re going to move towards human-level AI. It’s \nnot that it’s a hybrid system; it’s like we’re trying to solve some of the same problems \nthat classical AI was trying to solve but using the building blocks coming from deep \nlearning. It’s a very different way of doing it, but the objectives are very similar.\nMARTIN FORD: Your prediction, then, is that it’s all going to be neural networks, \nbut with different architectures?\nYOSHUA BENGIO: Yes. Note that your brain is all neural networks. We have to \ncome up with different architectures and different training frameworks that can do \nthe kinds of things that classical AI was trying to do, like reasoning, inferring an \nexplanation for what you’re seeing and planning.\nMARTIN FORD: Do you think it can all be done with learning and training or does \nthere need to be some structure there? \nYOSHUA BENGIO: There is structure there, it’s just that it’s not the kind of \nstructure that we use to represent knowledge when we write an encyclopedia, or \nwe write a mathematical formula. The kind of structure that we put in corresponds \nto the architecture of the neural net, and to fairly broad assumptions about the \nworld and the kind of task that we’re trying to solve. When we put in a special \nstructure and architecture that allows the network to have an attention mechanism, \nit’s putting in a lot of prior knowledge. It turns out that this is central to the \nsuccess of things like machine translation. \nYou need that kind of tool in your toolbox in order to solve some of those problems, \nin the same way that if you deal with images, you need to have something like \na convolutional neural network structure in order to do a good job. If you don’t \nput in that structure, then performance is much worse. There are already a lot of \ndomain-specific assumptions about the world and about the function you’re trying \nto learn, that are implicit in the kind of architectures and training objectives that \nare used in deep learning. This is what most of the research papers today are about.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 202
  },
  {
    "chunk_full": "YOSHUA BENGIO\n23\nMARTIN FORD: What I was trying to get at with the question on structure was \nthat, for example, a baby can recognize human faces right after it is born. Clearly, \nthen, there is some structure in the human brain that allows the baby to do that. \nIt’s not just raw neurons working on pixels.\nYOSHUA BENGIO: You’re wrong! It is raw neurons working on pixels, except \nthat there is a particular architecture in the baby’s brain that recognizes something \ncircular with two dots inside it.\nMARTIN FORD: My point is that the structure pre-exists. \nYOSHUA BENGIO: Of course it does, but all the things that we’re designing in \nthose neural networks also pre-exist. What deep learning researchers are doing is \nlike the work of evolution, where we’re putting in the prior knowledge in the form \nof both the architecture and the training procedure.\nIf we wanted, we could hardwire something that would allow the network to \nrecognize a face, but it’s useless for an AI because they can learn that very quickly. \nInstead, we put in the things that are really useful for solving the harder problems \nthat we’re trying to deal with. \nNobody is saying that there is no innate knowledge in humans, babies, and animals, \nin fact, most animals have only innate knowledge. An ant doesn’t learn much, it’s all \nlike a big, fixed program, but as you go higher up in the intelligence hierarchy, the \nshare of learning keeps increasing. What makes humans different from many other \nanimals is how much we learn versus how much is innate at the start.\nMARTIN FORD: Let’s step back and define some of those concepts. In the 1980s, \nneural networks were a very marginalized subject and they were just one layer, \nso there was nothing deep about them. You were involved in transforming that \ninto what we now call deep learning. Could you define, in relatively non-technical \nterms, what that is?\nYOSHUA BENGIO: Deep learning is an approach to machine learning. While \nmachine learning is trying to put knowledge into computers by allowing \ncomputers to learn from examples, deep learning is doing it in a way that is \ninspired by the brain. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 203
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n24\nDeep learning and machine learning are just a continuation of that earlier work on \nneural networks. They’re called “deep” because they added the ability to train deeper \nnetworks, meaning they have more layers, and each layer represents a different level \nof representation. We hope that as the network gets deeper, it can represent more \nabstract things, and so far, that does seem to be the case. \nMARTIN FORD: When you say layers, do you mean layers of abstraction? So, in \nterms of a visual image, the first layer would be pixels, then it would be edges, \nfollowed by corners, and then gradually you would get all the way up to objects?\nYOSHUA BENGIO: Yes, that’s correct. \nMARTIN FORD: If I understand correctly, though, the computer still doesn’t \nunderstand what that object is, right?\nYOSHUA BENGIO: The computer has some understanding, it’s not a black-and-\nwhite argument. A cat understands a door, but it doesn’t understand it as well as \nyou do. Different people have different levels of understanding of the many things \naround them, and science is about trying to deepen our understanding of those \nmany things. These networks have a level of understanding of images if they’ve \nbeen trained on images, but that level is still not as abstract and as general as \nours. One reason for this is that we interpret images in the context of our three-\ndimensional understanding of the world, obtained thanks to our stereo vision and \nour movements and actions in the world. This gives us a lot more than just a visual \nmodel: it also gives us a physical model of objects. The current level of computer \nunderstanding of images is still primitive but it’s still good enough to be incredibly \nuseful in many applications.\nMARTIN FORD: Is it true that the thing that has really made deep learning possible \nis backpropagation? The idea that you can send the error information back through \nthe layers, and adjust each layer based on the final outcome.\nYOSHUA BENGIO: Indeed, backpropagation has been at the heart of the success \nof deep learning in recent years. It is a method to do credit assignment, that is, \nto figure out how internal neurons should change to make the bigger network \nbehave properly. Backpropagation, at least in the context of neural networks, was \ndiscovered in the early 1980s, at the time when I started my own work. Yann LeCun \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 204
  },
  {
    "chunk_full": "YOSHUA BENGIO\n25\nindependently discovered it around the same time as Geoffrey Hinton and David \nRumelhart. It’s an old idea, but we didn’t practically succeed in training these deeper \nnetworks until around 2006, over a quarter of a century later.\nSince then, we’ve been adding a number of other features to these networks, which \nare very exciting for our research into artificial intelligence, such as attention \nmechanisms, memory, and the ability to not just classify but also generate images.\nMARTIN FORD: Do we know if the brain does something similar to backpropagation?\nYOSHUA BENGIO: That’s a good question. Neural nets are not trying to imitate \nthe brain, but they are inspired by some of its computational characteristics, at \nleast at an abstract level. \nYou have to realize that we don’t yet have a full picture of how the brain works. There \nare many aspects of the brain that are not yet understood by neuroscientists. There are \ntons of observations about the brain, but we don’t know how to connect the dots yet. \nIt may be that the work that we’re doing in machine learning with neural nets could \nprovide a testable hypothesis for brain science. That’s one of the things that I’m \ninterested in. In particular, backpropagation up to now has mostly been considered \nsomething that computers can do, but not realistic for brains. \nThe thing is, backpropagation is working incredibly well, and it suggests that \nmaybe the brain is doing something similar—not exactly the same, but with the \nsame function. As a result of that, I’m currently involved in some very interesting \nresearch in that direction.\nMARTIN FORD: I know that there was an “AI Winter” where most people had \ndismissed deep learning, but a handful of people, like yourself, Geoffrey Hinton, \nand Yann LeCun, kept it alive. How did that then evolve to the point where we \nfind ourselves today?\nYOSHUA BENGIO: By the end of the ‘90s and through the early 2000s, neural \nnetworks were not trendy, and very few groups were involved with them. I had \na strong intuition that by throwing out neural networks, we were throwing out \nsomething really important. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 205
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n26\nPart of that was because of something that we now call compositionality: The \nability of these systems to represent very rich information about the data in a \ncompositional way, where you compose many building blocks that correspond to the \nneurons and the layers. That led me to language models, early neural networks that \nmodel text using word embeddings. Each word is associated with a set of numbers \ncorresponding to different attributes that are learned autonomously by the machine. \nIt didn’t really catch on at the time, but nowadays almost everything to do with \nmodeling language from data uses these ideas. \nThe big question was how we could train deeper networks, and the breakthrough \nwas made by Geoffrey Hinton and his work with Restricted Boltzmann Machines \n(RBMs). In my lab, we were working on autoencoders, which are very closely \nrelated to RBMs, and autoencoders have given rise to all kinds of models, such \nas generative adversarial networks. It turned out that by stacking these RBMs or \nautoencoders we are able to train deeper networks than we were able to before. \nMARTIN FORD: Could you explain what an autoencoder is?\nYOSHUA BENGIO: There are two parts to an autoencoder, an encoder and a \ndecoder. The idea is that the encoder part takes an image, for example, and tries \nto represent it in a compressed way, such as a verbal description. The decoder then \ntakes that representation and tries to recover the original image. The autoencoder is \ntrained to do this compression and decompression so that it is as faithful as possible \nto the original. \nAutoencoders have changed quite a bit since that original vision. Now, we think of \nthem in terms of taking raw information, like an image, and transforming it into \na more abstract space where the important, semantic aspect of it will be easier to \nread. That’s the encoder part. The decoder works backwards, taking those high-level \nquantities—that you don’t have to define by hand—and transforming them into an \nimage. That was the early deep learning work.\nThen a few years later, we discovered that we didn’t need these approaches to train deep \nnetworks, we could just change the nonlinearity. One of my students was working with \nneuroscientists, and we thought that we should try rectified linear units (ReLUs)—we \ncalled them rectifiers in those days—because they were more biologically plausible, \nand this is an example of actually taking inspiration from the brain. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 206
  },
  {
    "chunk_full": "YOSHUA BENGIO\n27\nMARTIN FORD: What did you learn from all of that?\nYOSHUA BENGIO: We had previously used a sigmoid function to train neural nets, \nbut it turned out that by using ReLUs we could suddenly train very deep nets much \nmore easily. That was another big change that occurred around 2010 or 2011. \nThere is a very large dataset—the ImageNet dataset—which is used in computer \nvision, and people in that field would only believe in our deep learning methods if \nwe could show good results on that dataset. Geoffrey Hinton’s group actually did \nit, following up on earlier work by Yann LeCun on convolutional networks—that \nis, neural networks which were specialized for images. In 2012, these new deep \nlearning architectures with extra twists were used with huge success and showed a \nbig improvement on existing methods. Within a couple of years, the whole computer \nvision community switched to these kinds of networks.\nMARTIN FORD: So that’s the point at which deep learning really took off?\nYOSHUA BENGIO: It was a bit later. By 2014, things were lining up for a big \nacceleration in the community for the take-up of deep learning. \nMARTIN FORD: That’s when it transitioned from being centered in universities to \nbeing in the mainstream domain at places like Google, Facebook, and Baidu?\nYOSHUA BENGIO: Exactly. The shift started slightly earlier, around 2010, with \ncompanies like Google, IBM, and Microsoft, who were working on neural networks \nfor speech recognition. By 2012, Google had these neural networks on their \nAndroid smartphones. It was revolutionary for the fact that the same technology \nof deep learning could be used for both computer vision and speech recognition. \nIt drove a lot of attention toward the field.\nMARTIN FORD: Thinking back to when you first started in neural networks, are \nyou surprised at the distance things have come and the fact that they’ve become so \ncentral to what large companies, like Google and Facebook, are doing now?\nYOSHUA BENGIO: Of course, we didn’t expect that. We’ve had a series of important \nand surprising breakthroughs with deep learning. I mentioned earlier that speech \nrecognition came around 2010, and then computer vision around 2012. A couple \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 207
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n28\nof years later, in 2014 and 2015, we had breakthroughs in machine translation that \nended up being used in Google Translate in 2016. 2016 was also the year we saw \nthe breakthroughs with AlphaGo. All of these things, among a number of others, \nwere really not expected. \nI remember back in 2014 I looked at some of our results in caption generation, \nwhere the computer is trying to come up with a caption for an image, and I was \namazed that we were able to do that. If you had asked me just one year earlier if \nwe’d be able to do that in a year, I would have said no. \nMARTIN FORD: Those captions are pretty remarkable. Sometimes they’re way off \nthe mark, but most of the time they’re amazing. \nYOSHUA BENGIO: Of course, they’re way off sometimes! They’re not trained on \nenough data, and there are also some fundamental advances in basic research that need \nto be made for those systems to really understand an image and really understand \nlanguage. We’re far away from achieving those advances, but the fact that they were \nable to reach the level of performance that they have was not something we expected.\nMARTIN FORD: Let’s talk about your career. What was your own path into the \nfield of AI?\nYOSHUA BENGIO: When I was young, I would read a lot of science fiction, and I’m \nsure that had an impact on me. It introduced me to topics such as AI and Asimov’s \nThree Laws of Robotics, and I wanted to go to college and study physics and \nmathematics. That changed when my brother and I became interested in computers. \nWe saved our money to buy an Apple IIe and then an Atari 800. Software was scarce \nin those days, so we learned to program them ourselves in BASIC. \nI got so excited with programming that I went into computer engineering and then \ncomputer science for my Master’s and PhD. While doing my Master’s around 1985, \nI started reading some papers on early neural nets, including some of Geoffrey \nHinton’s papers, and it was like love at first sight. I quickly decided that this was \nthe subject I wanted to do my research in.\nMARTIN FORD: Is there any particular advice you’d give to someone who wants to \nget into the field of being a deep learning expert or researcher?\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 208
  },
  {
    "chunk_full": "YOSHUA BENGIO\n29\nYOSHUA BENGIO: Just jump in the water and start swimming. There’s a ton of \ninformation in the form of tutorials, videos, and open source libraries at all levels \nbecause there’s so much interest in this field. And there is the book I co-authored, \ncalled Deep Learning, which helps newcomers into the field and is available for free \nonline. I see many undergrad students training themselves by reading lots and lots \nof papers, trying to reproduce those papers, and then applying to get into the labs \nwhich are doing this kind of research. If you’re interested in the area, there’s no \nbetter time to start than now.\nMARTIN FORD: In terms of your career, one thing I noticed is that of the key \npeople in deep learning, you’re the only one that remains entirely in the academic \nworld. Most others are part-time at companies like Facebook or Google. What \nmade you take that career pathway?\nYOSHUA BENGIO: I’ve always valued academia and the freedom to work for \nthe common good or the things that I believe would have more impact. I also \nvalue working with students both psychologically and in terms of the efficiency \nand productivity of my research. If I went into the industry, I would be leaving \na lot of that behind. \nI also wanted to stay in Montreal, and at that time, it was the case that going \ninto the industry meant going to either California or New York. It was then that \nI thought that maybe we could build something in Montreal that could become \na new Silicon Valley for AI. As a result, I decided to stay and create Mila, The \nMontreal Institute for Learning Algorithms.\nMila carries out basic research, and also plays a leadership role in the AI \necosystem in Montreal. This role involves working in partnership with the Vector \nInstitute in Toronto, and Amii, in Edmonton, as part of the Canadian strategy \nto really push AI forward—in terms of science, in terms of the economy, and \nin terms of positive social impact.\nMARTIN FORD: Since you mention it, let’s talk more about AI and the economy, \nand some of the risks there. I have written a lot about the potential for artificial \nintelligence to bring on a new Industrial Revolution, and potentially to lead \nto a lot of job losses. How do you feel about that hypothesis, do you think \nthat it is overhyped?\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 209
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n30\nYOSHUA BENGIO: No, I don’t think it’s overhyped. The part that is less clear \nis whether this is going to happen over a decade or three decades. What I can \nsay is that even if we stop basic research in AI and deep learning tomorrow, the \nscience has advanced enough that there’s already a huge amount of social and \neconomic benefit to reap from it simply by engineering new services and new \nproducts from these ideas. \nWe also collect a huge amount of data that we don’t use. For example, in \nhealthcare, we’re only using a tiny, tiny fraction of what is available, or of what \nwill be available as even more gets digitized every day. Hardware companies are \nworking hard to build deep learning chips that are soon going to be easily a \nthousand times faster or more energy-efficient than the ones we currently have. \nThe fact that you could have these things everywhere around you, in cars and \nphones, is clearly going to change the world. \nWhat will slow things down are things like social factors. It takes time to change \nthe healthcare infrastructure, even if the technology is there. Society can’t change \ninfinitely fast, even if the technology is moving forward. \nMARTIN FORD: If this technology change does lead to a lot of jobs being eliminated, \ndo you think something like a basic income would be a good solution?\nYOSHUA BENGIO: I think a basic income could work, but we have to take a \nscientific view on this to get rid of our moral priors that say if a person doesn’t \nwork, then they shouldn’t have an income. I think it’s crazy. I think we have to \nlook at what’s going to work best for the economy and what’s going to work best \nfor people’s happiness, and we can do pilot experiments to answer those questions. \nIt’s not like there’s one clear answer, there are many ways that society could take \ncare of the people who are going to be left behind and minimize the amount of \nmisery arising from this Industrial Revolution. I’m going to go back to something \nthat my friend Yann LeCun said: If we had had the foresight in the 19th century \nto see how the Industrial Revolution would unfold, maybe we could have avoided \nmuch of the misery that followed. If in the 19th century we had put in place the \nkind of social safety net that currently exists in most Western nations, instead of \nwaiting until the 1940s and 1950s, then hundreds of millions of people would have \nled a much better and healthier life. The thing is, it’s going to take probably much \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 210
  },
  {
    "chunk_full": "YOSHUA BENGIO\n31\nless than a century this time to unfold that story, and so the potential negative \nimpacts could be even larger. \nI think it’s really important to start thinking about it right now and to start \nscientifically studying the options to minimize misery and optimize global well-\nbeing. I think it’s possible to do it, and we shouldn’t just rely on our old biases and \nreligious beliefs in order to decide on the answer to these questions.\nMARTIN FORD: I agree, but as you say, it could unfold fairly rapidly. It’s going to \nbe a staggering political problem, too. \nYOSHUA BENGIO: Which is all the more reason to act quickly!\nMARTIN FORD: A valid point. Beyond the economic impact, what are the other \nthings we should worry about in terms of artificial intelligence?\nYOSHUA BENGIO: I have been very active in speaking against killer robots.\nMARTIN FORD: I noticed you signed a letter aimed at a university in Korea which \nseemed to be headed towards research on killer robots. \nYOSHUA BENGIO: That’s right, and this letter is working. In fact, KAIST, The \nKorea Advanced Institute of Science and Technology, has been telling us that \nthey will avoid going into the development of military systems which don’t have \na human in the loop.\nLet me go back to this question about a human in the loop because I think this is \nreally important. People need to understand that current AI—and the AI that we \ncan foresee in the reasonable future—does not, and will not, have a moral sense or \nmoral understanding of what is right and what is wrong. I know there are differences \nacross cultures, but these moral questions are important in people’s lives. \nIt’s true, not just for killer robots but all kinds of other things, like the work that \na judge does deciding on the fate of a person—whether that person should return \nto prison or be freed into society. These are really difficult moral questions, where \nyou have to understand human psychology, and you have to understand moral \nvalues. It’s crazy to put those decisions in the hands of machines, which don’t have \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 211
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n32\nthat kind of understanding. It’s not just crazy; it’s wrong. We have to have social \nnorms or laws, which make sure that computers in the foreseeable future don’t \nget those kinds of responsibilities.\nMARTIN FORD: I want to challenge you on that. I think a lot of people would say \nthat you have a very idealistic view of human beings and the quality of their judgment. \nYOSHUA BENGIO: Sure, but I’d rather have an imperfect human being as a judge \nthan a machine that doesn’t understand what it’s doing.\nMARTIN FORD: But think of an autonomous security robot that would be happy \nto take a bullet first and shoot second, whereas a human would never do that, and \nthat could potentially save lives. In theory, an autonomous security robot would \nalso not be racist, if it were programmed correctly. These are actually areas where \nit might have an advantage over a human being. Would you agree?\nYOSHUA BENGIO: Well, it might be the case one day, but I can tell you we’re not \nthere yet. It’s not just about precision, it’s about understanding the human context, \nand computers have absolutely zero clues about that.\nMARTIN FORD: Other than the military and weaponization aspects, is there anything \nelse that we should be worried about with AI?\nYOSHUA BENGIO: Yes, and this is something that hasn’t been discussed much, but \nnow may come more to the forefront because of what happened with Facebook and \nCambridge Analytica. The use of AI in advertising or generally in influencing people \nis something that we should be really aware of as dangerous for democracy—and is \nmorally wrong in some ways. We should make sure that our society prevents those \nthings as much as possible. \nIn Canada, for example, advertising that is directed at children is forbidden. There’s \na good reason for that: We think that it’s immoral to manipulate their minds when \nthey are so vulnerable. In fact, though, every one of us is vulnerable, and if it \nweren’t the case, then advertising wouldn’t work. \nThe other thing is that advertising actually hurts market forces because it gives \nlarger companies a tool to slow down smaller companies coming into their markets \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 212
  },
  {
    "chunk_full": "YOSHUA BENGIO\n33\nbecause those larger companies can use their brand. Nowadays they can use AI to \ntarget their message to people in a much more accurate way, and I think that’s kind \nof scary, especially when it makes people do things that may be against their well-\nbeing. It could be the case in political advertising, for example, or advertising that \ncould change your behavior and have an impact on your health. I think we should be \nreally, really careful about how these tools are used to influence people in general.\nMARTIN FORD: What about the warnings from people like Elon Musk and \nStephen Hawking about an existential threat from super intelligent AI and \ngetting into a recursive improvement loop? Are these things that we should be \nconcerned about at this point?\nYOSHUA BENGIO: I’m not concerned about these things, I think it’s fine that \nsome people study the question. My understanding of the current science as it is \nnow, and as I can foresee it, is that those kinds of scenarios are not realistic. Those \nkinds of scenarios are not compatible with how we build AI right now. Things may \nbe different in a few decades, I have no idea, but that is science fiction as far as \nI’m concerned. I think perhaps those fears are detracting from some of the most \npressing issues that we could act on now. \nWe’ve talked about killer robots and we’ve talked about political advertising, \nbut there are other concerns, like how data could be biased and reinforce \ndiscrimination, for example. These are things that governments and companies \ncan act on now, and we do have some ways to mitigate some of these issues. The \ndebate shouldn’t focus so much on these very long-term potential risks, which \nI don’t think are compatible with my understanding of AI, but we should pay \nattention to short-term things like killer robots.\nMARTIN FORD: I want to ask you about the potential competition with China \nand other countries. You’ve talked a lot about, for example, having limitations on \nautonomous weapons and one obvious concern there is that some countries might \nignore those rules. How worried should we be about that international competition?\nYOSHUA BENGIO: Firstly, on the scientific side I don’t have any concern. The \nmore researchers around the world are working on a science, the better it is for \nthat science. If China is investing a lot in AI that’s fine; at the end of the day, we’re \nall going to take advantage of the progress that’s going to come of that research. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 213
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n34\nHowever, I think the part about the Chinese government potentially using this \ntechnology either for military purposes or for internal policing is scary. If you take \nthe current state of the science and build systems that will recognize people, recognize \nfaces, and track them, then essentially you can build a Big Brother society in just \na few years. It’s quite technically feasible and it is creating even more danger for \ndemocracy around the world. That is really something to be concerned about. It’s not \njust states like China where this could happen, either; it could also happen in liberal \ndemocracies if they slip towards autocratic rule, as we have seen in some countries. \nRegarding the military race to use AI, we shouldn’t confuse killer robots with the \nuse of AI in the military. I’m not saying that we should completely ban the use of \nAI in the military. For example, if the military uses AI to build weapons that will \ndestroy killer robots, then that’s a good thing. What is immoral is to have these \nrobots kill humans. It’s not like we all have to use AI immorally. We can build \ndefensive weapons, and that could be useful to stop the race.\nMARTIN FORD: It sounds like you feel there’s definitely a role for regulation in \nterms of autonomous weapons?\nYOSHUA BENGIO: There’s a role for regulation everywhere. In the areas where AI is going to \nhave a social impact, then we at least have to think about regulation. We have to consider what \nthe right social mechanism is that will make sure that AI is used for good.\nMARTIN FORD: And you think governments are equipped to take on that question? \nYOSHUA BENGIO: I don’t trust companies to do it by themselves because their \nmain focus is on maximizing profits. Of course, they’re also trying to remain popular \namong their users or customers, but they’re not completely transparent about \nwhat they do. It’s not always clear that those objectives that they’re implementing \ncorrespond to the well-being of the population in general. \nI think governments have a really important role to play, and it’s not just individual \ngovernments, it’s the international community because many of these questions are \nnot just local questions, they’re international questions.\nMARTIN FORD: Do you believe that the benefits to all of this are going to clearly \noutweigh the risks? \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 214
  },
  {
    "chunk_full": "YOSHUA BENGIO\n35\nYOSHUA BENGIO: They’ll only outweigh the risks if we act wisely. That’s why it’s \nso important to have those discussions. That’s why we don’t want to move straight \nahead with blinkers on; we have to keep our eyes open to all of the potential \ndangers that are lurking. \nMARTIN FORD: Where do you think this discussion should be taking place now? \nIs it something primarily think tanks and universities should do, or do you think \nthis should be part of the political discussion both nationally and internationally?\nYOSHUA BENGIO: It should totally be part of the political discussion. I was invited \nto speak at a meeting of G7 ministers, and one of the questions discussed was, \n“How do we develop AI in a way that’s both economically positive and keeps the \ntrust of the people?”, because people today do have concerns. The answer is to \nnot do things in secret or in ivory towers, but instead to have an open discussion \nwhere everybody around the table, including every citizen, should be part of the \ndiscussion. We’re going to have to make collective choices about what kind of future \nwe want, and because AI is so powerful, every citizen should understand at some \nlevel what the issues are. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 215
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n36\nYOSHUA BENGIO is Full Professor of the Department of Computer Science and Operations \nResearch, scientific director of the Montreal Institute for Learning Algorithms (Mila), CIFAR \nProgram co-director of the CIFAR program on Learning in Machines and Brains, Canada \nResearch Chair in Statistical Learning Algorithms. Together with Ian Goodfellow and Aaron \nCourville, he wrote Deep Learning, one of the defining textbooks on the subject. The book \nis available for free from https://www.deeplearningbook.org.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 216
  },
  {
    "chunk_full": "YOSHUA BENGIO\n37\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 217
  },
  {
    "chunk_full": "",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 218
  },
  {
    "chunk_full": "STUART J. RUSSELL\n39\nSTUART J. RUSSELL\nPROFESSOR OF COMPUTER SCIENCE,  \nUNIVERSITY OF CALIFORNIA, BERKELEY\nStuart J. Russell is widely recognized as one of the world’s leading contributors \nin the field of artificial intelligence. He is a Professor of Computer Science and \nDirector of the Center for Human-Compatible Artificial Intelligence at The \nUniversity of California, Berkeley. Stuart is the co-author of the leading AI \ntextbook, Artificial Intelligence: A Modern Approach, which is in use at \nover 1,300 colleges and universities throughout the world.\nOnce an AGI gets past kindergarten reading level, it \nwill shoot beyond anything that any human being has \never done, and it will have a much bigger knowledge \nbase than any human ever has.\n“ \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 219
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n40\nMARTIN FORD: Given that you co-wrote the standard textbook on AI in use today, \nI thought it might be interesting if you could define some key AI terms. What is \nyour definition of artificial intelligence? What does it encompass? What types of \ncomputer science problems would be included in that arena? Could you compare \nit or contrast it with machine learning?\nSTUART J. RUSSELL: Let me give you, shall we say, the standard definition of artificial \nintelligence, which is similar to the one in the book and is now quite widely accepted: \nAn entity is intelligent to the extent that it does the right thing, meaning that its \nactions are expected to achieve its objectives. The definition applies to both humans \nand machines. This notion of doing the right thing is the key unifying principle of AI. \nWhen we break this principle down and look deeply at what is required to do the \nright thing in the real world, we realize that a successful AI system needs some key \nabilities, including perception, vision, speech recognition, and action. \nThese abilities help us to define artificial intelligence. We’re talking about the ability \nto control robot manipulators, and everything that happens in robotics. We’re \ntalking about the ability to make decisions, to plan, and to problem-solve. We’re \ntalking about the ability to communicate, and so natural language understanding \nalso becomes extremely important to AI. \nWe’re also talking about an ability to internally know things. It’s very hard to \nfunction successfully in the real world if you don’t actually know anything. To \nunderstand how we know things, we enter the scientific field that we call knowledge \nrepresentation. This is where we study how knowledge can be stored internally and \nthen processed by reasoning algorithms, such as automated logical deduction and \nprobabilistic inference algorithms. \nThen there is learning. Learning is a key ability for modern artificial intelligence. \nMachine learning has always been a subfield of AI, and it simply means improving your \nability to do the right thing as a result of experience. That could be learning how to \nperceive better by seeing labeled examples of objects. That could also mean learning \nhow to reason better by experience—such as discovering which reasoning steps turn out \nto be useful for solving a problem, and which reasoning steps turn out to be less useful. \nAlphaGo, for example, is a modern AI Go program that recently beat the best human \nworld-champion players, and it really does learn. It learns how to reason better \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 220
  },
  {
    "chunk_full": "STUART J. RUSSELL\n41\nfrom experience. As well as learning to evaluate positions, AlphaGo learns how to \ncontrol its own deliberations so that it more effectively reaches high decision-quality \nmoves more quickly, with less computation. \nMARTIN FORD: Can you also define neural networks and deep learning?\nSTUART J. RUSSELL: Yes, in machine learning one of the standard techniques is \ncalled “supervised learning,” where we give the AI system a set of examples of \na concept, along with a description and a label for each example in the set. For \nexample, we might have a photograph, where we’ve got all the pixels in the image, \nand then we have a label saying that this is a photograph of a boat, or of a Dalmatian \ndog, or of a bowl of cherries. In supervised learning for this task, the goal is to \nfind a predictor, or a hypothesis, for how to classify images in general. \nFrom these supervised training examples, we try to give an AI the ability to \nrecognize pictures of, say, Dalmatian dogs, and the ability to predict how other \npictures of Dalmatian dogs might look.\nOne way of representing the hypothesis, or the predictor, is a neural net. A neural \nnet is essentially a complicated circuit with many layers. The input into this circuit \ncould be the values of pixels from pictures of Dalmatian dogs. Then, as those input \nvalues propagate through the circuit, new values are calculated at each layer of \nthe circuit. At the end, we have the outputs of the neural network, which are the \npredictions about what kind of object is being recognized. \nSo hopefully, if there’s a Dalmatian dog in our input image, then by the time all \nthose numbers and pixel values propagate through the neural network and all of its \nlayers and connections, the output indicator for a Dalmatian dog will light up with \na high value, and the output indicator for a bowl of cherries will have a low value. \nWe then say that the neural network has correctly recognized a Dalmatian dog. \nMARTIN FORD: How do you get a neural network to recognize images?\nSTUART J. RUSSELL: This is where the learning process comes in. The circuit \nhas adjustable connection strengths between all its connections, and what the \nlearning algorithms do is adjust those connection strengths so that the network \ntends to give the correct predictions on the training examples. Then if you’re \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 221
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n42\nlucky, the neural network will also give correct predictions on new images that \nit hasn’t seen before. And that’s a neural network! \nGoing one step further, deep learning is where we have neural networks that have \nmany layers. There is no required minimum for a neural network to be deep, but \nwe would usually say that two or three layers is not a deep learning network, while \nfour or more layers is deep learning.\nSome deep learning networks get up to one thousand layers or more. By having \nmany layers in deep learning, we can represent a very complex transformation \nbetween the input and output, by a composition of much simpler transformations, \neach represented by one of those layers in the network. \nThe deep learning hypothesis suggests that many layers make it easier for the learning \nalgorithm to find a predictor, to set all the connection strengths in the network so \nthat it does a good job.\nWe are just beginning now to get some theoretical understanding of when and \nwhy the deep learning hypothesis is correct, but to a large extent, it’s still a \nkind of magic, because it really didn’t have to happen that way. There seems to \nbe a property of images in the real world, and there is some property of sound \nand speech signals in the real world, such that when you connect that kind of \ndata to a deep network it will—for some reason—be relatively easy to learn a \ngood predictor. But why this happens is still anyone’s guess.\nMARTIN FORD: Deep learning is receiving enormous amounts of attention right now, \nand it would be easy to come away with the impression that artificial intelligence \nis synonymous with deep learning. But deep learning is really just one relatively \nsmall part of the field, isn’t it?\nSTUART J. RUSSELL: Yes, it would be a huge mistake for someone to think that \ndeep learning is the same thing as artificial intelligence, because the ability to \ndistinguish Dalmatian dogs from bowls of cherries is useful but it is still only \na very small part of what we need to give an artificial intelligence in order \nfor it to be successful. Perception and image recognition are both important \naspects of operating successfully in the real world, but deep learning is only \none part of the picture.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 222
  },
  {
    "chunk_full": "STUART J. RUSSELL\n43\nAlphaGo, and its successor AlphaZero, created a lot of media attention around \ndeep learning with stunning advances in Go and Chess, but they’re really a hybrid \nof classical search-based AI and a deep learning algorithm that evaluates each \ngame position that the classical AI system searches through. While the ability to \ndistinguish between good and bad positions is central to AlphaGo, it cannot play \nworld-champion-level Go just by deep learning.\nSelf-driving car systems also use a hybrid of classical search-based AI and deep \nlearning. Self-driving cars are not just pure deep learning systems, because that \ndoes not work very well. Many driving situations need classical rules for an AI to \nbe successful. For example, if you’re in the middle lane and you want to change \nlanes to the right, and there’s someone trying to pass you on the inside, then you \nshould wait for them to go by first before you pull over. For road situations that \nrequire lookahead, because no satisfactory rule is available, it may be necessary to \nimagine various actions that the car could take as well as the various actions that \nother cars might take, and then decide if those outcomes are good or bad. \nWhile perception is very important, and deep learning lends itself well to \nperception, there are many different types of ability that we need to give an AI \nsystem. This is particularly true when we’re talking about activities that span over \nlong timescales, like going on a vacation. Or very complex actions like building a \nfactory. There’s no possibility that those kinds of activities can be orchestrated by \npurely deep learning black-box systems. \nLet me take the factory example to close my point about the limitations of deep \nlearning here. Let’s imagine we try to use deep learning to build a factory. (After \nall, we humans know how to build a factory, don’t we?) So, we’ll take billions of \nprevious examples of building factories to train a deep learning algorithm; we’ll \nshow it all the ways that people have built factories. We take all that data and we put \nit into a deep learning system and then it knows how to build factories. Could we \ndo that? No, it’s just a complete pipe dream. There is no such data, and it wouldn’t \nmake any sense, even if we had it, to try to build factories that way. \nWe need knowledge to build factories. We need to be able to construct plans. We need \nto be able to reason about physical obstructions and the structural properties of the \nbuildings. We can build AI systems to work out these real-world problems, but it isn’t \nachieved by deep learning. Building a factory requires a different type of AI altogether.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 223
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n44\nMARTIN FORD: Are there recent advances in AI that have struck you as being more \nthan just incremental? What would you point to that is at the absolute forefront of \nthe field right now? \nSTUART J. RUSSELL: It’s a good question, because a lot of the things that are in the \nnews at the moment are not really conceptual breakthroughs, they are just demos. \nThe chess victory of Deep Blue over Kasparov is a perfect example. Deep Blue was \nbasically a demo of algorithms that were designed 30 years earlier and had been \ngradually enhanced and then deployed on increasingly powerful hardware, until they \ncould beat a world chess champion. But the actual conceptual breakthroughs behind \nDeep Blue were in how to design a chess program: how the lookahead works; the \nalpha-beta algorithm for reducing the amount of searching that had to be done; and \nsome of the techniques for designing the evaluation functions. So, as is often the \ncase, the media described the victory of Deep Blue over Kasparov as a breakthrough \nwhen in fact, the breakthrough had occurred decades earlier.\nThe same thing is still happening today as well. For instance, a lot of the recent \nAI reports about perception and speech recognition, and headlines about dictation \naccuracy being close to or exceeding human dictation accuracy, are all very \nimpressive practical engineering results, but they are again demos of conceptual \nbreakthroughs that happened much earlier—from the early deep learning systems \nand convolutional networks that date right back to the late ‘80s and early ‘90s. \nIt’s been something of a surprise that we already had the tools decades ago to do \nperception successfully; we just weren’t using them properly. By applying modern \nengineering to older breakthroughs, by collecting large datasets and processing \nthem across very large networks on the latest hardware, we’ve managed to create \na lot of interest recently in AI, but these have not necessarily been at the real \nforefront of AI. \nMARTIN FORD: Do you think DeepMind’s AlphaZero is a good example of a \ntechnology that’s right on the frontier of AI research?\nSTUART J. RUSSELL: I think AlphaZero was interesting. To me, it was not \nparticularly a surprise that you could use the same basic software that played Go to \nalso play chess and Shogi at world-champion level. So, it was not at the forefront \nof AI in that sense. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 224
  },
  {
    "chunk_full": "STUART J. RUSSELL\n45\nI mean, it certainly gives you pause when you think that AlphaZero, in the space of \nless than twenty-four hours, learned to play at superhuman levels in three different \ngames using the same software. But that’s more a vindication of an approach to \nAI that says that if you have a clear understanding of the problem class, especially \ndeterministic, two-player, turn-taking, fully-observable games with known rules, then \nthose kinds of problems are amenable to a well-designed class of AI algorithms. And \nthese algorithms have been around for some time—algorithms that can learn good \nevaluation functions and use classical methods for controlling search. \nIt’s also clear that if you want to extend those techniques to other classes of \nproblems, you’re going to have to come up with different algorithmic structures. \nFor example, partial observability—meaning that you can’t see the board, so to \nspeak—requires a different class of algorithm. There’s nothing AlphaZero can do \nto play poker, for example, or to drive a car. Those tasks require an AI system that \ncan estimate things that it can’t see. AlphaZero assumes that the pieces on the board \nare the pieces on the board, and that’s that.\nMARTIN FORD: There was also a poker playing AI system developed at Carnegie \nMellon University, called Libratus? Did they achieve a genuine AI breakthrough there? \nSTUART J. RUSSELL: Carnegie Mellon’s Libratus poker AI was another very \nimpressive hybrid AI example: it was a combination of several different algorithmic \ncontributions that were pieced together from research that’s happened over the last \n10 or 15 years. There has been a lot of progress in dealing with games like poker, \nwhich are games of partial information. One of the things that happens with partial-\ninformation games, like poker, is that you must have a randomized playing strategy \nbecause if, say, you always bluff, then people figure out that you’re bluffing and \nthen they call your bluff. But if you never bluff, then you can never steal a game \nfrom your opponent when you have a weak hand. It’s long been known, therefore, \nthat for these kinds of card games, you should randomize your playing behavior, \nand bluff with a certain probability.\nThe key to playing poker extremely well is adjusting those probabilities for how \nto bet; that is, how often to bet more than your hand really justifies, and how \noften to bet less. The calculations for these probabilities are feasible for an AI, and \nthey can be done very exactly, but only for small versions of poker, for example \nwhere there are only a few cards in a pack. It’s very hard for an AI to do these \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 225
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n46\ncalculations accurately for the full game of poker. As a result, over the decade \nor so that people have been working on scaling up poker, we’ve gradually seen \nimprovements in the accuracy and efficiency of how to calculate these probabilities \nfor larger and larger versions of poker.\nSo yes, Libratus is another impressive modern AI application. But whether the \ntechniques are at all scalable, given that it has taken a decade to go from one version \nof poker to another slightly larger version of poker, I’m not convinced. I think \nthere’s also a reasonable question about how much those game-theoretic ideas in \npoker extend into the real world. We’re not aware of doing much randomization in \nour normal day-to-day lives, even though—for sure—the world is full of agents; so \nit ought to be game-theoretic, and yet we’re not aware of randomizing very much \nin our day-to-day lives.\nMARTIN FORD: Self-driving cars are one of the highest-profile applications of AI. \nWhat is your estimate for when fully autonomous vehicles will become a truly \npractical technology? Imagine you’re in a random place in Manhattan, and you call \nup an Uber, and it’s going to arrive with no one in it, and then it will take you to \nanother random place that you specify. How far off is that realistically, do you think? \nSTUART J. RUSSELL: Yes, the timeline for self-driving cars is a concrete question, \nand it’s also an economically important question because companies are investing a \ngreat deal in these projects. \nIt is worth noting that the first actual self-driving car, operating on a public road, \nwas 30 years ago! That was Ernst Dickmanns’ demo in Germany of a car driving on \nthe freeway, changing lanes, and overtaking other vehicles. The difficulty of course \nis trust: while you can run a successful demonstration for a short time, you need \nan AI system to run for decades with no significant failures in order to qualify as \na safe vehicle. \nThe challenge, then, is to build an AI system that people are willing to trust \nthemselves and their kids to, and I don’t think we’re quite there. \nResults from vehicles that are being tested in California at the moment indicate that \nhumans still feel they must intervene as frequently as once every mile of road testing. \nThere are more successful AI driving projects, such as Waymo, which is the Google \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 226
  },
  {
    "chunk_full": "STUART J. RUSSELL\n47\nsubsidiary working on this, that have some respectable records; but they are still, I \nthink, several years away from being able to do this in a wide range of conditions. \nMost of these tests have been conducted in good conditions on well-marked roads. \nAnd as you know, when you’re driving at night and it’s pouring with rain, and \nthere are lights reflecting off the road, and there may also be roadworks, and they \nmight have moved the lane markers, and so on ... if you had followed the old lane \nmarkers, you’d have driven straight into a wall by now. I think in those kinds of \ncircumstances, it’s really hard for AI systems. That’s why I think that we’ll be lucky \nif the self-driving car problem is solved sufficiently in the next five years. \nOf course, I don’t know how much patience the major car companies have. I do think \neveryone is committed to the idea that AI-driven cars are going to come, and of course \nthe major car companies feel they must be there early or miss a major opportunity. \nMARTIN FORD: I usually tell people a 10-15-year time frame when they ask me \nabout self-driving cars. Your estimate of five years seems quite optimistic. \nSTUART J. RUSSELL: Yes, five years is optimistic. As I said, I think we’ll be lucky \nif we see driverless cars in five years, and it could well be longer. One thing that \nis clear, though, is that many of the early ideas of fairly simple architectures for \ndriverless cars are now being abandoned, as we gain more experience.\nIn the early versions of Google’s car, they had chip-based vision systems that were pretty \ngood at detecting other vehicles, lane markers, obstacles, and pedestrians. Those vision \nsystems passed that kind of information effectively in a sort of logical form and then \nthe controller applied logical rules telling the car what to do. The problem was that \nevery day, Google found themselves adding new rules. Perhaps they would go into a \ntraffic circle—or a roundabout, as we call them in England—and there would be a \nlittle girl riding her bicycle the wrong way around the traffic circle. They didn’t have a \nrule for that circumstance. So, then they have to add a new one, and so on, and so on. \nI think that there is probably no possibility that this type of architecture is ever going \nto work in the long run, because there are always more rules that should be encoded, \nand it can be a matter of life and death on the road if a particular rule is missing.\nBy contrast, we don’t play chess or Go by having a bunch of rules specific to one \nexact position or another—for instance, saying if the person’s king is here and their \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 227
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n48\nrook is there, and their queen is there, then make this move. That’s not how we \nwrite chess programs. We write chess programs by knowing the rules of chess and \nthen examining the consequences of various possible actions.\nA self-driving car AI must deal with unexpected circumstances on the road in the \nsame way, not through special rules. It should use this form of lookahead-based \ndecision-making when it doesn’t have a ready-made policy for how to operate in \nthe current circumstance. If an AI doesn’t have this approach as a fallback, then it’s \ngoing to fall through the cracks in some situations and fail to drive safely. That’s \nnot good enough in the real world, of course.\nMARTIN FORD: You’ve noted the limitations in current narrow or specialized AI \ntechnology. Let’s talk about the prospects for AGI, which promises to someday solve \nthese problems. Can you explain exactly what Artificial General Intelligence is? \nWhat does AGI really mean, and what are the main hurdles we need to overcome \nbefore we can achieve AGI?\nSTUART J. RUSSELL: Artificial General Intelligence is a recently coined term, and \nit really is just a reminder of our real goals in AI—a general-purpose intelligence \nmuch like our own. In that sense, AGI is actually what we’ve always called artificial \nintelligence. We’re just not finished yet, and we have not created AGI yet.\nThe goal of AI has always been to create general-purpose intelligent machines. AGI \nis also a reminder that the “general-purpose” part of our AI goals has often been \nneglected in favor of more specific subtasks and application tasks. This is because \nit’s been easier so far to solve subtasks in the real world, such as playing chess. If \nwe look again at AlphaZero for a moment, it generally works within the class of \ntwo-player deterministic fully-observable board games. However, it is not a general \nalgorithm that can work across all classes of problems. AlphaZero can’t handle \npartial observability; it can’t handle unpredictability; and it assumes that the rules \nare known. AlphaZero can’t handle unknown physics, as it were.\nNow if we could gradually remove those limitations around AlphaZero, we’d \neventually have an AI system that could learn to operate successfully in pretty \nmuch any circumstance. We could ask it to design a new high-speed watercraft, \nor to lay the table for dinner. We could ask it to figure out what’s wrong with \nour dog and it should be able to do that—perhaps even by reading everything \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 228
  },
  {
    "chunk_full": "STUART J. RUSSELL\n49\nabout canine medicine that’s ever been known and using that information to \nfigure out what’s wrong with our dog. \nThis kind of capability is thought to reflect the generality of intelligence that humans \nexhibit. And in principle a human being, given enough time, could also do all of \nthose things, and so very much more. That is the notion of generality that we have \nin mind when we talk about AGI: a truly general-purpose artificial intelligence.\nOf course, there may be other things that humans can’t do that an AGI will be able \nto do. We can’t multiply million-digit numbers in our heads, and computers can do \nthat relatively easily. So, we assume that in fact, machines may be able to exhibit \ngreater generality than humans do. \nHowever, it’s also worth pointing out that it’s very unlikely that there will ever be \na point where machines are comparable to human beings in the following sense. \nAs soon as machines can read, then a machine can basically read all the books ever \nwritten; and no human can read even a tiny fraction of all the books that have ever \nbeen written. Therefore, once an AGI gets past kindergarten reading level, it will \nshoot beyond anything that any human being has ever done, and it will have a much \nbigger knowledge base than any human ever has. \nAnd so, in that sense and many other senses, what’s likely to happen is that machines \nwill far exceed human capabilities along various important dimensions. There may \nbe other dimensions along which they’re fairly stunted and so they’re not going to \nlook like humans in that sense. This doesn’t mean that a comparison between humans \nand AGI machines is meaningless though: what will matter in the long run is our \nrelationship with machines, and the ability of the AGI machine to operate in our world. \nThere are dimensions of intelligence (for example, short-term memory) where \nhumans are actually exceeded by apes; but nonetheless, there’s no doubt which of \nthe species is dominant. And if you are a gorilla or a chimpanzee, your future is \nentirely in the hands of humans. Now that is because, despite our fairly pathetic \nshort-term memories compared to gorillas and apes, we are able to dominate them \nbecause of our decision-making capabilities in the real world. \nWe will undoubtedly face this same issue when we create AGI: how to avoid the fate \nof the gorilla and the chimpanzee, and not cede control of our own future to that AGI.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 229
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n50\nMARTIN FORD: That’s a scary question. Earlier, you talked about how conceptual \nbreakthroughs in AI often run decades ahead of reality. Do you see any indications \nthat the conceptual breakthroughs for creating AGI have already been made, or is \nAGI still far in the future?\nSTUART J. RUSSELL: I do feel that many of the conceptual building blocks \ntowards AGI pieces are already here, yes. We can start to explore this question \nby asking ourselves: “Why can’t deep learning systems be the basis for AGI, \nwhat’s wrong with them?” \nA lot of people might answer our question by saying: “Deep learning systems are \nfine, but we don’t know how to store knowledge, or how to do reasoning, or how \nto build more expressive kinds of models, because deep learning systems are just \ncircuits, and circuits are not very expressive after all.” \nAnd for sure, it’s because circuits are not very expressive that no one thinks about \nwriting payroll software using circuits. We instead use programming languages to \ncreate payroll software. Payroll software written using circuits would be billions \nof pages long and completely useless and inflexible. By comparison, programming \nlanguages are very expressive and very powerful. In fact, they are the most powerful \nthings that can exist for expressing algorithmic processes. \nIn fact, we already know how to represent knowledge and how to do reasoning: \nwe have developed computational logic over quite a long time now. Even \npredating computers, people were thinking about algorithmic procedures for \ndoing logical reasoning. \nAnd so, arguably, some of the conceptual building blocks for AGI have already been \nhere for decades. We just haven’t figured out yet how to combine those with the \nvery impressive learning capacities of deep learning. \nThe human race has also already built a technology called probabilistic \nprogramming, which I will say does combine learning capabilities with the \nexpressive power of logical languages and programming languages. Mathematically \nspeaking, such a probabilistic programming system is a way of writing down \nprobability models which can then be combined with evidence, using probabilistic \ninference to produce predictions.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 230
  },
  {
    "chunk_full": "STUART J. RUSSELL\n51\nIn my group we have a language called BLOG, which stands for Bayesian Logic. \nBLOG is a probabilistic modeling language, so you can write down what you know \nin the form of a BLOG model. You then combine that knowledge with data, and \nyou run inference, which in turn makes predictions. \nA real-world example of such a system is the monitoring system for the nuclear \ntest-ban treaty. The way it works is that we write down what we know about \nthe geophysics of the earth, including the propagation of seismic signals through \nthe earth, the detection of seismic signals, the presence of noise, the locations of \ndetection stations, and so on. That’s the model—which is expressed in a formal \nlanguage, along with all the uncertainties: for example, uncertainty in our ability to \npredict the speed of propagation of a signal through the earth. The data is the raw \nseismic information coming from the detection stations that are scattered around the \nworld. Then there is the prediction: What seismic events took place today? Where \ndid they take place? How deep were they? How big were they? And perhaps: Which \nones are likely to be nuclear explosions? This system is an active monitoring system \ntoday for the test-ban treaty, and it seems to be working pretty well. \nSo, to summarize, I think that many of the conceptual building blocks needed for AGI \nor human-level intelligence are already here. But there are some missing pieces. One \nof them is a clear approach to how natural language can be understood to produce \nknowledge structures upon which reasoning processes can operate. The canonical \nexample might be: How can an AGI read a chemistry textbook and then solve a \nbunch of chemistry exam problems—not multiple choice but real chemistry exam \nproblems—and solve them for the right reasons, demonstrating the derivations and \nthe arguments that produced the answers? And then, presumably if that’s done in \na way that’s elegant and principled, the AGI should then be able to read a physics \ntextbook and a biology textbook and a materials textbook, and so on. \nMARTIN FORD: Or we might imagine an AGI system acquiring knowledge from, say, \na history book and then applying what it’s learned to a simulation of contemporary \ngeopolitics, or something like that, where it’s really moving knowledge and applying \nit in an entirely different domain?\nSTUART J. RUSSELL: Yes, I think that’s a good example because it relates to the \nability of an AI system to then be able to manipulate the real world in a geopolitical \nsense or a financial sense. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 231
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n52\nIf, for example, the AI is advising a CEO on corporate strategy, it might be able \nto effectively outplay all the other companies by devising some amazing product \nmarketing acquisition strategies, and so on. \nSo, I’d say that the ability to understand language, and then to operate with the results \nof that understanding, is one important breakthrough for AGI that still needs to happen. \nAnother AGI breakthrough still to happen is the ability to operate over long \ntimescales. While AlphaZero is an amazingly good problem-solving system which \ncan think 20, sometimes 30 steps into the future, that is still nothing compared to \nwhat the human brain does every moment. Humans, in our primitive steps, use \nmotor control signals that we send to our muscles; and just typing a paragraph of \ntext is several tens of millions of motor control commands. So those 20 or 30 steps \nby AlphaZero would only get an AGI only a few milliseconds into the future. As \nwe talked about earlier, AlphaZero would be totally useless for planning the \nactivity of a robot. \nMARTIN FORD: How do humans even solve this problem with so many calculations \nand decisions to be made as they navigate the world?\nSTUART J. RUSSELL: The only way that humans and robots can operate in the \nreal world is to operate at multiple scales of abstraction. We don’t plan our lives \nin terms of exactly which thing are we going to actuate in exactly which order. \nWe instead plan our lives in terms of “OK, this afternoon I’m going try to write \nanother chapter of my book” and then: “It’s going to be about such and such.” Or \nthings like, “Tomorrow I’m going to get on the plane and fly back to Paris.” \nThose are our abstract actions. And then as we start to plan them in more detail, \nwe break them down into finer steps. That’s common sense for humans. We do this \nall the time, but we actually don’t understand very well how to have AI systems do \nthis. In particular, we don’t understand yet how to have AI systems construct those \nhigh-level actions in the first place. Behavior is surely organized hierarchically into \nthese layers of abstraction, but where does the hierarchy come from? How do we \ncreate it and then use it? \nIf we can solve this problem for AI, if machines can start to construct their \nown behavioral hierarchies that allow them to operate successfully in complex \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 232
  },
  {
    "chunk_full": "STUART J. RUSSELL\n53\nenvironments over long timescales, that will be a huge breakthrough for AGI that \ntakes us a long way towards a human-level functionality in the real world. \nMARTIN FORD: What is your prediction for when we might achieve AGI?\nSTUART J. RUSSELL: These kinds of breakthroughs have nothing to do with bigger \ndatasets or faster machines, and so we can’t make any kind of quantitative prediction \nabout when they’re going to occur. \nI always tell the story of what happened in nuclear physics. The consensus view as \nexpressed by Ernest Rutherford on September 11th, 1933, was that it would never be \npossible to extract atomic energy from atoms. So, his prediction was “never”, but what \nturned out to be the case was that the next morning Leo Szilard read Rutherford’s \nspeech, became annoyed by it, and invented a nuclear chain reaction mediated by \nneutrons! Rutherford’s prediction was “never” and the truth was about 16 hours later. \nIn a similar way, it feels quite futile for me to make a quantitative prediction about \nwhen these breakthroughs in AGI will arrive, but Rutherford’s story is a good one.\nMARTIN FORD: Do you expect AGI to happen in your lifetime?\nSTUART J. RUSSELL: When pressed, I will sometimes say yes, I expect AGI to happen \nin my children’s lifetime. Of course, that’s me hedging a bit because we may have some \nlife extension technologies in place by then, so that could stretch it out quite a bit.\nBut given that we kind of understand enough about these breakthroughs to at least \ndescribe them, and that people certainly have inklings of what their solutions might \nbe, suggests to me that we’re just waiting for a bit of inspiration. \nFurthermore, a lot of very smart people are working on these problems, probably \nmore than ever in the history of the field, mainly because of Google, Facebook, \nBaidu, and so on. Enormous resources are being put into AI now. There’s also \nenormous student interest in AI because it’s so exciting right now.\nSo, all those things lead one to believe that the rate of breakthroughs occurring is \nprobably likely to be quite high. These breakthroughs are certainly comparable in \nmagnitude to a dozen of the conceptual breakthroughs that happened over the last \n60 years of AI. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 233
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n54\nSo that is why most AI researchers have a feeling that AGI is something in the not-\ntoo-distant future. It’s not thousands of years in the future, and it’s probably not \neven hundreds of years in the future.\nMARTIN FORD: What do you think will happen when the first AGI is created?\nSTUART J. RUSSELL: When it happens, it’s not going to be a single finishing \nline that we cross. It’s going to be along several dimensions. We’ll see machines \nexceeding human capacities, just as they have in arithmetic, and now chess, Go, \nand in video games. We’ll see various other dimensions of intelligence and classes \nof problems that fall, one after the other; and those will then have implications \nfor what AI systems can do in the real world. AGI systems may, for example, have \nstrategic reasoning tools that are superhuman, and we use those for military and \ncorporate strategy, and so on. But those tools may precede the ability to read and \nunderstand complex text. \nAn early AGI system, by itself, still won’t be able to learn everything about how \nthe world works or be able to control that world. \nWe’ll still need to provide a lot of the knowledge to those early AGI systems. These \nAGIs are not going to look like humans though, and they won’t have even roughly \nthe same abilities across even roughly the same spectrum as humans. These AGI \nsystems are going to be very spiky in different directions.\nMARTIN FORD: I want to talk more about the risks associated with AI and AGI. I \nknow that’s an important focus of your recent work. \nLet’s start with the economic risks of AI, which is the thing that, of course, I’ve \nwritten about in my previous book, Rise of the Robots. A lot of people believe that \nwe are on the leading edge of something on the scale of a new industrial revolution. \nSomething that’s going to be totally transformative in terms of the job market, the \neconomy and so forth. Where do you fall on that? Is that overhyped, or would you \nline up with that assertion?\nSTUART J. RUSSELL: We’ve discussed how the timeline for breakthroughs in AI and \nAGI is hard to predict. Those are the breakthroughs that will enable an AI to do \na lot of the jobs that humans do right now. It’s also quite hard to forecast which \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 234
  },
  {
    "chunk_full": "STUART J. RUSSELL\n55\nsequence of employment categories are going to be at risk from machine replacement \nand a timeline around that.\nHowever, what I see in a lot of the discussions and presentations from people \ntalking about this, is that there’s probably an over-estimate of what current AI \ntechnologies are able to do and also, the difficulty of integrating what we know \nhow to do into the existing extremely complex functionality of corporations and \ngovernments, and so on. \nI do agree that a lot of jobs that have existed for the last few hundred years are \nrepetitive, and the humans who are doing them are basically exchangeable. If it’s \na job where you hire people by the hundred or by the thousand to do it, and you \ncan identify what that person does as a particular task that is then repeated over \nand over again, those kinds of jobs are going to be susceptible. That’s because you \ncould say that, in those jobs, we are using humans as robots. So, it’s not surprising \nthat when we have real robots, they’re going to be able to do those jobs. \nI also think that the current mindset among governments is: “Oh, well then. I guess \nwe really need to start training people to be data scientists, because that’s the job \nof the future—or robot engineers.” This clearly isn’t the solution because we don’t \nneed a billion data scientists and robot engineers: we just need a few million. This \nmight be a strategy for a small country like Singapore; or where I am currently, in \nDubai, it might also be a viable strategy. But it’s not a viable strategy for any major \ncountry because there is simply not going to be enough jobs in those areas. That’s \nnot to say that there are no jobs now: there certainly are, and training more people \nto do them makes sense; but this simply is not a solution to the long-term problem. \nThere are really only two futures for the human economy that I see in the long run. \nThe first is that effectively, most people are not doing anything that’s considered \neconomically productive. They’re not involved in economic exchange of work for \npay in any form, and this is the vision of the universal basic income: that there \nis a sector of the economy that is largely automated and incredibly productive, \nand that productivity generates wealth, in the form of goods and services, that in \none way or another ends up subsidizing the economic viability of everyone else. \nThat to me does not seem like a very interesting world to live in, at least not by \nitself, without a lot of other things needed to go on to make life worth living and \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 235
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n56\nprovide sufficient incentive for people to do all of the things that we do now. For \nexample, going to school, learning and training, and becoming experts in various \nareas. It’s hard to see the motivation for acquiring a good education when it doesn’t \nhave any economic function.\nThe second of the two futures I can see in the long run is that even though \nmachines will be doing a lot of goods and basic services like transportation, there \nare still things that people can do which improve the quality of life for themselves \nand for others. There are people who are able to teach, to inspire people to live \nricher, more interesting, more varied and more fulfilling lives, whether that’s \nteaching people to appreciate literature or music, how to build, or even how to \nsurvive in the wilderness. \nMARTIN FORD: Do you think we can navigate as individuals and as a species towards \na positive future, once AI has changed our economy?\nSTUART J. RUSSELL: Yes, I really do, but I think that a positive future will require \nhuman intervention to help people live positive lives. We need to start actively \nnavigating, right now, towards a future that can present the most constructive \nchallenges and the most interesting experiences in life for people. A world that can \nbuild emotional resilience and nurture a generally constructive and positive attitude \nto one’s own life—and to the lives of others. At the moment, we are pretty terrible \nat doing that. So, we have to start changing that now.\nI think that we’ll also need to fundamentally change our attitude about what science \nis for and what it can do for us. I have a cell phone in my pocket, and the human \nrace probably spent on the order of a trillion dollars on the science and engineering \nthat went into ultimately creating things like my cell phone. And yet we spend \nalmost nothing on understanding how people can live interesting and fulfilling lives, \nand how we can help people around us do that. I think as a race that we will need \nto start acknowledging that if we help another person in the right way, it creates \nenormous value for them for the rest of their lives. Right now, we have almost no \nscience base for how to do this, we have no degree programs in how to do it, we \nhave very few journals about it, and those that are trying are not taken very seriously.\nThe future can have a perfectly functioning economy where people who are expert \nin living life well, and helping other people, can provide those kinds of services. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 236
  },
  {
    "chunk_full": "STUART J. RUSSELL\n57\nThose services may be coaching, they may be teaching, they may be consoling, or \nmaybe collaborating, so that we can all really have a fantastic future. \nIt’s not a grim future at all: it’s a far better future than what we have at present; but \nit requires rethinking our education system, our science base, our economic structures. \nWe need now to understand how this will function from an economic point of \nview in terms of the future distribution of income. We want to avoid a situation \nwhere there are the super-rich who own the means of production—the robots \nand the AI systems—and then there are their servants, and then there is the rest \nof the world doing nothing. That’s sort of the worst possible outcome from an \neconomic point of view. \nSo, I do think that there is a positive future that makes sense once AI has changed \nthe human economy, but we need to get a better handle on what that’s going to \nlook like now, so that we can construct a plan for getting there.\nMARTIN FORD: You’ve worked on applying machine learning to medical data at \nboth Berkeley and nearby UCSF. Do you think artificial intelligence will create \na more positive future for humans through advances in healthcare and medicine?\nSTUART J. RUSSELL: I think so, yes, but I also think that medicine is an area \nwhere we know a great deal about human physiology—and so to me, knowledge-\nbased or model-based approaches are more likely to succeed than data-driven \nmachine learning systems.\nI don’t think that deep learning is going to work for a lot of important medical \napplications. The idea that today we can just collect terabytes of data from millions \nof patients and then throw that data into a black-box learning algorithm, doesn’t \nmake sense to me. There may be some areas of medicine where data-driven machine \nlearning works very well of course. Genomic data is one area; and predicting human \nsusceptibility to various kinds of genetically-related diseases. Also, I think, deep \nlearning AI will be strong at predicting the potential efficacy of particular drugs. \nBut these examples are a long way from an AI being able to act like a doctor and \nbeing able to decide, perhaps, that a patient has a blocked ventricle in the brain \nthat’s interfering with the circulation of cerebral spinal fluid. To really do that, \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 237
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n58\nis more like diagnosing which part of a car is not working. If you have no idea \nhow cars work, then figuring out that it’s the fan belt that’s broken is going to \nbe very, very difficult. \nOf course, if you’re an expert car mechanic and you know how it all works, and \nyou’ve got some symptoms to work with, maybe there’s a kind of a flapping noise \nand that the car’s overheating, then you generally can figure it out quickly. And it’s \ngoing to be the same with human physiology, except that there is a significant effort \nthat must be put in into building these models of human physiology.\nA lot effort was already put in to these models in the ‘60s and ‘70s, and they \nhave helped AI systems in medicine progress to some degree. But today we have \ntechnology that can in particular represent the uncertainty in those models. \nMechanical systems models are deterministic and have specific parameter values: \nthey represent exactly one completely predictable, fictitious human. \nToday’s probabilistic models, on the other hand, can represent an entire population, \nand they can accurately reflect the degree of uncertainty we might have about being \nable to predict, for example, exactly when someone is going to have a heart attack. \nIt’s very hard to predict things like heart attacks on an individual level, but we \ncan predict that there’s a certain probability per person, which might be increased \nduring extreme exercise or stress, and that this probability would depend on various \ncharacteristics of the individual. \nThis more modern and probabilistic approach behaves much more reasonably \nthan previous systems. Probabilistic systems enable us to combine the classical \nmodels of human physiology with observation and real-time data, to make strong \ndiagnosis and plan treatments. \nMARTIN FORD: I know you’ve focused a lot on the potential risks of weaponized \nAI. Could you talk more about that?\nSTUART J. RUSSELL: Yes, I think autonomous weapons are now creating the \nprospect of a new arms race. This arms race may already be leading towards the \ndevelopment of lethal autonomous weapons. These autonomous weapons can be \ngiven some mission description that the weapon has the ability to achieve by itself, \nsuch as identifying, selecting, and attacking human targets. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 238
  },
  {
    "chunk_full": "STUART J. RUSSELL\n59\nThere are moral arguments that this will cross a fundamental line for artificial \nintelligence: that we’re handing over the power over life and death to a machine \nto decide, and that is a fundamental reduction in the way we value human life \nand the dignity of human life. \nBut I think a more practical argument is that a logical consequence of autonomy \nis scalability. Since no supervision is required by an individual human for each \nindividual autonomous weapon, someone could launch as many weapons as they \nwant. Someone can launch an attack, where five guys in a control room could \nlaunch 10,000,000 weapons and wipe out all males between the age of 12 and \n60 in some country. So, these can be weapons of mass destruction, and they have \nthis property of scalability: someone could launch an attack with 10, or 1,000, or \n1,000,000 or 10,000,000 weapons. \nWith nuclear weapons, if they were used at all, someone would be crossing \na major threshold which we’ve managed to avoid so far as a race, by the \nskin of our teeth. We have managed to avoid crossing that threshold since \n1945. But autonomous weapons don’t have such a threshold, and so things \ncan more smoothly escalate. They are also easily proliferated, so once they \nare manufactured in very large numbers it’s quite likely they’ll be on the \ninternational arms market and they’ll be accessible to people who have less \nscruples than, you know, the Western powers.\nMARTIN FORD: There’s a lot of technology transfer between commercial applications \nand potential military applications. You can buy a drone on Amazon that could \npotentially be weaponized...\nSTUART J. RUSSELL: So, at the moment, you can buy a drone that’s remotely \npiloted, maybe with first-person vision. You could certainly attach a little bomb to \nit and deliver it and kill someone, but that’s a remotely piloted vehicle, which is \ndifferent. It’s not scalable because you can’t launch 10,000,000 of those unless you’ve \ngot 10,000,000 pilots. So, someone would need a whole country trained to do that, \nof course, or they could also give those 10,000,000 people machine guns and then \ngo and kill people. Thankfully we have an international system of control of \nsanctions, and military preparedness, and so on—to try to prevent these things \nfrom happening. But we don’t have an international system of control that would \nwork against autonomous weapons.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 239
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n60\nMARTIN FORD: Still, couldn’t a few people in a basement somewhere develop \ntheir own autonomous control system and then deploy it on commercially available \ndrones? How would we be able control those kinds of homemade AI weapons?\nSTUART J. RUSSELL: Yes, something resembling the software that controls a \nself-driving car could conceivably be deployed to control a quadcopter that \ndelivers a bomb. Then you might have something like a homemade autonomous \nweapon. It could be that under a treaty, there would be a verification mechanism \nthat would require the cooperation of drone manufacturers and the people who \nmake chips for self-driving cars and so on, so that anyone ordering large quantities \nwould be noticed—in the same way that anyone ordering large quantities of \nprecursor chemicals for chemical weapons is not going to get away with it because \nthe corporation is required, by the chemical weapons treaty, to know its customer \nand to report any unusual attempts that are made to purchase large quantities of \ncertain dangerous products. \nI think it will be possible to have a fairly effective regime that could prevent very \nlarge diversions of civilian technology to create autonomous weapons. Bad things \nwould still happen, and I think this may be inevitable, because in small numbers it \nwill likely always be feasible for homemade autonomous weapons to be built. In small \nnumbers, though, autonomous weapons don’t have a huge advantage over a piloted \nweapon. If you’re going to launch an attack with ten or twenty weapons, you might \nas well pilot them because you can probably find ten or twenty people to do that. \nThere are other risks of course with AI and warfare, such as where an AI system \nmay accidentally escalate warfare when machines misinterpret some signal and start \nattacking each other. And the future risk of a cyber-infiltration means that you may \nthink you have a robust defense based on autonomous weapons when in fact, all your \nweapons have been compromised and are going to turn on you instead when a conflict \nbegins. So that all contributes to strategic uncertainty, which is not great at all.\nMARTIN FORD: These are scary scenarios. You’ve also produced a short film called \nSlaughterbots, which is quite a terrifying video.\nSTUART J. RUSSELL: We made the video really just to illustrate these concepts \nbecause I felt that, despite our best efforts to write about them and give presentations \nabout them, that somehow the message wasn’t getting through. People were still \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 240
  },
  {
    "chunk_full": "STUART J. RUSSELL\n61\nsaying, “oh, autonomous weapons are science fiction.” They were still imagining it \nas Skynet and Terminators, as a technology that doesn’t exist. So, we were simply \ntrying to point out that we’re not talking about spontaneously evil weapons, and \nwe’re not talking about taking over the world—but we also not talking about \nscience fiction any more.\nThese AI warfare technologies are feasible today, and they bring some new kinds \nof extreme risks. We’re talking about scalable weapons of mass destruction falling \ninto the wrong hands. These weapons could inflict enormous damage on human \npopulations. So, that’s autonomous weapons. \nMARTIN FORD: In 2014, you published a letter, along with the late Stephen Hawking \nand the physicists Max Tegmark and Frank Wilczek, warning that we aren’t taking \nthe risks associated with advanced AI seriously enough. It’s notable that you were \nthe only computer scientist among the authors. Could you tell the story behind \nthat letter and what led you to write it?1 \nSTUART J. RUSSELL: So, it’s an interesting story. It started when I got a call \nfrom National Public Radio, who wanted to interview me about this movie called \nTranscendence. I was living in Paris at the time and the movie wasn’t out in Paris, \nso I hadn’t seen it yet. \nI happened to have a stopover in Boston on the way back from a conference in \nIceland, so I got off the plane in Boston and I went to the movie theatre to watch \nthe movie. I’m sitting there towards the front of the theatre, and I don’t really know \nwhat’s going to happen in the movie at all and then, “Oh, look! It’s showing Berkeley \ncomputer science department. That’s kind of funny.” Johnny Depp is playing the \nAI professor, “Oh, that’s kind of interesting.” He’s giving a talk about AI, and then \nsomeone, some anti-AI terrorist decides to shoot him. So, I’m sort of involuntarily \nshrinking down in my seat seeing this happening, because that could really be me \nat that time. Then the basic plot of the movie is that before he dies they manage \nto upload his brain into a big quantum computer and the combination of those two \nthings creates a super-intelligent entity that threatens to take over the world because \nit very rapidly develops all kinds of amazing new technologies. \n1 The letter is available at: https://www.independent.co.uk/news/science/stephen-hawking-transcend-\nence-looks-at-the-implications-of-artificial-intelligence-but-are-we-taking-9313474.html.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 241
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n62\nSo anyway, we wrote an article that was, at least superficially, a review of the movie, \nbut it was really saying, “You know, although this is just a movie, the underlying \nmessage is real: which is that if—or when—we create machines that can have a \ndominant effect on the real world, then that can present a very serious problem for us: \nthat we could, in fact, cede control over our futures to other entities besides humans.” \nThe problem is very straightforward: our intelligence is what gives us our ability to \ncontrol the world; and so, intelligence represents power over the world. If something \nhas a greater degree of intelligence, then it has more power.\nWe are already on the way to creating things that are much more powerful than us; \nbut somehow, we have to make sure that they never, ever, have any power. So, when \nwe describe the AI situation like that, people say, “Oh, I see. OK, there’s a problem.”\nMARTIN FORD: And yet, a lot of prominent AI researchers are quite dismissive \nof these concerns...\nSTUART J. RUSSELL: Let me talk about these AI denialists. There are various \narguments that people put forward as to why we shouldn’t pay any attention to \nthe AI problem, and that there are just too many of these arguments to count. \nI’ve collected somewhere between 25 and 30 distinct arguments, but they all share \na single property, which is that they simply do not make any sense. They don’t \nreally stand up to scrutiny. Just to give you one example, something you’ll often \nhear is, “well, you know, it’s absolutely not a problem because we’ll just be able \nto switch them off.” That is like saying that beating AlphaZero at Go is absolutely \nnot a problem. You just put the white pieces in the right place, you know? It just \ndoesn’t stand up to five seconds of scrutiny.\nA lot of these AI denialist arguments, I think, reflect a kind of a knee-jerk \ndefensive reaction. Perhaps some people think, “I’m an AI researcher. I feel \nthreatened by this thought, and therefore I’m going to keep this thought out \nof my head and find some reason to keep it out of my head.” That’s one of my \ntheories about why some otherwise very informed people will try to deny that \nAI is going to become a problem for humans.\nThis even extends to some mainstream people in the AI community who deny that \nAI will ever be successful, which is ironic because we’ve spent 60 years fending \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 242
  },
  {
    "chunk_full": "STUART J. RUSSELL\n63\noff philosophers, who have denied that the AI field will ever be successful. We’ve \nalso spent those 60 years demonstrating and proving, one time after another, how \nthings that the philosophers said would be impossible, can indeed happen—such as \nbeating the world champion in chess. \nNow, suddenly some people in the AI field are saying that AI is never going to \nsucceed, and so there isn’t anything to worry about. \nThis is a completely pathological reaction if you ask me. It seems prudent, just \nas with nuclear energy and atomic weapons, to assume that human ingenuity \nwill, in fact, overcome the obstacles and achieve intelligence of a kind that’s \nsufficient to present at least, potentially the threat of ceding control. It seems \nprudent to prepare for that and try to figure out how to design systems in \nsuch a way that that can’t happen. So that’s my goal: to help us prepare for the \nartificial intelligence threat. \nMARTIN FORD: How should we address that threat?\nSTUART J. RUSSELL: The key to the problem is that we have made a slight mistake \nin the way that we define AI, and so I have a reconstructed a new definition for \nAI that goes as follows. \nFirst of all, if we want to build artificial intelligence, we’d better figure out what \nit means to be intelligent. This means that we must draw from thousands of years \nof tradition, philosophy, economics and other disciplines. The idea of intelligence \nis that a human being is intelligent to the extent that their actions can be expected \nto achieve their objectives. This is the idea sometimes called rational behavior; and \nit contains within it various sub-kinds of intelligence, like the ability to reason; the \nability to plan; the ability to perceive; and so on. Those are all kind of required \ncapabilities for acting intelligently in the real world. \nThe problem with that is that if we succeed in creating artificial intelligence and \nmachines with those abilities, then unless their objectives happen to be perfectly \naligned with those of humans, then we’ve created something that’s extremely \nintelligent, but with objectives that are different from ours. And then, if that \nAI is more intelligent than us, then it’s going to attain its objectives—and we, \nprobably, are not! \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 243
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n64\nThe negative consequences for humans are without limit. The mistake is in the \nway we have transferred the notion of intelligence, a concept that makes sense for \nhumans, over to machines.\nWe don’t want machines with our type of intelligence. We actually want machines \nwhose actions can be expected to achieve our objectives, not their objectives. \nThe original idea we had for AI was that to make an intelligent machine, we should \nconstruct optimizers: things that choose actions really well when we give them an \nobjective. Then off it goes and achieves our objective. That’s probably a mistake. It’s \nworked up to now—but only because we haven’t made very intelligent machines, \nand the ones we have made we’ve only put in mini-worlds, like the simulated \nchessboard, the simulated Go board, and so on. \nWhen the AI that humans have so far made, get out into the real-world, that’s when \nthings can go wrong, and we saw an example of this with the flash crash. With the \nflash crash, there was a bunch of trading algorithms, some of them fairly simple, \nbut some of them fairly complicated AI-based decision-making and learning systems. \nOut there in the real world, during the flash crash things went catastrophically \nwrong and those machines crashed the stock market. They eliminated more than a \ntrillion dollars of value in equities in the space of a few minutes. The flash crash \nwas a warning signal about our AI.\nThe right way to think about AI is that we should be making machines which act \nin ways to help us achieve our objectives through them, but where we absolutely \ndo not put our objectives directly into the machine! \nMy vision is that AI must always be designed to try to help us achieve our objectives, \nbut that AI systems should not be assumed to know what those objectives are. \nIf we make AI this way, then there is always an explicit uncertainty about the nature \nof the objectives that an AI is obliged to pursue. It turns out that this uncertainty \nactually is the margin of safety that we require. \nI’ll give you an example to demonstrate this margin of safety that we really do \nneed. Let’s go back to an old idea that we can—if we ever need to—just switch the \nmachine off if we get into trouble. Well, of course, you know, if the machine has \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 244
  },
  {
    "chunk_full": "STUART J. RUSSELL\n65\nan objective like, “fetch the coffee,” then obviously a sufficiently intelligent machine \nrealizes that if someone switches it off, then it’s not going to be able to fetch the \ncoffee. If its life’s mission, if its objective, is to fetch the coffee, then logically it will \ntake steps to prevent itself from being switched off. It will disable the Off switch. \nIt will possibly neutralize anyone who might attempt to switch it off. So, you can \nimagine all these unanticipated consequences of a simple objective like “fetch the \ncoffee,” when you have a sufficiently intelligent machine. \nNow in my vision for AI, we instead design the machine so that although it still \nwants to “fetch the coffee” it understands that there are a lot of other things that \nhuman beings might care about, but it doesn’t really know what those are! In that \nsituation, the AI understands that it might do something that the human doesn’t \nlike—and if the human switches it off, that’s to prevent something that would make \nthe human unhappy. Since in this vision the goal of the machine is to avoid making \nthe human unhappy, even though the AI doesn’t know what that means, it actually \nhas an incentive to allow itself to be switched off. \nWe can take this particular vision for AI and put it into mathematics, and show that \nthe margin of safety (meaning, in this case, the incentive that the machine has to allow \nitself to be switched off) is directly related to the uncertainty it has about the human \nobjective. As we eliminate that uncertainty, and the machine starts to believe that it \nknows, for sure, what the true objective really is, then that margin of safety begins \nto disappear again, and the machine will ultimately stop us from switching it off. \nIn this way, we can show that, at least in a simplified mathematical framework, that \nwhen you design machines this way—with explicit uncertainty about the objective \nthat they are to pursue—then they can be provably beneficial, meaning that you \nare provably better off with this machine than without. \nWhat I’ve shared here is an indication that there may be a way of conceiving of AI \nwhich is a little bit different from how we’ve been thinking about AI so far, that \nthere are ways to build an AI system that has much better properties, in terms of \nsafety and control.\nMARTIN FORD: Related to these issues of AI safety and control, a lot of people \nworry about an arms race with other countries, especially China. Is that something \nwe should take seriously, something we should be very concerned about?\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 245
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n66\nSTUART J. RUSSELL: Nick Bostrom and others have raised a concern that, if \na party feels that strategic dominance in AI is a critical part of their national \nsecurity and economic leadership, then that party will be driven to develop the \ncapabilities of AI systems—as fast as possible, and yes, without worrying too \nmuch about the controllability issues. \nAt a high level, that sounds like a plausible argument. On the other hand, as we \nproduce AI products that can operate out there in the real world, there will be a \nclear economic incentive to make sure that they remain under control. \nTo explore this kind of scenario, let’s think about a product that might come along \nfairly soon: a reasonably intelligent personal assistant that keeps track of your \nactivities, conversations, relationships and so on, and kind of runs your life in the \nway that a good professional human assistant might help you. Now, if such a system \ndoes not have a good understanding of human preferences, and acts in ways that \nthat are unsafe in ways that we’ve already talked about, then people are simply not \ngoing to buy it. If it misunderstands these things, then it might book you into a \n$20,000-a-night hotel room, or it might cancel a meeting with the vice president \nbecause you’re supposed to go to the dentist. \nIn those kinds of situations, the AI is misunderstanding your preferences and, \nrather than being humble about its understanding of your preferences, it thinks \nthat it knows what you want, and it is just being plain wrong about it. I’ve cited \nin other forums the example of a domestic robot that doesn’t understand that the \nnutritional value of a cat is a lot less than the sentimental value of a cat, and so \nit just decides to cook the cat for dinner. If that happened, that would be the end \nof the domestic robot industry. No one is going to want a robot in its house that \ncould make that kind of mistake. \nToday, AI companies that are producing increasingly intelligent products have to solve \nat least a version of this problem in order for their products to be good AI systems. \nWe need to get the AI community to understand that AI that is not controllable \nand safe, is just not good AI. \nIn the same way that a bridge that falls down is simply not a good bridge, we need \nto recognize that AI that is not controllable and safe, is just not good AI. Civil \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 246
  },
  {
    "chunk_full": "STUART J. RUSSELL\n67\nengineers don’t go around saying, “Oh yeah, I design bridges that don’t fall down, \nyou know, unlike the other guy, he designs bridges that fall down.” It’s just built \ninto the meaning of the word “bridge” that it’s not supposed to fall down. \nThis should be built into the meaning of what we mean when we define AI. We \nneed to define AI in such a way that it remains under the control of the humans \nthat it’s supposed to be working for, in any country. And we need to define AI \nso that it has, now and in the future, properties that we call corrigibility: that \nit is able to be switched off, and that it is able to be corrected if it’s doing \nsomething that we don’t like. \nIf we can get everyone in AI, around the world, to understand that these are just \nnecessary characteristics of good AI, then I think we move a long way forward in \nmaking the future prospects of the field of AI much, much brighter. \nThere’s also no better way to kill the field of AI than to have a major control failure, \njust as the nuclear industry killed itself through Chernobyl and Fukushima. AI will \nkill itself if we fail to address the control issue.\nMARTIN FORD: So, on balance, are you an optimist? Do you think that things are \ngoing to work out?\nSTUART J. RUSSELL: Yes, I do think that I’m an optimist. I think there’s a long way \nto go. We are just scratching the surface of this control problem, but the first \nscratching seems to be productive, and so I’m reasonably optimistic that there is \na path of AI development that leads us to what we might describe as “provably \nbeneficial AI systems.”\nOf course, there is the risk that even if we do solve the control problem and even \nif we do build provably beneficial AI systems, that there will be some parties who \nchoose not to use them. The risk here is that one party or another chooses only to \nmagnify the capabilities of AI without regarding the safety aspects. \nThis could be the Dr. Evil character type, the Austin Powers villain who wants \nto take over the world and accidentally releases an AI system that ends up being \ncatastrophic for everyone. Or it could be a much more sociological risk, where \nit starts off as very nice for society to have capable, controllable AI but we then \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 247
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n68\noveruse it. In those risk scenarios, we head towards an enfeebled human society \nwhere we’ve moved too much of our knowledge and too much of our decision-\nmaking into machines, and we can never recover it. We could eventually lose our \nentire agency as humans along this societal path.\nThis societal picture is how the future is depicted in the WALL-E movie, where \nhumanity is off on spaceships and being looked after by machines. Humanity gradually \nbecomes fatter and lazier and stupider. That’s an old theme in science fiction and \nit’s very clearly illustrated in the WALL-E movie. That is a future that we need \nto be concerned about, assuming we successfully navigate all the other risks that \nwe’ve been discussing.\nAs an optimist, I can also see a future where AI systems are well enough designed \nthat they’re saying to humans, “Don’t use us. Get on and learn stuff yourself. Keep \nyour own capabilities, propagate civilization through humans, not through machines.” \nOf course, we might still ignore a helpful and well-design AI, if we prove to be too \nlazy and greedy as a race; and then we’ll pay the price. In that sense, this really \nmight become more of a sociocultural problem, and I do think that we need to do \nwork as a human race to prepare and make sure this doesn’t happen.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 248
  },
  {
    "chunk_full": "STUART J. RUSSELL\n69\nSTUART J. RUSSELL is a professor of electrical engineering and computer science at the \nUniversity of California Berkeley and is widely recognized as one of the world’s leading \ncontributors in the field of artificial intelligence. He is the co-author, along with Peter Norvig, \nof Artificial Intelligence: A Modern Approach, which is the leading AI textbook currently \nin use at over 1300 colleges and universities in 118 countries.\nStuart received his undergraduate degree in Physics from Wadham College, Oxford in 1982 \nand his PhD in Computer Science from Stanford in 1986. His research has covered many \ntopics related to AI, such as machine learning, knowledge representation, and computer vision, \nand he has received numerous awards and distinctions, including the IJCAI Computers and \nThought Award and election as a fellow to the American Association for the Advancement of \nScience, the Association for the Advancement of Artificial Intelligence and the Association of \nComputing Machinery. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 249
  },
  {
    "chunk_full": "",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 250
  },
  {
    "chunk_full": "GEOFFREY HINTON\n71\nGEOFFREY HINTON\nEMERITUS DISTINGUISHED PROFESSOR OF COMPUTER SCIENCE,  \nUNIVERSITY OF TORONTO \nVICE PRESIDENT & ENGINEERING FELLOW, GOOGLE\nGeoffrey Hinton is sometimes known as the Godfather of Deep Learning, and \nhe has been the driving force behind some of its key technologies, such as \nbackpropagation, Boltzmann machines, and the Capsules neural network. In \naddition to his roles at Google and the University of Toronto, he is also Chief \nScientific Advisor of the Vector Institute for Artificial Intelligence.\nIn the past when AI has been overhyped—including \nbackpropagation in the 1980s—people were expecting \nit to do great things, and it didn’t actually do things \nas great as they hoped. Today, it’s already done great \nthings, so it can’t possibly all be just hype.\n“ \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 251
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n72\nMARTIN FORD: You’re most famous for working on the backpropagation algorithm. \nCould you explain what backpropagation is?\nGEOFFREY HINTON: The best way to explain it is by explaining what it isn’t. When \nmost people think about neural networks, there’s an obvious algorithm for training \nthem: Imagine you have a network that has layers of neurons, and you have an \ninput at the bottom layer, and an output at the top layer. Each neuron has a weight \nassociated with each connection. What each neuron does is look at the neurons in \nthe layer below and it multiplies the activity of a neuron in the layer below by the \nweight, then adds all that up and gives an output that’s a function of that sum. By \nadjusting the weights on the connections, you can get networks that do anything \nyou like, such as looking at a picture of a cat and labeling it as a cat.\nThe question is, how should you adjust the weights so that the network does what \nyou want? There’s a very simple algorithm that will actually work but is incredibly \nslow—it’s a dumb mutation algorithm—where you start with random weights on \nall the connections, and you give your network a set of examples and see how well \nit works. You then take one of those weights, and you change it a little bit, and \nnow you give it another set of examples to see if it works better or worse than it \ndid before. If it works better than it did before, you keep the change you made. \nIf it works worse than it did before, you don’t keep that change, or perhaps you \nchange the weight in the opposite direction. Then you take another weight, and \nyou do the same thing. \nYou have to go around all of the weights, and for each weight, you have to measure \nhow well the network does on a set of examples, with each weight having to be \nupdated multiple times. It is an incredibly slow algorithm, but it works, and it’ll \ndo whatever you want.\nBackpropagation is basically a way of achieving the same thing. It’s a way of tinkering \nwith the weights so that the network does what you want, but unlike the dumb \nalgorithm, it’s much, much faster. It’s faster by a factor of how many weights there \nare in the network. If you’ve got a network with a billion weights, backpropagation \nis going to be a billion times faster than the dumb algorithm. \nThe dumb algorithm works by having you adjust one of the weights slightly, followed \nby you measuring to see how well the network does. For evolution, that’s what \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 252
  },
  {
    "chunk_full": "GEOFFREY HINTON\n73\nyou’ve got to do because the process that takes you from your genes to the finished \nproduct depends on the environment you’re in. There’s no way you can predict \nexactly what the phenotype will look like from the genotype, or how successful the \nphenotype will be because that depends on what’s going on in the world. \nIn a neural net, however, the processor takes you from the input and the weights \nto how successful you are in producing the right output. You have control over \nthat whole process because it’s all going on inside the neural net; you know all \nthe weights that are involved. Backpropagation makes use of all that by sending \ninformation backward through the net. Using the fact that it knows all the weights, \nit can compute in parallel for every single weight in the network, whether you \nshould make it a little bit bigger or smaller to improve the output. \nThe difference is that in evolution, you measure the effect of a change, and in \nbackpropagation, you compute what the effect would be of making a change, and you \ncan do that for all the weights at once with no interference. With backpropagation \nyou can adjust the weights rapidly because you can give it a few examples, then \nbackpropagate the discrepancies between what it said and what it should have said, \nand now you can figure out how to change all of the weights simultaneously to \nmake all of them a little bit better. You still need to do the process a number of \ntimes, but it’s much faster than the evolutionary approach.\nMARTIN FORD: The backpropagation algorithm was originally created by David \nRumelhart, correct, and you took that work forward?\nGEOFFREY HINTON: Lots of different people invented different versions of \nbackpropagation before David Rumelhart. They were mainly independent inventions, \nand it’s something I feel I’ve got too much credit for. I’ve seen things in the press \nthat say I invented backpropagation, and that’s completely wrong. It’s one of these \nrare cases when an academic feels he’s got too much credit for something! My main \ncontribution was to show how you can use it for learning distributed representations, \nso I’d like to set the record straight on that.\nIn 1981, I was a postdoc in San Diego, California and David Rumelhart came up \nwith the basic idea of backpropagation, so it’s his invention. Myself and Ronald \nWilliams worked with him on formulating it properly. We got it working, but we \ndidn’t do anything particularly impressive with it, and we didn’t publish anything. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 253
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n74\nAfter that, I went off to Carnegie Mellon and worked on the Boltzmann machine, \nwhich I think of as a much more interesting idea, even though it doesn’t work as \nwell. Then in 1984, I went back and tried backpropagation again so I could compare \nit with the Boltzmann machine, and discovered it actually worked much better, so \nI started communicating with David Rumelhart again. \nWhat got me really excited about backpropagation was what I called the \nfamily trees task, where you could show that backpropagation can learn \ndistributed representations. I had been interested in the brain having distributed \nrepresentations since high school, and finally, we had an efficient way to learn \nthem! If you gave it a problem, such as if I was to input two words and it \nhas to output the third word that goes with that, it would learn distributed \nrepresentations for the words, and those distributed representations would capture \nthe meanings of the words. \nBack in the mid-1980s, when computers were very slow, I used a simple example \nwhere you would have a family tree, and I would tell you about relationships \nwithin that family tree. I would tell you things like Charlotte’s mother is Victoria, \nso I would say Charlotte and mother, and the correct answer is Victoria. I would \nalso say Charlotte and father, and the correct answer is James. Once I’ve said \nthose two things, because it’s a very regular family tree with no divorces, you \ncould use conventional AI to infer using your knowledge of family relations that \nVictoria must be the spouse of James because Victoria is Charlotte’s mother and \nJames is Charlotte’s father. The neural net could infer that too, but it didn’t do \nit by using rules of inference, it did it by learning a bunch of features for each \nperson. Victoria and Charlotte would both be a bunch of separate features, and \nthen by using interactions between those vectors of features, that would cause the \noutput to be the features for the correct person. From the features for Charlotte \nand from the features for mother, it could derive the features for Victoria, and \nwhen you trained it, it would learn to do that. The most exciting thing was that \nfor these different words, it would learn these feature vectors, and it was learning \ndistributed representations of words. \nWe submitted a paper to Nature in 1986 that had this example of backpropagation \nlearning distributed features of words, and I talked to one of the referees of the \npaper, and that was what got him really excited about it, that this system was \nlearning these distributed representations. He was a psychologist, and he understood \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 254
  },
  {
    "chunk_full": "GEOFFREY HINTON\n75\nthat having a learning algorithm that could learn representations of things was a big \nbreakthrough. My contribution was not discovering the backpropagation algorithm, \nthat was something Rumelhart had pretty much figured out, it was showing that \nbackpropagation would learn these distributed representations, and that was what \nwas interesting to psychologists, and eventually, to AI people. \nQuite a few years later, in the early 1990s, Yoshua Bengio rediscovered the same \nkind of network but at a time where computers were faster. Yoshua was applying it \nto language, so he would take real text, taking a few words as context, and then try \nand predict the next word. He showed that the neural network was pretty good at \nthat and that it would discover these distributed representations of words. It made \na big impact because the backpropagation algorithm could learn representations and \nyou didn’t have to put them in by hand. People like Yann LeCun had been doing \nthat in computer vision for a while. He was showing that backpropagation would \nlearn good filters for processing visual input in order to make good decisions, and \nthat was a bit more obvious because we knew the brain did things like that. The \nfact that backpropagation would learn distributed representations that captured the \nmeanings and the syntax of words was a big breakthrough.\nMARTIN FORD: Is it correct to say that at that time using neural networks was \nstill not a primary thrust of AI research? It’s only quite recently this has come \nto the forefront.\nGEOFFREY HINTON: There’s some truth to that, but you also need to make a \ndistinction between AI and machine learning on the one hand, and psychology on the \nother hand. Once backpropagation became popular in 1986, a lot of psychologists \ngot interested in it, and they didn’t really lose their interest in it, they kept believing \nthat it was an interesting algorithm, maybe not what the brain did, but an interesting \nway of developing representations. Occasionally, you see the idea that there were \nonly a few people working on it, but that’s not true. In psychology, lots of people \nstayed interested in it. What happened in AI was that in the late 1980s, Yann LeCun \ngot something impressive working for recognizing handwritten digits, and there were \nvarious other moderately impressive applications of backpropagation from things \nlike speech recognition to predicting credit card fraud. However, the proponents of \nbackpropagation thought it was going to do amazing things, and they probably did \noversell it. It didn’t really live up to the expectations we had for it. We thought it \nwas going to be amazing, but actually, it was just pretty good. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 255
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n76\nIn the early 1990s, other machine learning methods on small datasets turned out to \nwork better than backpropagation and required fewer things to be fiddled with to get \nthem to work well. In particular, something called the support vector machine did \nbetter at recognizing handwritten digits than backpropagation, and handwritten digits \nhad been a classic example of backpropagation doing something really well. Because \nof that, the machine learning community really lost interest in backpropagation. They \ndecided that there was too much fiddling involved, it didn’t work well enough to \nbe worth all that fiddling, and it was hopeless to think that just from the inputs \nand outputs you could learn multiple layers of hidden representations. Each layer \nwould be a whole bunch of feature detectors that represent in a particular way. \nThe idea of backpropagation was that you’d learn lots of layers, and then you’d be able \nto do amazing things, but we had great difficulty learning more than a few layers, and \nwe couldn’t do amazing things. The general consensus among statisticians and people \nin AI was that we were wishful thinkers. We thought that just from the inputs and \noutputs, you should be able to learn all these weights; and that was just unrealistic. \nYou were going to have to wire in lots of knowledge to make anything work. \nThat was the view of people in computer vision until 2012. Most people in computer \nvision thought this stuff was crazy, even though Yann LeCun sometimes got systems \nworking better than the best computer vision systems, they still thought this stuff \nwas crazy, it wasn’t the right way to do vision. They even rejected papers by Yann, \neven though they worked better than the best computer vision systems on particular \nproblems, because the referees thought it was the wrong way to do things. That’s a \nlovely example of scientists saying, “We’ve already decided what the answer has to look \nlike, and anything that doesn’t look like the answer we believe in is of no interest.” \nIn the end, science won out, and two of my students won a big public competition, \nand they won it dramatically. They got almost half the error rate of the best \ncomputer vision systems, and they were using mainly techniques developed in Yann \nLeCun’s lab but mixed in with a few of our own techniques as well. \nMARTIN FORD: This was the ImageNet competition?\nGEOFFREY HINTON: Yes, and what happened then was what should happen in \nscience. One method that people used to think of as complete nonsense had now \nworked much better than the method they believed in, and within two years, they \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 256
  },
  {
    "chunk_full": "GEOFFREY HINTON\n77\nall switched. So, for things like object classification, nobody would dream of trying \nto do it without using a neural network now. \nMARTIN FORD: This was back in 2012, I believe. Was that the inflection point \nfor deep learning?\nGEOFFREY HINTON: For computer vision, that was the inflection point. For \nspeech, the inflection point was a few years earlier. Two different graduate students \nat Toronto showed in 2009 that you could make a better speech recognizer using \ndeep learning. They went as interns to IBM and Microsoft, and a third student \ntook their system to Google. The basic system that they had built was developed \nfurther, and over the next few years, all these companies’ labs converted to doing \nspeech recognition using neural nets. Initially, it was just using neural networks for \nthe frontend of their system, but eventually, it was using neural nets for the whole \nsystem. Many of the best people in speech recognition had switched to believing \nin neural networks before 2012, but the big public impact was in 2012, when the \nvision community, almost overnight, got turned on its head and this crazy approach \nturned out to win. \nMARTIN FORD: If you read the press now, you get the impression that neural \nnetworks and deep learning are equivalent to artificial intelligence—that it’s \nthe whole field.\nGEOFFREY HINTON: For most of my career, there was artificial intelligence, which \nmeant the logic-based idea of making intelligent systems by putting in rules that \nallowed them to process symbol strings. People believed that’s what intelligence \nwas, and that’s how they were going to make artificial intelligence. They thought \nintelligence consists of processing symbol strings according to rules, they just had to \nfigure out what the symbol strings were and what the rules were, and that was AI. \nThen there was this other thing that wasn’t AI at all, and that was neural networks. \nIt was an attempt to make intelligence by mimicking how the brain learns. \nNotice that standard AI wasn’t particularly interested in learning. In the 1970s, \nthey would always say that learning’s not the point. You have to figure out what \nthe rules are and what the symbolic expressions they’re manipulating are, and \nwe can worry about learning later. Why? Because the main point is reasoning. \nUntil you’ve figured out how it does reasoning, there’s no point thinking about \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 257
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n78\nlearning. The logic-based people were interested in symbolic reasoning, whereas the \nneural network-based people were interested in learning, perception, and motor \ncontrol. They’re trying to solve different problems, and we believe that reasoning \nis something that evolutionarily comes very late in people, and it’s not the way to \nunderstand the basics of how the brain works. It’s built on top of something that’s \ndesigned for something else. \nWhat’s happened now is that industry and government use “AI” to mean deep \nlearning, and so you get some really paradoxical things. In Toronto, we’ve received \na lot of money from the industry and government for setting up the Vector Institute, \nwhich does basic research into deep learning, but also helps the industry do deep \nlearning better and educates people in deep learning. Of course, other people would \nlike some of this money, and another university claimed they had more people doing \nAI than in Toronto and produced citation figures as evidence. That’s because they \nused classical AI. They used citations of conventional AI to say they should get some \nof this money for deep learning, and so this confusion in the meaning of AI is quite \nserious. It would be much better if we just didn’t use the term “AI.” \nMARTIN FORD: Do you really think that AI should just be focused on neural \nnetworks and that everything else is irrelevant? \nGEOFFREY HINTON: I think we should say that the general idea of AI is making \nintelligent systems that aren’t biological, they are artificial, and they can do \nclever things. Then there’s what AI came to mean over a long period, which \nis what’s sometimes called good old-fashioned AI: representing things using \nsymbolic expressions. For most academics—at least, the older academics—that’s \nwhat AI means: that commitment to manipulating symbolic expressions as a \nway to achieve intelligence. \nI think that old-fashioned notion of AI is just wrong. I think they’re making a very \nnaive mistake. They believe that if you have symbols coming in and you have symbols \ncoming out, then it must be symbols in-between all the way. What’s in-between is \nnothing like strings of symbols, it’s big vectors of neural activity. I think the basic \npremise of conventional AI is just wrong.\nMARTIN FORD: You gave an interview toward the end of 2017 where you said that \nyou were suspicious of the backpropagation algorithm and that it needed to be \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 258
  },
  {
    "chunk_full": "GEOFFREY HINTON\n79\nthrown out and we needed to start from scratch.1 That created a lot of disturbance, \nso I wanted to ask what you meant by that. \nGEOFFREY HINTON: The problem was that the context of the conversation wasn’t \nproperly reported. I was talking about trying to understand the brain, and I was raising \nthe issue that backpropagation may not be the right way to understand the brain. We \ndon’t know for sure, but there are some reasons now for believing that the brain might \nnot use backpropagation. I said that if the brain doesn’t use backpropagation, then \nwhatever the brain is using would be an interesting candidate for artificial systems. I \ndidn’t at all mean that we should throw out backpropagation. Backpropagation is the \nmainstay of all the deep learning that works, and I don’t think we should get rid of it.\nMARTIN FORD: Presumably, it could be refined going forward? \nGEOFFREY HINTON: There’s going to be all sorts of ways of improving it, and there \nmay well be other algorithms that are not backpropagation that also work, but I \ndon’t think we should stop doing backpropagation. That would be crazy. \nMARTIN FORD: How did you become interested in artificial intelligence? What was \nthe path that took you to your focus on neural networks?\nGEOFFREY HINTON: My story begins at high school, where I had a friend called \nInman Harvey who was a very good mathematician who got interested in the idea \nthat the brain might work like a hologram. \nMARTIN FORD: A hologram being a three-dimensional representation? \nGEOFFREY HINTON: Well, the important thing about a proper hologram is that \nif you take a hologram and you cut it in half, you do not get half the picture, but \ninstead you get a fuzzy picture of the whole scene. In a hologram, information \nabout the scene is distributed across the whole hologram, which is very different \nfrom what we’re used to. It’s very different from a photograph, where if you cut \nout a piece of a photograph you lose the information about what was in that piece \nof the photograph, it doesn’t just make the whole photograph go fuzzier.\n1 See: https://www.axios.com/artificial-intelligence-pioneer-says-we-need-to-start-over-1513305524-\nf619efbd-9db0-4947-a9b2-7a4c310a28fe.html\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 259
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n80\nInman was interested in the idea that human memory might work like that, where \nan individual neuron is not responsible for storing an individual memory. He \nsuggested that what’s happening in the brain is that you adjust the connection \nstrengths between neurons across the whole brain to store each memory, and that \nit’s basically a distributed representation. At that time, holograms were an obvious \nexample of distributed representation. \nPeople misunderstand what’s meant by distributed representation, but what I think \nit means is you’re trying to represent some things—maybe concepts—and each \nconcept is represented by activity in a whole bunch of neurons, and each neuron \nis involved in the representations of many different concepts. It’s very different \nfrom a one-to-one mapping between neurons and concepts. That was the first thing \nthat got me interested in the brain. We were also interested in how brains might \nlearn things by adjusting connection strengths, and so I’ve been interested in that \nbasically the whole time.\nMARTIN FORD: When you were at high school? Wow. So how did your thinking \ndevelop when you went to university? \nGEOFFREY HINTON: One of the things I studied at university was physiology. I \nwas excited by physiology because I wanted to learn how the brain worked. Toward \nthe end of the course they told us how neurons send action potentials. There were \nexperiments done on the giant squid axon, figuring out how an action potential \npropagated along an axon, and it turned out that was how the brain worked. It \nwas rather disappointing to discover, however, that they didn’t have any kind of \ncomputational model of how things were represented or learned.\nAfter that, I switched to psychology, thinking they would tell me how the brain \nworked, but this was at Cambridge, and at that time it was still recovering from \nbehaviorism, so psychology was largely about rats in boxes. There was some cognitive \npsychology then but they were fairly non-computational, and I didn’t really get much \nsense that they were ever going to figure out how the brain worked. \nDuring the psychology course, I did a project on child development. I was looking \nat children between the ages of two and five, and how the way that they attend to \ndifferent perceptual properties changes as they develop. The idea is that when they’re \nvery young, they’re mainly interested in color and texture, but as they get older, \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 260
  },
  {
    "chunk_full": "GEOFFREY HINTON\n81\nthey become more interested in shape. I conducted an experiment where I would \nshow the children three objects, of which one was the odd one out, for example, \ntwo yellow circles and a red circle. I trained the children to point at the odd one \nout, something that even very young children can learn to do. \nI’d also train them on two yellow triangles and one yellow circle, and then they’d \nhave to point at the circle because that was the odd one out on shape. Once they’d \nbeen trained on simple examples where there was a clear odd one out, I would \nthen give them a test example like a yellow triangle, a yellow circle, and a red \ncircle. The idea was that if they were more interested in color than shape, then \nthe odd one out would be the red circle, but if they were more interested in shape \nthan color, then the odd one out would be the yellow triangle. That was all well \nand good, and for a couple of children, they pointed out either the yellow triangle \nthat was a different shape or the red circle that was a different color. I remember, \nthough, that when I first did the test with one bright five-year-old, he pointed at \nthe red circle, and he said, “You’ve painted that one the wrong color.”\nThe model that I was trying to corroborate was a very dumb, vague model that \nsaid, “when they’re little, children attend more to color and as they get bigger, \nthey attend more to shape.” It’s an incredibly primitive model that doesn’t say \nhow anything works, it’s just a slight change in emphasis from color to shape. \nThen, I was confronted by this kid who looks at them and says, “You’ve painted \nthat one the wrong color.” Here’s an information processing system that has \nlearned what the task is from the training examples, and because he thinks there \nshould be an odd one out, he realizes there isn’t a single odd one out, and that \nI must have made a mistake, and the mistake was probably that I painted that \none the wrong color. \nNothing in the model of children that I was testing allowed for that level of \ncomplexity at all. This was hugely more complex than any of the models in \npsychology. It was an information processing system that was smart and could \nfigure out what was going on, and for me, that was the end of psychology. The \nmodels they had were hopelessly inadequate compared with the complexity of what \nthey were dealing with. \nMARTIN FORD: After leaving the field of psychology, how did you end up going \ninto artificial intelligence?\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 261
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n82\nGEOFFREY HINTON: Well, before I moved into the world of AI, I became a \ncarpenter, and whilst I enjoyed it, I wasn’t an expert at it. During that time, I \nmet a really good carpenter, and it was highly depressing, so because of that I \nwent back to academia.\nMARTIN FORD: Well, given the other path that opened up for you, it’s probably a \ngood thing that you weren’t a great carpenter! \nGEOFFREY HINTON: Following my attempt at carpentry, I worked as a research \nassistant on a psychology project trying to understand how language develops in \nvery young children, and how it is influenced by social class. I was responsible for \ncreating a questionnaire that would assess the attitude of the mother toward their \nchild’s language development. I cycled out to a very poor suburb of Bristol, and I \nknocked on the door of the first mother I was due to talk to. She invited me in and \ngave me a cup of tea, and then I asked her my first question, which was: “What’s \nyour attitude towards your child’s use of language?” She replied, “If he uses language, \nwe hit him.” So that was pretty much it for my career as a social psychologist. \nAfter that I went into AI and became a graduate student in artificial intelligence \nat The University of Edinburgh. My adviser was a very distinguished scientist \ncalled Christopher Longuet-Higgins who’d initially been a professor of chemistry \nat Cambridge and had then switched fields to artificial intelligence. He was very \ninterested in how the brain might work—and in particular, studying things like \nholograms. He had realized that computer modeling was the way to understand \nthe brain, and he was working on that, and that’s why I originally signed up \nwith him. Unfortunately for me, about the same time that I signed up with him, \nhe changed his mind. He decided that these neural models were not the way to \nunderstand intelligence, and the actual way to understand intelligence was to \ntry and understand language. \nIt’s worth remembering that at the time, there were some impressive models—using \nsymbol processing—of systems that could talk about arrangements of blocks. An \nAmerican professor of computer science called Terry Winograd wrote a very nice \nthesis that showed how you could get a computer to understand some language \nand to answer questions, and it would actually follow commands. You could say \nto it, “put the block that’s in the blue box on top of the red cube,” and it would \nunderstand and do that. It was only in a simulation, but it would understand the \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 262
  },
  {
    "chunk_full": "GEOFFREY HINTON\n83\nsentence. That impressed Christopher Longuet-Higgins a lot, and he wanted me to \nwork on that, but I wanted to keep working on neural networks. \nNow, Christopher was a very honorable guy, but we completely disagreed on \nwhat I should do. I kept refusing to do what he said, but he kept me on anyway. \nI continued my work on neural networks, and eventually, I did a thesis on neural \nnetworks, though at the time, neural networks didn’t work very well and there \nwas a consensus that they were just nonsense. \nMARTIN FORD: When was this in relation to Marvin Minsky and Seymour \nPapert’s Perceptrons book? \nGEOFFREY HINTON: This was in the early ‘70s, and Minsky and Papert’s book \ncame out in the late ‘60s. Almost everybody in artificial intelligence thought that \nwas the end of neural networks. They thought that trying to understand intelligence \nby studying neural networks was like trying to understand intelligence by studying \ntransistors; it just wasn’t the way to do it. They thought intelligence was all about \nprograms, and you had to understand what programs the brain was using. \nThese two paradigms were completely different, they aimed to try and solve \ndifferent problems, and they used completely different methods and different kinds \nof mathematics. Back then, it wasn’t at all clear which was going to be the winning \nparadigm. It’s still not clear to some people today.\nWhat was interesting, was that some of the people most associated with logic actually \nbelieved in the neural net paradigm. The biggest examples are John von Neumann \nand Alan Turing, who both thought that big networks of simulated neurons were a \ngood way to study intelligence and figure out how those things work. However, the \ndominant approach in AI was symbol processing inspired by logic. In logic, you take \nsymbol strings and alter them to arrive at new symbol strings, and people thought \nthat must be how reasoning works. \nThey thought neural nets were far too low-level, and that they were all about \nimplementation, just like how transistors are the implementation layer in a computer. \nThey didn’t think you could understand intelligence by looking at how the brain is \nimplemented, they thought you could only understand it by looking at intelligence \nin itself, and that’s what the conventional AI approach was. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 263
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n84\nI think it was disastrously wrong, something that we’re now seeing. The success \nof deep learning is showing that the neural net paradigm is actually far more \nsuccessful than the logic-based paradigm, but back then in the 1970s, that was \nnot what people thought. \nMARTIN FORD: I’ve seen a lot of articles in the press suggesting deep learning \nis being overhyped, and this hype could lead to disappointment and then less \ninvestment, and so forth. I’ve even seen the phrase “AI Winter” being used. Is that \na real fear? Is this potentially a dead end, or do you think that neural networks \nare the future of AI? \nGEOFFREY HINTON: In the past when AI has been overhyped—including \nbackpropagation in the 1980s—people were expecting it to do great things, and it \ndidn’t actually do things as great as they hoped. Today, it’s already done great things, \nso it can’t possibly all be just hype. It’s how your cell phone recognizes speech, it’s \nhow a computer can recognize things in photos, and it’s how Google does machine \ntranslation. Hype means you’re making big promises, and you’re not going to live \nup to them, but if you’ve already achieved them, that’s clearly not hype. \nI occasionally see an advertisement on the web that says it’s going to be a 19.9 \ntrillion-dollar industry. That seems like rather a big number, and that might be \nhype, but the idea that it’s a multi-billion-dollar industry clearly isn’t hype, because \nmultiple people have put billions of dollars into it and it’s worked for them. \nMARTIN FORD: Do you believe the best strategy going forward is to continue to \ninvest exclusively in neural networks? Some people still believe in symbolic AI, and \nthey think there’s potentially a need for a hybrid approach that incorporates both \ndeep learning and more traditional approaches. Would you be open to that, or do \nyou think the field should focus only on neural networks?\nGEOFFREY HINTON: I think big vectors of neural activities interacting with each \nother is how the brain works, and it’s how AI is going to work. We should definitely \ntry and figure out how the brain does reasoning, but I think that’s going to come \nfairly late compared with other things.\nI don’t believe hybrid systems are the answer. Let’s use the car industry as an \nanalogy. There are some good things about a petrol engine, like you can carry \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 264
  },
  {
    "chunk_full": "GEOFFREY HINTON\n85\na lot of energy in a small tank, but there are also some really bad things about \npetrol engines. Then there are electric motors, which have a lot to be said in their \nfavor compared with petrol engines. Some people in the car industry agreed that \nelectrical engines were achieving progress and then said they’d make a hybrid \nsystem and use the electric motor to inject the petrol into the engine. That’s how \npeople in conventional AI are thinking. They have to admit that deep learning is \ndoing amazing things, and they want to use deep learning as a kind of low-level \nservant to provide them with what they need to make their symbolic reasoning \nwork. It’s just an attempt to hang on to the view they already have, without really \ncomprehending that they’re being swept away.\nMARTIN FORD: Thinking more in terms of the future of the field, I know your \nlatest project is something you’re calling Capsules, which I believe is inspired by \nthe columns in the brain. Do you feel that it’s important to study the brain and \nbe informed by that, and to incorporate those insights into what you’re doing \nwith neural networks?\nGEOFFREY HINTON: Capsules is a combination of half a dozen different ideas, and \nit’s complicated and speculative. So far, it’s had some small successes, but it’s not \nguaranteed to work. It’s probably too early to talk about that in detail, but yes, it \nis inspired by the brain.\nWhen people talk about using neuroscience in neural networks, most people have \na very naive idea of science. If you’re trying to understand the brain, there’s \ngoing to be some basic principles, and there’s going to be a whole lot of details. \nWhat we’re after is the basic principles, and we expect the details all to be very \ndifferent if we use different kinds of hardware. The hardware we have in graphics \nprocessor units (GPUs) is very different from the hardware in the brain, and one \nmight expect lots of differences, but we can still look for principles. An example \nof a principle is that most of the knowledge in your brain comes from learning, it \ndoesn’t come from people telling you facts that you then store as facts. \nWith conventional AI, people thought that you have this big database of facts. You \nalso have some rules of inference. If I want to give you some knowledge, what I \ndo is simply express one of these facts in some language and then transplant it into \nyour head, and now you have the knowledge. That’s completely different from what \nhappens in neural networks: You have a whole lot of parameters in your head, that \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 265
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n86\nis weights of connections between neurons, and I have a whole lot of weights of \nconnections between the neurons in my head, and there’s no way that you can give \nme your connection strengths. Anyway, they wouldn’t be any use to me because my \nneural network’s not exactly the same as yours. What you have to do is somehow \nconvey information about how you are working so that I can work the same way, \nand you do that by giving me examples of inputs and outputs. \nFor example, if you look at a tweet from Donald Trump, it’s a big mistake to \nthink that what Trump is doing is conveying facts. That’s not what he’s doing. What \nTrump is doing is saying that given a particular situation, here’s a way you might \nchoose to respond. A Trump follower can then see the situation, they can see how \nTrump thinks they ought to respond, and they can learn to respond the same way \nas Trump. It’s not that some proposition is being conveyed from Trump to the \nfollower, it’s that a way of reacting to things has been conveyed by example. That’s \nvery different from a system that has a big store of facts, and you can copy facts \nfrom one system to another. \nMARTIN FORD: Is it true that the vast majority of applications of deep learning \nrely heavily on labeled data, or what’s called supervised learning, and that we still \nneed to solve unsupervised learning? \nGEOFFREY HINTON: That’s not entirely true. There’s a lot of reliance on labeled \ndata, but there are some subtleties in what counts as labeled data. For example, if \nI give you a big string of text and I ask you to try and predict the next word, then \nI’m using the next word as a label of what the right answer is, given the previous \nwords. In that sense, it’s labeled, but I didn’t need an extra label over and above \nthe data. If I give you an image and you want to recognize cats, then I need to give \nyou a label “cat,” and the label “cat” is not part of the image. I’m having to create \nthese extra labels, and that’s hard work.\nIf I’m just trying to predict what happens next, that’s supervised learning \nbecause what happens next acts as the label, but I don’t need to add extra \nlabels. There’s this thing in between unlabeled data and labeled data, which is \npredicting what comes next. \nMARTIN FORD: If you look at the way a child learns, though, it’s mostly wandering \naround the environment and learning in a very unsupervised way. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 266
  },
  {
    "chunk_full": "GEOFFREY HINTON\n87\nGEOFFREY HINTON: Going back to what I just said, the child is wandering around \nthe environment trying to predict what happens next. Then when what happens next \ncomes along, that event is labeled to tell it whether it got it right or not. The point \nis, with both those terms, “supervised” and “unsupervised,” it’s not clear how you \napply them to predicting what happens next. \nThere’s a nice clear case of supervised learning, which is that I give you an image and \nI give you the label “cat,” then you have to say it’s a cat, then there’s a nice clear case \nof unsupervised learning, which is if I give you a bunch of images, and you have to \nbuild representations of what’s going on in the images. Finally, there’s something that \ndoesn’t fall simply into either camp, which is if I give you a sequence of images and \nyou have to predict the next image. It’s not clear in that case whether you should call \nthat supervised learning or unsupervised learning, and that causes a lot of confusion. \nMARTIN FORD: Would you view solving a general form of unsupervised learning \nas being one of the primary obstacles that needs to be overcome?\nGEOFFREY HINTON: Yes. But in that sense, one form of unsupervised learning \nis predicting what happens next, and my point is that you can apply supervised \nlearning algorithms to do that.\nMARTIN FORD: What do you think about AGI, and how would you define that? \nI would take it to mean human-level artificial intelligence, namely an AI that \ncan reason in a general way, like a human. Is that your definition, or would you \nsay it’s something else?\nGEOFFREY HINTON: I’m happy with that definition, but I think people have various \nassumptions of what the future’s going to look like. People think that we’re going to \nget individual AIs that get smarter and smarter, but I think there are two things wrong \nwith that picture. One is that deep learning, or neural networks are going to get much \nbetter than us at some things, while they’re still quite a lot worse than us at other \nthings. It’s not like they’re going to get uniformly better at everything. They’re going \nto be much better, for example, at interpreting medical images, while they’re still a \nwhole lot worse at reasoning about them. In that sense, it’s not going to be uniform.\nThe second thing that’s wrong is that people always think about it as individual AIs, \nand they ignore the social aspect of it. Just for pure computational reasons, making \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 267
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n88\nvery advanced intelligence is going to involve making communities of intelligent \nsystems because a community can see much more data than an individual system. If \nit’s all a question of seeing a lot of data, then we’re going to have to distribute that \ndata across lots of different intelligent systems and have them communicate with one \nanother so that between them, as a community, they can learn from a huge amount \nof data meaning that in the future, the community aspect of it is going to be essential.\nMARTIN FORD: Do you envision it as being an emergent property of connected \nintelligences on the internet? \nGEOFFREY HINTON: No, it’s the same with people. The reason that you know \nmost of what you know is not because you yourself extracted that information from \ndata, it’s because other people, over many years, have extracted information from \ndata. They then gave you training experiences that allowed you to get to the same \nunderstanding without having to do the raw extraction from data. I think it’ll be \nlike that with artificial intelligence too. \nMARTIN FORD: Do you think AGI, whether it’s an individual system or a group of \nsystems that interact, is feasible? \nGEOFFREY HINTON: Oh, yes. I mean OpenAI already has something that plays \nquite sophisticated computer games as a team. \nMARTIN FORD: When do you think it might be feasible for an artificial intelligence, \nor a group of AIs that come together, to have the same reasoning, intelligence, and \ncapability as a human being?\nGEOFFREY HINTON: If you go for reasoning, I think that’s going to be one of the \nthings we get really good at later on, but it’s going to be quite a long time before \nbig neural networks are really as good as people at reasoning. That being said, they’ll \nbe better at all sorts of other things before we get to that point. \nMARTIN FORD: What about for a holistic AGI, though, where a computer system’s \nintelligence is as good as a person?\nGEOFFREY HINTON: I think there’s a presupposition that the way AIs can develop \nis by making individuals that are general-purpose robots like you see on Star Trek. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 268
  },
  {
    "chunk_full": "GEOFFREY HINTON\n89\nIf your question is, “When are we going to get a Commander Data?”, then I don’t \nthink that’s how things are going to develop. I don’t think we’re going to get single, \ngeneral-purpose things like that. I also think, in terms of general reasoning capacity, \nit’s not going to happen for quite a long time.\nMARTIN FORD: Think of it in terms of passing the Turing test, and not for five \nminutes but for two hours, so that you can have a wide-ranging conversation \nthat’s as good as a human being. Is that feasible, whether it’s one system or \nsome community of systems? \nGEOFFREY HINTON: I think there’s a reasonable amount of probability that it \nwill happen in somewhere between 10 and 100 years. I think there’s a very small \nprobability, it’ll happen before the end of the next decade, and I think there’s \nalso a big probability that humanity gets wiped out by other things before the \nnext 100 years occurs. \nMARTIN FORD: Do you mean through other existential threats like a nuclear \nwar or a plague?\nGEOFFREY HINTON: Yes, I think so. In other words, I think there are two \nexistential threats that are much bigger than AI. One is global nuclear war, and the \nother is a disgruntled graduate student in a molecular biology lab making a virus \nthat’s extremely contagious, extremely lethal, and has a very long incubation time. \nI think that’s what people should be worried about, not ultra-intelligent systems.\nMARTIN FORD: Some people, such as Demis Hassabis at DeepMind, do believe that \nthey can build the kind of system that you’re saying you don’t think is going to \ncome into existence. How do you view that? Do you think that it is a futile task?\nGEOFFREY HINTON: No, I view that as Demis and me having different \npredictions about the future.\nMARTIN FORD: Let’s talk about the potential risks of AI. One particular challenge \nthat I’ve written about is the potential impact on the job market and the economy. \nDo you think that all of this could cause a new Industrial Revolution and completely \ntransform the job market? If so, is that something we need to worry about, or is \nthat another thing that’s perhaps overhyped?\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 269
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n90\nGEOFFREY HINTON: If you can dramatically increase productivity and make more \ngoodies to go around, that should be a good thing. Whether or not it turns out \nto be a good thing depends entirely on the social system, and doesn’t depend at \nall on the technology. People are looking at the technology as if the technological \nadvances are a problem. The problem is in the social systems, and whether \nwe’re going to have a social system that shares fairly, or one that focuses all the \nimprovement on the 1% and treats the rest of the people like dirt. That’s nothing \nto do with technology.\nMARTIN FORD: That problem comes about, though, because a lot of jobs could be \neliminated—in particular, jobs that are predictable and easily automated. One social \nresponse to that is a basic income, is that something that you agree with?\nGEOFFREY HINTON: Yes, I think a basic income is a very sensible idea.\nMARTIN FORD: Do you think, then, that policy responses are required to \naddress this? Some people take a view that we should just let it play out, but \nthat’s perhaps irresponsible. \nGEOFFREY HINTON: I moved to Canada because it has a higher taxation rate and \nbecause I think taxes done right are good things. What governments ought to be is \nmechanisms put in place so that when people act in their own self-interest, it helps \neverybody. High taxation is one such mechanism: when people get rich, everybody \nelse gets helped by the taxes. I certainly agree that there’s a lot of work to be done \nin making sure that AI benefits everybody.\nMARTIN FORD: What about some of the other risks that you would associate with \nAI, such as weaponization? \nGEOFFREY HINTON: Yes, I am concerned by some of the things that President \nPutin has said recently. I think people should be very active now in trying to \nget the international community to treat weapons that can kill people without \na person in the loop the same way as they treat chemical warfare and weapons \nof mass destruction. \nMARTIN FORD: Would you favor some kind of a moratorium on that type of \nresearch and development?\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 270
  },
  {
    "chunk_full": "GEOFFREY HINTON\n91\nGEOFFREY HINTON: You’re not going to get a moratorium on that type of research, \njust as you haven’t had a moratorium on the development of nerve agents, but you \ndo have international mechanisms in place that have stopped them being widely used.\nMARTIN FORD: What about other risks, beyond the military weapon use? Are there \nother issues, like privacy and transparency?\nGEOFFREY HINTON: I think using it to manipulate elections and to manipulate \nvoters is worrying. Cambridge Analytica was set up by Bob Mercer who was a \nmachine learning person, and you’ve seen that Cambridge Analytica did a lot of \ndamage. We have to take that seriously.\nMARTIN FORD: Do you think that there’s a place for regulation?\nGEOFFREY HINTON: Yes, lots of regulation. It’s a very interesting issue, but I’m \nnot an expert on it, so don’t have much to offer.\nMARTIN FORD: What about the global arms race in general AI, do you think it’s \nimportant that one country doesn’t get too far ahead of the others? \nGEOFFREY HINTON: What you’re talking about is global politics. For a long time, \nBritain was a dominant nation, and they didn’t behave very well, and then it was \nAmerica, and they didn’t behave very well, and if it becomes the Chinese, I don’t \nexpect them to behave very well. \nMARTIN FORD: Should we have some form of industrial policy? Should the United \nStates and other Western governments focus on AI and make it a national priority? \nGEOFFREY HINTON: There are going to be huge technological developments, and \ncountries would be crazy not to try and keep up with that, so obviously, I think \nthere should be a lot of investment in it. That seems common sense to me.\nMARTIN FORD: Overall, are you optimistic about all of this? Do you think that the \nrewards from AI are going to outweigh the downsides? \nGEOFFREY HINTON: I hope the rewards will outweigh the downsides, but I don’t \nknow whether they will, and that’s an issue of social systems, not with the technology.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 271
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n92\nMARTIN FORD: There’s an enormous talent shortage in AI and everyone’s hiring. Is \nthere any advice you would give to a young person that wants to get into this field, \nanything that might help attract more people and enable them to become expert in \nAI and in deep learning, that you can offer?\nGEOFFREY HINTON: I’m worried that there may not be enough people who are \ncritical of the basics. The idea of Capsules is to say, maybe some of the basic ways \nwe’re doing things aren’t the best way of doing things, and we should throw a \nwider net. We should think about alternatives to some of the very basic assumptions \nwe’re making. The one piece of advice I give people is that if you have intuitions \nthat what people are doing is wrong and that there could be something better, \nyou should follow your intuitions. \nYou’re quite likely to be wrong, but unless people follow the intuitions when they \nhave them about how to change things radically, we’re going to get stuck. One \nworry is that I think the most fertile source of genuinely new ideas is graduate \nstudents being well advised in a university. They have the freedom to come up \nwith genuinely new ideas, and they learn enough so that they’re not just repeating \nhistory, and we need to preserve that. People doing a master’s degree and then \ngoing straight into the industry aren’t going to come up with radically new ideas. \nI think you need to sit and think for a few years.\nMARTIN FORD: There seems to be a hub of deep learning coalescing in Canada. Is \nthat just random, or is there something special about Canada that helped with that?\nGEOFFREY HINTON: The Canadian Institute for Advanced Research (CIFAR) provided \nfunding for basic research in high-risk areas, and that was very important. There’s also \na lot of good luck in that both Yann LeCun, who was briefly my postdoc, and Yoshua \nBengio were also in Canada. The three of us could form a collaboration that was very \nfruitful, and the Canadian Institute for Advanced Research funded that collaboration. \nThis was at a time when all of us would have been a bit isolated in a fairly hostile \nenvironment—the environment for deep learning was fairly hostile until quite \nrecently—it was very helpful to have this funding that allowed us to spend quite a lot of \ntime with each other in small meetings, where we could really share unpublished ideas.\nMARTIN FORD: So, it was a strategic investment on the part of the Canadian \ngovernment to keep deep learning alive?\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 272
  },
  {
    "chunk_full": "GEOFFREY HINTON\n93\nGEOFFREY HINTON: Yes. Basically, the Canadian government is significantly \ninvesting in advanced deep learning by spending half a million dollars a year, which is \npretty efficient for something that’s going to turn into a multi-billion-dollar industry.\nMARTIN FORD: Speaking of Canadians, do you have any interaction with your fellow \nfaculty member, Jordan Peterson? It seems like there’s all kinds of disruption coming \nout of the University of Toronto...\nGEOFFREY HINTON: Ha! Well, all I’ll say about that is that he’s someone who \ndoesn’t know when to keep his mouth shut.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 273
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n94\nGEOFFREY HINTON received his undergraduate degree from Kings College, Cambridge and \nhis PhD in Artificial Intelligence from the University of Edinburgh in 1978. After five years \nas a faculty member at Carnegie-Mellon University, he became a fellow of the Canadian \nInstitute for Advanced Research and moved to the Department of Computer Science at the \nUniversity of Toronto where he is now an Emeritus Distinguished Professor. He is also a \nVice President & Engineering Fellow at Google and Chief Scientific Adviser of the Vector \nInstitute for Artificial Intelligence. \nGeoff was one of the researchers who introduced the backpropagation algorithm and the \nfirst to use backpropagation for learning word embeddings. His other contributions to \nneural network research include Boltzmann machines, distributed representations, time-\ndelay neural nets, mixtures of experts, variational learning and deep learning. His research \ngroup in Toronto made seminal breakthroughs in deep learning that revolutionized speech \nrecognition and object classification.\nGeoff is a fellow of the UK Royal Society, a foreign member of the US National Academy \nof Engineering and a foreign member of the American Academy of Arts and Sciences. His \nawards include the David E. Rumelhart prize, the IJCAI award for research excellence, \nthe Killam prize for Engineering, the IEEE Frank Rosenblatt medal, the IEEE James Clerk \nMaxwell Gold medal, the NEC C&C award, the BBVA award, and the NSERC Herzberg \nGold Medal, which is Canada’s top award in science and engineering.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 274
  },
  {
    "chunk_full": "GEOFFREY HINTON\n95\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 275
  },
  {
    "chunk_full": "",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 276
  },
  {
    "chunk_full": "NICK BOSTROM\n97\nNICK BOSTROM\nPROFESSOR, UNIVERSITY OF OXFORD AND DIRECTOR OF THE FUTURE \nOF HUMANITY INSTITUTE\nNick Bostrom is widely recognized as one of the world’s top experts on \nsuperintelligence and the existential risks that AI and machine learning could \npotentially pose for humanity. He is the Founding Director of the Future of \nHumanity Institute at the University of Oxford, a multidisciplinary research \ninstitute studying big-picture questions about humanity and its prospects. He \nis a prolific author of over 200 publications, including the 2014 New York \nTimes bestseller Superintelligence: Paths, Dangers, Strategies.\nThe concern is not that [an AGI] would hate \nor resent us for enslaving it, or that suddenly a \nspark of consciousness would arise and it would \nrebel, but rather that it would be very competently \npursuing an objective that differs from what we \nreally want. Then you get a future shaped in \naccordance with alien criteria.\n“ \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 277
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n98\nMARTIN FORD: You’ve written about the risks of creating a superintelligence—an \nentity that could emerge when an AGI system turns its energies toward improving \nitself, creating a recursive improvement loop that results in an intelligence that is \nvastly superior to humans.\nNICK BOSTROM: Yes, that’s one scenario and one problem, but there are other \nscenarios and other ways this transition to a machine intelligence era could unfold, \nand there are certainly, other problems one could be worried about.\nMARTIN FORD: One idea you’ve focused on especially is the control or alignment \nproblem where a machine intelligence’s goals or values might result in outcomes \nthat are harmful to humanity. Can you go into more detail on what that alignment \nproblem, or control problem, is in layman’s terms?\nNICK BOSTROM: Well, one distinctive problem with very advanced AI systems \nthat’s different from other technologies is that it presents not only the possibility of \nhumans misusing the technology—that’s something we see with other technologies, \nof course—but also the possibility that the technology could misuse itself, as it were. \nIn other words, you create an artificial agent or a process that has its own goals \nand objectives, and it is very capable of achieving those objectives because, in this \nscenario, it is superintelligent. The concern is that the objectives that this powerful \nsystem is trying to optimize for are different from our human values, and maybe \neven at cross-purposes with what we want to achieve in the world. Then if you have \nhumans trying to achieve one thing and a superintelligent system trying to achieve \nsomething different, it might well be that the superintelligence wins and gets its way. \nThe concern is not that it would hate or resent us for enslaving it, or that suddenly \na spark of consciousness would arise and it would rebel, but rather that it would \nbe very competently pursuing an objective that differs from what we really want. \nThen you get a future shaped in accordance with alien criteria. The control \nproblem, or the alignment problem, then is how do you engineer AI systems so \nthat they are an extension of human will? In the sense that we have our intentions \nshape their behavior as opposed to a random, unforeseen and unwanted objective \ncropping up there?\nMARTIN FORD: You have a famous example of a system that manufactures paperclips. \nThe idea is that when a system is conceived and given an objective, it pursues that \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 278
  },
  {
    "chunk_full": "NICK BOSTROM\n99\ngoal with a superintelligent competence, but it does it in a way that doesn’t consider \ncommon sense, so it ends up harming us. The example you give is a system that \nturns the whole universe into paperclips because it’s a paperclip optimizer. Is that \na good articulation of the alignment problem?\nNICK BOSTROM: The paperclip example is a stand-in for a wider category of \npossible failures where you ask a system to do one thing and, perhaps, initially \nthings turn out pretty well but then it races to a conclusion that is beyond our \ncontrol. It’s a cartoon example, where you design an AI to operate a paperclip \nfactory. It’s dumb initially, but the smarter it gets, the better it operates the \npaperclip factory, and the owner of this factory is very pleased and wants to make \nmore progress. However, when the AI becomes sufficiently smart, it realizes that \nthere are other ways of achieving an even greater number of paperclips in the \nworld, which might then involve taking control away from humans and indeed \nturning the whole planet into paperclips or into space probes that can go out and \ntransform the universe into more paperclips. \nThe point here is that you could substitute almost any other goal you want for \npaperclips and if you think through what it would mean for that goal to be truly \nmaximized in this world, that unless you’re really, really careful about how you \nspecify your goals, you will find that as a side effect of maximizing for that goal \nhuman beings and the things we care about would be stamped out.\nMARTIN FORD: When I hear this problem described, it’s always given as a \nsituation where we give the system a goal, and then it pursues that goal in a \nway that we’re not happy with. However, I never hear of a system that simply \nchanges its goal, and I don’t quite understand why that is not a concern. Why \ncouldn’t a superintelligent system at some point just decide to have different \ngoals or objectives? Humans do it all of the time!\nNICK BOSTROM: The reason why this seems less of a concern is that although a \nsuperintelligence would have the ability to change its goals, you have to consider \nthe criteria it uses to choose its goals. It would make that choice based on the goals \nit has at that moment. In most situations, it would be a very poor strategic move \nfor an agent to change its goals because it can predict that in the future, there will \nthen not be an agent pursuing its current goal but instead an agent pursuing some \ndifferent goal. This would tend to produce outcomes that would rank lower by its \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 279
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n100\ncurrent goals, which by definition here are what it is using as the criteria by which \nto select actions. So, once you have a sufficiently sophisticated reasoning system, you \nexpect it to figure this out and therefore be able to achieve internal goal stability. \nHumans are a mess. We don’t have a particular goal from which all the other \nobjectives we pursue are sub-goals. We have different parts of our minds that are \npulling in different directions, and if you increase our hormone levels, we suddenly \nchange those values. Humans are not stable in the same way as machines, and maybe \ndon’t have a very clean, compact description as goal-maximizing agents. That’s \nwhy it can seem that we humans sometimes decide to change our goals. It’s not so \nmuch us deciding to change our goals; it’s our goals just changing. Alternatively, \nby “goals,” we don’t mean our fundamental criteria for judging things, but just \nsome particular objective, which of course can change as circumstances change or \nwe discover new plans.\nMARTIN FORD: A lot of the research going into this is informed by neural science, \nthough, so there are ideas coming from the human brain being injected into machine \nintelligence. Imagine a superintelligence that has at its disposal all of human \nknowledge. It would be able to read all of human history. It would read about \npowerful individuals, and how they had different objectives and goals. The machine \ncould also conceivably be subject to pathologies. The human brain has all kinds of \nproblems, and there are drugs that can change the way the brain works. How do \nwe know there’s not something comparable in the machine space? \nNICK BOSTROM: I think there well could be, particularly in the earlier stages \nof development, before the machine achieves sufficient understanding of how AI \nworks to be able to modify itself without messing itself up. Ultimately, there are \nconvergent instrumental reasons for developing technology to prevent your goals \nfrom being corrupted. I would expect a sufficiently capable system to develop those \ntechnologies for goal stability, and indeed it might place some priority on developing \nthem. However, if it’s in a rush or if it’s not yet very capable—if it’s roughly at the \nhuman level—the possibility certainly exists that things could get scrambled. A change \nmight be implemented with the hope that it would maybe make it a more effective \nthinker, but it turns out to have some side effect in changing its objective function. \nMARTIN FORD: The other thing that I worry about is that it’s always a concern \nabout how the machine is not going to do what we want, where “we” applies to \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 280
  },
  {
    "chunk_full": "NICK BOSTROM\n101\ncollective humanity as though there’s some sort of universal set of human desires \nor values. Yet, if you look at the world today, that’s really not the case. The world \nhas different cultures with different value sets. It seems to me that it might matter \nquite a lot where the first machine intelligence is developed. Is it naive to talk \nabout the machine and all of humanity as being one entity? To me, it just seems \nlike things are a lot messier than that\nNICK BOSTROM: You try to break up the big problem into smaller problems in \norder then to make progress on them. You try to break out one component of the \noverall challenge, in this case that is the technical problem of how to achieve AI \nalignment with any human values to get the machine to do what its developers want \nit to do. Unless you have a solution to that, you don’t have the privilege even to \ntry for a solution to the wider, political problems of ensuring that we humans will \nthen use this powerful technology for some beneficial purpose. \nYou need to solve the technical problem to get the opportunity to squabble over \nwhose values, or in what degrees different values should guide the use of this \ntechnology. It is true, of course, that even if you have a solution to the technical \ncontrol problem, you’ve really only solved part of the overall challenge. You also \nthen need to figure out a way that we can use this peacefully and in a way that \nbenefits all of humanity.\nMARTIN FORD: Is solving that technical control problem, in terms of how to build \na machine that remains aligned with the objective, what you’re working on at the \nFuture of Humanity Institute, and what other think tanks like OpenAI and the \nMachine Intelligence Research Institute are focusing on?\nNICK BOSTROM: Yes, that’s right. We do have a group working on that, but we’re \nalso working on other things. We also have a governance of AI group, that is focused \non the governance problems related to advances in machine intelligence.\nMARTIN FORD: Do you think that think tanks like yours are an appropriate level \nof resource allocation for AI governance, or do you think that governments should \njump into this at a larger scale? \nNICK BOSTROM: I think there could be more resources on AI safety. It’s not actually \njust us: DeepMind also has an AI safety group that we work with, but I do think \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 281
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n102\nmore resources would be beneficial. There is already a lot more talent and money \nnow than there was even four years ago. In percentage terms, there has been a \nrapid growth trajectory, even though in absolute terms it’s still a very small field.\nMARTIN FORD: Do you think that superintelligence concerns should be more in \nthe public sphere? Do you want to see presidential candidates in the United States \ntalking about superintelligence?\nNICK BOSTROM: Not really. It’s still a bit too early to seek involvement from states \nand governments because right now it’s not exactly clear what one would want \nthem to do that would be helpful at this point in time. The nature of the problem \nfirst needs to be clarified and understood better, and there’s a lot of work that can \nbe done without having governments come in. I don’t see any need right now for \nany particular regulations with respect to machine superintelligence. There are all \nkinds of things related to near-term AI applications where there might be various \nroles for governments to play.\nIf you’re going to have flying drones everywhere in the cities, or self-driving cars \non the streets, then there presumably needs to be a framework that regulates them. \nThe extent that AI will have an impact on the economy and the labor market is also \nsomething that should be of interest to people running education systems or setting \neconomic policy. I still think superintelligence is a little bit outside the purview of \npoliticians, who mainly think about what might happen during their tenure.\nMARTIN FORD: So, when Elon Musk says superintelligence is a bigger threat than \nNorth Korea, could that rhetoric potentially make things worse?\nNICK BOSTROM: If you are getting into this prematurely, with a view to there \nbeing a big arms race, which could lead to a more competitive situation where \nvoices for caution and global cooperation get sidelined, then yes, that could \nactually make things worse rather than better. I think one can wait until there \nis a clear concrete thing that one actually would need and want governments to \ndo in relation to superintelligence, and then one can try to get them activated. \nUntil that time, there’s still a huge amount of work that we can do, for example, \nin collaboration with the AI development community and with companies \nand academic institutions that are working with AI, so let’s get on with that \ngroundwork for the time being.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 282
  },
  {
    "chunk_full": "NICK BOSTROM\n103\nMARTIN FORD: How did you come to your role in the AI community? How \ndid you first become interested in AI, and how did your career develop to the \npoint it’s at right now?\nNICK BOSTROM: I’ve been interested in artificial intelligence for as long as I can \nremember. I studied artificial intelligence, and later computational neuroscience, \nat university, as well as other topics, like theoretical physics. I did this because I \nthought that firstly, AI technology could eventually be transformative in the world, \nand secondly because it’s very interesting intellectually to try to figure out how \nthinking is produced by the brain or in a computer.\nI published some work about superintelligence in the mid-1990s, and I had the \nopportunity in 2006 to create the Future of Humanity Institute (FHI) at Oxford \nUniversity. Together with my colleagues, I work full-time on the implications of \nfuture technologies for the future of humanity, with a particular focus—some \nmight say an obsession—on the future of machine intelligence. That then resulted \nin 2014 in my book Superintelligence: Paths, Dangers, Strategies. Currently, we have two \ngroups within the FHI. One group focuses on technical computer science work on \nthe alignment problem, so trying to craft algorithms for scalable control methods. \nThe other group focuses on governance, policy, ethics and the social implications \nof advances in machine intelligence.\nMARTIN FORD: In your work at the Future of Humanity Institute you’ve focused \non a variety of existential risks, not just AI-related dangers, right?\nNICK BOSTROM: That’s right, but we’re also looking at the existential opportunities, \nwe are not blind to the upside of technology.\nMARTIN FORD: Tell me about some of the other risks you’ve looked at, and why \nyou’ve chosen to focus so much on machine intelligence above all.\nNICK BOSTROM: At the FHI, we’re interested in really big-picture questions, \nthe things that could fundamentally change the human condition in some way. \nWe’re not trying to study what next year’s iPhone might be like, but instead \nthings that could change some fundamental parameter of what it means to be \nhuman—questions that shape the future destiny of Earth-originating intelligent \nlife. From that perspective, we are interested in existential risk—things that \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 283
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n104\ncould permanently destroy human civilization—and also things that could \npermanently shape our trajectory into the future. I think technology is maybe \nthe most plausible source for such fundamental reshapers of humanity, and within \ntechnology there are just a few that plausibly present either existential risks or \nexistential opportunities; AI might be the foremost amongst those. FHI also \nhas a group working on the biosecurity risks coming out of biotechnology, and \nwe’re interested more generally in how you put these different considerations \ntogether—a macro strategy, as we call it. \nWhy AI in particular? I think that if AI were to be successful at its original goal, \nwhich all along has been not just to automate specific tasks but to replicate in \nmachine substrates the general-purpose learning ability and planning ability that \nmakes us humans smart, then that would quite literally be the last invention that \nhumans ever needed to make. If achieved, it would have enormous implications \nnot just in AI, but across all technological fields, and indeed all areas where human \nintelligence currently is useful.\nMARTIN FORD: What about climate change, for example? Is that on your list of \nexistential threats?\nNICK BOSTROM: Not so much, partly because we prefer to focus where we think \nour efforts might make a big difference, which tends to be areas where the questions \nhave been relatively neglected. There are tons of people currently working on climate \nchange across the world. Also, it’s hard to see how the planet getting a few degrees \nwarmer would cause the extinction of the human species, or permanently destroy \nthe future. So, for those and some other reasons, that’s not been at the center of \nour own efforts, although we might cast a sideways glance at it on occasion by trying \nto sum up the overall picture of the challenges that humanity confronts. \nMARTIN FORD: So, you would argue that the risk from advanced AI is actually more \nsignificant than from climate change, and that we’re allocating our resources and \ninvestment in these questions incorrectly? That sounds like a very controversial view.\nNICK BOSTROM: I do think that there is some misallocation, and it’s not just \nbetween those two fields in particular. In general, I don’t think that we as a human \ncivilization allocate our attention that wisely. If we imagine humans as having an \namount of concern capital, chips of concern or fear that we can spread around \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 284
  },
  {
    "chunk_full": "NICK BOSTROM\n105\non different things that threaten human civilization, I don’t think we are that \nsophisticated in how we choose to allocate those concern chips. \nIf you look back over the last century, there has been at any given point in time \nmaybe one big global concern that all intellectually educated people are supposed to \nbe fixated on, and it’s changed over time. So maybe 100 years ago, it was dysgenics, \nwhere intellectuals were worrying about the deterioration of the human stock. Then \nduring the Cold War, obviously nuclear Armageddon was a big concern, and then for \na while, it was overpopulation. Currently, I would say it’s global warming, although \nAI has, over the last couple of years, been creeping up there. \nMARTIN FORD: That’s perhaps largely due to the influence of people like Elon \nMusk talking about it. Do you think that’s a positive thing that he’s been so \nvocal, or is there a danger that it becomes overhyped or it draws uninformed \npeople into the discussion?\nNICK BOSTROM: I think so far it has been met positively. When I was writing my \nbook, it was striking how neglected the whole topic of AI was. There were a lot \nof people working on AI, but very few people thinking about what would happen \nif AI were to succeed. It also wasn’t the kind of topic you could have a serious \nconversation with people about because they would dismiss it as just science fiction, \nbut that’s now changed. \nI think that’s valuable, and maybe as a consequence of this having become a more \nmainstream topic, it’s now possible to do research and publish technical papers on \nthings like the alignment problem. There are a number of research groups doing \njust that, including here at the FHI, where we have joint technical research seminars \nwith DeepMind, also OpenAI has a number of AI safety researchers, and there are \nother groups like the Machine Intelligence Research Institute at Berkeley. I’m not \nsure whether there would have been as much talent flowing into this field unless the \nprofile of the whole challenge had first been raised. What is most needed today is \nnot further alarm or further hand-wringing with people screaming for attention, the \nchallenge now is more to channel this existing concern and interest in constructive \ndirections and to get on with the work.\nMARTIN FORD: Is it true to say that the risks you worry about in terms of \nmachine intelligence are really all dependent on achieving AGI and beyond that, \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 285
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n106\nsuperintelligence? The risks associated with narrow AI are probably significant, but \nnot what you would characterize as existential.\nNICK BOSTROM: That’s correct. We do also have some interest in these more near-term \napplications of machine intelligence, which are interesting in their own right and also \nworth having a conversation about. I think the trouble arises when these two different \ncontexts, the near term, and the long term get thrown into the same pot and confused.\nMARTIN FORD: What are some of the near-term risks that we need to worry about \nover the next five years or so? \nNICK BOSTROM: In the near term, I think primarily there are things that I would \nbe very excited about and look forward to having roll out. In the near-term context, \nthe upside far outweighs the downside. Just look across to the economy and at all \nthe areas where having smarter algorithms could make a positive difference. Even \na low-key, boring algorithm running in the background in a big logistic center \npredicting demand curves more accurately would enable you to reduce the amount \nof stock, and therefore cut prices for consumers.\nIn healthcare, the same neural networks that can recognize cats, dogs, and faces \ncould recognize tumors in x-ray images and assist radiologists in making more \naccurate diagnoses. Those neural networks might run in the background and help \noptimize patient flows and track outcomes. You could name almost any area, and \nthere would probably be creative ways to use these new techniques that are emerging \nfrom machine learning to good effect. \nI think that’s a very exciting field, with a lot of opportunity for entrepreneurs. \nFrom a scientific point of view as well, it’s really exciting to begin to understand \na little bit about how intelligence works and how perception is performed by the \nbrain and in these neural systems.\nMARTIN FORD: A lot of people worry about the near-term risks of things like \nautonomous weapons that can make their own decisions about who to kill. Do you \nsupport a ban on weapons of those types?\nNICK BOSTROM: It would be positive if the world could avoid immediately jumping \ninto another arms race, where huge amounts of money are spent perfecting killer \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 286
  },
  {
    "chunk_full": "NICK BOSTROM\n107\nrobots. Broadly speaking, I’d prefer that machine intelligence is used for peaceful \npurposes, and not to develop new ways of destroying us. I think if one zooms \nin, it becomes a little bit less clear exactly what it is that one would want to see \nbanned by a treaty. \nThere’s a move to say that humans must be in the loop and that we should not \nhave autonomous drones make targeting decisions on their own, and maybe that is \npossible. However, the alternative is that you have exactly the same system in place, \nbut instead of the drone deciding to fire a missile, a19-year-old sits in Arlington, \nVirginia in front of a computer screen and has the job that whenever a window \npops up on the screen saying “Fire,” they need to press a red button. If that’s what \nhuman oversight amounts to, then it’s not clear that it really makes that much of a \ndifference from having the whole system be completely autonomous. I think maybe \nmore important is that there is some accountability, and there’s somebody whose \nbutt you can kick if things go wrong.\nMARTIN FORD: There are certain situations you can imagine where an autonomous \nmachine might be preferable. Thinking of policing rather than military applications, \nwe’ve had incidents in the United States of what appears to be police racism, for \nexample. A properly designed AI-driven robotic system in a situation like that would \nnot be biased. It would also be prepared to take a bullet first, and shoot second, \nwhich is really not an option for a human being. \nNICK BOSTROM: Preferably we shouldn’t be fighting any wars between ourselves \nat all, but if there are going to be wars, maybe it’s better if it’s machines killing \nmachines rather than young men shooting holes in other young men. If there are \ngoing to be strikes against specific combatants, maybe you can make precision \nstrikes that only kill the people you’re trying to kill, and don’t create collateral \ndamage with civilians. That’s why I’m saying that the overall calculation becomes \na little bit more complex when one considers the specifics, and what exactly the \nrule or agreement is that one would want to be implemented with regard to lethal \nautonomous weapons.\nThere are other areas of application that also raise interesting ethical questions such \nas in surveillance, or the management of data flows, marketing, and advertising, \nwhich might matter as much for the long-term outcome of human civilization as \nthese more direct applications of drones to kill or injure people.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 287
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n108\nMARTIN FORD: Do you feel there is a role for regulation of these technologies?\nNICK BOSTROM: Some regulation, for sure. If you’re going to have killer drones, \nyou don’t want any old criminal to be able to easily assassinate public officials from \nfive kilometers away using a drone with facial recognition software. Likewise, you \ndon’t want to have amateurs flying drones across airports and causing big delays. \nI’m sure a form of military framework will be required as we get more of these \ndrones traversing spaces where humans are traveling for other purposes.\nMARTIN FORD: It’s been about four years since your book Superintelligence: Paths, \nDangers, Strategies was published. Are things progressing at the rate that you expected?\nNICK BOSTROM: Progress has been faster than expected over the last few years, \nwith big advances in deep learning in particular. \nMARTIN FORD: You had a table in your book where you said that having a \ncomputer beat the best Go player in the world was a decade out, so that would \nhave been roughly 2024. As things turned out, it actually occurred just two \nyears after you published the book.\nNICK BOSTROM: I think the statement I made was that if progress continued at \nthe same rate as it had been going over the last several years, then one would \nexpect a Go Grand Champion machine to occur about a decade after the book \nwas written. However, the progress was faster than that, partly because there was \na specific effort toward solving Go. DeepMind took on the challenge and assigned \nsome good people to the task, and put a lot of computing power onto it. It was \ncertainly a milestone, though, and a demonstration of the impressive capabilities of \nthese deep learning systems. \nMARTIN FORD: What are the major milestones or hurdles that you would point to \nthat stand between us and AGI? \nNICK BOSTROM: There are several big challenges remaining in machine learning, \nsuch as needing better techniques for unsupervised learning. If you think about \nhow adult humans come to know all the things we do, only a small fraction \nof that is done through explicit instruction. Most of it is by us just observing \nwhat’s going on and using that sensory feed to improve our world models. We \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 288
  },
  {
    "chunk_full": "NICK BOSTROM\n109\nalso do a lot of trial and error as toddlers, banging different things into one \nanother and seeing what happens. \nIn order to get really highly effective machine intelligent systems, we also need \nalgorithms that can make more use of unsupervised and unlabeled data. As humans, \nwe tend to organize a lot of our world knowledge in causal terms, and that’s \nsomething that is not really done much by current neural networks. It’s more \nabout finding statistical regularities in complex patterns, but not really organizing \nthat as objects that can have various kinds of causal impacts on other objects. So, \nthat would be one aspect. \nI also think that there are advances needed in planning and a number of other \nareas as well, and it is not as if there are no ideas out there on how to achieve \nthese things. There are limited techniques available that can do various aspects \nof these things relatively poorly, and I think that there just needs to be a great \ndeal of improvement in those areas in order for us to get all the way to full \nhuman general intelligence. \nMARTIN FORD: DeepMind seems to be one of the very few companies that’s \nfocused specifically on AGI. Are there other players that you would point to \nthat are doing important work, that you think may be competitive with what \nDeepMind is doing?\nNICK BOSTROM: DeepMind is certainly among the leaders, but there are many \nplaces where there is exciting work being done on machine learning or work that \nmight eventually contribute to achieving artificial general intelligence. Google itself \nhas another world-class AI research group in the form of Google Brain. Other big \ntech companies now have their own AI labs: Facebook, Baidu, and Microsoft have \nquite a lot of research in AI going on. \nIn academia, there are a number of excellent places. Canada has Montreal and \nToronto, both of which are world-leading deep learning universities, and the likes \nof Berkeley, Oxford, Stanford, and Carnegie Mellon also have a lot of researchers \nin the field. It’s not just a Western thing, countries like China are investing greatly \nin building up their domestic capacity.\nMARTIN FORD: Those are not focused specifically on AGI, though.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 289
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n110\nNICK BOSTROM: Yes, but it’s a fuzzy boundary. Among those groups currently \novertly working towards AGI, aside from DeepMind, I guess OpenAI would be \nanother group that one could point to.\nMARTIN FORD: Do you think the Turing test is a good way to determine if we’ve \nreached AGI, or do we need another test for intelligence?\nNICK BOSTROM: It’s not so bad if what you want is a rough-and-ready criterion \nfor when you have fully succeeded. I’m talking about a full-blown, difficult version \nof the Turing test. Something where you can have experts interrogate the system \nfor an hour, or something like that. I think that’s an AI-complete problem. It can’t \nbe solved other than by developing general artificial intelligence. If what you’re \ninterested in is gauging the rate of progress, say, or establishing benchmarks to \nknow what to shoot for next with your AI research team, then the Turing test is \nmaybe not such a good objective. \nMARTIN FORD: Because it turns into a gimmick if it’s at a smaller scale? \nNICK BOSTROM: Yes. There’s a way of doing it right, but that’s too difficult, and \nwe don’t know at all how to do that right now. If you wanted incremental progress \non the Turing test, what you would get would be these systems that have a lot of \ncanned answers plugged in, and clever tricks and gimmicks, but that actually don’t \nmove you any closer to real AGI. If you want to make progress in the lab, or if you \nwant to measure the rate of progress in the world, then you need other benchmarks \nthat plug more into what is actually getting us further down the road, and that will \neventually lead to fully general AI.\nMARTIN FORD: What about consciousness? Is that something that might automatically \nemerge from an intelligent system, or is that an entirely independent phenomenon?\nNICK BOSTROM: It depends on what you mean by consciousness. One sense of \nthe word is the ability to have a functional form of self-awareness, that is, you’re \nable to model yourself as an actor in the world and reflect on how different \nthings might change you as an agent. You can think of yourself as persisting \nthrough time. These things come more or less as a side effect of creating more \nintelligent systems that can build better models of all kinds of aspects of reality, \nand that includes themselves. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 290
  },
  {
    "chunk_full": "NICK BOSTROM\n111\nAnother sense of the word “consciousness” is this phenomenal experiential field \nthat we have that we think has moral significance. For example, if somebody is \nactually consciously suffering, then it’s a morally bad thing. It means something \nmore than just that they tend to run away from noxious stimuli because they \nactually experience it inside of themselves as a subjective feeling. It’s harder to know \nwhether that phenomenal experience will automatically arise just as a side effect \nof making machine systems smarter. It might even be possible to design machine \nsystems that don’t have qualia but could still be very capable. Given that we don’t \nreally have a very clear grasp of what the necessary and sufficient conditions are \nfor morally relevant forms of consciousness, we must accept the possibility that \nmachine intelligences could attain consciousness, maybe even long before they \nbecome human-level or superintelligent. \nWe think many non-human animals have more of the relevant forms of experience. \nEven with something as simple as a mouse, if you want to conduct medical research \non mice, there is a set of protocols and guidelines that you have to follow. You have \nto anesthetize a mouse before you perform surgery on it, for example, because \nwe think it would suffer if you just carved it up without anesthesia. If we have \nmachine-intelligent systems, say, with the same behavioral repertoire and cognitive \ncomplexity as a mouse, then it seems to be a live question whether at that point it \nmight not also start to reach levels of consciousness that would give it some degree \nof moral status and limit what we can do to it. At least it seems we shouldn’t be \ndismissing that possibility out of hand. The mere possibility that it could be conscious \nmight already be sufficient grounds for some obligations on our part to do, at least \nif they’re easy to do, things that will make the machine have a better-quality life. \nMARTIN FORD: So, in a sense, the risks here run both ways? We worry about the \nrisk of AI harming us, but there’s also the risk that perhaps we’re going to enslave \na conscious entity or cause it to suffer. It sounds to me that there is no definitive \nway that we’re ever going to know if a machine is truly conscious. There’s nothing \nlike the Turing test for consciousness. I believe you’re conscious because you’re the \nsame species I am, and I believe I’m conscious, but you don’t have that kind of \nconnection with a machine. It’s a very difficult question to answer.\nNICK BOSTROM: Yes, I think it is difficult. I wouldn’t say species membership \nis the main criterion here that we use to posit consciousness, there are a lot \nof human beings that are not conscious. Maybe they are in a coma, or they are \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 291
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n112\nfetuses, or they could be brain dead, or under deep anesthesia. Most people \nalso think you can be a non-human being, for instance, certain animals, let us \nsay, have various degrees and forms of conscious experience. So, we are able \nto project it outside our own species, but I think it is true that it will be a \nchallenge for human empathy to extend the requisite level of moral consideration \nto digital minds, should such come to exist. \nWe have a hard enough time with animals. Our treatment of animals, particularly in \nmeat production, leaves much to be desired, and animals have faces and can squeak! \nIf you have an invisible process inside a microprocessor, it’s going to be much harder \nfor humans to recognize that there could be a sentient mind in there that deserves \nconsideration. Even today, it seems like one of those crazy topics that you can’t \nreally take seriously. It’s like a discussion for a philosophical seminar rather than a \nreal issue, like algorithmic discrimination is, or killer drones. \nUltimately, it needs to be moved out of this sphere of crazy topics that only \nprofessional philosophers talk about, and into a topic that you could have a \nreasonable public debate about. It needs to happen gradually, but I think maybe \nit’s time to start affecting that shift, just as the topic of what AI might do for \nthe human condition has moved from science-fiction into a more mainstream \nconversation over the last few years.\nMARTIN FORD: What do you think about the impact on the job market and the \neconomy that artificial intelligence might have? How big a disruption do you \nthink that could be and do you think that’s something we need to be giving a \nlot of attention to?\nNICK BOSTROM: In the very short term, I think that there might be a tendency \nto exaggerate the impacts on the labor market. It is going to take time to \nreally roll out systems on a large enough scale to have a big impact. Over time, \nthough, I do think that advances in machine learning will have an increasingly \nlarge impact on human labor markets and if you fully succeed with artificial \nintelligence, then yes, artificial intelligence could basically do everything. In \nsome respects, the ultimate goal is full unemployment. The reason why we do \ntechnology, and why we do automation is so that we don’t have to put in so \nmuch effort to achieve a given outcome. You can do more with less, and that’s \nthe gestalt of technology.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 292
  },
  {
    "chunk_full": "NICK BOSTROM\n113\nMARTIN FORD: That’s the utopian vision. So, would you support, for example, \na basic income as a mechanism to make sure that everyone can enjoy the fruits \nof all this progress?\nNICK BOSTROM: Some functional analog of that could start to look increasingly \ndesirable over time. If AI truly succeeds, and we resolve the technical control \nproblem and have some reasonable governance, then an enormous bonanza of \nexplosive economic growth takes place. Even a small slice of that would be ample \nenough to give everybody a really great life, so it seems one should at the minimum \ndo that. If we develop superintelligence, we will all carry a slice of the risk of this \ndevelopment, whether we like it or not. It seems only fair, then, that everybody \nshould also get some slice of the upside if things go well.\nI think that should be part of the vision of how machine superintelligence should \nbe used in the world; at least a big chunk of it should be for the common good of \nall of humanity. That’s also consistent with having private incentives for developers, \nbut the pie, if we really hit the jackpot, would be so large that we should make sure \nthat everybody has a fantastic quality of life. That could take the form of some kind \nof universal basic income or there could be other schemes, but the net result of that \nshould be that everybody sees a great gain in terms of their economic resources. \nThere will also be other benefits—like better technologies, better healthcare, and \nso forth—that superintelligence could enable.\nMARTIN FORD: What are your thoughts on the concern that China could reach AGI \nfirst, or at the same time as us? It seems to me that the values of whatever culture \ndevelops this technology do matter.\nNICK BOSTROM: I think it might matter less which particular culture happens to \ndevelop it first. It matters more how competent the particular people or group that \nare developing it are, and whether they have the opportunity to be careful. This \nis one of the concerns with a racing dynamic, where you have a lot of different \ncompetitors racing to get to some kind of finish line first—in a tight race you are \nforced to throw caution to the wind. The race would go to whoever squanders the \nleast effort on safety, and that would be a very undesirable situation. \nWe would rather have whoever it is that develops the first superintelligence to have \nthe option at the end of the development process to pause for six months, or maybe \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 293
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n114\na couple of years to double-check their systems and install whatever extra safeguards \nthey can think of. Only then would they slowly and cautiously amplify the system’s \ncapabilities up to the superhuman level. You don’t want them to be rushed by the \nfact that some competitor is nipping at their heels. When thinking about what the \nmost desirable strategic situation for humanity is when superintelligence arises in \nthe future, it seems that one important desideratum is that the competitive dynamics \nshould be allayed as much as possible.\nMARTIN FORD: If we do have a “fast takeoff” scenario where the intelligence can \nrecursively improve itself, though, then there is an enormous first-mover advantage. \nWhoever gets there first could essentially be uncatchable, so there’s a huge incentive \nfor exactly the kind of competition that you’re saying isn’t a good thing.\nNICK BOSTROM: In certain scenarios, yes, you could have dynamics like that, but \nI think the earlier point I made about pursuing this with a credible commitment \nto using it for the global good is important here, not only from an ethical point \nof view but also from the point of view of reducing the intensity of the racing \ndynamic. It would be good if all the competitors feel that even if they don’t win \nthe race, they’re still going to benefit tremendously. That will then make it more \nfeasible to have some arrangement in the end where the leader can get a clean shot \nat this without being rushed.\nMARTIN FORD: That calls for some sort of international coordination, and \nhumanity’s track record isn’t that great. Compared to the chemical weapons ban \nand the nuclear non-proliferation act, it sounds like AI would be an even greater \nchallenge in terms of verifying that people aren’t cheating, even if you did have \nsome sort of agreement.\nNICK BOSTROM: In some respects it would be more challenging, and in other \nrespects maybe less challenging. The human game has often been played around \nscarcity—there is a very limited set of resources, and if one person or country \nhas those resources, then somebody else does not have them. With AI there is the \nopportunity for abundance in many respects, and that can make it easier to form \ncooperative arrangements.\nMARTIN FORD: Do you think that we will solve these problems and that AI will \nbe a positive force overall?\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 294
  },
  {
    "chunk_full": "NICK BOSTROM\n115\nNICK BOSTROM: I’m full of both hopes and fears. I would like to emphasize the \nupsides here, both in the short term and longer term. Because of my job and my \nbook, people always ask me about the risks and downsides, but a big part of me \nis also hugely excited and eager to see all the beneficial uses that this technology \ncould be put to and I hope that this could be a great blessing for the world. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 295
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n116\nNICK BOSTROM is a Professor at Oxford University, where he is the founding Director of \nthe Future of Humanity Institute. He also directs the Governance of Artificial Intelligence \nProgram. Nick studied at the University of Gothenburg, Stockholm University and Kings College \nLondon prior to receiving his PhD in philosophy from the London School of Economics in \n2000. He is the author of some 200 publications, including Anthropic Bias (2002), Global \nCatastrophic Risks (2008), Human Enhancement (2009), and Superintelligence: Paths, \nDangers, Strategies (2014), a New York Times bestseller.\nNick has a background in physics, artificial intelligence, and mathematical logic as well \nas philosophy. He is recipient of a Eugene R. Gannon Award (one person selected annually \nworldwide from the fields of philosophy, mathematics, the arts and other humanities, and \nthe natural sciences). He has been listed on Foreign Policy’s Top 100 Global Thinkers \nlist twice; and he was included on Prospect magazine’s World Thinkers list, the \nyoungest person in the top 15 from all fields and the highest-ranked analytic philosopher. \nHis writings have been translated into 24 languages. There have been more than 100 \ntranslations and reprints of his works. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 296
  },
  {
    "chunk_full": "NICK BOSTROM\n117\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 297
  },
  {
    "chunk_full": "",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 298
  },
  {
    "chunk_full": "YANN LECUN\n119\nYANN LECUN\nVP & CHIEF AI SCIENTIST, FACEBOOK \nPROFESSOR OF COMPUTER SCIENCE, NYU \nYann LeCun has been involved in the academic and industry side of AI and \nMachine Learning for over 30 years. Prior to joining Facebook, Yann worked \nat AT&T’s Bell Labs, where he is credited with developing convolutional neural \nnetworks—a machine learning architecture inspired by the brain’s visual cortex. \nAlong with Geoff Hinton and Yoshua Bengio, Yann is part of a small group \nof researchers whose effort and persistence led directly to the current revolution \nin deep learning neural networks.\nA human can learn to drive a car in 15 hours of \ntraining without crashing into anything. If you want \nto use the current reinforcement learning methods to \ntrain a car to drive itself, the machine will have to \ndrive off cliffs 10,000 times before it figures out how \nnot to do that.\n“ \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 299
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n120\nMARTIN FORD: Let’s jump right in and talk about the deep learning revolution \nthat’s been unfolding over the past decade or so. How did that get started? \nAm I right that it was the confluence of some refinements to neural network \ntechnology, together with much faster computers and an explosion in the amount \nof training data available?\nYANN LECUN: Yes, but it was more deliberate than that. With the emergence of the \nbackpropagation algorithm in 1986-87, people were able to train neural nets with \nmultiple layers, which was something that the old models didn’t do. This resulted \nin a wave of interest that lasted right through to around 1995 before petering out.\nThen in 2003, Geoffrey Hinton, Yoshua Bengio, and I got together and said, we \nknow these techniques are eventually going to win out, and we need to get together \nand hash out a plan to renew the community interest in these methods. That’s what \nbecame deep learning. It was a deliberate conspiracy, if you will.\nMARTIN FORD: Looking back, did you imagine the extent to which you would \nbe successful? Today, people think artificial intelligence and deep learning are \nsynonymous. \nYANN LECUN: Yes and no. Yes, in the sense that we knew eventually those \ntechniques would come to the fore for computer vision, speech recognition, \nand maybe a couple of other things—but no, we didn’t realize it would become \nsynonymous with deep learning.\nWe didn’t realize that there would be so much of an interest from the wider \nindustry that it would create a new industry altogether. We didn’t realize that there \nwould be so much interest from the public, and that it would not just revolutionize \ncomputer vision and speech recognition, but also natural language understanding, \nrobotics, medical imaging analysis, and that it would enable self-driving cars that \nactually work. That took us by surprise, that’s for sure. \nBack in the early ‘90s, I would have thought that that this kind of progress would \nhave happened slightly earlier but more progressively, rather than the big revolution \nthat occurred around 2013.\nMARTIN FORD: How did you first become interested in AI and machine learning?\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 300
  },
  {
    "chunk_full": "YANN LECUN\n121\nYANN LECUN: As a kid, I was interested in science and engineering and the big \nscientific questions—life, intelligence, the origin of humanity. Artificial intelligence \nwas something that fascinated me, even though it didn’t really exist as a field in \nFrance during the 1960s and 1970s. Even with a fascination for those questions, \nwhen I finished high school I believed that I would eventually become an engineer \nrather than a scientist, so I began my studies in the field of engineering. \nEarly on in my studies, around 1980, I stumbled on a philosophy book which was a \ntranscription of a debate between Jean Piaget, the developmental psychologist, and \nNoam Chomsky, the linguist, called, Language and Learning: The Debate Between Jean \nPiaget and Noam Chomsky. The book contained a really interesting debate between \nthe concepts of nature and nurture and the emergence of language and intelligence.\nOn the side of Piaget in the debate was Seymour Papert, who was a professor at \nMIT in computer science and who was involved with early machine learning and \narguably actually killed the field off in the first wave of neural nets in the late 1960s. \nHere he was, 10 years later, singing the praise of a very simple machine learning \nmodel called the perceptron that had been invented in the 1950s, and that he had \nbeen working on in the 1960s. That was the first time I read about the concept of \na learning machine, and I was absolutely fascinated by the idea that a machine could \nlearn. I thought learning was an integral part of intelligence. \nAs an undergrad, I dug up all the literature I could find about machine learning and \ndid a couple of projects on it. I discovered that nobody in the West was working on \nneural nets. A few Japanese researchers were working on what became known as neural \nnetworks, but no one in the West was, because the field had been killed in the late ‘60s \nin part by Seymour Papert and Marvin Minsky, the famous American AI researcher. \nI carried on working on neural nets on my own, and I did a PhD in 1987 titled, \nModeles connexionnistes de l’apprentissage (Connectionist learning models). My advisor, \nMaurice Milgram, was not actually working on this topic, and he told me outright, \n“I can be your official advisor, but I can’t help you technically.” \nI discovered through my work that in the early 1980s, there was a community of \npeople around the world who were working on neural nets, and I connected with \nthem and ended up discovering things like backpropagation in parallel with people \nlike David Rumelhart and Geoffrey Hinton. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 301
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n122\nMARTIN FORD: So, in the early 1980s there was a lot of research in this area \ngoing on in Canada?\nYANN LECUN: No, this was the United States. Canada was not on the map for \nthis type of research yet. In the early 1980s, Geoffrey Hinton was a postdoc at the \nUniversity of California, San Diego where he was working with cognitive scientists \nlike David Rumelhart and Jay McClelland. Eventually they published a book explaining \npsychology by simple neural nets and models of computation. Geoffrey then became \nAssociate Professor at Carnegie Mellon University, and only moved to Toronto in 1987. \nThat’s when I also moved to Toronto, where I was a postdoc in his lab for one year. \nMARTIN FORD: I was an undergraduate studying computer engineering in the early \n1980s, and I don’t recall much exposure to neural networks at all. It was a concept \nthat was out there, but it was definitely very much marginalized. Now, in 2018, \nthat has changed dramatically.\nYANN LECUN: It was worse than marginalized. In the ‘70s and early ‘80s it was \nanathema within the community. You couldn’t publish a paper that even mentioned \nthe phrase neural networks because it would immediately be rejected by your peers. \nIn fact, Geoffrey Hinton and Terry Sejnowski published a very famous paper in 1983 \ncalled, Optimal Perceptual Inference, which described an early deep learning or neural \nnetwork model. Hinton and Sejnowski had to use code words to avoid mentioning that \nit was a neural network. Even the title of their paper was cryptic; it was all very strange!\nMARTIN FORD: One of the main innovations you’re known for is the convolutional \nneural network. Could you explain what that is and how it’s different from other \napproaches in deep learning?\nYANN LECUN: The motivation for convolutional neural networks was building a \nneural network that was appropriate for recognizing images. It turned out to be \nuseful for a wide-range of tasks, such as speech recognition and language translation. \nIt’s somewhat inspired by the architecture of the visual cortex in animals or humans.\nDavid Hubel and Torsten Wiesel did some Nobel prize-winning work in neuroscience \nin the 1950s and 1960s about the type of functions that the neurons in the visual \ncortex perform and how they’re connected with each other. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 302
  },
  {
    "chunk_full": "YANN LECUN\n123\nA convolutional network is a particular way of connecting the neurons with each \nother in such a way that the processing that takes place is appropriate for things \nlike images. I should add that we don’t normally call them neurons because they’re \nnot really an accurate reflection of biological neurons.\nThe basic principle of how the neurons are connected is that they’re organized in \nmultiple layers and each neuron in the first layer is connected with a small patch \nof pixels in the input image. Each neuron computes a weighted sum of its inputs. \nThe weights are the quantities that are modified by learning. The neurons only see \na tiny window of pixels of the input, and there’s a whole bunch of neurons that \nlook at the same little window. Then, there’s a whole bunch of neurons that look at \nanother slightly shifted window, but this bunch performs the same operation as the \nother bunch. If you have a neuron that detects a particular motif in one window, \nyou’re going to have another neuron that detects exactly the same motif in the next \nwindow and other neurons for all windows across the image.\nOnce you put all those neurons together and you realize what kind of mathematical \noperation they do, that operation is called a discrete convolution, which is why this \nis called a convolutional net.\nThat’s the first layer, and then there’s a second layer, which is a non-linearity layer—\nbasically a threshold where each neuron turns on or turns off if the weighted sum \ncomputed by the convolution layer is above or below the threshold. \nFinally, there’s a third layer that performs what’s called a pooling operation. I’m not \ngoing to cover it in detail, but it basically plays a role in making sure that when the \ninput image is slightly shifted or deformed, the output responses don’t change that \nmuch. That’s a way of building a bit of invariance to distortion shifts or deformation \nof the object in the input image.\nThe convolutional net is basically a stack of layers of this type—convolution, non-\nlinearity, pooling. You stack multiple layers of those, and by the time you get to the \ntop, you have neurons that are supposed to detect individual objects. \nYou might have a neuron that turns on if you put an image of a horse in the \nimage, and then you have one for cars, people, chairs, and all other categories \nyou might want to recognize.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 303
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n124\nThe trick is that the function that this neural network is doing is determined by \nthe strength of the connections between the neurons, the weights, and those are \nnot programmed; they’re trained.\nThis is what is learned when you train the neural net. You show it the image of \na horse, and if it doesn’t say “horse,” you tell it that it’s wrong and here is the \nanswer that it should have said. Then by using the backpropagation algorithm, it \nadjusts all the weights of all the connections in the network so that next time you \nshow the same image of a horse, the output would be closer to the one you want, \nand you keep doing this for thousands of images. \nMARTIN FORD: That process of training a network by giving it images of cats \nor horses, and so on, is what’s called supervised learning, correct? Is it true to \nsay that supervised learning is the dominant approach today, and that it takes \nhuge amounts of data?\nYANN LECUN: Exactly. Almost all of the applications of deep learning today \nuse supervised learning. \nSupervised learning is when you give the correct answer to the machine when \nyou’re training it, and then it corrects itself to give the correct answer. The magic \nof it is that after it’s been trained, it produces a correct answer most of the time \nin categories that it’s been trained on, even for images it’s never seen before. \nYou’re correct, that does typically require a lot of samples, at least the first time \nyou train the network.\nMARTIN FORD: How do you see the field moving forward in the future? Supervised \nlearning is very different from the way a human child learns. You could point at a \ncat once and say, “there’s a cat,” and that one sample might be enough for a child \nto learn. That’s dramatically different from where AI is today.\nYANN LECUN: Well, yes and no. As I said, the first time you train a convolutional \nnetwork you train it with thousands, possibly even millions of images of various \ncategories. If you then want to add a new category, for example if the machine \nhas never seen a cat and you want to train it to recognize cats, then it only \nrequires a few samples of cats. That is because it has already been trained to \nrecognize images of any type and it knows how to represent images; it knows \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 304
  },
  {
    "chunk_full": "YANN LECUN\n125\nwhat an object is, and it knows a lot of things about various objects. So, to train \nit to recognize a new object, you just show it a few samples, and you just need \nto train a couple of the top layers.\nMARTIN FORD: So, if you trained a network to recognize other kinds of animals \nlike dogs and bears, then would it only take a small amount of data to get to a cat? \nThat seems not so different from what a child is probably doing.\nYANN LECUN: But it is different, and that’s the unfortunate thing. The way a child \nlearns (and animals, for that matter) is that most of the learning they do is before \nyou can tell them, “this is a cat.” In the first few months of life, babies learn a \nhuge amount by observation without having any notion of language. They learn an \nenormous amount of knowledge about how the world works just by observation \nand with a little interaction with the world. \nThis sort of accumulation of enormous amounts of background knowledge about \nthe world is what we don’t know how to do with machines. We don’t know what \nto call this, some people call this unsupervised learning, but it’s a loaded term. It’s \nsometimes called predictive learning, or imputative learning. I call it self-supervised \nlearning. It’s the kind of learning where you don’t train for a task, you just observe \nthe world and figure out how it works, essentially. \nMARTIN FORD: Would reinforcement learning, or learning by practice with a reward \nfor succeeding, be in the category of unsupervised learning?\nYANN LECUN: No, that’s a different category altogether. There are three categories \nessentially; it’s more of a continuum, but there is reinforcement learning, supervised \nlearning, and self-supervised learning. \nReinforcement learning is learning by trial and error, getting rewards when you \nsucceed and not getting rewards when you don’t succeed. That form of learning in \nits purest form is incredibly inefficient in terms of samples, and as a consequence \nworks well for games, where you can try things as many times as you want, but \ndoesn’t work in many real-world scenarios. \nYou can use reinforcement learning to train a machine to play Go or chess. That \nworks really well, as we’ve seen with AlphaGo, for example, but it requires a \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 305
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n126\nridiculous number of samples or trials. A machine has to basically play more games \nthan all of humanity in the last 3,000 years to reach good performance, and it \nworks really well if you can do that, but it is often impractical in the real world. \nIf you want to use reinforcement learning to train a robot to grab objects, it will \ntake a ridiculous amount of time to achieve that. A human can learn to drive a \ncar in 15 hours of training without crashing into anything. If you want to use the \ncurrent reinforcement learning methods to train a car to drive itself, the machine \nwill have to drive off cliffs 10,000 times before it figures out how not to do that. \nMARTIN FORD: I guess that’s the argument for simulation.\nYANN LECUN: I don’t agree. It might be an argument for simulation, but it’s also \nan argument for the fact that the kind of learning that we can do as humans is very, \nvery different from pure reinforcement learning.\nIt’s more akin to what people call model-based reinforcement learning. This is where \nyou have your internal model of the world that allows you to predict that when you \nturn the wheel in a particular direction then the car is going to go in a particular \ndirection, and if another car comes in front you’re going to hit it, or if there is a \ncliff you are going to fall off that cliff. You have this predictive model that allows \nyou to predict in advance the consequence of your actions. As a result, you can \nplan ahead and not take the actions that result in bad outcomes. \nLearning to drive in this context is called model-based reinforcement learning, and \nthat’s one of the things we don’t really know how to do. There is a name for it, \nbut there’s no real way to make it work reliably! Most of the learning is not in the \nreinforcement, it’s in learning the predictive models in a self-supervised manner, \nand that’s the main problem we don’t know how to solve today.\nMARTIN FORD: Is this an area that you’re focused on with your work at Facebook? \nYANN LECUN: Yes, it is one of the things that we’re working on at Facebook. \nWe’re working on a lot of different things, including getting machines to learn \nby observation from different data sources—learning how the world works. We’re \nbuilding a model of the world so that perhaps some form of common sense will \nemerge and perhaps that model could be used as kind of a predictive model that \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 306
  },
  {
    "chunk_full": "YANN LECUN\n127\nwould allow a machine to learn the way people do without having to try and fail \n10,000 times before they’ve succeeded.\nMARTIN FORD: Some people argue that deep learning alone is not going to be \nenough, or that there needs to be more structure in the networks, some kind of \nintelligent design from the onset. You seem to be a strong believer in the idea \nthat intelligence will emerge organically from relatively generic neural networks. \nYANN LECUN: I think that would be an exaggeration. Everybody agrees that there \nis a need for some structure, the question is how much, and what kind of structure \nis needed. I guess when you say that some people believe that there should be \nstructures such as logic and reasoning, you’re probably referring to Gary Marcus \nand maybe Oren Etzioni.\nI actually had a debate with Gary Marcus on this earlier today. Gary’s view isn’t \nparticularly well accepted in the community because he’s been writing critically \nabout deep learning, but he’s not been contributing to it. That’s not the case for \nOren Etzioni because he’s been in the field for a while, but his view is considerably \nmilder than Gary’s. The one thing all of us agree on, though, is that there is a \nneed for some structure. \nIn fact, the very idea of convolutional networks is to put a structure in neural \nnetworks. Convolutional networks are not a blank slate, they do have a little bit \nof structure. The question is, if we want AI to emerge, and we’re talking general \nintelligence or human-level AI, how much structure do we need? That’s where \npeople’s views may differ, like whether we need explicit structures that will allow \na machine to manipulate symbols, or if we need explicit structures for representing \nhierarchical structures in language. \nA lot of my colleagues, like Geoffrey Hinton and Yoshua Bengio, agree that \nin the long run we won’t need precise specific structures for this. It might be \nuseful in the short term because we may not have figured out a general learning \nmethod for self-supervised learning. So, one way to cut corners is to hardwire \nthe architecture; that is a perfectly fine thing to do. In the long run, though, \nit’s not clear how much of that we need. The microstructure of the cortex \nseems to be very, very uniform all over, whether you’re looking at the visual \nor prefrontal cortex.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 307
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n128\nMARTIN FORD: Does the brain use something like backpropagation? \nYANN LECUN: We don’t really know. There are more fundamental questions than \nthat, though. Most of the learning algorithms that people have come up with \nessentially consist of minimizing some objective function.\nWe don’t even know if the brain minimizes an objective function. If the brain does \nminimize an objective function, does it do it through a gradient-based method? Does \nthe brain have some way of estimating in which direction to modify all of its synaptic \nconnections in such a way as to improve this objective function? We don’t know \nthat. If it estimates that gradient, does it do it by some form of backpropagation? \nIt’s probably not backpropagation as we know it, but it could be a form of \napproximation of gradient estimation that is very similar to backpropagation. Yoshua \nBengio has been working on biologically plausible forms of gradient estimation, so \nit’s not entirely impossible that the brain does some sort of gradient estimation of \nsome objective function, we just simply don’t know. \nMARTIN FORD: What other important topics are you working on at Facebook?\nYANN LECUN: We’re working on a lot of fundamental research and questions \non machine learning, so things that have more to do with applied mathematics \nand optimization. We are working on reinforcement learning, and we are also \nworking on something called generative models, which are a form of self-\nsupervised or predictive learning. \nMARTIN FORD: Is Facebook working on building systems that can actually carry \nout a conversation?\nYANN LECUN: What I’ve mentioned so far are the fundamental topics of research, \nbut there are a whole bunch of application areas. \nFacebook is very active in computer vision, and I think we can claim to have \nthe best computer vision research group in the world. It’s a mature group and \nthere are a lot of really cool activities there. We’re putting quite a lot of work \ninto natural language processing, and that includes translation, summarization, \ntext categorization—figuring out what topic a text talks about, as well as dialog \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 308
  },
  {
    "chunk_full": "YANN LECUN\n129\nsystems. Actually, dialog systems are a very important area of research for virtual \nassistants, question and answering systems, and so on.\nMARTIN FORD: Do you anticipate the creation of an AI that someday could pass \nthe Turing test? \nYANN LECUN: It’s going to happen at some point, but the Turing test is not actually \nan interesting test. In fact, I don’t think a lot of people in the AI field at the moment \nconsider the Turing test to be a good test. It’s too easy to trick it, and to some \nextent, the Turing test has already been and gone. \nWe give a lot of importance to language as humans because we are used to discussing \nintelligent topics with other humans through language. However, language is sort \nof an epiphenomenon of intelligence, and when I say this, my colleagues who work \non natural language processing disagree vehemently!\nLook at orangutans, who are essentially almost as smart as we are. They have a \nhuge amount of common sense and very good models of the world, and they can \nbuild tools, just like humans. However, they don’t have language, they’re not social \nanimals, and they barely interact with other members of the species outside the non-\nlinguistic mother-and-child interaction. There is a whole component of intelligence \nthat has nothing to do with language, and we are ignoring this if we reduce AI to \njust satisfying the Turing test.\nMARTIN FORD: What is the path to artificial general intelligence and what do we \nneed to overcome to get there? \nYANN LECUN: There are probably other problems that we do not see at the moment \nthat we’re going to eventually encounter, but one thing I think we’ll need to figure \nout is the ability that babies and animals have to learn how the world works by \nobservation in the first few days, weeks, and months of life. \nIn that time, you learn that the world is three-dimensional. You learn that there are \nobjects that move in front of others in different ways when you move your head. \nYou learn object permanence, so you learn that when an object is hidden behind \nanother one, it’s still there. As time goes on, you learn about gravity, inertia, and \nrigidity—very basic concepts that are learnt essentially by observation. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 309
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n130\nBabies don’t have a huge amount of means to act on the world, but they observe \na lot, and they learn a huge amount by observing. Baby animals also do this. They \nprobably have more hardwired stuff, but it’s very similar. \nUntil we figure out how to do this unsupervised/self-supervised/predictive \nlearning, we’re not going to make significant progress because I think that’s \nthe key to learning enough background knowledge about the world so that \ncommon sense will emerge. That’s the main hurdle. There are more technical \nsubproblems of this that I can’t get into, like prediction under uncertainty, but \nthat’s the main thing. \nHow long is it going to take before we figure out a way to train machines so that \nthey learn how the world works by watching YouTube videos? That’s not entirely \nclear. We could have a breakthrough in two years that might take another 10 years \nto actually make it work, or it might take 10 or 20 years. I have no idea when it \nwill happen, but I do know it has to happen. \nThat’s just the first mountain we have to climb, and we don’t know how many \nmountains are behind it. There might be other huge issues and major questions that \nwe do not see yet because we haven’t been there yet and it’s unexplored territory. \nIt will probably take 10 years before we find this kind of breakthrough and before \nit has some consequence in the real world, and that has to happen way before we \nreach human-level artificial general intelligence. The question is, once we clear this \nhurdle, what other problems are going to pop up? \nHow much prior structure do we need to build into those systems for them \nto actually work appropriately and be stable, and for them to have intrinsic \nmotivations so that they behave properly around humans? There’s a whole lot of \nproblems that will absolutely pop up, so AGI might take 50 years, it might take \n100 years, I’m not too sure. \nMARTIN FORD: But you think it’s achievable?\nYANN LECUN: Oh, definitely.\nMARTIN FORD: Do you think it’s inevitable? \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 310
  },
  {
    "chunk_full": "YANN LECUN\n131\nYANN LECUN: Yes, there’s no question about that. \nMARTIN FORD: When you think of an AGI, would it be conscious, or could it be \na zombie with no conscious experience at all? \nYANN LECUN: We don’t know what that means. We have no idea what consciousness \nis. I think it’s a non-problem. It’s one of those questions that in the end, when you \nrealize how things actually work, you realize that question was immaterial. \nBack in the 17th century when people figured out that the image in the back of \nthe eye on the retina forms upside down, they were puzzled by the fact that we \nsee right-side up. When you understand what kind of processing is required after \nthis, and that it doesn’t really matter in which order the pixels come, you realize \nit’s kind of a funny question because it doesn’t make any sense. It’s the same thing \nhere. I think consciousness is a subjective experience and it could be a very simple \nepiphenomenon of being smart. \nThere are several hypotheses for what causes this illusion of consciousness—because I think \nit is an illusion. One possibility is that we have essentially a single engine in our prefrontal \ncortex that allows us to model the world, and a conscious decision to pay attention \nto a particular situation configures that model of the world for the situation at hand. \nThe conscious state is sort of an important form of attention, if you will. We may \nnot have the same conscious experience if our brain were ten times the size and \nwe didn’t have a single engine to model the world, but a whole bunch of them. \nMARTIN FORD: Let’s talk about some of the risks associated with AI. Do you \nbelieve that we’re on the cusp of a big economic disruption with the potential for \nwide spread job losses? \nYANN LECUN: I’m not an economist, but I’m obviously interested in those \nquestions, too. I’ve talked to a bunch of economists, and I’ve attended a number \nof conferences with a whole bunch of very famous economists who were discussing \nthose very questions. First of all, what they say is that AI is what they call a \ngeneral-purpose technology or GPT for short. What that means is that it’s a piece \nof technology that will diffuse into all corners of the economy and transform \npretty much how we do everything. I’m not saying this; they are saying this. If \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 311
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n132\nI was saying this, I would sound self-serving or arrogant, and I would not repeat \nit unless I had heard it from other people who know what they’re talking about. \nSo, they’re saying this, and I didn’t really realize that this was the case before I \nheard them say it. They say this is something on the scale of electricity, the steam \nengine, or the electric motor.\nOne thing I’m worried about, and this was before talking to the economists, is the \nproblem of technological unemployment. The idea that technology progresses rapidly \nand the skills that are required by the new economy are not matched by the skills \nof the population. A whole proportion of the population suddenly doesn’t have the \nright skills, and it’s left behind. \nYou would think that as technological progress accelerates, there’d be more and \nmore people left behind, but what the economists say is that the speed at which \na piece of technology disseminates in the economy is actually limited by the \nproportion of people who are not trained to use it. In other words, the more people \nare left behind, the less quickly the technology can diffuse in the economy. It’s \ninteresting because it means that the evil has kind of a self-regulating mechanism in \nit. We’re not going to have widely disseminated AI technology unless a significant \nproportion of the population is trained to actually take advantage of it, and the \nexample they use to demonstrate this is computer technology. \nComputer technology popped up in the 1960s and 1970s but did not have an \nimpact on productivity on the economy until the 1990s because it took that long for \npeople to get familiar with keyboards, mice, etc., and for software and computers \nto become cheap enough for them to have mass appeal.\nMARTIN FORD: I think there is a question of whether this time is different relative \nto those historical cases, because machines are taking on cognitive capability now.\nYou now have machines that can learn to do a lot of routine, predictable things, and \na significant percentage of our workforce is engaged in things that are predictable. \nSo, I think the disruption could turn out to be bigger this time than what we’ve \nseen in the past.\nYANN LECUN: I don’t actually think that’s the case. I don’t think that we’re going \nto face mass unemployment because of the appearance of this technology. I think \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 312
  },
  {
    "chunk_full": "YANN LECUN\n133\ncertainly the economic landscape is going to be vastly different in the same way \nthat 100 years ago most of the population were working in the fields, and now \nit’s 2% of the population. \nCertainly, over the next several decades, you’re going to see this kind of shift and \npeople are going to have to retrain for it. We’ll need some form of continuous \nlearning, and it’s not going to be easy for everyone. I don’t believe, though, that \nwe’re going to run out of jobs. I heard an economist say, “We’re not going to run \nout of jobs because we’re not going to run out of problems.”\nThe upcoming AI systems are going to be an amplification of human intelligence in \nthe way that mechanical machines have been an amplification of physical strength. \nThey’re not going to be a replacement. It’s not like just because AI systems that \nanalyze MRI images would be better at detecting tumors, then radiologists are out \nof a job. It’s going to be a very different job, and it’s going to be a much more \ninteresting job. They’re going to spend their time doing more interesting things like \ntalking to patients instead of staring at screens for 8 hours a day.\nMARTIN FORD: Not everyone’s a doctor, though. A lot of people are taxi drivers \nor truck drivers or fast food workers and they may have a harder time transitioning. \nYANN LECUN: What’s going to happen is the value of things and services is going \nto change. Everything that’s by done by machine is going to get a lot cheaper, \nand anything that’s done by humans is going to get more expensive. We’re going \nto pay more for authentic human experience, and the stuff that can be done by \nmachine is going to get cheap. \nAs an example, you can buy a Blu-ray player for $46. If you think about how \nmuch incredibly sophisticated technology goes into a Blu-ray player, it’s insane \nthat it costs $46. It’s got technology in the form of blue lasers that didn’t \nexist 20 years ago. It’s got an incredibly precise servo mechanism to drive \nthe laser to microns of precision. It’s also got, H.264 video compression and \nsuperfast processors. It has a ridiculous amount of technology that goes in there, \nand it’s $46 because it’s essentially mass-produced by machines. Now, go on \nthe web and search for a handmade ceramic salad bowl, and the first couple \nof hits you’re going to get are going to propose handmade ceramic bowl, a \n10,000-year-old technology, for something in the region of $500. Why $500? \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 313
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n134\nBecause it’s handmade and you’re paying for the human experience and the \nhuman connection. You can download a piece of music for a buck, but then if \nyou want to go to a show where that music is being played live, it’s going to \nbe $200. That’s for human experience. \nThe value of things is going to change, with more value placed on human \nexperience and less to things that are automated. A taxi ride is going to be \ncheap because it can be driven by the AI system, but a restaurant where an \nactual person serves you or an actual human cook creates something, is going \nto be more expensive.\nMARTIN FORD: That does presume that everyone’s got a skill or talent that’s \nmarketable, which I’m not sure is true. What do you think of the idea of a universal \nbasic income as a way to adapt to these changes? \nYANN LECUN: I’m not an economist, so I don’t have an informed opinion on \nthis, but every economist I talked to seemed against the idea of a universal basic \nincome. They all agree with the fact that as a result of increased inequality brought \nabout by technological progress, some measures have to be taken by governments \nto compensate. All of them believe this has to do with fiscal policy in the form \nof taxing, and wealth and income redistribution. \nThis income inequality is something that is particularly apparent in the US, but \nalso to a smaller scale in Western Europe. The Gini index—a measure of income \ninequality—of France or Scandinavia is around 25 or 30. In the US, it’s 45, and \nthat’s the same level as third-world countries. In the US, Erik Brynjolfsson, an \neconomist at MIT, wrote a couple of books with his colleague from MIT, Andrew \nMcAfee, studying the impact of technology on the economy. They say that the \nmedian income of a household in America has been flat since the 1980s where we \nhad Reaganomics and the lowering of taxes for higher incomes, whereas productivity \nhas gone up more or less continuously. None of that occurred in Western Europe. \nSo, it’s purely down to fiscal policy. It’s maybe fueled by technological progress, \nbut there are easy things that governments can do to compensate for the disruption, \nand they’re just not doing it in the US.\nMARTIN FORD: What other risks are there, beyond the impact on the job market \nand economy, that come coupled with AI?\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 314
  },
  {
    "chunk_full": "YANN LECUN\n135\nYANN LECUN: Let me start with one thing we should not worry about, the \nTerminator scenario. This idea that somehow we’ll come up with the secret to \nartificial general intelligence, and that we’ll create a human-level intelligence that \nwill escape our control and all of a sudden robots will want to take over the \nworld. The desire to take over the world is not correlated with intelligence, it’s \ncorrelated with testosterone. \nWe have a lot of examples today in American politics, clearly illustrating that the \ndesire for power is not correlated with intelligence. \nMARTIN FORD: There is a pretty reasoned argument, though, that Nick Bostrom, \nin particular, has raised. The problem is not an innate need to take over the world, \nbut rather that an AI could be given a goal and then it might decide to pursue that \ngoal in a way that turns out to be harmful to us. \nYANN LECUN: So, somehow we’re smart enough to build artificial general \nintelligence machines, then the first thing we do is tell them to build as many \npaper clips as they can and they turn the entire universe into paper clips? That \nsounds unrealistic to me.\nMARTIN FORD: I think Nick intends that as kind of a cartoonish example. \nThose kinds of scenarios all seem far-fetched, but if you are truly talking about \nsuperintelligence, then you would have a machine that might act in ways that would \nbe incomprehensible to us. \nYANN LECUN: Well, there is the issue of objective function design. All of those \nscenarios assume that somehow, you’re going to design the objective function—\nthe intrinsic motivations—of those machines in advance, and that if you get it \nwrong, they’re going to do crazy things. That’s not the way humans are built. \nOur intrinsic objective functions are not hardwired. A piece of it is hardwired \nin a sense that we have the instinct to eat, breathe, and reproduce, but a lot of \nour behavior and value system is learned. \nWe can very much do the same with machines, where their value system is going \nto be trained and we’re going to train them to essentially behave in society and be \nbeneficial to humanity. It’s not just a problem of designing those functions but also \ntraining them, and it’s much easier to train an entity to behave. We do it with our \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 315
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n136\nkids to educate them in what’s right and wrong, and if we know how to do it with \nkids why wouldn’t we be able to do this with robots or AI systems? \nClearly, there are issues there, but it’s a bit like we haven’t invented the internal \ncombustion engine yet and we are already worrying that we’re not going to be able to \ninvent the brake and the safety belt. The problem of inventing the internal combustion \nengine is considerably more complicated than inventing brakes and safety belts.\nMARTIN FORD: What do you think of the fast takeoff scenario, where you have \nrecursive improvement that happens at an extraordinary rate, and before you know \nit, we’ve got something that makes us look like a mouse or an insect in comparison? \nYANN LECUN: I absolutely do not believe in that. Clearly there’s going to be \ncontinuous improvement, and certainly, the more intelligent machines become, \nthe more they’re going to help us design the next generation. It’s already the case, \nand it’s going to accelerate. \nThere is some sort of differential equation that governs the progress of technology, \nthe economy, consumption of resources, communication, the sophistication of \ntechnology, and all that stuff. There’s a whole bunch of friction terms in this equation \nthat is completely ignored by the proponent of singularity or fast takeoff. Every \nphysical process at some point has to saturate, by exhausting resources if nothing \nelse. So, I don’t believe in a fast takeoff. It’s a fallacy that someone will figure out \nthe secret to AGI, then all of a sudden, we’re going to go from machines that are as \nintelligent as a rat to some that are as intelligent as an orangutan, and then a week \nlater they are more intelligent than us, and then a month later, way more intelligent. \nThere’s also no reason necessarily to believe that being way more intelligent \nthan a single human will allow a machine to be completely superior to a single \nhuman. Humans can get killed by viruses that are extremely stupid, but they are \nspecialized to kill us.\nIf we can build an artificial intelligence system that has general intelligence in that \nsense, then we can probably also build a more specialized intelligence designed to \ndestroy the first one. It would be much more efficient at killing the AGI because \nmore specialized machines are more efficient than general ones. I just think that \nevery issue has its own solution built in.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 316
  },
  {
    "chunk_full": "YANN LECUN\n137\nMARTIN FORD: So, what should we legitimately be worried about in the next \ndecade or two?\nYANN LECUN: Economic disruption is clearly an issue. It’s not an issue without \na solution, but it’s an issue with considerable political obstacles, particularly in \ncultures like the US where income and wealth redistribution are not something \nthat’s culturally accepted. There is an issue of disseminating the technology so \nthat it doesn’t only profit the developed world, but it’s shared across the world. \nThere is a concentration of power. Currently, AI research is very public and \nopen, but it’s widely deployed by a relatively small number of companies at \nthe moment. It’s going to take a while before it’s used by a wider swath of the \neconomy and that’s a redistribution of the cards of power. That will affect the \nworld in some ways, it may be positive but it may also be negative, and we need \nto ensure that it’s positive. \nI think the acceleration of technological progress and the emergence of AI is \ngoing to prompt governments to invest more massively into education, particularly \ncontinuous education because people are going to have to learn new jobs. That’s \na real aspect of the disruption that needs to be dealt with. It’s not something that \ndoesn’t have a solution, it’s just a problem that people have to realize exists in \norder for them to solve it.\nIf you have a government that doesn’t even believe in established scientific facts \nlike global warming, how can they believe in this kind of stuff? There are a \nlot of issues of this type, including ones in the area of bias and equity. If we \nuse supervised learning to train our systems, they’re going to reflect the biases \nthat are in the data, so how can you make sure they don’t prolong the status \nquo in terms of biases?\nMARTIN FORD: The problem there is that the biases are encapsulated in the data so \nthat a machine learning algorithm would naturally acquire them. One would hope \nthat it might be much easier to fix bias in an algorithm than in a human. \nYANN LECUN: Absolutely. I’m actually quite optimistic in that dimension because I \nthink it would indeed be a lot easier to reduce bias in a machine than it currently \nis with people. People are biased in ways that are extremely difficult to fix.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 317
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n138\nMARTIN FORD: Do you worry about military applications, like autonomous weapons? \nYANN LECUN: Yes and no. Yes, because of course AI technology can be used \nfor building weapons, but some people, like Stuart Russell, have characterized a \npotential new generation of AI-powered weapons as weapons of mass destruction \nand I completely disagree with that.\nI think the way that militaries are going to use AI technology is exactly the \nopposite. It’s for what the military calls, surgical actions. You don’t drop a bomb \nthat destroys an entire building, you send in your drone that just puts the person \nyou are interested in capturing to sleep; it could be non-lethal.\nWhen it gets to that point, it makes the military look more like police. Is that good \nin the long term? I don’t think anyone can guess. It’s less destructive than nukes—it \ncan’t be more destructive than nukes! \nMARTIN FORD: Do you worry about a race with China in terms of advancing \nartificial intelligence? They have over a billion people, so they have got more data \nand along with that, fewer constraints on privacy. Is that going to give them an \nadvantage in moving forward? \nYANN LECUN: I don’t think so. I think currently progress in the science is not \nconditioned on the wide availability of data. There may be more than 1 billion people \nin China, but the proportion of people who are actually involved in technology and \nresearch is actually relatively small. \nThere’s no question that it will grow, China is really progressing in that \ndirection. I think the style of government and the type of education they have \nmay be stifling for creativity after a while. There is good work coming out of \nChina, though, with some very smart people there, and they’re going to make \ncontributions to this field.\nThere was the same kind of fear of the West being overrun by Japanese technology \nin the 1980s, and it happened for a while and then it kind of saturated. Then it \nwas the Koreans, and now it’s the Chinese. There are going to be big mutations \nin Chinese society that will have to happen over the next few decades that will \nprobably change the situation completely. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 318
  },
  {
    "chunk_full": "YANN LECUN\n139\nMARTIN FORD: Do you think that AI needs to be regulated at some level? Is there \na place for government regulation for the kind of research you’re doing and the \nsystems that you’re building?\nYANN LECUN: While I don’t think there is any point in regulating AI research at \nthe moment, I do think there is certainly a need for regulating applications. Not \nbecause they use AI, but because of the domain of applications that they are. \nTake the use of AI in the context of drug design; you always want to regulate how \ndrugs are being tested, how they are deployed, and how they are used. It’s already \nthe case. Take self-driving cars: cars are regulated, and there are strict road safety \nregulations. Certainly, those are application areas where existing regulations might \nneed to be tweaked because AI is going to become preponderant.\nHowever, I don’t see any need for the regulation of AI at the moment.\nMARTIN FORD: So, I assume you disagree quite strongly with the kind of rhetoric \nElon Musk has been using?\nYANN LECUN: Oh, I completely and absolutely disagree with him. I’ve talked \nto him several times, but I don’t know where his views are coming from. He’s a \nvery smart guy and I’m in awe of some of his projects, but I’m not sure what his \nmotivation is. He wants to save humanity, so maybe he needs another existential \nthreat for it. I think he is genuinely worried, but none of us have been able to \nconvince him that Bostrom-style, hard take-off scenarios are not going to happen.\nMARTIN FORD: Are you an optimist overall? Do you believe that the benefits of AI \nare going to outweigh the downsides?\nYANN LECUN: Yes, I would agree with that.\nMARTIN FORD: In what areas do you think it will bring the most benefits?\nYANN LECUN: Well, I really hope that we figure out the way to get machines to learn \nlike baby humans and animals. That’s my scientific program for the next few years. \nI also hope we’re going to make some convincing breakthrough before the people \nfunding all this research get tired, because that’s what happened in previous decades. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 319
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n140\nMARTIN FORD: You’ve warned that AI is being overhyped and that this might even \nlead to another “AI Winter.” Do you really think there’s a risk of that? Deep learning \nhas become so central to the business models of Google, Facebook, Amazon, Tencent, \nand all these other incredibly wealthy corporations. So, it seems hard to imagine \nthat investment in the technology would fall off dramatically.\nYANN LECUN: I don’t think we’re going to see an AI winter in the way we saw \nbefore because there is a big industry around it and there are real applications that \nare bringing real revenue to these companies.\nThere’s still a huge amount of investment, with the hope that, for example, self-\ndriving cars are going to be working in the next five years and that medical imaging \nis going to be radically revolutionized. Those are probably going to be the most \nvisible effects over the next few years, medicine and health care, transportation, \nand information access.\nVirtual assistants are another case. They are only mildly useful today because \nthey’re kind of scripted by hand. They don’t have any common sense, and they \ndon’t really understand what you tell them at a deep level. The question is \nwhether we need to solve the AGI problem before we get virtual assistants that \nare not frustrating, or whether we can make more continuous progress before \nthat. Right now, I don’t know. \nWhen that becomes available, though, that’s going to change a lot of how people \ninteract with each other and how people interact with the digital world. If \neveryone has a personal assistant that has human-level intelligence, that’s going \nto make a huge difference. \nI don’t know if you’ve seen the movie Her? It’s not a bad depiction in some ways \nof what might happen. Among all the sci-fi movies on AI, it’s probably one of \nthe least ridiculous. \nI think a lot of AI-related technology is going to be widely available in the hands of \npeople because of hardware progress. There’s a lot of effort now to develop low-\npower and cheap hardware that can fit in your smartphone or your vacuum cleaner \nthat can run a convolutional network on 100 milliwatts of power, and the chip can be \nbought for 3 bucks. That’s going to change a lot of how the world around us works. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 320
  },
  {
    "chunk_full": "YANN LECUN\n141\nInstead of going randomly around your room, your vacuum cleaner is now going \nto be able to see where it needs to go, and your lawnmower is going to be able \nto mow your lawn without running over your flowerbeds. It’s not just your car \nthat will drive itself.\nIt might also have interesting environmental consequences, like wildlife \nmonitoring. AI is going to be in the hands of everyone because of progress in \nhardware technology that is specialized for deep learning, and that’s coming in \nthe next 2 or 3 years. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 321
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n142\nYANN LECUN is a Vice President and Chief AI Scientist at Facebook, as well as a professor of \ncomputer science at New York University. Along with Geoff Hinton and Yoshua Bengio, Yann is \npart of the so-called “Canadian Mafia”—the trio of researchers whose effort and persistence \nled directly to the current revolution in deep learning neural networks.\nPrior to joining Facebook, Yann worked at AT&T’s Bell Labs, where he is credited with \ndeveloping convolutional neural networks—a machine learning architecture inspired by the \nbrain’s visual cortex. Yann used convolutional neural nets to develop a handwriting recognition \nsystem that became widely used in ATMs and at banks to read the information on checks. \nIn recent years, deep convolutional nets, powered by ever faster computer hardware, have \nrevolutionized computer image recognition and analysis. \nYann received an Electrical Engineer Diploma from Ecole Superieure d’Ingenieurs en \nElectrotechnique et Electronique (ESIEE) in Paris, and a PhD in Computer Science from \nUniversite Pierre et Marie Curie in 1987. He later worked as a post-doctoral researcher in \nGeoff Hinton’s lab at the University of Toronto. He joined Facebook in 2013 to establish and \nrun the Facebook AI Research (FAIR) organization, headquartered in New York City.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 322
  },
  {
    "chunk_full": "YANN LECUN\n143\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 323
  },
  {
    "chunk_full": "",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 324
  },
  {
    "chunk_full": "FEI-FEI LI\n145\nFEI-FEI LI\nPROFESSOR OF COMPUTER SCIENCE, STANFORD \nCHIEF SCIENTIST, GOOGLE CLOUD\nFei-Fei Li is Professor of Computer Science at Stanford University, and Director of \nthe Stanford Artificial Intelligence Lab (SAIL). Working in areas of computer vision \nand cognitive neuroscience, Fei-Fei builds smart algorithms that enable computers \nand robots to see and think, inspired by the way the human brain works in the real \nworld. Fei-Fei is Chief Scientist, AI and Machine Learning at Google Cloud, where \nshe works to advance and democratize AI. Fei-Fei is a strong proponent of diversity \nand inclusion in artificial intelligence and co-founded AI4ALL, an organization \nto attract more women and people from underrepresented groups into the field.\nIf we look around, whether you’re looking at AI  \ngroups in companies, AI professors in academia, AI  \nPhD students or AI presenters at top AI conferences,  \nno matter where you cut it: we lack diversity. We lack  \nwomen, and we lack under-represented minorities.\n“ \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 325
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n146\nMARTIN FORD: Let’s talk about your career trajectory. How did you first become \ninterested in AI, and how did that lead to your current position at Stanford?\nFEI-FEI LI: I’ve always been something of a STEM student, so the sciences have \nalways appealed to me, and in particular I love physics. I went to Princeton \nUniversity where I majored in Physics, and a by-product of studying physics is that \nI became fascinated by the fundamentals of the universe. Questions like, where \ndoes the universe come from? What does it mean to exist? Where is the universe \ngoing? The fundamental quest of human curiosity.\nIn my research I noticed something really interesting: since the beginning of \nthe 20th century, we’ve seen a great awakening of modern physics, due to the \nlikes of Einstein and Schoenberg, who towards the end of their lives became \nfascinated not only by the physical matter of the universe but by life, and \nbiology, and by the fundamental questions of being. I became very fascinated by \nthese questions as well. When I started to study, I realized that my real interest \nin life is not to discover physical matters but to understand intelligence—which \ndefines human life.\nMARTIN FORD: Was this when you were in China?\nFEI-FEI LI: I was in the US, at Princeton Physics, when my intellectual interest \nin AI and neuroscience began. When I applied for a PhD there I was very lucky, \nand to this day, it’s still a bit of a rare combination to do what I did—which was \nboth neuroscience and AI.\nMARTIN FORD: Do you think then that it’s an important advantage to study both of \nthose fields rather than to focus exclusively on a computer-science-driven approach?\nFEI-FEI LI: I think it gives me a unique angle because I consider myself a scientist, \nand so when I approach AI, what drives me is scientific hypotheses and the scientific \nquest. The field of AI is about thinking machines, making machines intelligent, and \nI like to work on problems at the core of conquering machine intelligence. \nComing from a cognitive neuroscience background, I take an algorithmic point of \nview, and a detailed modeling point of view. So, I find the connection between \nthe brain and machine learning fascinating. I also think a lot about human-inspired \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 326
  },
  {
    "chunk_full": "FEI-FEI LI\n147\ntasks that drive AI advances: the real-world tasks that our natural intelligence had \nto solve through evolution. My background has in this way given me a unique \nangle and approach to working with AI.\nMARTIN FORD: Your focus has really been on computer vision, and you’ve made \nthe point that, in evolutionary terms, the development of the eye likely led to the \ndevelopment of the brain itself. The brain was providing the compute power to \ninterpret images, and so maybe understanding vision is the gateway to intelligence. \nAm I correct in that line of thinking?\nFEI-FEI LI: Yes, you’re right. Language is a huge part of human intelligence, of \ncourse: along with speech, tactile awareness, decision-making, and reasoning. But \nvisual intelligence is embedded in all of these things. \nIf you look at the way nature designed our brain, half of the human brain is involved \nin human intelligence, and that human intelligence is intimately related to a motor \nsystem, to decision-making, to emotion, to intention, and to language. The human \nbrain does not just happen to recognize isolated objects; these functions are an \nintegral part of what deeply defines human intelligence.\nMARTIN FORD: Could you sketch out some of the work you’ve done in computer \nor machine vision?\nFEI-FEI LI: During the first decade of the 21st century, object recognition was the \nholy grail that the field of computer vision was working on. Object recognition is \na building block for all vision. As humans, if we open our eyes and look around \nour environment, we recognize almost every object we look at. Recognition is \ncritically important for us to be able to navigate the world, understand the world, \ncommunicate about the world, and do things in the world. Object recognition \nwas a very lofty holy grail in computer vision, and we were using tools such as \nmachine learning at that time.\nThen in the mid-2000s, as I transitioned from a PhD student to become a \nprofessor, it became obvious that computer vision as a field was stuck, and that \nthe machine learning models were not making huge progress. Back then, the \nwhole international community was benchmarking autorecognition tasks with \naround 20 different objects. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 327
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n148\nSo, along with my students and collaborators, we started thinking deeply about \nhow we might make a quantum leap forward. We began to see that it was just not \ngoing to be sufficient for us to work with such a small-scale problem involving 20 \nobjects to reach the lofty goal of object recognition. I was very much inspired by \nhuman cognition at this point, and the developmental story of any child, where \nthe first few years of development involves a huge amount of data. Children engage \nin a huge amount of experimenting with their world, seeing the world, and just \ntaking it in. Coincidentally, at was just at this time that the internet had boomed \ninto a global phenomenon that provided a lot of big data. \nI wanted to do a pretty crazy project that would take all the pictures we could \nfind on the internet, organize them into concepts that mattered to humans, and \nlabel those images. As it turned out, this crazy idea turned into the project called \nImageNet, with 15 million images organized into 22,000 labels. \nWe immediately open-sourced ImageNet for the world, because to this day I believe \nin the democratization of technology. We released the entire 15 million images to \nthe world and started to run international competitions for researchers to work on \nthe ImageNet problems: not on the tiny small-scale problems but on the problems \nthat mattered to humans and applications.\nFast-forward to 2012, and I think we see the turning point in object recognition for \na lot of people. The winner of the 2012 ImageNet competition created a convergence \nof ImageNet, GPU computing power, and convolutional neural networks as an \nalgorithm. Geoffrey Hinton wrote a seminal paper that, for me, was Phase One in \nachieving the holy grail of object recognition. \nMARTIN FORD: Did you continue this project?\nFEI-FEI LI: For the next two years, I worked on taking object recognition a step \nfurther. If we again look at human development, babies start by babbling, a few \nwords, and then they start making sentences. I have a two-year-old daughter and \na six-year-old son. The two-year-old is making a lot of sentences, which is huge \ndevelopmental progress, something that humans do as intelligent agents and animals. \nInspired by this human development, I started working on the problem of how \nto enable computers to speak sentences when they see pictures, rather than just \nlabeling a chair or a cat. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 328
  },
  {
    "chunk_full": "FEI-FEI LI\n149\nWe were working on this problem using deep learning models for a few years. \nIn 2015, I talked about the project at the TED2015 conference. The title of my \ntalk was How we’re teaching computers to understand pictures, and I discussed enabling \ncomputers to be able to understand the content of an image and summarize it in a \nhuman, natural-language sentence which could then be communicated.\nMARTIN FORD: The way algorithms are trained is quite different from what happens \nwith a human baby or young child. Children for the most part are not getting \nlabeled data—they just figure things out. And even when you point to a cat and say, \n“look there’s a cat,” you certainly don’t have to do that a hundred thousand times. \nOnce or twice is probably enough. There’s a pretty remarkable difference in terms \nof how a human being can learn from the unstructured, real-time data we meet in \nthe world, versus the supervised learning that’s done with AI now.\nFEI-FEI LI: You totally nailed it, and this is why as an AI scientist I wake up so \nexcited every day because there’s so much to work with. Some part of the work has \ninspiration from humans, but a large part of the work does not resemble humans \nat all. As you say, the success today of neural networks and deep learning mostly \ninvolve supervised pattern recognition, which means that it’s a very narrow sliver \nof capabilities compared to general human intelligence. \nI gave a talk at Google’s I/O conference this year, where I was again using the \nexample of my two-year-old daughter. A couple of months ago, I watched her \non a baby monitor escape from her crib by learning the cracks in the system, a \npotential path to escape from the crib. I saw her open her sleeping bag, which I \nhad particularly modified in order to prevent her from opening and get herself \nout. That kind of coordinated intelligence to a visual motor, planning, reasoning, \nemotion, intention, and persistence, is really nowhere to be seen in our current \nAI. We’ve got a lot of work to do, and it’s really important to recognize that.\nMARTIN FORD: Do you think there will likely be breakthroughs that allow computers \nto learn more like children? Are people actively working on how to solve this problem? \nFEI-FEI LI: There are absolutely people working on that, especially within the \nresearch community. A lot of us are working on the next horizon problem. In my \nown lab at Stanford, we are working on robotic learning problems where the AI is \nlearning by imitation, which is much more natural than learning by supervised labels. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 329
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n150\nAs kids, we watch how other humans do things and then we do it; so, the field \nis now starting to get into inverse reinforcement learning algorithms, and neuro-\nprogramming algorithms. There is a lot of new exploration, and DeepMind \nis doing that. Google Brain is doing that; Stanford is doing that; and MIT is \ndoing that. I’m very hopeful that in our lifetime we’ll be seeing a lot more AI \nbreakthroughs, given the incredible amount of global investment in this area. \nWe also see a lot of effort in the research community to look at algorithms \nbeyond supervised learning. \nDating when a breakthrough will come, is much harder to predict. I learned, as a \nscientist, not to predict scientific breakthroughs, because they come serendipitously, \nand they come when a lot of ingredients in history converge. But I’m very hopeful \nthat in our lifetime we’ll be seeing a lot more AI breakthroughs given the incredible \namount of global investment in this area.\nMARTIN FORD: I know you’re the chief scientist for Google Cloud. A point that \nI always make when I give presentations is that AI and machine learning are going \nto be like a utility—almost like electricity—something that can be deployed almost \nanywhere. It seems to me that integrating AI into the cloud is one of the first steps \ntoward making the technology universally available. Is that in line with your vision?\nFEI-FEI LI: As a professor, every seven or eight years there is a built-in encouragement \nfor sabbaticals where we leave the university for a couple of years to explore a \ndifferent line of work or to refresh yourself. Two years ago, I was very sure that \nI wanted to join an industry to really democratize AI technologies, because AI \nhas advanced to a point where some of the technology that is now working, like \nsupervised learning and pattern recognition, is doing good things for society. And \nlike you say, if you think about disseminating technology like AI, the best and \nbiggest platform is a cloud because there’s no other computing on any platform \nwhich humanity has invented that reaches as many people. Google Cloud alone, at \nany moment, is empowering, helping, or serving billions of people. \nI was therefore very happy to be invited as chief scientist of Google Cloud, where \nthe mission is to democratize AI. This is about creating products that empower \nbusinesses and partners, and then taking the feedback from customers and working \nwith them closely to improve the technology itself. This way we can close that \nloop between the democratization of AI and the advancement AI. I’m overseeing \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 330
  },
  {
    "chunk_full": "FEI-FEI LI\n151\nboth the research part of cloud AI as well as the product of cloud AI, and we’ve \nbeen here since January 2017. \nAn example of what we’re doing is a product we created that’s called AutoML. This \nis a unique product on the market to really lower the entry barrier of AI as much \nas much as possible—so that AI can be delivered to people who don’t do AI. The \ncustomer pain point is that so many businesses need customized models to help \nthem to tackle their own problems. So, in the context of computer vision, if say \nI were a retailer, I might need a model to recognize my logo. If I were National \nGeographic magazine, I might need a model to recognize wild animals. If I worked in \nthe agricultural industry, I might need a model to recognize apples. People have all \nkinds of use cases, but not everybody has the machinery expertise to create the AI.\nSeeing this problem, we built the AutoML product so that as long as someone \nknows what they need, such as, “I need it for apples versus oranges,” and you bring \nthe training data, we will do everything for you. So, from your perspective, it’s all \nautomatic and delivers a customized machine learning model for your problem. We \nrolled AutoML out in January, and tens of thousands of customers have signed up to \nthis service. It’s been very rewarding to see this democratization of cutting-edge AI.\nMARTIN FORD: It sounds like AutoML, if it makes machine learning accessible to \nless technical people, could easily result in a sort of explosion of all kinds of AI \napplications created by different people with different objectives.\nFEI-FEI LI: Yes, exactly! In fact, I used a Cambrian explosion analogy in one \nof my presentations.\nMARTIN FORD: Today there is an enormous focus on neural networks and deep \nlearning. Do you think that’s the way forward? You obviously believe that deep \nlearning will be refined over time, but you do think that it is really the foundational \ntechnology that’s going to lead AI into the future? Or is there another thing out \nthere that’s completely different, where we’re going to end up throwing away deep \nlearning and back propagation and all of that, and have something entirely new?\nFEI-FEI LI: If you look at human civilization, the path of scientific progress is always \nbuilt upon undoing yourself. There isn’t a moment in history where scientists would \nhave said that there’s nothing more to come, that there’s no refinement left. This is \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 331
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n152\nespecially true for AI, which is such a nascent field that’s only been around for 16 \nyears. Compared to fields like physics, biology, and chemistry, which have hundreds \nif not thousands of years of history, AI still has a lot to progress.\nAs an AI scientist, I do not philosophically believe we’ve finished our task, that \nconvolutional neural networks and deep learning are the answers to everything—\nnot by a huge margin. As you said earlier, a lot of problems are not labeled data \nor involve lots of training examples. Looking at the history of civilization and the \nthings it’s taught us, we cannot possibly think we’ve reached a destination yet. As \nmy two-year-old kid escaping the crib story tells us, we don’t have any AI that is \nclose to that level of intelligence sophistication. \nMARTIN FORD: What particular projects would you point to that you think are at \nthe forefront of research in AI?\nFEI-FEI LI: In my own lab, we have been doing a project that goes way beyond \nImageNet, called the Visual Genome Project. In this project, we’ve thought deeply \nabout the visual world, and we have recognized that ImageNet is very impoverished. \nImageNet just gives some discreet labels of objects on the picture or visual scene, \nwhereas in real visual scenes, objects are connected, humans and objects are doing \na lot of things. There’s also the connection between vision and language, so Visual \nGenome Project is really what one would call the next step beyond ImageNet. \nIt’s designed to really focus on the relationships between the visual world and our \nlanguage, so we’ve been doing a lot of work in pushing that forwards. \nAnother direction I’m super excited about involves AI and healthcare. We’re \ncurrently working on a project in my lab that’s inspired by a focus on one particular \nelement of healthcare—care itself. The topic of care touches a lot of people. Care \nis the process of taking care of patients, but if you look at our hospital system, \nfor example, there are a lot of inefficiencies: low quality care, lack of monitoring, \nerrors, and high costs associated with the whole healthcare delivery process. Just \nlook at the mistakes of the surgery world, and the lack of hygiene that can result \nin hospitals acquiring infections. There’s also the lack of help and of awareness in \nsenior home care. There are a lot of problems in care. \nWe recognized, about five years ago, that the technology that could help \nhealthcare delivery is very similar to the top technology of self-driving cars and \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 332
  },
  {
    "chunk_full": "FEI-FEI LI\n153\nAI. We need smart sensors to sense the environment and the mood, and we need \nalgorithms to make sense of the data collected and give feedback to clinicians, \nnurses, the patient and family members. So, we started pioneering this AI for \nhealthcare delivery area of research. We’re working with Stanford children’s \nhospital, Utah’s Intermountain Hospital, and San Francisco’s unlocked senior \nhomes. We recently published an opinion piece in the New England Journal of \nMedicine. I think it’s very exciting because it’s using cutting-edge AI technology, \nlike the ones self-driving cars use, but it’s applied to an area that is so deeply \ncritical for human needs and wellbeing.\nMARTIN FORD: I want to talk about the path to artificial general intelligence (AGI). \nWhat you think the major hurdles that we would need to surmount are?\nFEI-FEI LI: I want to answer your question in two parts. The first part I’ll answer \nmore narrowly on the question about the path to AGI, and in the second part, I \nwant to talk about what I think the framework and frame of mind should be for \nthe future development of AI. \nSo, let’s first define AGI, because this isn’t about AI versus AGI: it’s all on one \ncontinuum. We all recognize today’s AI is very narrow and task specific, focusing \non pattern recognition with labeled data, but as we make AI more advanced, that \nis going to be relaxed, and so in a way, the future of AI and AGI is one blurred \ndefinition. I guess the general definition of AGI would be the kind of intelligence that \nis contextualized, situationally aware, nuanced, multifaceted and multidimensional—\nand one that has the kind of learning capability that humans do, which is not only \nthrough big data but also through unsupervised learning, reinforcement learning, \nvirtual learning, and various kinds of learning.\nIf we use that as a definition of AGI, then I think the path to AGI is a continued \nexploration of algorithms that are beyond just supervised. I also believe that it’s \nimportant to recognize the interdisciplinary need for collaborations in brain science, \ncognitive science, and behavior science. A lot of AI’s technology, whether it’s the \nhypothesis of the task or the evaluation or the conjecture of algorithms, can touch \non related areas like brain science and cognitive science. It’s also really critical \nthat we invest and advocate for this collaboration and interdisciplinary approach. \nI’ve actually written about this in my New York Times editorial opinion piece in \nMarch 2018 titled, How to Make A.I. That’s Good for People.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 333
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n154\nMARTIN FORD: Right, I read that, and I know you’ve been advocating a comprehensive \nframework for the next phase of AI development.\nFEI-FEI LI: Yes, I did that because AI has graduated from an academic and niche \nsubject area into a much bigger field that impacts human lives in very profound ways. \nSo how do we divide AI, and how do we create AI in the next phase, for the future? \nThere are three core components or elements of human-centered AI. The first \ncomponent is advancing AI itself, which has a lot to do with what I was just \ntalking about: interdisciplinary research and work, on AI, across neuroscience \nand cognitive science. \nThe second component of human-centered AI is really the technology and \napplication; the human-centered technology. We talk a lot about AI replacing \nhumans in terms of a job scenario, but there are way more opportunities for AI to \nenhance humans and augment humans. The opportunities are much, much wider \nand I think we should advocate and invest in technology that is about collaboration \nand interaction between humans and machines. That’s robotics, natural language \nprocessing, human-centric design, and all that. \nThe third component of human-centered AI recognizes that computer science alone \ncannot address all the AI opportunities and issues. It’s a deeply impactful technology \nto humanity, so we should be bringing in economists to talk about jobs, to talk \nabout bigger organizations, to talk about finance. We should bring in policymakers \nand law scholars and ethicists to talk about regulations, to talk about bias, to talk \nabout security and privacy. We should work with historians, with artists, with \nanthropologists, and with philosophers—to look at the different implications and \nnew areas of AI research. These are really the three elements that are about human-\ncentered AI for the next phase.\nMARTIN FORD: When you talk about human-centered AI, you’re trying to address \nsome concerns that have been raised, and I wanted to touch on some of those. \nThere’s this idea that there is a true existential threat, something that’s been raised \nby Nick Bostrom, Elon Musk, and Stephen Hawking, where super intelligence could \nhappen very rapidly, a recursive self-improvement loop. I’ve heard people say that \nyour AutoML might be one step toward that because you’re using technology to \ndesign other machine learning systems. What do you think about that?\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 334
  },
  {
    "chunk_full": "FEI-FEI LI\n155\nFEI-FEI LI: I think that it’s healthy that we have thought leaders like Nick Bostrom \nto conjecture a fairly troubling future of AI, or at least send warning signs of things \nthat could impact us in ways that we didn’t expect. But I think it’s important to \ncontextualize that, because in the long history of human civilization, every time a \nnew social order or technology has been invented, it’s had that same potential to \ndisrupt the human world in unexpected and deeply profound ways.\nI also think that it’s healthy to have different ways of exploring these important \nquestions through a diversity of voices. And from voices coming from different \ndevelopment paths. It’s good to have Nick, who is a philosopher, to philosophize \nthe potentials. Nick’s is one type of voice in the social discourse of AI. I think \nwe need many voices to contribute.\nMARTIN FORD: That particular concern really has been given a lot of weight by \npeople like Elon Musk who attracts a lot of attention by saying, for example, that \nAI is a bigger threat than North Korea. Do you think that’s over the top, or should \nwe really be that concerned as a society, at this point in time?\nFEI-FEI LI: By definition, we tend to remember over-the-top statements. As a \nscientist and as a scholar I tend to focus on arguments that are built on deeper and \nwell substantiated evidence and logical deduction. It’s really not important whether \nI judge a particular sentence or not.\nThe important thing is what we do with the opportunities we have now, and \nwhat each one of us is doing. For example, I’m more vocal to discuss the bias and \nlack of diversity in AI, and so that’s what I speak about, because it’s much more \nimportant to look at what I do.\nMARTIN FORD: So, the existential threat is pretty far in the future?\nFEI-FEI LI: Well like I said, it’s healthy that some people are thinking about \nthat existential threat.\nMARTIN FORD: You mentioned briefly the impact on jobs, and this is something that \nI’ve written about a lot, in fact, it’s what my previous book was about. You said that \nthere are definitely opportunities to enhance people—but at the same time, there is \nthis intersection of technology and capitalism, and businesses always have a very strong \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 335
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n156\nmotive to eliminate labor if they can. That’s happened throughout history. It seems \nas though we’re at an inflection point today, where there are soon going to be tools \nthat are able to automate a much broader range of tasks than anything in the past. \nThese tools will replace cognitive and intellectual tasks, and not just manual work. Is \nthere potential for lots of job losses, deskilling of jobs, depressed wages, and so forth?\nFEI-FEI LI: I don’t pretend to be an economist, but capitalism is one form of human \nsocietal order and it is what, 100 years old? What I’m saying is that no one can \npredict that capitalism is the only form of human society going forward; nor can \nanyone predict how technology is going to morph in that future society. \nMy argument is that AI, as a technology with a lot of potentials, has an opportunity \nto make life a lot better, to make work more productive. I’ve been working with \ndoctors for five years, and I get that there are parts of doctors’ work that can be \npotentially replaced by a machine. But I really want that part to be replaced, because \nI see our doctors overworked, overwhelmed, and their brilliance is sometimes not \nused in the ways that it should be used. I want to see our doctors having time to \ntalk to patients, having time to talking to each other, and having time to understand \nand optimize for the best treatment of diseases. I want to see our doctors having \ntime to do the detective work that some rare or harder illnesses need. \nAI as a technology has so much potential to enhance and augment labor, in addition \nto just replace it, and I hope that we see more and more of that. This is something \nthat we’ve got evidence of in history. Computers automated a lot of jobs away from \noffice typists some 40 years ago. But what we see is new jobs, we now have software \nengineers as a new job, we have people doing way more interesting work around \nthe office. The same went with ATM machines: when they started to automate some \nof these transactions in the bank, the number of tellers actually increased because \nthere were more financial services that could be done by humans—and the mundane \ncash deposit or withdrawal can now be done by ATM machines. It’s not a black and \nwhite story at all, and it’s our work together that defines how things go.\nMARTIN FORD: Let’s talk about some of the other topics you’ve focused on, \nlike diversity and bias. It seems to me that these are two separate things, really. \nThe bias comes about because it’s encapsulated in the human-generated data that \nmachine learning algorithms are trained on, whereas diversity is more of an issue \nof who’s working in AI.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 336
  },
  {
    "chunk_full": "FEI-FEI LI\n157\nFEI-FEI LI: First of all, I don’t think they’re as separate as you think because at the end \nof the day, it’s the values that humans bring to machines. If we have a machine learning \npipeline, starting with the data itself, then when that data is biased our machine learning \noutcome will be biased. And some forms of bias might have even fatal implications. But \nthat itself is potentially linked to the development process of the pipeline. I just want \nto make a philosophical point that they are actually potentially linked. \nThat now said, I agree with you that bias and diversity can be treated a little more \nseparately. For example, in terms of data bias resulting in machine learning outcome \nbias, a lot of academia researchers are recognizing this now, and working on ways to \nexpose that kind of bias. They’re also modifying algorithms to respond to bias in a way \nto try to correct it that way. This exposure to the bias of products and technology, \nfrom academia to industry, is really healthy, and it keeps the industry on their toes. \nMARTIN FORD: You must have to deal with machine learning bias at Google. \nHow do you address it?\nFEI-FEI LI: Google now has a whole group of researchers working on machine \nlearning bias and “explainability” because the pressure is there to tackle bias, \nto deliver a better product, and we want to be helping others. It’s still early \ndays, but it’s so critical that this area of research gets invested and that there’s \nmore development in that. \nOn the topic of diversity and the bias of people, I think it’s a huge crisis. We’ve \nnot solved the issue of diversity in our workforces, especially in STEM. Then \nwith tech and AI being so nascent and yet so impactful as a technology, this \nproblem is exacerbated. If we look around, whether you’re looking at AI groups \nin companies, AI professors in academia, AI PhD students or AI presenters at top \nAI conferences, no matter where you cut it: we lack diversity. We lack women, \nand we lack under-represented minorities.\nMARTIN FORD: I know you started the AI4ALL project, which is focused on attracting \nwomen and underrepresented minorities into the field of AI. Could you talk about that?\nFEI-FEI LI: Yes, that lack of representation we’ve been discussing led to me start \nthe Stanford AI4ALL project four years ago. One important effort we can make \nis to inspire high school students, before they go to college and decide on their \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 337
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n158\nmajor and future career, and to invite them into AI research and AI study. We \nespecially think that, for underrepresented minorities who are inspired by human \nmissions in AI, they respond to the kind of bigger-than-themselves motivations \nand inspiration. As a result, we’ve crafted this summer curriculum every year \nat Stanford, for the past four years, and invited high school girls to participate \nin AI. This was so successful that in 2017 we formed a national nonprofit \norganization called AI4ALL and started to replicate this model and invite other \nuniversities to participate. \nA year later, we have six universities targeting different areas where AI has \nreally struggled to get people involved. In addition to Stanford and Simon \nFraser University, we’ve also got Berkeley targeting AI for low-income students, \nPrinceton focusing on AI for racial minorities, Christopher Newport University \ndoing AI for off-the-rails students, and Boston University doing AI for girls. \nThese have only been running for a small amount of time, but we’re hoping to \nmushroom the program and continue to invite future leaders of AI from a much \nmore diverse background.\nMARTIN FORD: I wanted to ask if you think there’s a place for the regulation of \nartificial intelligence. Is that something you’d like to see? Would you advocate for \nthe government taking more of an interest, in terms of making rules, or do you \nthink that the AI community can solve these problems internally?\nFEI-FEI LI: I actually don’t think AI, if you mean the AI technologists, can solve \nall the AI problems by themselves: our world is interconnected, human lives are \nintertwined, and we all depend on each other. \nNo matter how much AI that I make happen, I still drive on the same highway, \nbreathe the same air, and send my kids to community schools. I think that we need \nto have a very humanistic view of this and recognize that for any technology to have \nthis profound impact, we need to invite all sectors of life and society to participate. \nI also think the government has a huge role, which is to invest in basic science, \nresearch, and education of AI. Because if we want to have the transparent technology, \nand if we want to have the fair technology, and if we want to have more people who \ncan understand and impact this technology in positive ways, then the government \nneeds to invest in our universities, research institutes and schools to educate people \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 338
  },
  {
    "chunk_full": "FEI-FEI LI\n159\nabout AI and support basic science research. I’m not trained as a policymaker, but \nI talk to some policymakers, and I talk to my friends. Whether it’s about privacy, \nfairness, dissemination, or collaboration, I see a role the government can play.\nMARTIN FORD: The final thing I want to ask you about is this perceived AI arms \nrace, especially with China. How seriously do you take that, and is it something \nwe should worry about?\nChina does have a different system, a more authoritarian system, and a much bigger \npopulation which means more data to train algorithms on and less restrictions \nregarding privacy and so forth. Are we at risk of falling behind in AI leadership?\nFEI-FEI LI: Right now, we’re living in a major hype-cycle of modern physics and how \nthat can transform technology, whether it’s nuclear technology, or electrical technology. \nOne hundred years later, will we ask ourselves the question: which person owned \nmodern physics? Will we try to name the company or country that owned modern \nphysics and everything after the industrial revolution? I think it will be difficult for \nany of us to answer those questions. My point is, as a scientist and as an educator, that \nthe human quest for knowledge and truth has no borders. If there is a fundamental \nprinciple of science, it is that these are the universal truths and quests for these truths, \nwhich we all seek as a species together. And AI is a science in my opinion. \nFrom that point of view, as a basic scientist and as an educator, I work with \npeople from all backgrounds. My Stanford lab literally consists of students from \nevery continent. With the technology we create, whether it’s automation or it’s \nhealthcare, we hope to benefit everyone. \nOf course, there is going to be competition between companies and between \nregions, and I hope that’s healthy. Healthy competition means that we respect \neach other, we respect the market, we respect the users and consumers, and \nwe respect the laws, even if it’s cross-border laws or international laws. As a \nscientist, that’s what I advocate for, and I continue to publish in the open source \ndomain to educate students of all colors and nations, and I want to collaborate \nwith people of all backgrounds.\nMore Information about AI4ALL can be found at http://ai-4-all.org/.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 339
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n160\nFEI-FEI LI is Chief Scientist, AI and Machine Learning at Google Cloud, Professor of \nComputer Science at Stanford University, and Director of both the Stanford Artificial \nIntelligence Lab and the Stanford Vision Lab. Fei-Fei received her undergraduate degree in \nphysics from Princeton University and her PhD in electrical engineering from the California \nInstitute of Technology. Her work has focused on computer vision and cognitive neural \nscience and she is widely published in top academic journals. She is the co-founder of \nAI4ALL, an organization focused on attracting women and people from underrepresented \ngroups into the field of AI, which began at Stanford and has now scaled up to universities \nacross the United States. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 340
  },
  {
    "chunk_full": "FEI-FEI LI\n161\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 341
  },
  {
    "chunk_full": "",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 342
  },
  {
    "chunk_full": "DEMIS HASSABIS\n163\nDEMIS HASSABIS\nCO-FOUNDER & CEO OF DEEPMIND \nAI RESEARCHER AND NEUROSCIENTIST\nDemis Hassabis is a former child chess prodigy, who started coding and designing \nvideo games professionally at age 16. After graduating from Cambridge University, \nDemis spent a decade leading and founding successful startups focused on video \ngames and simulation. He returned to academia to complete a PhD in cognitive \nneuroscience at University College London, followed by postdoctoral research at \nMIT and Harvard. He co-founded DeepMind in 2010. DeepMind was acquired \nby Google in 2014 and is now part of Alphabet’s portfolio of companies.\nGames are just our training domain. We’re not doing \nall this work just to solve games; we want to build  \nthese general algorithms that we can apply to  \nreal-world problems.\n“ \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 343
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n164\nMARTIN FORD: I know you had a very strong interest in chess and video games \nwhen you were younger. How has that influenced your career in AI research and \nyour decision to found DeepMind? \nDEMIS HASSABIS: I was a professional chess player in my childhood with \naspirations of becoming the world chess champion. I was an introspective kid \nand I wanted to improve my game, so I used to think a lot about how my brain \nwas coming up with these ideas for moves. What are the processes that are \ngoing on there when you make a great move or a blunder? So, very early on I \nstarted to think a lot about thinking, and that led me to my interest in things \nlike neuroscience later on in my life.\nChess, of course, has a deeper role in AI. The game itself has been one of the main \nproblem areas for AI research since the dawn of AI. Some of the early pioneers in \nAI like Alan Turing and Claude Shannon were very interested in computer chess. \nWhen I was 8 years old, I purchased my first computer using the winnings from \nthe chess tournaments that I entered. One of the first programs that I remember \nwriting was for a game called Othello—also known as Reversi—and while it’s a \nsimpler game than chess, I used the same ideas that those early AI pioneers had \nbeen using in their chess programs, like alpha-beta search, and so on. That was my \nfirst exposure to writing an AI program.\nMy love of chess and games got me into programming, and specifically into \nwriting AI for games. The next stage for me was to combine my love of games and \nprogramming into writing commercial videogames. One key theme that you’ll see \nin a lot of my games, from Theme Park (1994) to Republic: The Revolution (2003), \nwas that they had simulation at the heart of their gameplay. The games presented \nplayers with sandboxes with characters in them that reacted to the way that you \nplayed. It was AI underpinning those characters, and that was always the part that \nI worked on specifically. \nThe other thing that I was doing with games was training my mind on certain \ncapabilities. For example, with chess, I think it’s a great thing for kids to learn at \nschool because it teaches problem-solving, planning, and all sorts of other meta-\nskills that I think are then useful and translatable to other domains. Looking back, \nperhaps all of that information was in my subconscious when I started DeepMind \nand started using games as a training environment for our AI systems. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 344
  },
  {
    "chunk_full": "DEMIS HASSABIS\n165\nThe final step for me, before starting DeepMind, was taking undergraduate \ncomputer science course at Cambridge University. At the time, which was the early \n2000s, I felt that as a field we didn’t have quite enough ideas to try and attempt to \nclimb the Everest of AGI. This led me to my PhD in Neuroscience because I felt \nwe needed a better understanding of how the brain solved some of these complex \ncapabilities, so that we could be inspired by that to come up with new algorithmic \nideas. I learned a lot about memory and imagination—topics that we didn’t at the \ntime, and in some cases still don’t, know how to get machines to do. All those \ndifferent strands then came together into DeepMind. \nMARTIN FORD: Your focus then, right from the beginning, has been on machine \nintelligence and especially AGI?\nDEMIS HASSABIS: Exactly. I’ve known I wanted to do this as a career since my \nearly teens. That journey started with my first computer. I realized straight away \nthat a computer was a magical tool because most machines extend your physical \ncapability, but here was a machine that could extend your mental capabilities. \nI still get excited by the fact that you can write a program to crunch a scientific \nproblem, set it running, go off to sleep, and then when you wake up in the morning \nit’s solved it. It’s almost like outsourcing your problems to the machine. This led me \nto think of AI as the natural next step, or even the end step, where we get machines \nto be smarter in themselves so they’re not just executing what you’re giving them, \nbut they’re actually able to come up with their own solutions. \nI’ve always wanted to work on learning systems that learn for themselves, and I’ve \nalways been interested in the philosophical idea of what is intelligence and how can \nwe recreate that phenomena artificially, which is what led me to create DeepMind.\nMARTIN FORD: There aren’t many examples of pure AGI companies around. One \nreason is that there’s not really a business model for doing that; it’s hard to generate \nrevenue in the short term. How did DeepMind overcome that?\nDEMIS HASSABIS: From the beginning, we were an AGI company, and we were \nvery clear about that. Our mission statement of solving intelligence was there \nfrom the beginning. As you can imagine, trying to pitch that to standard venture \ncapitalists was quite hard.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 345
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n166\nOur thesis was that because what we were building was a general-purpose technology, \nif you could build it powerfully enough, general enough, and capable enough, then \nthere should be hundreds of amazing applications for it. You’d be inundated with \nincoming possibilities and opportunities, but you would require a large amount of \nupfront research first from a group of very talented people that we’d need to get \ntogether. We thought that was defensible because of the small number of people \nin the world that could actually work on this, especially if you think back to 2009 \nand 2010 when we first started out. You could probably count less than 100 people \nthat could contribute to that type of work. Then there was the question of can we \ndemonstrate clear and measurable progress?\nThe problem with having a large and long-term research goal is how do your \nfunders get confidence that you actually know what you’re talking about? With \na typical company, your metric is your product and the number of users, \nsomething that’s easily measurable. The reason why a company like DeepMind \nis so rare is that’s very hard for an external non-specialist, like a venture \ncapitalist, to judge whether you’re making sense and your plan really is sensible, \nor whether you’re just crazy. \nThe line is very thin, especially when you’re going very far out, and in 2009 and \n2010 no one was talking about AI. AI was not the hot topic that it is today. It was \nreally difficult for me to get my initial seed funding because of the previous 30 years \nof failed promises in AI. We had some very strong hypotheses as to why that was, \nand those were the pillars that we were basing DeepMind on. Things like taking \ninspiration from neuroscience, which had massively improved our understanding of \nthe brain in the last 10 years; doing learning systems not traditional expert systems; \nusing benchmarking and simulations for the rapid development and testing of AI. \nThere was a set of things that we committed to that turned out to be correct and \nwere our explanations for why AI hadn’t improved in the previous years. Another \nvery powerful thing was that these new techniques required a lot of computing \npower, which was now becoming available in the form of GPUs.\nOur thesis made sense to us, and in the end, we managed to convince enough \npeople, but it was hard because we were operating at that point within a very \nskeptical, non-fashionable domain. Even in academia, AI was frowned upon. It had \nbeen rebranded “machine learning,” and people who worked on AI were considered \nto be fringe elements. It’s amazing to see how quickly all of that has changed.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 346
  },
  {
    "chunk_full": "DEMIS HASSABIS\n167\nMARTIN FORD: Eventually you were able to secure the funding to be viable as \nan independent company. But then you decided to let Google acquire DeepMind. \nCan you tell me about the rationale behind the acquisition and how that happened?\nDEMIS HASSABIS: It’s worth noting that we had no plans to sell, partly because \nwe figured no big corporate would understand our value until DeepMind started \nproducing products. It’s also not fair to say that we didn’t have a business model. \nWe did, we just hadn’t gone very far down the line of executing it. We did already \nhave some cool technology, DQN (deep Q-network—our first general-purpose \nlearning model) and our Atari work had already been done by 2013. But then \nLarry Page, the Co-Founder of Google, heard about us through some of our \ninvestors and out of the blue in 2013 I received an email from Alan Eustace, who \nwas running search and research at Google, saying that Larry’s heard of DeepMind \nand he’d like to have a chat.\nThat was the start, but the process took a long time because there were a lot of things \nI wanted to be sure of before we joined forces with Google. But at the end of the \nday, I became convinced that by combining with Google’s strengths and resources—\ntheir computing power and their ability to construct a much bigger team, we would \nbe able to execute on our mission much more quickly. It wasn’t to do with money, \nour investors were willing to increase funding to keep us going independently, but \nDeepMind has always been about delivering AGI and using it for the benefit of the \nworld, and there was an opportunity with Google to accelerate that.\nLarry and the people at Google were just as passionate about AI as I was, and they \nunderstood how important the work we would do would be. They agreed to give us \nautonomy as to our research roadmap and our culture, and also to staying in London, \nwhich was very important to me. Finally, they also agreed to have an ethics board \nconcerning our technology, which was very unusual but very prescient of them. \nMARTIN FORD: Why did you choose to be in London, and not Silicon Valley? Is \nthat a Demis Hassabis or a DeepMind thing?\nDEMIS HASSABIS: Both really. I’m a born-and-bred Londoner, and I love London, \nbut at the same time, I thought it was a competitive advantage because the UK and \nEurope have amazing universities in the field of AI like Cambridge and Oxford. But \nalso, at the time there was no real ambitious research company in the UK, or really \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 347
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n168\nin Europe, so our hiring prospects were high, especially with all these universities \noutputting great postgraduate and graduate students.\nIn 2018 there are now a number of companies in Europe, but we were the first in \nAI who were doing deep research. But more culturally, I think it’s important that \nwe have more stakeholders and cultures involved in making AI, not just Silicon \nValley in the United States, but also European sensibilities and Canadian, and so on. \nUltimately, this is going to be of global significance and having different voices about \nhow to use it, what to use it for, and how to distribute the proceeds, is important. \nMARTIN FORD: I believe you’re also opening up labs in other European cities?\nDEMIS HASSABIS: We’ve opened a small research lab in Paris, which is our first \ncontinental European office. We’ve also opened two labs in Canada in Alberta and \nMontreal. More recently, since joining Google, we now have an applied team office in \nMountain View, California who are right next to the Google teams that we work with.\nMARTIN FORD: How closely do you work with the other AI teams at Google? \nDEMIS HASSABIS: Google’s a huge place, and there are thousands of people working \non every aspect of machine learning and AI, from both a very applied perspective \nto a pure research point of view. As a result of that, there are a number of team \nleads who all know each other, and there’s a lot of cross-collaboration, both with \nproduct teams and research teams. It tends to be ad hoc, so it depends on individual \nresearchers or individual topics, but we keep each other informed at a high level \nof our overall research directions. \nAt DeepMind, we’re quite different from other teams in that we’re pretty focused \naround this one moonshot goal of AGI. We’re organized around a long-term roadmap, \nwhich is our neuroscience-based thesis, which talks about what intelligence is and \nwhat’s required to get there. \nMARTIN FORD: DeepMind’s accomplishments with AlphaGo are well documented. \nThere’s even a documentary film about it1, so I wanted to focus more on your latest \ninnovation, AlphaZero, and on your plans for the future. It seems to me that you’ve \n1 https://www.alphagomovie.com/\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 348
  },
  {
    "chunk_full": "DEMIS HASSABIS\n169\ndemonstrated something very close to a general solution for information-complete \ntwo-player games; in other words, games where everything that can be known is \navailable there on the board or in terms of pixels on the screen. Going forward, \nare you finished with that type of game? Are you planning to move on to more \ncomplex games with hidden information, and so forth? \nDEMIS HASSABIS: There’s a new version of AlphaZero that we’re going to publish \nsoon that’s even more improved, and as you’ve said, you can think of that as a \nsolution to two-player perfect-information games like chess, Go, shogi, and so \non. Of course, the real world is not made up of perfect information, so as you’ve \nsaid, the next step is to create systems that can deal with that. We’re already \nworking on that, and one example of this is our work with the PC strategy game, \nStarCraft, which has a very complicated action space. It’s very complex because \nyou build units, so it’s not static in terms of what pieces you have, like in chess. \nIt’s also real time, and the game has hidden information, for example, the “fog of \nwar” that obscures onscreen information until you explore that area. \nBeyond that, games are just our training domain. We’re not doing all this work \njust to solve games; we want to build these general algorithms that we can apply \nto real-world problems.\nMARTIN FORD: So far, your focus has primarily been on combining deep learning \nwith reinforcement learning. That’s basically learning by practice, where the system \nrepeatedly attempts something, and there’s a reward function that drives it toward \nsuccess. I’ve heard you say that you believe that reinforcement learning offers a \nviable path to general intelligence, that it might be sufficient to get there. Is that \nyour primary focus going forward?\nDEMIS HASSABIS: Going forward, yes, it is. I think that technique is extremely \npowerful, but you need to combine it with other things to scale it. Reinforcement \nlearning has been around for a long time, but it was only used in very small toy \nproblems because it was very difficult for anyone to scale up that learning in any way. \nIn our Atari work, we combined that with deep learning, which did the processing \nof the screen, and the model of the environment you’re in. Deep learning is amazing \nat scaling, so combining that with reinforcement learning allowed it to scale to these \nlarge problems that we’ve now tackled in AlphaGo and DQN—all of these things \nthat people would have told you was impossible 10 years ago.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 349
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n170\nI think we proved that first part. The reason we were so confident about it and why \nwe backed it when we did was because in my opinion reinforcement learning will \nbecome as big as deep learning in the next few years. DeepMind is one of the few \ncompanies that take that seriously because, from the neuroscience perspective, we \nknow that the brain uses a form of reinforcement learning as one of its learning \nmechanisms, it’s called temporal difference learning, and we know the dopamine \nsystem implements that. Your dopamine neurons track the prediction errors your \nbrain is making, and then you strengthen your synapses according to those reward \nsignals. The brain works along these principles, and the brain is our only example \nof general intelligence, which is why we take neuroscience very seriously here. To \nus, that must be a viable solution to the problem of general intelligence. It may not \nbe the only one, but from a biologically inspired standpoint, it seems reinforcement \nlearning is sufficient once you scale it up enough. Of course, there are many \ntechnical challenges with doing that, and many of them are unsolved. \nMARTIN FORD: Still, when a child learns things like language or an understanding of \nthe world, it doesn’t really seem like reinforcement learning for the most part. It’s \nunsupervised learning, as no one’s giving the child labeled data the way we would do \nwith ImageNet. Yet somehow, a young child can learn organically directly from the \nenvironment. But it seems to be more driven by observation or random interaction \nwith the environment rather than learning by practice with a specific goal in mind.\nDEMIS HASSABIS: A child learns with many mechanisms, it’s not like the brain \nonly uses one. The child gets supervised learning from their parents, teachers, or \ntheir peers and they do unsupervised learning when they’re just experimenting \nwith stuff, with no goal in mind. They also do reward learning and reinforcement \nlearning when they do something, and they get a reward for it.\nWe work on all three of those, and they’re all going to be needed for intelligence. \nUnsupervised learning is hugely important, and we’re working on that. The question \nhere is, are there intrinsic motivations that evolution has designed in us that end \nup being proxies for reward, which then guide the unsupervised learning? Just look \nat information gain. There is strong evidence showing that gaining information is \nintrinsically rewarding to your brain.\nAnother thing would be novelty seeking. We know that seeing novel things releases \ndopamine in the brain, so that means novelty is intrinsically rewarding. In a sense, \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 350
  },
  {
    "chunk_full": "DEMIS HASSABIS\n171\nit could be that these intrinsic motivations that we have chemically in our brains \nare guiding what seems to us to be unstructured play or unsupervised learning. If \nthe brain finds finding information and structure rewarding in itself, then that’s a \nhugely useful motivation for unsupervised learning; you’re just going to try and find \nstructure, no matter what, and it seems like the brain is doing that. \nDepending on what you determine as the reward, some of these things could be \nintrinsic rewards that could be guiding the unsupervised learning. I find that it is \nuseful to think about intelligence in the framework of reinforcement learning.\nMARTIN FORD: One thing that’s obvious from listening to you is that you combine a \ndeep interest in both neuroscience and computer science. Is that combined approach \ntrue for DeepMind as a whole? How does the company integrate knowledge and \ntalent from those two areas?\nDEMIS HASSABIS: I’m definitely right in the middle for both those fields, as I’m \nequally trained in both. I would say DeepMind is clearly more skewed towards \nmachine learning; however, our biggest single group here at DeepMind is made up \nof neuroscientists led by Matt Botvinick, an amazing neuroscientist and professor \nfrom Princeton. We take it very seriously. \nThe problem with neuroscience is that it’s a massive field in itself, way bigger \nthan machine learning. If you as a machine-learning person wanted to quickly \nfind out which parts of neuroscience would be useful to you, then you’d be stuck. \nThere’s no book that’s going to tell you that, there’s just a mass of research \nwork, and you’ll have to figure out for yourself how to parse that information \nand find the nuggets that could be useful from an AI perspective. Most of that \nneuroscience research is being undertaken for medical research, psychology, \nor for neuroscience itself. Neuroscientists aren’t designing those experiments \nthinking they would be useful for AI. 99% of that literature is not useful to \nyou as an AI researcher and so you have to get really good at training yourself \nto navigate and pick out what are the right influences and what is the right level \nof influence for each of those. \nQuite a lot of people talk about neuroscience inspiring AI work, but I don’t think a \nlot of them really have concrete ideas on how to do that. Let’s explore two extremes. \nOne is you could try and reverse-engineer the brain, which is what quite a lot of \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 351
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n172\npeople are attempting to do in their approach to AI, and I mean literally reverse-\nengineer the brain on a cortical level, a prime example being the Blue Brain Project.\nMARTIN FORD: That’s being directed by Henry Markram, right?\nDEMIS HASSABIS: Right, and he’s literally trying to reverse-engineer cortical \ncolumns. It may be interesting neuroscience but, in my view, that is not the \nmost efficient path towards building AI because it’s too low-level. What we’re \ninterested in at DeepMind is a systems-level understanding of the brain and the \nalgorithms the brain implements, the capabilities it has, the functions it has, and \nthe representations it uses.\nDeepMind is not looking at the exact specifics of the wetware or how the biology \nactually instantiates it, we can abstract all of that away. That makes sense, because \nwhy would you imagine an in-silico system would have to mimic an in-carbo \nsystem because there are completely different strengths and weaknesses about those \ntwo systems. In silicon, there’s no reason why you would want to copy the exact \npermutation details of, say a hippocampus. On the other hand, I am very interested in \nthe computations and the functions that the hippocampus has, like episodic memory, \nnavigating in space, and the grid cells it uses. These are all systems-level influences \nfrom neuroscience and showcase our interest in the functions, representations and \nthe algorithms that the brain uses, not the exact details of implementation. \nMARTIN FORD: You often hear the analogy that airplanes don’t flap their wings. \nAirplanes achieve flight, but don’t precisely mimic what birds do.\nDEMIS HASSABIS: That’s a great example. At DeepMind, we’re trying to understand \naerodynamics by looking at birds, and then abstracting the principles of aerodynamics \nand building a fixed-wing plane.\nOf course, people who built planes were inspired by birds. The Wright Brothers \nknew that heavier-than-air flight was possible because they’d seen birds. Before the \nairfoil was invented, they tried without success to use deformable wings, but they \nwere more like birds gliding. What you’ve got to do is look at nature, and then \ntry and abstract away the things that are not important for the phenomenon you’re \nafter in that case, flying and in our case, intelligence. But that doesn’t mean that \nthat didn’t help your search process. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 352
  },
  {
    "chunk_full": "DEMIS HASSABIS\n173\nMy point is that you don’t know yet what the outcome looks like. If you’re trying \nto build something artificial like intelligence and it doesn’t work straight away, how \ndo you know that you’re looking in the right place? Is your 20-person team wasting \ntheir time, or should you push a bit harder, and maybe you’ll crack it next year? \nBecause of that, having neuroscience as a guide can allow me to make much bigger, \nmuch stronger bets on things like that.\nA great example of this is reinforcement learning. I know reinforcement learning \nhas to be scalable because the brain does scale it. If you didn’t know that the brain \nimplemented reinforcement learning and it wasn’t scaling, how would you know on \na practical level if you should spend another two years on this? It’s very important \nto narrow down the search space that you’re exploring as a team or a company, and \nI think that’s a meta-point that is often missed by people that ignore neuroscience. \nMARTIN FORD: I think you’ve made the point that the work in AI could also inform \nresearch being done in neuroscience. DeepMind just came out with a result on grid \ncells used in navigation, and it sounds like you’ve got them to emerge organically in \na neural network. In other words, the same basic structure naturally arises in both \nthe biological brain and in artificial neural networks, which seems pretty remarkable.\nDEMIS HASSABIS: I’m very excited about that because it’s one of our biggest \nbreakthroughs in the last year. Edvard Moser and May-Britt Moser, who discovered \ngrid cells and won the Nobel Prize for their work both wrote to us very excited \nabout this finding because it means that, possibly, these grid cells are not just a \nfunction of the wiring of the brain, but actually may be the most optimal way \nof representing space from a computational sense. That’s a huge and important \nfinding for the neuroscientists because what they’re speculating now is that maybe \nthe brain isn’t necessarily hardwired to create grid cells. Perhaps if you have that \nstructure of neurons and you just expose them to space, that is the most efficient \ncoding any system would come up with. \nWe’ve also recently created a whole new theory around how the prefrontal cortex \nmight work, based on looking at our AI algorithms and what they were doing, and \nthen having our neuroscientists translate that into how the brain might work. \nI think that this is the beginning of seeing many more examples of AI ideas and \nalgorithms inspiring us to look at things in a different way in the brain or looking \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 353
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n174\nfor new things in the brain, or as an analysis tool to experiment with our ideas \nabout how we think the brain might work. \nAs a neuroscientist, I think that the journey we’re on of building neuroscience-\ninspired AI is one of the best ways to address some of the complex questions we \nhave about the brain. If we build an AI system that’s based on neuroscience, we can \nthen compare it to the human brain and maybe start gleaning some information \nabout its unique characteristics. We could start shedding light on some of the \nprofound mysteries of the mind like the nature of consciousness, creativity, and \ndreaming. I think that comparing the brain to an algorithmic construct could be a \nway to understand that.\nMARTIN FORD: It sounds like you think there could be some discoverable general \nprinciples of intelligence that are substrate-independent. To return to the flight \nanalogy, you might call it “the aerodynamics of intelligence.”\nDEMIS HASSABIS: That’s right, and if you extract that general principle, then it \nmust be useful for understanding the particular instance of the human brain.\nMARTIN FORD: Can you talk about some of the practical applications that you \nimagine happening within the next 10 years? How are your breakthroughs going \nto be applied in the real world in the relatively near future? \nDEMIS HASSABIS: We’re already seeing lots of things in practice. All over the \nworld people are interacting with AI today through machine translation, image \nanalysis, and computer vision. \nDeepMind has started working on quite a few things, like optimizing the energy \nbeing used in Google’s data centers. We’ve worked on WaveNet, the very human-like \ntext-to-speech system that’s now in the Google Assistant in all Android-powered \nphones. We use AI in recommendation systems, in Google Play, and even on behind-\nthe-scenes elements like saving battery life on your Android phone. Things that \neveryone uses every single day. We’re finding that because they’re general algorithms, \nthey’re coming up all over the place, so I think that’s just the beginning. \nWhat I’m hoping will come through next are the collaborations we have in \nhealthcare. An example of this is our work with the famous UK eye hospital, \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 354
  },
  {
    "chunk_full": "DEMIS HASSABIS\n175\nMoorfields, where we’re looking at diagnosing macular degeneration from your \nretina scans. We published the results from the first phase of our joint research \npartnership in Nature Medicine, and they show that our AI system can quickly \ninterpret eye scans from routine clinical practice with unprecedented accuracy. It \ncan also correctly recommend how patients should be referred for treatment for \nover 50 sight-threatening eye diseases as accurately as world-leading expert doctors.\nThere are other teams doing similar work for diseases like skin cancer. Over the \nnext five years, I think healthcare will be one of the biggest areas to see a benefit \nfrom the work we’re all doing in the field.\nWhat I’m really personally excited about, and this is something I think we’re on \nthe cusp of, is using AI to actually help with scientific problems. We’re working \non things like protein folding, but you can imagine its use in material design, drug \ndiscovery and chemistry. People are using AI to analyze data from the Large Hadron \nCollider to searching for exoplanets. There’s a lot of really cool areas of masses of \ndata that we as human experts find hard to identify the structure in that I think this \nkind of AI is going to become increasingly used for. I’m hoping that over the next \n10 years this will result in an advancement in the speed of scientific breakthroughs \nin some really fundamental areas.\nMARTIN FORD: What does the path to AGI look like? What would you say are \nthe main hurdles that will have to be surmounted before we have human-level AI?\nDEMIS HASSABIS: From the beginning of DeepMind we identified some big \nmilestones, such as the learning of abstract, conceptual knowledge, and then using \nthat for transfer learning. Transfer learning is where you usefully transfer your \nknowledge from one domain to a new domain that you’ve never seen before, it’s \nsomething humans are amazing at. If you give me a new task, I won’t be terrible at \nit out of the box because I’ll bring some knowledge from similar things or structural \nthings, and I can start dealing with it straight away. That’s something that computer \nsystems are pretty terrible at because they require lots of data and they’re very \ninefficient. We need to improve that.\nAnother milestone is that we need to get better at language understanding, and \nanother is replicating things that old AI systems were able to do, like symbolic \nmanipulation, but using our new techniques. We’re a long way from all of those, but \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 355
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n176\nthey would be really big milestones if they were to happen. If you look at where \nwe were in 2010, just eight years ago, we’ve already achieved some big things that \nwere milestones to us, like AlphaGo, but there are more to come. So those would \nbe the big ones for me, concepts and transfer learning.\nMARTIN FORD: When we do achieve AGI, do you imagine intelligence being \ncoupled with consciousness? Is it something that would automatically emerge, or is \nconsciousness a completely separate thing?\nDEMIS HASSABIS: That’s one of the interesting questions that this journey will \naddress. I don’t know the answer to it at the moment, but that’s one of the very \nexciting things about the work that both we and others are doing in this field. \nMy hunch currently would be that consciousness and intelligence are double-\ndissociable. You can have intelligence without consciousness, and you can have \nconsciousness without human-level intelligence. I’m pretty sure smart animals \nhave some level of consciousness and self-awareness, but they’re obviously not \nthat intelligent at least compared to humans, and I can imagine building machines \nthat are phenomenally intelligent by some measures but would not feel conscious \nto us in any way at all. \nMARTIN FORD: Like an intelligent zombie, something that has no inner experience. \nDEMIS HASSABIS: Something that wouldn’t feel sentient in the way we feel about \nother humans. Now that’s a philosophical question, because the problem is, as we \nsee with the Turing test, how would we know if it was behaving in the same way \nas we were? The Occam’s razor explanation is to say that if you’re exhibiting the \nsame behavior as I exhibit, and you’re made from the same stuff as I’m made from, \nand I know what I feel, then I can assume you’re feeling the same thing as me. \nWhy would you not? \nWhat’s interesting with a machine is that they could exhibit the same behavior \nas a human, if we designed them like that, but they’re on a different substrate. \nIf you’re not on the same substrate then that Occam’s razor idea doesn’t hold \nas strongly. It may be that they are conscious in some sense, but we don’t feel \nit in the same way because we don’t have that additional assumption to rely on. \nIf you break down why we think each of us is conscious, I think that’s a very \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 356
  },
  {
    "chunk_full": "DEMIS HASSABIS\n177\nimportant assumption, if you’re operating on the same substrate as me, why \nwould it feel different to your substrate?\nMARTIN FORD: Do you believe machine consciousness is possible? There are some \npeople that argue consciousness is fundamentally a biological phenomenon.\nDEMIS HASSABIS: I am actually open-minded about that, in the sense that I don’t \nthink we know. It could well turn out that there’s something very special about \nbiological systems. There are people like Sir Roger Penrose that think it’s to do \nwith quantum consciousness, in which case a classical computer wouldn’t have it, \nbut it’s an open question. That’s why I think the path we’re on will shed some light \non it because I actually think we don’t know whether that’s a limit or not. Either \nway, it will be fascinating because it would be pretty amazing if it turned out that \nyou couldn’t build consciousness at all on a machine. That would tell us a lot about \nwhat consciousness is and where it resides.\nMARTIN FORD: What about the risks and the downsides associated with AGI? Elon \nMusk has talked about “raising the demon” and an existential threat. There’s also \nNick Bostrom, who I know is on DeepMind’s advisory board and has written a lot \non this idea. What do you think about these fears? Should we be worried?\nDEMIS HASSABIS: I’ve talked to them a lot about these things. As always, the \nsoundbites seem extreme but it’s a lot more nuanced when you talk to any of \nthese people in person. \nMy view on it is that I’m in the middle. The reason I work on AI is because \nI think it’s going to be the most beneficial thing to humanity ever. I think it’s \ngoing to unlock our potential within science and medicine in all sorts of ways. \nAs with any powerful technology, and AI could be especially powerful because \nit’s so general, the technology itself is neutral. It depends on how we as humans \ndecide to design and deploy it, what we decide to use it for, and how we decide \nto distribute the gains. \nThere are a lot of complications there, but those are more like geopolitical issues \nthat we need to solve as a society. A lot of what Nick Bostrom worries about \nare the technical questions we have to get right, such as the control problem \nand the value alignment problem. My view is that on those issues we do need a \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 357
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n178\nlot more research because we’ve only just got to the point now where there are \nsystems that can even do anything interesting at all. \nWe’re still at a very nascent stage. Five years ago, you might as well have been \ntalking about philosophy because no one had anything that was interesting. We’ve \nnow got AlphaGo and a few other interesting technologies that are still very nascent, \nbut we’re now at the point where we should start reverse-engineering those things \nand experimenting on them by building visualization and analysis tools. We’ve got \nteams doing this to better understand what these black-box systems are doing and \nhow we interpret their behavior. \nMARTIN FORD: Are you confident that we’ll be able to manage the risks that come \nalong with advanced AI?\nDEMIS HASSABIS: Yes, I’m very confident, and the reason is that we’re at the \ninflection point where we’ve just got these things working, and not that much effort \nhas yet gone into reverse engineering them and understanding them, and that’s \nhappening now. Over the next decade, most of these systems won’t be black-box \nin the sense that we mean now. We’ll have a good handle on what’s going on with \nthese systems, and that will lead to a better understanding of how to control the \nsystems and what their limits are mathematically, and then that could lead into best \npractices and protocols. \nI’m pretty confident that path will address a lot of the technical issues that people \nlike Nick Bostrom are worried about, like the collateral consequences of goals not \nbeing set correctly. To make advances in that, my view has always been that the best \nscience occurs when theory and practice—empirical work—go hand in hand, and \nfor this subject and field, empirical work experiments are engineering.\nA lot of the fears that some of the people not working at the coalface of this \ntechnology have won’t hold once we actually have a much better understanding of \nthese systems. That’s not to say that I think that there’s nothing to worry about, \nbecause I think we should worry about these things. There are plenty of near-term \nquestions to resolve as well—like how do we test these systems as we deploy \nthem in products? Some of the long-term problems are so hard that we want to \nbe thinking about them in the time we have right now, well ahead of when we’re \ngoing to need the answers. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 358
  },
  {
    "chunk_full": "DEMIS HASSABIS\n179\nWe also need to be able to inform the research that has to be done to come up \nwith the solutions to some of those questions that are posed by people like Nick \nBostrom. We are actively thinking about these problems and we’re taking them \nseriously, but I’m a big believer in human ingenuity to overcome those problems if \nyou put enough brainpower on it collectively around the world. \nMARTIN FORD: What about the risks that will arise long before AGI is achieved? \nFor example, autonomous weapons. I know you’ve been very outspoken about AI \nbeing used in military applications.\nDEMIS HASSABIS: These are very important questions. At DeepMind, we start from \nthe premise that AI applications should remain under meaningful human control, and \nbe used for socially beneficial purposes. This means banning the development and \ndeployment of fully autonomous weapons, since it requires a meaningful level of human \njudgment and control to ensure that weapons are used in ways that are necessary and \nproportionate. We’ve expressed this view in a number of ways, including signing an \nopen letter and supporting the Future of Life Institute’s pledge on the subject. \nMARTIN FORD: It’s worth pointing out even though chemical weapons are in \nfact banned, they have still been used. All of this requires global coordination \nand it seems that rivalries between countries could push things in the other \ndirection. For example, there is a perceived AI race with China. They do have \na much more authoritarian system of government. Should we worry that they \nwill gain an advantage in AI?\nDEMIS HASSABIS: I don’t think it’s a race in that sense because we know all \nthe researchers and there’s a lot of collaboration. We publish papers openly and \nI know that for example Tencent has created an AlphaGo clone, so I know many \nof the researchers there. I do think that if there’s going to be coordination and \nperhaps even regulation and best practices down the road, it’s important that it’s \ninternational and the whole world adopts that. It doesn’t work if some countries \ndon’t adopt those principles. However, that’s not an issue that’s unique to AI. There \nare many other problems that we’re already grappling with that are a question \nof global coordination and organization—the obvious one being climate change.\nMARTIN FORD: What about the economic impact of all of this? Is there going to be \na big disruption of the job market and perhaps rising unemployment and inequality? \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 359
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n180\nDEMIS HASSABIS: I think there’s been very minimal disruption so far from AI, it’s \njust been part of the technology disruption in general. AI is going to be hugely \ntransformative, though. Some people believe that it’s going to be on the scale of \nthe Industrial Revolution or electricity, while other people believe it’s going to \nbe a class of its own above that, and that’s something I think that remains to be \nseen. Maybe it will mean we’re in a world of abundance, where there are huge \nproductivity gains everywhere? Nobody knows for sure. The key thing is to make \nsure those benefits are shared with everyone.\nI think that’s the key thing, whether that’s universal basic income, or it’s done in some \nother form. There are lots of economists debating these things, and we need to think \nvery carefully about how everyone in society will benefit from those presumably huge \nproductivity gains, which must be coming in, otherwise it wouldn’t be so disruptive. \nMARTIN FORD: Yes, that’s basically the argument that I’ve been making, that it’s \nfundamentally a distributional problem and that a large part of our population is \nin danger of being left behind. But it is a staggering political challenge to come up \nwith a new paradigm that will create an economy that works for everyone.\nDEMIS HASSABIS: Right.\nWhenever I meet an economist, I think they should be working quite hard on \nthis problem, but it’s difficult to because they can’t really envisage how it could \nbe so productive because people have been talking about massive productivity \ngains for 100 years. \nMy dad studied economics at university, and he was saying that in the late 1960s a \nlot of people were seriously talking about that: “What is everyone going to do in the \n1980s when we have so much abundance, and we don’t have to work?” That, of course, \nnever happened, in the 1980s or since then, and we’re working harder than ever. I \nthink a lot of people are not sure if it’s ever going to be like that, but if it does end \nup that we have a lot of extra resources and productivity, then we’ve got to distribute \nit widely and equitably, and I think if we do that, then I don’t see a problem with it.\nMARTIN FORD: Is it safe to say that you’re an optimist? I’d guess that you see AI as \ntransformative and that it’s arguably going to be one of the best things that’s ever \nhappened to humanity. Assuming, of course, that we manage it wisely?\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 360
  },
  {
    "chunk_full": "DEMIS HASSABIS\n181\nDEMIS HASSABIS: Definitely, and that’s why I’ve worked towards it my whole life. \nAll of the things I’ve been doing that we covered in the first part of our discussion \nhave been building towards achieving that. I would be quite pessimistic about the \nway the world’s going, if AI was not going to come along. I actually think there’s \na lot of problems in the world that require better solutions, like climate change, \nAlzheimer’s research or water purification. I can give you a list of things that are \ngoing to get worse over time. What is a worry is that I don’t see how we’re going \nto get the global coordination and the excess resources or activity to solve them. \nBut ultimately, I’m actually optimistic about the world because a transformative \ntechnology like AI is coming.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 361
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n182\nDEMIS HASSABIS is a former child chess prodigy who finished his high school exams two \nyears early before coding the multi-million selling simulation game Theme Park at age \n17. Following graduation from Cambridge University with a Double First in Computer \nScience he founded the pioneering videogames company Elixir Studios producing award \nwinning games for global publishers such as Vivendi Universal. After a decade of experience \nleading successful technology startups, Demis returned to academia to complete a PhD in \ncognitive neuroscience at University College London, followed by postdoctoral research at \nMIT and Harvard. His research into the neural mechanisms underlying imagination and \nplanning was listed in the top ten scientific breakthroughs of 2007 by the journal Science. \nDemis is a five-time World Games Champion, and a Fellow of the Royal Society of Arts \nand the Royal Academy of Engineering, winning the Academy’s Silver Medal. In 2017 he \nwas named in the Time 100 list of the world’s most influential people, and in 2018 was \nawarded a CBE for services to science and technology. He was elected as a Fellow of the \nRoyal Society, has been a recipient of the Society’s Mullard Award, and was also awarded \nan Honorary Doctorate by Imperial College London.\nDemis co-founded DeepMind along with Shane Legg and Mustafa Suleyman in 2010. \nDeepMind was acquired by Google in 2014 and is now part of Alphabet. In 2016 \nDeepMind’s AlphaGo system defeated Lee Sedol, arguably the world’s best player of \nthe ancient game of Go. That match is chronicled in the documentary film AlphaGo \n(https://www.alphagomovie.com/).\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 362
  },
  {
    "chunk_full": "DEMIS HASSABIS\n183\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 363
  },
  {
    "chunk_full": "",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 364
  },
  {
    "chunk_full": "ANDREW NG\n185\nANDREW NG \nCEO, LANDING AI & GENERAL PARTNER, AI FUND \nADJUNCT PROFESSOR COMPUTER SCIENCE, STANFORD\nAndrew Ng is widely recognized for his contributions to artificial intelligence \nand deep learning, as both an academic researcher and an entrepreneur. He \nco-founded both the Google Brain project and the online education company, \nCoursera. He then became the chief scientist at Baidu, where he built an \nindustry-leading AI research group. Andrew played a major role in the \ntransformation of both Google and Baidu into AI-driven organizations. In 2018 \nhe established AI Fund, a venture capital firm focused on building startup \ncompanies in the AI space from scratch. \nThe rise of supervised learning has created a lot  \nof opportunities in probably every major industry.  \nSupervised learning is incredibly valuable and will  \ntransform multiple industries, but I think there is  \na lot of room for something even better to be invented. \n“ \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 365
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n186\nMARTIN FORD: Let’s start by talking about the future of AI. There’s been remarkable \nsuccess, but also enormous hype, associated with deep learning. Do you feel that \ndeep learning is the way forward and—the primary idea that will continue to \nunderlie progress in AI? Or is it possible that an entirely new approach will replace \nit in the long run?\nANDREW NG: I really hope there’s something else out there better than deep \nlearning. All of the economic value driven by this recent rise of AI is down to \nsupervised learning—basically learning input and output mappings. For example, \nwith self-driving cars the input is a video picture of what’s in front of your \ncar, and the output is the actual position of the other cars. There are other \nexamples, speech recognition has an input of an audio clip and an output of a \ntext transcript, machine translation has an input of English text and an output \nof Chinese text, say. \nDeep learning is incredibly effective for learning these input/output mappings \nand this is called supervised learning, but I think that artificial intelligence is \nmuch bigger than supervised learning. \nThe rise of supervised learning has created a lot of opportunities in probably \nevery major industry. Supervised learning is incredibly valuable and will \ntransform multiple industries, but I think that there is a lot of room for \nsomething even better to be invented. It’s hard to say right now exactly what \nthat would be, though.\nMARTIN FORD: What about the path to artificial general intelligence? What would \nyou say are the primary breakthroughs that have to occur for us to get to AGI?\nANDREW NG: I think the path is very unclear. One of the things we will \nprobably need is unsupervised learning. For example, today in order to teach \na computer what a coffee mug is we show it thousands of coffee mugs, but no \nchild’s parents, no matter how patient and loving, ever pointed out thousands of \ncoffee mugs to that child. The way that children learn is by wandering around \nthe world and soaking in images and audio. The experience of being a child \nallows them to learn what a coffee mug is. The ability to learn from unlabeled \ndata, without parents or labelers pointing out thousands of coffee mugs, will be \ncrucial to making our systems more intelligent. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 366
  },
  {
    "chunk_full": "ANDREW NG\n187\nI think one of the problems in AI is that we’ve made a lot of progress in building \nspecialized intelligence or narrow intelligence, and very little progress towards AGI. \nThe problem is, both of these things are called AI. AI turns out to be incredibly \nvaluable for online advertising, speech recognition and self-driving cars, but it’s \nspecialized intelligence, not general. Much of what the public sees is progress in \nbuilding specialized intelligence and they think that we are therefore making rapid \nprogress toward artificial general intelligence. It’s just not true. \nI would love to get to AGI, but the path is very unclear. I think that individuals \nthat are less knowledgeable about AI have used very simplistic extrapolations, and \nthat has led to unnecessary amounts of hype about AI.\nMARTIN FORD: Do you expect AGI to be achieved in your lifetime?\nANDREW NG: The honest answer is that I really don’t know. I would love to see \nAGI in my lifetime, but I think there’s a good chance it’ll be further out than that. \nMARTIN FORD: How did you become interested in AI? And how did that lead to \nsuch a varied career trajectory?\nANDREW NG: My first encounter with neural networks was when I was in high \nschool where I did an office assistant internship. There may not seem like an \nobvious link between an internship and neural networks, but during the course of \nmy internship I thought about how we could automate some of the work that I \nwas doing, and that was the earliest time I was thinking about neural networks. I \nwound up doing my bachelor’s at Carnegie Mellon, my master’s from MIT and a \nPhD, with a thesis titled, Shaping and Policy Search in Reinforcement Learning, from \nthe University of California, Berkeley. \nFor about the next twelve years I taught at the Stanford University Department \nof Computer Science and the Department of Electrical Engineering as a \nprofessor. Then between 2011 and 2012, I was a founding member of the Google \nBrain team, which helped transform Google into the AI company that we now \nperceive it to be. \nMARTIN FORD: And Google Brain was the first attempt to really use deep learning \nat Google, correct?\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 367
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n188\nANDREW NG: To an extent. There had been some small-scale projects based \naround neural networks, but the Google Brain team really was the force that took \ndeep learning into many parts of Google. The first thing I did when I was leading \nthe Brain team was to teach a class within Google for around 100 engineers. This \nhelped teach a lot of Google engineers about deep learning, and it created a lot \nof allies and partners for the Google Brain team and opened up deep learning \nto a lot more people. \nThe first two projects we did were partnering with the speech team, which I think \nhelped transform speech recognition at Google, and working on unsupervised \nlearning, which led to the somewhat infamous Google cat. This is where we set \nan unsupervised neural network free on YouTube data and it learned to recognize \ncats. Unsupervised learning isn’t what actually creates the most value today, but \nthat was a nice technology demonstration of the type of scale we could achieve \nusing Google’s compute cluster at the time. We were able to do very large-scale \ndeep learning algorithms.\nMARTIN FORD: You stayed at Google until 2012. What came next for you?\nANDREW NG: Towards the end of my time at Google, I felt that deep learning \nshould move toward GPUs. As a result, I wound up doing that work at Stanford \nUniversity rather than at Google. In fact, I remember a conversation that I had with \nGeoff Hinton at NIPS, the annual conference on Neural Information Processing \nSystems, where I was trying to use GPUs, and I think that later influenced his \nwork with Alex Krizhevsky and influenced, quite a lot of people to then adopt \nGPUs for deep learning. \nI was lucky to be teaching at Stanford at the time because being here in Silicon \nValley, we saw the signals that GPGPU (general-purpose GPU) computing was \ncoming. We were in the right place at the right time and we had friends at Stanford \nworking on GPGPUs, so we saw the ability of GPUs to help scale up deep learning \nalgorithms earlier than almost everyone else. \nMy former student at Stanford, Adam Coates was actually the reason I decided to \npitch the Google Brain team to Larry Page in a bid to get Larry to approve me \nusing a lot of their computers to build a very large neural network. It was really \none figure that was generated by Adam Coates, where the x-axis was the amount \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 368
  },
  {
    "chunk_full": "ANDREW NG\n189\nof data, and the y-axis was the performance of an algorithm. Adam generated this \nfigure showing that the more data we could train these deep learning algorithms \non, the better they’d perform. \nMARTIN FORD: After that you went on to start Coursera with Daphne Koller, who \nis also interviewed in this book. Then you moved on to Baidu. Can you describe \nyour path through those roles? \nANDREW NG: Yes, I helped to start Coursera with Daphne because I wanted to \nscale online teaching both around AI and other things to millions of people around \nthe world. I felt that the Google Brain team already had tremendous momentum \nat that point, so I was very happy to hand the reins over to Jeff Dean and move \non to Coursera. I worked at building Coursera from the ground up for a couple of \nyears until 2014 when I stepped away from my day-to-day work there to go and \nwork at Baidu’s AI Group. Just as Google Brain helped transform Google into the \nAI company you perceive it to be today, the Baidu AI group did a lot of work to \ntransform Baidu into the AI company that a lot of people now perceive Baidu to \nbe. At Baidu, I built a team that built technology, supported existing business units, \nand then systematically initiated new businesses using AI. \nAfter three years there the team was running very well, so I decided to move on \nagain this time becoming the CEO of Landing AI and a general partner at AI Fund. \nMARTIN FORD: You’ve been instrumental in transforming both Google and Baidu \ninto AI-driven companies, and it sounds like now you want to scale that out and \ntransform everything else. Is that your vision for AI Fund and Landing AI? \nANDREW NG: Yes, I’m done transforming large web search engines, and now I’d \nrather go and transform some other industries. At Landing AI, I help to transform \ncompanies using AI. There are a lot of opportunities in AI for incumbent companies, \nso Landing AI is focused on helping those companies that already exist to transform \nand embrace those AI opportunities. AI Fund takes this a step further, looking at \nthe opportunities for new startups and new businesses to be created from scratch \nbuilt around AI technologies. \nThese are very different models with different opportunities. For example, \nif you look at the recent major technological transformation of the internet, \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 369
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n190\nincumbent companies like Apple and Microsoft did a great job transforming \nthemselves to be internet companies. However, you only have to look at how \nbig the “startups,” like Google, Amazon, Baidu, and Facebook are now and how \nthey did such a great job building incredibly valuable businesses based on the \nrise of the internet.\nWith the rise of AI there will also be some incumbent companies, ironically many \nof them were startups in the previous age, like Google, Amazon, Facebook, and \nBaidu, that’ll do very well with the rise of AI. AI Fund is trying to create the new \nstartup companies that leverage these new AI capabilities we have. We want to find \nor create the next Google or Facebook.\nMARTIN FORD: There are a lot of people who say that the incumbents like Google \nand Baidu are essentially unshakable because they have access to so much data, and \nthat creates a barrier to entry for smaller companies. Do you think startups and \nsmaller companies are going to struggle to get traction in the AI space? \nANDREW NG: That data asset that the large search engines have definitely creates \na highly defensible barrier to the web search business, but at the same time, it’s \nnot obvious how web search clickstream data is useful for medical diagnosis or for \nmanufacturing or for personalized educational tutors, for example. \nI think data is actually verticalized, so building a defensible business in one \nvertical can be done with a lot of data from that vertical. Just as electricity \ntransformed multiple industries 100 years ago, AI will transform multiple \nindustries, and I think that there is plenty of room for multiple companies to \nbe very successful.\nMARTIN FORD: You mentioned AI Fund, which you founded recently and which I \nthink operates differently from other venture capital funds. What is your vision for \nAI Fund, and how is it unique? \nANDREW NG: Yes. AI Fund is extremely different from most venture capital funds, \nand I think most venture capital funds are in the business of trying to identify \nwinners, while we’re in the business of creating winners. We build startups from \nscratch, and we tell entrepreneurs that if you already have a pitch deck, you’re \nprobably at too late a stage for us. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 370
  },
  {
    "chunk_full": "ANDREW NG\n191\nWe bring in teams as employees and work with them, mentor them, and support \nthem, whatever is needed to try and build a successful startup from scratch. We \nactually tell people that if you’re interested in working with us, don’t send us a pitch \ndeck, send us a resume and then we’ll work together to flesh out the startup idea.\nMARTIN FORD: Do most people that come to you already have an idea, or do you \nhelp them come up with something? \nANDREW NG: If they have an idea we’re happy to talk about it, but my team has \na long list of ideas that we think are promising but we don’t have the bandwidth \nto invest in. When people join us, we’re very happy to share this long list of ideas \nwith them to see which ones fit.\nMARTIN FORD: It sounds like your strategy is to attract AI talent in part by offering \nthe opportunity and infrastructure to found a startup venture.\nANDREW NG: Yes, building a successful AI company takes more than AI talent. We \nfocus so much on the technology because it’s advancing so quickly, but building a \nstrong AI team often needs a portfolio of different skills ranging from the tech, \nto the business strategy, to product, to marketing, to business development. Our \nrole is building full stack teams that are able to build concrete business verticals. \nThe technology is super important, but a startup is much more than technology. \nMARTIN FORD: So far, it seems that any AI startup that demonstrates real potential \ngets acquired by one of the huge tech firms. Do you think that eventually there’ll \nbe AI startups that will go on to have IPOs and become public companies?\nANDREW NG: I really hope there’ll be plenty of great AI startups that are not \njust acquired by much larger startups. Initial public offering as a tactic is not the \ngoal, but I certainly hope that there’ll be many very successful AI startups that \nwill end up thriving as standalone entities for a long time. We don’t really have \na financial goal; the goal is to do something good in the world. I’d be really \nsad if every AI startup ends up being acquired by a bigger company, and I don’t \nthink we’re headed there.\nMARTIN FORD: Lately, I’ve heard a number of people express the view that deep \nlearning is over-hyped and might soon “hit a wall” in terms of continued progress. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 371
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n192\nThere have even been suggestions that a new AI Winter could be on the horizon. Do \nyou think that’s a real risk? Could disillusionment lead to a big drop off in investment? \nANDREW NG: No, I don’t think there’ll be another AI winter, but I do think there \nneeds to be a reset of expectations about AGI. In the earlier AI winters, there \nwas a lot of hype about technologies that ultimately did not really deliver. The \ntechnologies that were hyped were really not that useful, and the amount of value \ncreated by those earlier generations of technology was vastly less than expected. \nI think that’s what caused the AI winters. \nIn the current era, if you look at the number of people actually working on deep \nlearning projects to date, it’s much greater than six months ago, and six months ago, \nit was much greater than six months before that. The number of concrete projects in \ndeep learning, the number of people researching it, the number of people learning \nit, and the number of companies being built on it means the amount of revenue \nbeing generated is actually growing very strongly. \nThe fundamentals of the economics support continued investment in deep learning. \nLarge companies are continuing to back deep learning strongly, and it’s not based \non just hopes and dreams, it’s based on the results we’re already seeing. That will \nsee confidence continue to grow. Now, I do think we need to reset the expectations \nabout AI as a whole, and AGI in particular. I think the rise of deep learning was \nunfortunately coupled with false hopes and dreams of a sure path to achieving AGI, \nand I think that resetting everyone’s expectations about that would be very helpful. \nMARTIN FORD: So, aside from unrealistic expectations about AGI, do you think \nwe will continue to see consistent progress with the use of deep learning in \nmore narrow applications? \nANDREW NG: I think there are a lot of limitations to the current generation of \nAI. AI is a broad category, though, and I think when people discuss AI, what they \nreally mean is the specific toolset of backpropagation, supervised learning, and \nneural networks. That is the most common piece of deep learning that people \nare working on right now.\nOf course, deep learning is limited, just like the internet is limited, and electricity \nis limited. Just because we invented electricity as a utility, it didn’t suddenly solve \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 372
  },
  {
    "chunk_full": "ANDREW NG\n193\nall of the problems of humanity. In the same way, backpropagation will not solve \nall the problems of humanity, but it is turning out to be incredibly valuable, and \nwe’re nowhere near done building out all the things we could do with neural \nnetworks trained by backpropagation. We’re just in the early phases of figuring \nout the implications of even the current generation of technology.\nSometimes, when I’m giving a talk about AI, the first thing I say is “AI is not \nmagic, it can’t do everything.” I think it’s very strange that we live in a world \nwhere anyone even has to say sentences like that—that there’s a technology that \ncannot do everything. \nThe huge problem that AI has had is what I call the communications problem. \nThere’s been tremendous progress in narrow artificial intelligence and also real \nprogress in artificial general intelligence, but both of these things are called AI. So, \ntremendous progress in economics and value through narrow artificial intelligence \nis rightly causing people to see that there’s tremendous progress in AI, but it’s also \ncausing people to falsely reason that there’s tremendous progress in AGI as well. \nFrankly, I do not see much progress. Other than having faster computers and data, \nand progress at a very general level, I do not see specific progress toward AGI. \nMARTIN FORD: There seem to be two general camps with regard to the future of \nAI. Some people believe it will be neural networks all the way, while others think \na hybrid approach that incorporates ideas from other areas, for example symbolic \nlogic, will be required to achieve continued progress. What’s your view? \nANDREW NG: I think it depends on whether you’re talking short term or long \nterm. At Landing AI we use hybrids all the time to build solutions for industrial \npartners. There’s often a hybrid of deep learning tools together with, say, traditional \ncomputer vision tools because when your datasets are small, deep learning by itself \nisn’t always the best tool. Part of the skill of being an AI person is knowing when \nto use a hybrid and how to put everything together. That’s how we deliver tons of \nshort-term useful applications.\nOn balance, there’s been a shift from traditional tools toward deep learning, \nespecially when you have a lot of data, but there are still plenty of problems in \nthe world where you have only small datasets, and then the skill is in designing the \nhybrid and getting the right mix of techniques. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 373
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n194\nI think in the long term, if we ever move toward more human-level intelligence, \nmaybe not for AGI but more flexible learning algorithms, I think that we’ll continue \nto see a shift toward neural networks, but one of the most exciting things yet to \nbe invented will be other algorithms that are much better than backpropagation. \nJust like alternating current power is incredibly limited, but also incredibly useful, \nI think backpropagation is also incredibly limited, but incredibly useful, and I don’t \nsee any contradiction in those circumstances.\nMARTIN FORD: So, as far as you’re concerned, neural networks are clearly the best \ntechnology to take AI forward? \nANDREW NG: I think that for the foreseeable future, neural networks will have \na very central place in the AI world. I don’t see any candidates on the horizon \nfor replacing neural networks, that’s not to say that there won’t be something on \nthe horizon in the future.\nMARTIN FORD: I recently spoke with Judea Pearl, and he believes very strongly \nthat AI needs a causal model in order to progress and that current AI research isn’t \ngiving enough attention to that. How would you respond to that view? \nANDREW NG: There are hundreds of different things that deep learning doesn’t do, \nand causality is one of them. There are other things, such as not doing explainability \nwell enough; we need to sort out how to defend against adversarial attacks; we need \nto get a lot better at learning from small datasets rather than big datasets; we need \nto get much better at transfer or multitask learning; we need to figure out how \nto use unlabeled data better. So yes, there are a lot of things that backpropagation \ndoesn’t do well, and again causality is one of them. When I look at the amount \nof high value projects being created, I don’t see causality as a hindering factor in \nthem, but of course we’d love to make progress there. We’d love to make progress \nin all of those things I mentioned.\nMARTIN FORD: You mentioned adversarial attacks. I’ve seen research indicating that \nit is fairly easy to trick deep learning networks using manufactured data. Is that \ngoing to be a big problem as this technology becomes more prevalent?\nANDREW NG: I think it is already a problem, especially in anti-fraud. When I \nwas head of the Baidu AI team we were constantly fighting against fraudsters both \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 374
  },
  {
    "chunk_full": "ANDREW NG\n195\nattacking AI systems and using AI tools to commit fraud. This is not a futuristic \nthing. I’m not fighting that war right now, because I’m not leading an anti-fraud \nteam, but I have led teams and you feel very adversarial and very zero-sum when \nyou’re fighting against fraud. The fraudsters are very smart and very sophisticated, \nand just as we think multiple steps ahead, they think multiple steps ahead. As the \ntechnology evolves, the attacks and the defenses will both have to evolve. This is \nsomething that those of us shipping products in the AI community have been dealing \nwith for a few years already.\nMARTIN FORD: What about privacy issues? In China especially, facial recognition \ntechnology is becoming ubiquitous. Do you think we run the risk that AI is going \nto be deployed to create an Orwellian surveillance state?\nANDREW NG: I’m not an expert on that, so I’ll defer to others. One thing that I \nwould say, is that one trend we see with many rises in technology is the potential \nfor greater concentration of power. I think this is true of the internet, and this is \ntrue again with the rise of AI. It becomes possible for smaller and smaller groups \nto be more and more powerful. The concentration of power can happen at the \nlevel of corporations, where corporations with relatively few employees can have \na bigger influence, or at the level of governments. \nThe technology available to small groups is more powerful than ever before. For \nexample, one of the risks of AI that we have already seen is the ability of a small \ngroup to influence the way very large numbers of people vote, and the implications \nof that on democracy is something that we need to pay close attention to, to \nmake sure that democracy is able to defend itself so that votes are truly fair and \nrepresentative of the interests of the population. What we saw in the recent US \nelection was based more on internet technologies rather than AI technologies, but \nthe opportunity is there. Before that, television had a huge effect on democracy and \nhow people voted. As technology evolves, the nature and texture of governance and \ndemocracy changes, which is why we have to constantly refresh our commitment \nto protecting society from its abuse.\nMARTIN FORD: Let’s talk about one of the highest-profile applications of AI: self-\ndriving cars. How far off are they really? Imagine you’re in a city and you’re going to \ncall for a fully autonomous car that will take you from one random location to another. \nWhat’s the time frame for when you think that becomes a widely available service?\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 375
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n196\nANDREW NG: I think that self-driving cars in geofenced regions will come relatively \nsoon, possibly by the end of this year, but that self-driving cars in more general \ncircumstances will be a long way off, possibly multiple decades.\nMARTIN FORD: By geofenced, you mean autonomous cars that are running \nessentially on virtual trolley tracks, or in other words only on routes that have \nbeen intensively mapped? \nANDREW NG: Exactly! A while back I co-authored a Wired article talking about \nTrain Terrain1 about how I think self-driving cars might roll out. We’ll need \ninfrastructure changes, and societal and legal changes, before we’ll see mass \nadoption of self-driving cars.\nI have been fortunate to have seen the self-driving industry evolve for over 20 years \nnow. As an undergraduate at Carnegie Mellon in the late ‘90s, I did a class with Dean \nPomerleau working on their autonomous car project that steered the vehicle based \nan input video image. The technology was great, but it wasn’t ready for its time. \nThen at Stanford, I was a peripheral part of the DARPA Urban Challenge in 2007. \nWe flew down to Victorville, and it was the first time I saw so many self-driving \ncars in the same place. The whole Stanford team were all fascinated for the first \nfive minutes, watching all these cars zip around without drivers, and the surprising \nthing was that after five minutes, we acclimatized to it, and we turned our backs \nto it. We just chatted with each other while self-driving cars zipped passed us 10 \nmeters away, and we weren’t paying attention. One thing that’s remarkable about \nhumanity is how quickly we acclimatize to new technologies, and I feel that it’s \nnot going to be too long before self-driving cars are no longer called self-driving \ncars, they’re just called cars. \nMARTIN FORD: I know you’re on the board of directors of the self-driving car \ncompany Drive.ai. Do you have an estimate for when their technology will be \nin general use?\nANDREW NG: They’re driving round in Texas right now. Let’s see, what time \nis it? Someone’s just taken one and gone for lunch. The important thing is how \n1 https://www.wired.com/2016/03/self-driving-cars-wont-work-change-roads-attitudes/\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 376
  },
  {
    "chunk_full": "ANDREW NG\n197\nmundane that is. Someone’s just gone out for lunch, like any normal day, and \nthey’ve done it by getting in a self-driving car.\nMARTIN FORD: How do you feel about the progress you’ve seen in self-driving \ncars so far? How has it compared with your expectations? \nANDREW NG: I don’t like hype, and I feel like a few companies have spoken publicly \nand described what I think of as unrealistic timelines about the adoption of self-\ndriving cars. I think that self-driving cars will change transportation, and will make \nhuman life much better. However, I think that everyone having a realistic roadmap \nto self-driving cars is much better than having CEOs stand on stage and proclaim \nunrealistic timelines. I think the self-driving world is working toward more realistic \nprograms for bringing the tech to market, and I think that’s a very good thing.\nMARTIN FORD: How do you feel about the role of government regulation, both \nfor self-driving cars and AI more generally? \nANDREW NG: The automotive industry has always been heavily regulated because \nof safety, and I think that the regulation of transportation needs to be rethought \nin light of AI and self-driving cars. Countries with more thoughtful regulation \nwill advance faster to embrace the possibilities enabled by, for example, AI-driven \nhealthcare systems, self-driving cars, or AI-driven educational systems, and I think \ncountries that are less thoughtful about regulation will risk falling behind. \nRegulation should be in these specific industry verticals because we can have a \ngood debate about the outcomes. We can more easily define what we do and do \nnot want to happen. I find it less useful to regulate AI broadly. I think that the act \nof thinking through the impact of AI in specific verticals for regulation will not \nonly help the verticals grow but will also help AI develop the right solutions and \nbe adopted faster across verticals.\nI think self-driving cars are only a microcosm of a broader theme here, which \nis the government. Every time there is a technological breakthrough, regulators \nmust act. Regulators have to act to make sure that democracy is defended, even \nin the era of the internet and the era of artificial intelligence. In addition to \ndefending democracy, governments must act to make sure that their countries \nare well positioned for the rise of AI.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 377
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n198\nAssuming that one of governments’ primary responsibilities is the well-being of \ntheir citizens, I think that governments that act wisely can help their nations ride \nthe rise of AI, to much better outcomes for their people. In fact, even today, some \ngovernments use the internet much better than other governments. This is about \nexternal websites and services to citizens, as well as internal ones, in terms of, how \nare your government IT services organized? \nSingapore has an integrated healthcare system, where every patient has a unique \npatient ID, and this allows for the integration of healthcare records in a way that \nis the envy of many other nations. Now, Singapore’s a small country, so maybe it’s \neasier for Singapore than a larger country, but the way the Singapore government \nhas shifted the healthcare system to use the internet better, has a huge impact on \nthe healthcare system, and on the health of the Singaporean citizens. \nMARTIN FORD: It sounds like you think the relationship between government and \nAI should extend beyond just regulating the technology.\nANDREW NG: I think governments have a huge role to play in the rise of AI \nand in making sure that first, governance is done well with AI. For instance, \nshould we better allocate government personnel using AI? How about the forestry \nresources, can we allocate that better using AI? Can AI help us set better economic \npolicies? Can the government weed out fraud—maybe tax fraud—better and more \nefficiently using AI? I think AI will have hundreds of applications in governance, \njust as AI has hundreds of applications in the big AI companies. Governments \nshould use AI well for themselves. \nFor the ecosystem as well, I think public-private partnerships will accelerate the \ngrowth of domestic industry, and governments that make thoughtful regulation \nabout self-driving cars will see self-driving accelerate in their communities. I’m very \ncommitted to my home state of California, but California regulations do not allow \nself-driving car companies to do certain things, which is why many self-driving car \ncompanies can’t have their home bases in California and are now almost forced to \noperate outside of California. \nI think that both at the state level as well as at the nation level, countries that have \nthoughtful policies about self-driving cars, about drones, and about the adoption \nof AI in payment systems and in healthcare systems, for example—those countries \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 378
  },
  {
    "chunk_full": "ANDREW NG\n199\nwith thoughtful policies in all of these verticals will see much faster progress in how \nthese amazing new tools can be brought to bear on some of the most important \nproblems for their citizens. Beyond regulation and public-private partnership, to \naccelerate the adoption of these amazing tools, I think governments also need to \ncome up with solutions in education and on the jobs issue. \nMARTIN FORD: The impact on jobs and the economy is an area that I’ve written \nabout a lot. Do you think we may be on the brink of a massive disruption that \ncould result in widespread job losses?\nANDREW NG: Yes, and I think it’s the biggest ethical problem facing AI. Whilst the \ntechnology is very good at creating wealth in some segments of society, we have \nfrankly left large parts of the United States and also large parts of the world behind. \nIf we want to create not just a wealthy society but a fair one, then we still have a \nlot of important work to do. Frankly, that’s one of the reasons why I remain very \nengaged in online education. \nI think our world is pretty good at rewarding people who have the required skills at \na particular time. If we can educate people to reskill even as their jobs are displaced \nby technology, then we have a much better chance of making sure that this next \nwave of wealth creation ends up being distributed in a more equitable way. A lot \nof the hype about evil AI killer robots distracts leaders from the much harder, but \nmuch more important conversation about what we do about jobs.\nMARTIN FORD: What do you think of a universal basic income as part of a \nsolution to that problem? \nANDREW NG: I don’t support a universal basic income, but I do think a conditional \nbasic income is a much better idea. There’s a lot about the dignity of work and I \nactually favor a conditional basic income in which unemployed individuals can be \npaid to study. This would increase the odds that someone that’s unemployed will \ngain the skills they need to re-enter the workforce and contribute back to the tax \nbase that is paying for the conditional basic income.\nI think in today’s world, there are a lot of jobs in the gig economy, where you \ncan earn enough of a wage to get by, but there isn’t much room for lifting up \nyourself or your family. I am very concerned about an unconditional basic income \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 379
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n200\ncausing a greater proportion of the human population to become trapped doing \nthis low-wage, low-skilled work. \nA conditional basic income that encourages people to keep learning and keep \nstudying will make many individuals and families better off because we’re helping \npeople get the training they need to then do higher-value and better-paying jobs. \nWe see economists write reports with statistics like “in 20 years, 50% of jobs are \nat risk of automation,” and that’s really scary, but the flip side is that the other \n50% of jobs are not at risk of automation. \nIn fact, we can’t find enough people to do some of these jobs. We can’t find \nenough healthcare workers, we can’t find enough teachers in the United States, and \nsurprisingly we can’t seem to find enough wind turbine technicians. \nThe question is, how do people whose jobs are displaced take on these other great-\npaying, very valuable jobs that we just can’t find enough people to do? The answer \nis not for everyone to learn to program. Yes, I think a lot of people should learn \nto program, but we also need to skill up more people in those areas of healthcare, \neducation, and wind turbine technicians, and other in-demand rising categories of jobs.\nI think we’re moving away from a world where you have one career in your \nlifetime. Technology changes so fast that there will be people that thought they \nwere doing one thing when they went to college that will realize that the career \nthey set out toward when they were 17-years-old is no longer viable, and that \nthey should branch into a different career.\nWe’ve seen how millennials are more likely to hop among jobs, where you go from \nbeing a product manager in one company to the product manager of a different \ncompany. I think that in the future, increasingly we’ll see people going from being \na material scientist in one company to being a biologist in a different company, to \nbeing a security researcher in a third company. This won’t happen overnight, it will \ntake a long time to change. Interestingly, though, in my world of deep learning, I \nalready see many people doing deep learning that did not major in computer science, \nthey did subjects like physics, astronomy, or pure mathematics. \nMARTIN FORD: Is there any particular advice you’d give to a young person who \nis interested in a career in AI, or in deep learning specifically? Should they focus \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 380
  },
  {
    "chunk_full": "ANDREW NG\n201\nentirely on computer science or is brain science, or the study of cognition in \nhumans also important? \nANDREW NG: I would say to study computer science, machine learning, and \ndeep learning. Knowledge of brain science or physics is all useful, but the most \ntime-efficient route to a career in AI is computer science, machine learning and \ndeep learning. Because of YouTube videos, talks, and books, I think it’s easier \nthan ever for someone to find materials and study by themselves, just step by \nstep. Things don’t happen overnight, but step by step, I think it’s possible for \nalmost anyone to become great at AI. \nThere are a couple of pieces of advice that I tend to give to people. Firstly, people \ndon’t like to hear that it takes hard work to master a new field, but it does take \nhard work, and the people who are willing to work hard at it will learn faster. I \nknow that it’s not possible for everyone to learn a certain number of hours every \nweek, but people that are able to find more time to study will just learn faster.\nThe other piece of advice I tend to give people is that let’s say you’re currently a \ndoctor and you want to break into AI—as a doctor you’d be uniquely positioned \nto do very valuable work in healthcare that very few others can do. If you are \ncurrently a physicist, see if there are some ideas on AI applied to physics. If you’re \na book publisher, see if there’s some work you can do with AI in book publishing, \nbecause that’s one way to leverage your unique strengths and to complement that \nwith AI, rather than competing on a more even playing field with the fresh college \ngrad stepping into AI.\nMARTIN FORD: Beyond the possible impact on jobs, what are the other risks \nassociated with AI that you think we should be concerned about now or in the \nrelatively near future?\nANDREW NG: I like to relate AI to electricity. Electricity is incredibly powerful and on \naverage has been used for tremendous good, but it can also be used to harm people. AI \nis the same. In the end, it’s up to individuals, as well as companies and governments, \nto try to make sure we use this new superpower in positive and ethical ways.\nI think that bias in AI is another major issue. AI that learns from human-generated \ntext data can pick up on health, gender, and racial stereotypes. AI teams are aware \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 381
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n202\nof this and are actively working on this, and I am very encouraged that today we \nhave better ideas for reducing bias in AI than we do for reducing bias in humans. \nMARTIN FORD: Addressing bias in people is very difficult, so it does seem like it \nmight be an easier problem to solve in software. \nANDREW NG: Yes, you can zero a number in an AI piece of software and it will \nexhibit much less gender bias, we don’t have similarly effective ways of reducing \ngender bias in people. I think that soon we might see that AI systems will be \nless biased than many humans. That is not to say that we should be satisfied \nwith just having less bias, there’s still a lot of work to do and we should keep \non working to reduce that bias. \nMARTIN FORD: What about the concern that a superintelligent system might \nsomeday break free of our control and pose a genuine threat to humanity?\nANDREW NG: I’ve said before that worrying about AGI evil killer robots today \nis like worrying about overpopulation on the planet Mars. A century from now \nI hope that we will have colonized the planet Mars. By that time, it may well be \noverpopulated and polluted, and we might even have children dying on Mars from \npollution. It’s not that I’m heartless and don’t care about those dying children—I \nwould love to find a solution to that, but we haven’t even landed on the planet yet, \nso I find it difficult to productively work on that problem. \nMARTIN FORD: You don’t think then that there’s any realistic fear of what people \ncall the “fast takeoff” scenario, where an AGI system goes through a recursive self-\nimprovement cycle and rapidly becomes superintelligent?\nANDREW NG: A lot of the hype about superintelligence and exponential growth \nwere based on very naive and very simplistic extrapolations. It’s easy to hype almost \nanything. I don’t think that there is a significant risk of superintelligence coming \nout of nowhere and it happening in a blink of an eye, in the same way that I don’t \nsee Mars becoming overpopulated overnight.\nMARTIN FORD: What about the question of competition with China? It’s often pointed \nout that China has certain advantages, like access to more data due to a larger population \nand fewer concerns about privacy. Are they going to outrun us in AI research?\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 382
  },
  {
    "chunk_full": "ANDREW NG\n203\nANDREW NG: How did the competition for electricity play out? Some countries \nlike the United States have a much more robust electrical grid than some \ndeveloping economies, so that’s great for the United States. However, I think the \nglobal AI race is much less of a race than the popular press sometimes presents \nit to be. AI is an amazing capability, and I think every country should figure out \nwhat to do with this new capability, but I think that it is much less of a race \nthan the popular press suggests.\nMARTIN FORD: AI clearly does have military applications, though, and potentially \ncould be used to create automated weapons. There’s currently a debate in the United \nNations about banning fully autonomous weapons, so it’s clearly something people \nare concerned about. That’s not futuristic AGI-related stuff, but rather something \nwe could see quite soon. Should we be worried?\nANDREW NG: The internal combustion engine, electricity, and integrated circuits \nall created tremendous good, but they were all useful for the military. It’s the same \nwith any new technology, including AI. \nMARTIN FORD: You’re clearly an optimist where AI is concerned. I assume you believe \nthat the benefits are going to outweigh the risks as artificial intelligence advances? \nANDREW NG: Yes, I do. I’ve been fortunate to be on the front lines, shipping AI \nproducts for the last several years and I’ve seen firsthand the way that better speech \nrecognition, better web search, and better optimized logistics networks help people. \nThis is the way that I think about the world, which may be a very naïve way. The \nworld’s gotten really complicated, and the world’s not the way I want it to be. \nFrankly, I miss the times when I could listen to political leaders and business leaders, \nand take much more of what they said at face value.\nI miss the times when I had greater confidence in many companies and leaders \nto behave in an ethical way and to mean what they say and say what they mean. \nIf you think about your as-yet-unborn grandchildren or your unborn great-great-\ngrandchildren, I don’t think the world is yet the way that you want it to be for \nthem to grow up in. I want democracy to work better, and I want the world to be \nfairer. I want more people to behave ethically and to think about the actual impact \non other people, and I want the world to be fairer, for everyone to have access \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 383
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n204\nto and gain an education. I want people to work hard, but to work hard and to \nkeep studying, and to do work that they find meaningful, and I think many parts \nof the world are not yet the way I think we would all like it to be. \nEvery time there’s a technological disruption, it gives us the opportunity to make a \nchange. I would like my teams, as well as other people around the world to take a \nshot at making the world a better place in the ways that we want it to be. I know \nthat sounds like I’m a dreamer, but that’s what I actually want to do. \nMARTIN FORD: I think that’s a great vision. I guess the problem is that it’s a decision \nfor society as a whole to set us on the path to that kind of optimistic future. Are \nyou confident that we’ll make the right choices?\nANDREW NG: I don’t think it will be in a straight line, but I think there are enough \nhonest, ethical, and well-meaning people in the world to have a very good shot at it. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 384
  },
  {
    "chunk_full": "ANDREW NG\n205\nANDREW NG is one of the most recognizable names in AI and machine learning. He co-\nfounded the Google Brain deep learning project as well as the online education company \nCoursera. Between 2014 and 2017, he was a vice president and chief scientist at Baidu, \nwhere he built the company’s AI group into an organization with several thousand people. \nHe is generally credited with playing a major role in the transformation of both Google and \nBaidu into AI-driven companies. \nSince leaving Baidu, Andrew has undertaken a number of projects including launching \ndeeplearning.ai, an online education platform geared toward educating deep learning experts, as \nwell as Landing AI, which seeks to transform enterprises with AI. He’s currently the chairman \nof Woebot, a startup focused on mental health applications for AI and is on the board of \ndirectors of self-driving car company Drive.ai. He is also the founder and General Partner at \nAI Fund, a venture capital firm that builds new AI startups from the ground up.\nAndrew is currently an adjunct professor, and formerly the associate professor and Director of \nthe AI Lab at Stanford University. He received his undergraduate degree in computer science \nfrom Carnegie Mellon University, his master’s degree from MIT, and his PhD from The \nUniversity of California, Berkeley.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 385
  },
  {
    "chunk_full": "",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 386
  },
  {
    "chunk_full": "RANA EL KALIOUBY\n207\nRANA EL KALIOUBY\nCEO & CO-FOUNDER OF AFFECTIVA\nRana el Kaliouby is the co-founder and CEO of Affectiva, a startup company \nthat specializes in AI systems that sense and understand human emotions. \nAffectiva is developing cutting-edge AI technologies that apply machine learning, \ndeep learning, and data science to bring new levels of emotional intelligence to \nAI. Rana is an active participant in international forums that focus on ethical \nissues and the regulation of AI to help ensure the technology has a positive \nimpact on society. She was selected as a Young Global Leader by the World \nEconomic Forum in 2017. \nI feel that this view, about the existential threat that  \nrobots are going to take over humanity, takes away  \nour agency as humans. At the end of the day, we’re  \ndesigning these systems, and we get to say how  \nthey are deployed, we can turn the switch off.\n“ \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 387
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n208\nMARTIN FORD: I want to begin by exploring your background; I’m especially \ninterested in how you became involved with AI and how your trajectory went from \nan academic background to where you are today with your company, Affectiva.\nRANA EL KALIOUBY: I grew up around the Middle East, being born in Cairo, \nEgypt and spending much of my childhood in Kuwait. During this time, I found \nmyself experimenting with early computers, as a result of both my parents being \nin technology, and my dad would bring home the old Atari machines where we \nwould pick them apart. Fast-forward and that grew into my undergraduate course \nwhere I majored in Computer Science at the American University in Cairo. I guess \nyou could say this is where the thinking behind Affectiva first came into play. \nDuring this time, I became fascinated by how technology changes how humans \nconnect with one another. Nowadays a lot of our communication is mediated via \ntechnology, and so the special way that we connect with technology, but also with \none another, fascinates me.\nThe next step was to do a PhD. I received a scholarship to work with the Computer \nScience department at Cambridge University, which, on a side note, was something \nthat was quite unusual for a young Egyptian and Muslim woman to do. This was \nin the year 2000, so it was before we all had smartphones, but at the time I was \nquite interested in this idea of human-computer interaction and how our interface \nis going to evolve over the next few years. \nThrough my own experience, I realized that I was spending a lot of time in front \nof my machine, where I was coding and writing all these research papers, which \nopened me to two realizations. The first realization was that the laptop I was using \n(remember no smartphones yet) was supposedly quite intimate with me. I mean, I \nwas spending a lot of hours with it, and while it knew a lot of things about me—like \nif I was writing a Word document or coding—it had no idea how I was feeling. It \nknew my location, it knew my identity, but it was just completely oblivious to my \nemotional and cognitive state. \nIn that sense my laptop reminded me of Microsoft Clippy, where you would be \nwriting a paper, and then this paper-clip would show up, do a little twirl, and it \nwould say, “Oh, it looks like you’re writing a letter! Do you need any help?” Clippy \nwould often show up at the weirdest times, for example when I was super-stressed \nand my deadline was in 15 minutes... and the paperclip would do its funny little \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 388
  },
  {
    "chunk_full": "RANA EL KALIOUBY\n209\ncheesy thing. Clippy helped me realize that we have an opportunity here, because \nthere’s an emotional intelligence gap with our technology.\nThe other thing that was kind of very clear is that this machine mediated a lot \nof my communication with my family back home. During my PhD, there were \ntimes when I was that homesick, and I would be chatting with my family in tears, \nand yet they’d have no idea because I was hiding behind my screen. It made me \nfeel very lonely and I realized how all of the rich non-verbal communications that \nwe have when we’re face to face, in a phone conversation or a video conference, \nare all lost in cyberspace when we are interacting digitally. \nMARTIN FORD: So, your own life experiences led you to become interested in the \nidea of technology that could understand human emotions. Did your PhD focus \nmuch on exploring this idea?\nRANA EL KALIOUBY: Yes, I became intrigued by the idea that we’re building a lot of \nsmartness into our technologies but not a lot of emotional intelligence, and this was an \nidea that I started to explore during my PhD. It all began during one of my very early \npresentations at Cambridge, where I was talking to an audience about how curious \nI was about how we might build computers that could read emotions. I explained \nduring the presentation how I am, myself, a very expressive person—that I’m very \nattuned to people’s facial expressions, and how intriguing I found it to think about \nhow we could get a computer to do the same. A fellow PhD student popped up and \nsaid, “Have you looked into autism because people on the autism spectrum also find \nit very challenging to read facial expressions and non-verbal behaviors?” As a result \nof that question, I ended up collaborating very closely with the Cambridge Autism \nResearch Center during my PhD. They had an amazing dataset that they’d compiled \nto help kids on the autism spectrum to learn about different facial expressions.\nMachine learning needs a lot of data, and so I borrowed their dataset to train the \nalgorithms I was creating, on how to read different emotions, something that showed \nsome really promising results. This data opened up an opportunity to focus not just \non the happy/sad emotions, but also on the many nuanced emotions that we see in \neveryday life, such as confusion, interest, anxiety or boredom. \nI could soon see that we had this tool that we could package up and provide as a \ntraining tool for individuals on the autism spectrum. This is where I realized that \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 389
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n210\nmy work wasn’t just about improving human-computer machine interfaces, but also \nabout improving human communication and human connection. \nWhen I completed my PhD at Cambridge, I met with the MIT professor, Rosalind \nPicard, who authored the book Affective Computing, and would later co-found \nAffectiva with me. But back in 1998, Rosalind posited that technology needs to \nbe able to identify human emotions and respond to those emotions. \nLong story short, we ended up chatting, and Rosalind invited me to join her lab at \nthe MIT Media Lab. The project that brought me over to the US was a National \nScience Foundation project that would take my technology of reading emotions and, \nby integrating it with a camera, we could apply it for kids on the autism spectrum. \nMARTIN FORD: In one of the articles I read about you, I think you described an \n“emotional hearing aid” for autistic kids. Is this what you are referring to? Did \nthat invention stay at the conceptual level or did it become a practical product?\nRANA EL KALIOUBY: I joined MIT in 2006, and between then and 2009 we \npartnered with a school in Providence, Rhode Island, and they were focused \non kids on the autism spectrum. We deployed our technology there, and we \nwould take prototypes to the kids and have them try it, and they would say “this \ndoesn’t feel quite right,” so we iterated the system until it began to succeed. \nEventually, we were able to demonstrate that the kids who were using the \ntechnology were having a lot more eye contact, and they were doing a lot more \nthan just looking at people’s faces. \nImagine how these kids, somewhere on the spectrum of autism, would wear these \npairs of glasses with a camera facing outwards. When we first started doing this \nresearch, a lot of the camera data we got was just of the floor or the ceiling: the \nkids weren’t even looking at the face. But the input that we got, from working \nwith these kids, allowed us to build real-time feedback that helped encourage them \nto make face contact. Once those kids started to do that, we gave them feedback \non what kind of emotions people are displaying. It all looked very promising. \nYou’ve got to remember that Media Lab is a unique academic department at MIT, \nin the sense that it has very strong ties to industry, to the point where about \n80% of the lab’s funding comes from Fortune 500 companies. So twice a year, \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 390
  },
  {
    "chunk_full": "RANA EL KALIOUBY\n211\nwe would host these companies for what we called Sponsor Week, where it was \nvery demo-or-die because you had to actually show what you were working on. \nA PowerPoint wouldn’t cut it! \nSo, twice a year between 2006 and 2008 we’d invite all these folks over to MIT, and \nwe would demo the autism prototype. During these kinds of events, companies like \nPepsi would ask if we’d thought about applying this work to test whether advertising \nwas effective. And Procter & Gamble wanted to use it to test its latest shower gels, \nbecause it wanted to know if people liked the smells or not. Toyota wanted to use \nit for driver state monitoring, and The Bank of America wanted to optimize the \nbanking experience. We explored getting some more research assistants to help \ndevelop the ideas that our funders wanted, but we soon realized that this was not \nresearch anymore, that it was in fact a commercial opportunity. \nI was apprehensive about leaving academia, but I was starting to get a little frustrated \nthat in academia you do all these prototypes, but they never get deployed at scale. \nWith a company, I felt we had an opportunity to scale and bring products to market, \nand to change how people communicate and do things on a day-to-day basis. \nMARTIN FORD: It sounds like Affectiva has been very customer-driven. Many startups \ntry to create a product in anticipation of a market being there; but in your case, the \ncustomers told you exactly what they wanted, and you responded directly to that.\nRANA EL KALIOUBY: You’re absolutely right, and it quickly became apparent that \nwe were sitting on a potentially huge commercial opportunity. Collectively, Rosalind \nand I felt that between us we had started this field, we were thought leaders, and \nthat we wanted to do it in a very ethical way as well—which was core to us. \nMARTIN FORD: What are you working on at Affectiva now, and what’s your overall \nvision for where it’s going to go in the future?\nRANA EL KALIOUBY: Our overall vision is that we’re on a mission to humanize \ntechnology. We’re starting to see technology permeate every aspect of our life. \nWe’re also starting to see how interfaces are becoming conversational, and that our \ndevices are becoming more perceptual—and a lot more potentially relational. We’re \nforming these tight relationships with our cars, our phones, and our smart-enabled \ndevices like Amazon’s Alexa or Apple’s Siri.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 391
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n212\nIf you think about a lot of people who are building these devices, right now, they’re \nfocused on the cognitive intelligence aspect of these devices, and they’re not paying \nmuch attention to the emotional intelligence. But if you look at humans, it’s not just \nyour IQ that matters in how successful you are in your professional and personal \nlife; it’s often really about your emotional and social intelligence. Are you able to \nunderstand the mental states of people around you? Are you able to adapt your \nbehavior to take that into consideration and then motivate them to change their \nbehavior, or persuade them to take action?\nAll of these situations, where we are asking people to take action, we all need \nto be emotionally intelligent to get to that point. I think that this is equally true \nfor technology that is going to be interfacing with you on a day-to-day basis and \npotentially asking you to do things. \nWhether that is helping you sleep better, eat better, exercise more, work more \nproductively, or be more social, whatever that technology is, it needs to consider \nyour mental state when it tries to persuade you to take part in them. \nMy thesis is that this kind of interface between humans and machines is going to \nbecome ubiquitous, that it will just be ingrained in the future human-machine \ninterfaces, whether it’s our car, our phone or smart devices at our home or in \nthe office. We will just be coexisting and collaborating with these new devices, \nand new kinds of interfaces. \nMARTIN FORD: Could you sketch out some of the specific things you’re working \non? I know you’re doing something with monitoring drivers in cars to make sure \nthey are attentive.\nRANA EL KALIOUBY: Yes, the issue today around monitoring drivers in cars is that \nthere are so many situations to cater for, that Affectiva as a company has focused \nspecifically on situations that are ethical, and where there’s a good product-market \nfit. And of course, for where the markets are ready. \nWhen Affectiva started in 2009, the first kind of low-hanging market opportunities \nwere in advertising testing, as I mentioned, and today Affectiva works with a quarter \nof the Fortune Global 500 companies to help them understand the emotional \nconnection their advertising creates with their consumers. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 392
  },
  {
    "chunk_full": "RANA EL KALIOUBY\n213\nOften, companies will spend millions of dollars to create an advertisement that’s \nfunny or one that tugs at your heart. But they have no idea if they struck the right \nemotional chord with you. The only way that they could find that sort of thing out, \nbefore our technology existed, was to ask people. So, if you, Martin Ford, were the \nperson watching the ad, then you’d get a survey, and it would say, “Hey, did you \nlike this ad? Did you think it was funny? Are you going to buy the product?” And \nthe problem with that is that it’s very unreliable and very biased data. \nSo now, with our technology, as you’re watching the ad, with your consent it will \nanalyze on a moment-by-moment basis all your facial expressions and aggregate that \nover the thousands of people who watched that same ad. The result is an unbiased, \nobjective set of data around how people respond emotionally to the advertising. \nWe can then correlate that data with things like customer purchase intent, or even \nactual sales data and virality. \nToday we have all these KPIs that can be tracked, and we’re able to tie the emotional \nresponse to actual consumer behavior. That’s a product of ours that’s in 87 countries, \nfrom the US and China to India, but also smaller countries like Iraq and Vietnam. \nIt’s a pretty robust product at this point, and it’s been amazing because it allows us \nto collect data from all over the world, and it’s all very spontaneous data. It’s data \nthat, I would argue, even Facebook and Google don’t have because it’s not just your \nprofile picture, it’s you sitting in your bedroom one night, watching a shampoo ad. \nThat’s the data we have, and that’s what drives our algorithm.\nMARTIN FORD: What are you analyzing? Is it mostly based on facial expressions or \nalso on other things like voice?\nRANA EL KALIOUBY: Well, when we first started, we worked with just the face, \nbut about eighteen months ago we went back to the drawing board and asked: how \ndo we as humans monitor the responses of other humans? \nPeople are pretty good at monitoring the mental states of the people around \nthem, and we know that about 55% of the signals we use are in facial expression \nand your gestures, while about 38% of the signal we respond to is from tone \nof voice. So how fast someone is speaking, the pitch, and how much energy \nis in the voice. Only 7% of the signal is in the text and the actual choice of \nwords that someone uses! \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 393
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n214\nNow when you think of the entire industry of sentiment analysis, the multi-\nbillion-dollar industry of people listening to tweets and analyzing text messages \nand all that, it only accounts for 7% of how humans communicate. What I like \nto think about what we’re doing here, is trying to capture the other 93% of \nnon-verbal communication. \nSo, back to your questions: about eighteen months ago I started a speech team \nthat looks at these prosodic paralinguistic features. They would look at the \ntone of voice and the occurrence of speech events, such as how many times \nyou say “um” or how many times you laughed. All of these speech events are \nindependent of the actual words that we’re saying. Affectiva technology now \ncombines these things and takes what we call a multimodal approach, where \ndifferent modalities are combined, to truly understand a person’s cognitive, \nsocial or emotional state. \nMARTIN FORD: Are the emotional indicators you look for consistent across languages \nand cultures, or are there significant differences between populations?\nRANA EL KALIOUBY: If you take facial expressions or even the tone of a person’s \nvoice, the underlying expressions are universal. A smile is a smile everywhere in \nthe world. However, we are seeing this additional layer of cultural display norms, \nor rules, that depict when people portray their emotions, or how often, or how \nintensely they show their emotion. We see examples of people amplifying their \nemotions, dampening their emotions, or even masking their emotions altogether. \nWe particularly see signs of masking in Asian markets, where Asian populations are \nless likely to show negative emotions, for instance. So, in Asia we see an increased \nincidence of what we call a social smile, or a politeness smile. Those are not \nexpressions of joy, but are more themed around saying, “I acknowledge you,” and \nin that sense they are a very social signal. \nBy and large, everything is universal. There are cultural nuances, of course, and \nbecause we have all this data, we’ve been able to build region-specific and sometimes \neven country-specific norms. We have so much data in China, for instance, that \nChina is its own norm. Instead of comparing a Chinese individual’s response to \nsay, a chocolate ad, we compare a Chinese individual to the subpopulation that’s \nmost like them. And this particular approach has been critical to our success in \nmonitoring emotional states in different cultures around the world.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 394
  },
  {
    "chunk_full": "RANA EL KALIOUBY\n215\nMARTIN FORD: I guess then that other applications you’re working on are oriented \ntoward safety, for example monitoring drivers or the operators of dangerous \nequipment to make sure they stay attentive?\nRANA EL KALIOUBY: Absolutely. In fact in the last year we’ve started to get a \nton of inbound interest from the automotive industry. It’s really exciting because \nit’s a major market opportunity for Affectiva and we’re solving two interesting \nproblems for the car industry. \nIn the cars of today, where there is an active driver, safety is a huge issue. And \nsafety will continue to be an issue, even when we have semi-autonomous vehicles \nlike Tesla that can drive themselves for a while but do still need a co-pilot to \nbe paying attention. \nUsing Affectiva software, we’re able to monitor the driver or the co-pilot for \nthings like drowsiness, distraction, fatigue and even intoxication. In the case \nof intoxication, we would alert the driver or also even potentially have the car \nintervene. Intervention could be anything from changing the music to blasting \na little bit of cold air, or tightening the seat belt, all the way to potentially \nsaying, “You know what? I’m the car, and I feel I could be a safer driver than \nyou are right now. I’m taking control over.” There’s a lot of actions the car can \ntake once it understands the level of attention and how impaired a driver is. So, \nthat’s one class of use cases. \nThe other problem we’re solving for the automotive industry is around the occupant \nexperience. Let’s look into the future where we have fully autonomous vehicles and \nrobot-taxis, where there’s no driver in the car at all. In those situations, the car \nneeds to understand the state of the occupants such as, how many people are in the \ncar, what’s their relationship, are they in a conversation, or even do we have a baby \nin the car that’s potentially getting left behind? Once you understand the mood of \nthe occupants in the car, you can personalize the experience.\nThe robot-taxi could make product recommendations or route recommendations. \nThis would also introduce new business models for auto companies, especially \npremium brands like a BMW or a Porsche, because right now they’re all about \nthe driving experience. But in the future, it’s not going to be about driving \nanymore: it’s going to be about transforming and redefining that transport, that \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 395
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n216\nmobility experience. Modern transport is a very exciting market, and we’re \nspending a lot of our mindshare building products for that industry, and also \nfor those partnered with Tier 1 companies.\nMARTIN FORD: Do you see potential applications in healthcare? Given that we do \nhave a mental health crisis, I wonder if you think the kind of technology you’re \nbuilding at Affectiva might help in areas like counseling?\nRANA EL KALIOUBY: Healthcare is probably what I’m most excited about, because \nwe know that there are facial and vocal biomarkers of depression, and we know that \nthere are signs that could be predictive of suicidal intent in a person. Think about \nhow often we are in front of our devices and our phones, that’s an opportunity to \ncollect very objective data. \nRight now, you can only ask a person, on a scale from 1 to 10, how depressed \nthey are, or how suicidal they are. It’s just not accurate. But we now have the \nopportunity to collect data at scale and build a baseline model of who someone \nis and what their baseline mental state or mental health state is. Once we have \nthat data, if someone starts to deviate from their normal baseline, then a system \ncan signal that to the person themselves, to their family members or even maybe \na healthcare professional. \nThen imagine how we could use these same metrics to analyze the efficacy of \ndifferent treatments. The person could try cognitive behavioral therapy or certain \ndrugs, and we would be able to quantify, very accurately and very objectively over \ntime, if those treatments were effective or not. I feel that there’s a real potential \nhere to understand anxiety, stress, and depression, and be able to quantify it.\nMARTIN FORD: I want to move into a discussion about the ethics of AI. It’s easy \nto think of things that people might find disturbing about this kind of technology. \nFor example, during a negotiation, if your system was secretly watching someone \nand giving the other side information about their responses, that would create an \nunfair advantage. Or it could be used for some form of wider workplace surveillance. \nMonitoring someone when they’re driving to make sure they’re attentive would \nprobably be okay with most people, but they might feel very different about the \nidea of your system watching an office worker sitting in front of a computer. How \ndo you address those concerns?\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 396
  },
  {
    "chunk_full": "RANA EL KALIOUBY\n217\nRANA EL KALIOUBY: There’s a little history lesson here about when Rosalind, \nmyself, and our first employee met around Rosalind’s kitchen table and we were \nthinking: Affectiva is going to get tested, so what are our boundaries and what’s \nnon-negotiable? In the end, we landed on this core value of respecting that \npeople’s emotions are a very personal type of data. From then on, we agreed \nthat we would only take on situations where people are explicitly consenting and \nopting in to share that data. And, ideally, where they’re also getting some value \nin return for sharing that data.\nThese are things that Affectiva has been tested on. In 2011, we were running low \non funds, but we had the opportunity for funding from a security agency that had \na venture arm, and it was very interested in using the technology for surveillance \nand security. Even though most people know that when they go to an airport, \nthey’re being watched, we just felt that this was not in line with our core value \nof consent and opt-in, so we declined the offer even though the money was there. \nAt Affectiva, we’ve stayed away from applications where we feel that people aren’t \nnecessarily opting in and the value equation is not balanced. \nWhen you think about the applications around the workplace, this question does \nbecome very interesting because the same tool could be used in ways that might \nbe very empowering—or of course, very like Big Brother. I do think it would be \nsuper-interesting if people wanted to opt-in, anonymously, and employers were \nable to then get a sentiment score, or just an overall view, of whether people are \nstressed in the office—or whether people are engaged and happy.\nAnother great example would be where a CEO is giving a presentation, to people \ndialed in from around the world, and the machine indicates whether or not the \nmessage is resonating as they CEO intends. Are the goals exciting? Are people \nmotivated? These are core questions that if we’re all co-located, it would be easy \nto collect; but now, with everybody distributed, it’s just really hard to get a sense \nof these things. However, if you turn it around and use the same technology to say, \n“OK. I’m going to pick on a certain member of staff because they seemed really \ndisengaged,” then that’s a total abuse of the data.\nAnother example would be where we have a version of the technology that tracks \nhow meetings go, and at the end of every meeting, it can give people feedback. It \nwould give you feedback like, “you rambled for 30 minutes, and you were pretty \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 397
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n218\nhostile towards so-and-so, you should be a little bit more thoughtful or more \nempathetic.” You can easily imagine how this technology could be used as a coach \nto help staff negotiate better or be a more thoughtful team member; but at the \nsame time, you could use it to hurt people’s careers. \nI would like to think of us as advocating for situations where people can get the \ndata back, and they can learn something about it, and it could help them advance \ntheir social and emotional intelligence skills.\nMARTIN FORD: Let’s delve into the technology you’re using. I know that you use \ndeep learning quite heavily. How do you feel about that as a technology? There \nhas been some recent pushback, with some people suggesting that progress in \ndeep learning is going to slow or even hit a wall, and that another approach will \nbe needed. How do you feel about the use of neural networks and how they’re \ngoing to evolve in the future? \nRANA EL KALIOUBY: Back when I did my PhD, I used dynamic Bayesian networks \nto quantify and build these classifiers. Then a couple of years ago we moved all \nour science infrastructure to be deep learning-based, and we have absolutely \nreaped the benefits of that. \nI would say that we haven’t even maxed out yet on deep learning. With more \ndata combined with these deep neural nets, we see increases in the accuracy and \nrobustness of our analysis across so many different situations. \nDeep learning being awesome, I don’t think that it’s the be-all, end-all to all \nof our needs. It’s still pretty much supervised, so you still need to have some \nlabeled data to track these classifiers. I think of it as an awesome tool within \nthis bigger bucket of machine learning, but deep learning is not going to be the \nonly tool that we use. \nMARTIN FORD: Thinking more generally now, let’s talk about the march towards \nartificial general intelligence. What are the hurdles involved? Is AGI something that \nis feasible, realistic or even something you expect to see in your lifetime?\nRANA EL KALIOUBY: We’re many, many, many, many, many years away from an \nAGI and the reason I say that is because when you look at all the examples of AI \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 398
  },
  {
    "chunk_full": "RANA EL KALIOUBY\n219\nthat we have today, all of them are pretty narrow. Today’s AI does one thing well, \nbut they all had to be bootstrapped in one way or another, even if they learned \nhow to play a game from scratch. \nI think there are sub-assumptions, or some level of sub-curation, that happens with \nthe dataset, which has allowed that algorithm to learn whatever it learns, and I don’t \nthink that we’ve yet figured out how to give it human-level intelligence. \nEven if you look at the best natural language processing system that we have today, \nand you give it something like a third-grade test, it doesn’t pass. \nMARTIN FORD: What are your thoughts about the intersection between AGI and \nemotion? A lot of your work is primarily focused on getting machines to understand \nemotion, but flipping the coin, what about having a machine that exhibits emotion? \nDo you think that’s an important part of what AGI would be, or do you imagine a \nzombie-like machine that has no emotional sense at all? \nRANA EL KALIOUBY: I would say that we are already there, right now, in terms of \nmachines exhibiting emotions. Affectiva has developed an emotion-sensing platform, \nand a lot of our partners use this sensing platform to actuate machine behavior. \nWhether that technology is a car, or a social robot, an emotion-sensing platform \ncan take our human metrics as input, and that data can be used to decide how a \nrobot is going to respond. Those responses could be the things that a robot says \nfrom our stimuli, just like Amazon Alexa responds today.\nOf course, if you’re asking Amazon Alexa to order something and it keeps getting it \nwrong, then you’re now getting annoyed. But instead of Alexa just being completely \noblivious to all of that, your Alexa device could say, “OK, I’m sorry. I realize I’m \ngetting this wrong. Let me try again.” Alexa could acknowledge our level of frustration \nand it could then incorporate that into its response, and into what it actually does \nnext. A robot could move its head, it could move around, it could write, and it could \nexhibit actions that we would translate into, “Oh! It looks like it’s sorry.”\nI would argue that machine systems are already incorporating emotional cues in \ntheir actions, and that they can portray emotions, in any way that someone designs \nthem to do so. That is quite different, of course, from the device actually having \nemotions, but we don’t need to go there.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 399
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n220\nMARTIN FORD: I want to talk about the potential impact on jobs. How do you \nfeel about that? Do you think that there is the potential for a big economic and \njob-market disruption from AI and robotics, or do you think that’s perhaps been \noverhyped, and we shouldn’t worry quite so much about it? \nRANA EL KALIOUBY: I’d like to think of this as more of a human-technology \npartnership. I acknowledge that some jobs are going to cease to exist, but that’s \nnothing new in the history of humanity. We’ve seen that shift of jobs over and \nover again, and so I think there’s going to be a whole new class of jobs and job \nopportunities. While we can envision some of those new jobs now, we can’t \nenvision all of them. \nI don’t subscribe to the vision of a world where robots are going to take over and \nbe in control, whilst humanity will just sit around and chill by the beach. I grew \nup in the Middle East during the time of the first Gulf War, so I’ve realized that \nthere are so many problems in the world that need to be solved. I don’t think we’re \nanywhere close to a machine that’s just going to wake up someday and be able to \nsolve all these problems. So, to answer your question, I’m not concerned.\nMARTIN FORD: If you think about a relatively routine job, for example a customer \nservice job in a call center, it does sound like the technology you’re creating might \nenable machines to do that more human element of the work as well. When I’m \nasked about this, which is often, I say the jobs that are most likely to be safe are \nthe more human-oriented jobs, the ones that involve emotional intelligence. But it \nsounds like you’re pushing the technology into this area as well, so it does seem \nthat there’s a very broad range of occupations that could be eventually be impacted, \nincluding some areas currently perceived as quite safe from automation.\nRANA EL KALIOUBY: I think you’re right about this, and let me give an example \nwith nurses. At Affectiva, we are collaborating with companies that are building \nnurse avatars for our phones, and even installing social robots in our homes, \nwhich are designed to be a companion to terminally-ill patients. I don’t think \nthis is going to take the place of real nurses, but I do think it’s going to change \nhow nurses do their jobs. \nYou can easily imagine how a human nurse could be assigned to twenty patients, \nand each of these patients has access to a nurse avatar or a nurse robot. The human \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 400
  },
  {
    "chunk_full": "RANA EL KALIOUBY\n221\nnurse only gets brought into the loop if there is a problem that the nurse robot \ncan’t deal with. The technology allows the nurse robot to manage so many more \npatients, and manage them longitudinally, in a way that’s not possible today. \nThere’s a similar example with teachers. I don’t think intelligent learning systems \nare going to replace teachers, but they are going to augment them in places where \nthere isn’t access to enough teachers. It’s like we’re delegating these jobs to those \nmini-robots that could do parts of the job on our behalf. \nI think this is even true for truck drivers. Nobody will be driving a truck in \nthe next ten years, but someone is sitting at home and tele-operating 100 fleets \nout there and making sure that they’re all on track. There may instead be a \njob where someone needs to intervene, every so often, and take human control \nof one of them. \nMARTIN FORD: What is your response to some of the fears expressed about AI or \nAGI, in particular by Elon Musk, who has been very vocal about existential risks?\nRANA EL KALIOUBY: There’s a documentary on the internet called Do You Trust \nThis Computer? which was partially funded by Elon Musk, and I was featured in \nit being interviewed. \nMARTIN FORD: Yes, in fact, a couple of the other people I’ve interviewed in this \nbook were also featured in that documentary.\nRANA EL KALIOUBY: Having grown up in the Middle East, I feel that humanity \nhas bigger problems than AI, so I’m not concerned. \nI feel that this view, about the existential threat that robots are going to take \nover humanity, takes away our agency as humans. At the end of the day, we’re \ndesigning these systems, and we get to say how they are deployed, we can turn \nthe switch off. So, I don’t subscribe to those fears. I do think that we have more \nimminent concerns with AI, and these have to do with the AI systems themselves \nand whether we are, through them, just perpetuating bias?\nMARTIN FORD: So, you would say that bias is one of the more pressing issues \nthat we’re currently facing?\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 401
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n222\nRANA EL KALIOUBY: Yes. Because the technology is moving so fast, while we \ntrain these algorithms, we don’t necessarily know exactly what the algorithm or \nthe neural network is learning. I fear that we are just rebuilding all the biases that \nexist in society by implementing them in these algorithms.\nMARTIN FORD: Because the data is coming from people, so inevitably it incorporates \ntheir biases. You’re saying that it isn’t the algorithms that are biased, it’s the data. \nRANA EL KALIOUBY: Exactly, it’s the data. It’s how we’re applying this data. So \nAffectiva, as a company, is very transparent about the fact that we need to make \nsure that the training data is representative of all the different ethnic groups, and \nthat it has gender balance and age balance.\nWe need to be very thoughtful about how we train and validate these algorithms. \nThis an ongoing concern, it’s always a work in progress. There is always more that \nwe can do to guard against these kinds of biases.\nMARTIN FORD: But the positive side would be that while fixing bias in people is \nvery hard, fixing bias in an algorithm, once you understand it, might be a lot easier. \nYou could easily make an argument that relying on algorithms more in the future \nmight lead to a world with much less bias or discrimination.\nRANA EL KALIOUBY: Exactly. One great example is in hiring. Affectiva has \npartnered a company called HireVue, who use our technology in the hiring \nprocess. Instead of sending a Word resume, candidates send a video interview, \nand by using a combination of our algorithms and natural language processing \nclassifiers, the system ranks and sorts those candidates based on their non-verbal \ncommunication, in addition to how they answered the questions. This algorithm \nis gender-blind, and it’s ethnically blind. So, the first filters for these interviews \ndo not consider gender and ethnicity. \nHireVue has published a case study, with Unilever, where it shows that not only \ndid it reduce its time to hire by 90%, but the process resulted in a 16% increase \nin the diversity of its incoming hiring population. I found that to be pretty cool.\nMARTIN FORD: Do you think AI will need to be regulated? You’ve talked about \nhow you’ve got very high ethical standards at Affectiva, but looking into the \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 402
  },
  {
    "chunk_full": "RANA EL KALIOUBY\n223\nfuture, there’s a real chance that your competitors are going to develop similar \ntechnologies but perhaps not adhere to the same standards. They might accept the \ncontract from an authoritarian state, or the corporation that wants to secretly spy \non its employees or customers, even if you would not. Given this, do you think \nthere’s going to be a need to regulate this type of technology?\nRANA EL KALIOUBY: I’m a big advocate of regulation. Affectiva is part of the \nPartnership on AI consortium, and a member of the FATE working group, which \nis the Fair, Accountable, Transparent and Equitable AI. \nThrough working with these groups, our mandate is to develop guidelines that \nadvocate for the equivalent of an FDA (Food and Drug Administration) process \nfor AI. Alongside this work, Affectiva publishes best practices and guidelines \nfor the industry. Since we are thought leaders, it is our responsibility to be an \nadvocate for regulation, and to move the ball forward, as opposed to just saying, \n“Oh, yeah. We’re just going to wait until legislation comes about.” I don’t think \nthat that’s the right solution.\nI’m also a part of the World Economic Forum, on which there’s an international \nforum council on robotics and AI. Through working with this forum, I’ve become \nfascinated by the cultural differences in how different countries think about AI. \nA great example can be seen in China, which is part of this council. We know \nthat the Chinese government doesn’t really care about ethics, and so it begs the \nquestion, how do you navigate that? Different nations think about AI regulation \ndifferently, which makes this difficult to answer the question.\nMARTIN FORD: To end on an upbeat note, I assume you’re an optimist? That you \nbelieve these technologies are, on balance, going to be beneficial for humanity?\nRANA EL KALIOUBY: Yes, I would say that I’m an optimist because I believe that \ntechnology is neutral. What matters is how we decide to use it, and I think there’s a \npotential for good, and we should, as an industry, follow the footsteps of my team, \nwhere we’ve decided to focus our mindshare on the positive applications of AI.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 403
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n224\nRANA EL KALIOUBY is the CEO and co-founder of Affectiva, a company focused on emotion \nAI. She received her undergraduate and master’s degrees from American University in Cairo, \nEgypt and her PhD from the Computer Lab at the University of Cambridge. She worked as \na research scientist at the MIT Media Lab, where she developed technology to assist autistic \nchildren. That work led directly to the launch of Affectiva.\nRana has received a number of awards and distinctions, including selection as a Young Global \nLeader in 2017 by the World Economic Forum. She was also featured on Fortune Magazine’s \n40 under 40 and TechCrunch’s 40 Female founders who crushed it in 2016 lists.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 404
  },
  {
    "chunk_full": "RANA EL KALIOUBY\n225\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 405
  },
  {
    "chunk_full": "",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 406
  },
  {
    "chunk_full": "RAY KURZWEIL\n227\nRAY KURZWEIL\nDIRECTOR OF ENGINEERING AT GOOGLE\nRay Kurzweil is one of the world’s leading inventors, thinkers, and futurists. \nHe has received 21 honorary doctorates, and honors from three US presidents. \nHe is the recipient of the MIT Lemelson Prize for innovation and in 1999, \nhe received the National Medal of Technology, the nation’s highest honor in \ntechnology, from President Clinton. Ray is also a prolific writer, authoring \n5 national bestsellers. In 2012, Ray became a Director of Engineering at \nGoogle—heading up a team of engineers developing machine intelligence and \nnatural language understanding. Ray’s first novel, Danielle, Chronicles of a \nSuperheroine, is being published in early 2019. Another book by Ray, The \nSingularity is Nearer, is expected to be published in late 2019. \nThe scenario that I have is that we will send medical  \nnanorobots into our bloodstream. [...] These robots  \nwill also go into the brain and provide virtual and  \naugmented reality from within the nervous system  \nrather than from devices attached to the outside  \nof our bodies.\n“ \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 407
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n228\nMARTIN FORD: How did you come to start out in AI? \nRAY KURZWEIL: I first got involved in AI in 1962, which was only 6 years after \nthe term was coined by Marvin Minsky and John McCarthy at the 1956 Dartmouth \nConference in Hanover, New Hampshire.\nThe field of AI had already bifurcated into two warring camps: the symbolic school \nand the connectionist school. The symbolic school was definitely in the ascendancy \nwith Marvin Minsky regarded as its leader. The connectionists were the upstarts, \nand one such person was Frank Rosenblatt at Cornell University, who had the first \npopularized neural net called the perceptron. I wrote them both letters and they \nboth invited me to come up, so I first went to visit Minsky, where he spent all \nday with me and we struck up a rapport that would last for 55 years. We talked \nabout AI, which at the time was a very obscure field that nobody was really paying \nattention to. He asked who I was going to see next, and when I mentioned Dr. \nRosenblatt, he said that I shouldn’t bother.\nI then went to go and see Dr. Rosenblatt, who had this single-layer neural net \ncalled the perceptron; it was a hardware device that had a camera. I brought some \nprinted letters to my meeting with Dr. Rosenblatt where his device recognized them \nperfectly as long as they were in Courier 10. \nOther type styles didn’t work as well, and he said, “Don’t worry, I can take the \noutput of the perceptron and feed it as the input to a secondary perceptron, then \nwe can take the output of that and feed it to a third layer, and as we add layers \nit’ll get smarter and generalize and be able to do all these remarkable things.” I \nresponded saying, “Have you tried that?”, and he said, “well, not yet, but it’s high \non our research agenda.” \nThings didn’t move quite as quickly back in the 1960s as they do today, and sadly \nhe died 9 years later in 1971 never having tried that idea. The idea was remarkably \nprescient, however. All of the excitement we see now in neural nets is due to these \ndeep neural networks with many layers. It was a pretty remarkable insight, as it \nreally was not obvious that it would work. \nIn 1969, Minsky wrote his book, Perceptrons, with his colleague, Seymour Papert. \nThe book basically proved a theorem that a perceptron could not devise answers \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 408
  },
  {
    "chunk_full": "RAY KURZWEIL\n229\nthat required the use of the XOR logical function, nor could they solve the \nconnectedness problem. There are two maze-like images on the cover of that \nbook, and if you look carefully, you can see one is fully connected, and the \nother is not. Making that classification is called the connectedness problem. \nThe theorem proved that a perceptron could not do that. The book was very \nsuccessful in killing all funding for connectionism for the next 25 years, which \nis something Minsky regretted, as shortly before he died he told me that he now \nappreciated the power of deep neural nets. \nMARTIN FORD: Marvin Minsky did work on early connectionist neural nets back \nin the ‘50s, though, right?\nRAY KURZWEIL: That’s right, but he became disillusioned with them by the \n1960s, and really didn’t appreciate the power of multi-layer neural nets. It was not \napparent until decades later when 3-layer neural nets were tried and they worked \nsomewhat better. There was a problem going with too many layers, because of \nthe exploding gradient or vanishing gradient problem, which is basically where \nthe dynamic range of the values of the coefficients would decline because the \nnumbers got too big or too small. \nGeoffrey Hinton and a group of mathematicians solved that problem and now \nwe can go to any number of levels. Their solution was that you recalibrate \nthe information after each level, so it doesn’t outstrip the range of values that \ncan be represented and these 100-layer neural nets have been very successful. \nThere’s still a problem though, which is summarized by the motto, “Life begins \nat a billion examples.” \nOne of the reasons I’m here at Google is that we do have a billion examples of some \nthings like pictures of dogs and cats and other image categories that are annotated, \nbut there are also lots of things we don’t have a billion examples of. We have lots \nof examples of language, but they’re not annotated with what they mean, and how \ncould we annotate them anyway using language that we can’t understand in the \nfirst place? There’s a certain category of problems where we can work around that, \nand playing Go is a good example. The DeepMind system was trained on all of the \nonline moves, which is in the order of a million moves. That’s not a billion. That \ncreated a fair amateur player, but they need another 999 million examples, so where \nare they going to get them from? \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 409
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n230\nMARTIN FORD: What you’re getting at is that deep learning right now is very \ndependent on labeled data and what’s called supervised learning.\nRAY KURZWEIL: Right. One way to work around it is if you can simulate the \nworld you’re working in, then you can create your own training data, and that’s \nwhat DeepMind did by having it play itself. They could annotate the moves with \ntraditional annotation methods. Subsequently AlphaZero actually trained a neural \nnet to improve on the annotation, so it was able to defeat AlphaGo 100 games to \n0 starting with no human training data. \nThe question is, in what situations can you do that in? For example, another situation \nwhere we can do that is math, because we can simulate math. The axioms of number \ntheory are no more complicated than the rules of Go. \nAnother situation is self-driving cars, even though driving is much more complex \nthan a board game or the axioms of a math system. The way that worked is \nthat Waymo created a pretty good system with a combination of methods and \nthen drove millions of miles with humans at the wheel ready to take over. That \ngenerated enough data to create an accurate simulator of the world of driving. \nThey’ve now driven on the order of a billion miles with simulated vehicles in \nthe simulator, which has generated training data for a deep neural net designed \nto improve the algorithms. This has worked even though the world of driving \nis much more complex than a board game.\nThe next exciting area to attempt to simulate is the world of biology and medicine. \nIf we could simulate biology, and it’s not impossible, then we could do clinical trials \nin hours rather than years, and we could generate our own data just like we’re \ndoing with self-driving cars or board games or math. \nThat’s not the only approach to the problem of providing sufficient training data. \nHumans can learn from much less data because we engage in transfer learning, using \nlearning from situations which may be fairly different from what we are trying to \nlearn. I have a different model of learning based on a rough idea of how the human \nneocortex works. In 1962 I came up with a thesis on how I thought the human brain \nworks, and I’ve been thinking about thinking for the last 50 years. My model is not \none big neural net, but rather many small modules, each of which can recognize a \npattern. In my book, How to Create a Mind, I describe the neocortex as basically 300 \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 410
  },
  {
    "chunk_full": "RAY KURZWEIL\n231\nmillion of those modules, and each can recognize a sequential pattern and accept \na certain amount of variability. The modules are organized in a hierarchy, which is \ncreated through their own thinking. The system creates its own hierarchy.\nThat hierarchical model of the neocortex can learn from much less data. It’s the \nsame with humans. We can learn from a small amount of data because we can \ngeneralize information from one domain to another.\nLarry Page, one of the co-founders of Google, liked my thesis in How to Create a \nMind and recruited me to Google to apply those ideas to understanding language. \nMARTIN FORD: Do you have any real-world examples of you applying those \nconcepts to a Google product?\nRAY KURZWEIL: Smart Reply on Gmail (which provides three suggestions to reply \nto each email) is one application from my team that uses this hierarchical system. \nWe just introduced Talk to Books1, where you ask a question in natural language \nand the system then reads 100,000 books in a half-second—that’s 600 million \nsentences—and then returns the best answers that it can find from those 600 million \nsentences. It’s all based on semantic understanding, not keywords. \nAt Google we’re making progress in natural language, and language was the first \ninvention of the neocortex. Language is hierarchical; we can share the hierarchical \nideas we have in our neocortex with each other using the hierarchy of language. \nI think Alan Turing was prescient in basing the Turing test on language because I \nthink it does require the full range of human thinking and human intelligence to \ncreate and understand language at human levels. \nMARTIN FORD: Is your ultimate objective to extend this idea to actually build a \nmachine that can pass the Turing test? \nRAY KURZWEIL: Not everybody agrees with this, but I think the Turing test, if \norganized correctly, is actually a very good test of human-level intelligence. The issue is \nthat in the brief paper that Turing wrote in 1950, it’s really just a couple of paragraphs \nthat talked about the Turing test, and he left out vital elements. For example, he \n1 https://books.google.com/talktobooks/\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 411
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n232\ndidn’t describe how to actually go about administering the test. The rules of the test \nare very complicated when you actually administer it, but if a computer is to pass a \nvalid Turing test, I believe it will need to have the full range of human intelligence. \nUnderstanding language at human levels is the ultimate goal. If an AI could do that, \nit could read all documents and books and learn everything else. We’re getting there \na little bit at a time. We can understand enough of the semantics, for example to \nenable our Talk to Books application to come up with reasonable answers to questions, \nbut it’s still not at human levels. Mitch Kapor and I have a long-range bet on this for \n$20,000, with the proceeds to go to the charity of the winner’s choice. I’m saying \nthat an AI will pass the Turing test by 2029, whereas he’s saying no.\nMARTIN FORD: Would you agree that for the Turing test to be an effective test of \nintelligence, there probably shouldn’t be a time limit at all? Just tricking someone \nfor 15 minutes seems like a gimmick.\nRAY KURZWEIL: Absolutely, and if you look at the rules that Mitch Kapor and I \ncame up with, we gave a number of hours, and maybe even that’s not enough time. \nThe bottom line is that if an AI is really convincing you that it’s human, then it \npasses the test. We can debate how long that needs to be—probably several hours \nif you have a sophisticated judge—but I agree that if the time is too short, then \nyou might get away with simple tricks. \nMARTIN FORD: I think it’s easy to imagine an intelligent computer that just isn’t \nvery good at pretending to be human because it would be an alien intelligence. So, \nit seems likely that you could have a test where everyone agreed that the machine \nwas intelligent, even though it didn’t actually seem to be human. And we would \nprobably want to recognize that as an adequate test as well. \nRAY KURZWEIL: Whales and octopi have large brains and they exhibit intelligent \nbehavior, but they’re obviously not in a position to pass the Turing test. A Chinese \nperson who speaks mandarin and not English would not pass the English Turing \ntest, so there are lots of ways to be intelligent without passing the test. The key \nstatement is the converse: In order to pass the test, you have to be intelligent. \nMARTIN FORD: Do you believe that deep learning, combined with your hierarchical \napproach, is really the way forward, or do you think there needs to be some other \nmassive paradigm shift in order to get us to AGI/human-level intelligence?\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 412
  },
  {
    "chunk_full": "RAY KURZWEIL\n233\nRAY KURZWEIL: No, I think humans use this hierarchical approach. Each of these \nmodules is capable of doing learning, and I actually make the case in my book that \nin the brain they’re not doing deep learning in each module, they’re doing something \nequivalent to a Markov process, but it actually is better to use deep learning. \nIn our systems at Google we use deep learning to create vectors that represent the \npatterns in each module and then we have a hierarchy that goes beyond the deep \nlearning paradigm. I think that’s sufficient for AGI, though. The hierarchical approach \nis how the human brain does it in my view, and there’s a lot of evidence now for \nthat from the brain reverse engineering projects. \nThere’s an argument that human brains follow a rule-based system rather than \na connectionist one. People point out that humans are capable of having sharp \ndistinctions and we’re capable of doing logic. A key point is that connectionism can \nemulate a rule-based approach. A connectionist system in a certain situation might \nbe so certain of its judgment that it looks and acts like a rule-based system, but \nthen it’s also able to deal with rare exceptions and the nuances of its apparent rules. \nA rule-based system really cannot emulate a connectionist system, so the \nconverse statement is not the case. Doug Lenat’s “Cyc” is an impressive project, \nbut I believe that it proves the limitations of a rule-based system. You reach a \ncomplexity ceiling, where the rules get so complex that if you try to fix one \nthing, you break three other things. \nMARTIN FORD: Cyc is the project where people are manually trying to enter logic \nrules for common sense?\nRAY KURZWEIL: Right. I’m not sure of the count, but they have a vast number of \nrules. They had a mode where it could print out its reasoning for a behavior and \nthe explanations would go on for a number of pages and are very hard to follow. \nIt’s impressive work, but it does show that this is really not the approach, at least \nnot by itself, and it’s not how humans achieve intelligence. We don’t have cascades \nof rules that we go through, we have this hierarchical self-organizing approach. \nI think another advantage of a hierarchical, but connectionist approach is that it’s \nbetter at explaining itself because you can look at the modules in the hierarchy \nand see which module influences which decision. When you have these massive \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 413
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n234\n100-layer neural nets, they act like a big black box. It’s very hard to understand \nits reasoning, though there have been some attempts to do that. I do think that \nthis hierarchical spin on a connectionist approach is an effective approach, and \nthat’s how humans think. \nMARTIN FORD: There are some structures, though, in the human brain, even at \nbirth. For example, babies can recognize faces.\nRAY KURZWEIL: We do have some feature generators. For example, in our brains \nwe have this module called the fusiform gyrus that contains specialized circuitry and \ncomputes certain ratios, like the ratio of the tip of the nose to the end of the nose, \nor the distance between the eyes. There is set of a dozen or so fairly simple features, \nand experiments have shown that if we generate those features from images and then \ngenerate new images that have the same features—the same ratios—then people will \nimmediately recognize them as a picture of that same person, even though other \ndetails have changed quite a bit in the image. There are various feature generators \nlike that, some with audio information that we compute certain ratios and recognize \npartial overtones, and these features then feed into the hierarchical connectionist \nsystem. So, it is important to understand these feature generators, and there are \nsome very specific features in recognizing faces, and that’s what babies rely on. \nMARTIN FORD: I’d like to talk about the path and the timing for Artificial General \nIntelligence (AGI). I’m assuming AGI and human-level AI are equivalent terms. \nRAY KURZWEIL: They’re synonyms, and I don’t like the term AGI because I think \nit’s an implicit criticism of AI. The goal of AI has always been to achieve greater and \ngreater intelligence and ultimately to reach human levels of intelligence. As we’ve \nprogressed, though, we’ve spun off separate fields. For example, once we mastered \nrecognizing characters, it became the separate field of OCR. The same happened \nwith speech recognition and robotics, and it was felt that the overarching field of \nAI was no longer focusing on general intelligence. My view is always that we’ll get \nto general intelligence step by step by solving one problem at a time. \nAnother bit of color on that is that human performance in any type of task is a \nvery broad range. What is the human performance level in Go? It’s a broad range \nfrom a child who’s playing their first game to the world champion. One thing \nwe’ve seen is that once a computer can achieve human levels, even at the low end \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 414
  },
  {
    "chunk_full": "RAY KURZWEIL\n235\nof that range, it very quickly soars past human performance. A little over a year \nago computers were playing at a low-level in Go and then they quickly soared past \nthat. More recently, AlphaZero soared past AlphaGo and beat it 100 games to 0, \nafter training for a few hours. \nComputers are also improving in their language understanding, but not at the \nsame rate, because they don’t yet have sufficient real-world knowledge. Computers \ncurrently can’t do multi-chain reasoning very well, basically taking inferences from \nmultiple statements while at the same time considering real-world knowledge. \nFor example, on a third-grade language understanding test, a computer didn’t \nunderstand that if a boy had muddy shoes he probably got them muddy by walking \nin the mud outside and if he got the mud on the kitchen floor it would make \nhis mother mad. That may all seem obvious to us humans because we may have \nexperienced that, but it’s not obvious to the AI. \nI don’t think the process will be as quick to go from the average adult \ncomprehension performance that we have now for computers on some language \ntests to superhuman performance because I think there are more fundamental \nissues to solve to do that. Nonetheless, human performance is a broad range, as \nwe’ve seen, and once computers get in that range they can ultimately soar past \nit to become superhuman. The fact that they’re performing at any kind of adult \nlevel in language understanding is very impressive because I feel that language \nrequires the full range of human intelligence, and has the full range of human \nambiguity and hierarchical thinking. To sum up, yes, AI is making very rapid \nprogress and yes, all of this is using connectionist approaches. \nI just had a discussion with my team here about what we have to do to pass \nthe Turing test beyond what we’ve already done. We already have some level of \nlanguage understanding. One key requirement is multi-chain reasoning—being \nable to consider the inferences and implications of concepts—that’s a high priority. \nThat’s one area where chatbots routinely fail. \nIf I say I’m worried about my daughter’s performance in nursery school, you wouldn’t \nwant to then ask three turns later, do you have any children? Chatbots do that kind \nof thing because they’re not considering all the inferences of everything that has been \nsaid. As I mentioned, there is also the issue of real-world knowledge, but if we could \nunderstand all the implications of language, then real-world knowledge could be gained \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 415
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n236\nby reading and understanding the many documents available online. I think we have \nvery good ideas on how to do those things and we have plenty of time to do them. \nMARTIN FORD: You’ve been very straightforward for a long time that the year when \nyou think human-level AI is going to arrive is 2029. Is that still the case?\nRAY KURZWEIL: Yes. In my book, The Age of Intelligent Machines, which came out in \n1989, I put a range around 2029 plus or minus a decade or so. In 1999 I published \nThe Age of Spiritual Machines and made the specific prediction of 2029. Stanford \nUniversity held a conference of AI experts to deal with this apparently startling \nprediction. At that time, we didn’t have instant polling machines, so we basically \nhad a show of hands. The consensus view then was it would take hundreds of years, \nwith about a quarter of the group saying it would never happen. \nIn 2006 there was a conference at Dartmouth College celebrating the 50th \nanniversary of the 1956 Dartmouth conference, which I mentioned earlier, and \nthere we did have instant polling devices and the consensus was about 50 years. 12 \nyears later, in 2018 the consensus view now is about 20 to 30 years, so anywhere \nfrom 2038 to 2048, so I’m still more optimistic than the consensus of AI experts, \nbut only slightly. My view and the consensus view of AI experts is getting closer \ntogether, but not because I’ve changed my view. There’s a growing group of people \nwho think I’m too conservative.\nMARTIN FORD: 2029 is only 11 years away, which is not that far away really. I have \nan 11-year-old daughter, which really brings it into focus.\nRAY KURZWEIL: The progress is exponential; look at the startling progress just \nin the last year. We’ve made dramatic advances in self-driving cars, language \nunderstanding, playing Go and many other areas. The pace is very rapid, both in \nhardware and software. In hardware, the exponential progression is even faster than \nfor computation generally. We have been doubling the available computation for \ndeep learning every three months over the past few years, compared to a doubling \ntime of one year for computation in general.\nMARTIN FORD: Some very smart people with a deep knowledge of AI are still \npredicting that it will take over 100 years, though. Do you think that is because \nthey are falling into that trap of thinking linearly?\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 416
  },
  {
    "chunk_full": "RAY KURZWEIL\n237\nRAY KURZWEIL: A) they are thinking linearly, and B) they are subject to what I call \nthe engineer’s pessimism—that is being so focused on one problem and feeling that \nit’s really hard because they haven’t solved it yet, and extrapolating that they alone \nare going to solve the problem at the pace they’re working on. It’s a whole different \ndiscipline to consider the pace of progress in a field and how ideas interact with each \nother and study that as a phenomenon. Some people are just not able to grasp the \nexponential nature of progress, particularly when it comes to information technology. \nHalfway through the human genome project, 1% had been collected after 7 years, \nand mainstream critics said, “I told you this wasn’t going to work. 1% in 7 years \nmeans it’s going to take 700 years, just like we said.” My reaction was, “We finished \none percent—We’re almost done. We’re doubling every year. 1% is only 7 doublings \nfrom 100%.” And indeed, it was finished 7 years later. \nA key question is why do some people readily get this, and other people don’t? It’s \ndefinitely not a function of accomplishment or intelligence. Some people who are \nnot in professional fields understand this very readily because they can experience \nthis progress just in their smartphones, and other people who are very accomplished \nand at the top of their field just have this very stubborn linear thinking. So, I really \ndon’t actually have an answer for that.\nMARTIN FORD: You would agree though that it’s not just about exponential \nprogress in terms of computing speed or memory capacity? There are clearly some \nfundamental conceptual breakthroughs that have to happen in terms of teaching \ncomputers to learn from real time, unstructured data the way that human beings \ndo, or in reasoning and imagination?\nRAY KURZWEIL: Well, progress in software is also exponential, even though it \nhas that unpredictable aspect that you’re alluding to. There’s a cross-fertilization of \nideas that is inherently exponential, and once we have established performance at \none level, ideas emerge to get to the next level. \nThere was a study done by the Obama administration scientific advisory board \non this question. They examined how hardware and software progress compares. \nThey took a dozen classical engineering and technical problems and looked at the \nadvance quantitatively to see how much was attributable to hardware. Generally, \nover the previous 10 years from that point, it was about 1,000 to 1 in hardware, \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 417
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n238\nwhich is consistent with the implication of doubling in price performance every \nyear. The software, as you might expect, varied, but in every case, it was greater \nthan the hardware. Advances tend to be exponential. If you make an advance in \nsoftware, it doesn’t progress linearly; it progresses exponentially. On the overall \nprogress is the product of the progress in hardware and software. \nMARTIN FORD: The other date that you’ve given as a projection is 2045 for \nwhat you referred to as the singularity. I think most people associate that with an \nintelligence explosion or the advent of a true superintelligence. Is that the right \nway to think about it? \nRAY KURZWEIL: There are actually two schools of thought on the singularity: there’s \na hard take off school and a soft take off school. I’m actually in the soft take off school \nthat says we will continue to progress exponentially, which is daunting enough. The \nidea of an intelligence explosion is that there is a magic moment where a computer \ncan access its own design and modify it and create a smarter version of itself, and that \nit keeps doing that in a very fast iterative loop and just explodes in its intelligence. \nI think we’ve actually been doing that for thousands of years, ever since we created \ntechnology. We are certainly smarter as a result of our technology. Your smartphone \nis a brain extender, and it does make us smarter. It’s an exponential process. A \nthousand years ago paradigm shifts and advances took centuries, and it looked like \nnothing was happening. Your grandparents lived the same lives you did, and you \nexpected your grandchildren to do the same. Now, we see changes on an annual \nbasis if not faster. It is exponential and that results in an acceleration of progress, \nbut it’s not an explosion in that sense.\nI think we will achieve a human level of intelligence by 2029 and it’s immediately \ngoing to be superhuman. Take for example our Talk to Books, you ask it a question \nand it reads 600 million sentences, 100,000 books, in half a second. Personally, it \ntakes me hours to read 100,000 books!\nYour smartphone right now is able to do searching based on keywords and other \nmethods and search all human knowledge very quickly. Google search already goes \nbeyond keyword search and has some semantic capability. The semantic understanding \nis not yet at human levels, but it’s a billion times faster than human thinking. And \nboth the software and the hardware will continue to improve at an exponential pace.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 418
  },
  {
    "chunk_full": "RAY KURZWEIL\n239\nMARTIN FORD: You’re also well known for your thoughts on using technology to \nexpand and extend human life. Could you let me know more about that?\nRAY KURZWEIL: One thesis of mine is that we’re going to merge with the \nintelligent technology that we are creating. The scenario that I have is that we will \nsend medical nanorobots into our bloodstream. One application of these medical \nnanorobots will be to extend our immune systems. That’s what I call the third bridge \nto radical life extension. The first bridge is what we can do now, and bridge two \nis the perfecting of biotechnology and reprogramming the software of life. Bridge \nthree constitutes these medical nanorobots to perfect the immune system. These \nrobots will also go into the brain and provide virtual and augmented reality from \nwithin the nervous system rather than from devices attached to the outside of our \nbodies. The most important application of the medical nanorobots is that we will \nconnect the top layers of our neocortex to synthetic neocortex in the cloud. \nMARTIN FORD: Is this something that you’re working on at Google? \nRAY KURZWEIL: The projects I have done with my team here at Google use what I \nwould call crude simulations of the neocortex. We don’t have a perfect understanding \nof the neocortex yet, but we’re approximating it with the knowledge we have now. \nWe are able to do interesting applications with language now, but by the early 2030s \nwe’ll have very good simulations of the neocortex. \nJust as your phone makes itself a million times smarter by accessing the cloud, we \nwill do that directly from our brain. It’s something that we already do through our \nsmartphones, even though they’re not inside our bodies and brains, which I think \nis an arbitrary distinction. We use our fingers and our eyes and ears, but they \nare nonetheless brain extenders. In the future, we’ll be able to do that directly \nfrom our brains, but not just to perform tasks like search and language translation \ndirectly from our brains, but to actually connect the top layers of our neocortex \nto synthetic neocortex in the cloud. \nTwo million years ago, we didn’t have these large foreheads, but as we evolved \nwe got a bigger enclosure to accommodate more neocortex. What did we do \nwith that? We put it at the top of the neocortical hierarchy. We were already \ndoing a very good job at being primates, and now we were able to think at an \neven more abstract level. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 419
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n240\nThat was the enabling factor for us to invent technology, science, language, and \nmusic. Every human culture that we have discovered has music, but no primate \nculture has music. Now that was a one-shot deal, we couldn’t keep growing the \nenclosure because birth would have become impossible. This neocortical expansion \ntwo million years ago actually made birth pretty difficult as it was. \nThis new extension in the 2030s to our neocortex will not be a one-shot deal. \nEven as we speak, the cloud is doubling in power every year. It’s not limited by \na fixed enclosure, so the non-biological portion of our thinking will continue to \ngrow. If we do the math, we will multiply our intelligence a billion-fold by 2045, \nand that’s such a profound transformation that it’s hard to see beyond that event \nhorizon. So, we’ve borrowed this metaphor from physics of the event horizon and \nthe difficulty of seeing beyond it.\nTechnologies such as Google Search and Talk to Books are at least a billion times \nfaster than humans. It’s not at human levels of intelligence yet, but once we get \nto that point, AI will take advantage of the enormous speed advantage which \nalready exists and an ongoing exponential increase in capacity and capability. \nSo that’s the meaning of the singularity, it’s a soft take off, but exponentials \nnonetheless become quite daunting. If you double something 30 times, you’re \nmultiplying by a billion. \nMARTIN FORD: One of the areas where you’ve talked a lot about the singularity \nhaving an impact is in medicine and especially in the longevity of human life, and \nthis is maybe one area where you’ve been criticized. I heard a presentation you \ngave at MIT last year where you said that within 10 years, most people might be \nable to achieve what you call “longevity escape velocity,” and you also said that \nyou think you personally might have achieved that already? Do you really believe \nit could happen that soon?\nRAY KURZWEIL: We are now at a tipping point in terms of biotechnology. \nPeople look at medicine, and they assume that it is just going to plod along \nat the same hit or miss pace that they have been used to in the past. Medical \nresearch has essentially been hit or miss. Drug companies will go through a \nlist of several thousand compounds to find something that has some impact, \nas opposed to actually understanding and systematically reprogramming the \nsoftware of life.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 420
  },
  {
    "chunk_full": "RAY KURZWEIL\n241\nIt’s not just a metaphor to say that our genetic processes are software. It is a string \nof data, and it evolved in an era where it was not in the interest of the human \nspecies for each individual to live very long because there were limited resources \nsuch as food. We are transforming from an era of scarcity to an era of abundance\nEvery aspect of biology as an information process has doubled in power every year. \nFor example, genetic sequencing has done that. The first genome cost US $1 billion, \nand now we’re close to $1,000. But our ability to not only collect this raw object \ncode of life but to understand it, to model it, to simulate it, and most importantly \nto reprogram it, is also doubling in power every year. \nWe’re now getting clinical applications—it’s a trickle today, but it’ll be a flood \nover the next decade. There are hundreds of profound interventions in process \nthat are working their way through the regulatory pipeline. We can now fix a \nbroken heart from a heart attack, that is, rejuvenate a heart with a low ejection \nfraction after a heart attack using reprogrammed adult stem cells. We can grow \norgans and are installing them successfully in primates. Immunotherapy is basically \nreprogramming the immune system. On its own, the immune system does not go \nagainst cancer because it did not evolve to go after diseases that tend to get us \nlater on in life. We can actually reprogram it and turn it on to recognize cancer \nand treat it as a pathogen. This is a huge bright spot in cancer treatment, and there \nare remarkable trials where virtually every person in the trial goes from stage 4 \nterminal cancer to being in remission.\nMedicine is going to be profoundly different in a decade from now. If you’re \ndiligent, I believe you will be able to achieve longevity escape velocity, which \nmeans that we’ll be adding more time than is going by, not just to infant life \nexpectancy but to your remaining life expectancy. It’s not a guarantee, because \nyou can still be hit by the proverbial bus tomorrow, and life expectancy is \nactually a complicated statistical concept, but the sands of time will start \nrunning in rather than running out. In another decade further out, we’ll be \nable to reverse aging processes as well. \nMARTIN FORD: I want to talk about the downsides and the risks of AI. I would \nsay that sometimes you are unfairly criticized as being overly optimistic, maybe \neven a bit Pollyannaish, about all of this. Is there anything we should worry about \nin terms of these developments?\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 421
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n242\nRAY KURZWEIL: I’ve written more about the downsides than anyone, and this was \ndecades before Stephen Hawking or Elon Musk were expressing their concerns. There \nwas extensive discussion of the downsides of GNR—Genetics, Nanotechnology, and \nRobotics (which means AI)—in my book, The Age of Spiritual Machines, which came \nout in 1999 that led Bill Joy to write his famous Wired cover story in January 2000 \ntitled, Why the Future Doesn’t Need Us.\nMARTIN FORD: That was based upon a quote from Ted Kaczynski, the \nUnabomber, wasn’t it?\nRAY KURZWEIL: I have a quote from him on one page that sounds like a very \nlevel-headed expression of concern, and then you turn the page, and you see that \nthis is from the Unabomber Manifesto. I discussed in quite some detail in that \nbook the existential risk of GNR. In my 2005 book, The Singularity is Near, I go \ninto the topic of GNR risks in a lot of detail. Chapter 8 is titled, “The Deeply \nIntertwined Promise versus Peril of GNR.”\nI’m optimistic that we’ll make it through as a species. We get far more profound \nbenefit than harm from technology, but you don’t have to look very far to see the \nprofound harm that has manifested itself, for example, in all of the destruction in \nthe 20th century—even though the 20th century was actually the most peaceful \ncentury up to that time, and we’re in a far more peaceful time now. The world is \ngetting profoundly better, for example, poverty has been cut 95% in the last 200 \nyears and literacy rates have gone from under 10% to over 90% in the world. \nPeople’s algorithm for whether the world is getting better or worse is “how often \ndo I hear good news versus bad news?”, and that’s not a very good method. There \nwas a poll taken of 24,000 people in about 26 countries asking this question, “Is \npoverty worldwide getting better or worse over the last 20 years?” 87% said, \nincorrectly, that it’s getting worse. Only 1% said correctly that it’s fallen by half \nor more in the last 20 years. Humans have an evolutionary preference for bad news. \n10,000 years ago, it was very important that you paid attention to bad news, for \nexample that little rustling in the leaves that might be a predator. That was more \nimportant to pay attention to than studying that your crops are half a percent better \nthan last year, and we continue to have this preference for bad news. \nMARTIN FORD: There’s a step-change, though, between real risks and existential risks.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 422
  },
  {
    "chunk_full": "RAY KURZWEIL\n243\nRAY KURZWEIL: Well, we’ve also done reasonably well with existential risks from \ninformation technology. Forty years ago, a group of visionary scientists saw both \nthe promise and the peril of biotechnology, neither of which was close at hand at \nthe time, and they held the first Asilomar Conference on biotechnology ethics. \nThese ethical standards and strategies have been updated on a regular basis. That \nhas worked very well. The number of people who have been harmed by intentional \nor accidental abuse or problems with biotechnology has been close to zero. We’re \nnow beginning to get the profound benefit that I alluded to, and that’s going to \nbecome a flood over the next decade. \nThat’s a success for this approach of comprehensive ethical standards, and technical \nstrategies on how to keep the technology safe, and much of that is now baked into \nlaw. That doesn’t mean we can cross danger from biotechnology off our list of \nconcerns; we keep coming up with more powerful technologies like CRISPR and \nwe have to keep reinventing the standards. \nWe had our first AI ethics Asilomar conference about 18 months ago where we came \nup with a set of ethical standards. I think they need further development, but it’s \nan overall approach that can work. We have to give it a high priority. \nMARTIN FORD: The concern that’s really getting a lot of attention right now is what’s \ncalled the control problem or the alignment problem, where a superintelligence \nmight not have goals that are aligned with what’s best for humanity. Do you take \nthat seriously, and should work be done on that? \nRAY KURZWEIL: Humans don’t all have aligned goals with each other, and that’s \nreally the key issue. It’s a misconception to talk about AI as a civilization apart, as \nif it’s an alien invasion from Mars. We create tools to extend our own reach. We \ncouldn’t reach food at that higher branch 10,000 years ago, so we made a tool that \nextended our reach. We can’t build a skyscraper with our bare hands, so we have \nmachines that leverage the range of our muscles. A kid in Africa with a smartphone \nis connected to all of the human knowledge with a few keystrokes. \nThat is the role of technology; it enables us to go beyond our limitations, and that’s \nwhat we are doing and will continue to do with AI. It’s not us versus the AIs, \nwhich has been the theme of many AI futurist dystopian movies. We are going to \nmerge with it. We already have. The fact that your phone is not physically inside \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 423
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n244\nyour body and brain is a distinction without a difference, because it may as well \nbe. We don’t leave home without it, we’re incomplete without it, nobody could do \ntheir work, get their education, or keep their relationships without their devices \ntoday, and we’re getting more intimate with them. \nI went to MIT because it was so advanced in 1965 that it had a computer. I had \nto take my bicycle across the campus to get to it and show my ID to get into the \nbuilding, and now half a century later we’re carrying them in our pockets, and \nwe’re using them constantly. They are integrated into our lives and will ultimately \nbecome integrated into our bodies and brains. \nIf you look at the conflict and warfare we’ve had over the millennia, it’s been from \nhumans having disagreements. I do think technology tends to actually create greater \nharmony and peace and democratization. You can trace the rise of democratization to \nimprovements in communication. Two centuries ago, there was only one democracy \nin the world. There were half a dozen democracies one century ago. Now there are \n123 democracies out of 192 recognized countries, that’s 64% of the world. The \nworld’s not a perfect democracy, but democracy has actually been accepted as the \nstandard today. It is the most peaceful time in human history, and every aspect of \nlife is getting better, and this is due to the effect of technology which is becoming \nincreasingly intelligent, and it’s deeply integrated into who we are. \nWe have conflict today between different groups of humans, each of whom are \namplified by their technology. That will continue to be the case, although I think \nthere’s this other theme that better communication technology harnesses our short-\nrange empathy. We have a biological empathy for small groups of people, but that’s \nnow amplified by our ability to actually experience what happens to people half a \nworld away. I think that’s the key issue; we still have to manage our human relations \nas we increase our personal powers through technology.\nMARTIN FORD: Let’s talk about the potential for economic and job market \ndisruption. I personally do think there’s a lot of potential for jobs to be lost or \ndeskilled and for greatly increasing inequality. I actually think it could be something \nthat will be disruptive on the scale of a new Industrial Revolution.\nRAY KURZWEIL: Let me ask you this: how did that last Industrial Revolution \nwork out? Two hundred years ago, the weavers had enjoyed a guild that was \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 424
  },
  {
    "chunk_full": "RAY KURZWEIL\n245\npassed down from generation to generation for hundreds of years. Their business \nmodel was turned on its head and disrupted when all these thread-spinning and \ncloth-weaving machines came out that completely upended their livelihoods. They \npredicted that more machines would come out and that most people would lose \ntheir jobs, and that employment would be enjoyed just by an elite. Part of that \nprediction came true—more textile machines were introduced and many types \nof skills and jobs were eliminated. However, employment went up, not down as \nsociety became more prosperous. \nIf I were a prescient futurist in 1900 I would point out that 38% of you work on \nfarms and 25% of you work in factories, but I predict that 115 years from now, \nin 2015, that’ll be 2% on farms, and 9% in factories. Everybody’s reaction would \nbe, “Oh my god I’m going to be out of work!” I would then say “Don’t worry, the \njobs that are eliminated are at the bottom of the skill ladder, and we are going to \ncreate an even larger number of jobs at the top of the skill ladder.” \nPeople would say, “Oh really, what new jobs?”, and I’d say, “Well I don’t know, \nwe haven’t invented them yet.” People say we’ve destroyed many more jobs than \nwe’ve created but that’s not true, we’ve gone from 24 million jobs in 1900 to \n142 million jobs today, and as a percentage of the population that goes from 31% \nto 44%. How do these new jobs compare? Well, for one thing, the average job \ntoday pays 11 times as much in constant dollars per hour than in 1900. As a \nresult, we’ve shortened the work year from about 3,000 hours to 1,800 hours. \nPeople still make 6 times as much per year in constant dollars, and the jobs have \nbecome much more interesting. I think that’s going to continue to be the case \neven in the next Industrial Revolution. \nMARTIN FORD: The real question is whether this time it’s different. What you say \nabout what happened previously is certainly true, but it is also true, according to \nmost estimates, that maybe half or more of the people in the workforce are doing \nthings that are fundamentally predictable and relatively routine, and all those jobs \nare going to be potentially threatened by machine learning. Automating most of \nthose predictable jobs does not require human-level AI. \nThere may be new kinds of work created for robotics engineers and deep \nlearning researchers and all of that, but you cannot take all the people that are \nnow flipping hamburgers or driving taxis and realistically expect to transition \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 425
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n246\nthem into those kinds of jobs, even assuming that there are going to be a \nsufficient number of these new jobs. We’re talking about a technology that \ncan displace people cognitively, displace their brainpower, and it’s going to be \nextraordinarily broad-based.\nRAY KURZWEIL: Your model that’s implicit in your prediction is us-versus-them, \nand what are the humans going to do versus the machines. We’ve already made \nourselves smarter in order to do these higher-level types of jobs. We’ve made \nourselves smarter not with things connected directly into our brains yet, but with \nintelligent devices. Nobody can do their jobs without these brain extenders, and \nthe brain extenders are going to extend our brains even further, and they’re going \nto be more closely integrated into our lives.\nOne thing that we did to improve our skills is education. We had 68,000 college \nstudents in 1870 and today we have 15 million. If you take them and all the \npeople that service them, such as faculty and staff, it is about 20 percent of \nthe workforce that is just involved in higher education, and we are constantly \ncreating new things to do. The whole app economy did not exist about six \nyears ago, and that forms a major part of the economy today. We’re going to \nmake ourselves smarter. \nA whole other thesis that needs to be looked at in considering this question is the \nradical abundance thesis that I mentioned earlier. I had an on-stage dialogue with \nChristine Lagarde, the managing director of the IMF, at the annual International \nMonetary Fund meeting and she said, “Where’s the economic growth associated \nwith this? The digital world has these fantastic things, but fundamentally you can’t \neat information technology, you can’t wear it, you can’t live in it,” and my response \nwas, “All that’s going to change.”\n“All those types of nominally physical products are going to become an information \ntechnology. We’re going to grow food with vertical agriculture in AI-controlled \nbuildings with hydroponic fruits and vegetables, and in vitro cloning of muscle \ntissue for meat, providing very high-quality food without chemicals at very low \ncost, and without animal suffering. Information technology has a 50% deflation \nrate; you get the same computation, communication, genetic sequencing that you \ncould purchase a year ago for half the price, and this massive deflation is going to \nattend to these traditionally physical products.” \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 426
  },
  {
    "chunk_full": "RAY KURZWEIL\n247\nMARTIN FORD: So, you think that technologies like 3D printing or robotic factories \nand agriculture could drive costs down for nearly everything?\nRAY KURZWEIL: Exactly, 3D printing will print out clothing in the 2020s. We’re not \nquite there yet for various reasons, but all that’s moving in the right direction. The other \nphysical things that we need will be printed out on 3D printers, including modules \nwhich will snap together a building in a matter of days. All the physical things we \nneed will ultimately become facilitated by these AI-controlled information technologies. \nSolar energy is being facilitated by applying deep learning to come up with better \nmaterials, and as a result, the cost of both energy storage and energy collection \nis coming down rapidly. The total amount of solar energy is doubling every two \nyears, and the same trend exists with wind energy. Renewable energy is now only \nabout five doublings, at two years per doubling, away from meeting 100% of our \nenergy needs, by which time it will use one part in thousands of the energy from \nthe sun or from the wind. \nChristine Lagarde said, “OK, there is one resource that will never be an information \ntechnology, and that’s land. We are already crowded together.” I responded “That’s \nonly because we decided to crowd ourselves together and create cities so we \ncould work and play together.” People are already spreading out as our virtual \ncommunication becomes more robust. Try taking a train trip anywhere in the world \nand you will see that 95% of the land is unused. \nWe’re going be able to provide a very high quality of living that’s beyond what \nwe consider a high standard of living today for everyone, for all of the human \npopulation, as we get to the 2030s. I made a prediction at TED that we will have \nuniversal basic income, which won’t actually need to be that much to provide a \nvery high standard of living, as we get into the 2030s. \nMARTIN FORD: So, you’re a proponent of a basic income, eventually? You agree that \nthere won’t be a job for everyone, or maybe everyone won’t need a job, and that \nthere’ll be some other source of income for people, like a universal basic income?\nRAY KURZWEIL: We assume that a job is a road to happiness. I think the key \nissue will be purpose and meaning. People will still compete to be able to \ncontribute and get gratification.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 427
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n248\nMARTIN FORD: But you don’t necessarily have to get paid for the thing that \nyou get meaning from? \nRAY KURZWEIL: I think we will change the economic model and we are already \nin the process of doing that. I mean, being a student in college is considered a \nworthwhile thing to do. It’s not a job, but it’s considered a worthwhile activity. \nYou won’t need income from a job in order to have a very good standard of living \nfor the physical requirements of life, and we will continue to move up Maslow’s \nhierarchy. We have been doing that, just compare today to 1900. \nMARTIN FORD: What do you think about the perceived competition with China to \nget to advanced AI? China does have advantages in terms of having less regulation \non things like privacy. Plus, their population is so much larger, which generates \nmore data and also means they potentially have a lot more young Turings or von \nNeumanns in the pipeline.\nRAY KURZWEIL: I don’t think it’s a zero-sum game. An engineer in China who \ncomes up with a breakthrough in solar energy or in deep learning benefits all \nof us. China is publishing a lot just as the United States is, and the information \nis actually shared pretty widely. Look at Google, which put its TensorFlow deep \nlearning framework into the public domain, and we did that in our group with \nthe technology underlying Talk to Books and Smart Reply being made open source \nso people can use that. \nI personally welcome the fact that China is emphasizing economic development \nand entrepreneurship. When I was in China recently the tremendous explosion \nof entrepreneurship was apparent. I would encourage China to move in the \ndirection of free exchange of information. I think that’s fundamental for this type \nof progress. All around the world we see Silicon Valley as a motivating model. \nSilicon Valley really is just a metaphor for entrepreneurship, the celebrating of \nexperimenting, and calling failure experience. I think that’s a good thing, I really \ndon’t see it as an international competition. \nMARTIN FORD: But do you worry about the fact that China is an authoritarian state, \nand that these technologies do have, for example, military applications? Companies \nlike Google and certainly DeepMind in London have been very clear that they don’t \nwant their technology used in anything that is even remotely military. Companies like \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 428
  },
  {
    "chunk_full": "RAY KURZWEIL\n249\nTencent and Baidu in China don’t really have the option to make that choice. Is that \nsomething we should worry about, that there’s a kind of asymmetry going forward?\nRAY KURZWEIL: Military use is a different issue from authoritarian government \nstructure. I am concerned about the authoritarian orientation of the Chinese government, \nand I would encourage them to move toward greater freedom of information and \ndemocratic ways of governing. I think that will help them and everyone economically. \nI think these political and social and philosophical issues remain very important. My \nconcern is not that AI is going to go off and do something on its own, because I \nthink it’s deeply integrated with us. I’m concerned about the future of the human \npopulation, which is already a human technological civilization. We’re going to \ncontinue to enhance ourselves through technology, and so the best way to assure \nthe safety of AI is to attend to how we govern ourselves as humans.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 429
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n250\nRAY KURZWEIL is widely recognized as one of the world’s foremost inventors and futurists. \nRay received his engineering degree from MIT, where he was mentored by Marvin Minsky, \none of the founding fathers of the field of artificial intelligence. He went on to make major \ncontributions in a variety of areas. He was the principal inventor of the first CCD flat-bed \nscanner, the first omni-font optical character recognition, the first print-to-speech reading \nmachine for the blind, the first text-to-speech synthesizer, the first music synthesizer capable \nof recreating the grand piano and other orchestral instruments, and the first commercially \nmarketed large-vocabulary speech recognition. \nAmong Ray’s many honors, he received a Grammy Award for outstanding achievements in \nmusic technology; he is the recipient of the National Medal of Technology (the nation’s \nhighest honor in technology), was inducted into the National Inventors Hall of Fame, holds \ntwenty-one honorary doctorates, and honors from three US presidents. \nRay has written five national best-selling books, including New York Times bestsellers The \nSingularity Is Near (2005) and How To Create A Mind (2012). He is Co-Founder and \nChancellor of Singularity University and a Director of Engineering at Google, heading up a \nteam developing machine intelligence and natural language understanding. \nRay is known for his work on exponential progress in technology, which he has formalized \nas “The Law of Accelerating Returns.” Over the course of decades, he has made a number of \nimportant predictions that have proven to be accurate. \nRay’s first novel, Danielle, Chronicles of a Superheroine, is being published in early 2019. \nAnother book by Ray, The Singularity is Nearer, is expected to be published in late 2019. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 430
  },
  {
    "chunk_full": "RAY KURZWEIL\n251\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 431
  },
  {
    "chunk_full": "",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 432
  },
  {
    "chunk_full": "DANIELA RUS\n253\nDANIELA RUS\nDIRECTOR OF MIT CSAIL\nDaniela Rus is the Director of the Computer Science and Artificial Intelligence \nLaboratory (CSAIL) at MIT, one of the world’s largest research organizations \nfocused on AI and robotics. Daniela is a fellow of ACM, AAAI and IEEE, \nand a member of the National Academy of Engineering, and the American \nAcademy for Arts and Science. Daniela leads research in robotics, mobile \ncomputing, and data science.\nI like to think of a world where more mundane  \nroutine tasks are taken off your plate. Maybe \ngarbage cans that take themselves out and smart  \ninfrastructure to ensure that they disappear,  \nor robots that will fold your laundry.\n“ \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 433
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n254\nMARTIN FORD: Let’s start by talking about your background and looking at how \nyou became interested in AI and robotics.\nDANIELA RUS: I’ve always been interested in science and science fiction, and when \nI was a kid I read all the popular science fiction books at the time. I grew up in \nRomania where we didn’t have the range of media that you had in the US, but there \nwas one show that I really enjoyed, and that’s the original Lost in Space.\nMARTIN FORD: I remember that. You’re not the first person I’ve spoken to who \nhas drawn their career inspiration from science fiction.\nDANIELA RUS: I never missed an episode of Lost in Space, and I loved the cool \ngeeky kid Will and the robot. I didn’t imagine that I would do anything remotely \nassociated with that at that time. I was lucky enough to be quite good at math \nand science, and by the time I got to college age I knew that I wanted to do \nsomething with math, but not pure math because it seemed too abstract. I studied \ncomputer science with a major in computer science and mathematics, and a minor \nin astronomy—the astronomy continuing the connection to my fantasies of what \ncould be in other worlds. \nToward the end of my undergraduate degree I went to a talk given by John \nHopcroft, the Turing Award-winning theoretical computer scientist, and in that \ntalk, John said that classical computer science was finished. What he meant by that \nwas that many of the graph-theoretic algorithms that were posed by the founders \nof the field of computing had solutions and it was time for the grand applications, \nwhich in his opinion were robots.\nI found that an exciting idea, so I worked on my PhD with John Hopcroft because \nI wanted to make contributions to the field of robotics. However, at that time the \nfield of robotics was not at all developed. For example, the only robot that was \navailable to us was a big PUMA arm (Programmable Universal Manipulation Arm), \nan industrial manipulator that had little in common with my childhood fantasies \nof what robots should be. It got me thinking a lot about what I could contribute, \nand I ended up studying dexterous manipulation, but very much from a theoretical, \ncomputational point of view. I remember finishing my thesis and trying to implement \nmy algorithms to go beyond simulation and create real systems. Unfortunately, the \nsystems that were available at the time were the Utah/MIT hand and the Salisbury \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 434
  },
  {
    "chunk_full": "DANIELA RUS\n255\nhand, and neither one of those hands was able to exert the kind of forces and \ntorques that my algorithms required. \nMARTIN FORD: It sounds to me like there was a big gap between where the physical \nmachines were and where the algorithms were.\nDANIELA RUS: Exactly. At the time, I really realized that a machine is actually a \nclosed connection between body and brain, and for any task you want that machine \nto execute, you really needed a body capable of those tasks, and then you needed \na brain to control the body to deliver what it was meant to do. \nAs a result, I became very interested in the interaction between body and brain, and \nchallenging the notion of what a robot is. So industrial manipulators are excellent \nexamples of robots, but they are not all that we could do with robots; there are \nso many other ways to envision robots. \nToday in my lab, we have all kinds of very non-traditional robots. There are modular \ncellular robots, soft robots, robots built out of food, and even robots built out of \npaper. We’re looking at new types of materials, new types of shapes, new types of \narchitectures and different ways of imagining what the machine body ought to be. \nWe also do a lot of work on the mathematical foundations of how those bodies \noperate, and I’m very interested in understanding and advancing the engineering \nof both the science of autonomy and of intelligence.\nI became very interested in the connection between the hardware of the device \nand the algorithms that control the hardware. When I think about algorithms, I \nthink that while it’s very important to consider the solutions, it’s also important \nto consider the mathematical foundations for those solutions because that’s in some \nsense where we create the nuggets of knowledge that other people can build on. \nMARTIN FORD: You’re the director of the MIT Computer Science and Artificial \nIntelligence Laboratory (CSAIL), which is one of the most important research endeavors \nin not just robotics, but in AI generally. Could you explain what exactly CSAIL is? \nDANIELA RUS: Our objective at CSAIL is to invent the future of computing to \nmake the world better through computing, and to educate some of the best students \nin the world in research.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 435
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n256\nCSAIL is an extraordinary organization. When I was a student, I looked up to it \nas the Mount Olympus of technology and never imagined that I’d become a part \nof it. I like to think of CSAIL as the prophet for the future of computing, and the \nplace where people envision how computing can be used to make the world better. \nCSAIL actually has two parts, Computer Science (CS) and AI, both having a really \ndeep history. The AI side of our organization goes back to 1956 when the field was \ninvented and founded. In 1956, Marvin Minsky gathered his friends in New Hampshire \nwhere they spent a month, no doubt hiking in the woods, drinking wine and having \ngreat conversations, uninterrupted by social media, email, and smartphones. \nWhen they emerged from the woods, they told the world that they had coined a \nnew field of study: artificial intelligence. AI refers to the science and engineering of \ncreating machines that exhibit human-level skills in how they perceive the world; in \nhow they move in the world; in how they play games; in how they reason; in how \nthey communicate; and even, in how they learn. Our researchers at CSAIL have been \nthinking about these questions and making groundbreaking contributions ever since, \nand it’s an extraordinary privilege to be part of this community. \nThe computer science side goes back to 1963, when Bob Fano, a computer scientist \nand MIT professor, had the crazy idea that two people might use the same computer \nat the same time. You have to understand this was a big dream back then when \ncomputers were the size of rooms and you had to book time on them. Originally, \nit was set up as Project MAC, which stood for Machine-Aided Cognition, but there \nwas a joke that it was actually named MAC after Minsky and Corby (Fernando \n“Corby” Corbató), who were the two technical leads for the CS and the AI side. \nEver since the founding of the laboratory in 1963, our researchers have put a lot \nof effort into imagining what computing looks like and what it can accomplish. \nMany of the things that you take for granted today have their roots in the research \ndeveloped at CSAIL, such as the password, RSA encryption, the computer \ntime-sharing systems that inspired Unix, the optical mouse, object-oriented \nprogramming, speech systems, mobile robots with computer vision, the free \nsoftware movement, the list goes on. More recently CSAIL has been a leader in \ndefining the cloud and cloud computing, and in democratizing education through \nMassive Open Online Courses (MOOCs) and in thinking about security, privacy, \nand many other aspects of computing. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 436
  },
  {
    "chunk_full": "DANIELA RUS\n257\nMARTIN FORD: How big is CSAIL today?\nDANIELA RUS: CSAIL is the largest research laboratory at MIT, with over 1,000 \nmembers, and it cuts across 5 schools and 11 departments. CSAIL today has 115 \nfaculty members, and each of these faculty members has a big dream about computing, \nwhich is such an important part of our ethos here. Some of our faculty members \nwant to make computing better through algorithms, systems or networks, while others \nwant to make life better for humanity with computing. For example, Shafi Goldwasser \nwants to make sure that we can have private conversations over the internet; and Tim \nBerners-Lee wants to create a bill of rights, a Magna Carta of the World Wide Web. \nWe have researchers who want to make sure that if we get sick, the treatments that \nare available to us are personalized and customized to be as effective as they can be. \nWe have researchers who want to advance what machines can do: Leslie Kaelbling \nwants to make Lieutenant-Commander Data, and Russ Tedrake wants to make robots \nthat can fly. I want to make shape-shifting robots because I want to see a world with \npervasive robots that support us in our cognitive and physical tasks.\nThis aspiration is really inspired by looking back at history and observing that \nonly 20 years ago, computation was a task reserved for the expert few because \ncomputers were large, expensive, and difficult to handle, and it took knowledge to \nknow what to do with them. All of that changed a decade ago when smartphones, \ncloud computing, and social media came along. \nToday, so many people compute. You don’t have to be an expert in order to use \ncomputing, and you use computing so much that you don’t even know how much \nyou depend on it. Try to imagine a day in your life without the world wide web \nand everything that enables. No social media; no communication through email; \nno GPS; no diagnosis in hospitals; no digital media; no digital music; no online \nshopping. It’s just incredible to see how computation has permeated into the fabric \nof life. To me, this raises a very exciting and important question, which is: In this \nworld that has been so changed by computation, what might it look like with robots \nand cognitive assistants helping us with physical and cognitive tasks? \nMARTIN FORD: As a university-based organization, what’s the balance between \nwhat you would classify as pure research and things that are more commercial \nand that end up actually developing into products? Do you spin off startups or \nwork with commercial companies?\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 437
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n258\nDANIELA RUS: We don’t house companies; instead, we focus on training our \nstudents and giving them various options for what they could do when they graduate, \nwhether that be joining the academic life, going into high-tech industry, or becoming \nentrepreneurs. We fully support all of those paths. For example, say a student \ncreates a new type of system after several years of research, and all of a sudden \nthere is an immediate application for the system. This is the kind of technological \nentrepreneurship that we embrace, and hundreds of companies have been spun out \nof CSAIL research, but the actual companies do not get housed by CSAIL.\nWe also don’t create products, but that’s not to say we ignore them. We’re very \nexcited about how our work could be turned into products, but generally, our \nmission is really to focus on the future. We think about problems that are 5 to \n10 years out, and that’s where most of our work is, but we also embrace the \nideas that matter today. \nMARTIN FORD: Let’s talk about the future of robotics, which sounds like something \nyou spend a great deal of your time thinking about. What’s coming down the line \nin terms of future innovations? \nDANIELA RUS: Our world has already been transformed by robotics. Today, \ndoctors can connect with patients, and teachers can connect with students that \nare thousands of miles away. We have robots that help with packing on factory \nfloors, we’ve got networked sensors that we deploy to monitor facilities, and \nwe have 3D printing that creates customized goods. Our world has already been \ntransformed by advances in artificial intelligence and robotics, and when we \nconsider adding even more extensive capabilities from our AI and robot systems, \nextraordinary things will be possible. \nAt the high level, we have to picture a world where routine tasks will be taken \noff our plate because this is the sweet spot for where technology is today. These \nroutine tasks could be physical tasks or could be computational or cognitive tasks. \nYou already see some of that in the rise of machine learning applications for \nvarious industries, but I like to think of a world where more mundane routine \ntasks are taken off your plate. Maybe garbage cans that take themselves out \nand smart infrastructure to ensure that they disappear, or robots that will fold \nyour laundry. We will have transportation available in the same way that water \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 438
  },
  {
    "chunk_full": "DANIELA RUS\n259\nor electricity are available, and you will be able to go anywhere at any time. \nWe will have intelligent assistants who will enable us to maximize our time at \nwork and optimize our lives to live better and more healthily, and to work more \nefficiently. It will be extraordinary. \nMARTIN FORD: What about self-driving cars? When will I be able to call a robot \ntaxi in Manhattan and have it take me anywhere?\nDANIELA RUS: I’m going to qualify my answer and say that certain autonomous \ndriving technologies are available right now. Today’s solutions are good for certain \nlevel 4 autonomy situations (the penultimate level before full autonomy, as defined \nby the Society of Automotive Engineers). We already have robot cars that can \ndeliver people and packages, and that operate at low speeds in low-complexity \nenvironments where you have low interaction. Manhattan is a challenging case \nbecause traffic in Manhattan is super chaotic, but we do already have robot cars \nthat could operate in retirement communities or business campuses, or in general \nplaces where there is not too much traffic. Nevertheless, those are still real-world \nplaces where you can expect other traffic, other people, and other vehicles. \nNext, we have to think about how we extend this capability to make it applicable \nto bigger and more complex environments where you’ll face more complex \ninteractions at higher speeds. That technology is slowly coming, but there are \nstill some serious challenges ahead. For instance, the sensors that we use in \nautonomous driving today are not very reliable in bad weather. We’ve still got a \nlong way to go to reach level 5 autonomy where the car is fully autonomous in \nall weather conditions. These systems also have to be able to handle the kind of \ncongestion that you find in New York City, and we have to become much better at \nintegrating robot cars with human-driven cars. This is why thinking about mixed \nhuman/machine environments is very exciting and very important. Every year we \nsee gradual improvements in the technology but getting to a complete solution, \nif I was to estimate, could take another decade. \nThere are, though, specific applications where we will see autonomy used \ncommercially sooner than other applications. I believe that a retirement community \ncould use autonomous shuttles today. I believe that long-distance driving with \nautonomous trucks is coming soon. It’s a little bit simpler than driving in New \nYork, but it’s harder than what driving in a retirement community would look like \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 439
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n260\nbecause you have to drive at high speed, and there are a lot of corner cases and \nsituations where maybe a human driver would have to step in. Let’s say it’s raining \ntorrentially and you are on a treacherous mountain pass in the Rockies. To face that, \nyou need to have a collaboration between a really great sensor and control system, \nand the human’s reasoning and control capabilities. With autonomous driving on \nhighways, we will see patches of autonomy interleaved with human assistance, or \nvice versa, and that will be sooner than 10 years, for sure, maybe 5. \nMARTIN FORD: So in the next decade a lot of these problems would be solved, \nbut not all of them. Maybe the service would be confined to specified routes or \nareas that are really well mapped?\nDANIELA RUS: Well, not necessarily. Progress is happening. In our group we just \nreleased a paper that demonstrates one of the first systems capable of driving on \ncountry roads. So, on the one hand, the challenges are daunting, but on the other \nhand, 10 years is a long time. 20 years ago, Mark Weiser, who was the chief scientist \nat Xerox PARC, talked about pervasive computing and he was seen as a dreamer. \nToday, we have solutions for all of the situations he envisioned where computing \nwould be used, and how computing would support us. \nI want to be a technology optimist. I want to say that I see technology as something \nthat has the huge potential to unite people rather than divide people, and to empower \npeople rather than estrange people. In order to get there, though, we have to advance \nscience and engineering to make technology more capable and more deployable.\nWe also have to embrace programs that enable broad education and allow people \nto become familiar with technology to the point where they can take advantage \nof it and where anyone could dream about how their lives could be better by the \nuse of technology. That’s something that’s not possible with AI and robotics today \nbecause the solutions require expertise that most people don’t have. We need to \nrevisit how we educate people to ensure that everyone has the tools and the skills \nto take advantage of technology. The other thing that we can do is to continue to \ndevelop the technology side so that machines begin to adapt to people, rather than \nthe other way around.\nMARTIN FORD: In terms of ubiquitous personal robots that can actually do useful \nthings, it seems to me that the limiting factor is really dexterity. The cliché is \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 440
  },
  {
    "chunk_full": "DANIELA RUS\n261\nbeing able to ask a robot to go to the refrigerator and get you a beer. That’s a real \nchallenge in terms of the technology that we have today. \nDANIELA RUS: Yes, I think you’re right. We do currently see significantly greater \nsuccesses in navigation than in manipulation, and these are two major types of \ncapabilities for robots. The advances in navigation were enabled by hardware \nadvances. When the LIDAR sensor—the laser scanner—was introduced, all of a \nsudden, the algorithms that didn’t work with sonar started working, and that was \ntransformational. We now had a reliable sensor that control algorithms could use \nin a robust way. As a result of that, mapping, planning, and localization took off, \nand that fueled the great enthusiasm in autonomous driving. \nComing back to dexterity, on the hardware side, most of our robot hands still look \nlike they did 50 years ago. Most of our robot hands are still very rigid, industrial \nmanipulators with a two-pronged pincer, and we need something different. I \npersonally believe that we are getting closer because we are beginning to look at \nreimagining what a robot is. In particular, we have been working on soft robots \nand soft robot hands. We’ve shown that with soft robot hands—the kind that \nwe can design and build in my lab—we are able to pick up objects and handle \nobjects much more reliably and much more intuitively than what is possible with \ntraditional two-finger grasps.\nIt works as follows: if you have a traditional robot hand where the fingers are all \nmade out of metal, then they are capable of what is technically called “hard finger \ncontact”—you put your finger on the object you’re trying to grasp at one point, \nand that’s the point at which you can exert forces and torques. If you have that \nkind of a setup, then you really need to know the precise geometry of the object \nthat you’re trying to pick up. You then need to calculate very precisely where to \nput your fingers on the surface of the object so that all their forces and torques \nbalance out, and they can resist external forces and torques. This is called in technical \nliterature, “the force closure and form closure problem.” This problem requires very \nheavy computation, very precise execution, and very accurate knowledge of the \nobject that you’re trying to grasp. \nThat’s not something that humans do when they grasp an object. As an experiment, \ntry to grasp a cup with your fingernails—it is such a difficult task. As a human, \nyou have a perfect knowledge of the object and where it is located, but you will \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 441
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n262\nhave a difficult time with that. With soft fingers, you actually don’t need to know \nthe exact geometry of the object you’re trying to grasp because the fingers will \ncomply to whatever the object surface is. Contact along a wider surface area means \nthat you don’t have to think precisely about where to place the fingers in order to \nreliably envelop and lift the object. \nThat translates into much more capable robots and much simpler algorithms. As \na result, I’m very bullish about the future progress in grasping and manipulation. \nI think that soft hands, and in general, soft robots are going to be a very critical \naspect of advancement in dexterity, just like the laser scanner was a critical aspect \nof advancing the navigation capabilities of robots. \nThat goes back to my observation that machines are made up of bodies and brains. \nIf you change the body of the machine and you make it more capable, then you will \nbe able to use different types of algorithms to control that robot. I’m very excited \nabout soft robotics, and I’m very excited about the potential for soft robotics to \nimpact an area of robotics that has been stagnant for many years. A lot of progress \nhas been made in grasping and manipulation, but we do not have the kinds of \ncapabilities that compare with those of natural systems, people or animals.\nMARTIN FORD: Let’s talk about progress in AI toward human-level artificial \nintelligence or AGI. What does that path look like, and how close are we?\nDANIELA RUS: We have been working on AI problems for over 60 years, and if the \nfounders of the field were able to see what we tout as great advances today, they \nwould be very disappointed because it appears we have not made much progress. \nI don’t think that AGI is in the near future for us at all. \nI think that there is a great misunderstanding in the popular press about what \nartificial intelligence is and what it isn’t. I think that today, most people who \nsay “AI,” actually mean machine learning, and more than that, they mean deep \nlearning within machine learning. \nI think that most people who talk about AI today tend to anthropomorphize \nwhat these terms mean. Someone who is not an expert says the word \n“intelligence” and only has one association with intelligence, and that is the \nintelligence of people. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 442
  },
  {
    "chunk_full": "DANIELA RUS\n263\nWhen people say “machine learning,” they imagine that the machine learned just like \na human has learned. Yet these terms mean such different things in the technical \ncontext. If you think about what machine learning can do today, it’s absolutely \nextraordinary. Machine learning is a process that starts with millions of usually \nmanually labeled data points, and the system aims to learn a pattern that is prevalent \nin the data, or to make a prediction based on that data. \nThese systems can do this much better than humans because these systems can \nassimilate and correlate many more data points then humans are able to. However, \nwhen a system learns, for example, that there is a coffee mug in a photograph, what \nit is actually doing is it’s saying that the pixels that form this blob that represents the \ncoffee mug in the current photo are the same as other blobs that humans have labeled \nin images as coffee mugs. The system has no real idea what that coffee mug represents. \nThe system has no idea what to do with it, it doesn’t know if you drink it, eat it, \nor if you throw it. If I told you that there is a coffee mug on my desk, you don’t \nneed to see that coffee mug in order to know what it is because you have the kind \nof reasoning and experience that machines today simply do not have. \nTo me, the gap between this and human-level intelligence is extraordinary, and it \nwill take us a long time to get there. We have no idea of the processes that define \nour own intelligence, and no idea how our brain works. We have no idea how \nchildren work. We know a little bit about the brain, but that amount is insignificant \nto how much there is to know. The understanding of intelligence is one of the most \nprofound questions in science today. We see progress at the intersection between \nneuroscience, cognitive science, and computer science. \nMARTIN FORD: Is it possible that there might be an extraordinary breakthrough \nthat really moves things along?\nDANIELA RUS: That’s possible. In our lab, we’re very interested in figuring out \nwhether we can make robots that will adapt to people. We started looking at whether \nwe can detect and classify brain activity, which is a challenging problem. \nWe are mostly able to classify whether a person detects that something is wrong \nbecause of the “you are wrong” signal—called the “error-related potential.” This is \na signal that everyone makes, independent of their native tongue and independent \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 443
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n264\nof their circumstances. With the external sensors we have today, which are called \nEEG caps, we are fairly reliably able to detect the “you are wrong” signal. That’s \ninteresting because if we can do that, then we can imagine applications where \nworkers could work side by side with robots, and they could observe the robots \nfrom a distance and correct their mistakes when a mistake is detected. In fact, we \nhave a project that addresses this question. \nWhat’s interesting, though, is that these EEG caps are made up of 48 electrodes \nplaced on your head—it’s a very sparse, mechanical setup that reminds you of when \ncomputers were made up of levers. On the other hand, we have the ability to do \ninvasive procedures to tap into neurons at the level of the neural cell, so you could \nactually stick probes into the human brain, and you could detect neural-level activity \nvery precisely. There’s a big gap between what we can do externally and what we \ncan do invasively, and I wonder whether at some point we will have some kind of \nMoore’s law improvement on sensing brain activity and observing brainwave activity \nat a much higher resolution. \nMARTIN FORD: What about the risks and the downsides of all of this technology? One \naspect is the potential impact on jobs. Are we looking at a big disruption that could \neliminate a lot of work, and is that something we have to think about adapting to?\nDANIELA RUS: Absolutely! Jobs are changing: jobs are going away, and jobs are \nbeing created. The McKinsey Global Institute published a study that gives some \nreally important views. They looked at a number of professions and observed that \nthere are certain tasks that can be automated with the level of machine capability \ntoday, and others that cannot. \nIf you do an analysis of how people spend time in various professions, there are certain \ncategories of work. People spend time applying expertise; interacting with others; \nmanaging; doing data processing; doing data entry; doing predictable physical work; \ndoing unpredictable physical work. Ultimately, there are tasks that can be automated \nand tasks that can’t. The predictable physical work and the data tasks are routine tasks \nthat can be automated with today’s technologies, but the other tasks can’t. \nI’m actually very inspired by this because what I see is that technology can relieve \nus of routine work in order to give us time to focus on the more interesting parts \nof our work. Let’s go through an example in healthcare. We have an autonomous \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 444
  },
  {
    "chunk_full": "DANIELA RUS\n265\nwheelchair, and we have been talking with physical therapists about using this \nwheelchair. They are very excited about it because, at the moment, the physical \ntherapist works with patients in the hospital in the following way: \nFor every new patient, the physical therapist has to go to the patient’s bed where \nthey have to put the patient in a wheelchair, push the patient to the gym where \nthey’ll work together in the gym and at the end of the hour, the physical therapist \nhas to take the patient back to the patient’s hospital bed. A significant amount of \ntime is spent moving the patient around and not on patient care. \nNow imagine if the physical therapist didn’t have to do this. Imagine if the physical \ntherapist could stay in the gym, and the patient would show up delivered by an \nautonomous wheelchair. Then both the patient and the physical therapist would \nhave a much better experience. The patient would get more help from the physical \ntherapist, and the physical therapist would focus on applying their expertise. I’m \nvery excited about the possibility of enhancing the quality of time that we spend \nin our jobs and increasing our efficiency in our jobs. \nA second observation is that in general, it is much easier for us to analyze \nwhat might go away than to imagine what might come back. For instance, in \nthe 20th century, agricultural employment dropped from 40% to 2% in the \nUnited States. Nobody in the 20th century guessed that this would happen. \nJust consider, then, that only 10 years ago, when the computer industry was \nbooming, nobody predicted the level of employment in social media; in app \nstores; in cloud computing; and even in other things like college counseling. \nThere are so many jobs that employ a lot of people today that did not exist \n10 years ago, and that people did not anticipate would exist. I think that it’s \nexciting to think about the possibilities for the future and the new kinds of jobs \nthat will be created as a result of technology. \nMARTIN FORD: So, you think the jobs destroyed by technology and the new jobs \ncreated will balance out?\nDANIELA RUS: Well, I do also have concerns. One concern is in the quality \nof jobs. Sometimes, when you introduce technology, the technology levels the \nplaying field. For instance, it used to be that taxi drivers had to have a lot of \nexpertise—they had to have great spatial reasoning, and they had to memorize \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 445
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n266\nlarge maps. With the advent of GPS, that level of skill is no longer needed. What \nthat does is open the field for many more people to join the driving market, and \nthat tends to lower the wages. \nAnother concern is that I wonder if people are going to be trained well enough \nfor the good jobs that will be created as a result of technology. I think that \nthere are only two ways to approach this challenge. In the short term, we \nhave to figure out how to help people retrain themselves, how to help people \ngain the skills that are needed in order to fulfill some of the jobs that exist. I \ncan’t tell you how many times a day I hear, “We want your AI students. Can \nyou send us any AI students?” Everyone wants experts in artificial intelligence \nand machine learning, so there are a lot of jobs, and there are also a lot of \npeople who are looking for jobs. However, the skills that are in demand are \nnot necessarily the skills that people have, so we need retraining programs to \nhelp people acquire those skills. \nI’m a big believer in the fact that actually anybody can learn technology. My \nfavorite example is a company called BitSource. BitSource was launched a \ncouple of years back in Kentucky, and this company is retraining coal miners \ninto data miners and has been a huge success. This company has trained a lot \nof the miners who lost their jobs and who are now in a position to get much \nbetter, much safer and much more enjoyable jobs. It’s an example that actually \ntells us that with the right programs and the right support, we can actually \nhelp people in this transition period. \nMARTIN FORD: Is that just in terms of retraining workers, or do we need to \nfundamentally change our entire educational system? \nDANIELA RUS: In the 20th century we had reading, writing, and arithmetic that \ndefined literacy. In the 21st century, we should expand what literacy means, and we \nshould add computational thinking. If we teach in schools how to make things and \nhow to breathe life into them by programming, we will empower our students. We \ncan get them to the point where they can imagine anything and make it happen, \nand they will have the tools to make it happen. More importantly, by the time they \nfinish high school, these students will have the technical skills that will be required \nin the future, and they will be exposed to a different way of learning that will \nenable them to help themselves for the future. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 446
  },
  {
    "chunk_full": "DANIELA RUS\n267\nThe final thing I want to say about the future of work is that our attitude toward \nlearning will also have to change. Today, we operate with a sequential model of \nlearning and working. What I mean by this is that most people spend some chunk \nof their lives studying and at some point, they say, “OK, we’re done studying, now \nwe’re going to start working.” With technology accelerating and bringing in new \ntypes of capabilities, though, I think it’s very important to reconsider the sequential \napproach to learning. We should consider a more parallel approach to learning and \nworking, where we will be open to acquiring new skills and applying those skills \nas a lifelong learning process.\nMARTIN FORD: Some countries are making AI a strategic focus or adopting an \nexplicit industrial policy geared toward AI and robotics. China, in particular, is \ninvesting massively in this area. Do you think that there is a race toward advanced \nAI, and is the US at risk of falling behind? \nDANIELA RUS: When I look at what is happening in AI around the world, I think \nit is amazing. You have China, Canada, France, and the UK, among dozens of others, \nhugely investing in AI. Many countries are betting their future on AI, and I think \nwe in the US should do too. I think we should consider the potential for AI, and \nwe should increase the support and the funding of AI.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 447
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n268\nDANIELA RUS is the Andrew (1956) and Erna Viterbi Professor of Electrical Engineering \nand Computer Science and Director of the Computer Science and Artificial Intelligence \nLaboratory (CSAIL) at MIT. Daniela’s research interests are in robotics, artificial \nintelligence, and data science.\nThe focus of her work is developing the science and engineering of autonomy, toward the \nlong-term objective of enabling a future with machines pervasively integrated into the fabric \nof life, supporting people with cognitive and physical tasks. Her research addresses some of the \ngaps between where robots are today and the promise of pervasive robots: increasing the ability \nof machines to reason, learn, and adapt to complex tasks in human-centered environments, \ndeveloping intuitive interfaces between robots and people, and creating the tools for designing \nand fabricating new robots quickly and efficiently. The applications of this work are broad and \ninclude transportation, manufacturing, agriculture, construction, monitoring the environment, \nunderwater exploration, smart cities, medicine, and in-home tasks such as cooking.\nDaniela serves as the Associate Director of MIT’s Quest for Intelligence Core, and as \nDirector of the Toyota-CSAIL Joint Research Center, whose focus is the advancement of \nAI research and its applications to intelligent vehicles. She is a member of the Toyota \nResearch Institute advisory board.\nDaniela is a Class of 2002 MacArthur Fellow, a fellow of ACM, AAAI and IEEE, and a member \nof the National Academy of Engineering and the American Academy of Arts and Sciences. \nShe is the recipient of the 2017 Engelberger Robotics Award from the Robotics Industries \nAssociation. She earned her PhD in Computer Science from Cornell University.\nDaniela has also worked on two collaborative projects with the Pilobolus Dance company at the \nintersection of technology and art. Seraph, a pastoral story about human-machine friendship, \nwas choreographed in 2010 and performed in 2010-2011 in Boston and New York City. The \nUmbrella Project, a participatory performance exploring group behavior, was choreographed \nin 2012 and performed at PopTech 2012, in Cambridge, Baltimore, and Singapore.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 448
  },
  {
    "chunk_full": "DANIELA RUS\n269\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 449
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n270\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 450
  },
  {
    "chunk_full": "JAMES MANYIKA\n271\nJAMES MANYIKA\nCHAIRMAN AND DIRECTOR OF MCKINSEY GLOBAL INSTITUTE\nJames is a senior partner at McKinsey and Chairman of the McKinsey Global \nInstitute, researching global economic and technology trends. James consults with the \nchief executives and founders of many of the world’s leading technology companies. \nHe leads research on AI and digital technologies and their impact on organizations, \nwork, and the global economy. James was appointed by President Obama as vice \nchair of the Global Development Council at the White House and by US Commerce \nSecretaries to the Digital Economy Board and National Innovation Board. He is on \nthe boards of the Oxford Internet Institute, MIT’s Initiative on the Digital Economy, \nthe Stanford-based 100-Year Study on AI, and he is a fellow at DeepMind. \nSomebody should be thinking about what the  \nregulation of AI should look like. But I think the  \nregulation shouldn’t start with the view that its goal  \nis to stop AI and put back the lid on a Pandora’s box,  \nor hold back the deployment of these technologies  \nand try and turn the clock back.\n“ \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 451
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n272\nMARTIN FORD: I thought we could start by having you trace your academic and \ncareer trajectory. I know you came from Zimbabwe. How did you get interested in \nrobotics and artificial intelligence and then end up in your current role at McKinsey? \nJAMES MANYIKA: I grew up in a segregated black township in what was then \nRhodesia, before it became Zimbabwe. I was always inspired by the idea of science, \npartly because my father had been the first black Fulbright scholar from Zimbabwe \nto come to the United States of America in the early 1960s. While there, my father \nvisited NASA at Cape Canaveral, where he watched rockets soar up into the sky. \nAnd in my early childhood after he came back from America, my father filled my \nhead with the idea of science, space, and technology. So, I grew up in this segregated \ntownship, thinking about science and space, building model planes and machines \nout of whatever I could find. \nWhen I got to university after the country had become Zimbabwe, my undergraduate \ndegree was in electrical engineering with heavy doses of mathematics and computer \nscience. And while there a visiting researcher from the University of Toronto got me \ninvolved in a project on neural networks. That’s when I learned about Rumelhart \nBackpropagation and the use of logisti sigmoid functions in neural network algorithms. \nFast forward, I did well enough to get a Rhodes scholarship to go to Oxford University, \nwhere I was in the Programming Research Group, working under Tony Hoare, who is \nbest known for inventing Quicksort and for his obsession with formal methods and \naxiomatic specifications of programming languages. I studied for a master’s degree in \nmathematics and computer science and worked a lot on mathematical proofs and the \ndevelopment and verification of algorithms. By this time, I’d given up on the idea \nthat I would be an astronaut, but I thought that at least if I worked on robotics and \nAI, I might get close to science related to space exploration. \nI wound up in the Robotics Research Group at Oxford, where they were actually \nworking on AI, but not many people called it that in those days because AI had \na negative connotation at the time, after what had recently been a kind of “AI \nWinter” or a series of winters, where AI had underdelivered on its hype and \nexpectations. So, they called their work everything but AI—it was machine \nperception, machine learning, it was robotics or just plain neural networks; but \nno-one in those days was comfortable calling their work AI. Now we have the \nopposite problem, everyone wants to call everything AI. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 452
  },
  {
    "chunk_full": "JAMES MANYIKA\n273\nMARTIN FORD: When was this? \nJAMES MANYIKA: This was in 1991, when I started my PhD at the Robotics \nResearch Group at Oxford. This part of my career really opened me to working \nwith a number of different people in the robotics and AI fields. So, I met people \nlike Andrew Blake and Lionel Tarassenko, who were working on neural networks; \nMichael Brady, now Sir Michael, who was working on machine vision; and I met \nHugh Durrant-Whyte, who was working on distributed intelligence and robotic \nsystems. He became my PhD advisor. We built a few autonomous vehicles together \nand we also wrote a book together drawing on the research and intelligence \nsystems we were developing. \nThrough the research I was doing, I wound up collaborating with a team at the \nNASA Jet Propulsion Laboratory that was working on the Mars rover vehicle. NASA \nwas interested in applying the machine perception systems and algorithms that they \nwere developing to the Mars rover vehicle project. I figured that this was as close \nas I’m ever going to get to go into space!\nMARTIN FORD: So, there was actually some code that you wrote running on \nthe rover, on Mars? \nJAMES MANYIKA: Yes, I was working with the Man Machine Systems group at JPL \nin Pasadena, California. I was one of several visiting scientists there working on \nthese machine perception and navigation algorithms, and some of them found their \nway onto the modular and autonomous vehicle systems and other places. \nThat period at Oxford in the Robotics Research Group is what really sparked my \ninterest in AI. I found machine perception particularly fascinating: the challenges \nof how to build learning algorithms for distributed and multi-agent systems, how \nto use machine learning algorithms to make sense of environments, and how to \ndevelop algorithms that could autonomously build models of those environments, \nin particular, environments where you had no prior knowledge of them and had \nto learn as you go—like the surface of Mars. \nA lot of what I was working on had applications not just in machine vision, but in \ndistributed networks and sensing and sensor fusion. We were building these neural \nnetwork-based algorithms that were using a combination of Bayesian networks of the \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 453
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n274\nkind Judea Pearl had pioneered, Kalman filters and other estimation and prediction \nalgorithms to essentially build machine learning systems. The idea was that these \nsystems could learn from the environment, learn from input data from a wide \nrange of sources of varying quality, and make predictions. They could build maps \nand gather knowledge of the environments that they were in; and then they might \nbe able to make predictions and decisions, much like intelligent systems would. \nSo, eventually I met Rodney Brooks, who I’m still friends with today, during my \nvisiting faculty fellowship at MIT, where I was working with the Robotics Group \nat MIT and the Sea Grant project that was building underwater robots. During this \ntime, I also got to know people like Stuart Russell, who’s a professor in robotics \nand AI at Berkeley, because he had spent time at Oxford in my research group. In \nfact, many of my colleagues from those days have continued to do pioneering work, \npeople like John Leonard, now a Robotics Professor at MIT and Andrew Zisserman, \nat DeepMind. Despite the fact that I’ve wandered off into other areas in business \nand economics, I’ve stayed close to the work going on in AI and machine learning \nand try to keep up as best as I can. \nMARTIN FORD: So, you started out with a very technical orientation, given that \nyou were teaching at Oxford?\nJAMES MANYIKA: Yes, I was on the faculty and a fellow at Balliol College, Oxford, \nand I was teaching students courses in mathematics and computer science and as \nwell as on some of the research we were doing in robotics.\nMARTIN FORD: It sounds like a pretty unusual jump from there to business and \nmanagement consulting at McKinsey.\nJAMES MANYIKA: That was actually as much by accident as anything else. I’d \nrecently become engaged, and I had also received an offer from McKinsey to \njoin them in Silicon Valley; and I thought it would be a brief, interesting detour, \nto go to McKinsey.\nAt the time, like many of my friends and colleagues, such as Bobby Rao, who \nhad also been in the Robotics Research Lab with me, I was interested in building \nsystems that could compete in the DARPA driverless car challenge. This was \nbecause a lot of our algorithms were applicable to autonomous vehicles and \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 454
  },
  {
    "chunk_full": "JAMES MANYIKA\n275\ndriverless cars and back then, the DARPA challenge was one of the places where \nyou could apply those algorithms. All of my friends were moving to Silicon Valley \nthen. Bobby was at that time a post-doc at Berkeley working with Stuart Russell \nand others, and so I thought I should take this McKinsey offer in San Francisco. \nIt was a way to be close to Silicon Valley and to be close to where some of the \naction, including the DARPA challenge, was taking place.\nMARTIN FORD: What is your role now at McKinsey? \nJAMES MANYIKA: I’ve ended up doing two kinds of things. One is working with \nmany of the pioneering technology companies in Silicon Valley, where I have been \nfortunate to work with and advise many founders and CEOs. The other part, \nwhich has grown over time, is leading research at the intersection of technology \nand its impact on business and the economy. I’m the chairman of the McKinsey \nGlobal Institute, where we research not just technology but also macroeconomic \nand global trends to understand their impact on business and the economy. We \nare privileged to have amazing academic advisors that include economists who also \nthink a lot about technology’s impacts, people like Erik Brynjolffson, Hal Varian, \nand Mike Spence, the Nobel laureate, and even Bob Solow in the past. \nTo link this back to AI, we’ve been looking a lot at disruptive technologies, and \ntracking the progress of AI, and I’ve stayed in constant dialogues as well as collaborated \nwith AI friends like Eric Horvitz, Jeff Dean, Demis Hassabis, and Fei-Fei Li, and \nalso learning from legends like Barbara Grosz. While I’ve tried to stay close to the \ntechnology and the science, my MGI colleagues and I have spent more time thinking \nabout and researching the economic and business impacts of these technologies.\nMARTIN FORD: I definitely want to delve into the economic and job market impact, \nbut let’s begin by talking about AI technology. \nYou mentioned that you were working on neural networks way back in the 1990s. \nOver the past few years, there’s been this explosion in deep learning. How do \nyou feel about that? Do you see deep learning as the holy grail going forward, \nor has it been overhyped? \nJAMES MANYIKA: We’re only just discovering the power of techniques such as deep \nlearning and neural networks in their many forms, as well as other techniques like \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 455
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n276\nreinforcement learning and transfer learning. These techniques all still have enormous \nheadroom; we’re only just scratching the surface of where they can take us. \nDeep learning techniques are helping us solve a huge number of particular problems, \nwhether it’s in image and object classification, natural language processing or \ngenerative AI, where we predict and create sequences and outputs whether its \nspeech, images, and so forth. We’re going to make a lot of progress in what is \nsometimes called “narrow AI,” that is, solving particular areas and problems using \nthese deep learning techniques. \nIn comparison, we’re making slower progress on what is sometimes called “artificial \ngeneral intelligence” or AGI. While we’ve made more progress recently than we’ve \ndone in a long time, I still think progress is going to be much, much slower towards \nAGI, just because it involves a much more complex and difficult set of questions \nto answer and will require many more breakthroughs. \nWe need to figure out how to think about problems like transfer learning, because \none of the things that humans do extraordinarily well is being able to learn \nsomething, over here, and then to be able to apply that learning in totally new \nenvironments or on a previously unencountered problem, over there. There are \ndefinitely some exciting new techniques coming up, whether in reinforcement \nlearning or even simulated learning—the kinds of things that AlphaZero has begun \nto do—where you self-learn and self-create structures, as well start to solve wider \nand different categories of challenges, in the case of AlphaZero different kinds of \ngames. In another direction the work that Jeff Dean and others at Google Brain \nare doing using AutoML is really exciting. That’s very interesting from the point \nof helping us start to make progress in machines and neural networks that design \nthemselves. These are just a few examples. One could say all of this progress is \nnudging us towards AGI. But these are really just small steps; much, much more \nis needed, there are whole areas of high-level reasoning etc. that we barely know \nhow to tackle. This is why I think AGI is still quite a long way away. \nDeep learning is certainly going to help us with narrow AI applications. We’re going \nto see lots and lots and lots and lots of applications that are already being turned \ninto new products and new companies. At the same time, it’s worth pointing out \nthat there are still some practical limitations to the use and application of machine \nlearning, and we have pointed this out in some of our MGI work. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 456
  },
  {
    "chunk_full": "JAMES MANYIKA\n277\nMARTIN FORD: Do you have any examples?\nJAMES MANYIKA: For example, we know that many of these techniques still largely \nrely on labelled data, and there’s still lots of limitations in terms of the availability \nof labelled data. Often this means that humans must label underlying data, which \ncan be a sizable and error-prone chore. In fact, some autonomous vehicle companies \nare hiring hundreds of people to manually annotate hours of video from prototype \nvehicles to help train the algorithms. There are some new techniques that are \nemerging to get around the issue of needing labeled data, for example, in-stream \nsupervision pioneered by Eric Horvitz and others; the use of techniques like \nGenerative Adversarial Networks or GANs, which is a semi-supervised technique \nthrough which usable data can be generated in a way that reduces the need for \ndatasets that require labeling by humans. \nBut then we still have a second challenge of needing such large and rich data \nsets. It is quite interesting that you can more or less identify those areas that \nare making spectacular progress simply by observing which areas have access \nto a huge amount of available data. So, it is no surprise that we have made \nmore progress in machine vision than in other applications, because of the huge \nvolume of images and now video being put on the internet every day. Now, \nthere are some good reasons—regulatory, privacy, security, and otherwise—that \nmay limit data availability to some extent. And this can also, in part, explain \nwhy different societies are going to experience differential rates of progress \non making data available. Countries with large populations, naturally, generate \nlarger volumes of data, and different data use standards may make it easier to \naccess large health data sets, for example, and use that to train algorithms. \nSo, in China you might see more progress in using AI in genomics and “omics” \ngiven larger available data sets. \nSo, data availability is a big deal and may explain why some areas of AI applications \ntake off much faster in some places than others. But we’ve also got other limitations \nto deal with, like we still don’t have generalized tools in AI and we still don’t \nknow how to solve general problems in AI. In fact, one of the fun things, and you \nmay have seen this, is that people are now starting to define new forms of what \nused to be the Turing test.\nMARTIN FORD: A new Turing Test? How would that work?\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 457
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n278\nJAMES MANYIKA: Steve Wozniak, the co-founder of Apple, has actually proposed \nwhat he calls the “coffee test” as opposed to Turing tests, which are very narrow \nin many respects. A coffee test is kind of fun: until you get a system that can \nenter an average and previously unknown American home and somehow figure out \nhow to make a cup of coffee, we’ve not solved AGI. The reason why that sounds \ntrivial but at the same time quite profound is because you’re solving a large number \nof unknowable and general problems in order to make that cup of coffee in an \nunknown home, where you don’t know where things are going to be, what type \nof coffee maker it is or other tools they have, etc. That’s very complex generalized \nproblem-solving across numerous categories of problems that the system would have \nto do. Therefore, it may be that we need Turing tests of that form if you want to \ntest for AGI, and maybe that’s where we need to go. \nI should point out the other limitation, which is the question of potential issues \nnot so much in the algorithm, but in the data. This is a big question which \ntends to divide the AI community. One view is the idea that these machines are \nprobably going to be less biased than humans. You can look at multiple examples, \nsuch as human judges and bail decisions where using an algorithm could take out \nmany of the inherent human biases, including human fallibility and even time of \nday biases. Hiring and advancement decisions could be another similar area like \nthis, thinking about Marianne Bertrand and Sendhil Mullainathan’s work looking \nat the difference in calls back received by different racial groups who submitted \nidentical resumes for jobs.\nMARTIN FORD: That’s something that has come up in a number of the conversations \nI’ve had for this book. The hope should be that AI can rise above human biases, but \nthe catch always seems to be that that the data you’re using to train the AI system \nencapsulates human bias, so the algorithm picks it up.\nJAMES MANYIKA: Exactly, that’s the other view of the bias question that recognizes \nthat the data itself could actually be quite biased, both in its collection, the sampling \nrates—either through oversampling or undersampling—and what that means \nsystematically, either to different groups of people or different kinds of profiles. \nThe general bias problem has been shown in quite a spectacular fashion in lending, \nin policing and criminal justice cases, and so in any dataset that we have want to \nuse, we could have large-scale biases already built it, many likely unintended. Julia \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 458
  },
  {
    "chunk_full": "JAMES MANYIKA\n279\nAngwin and her colleagues at ProPublica have highlighted such biases in their work, \nas has MacArthur Fellow Sendhil Mullainathan and his colleagues. One of the most \ninteresting findings to come out of that work, by the way, is that algorithms may \nbe mathematically unable to satisfy different definitions of fairness at the same \ntime, so deciding how we will define fairness is becoming a very important issue. \nI think both views are valid. On the one hand, machine systems can help us \novercome human bias and fallibility, and yet on the other hand, they could also \nintroduce potentially larger issues of their own. This is another important limitation \nwe’re going to need to work our way through. But here again we are starting to \nmake progress. I am particularly excited about the pioneering work that Silvia \nChiappa at DeepMind is doing using counterfactual fairness and causal model \napproaches to tackle fairness and bias. \nMARTIN FORD: That’s because the data directly reflects the biases of people, right? \nIf it’s collected from people as they’re behaving normally, using an online service \nor something, then the data is going to end up reflecting whatever biases they have.\nJAMES MANYIKA: Right, but it can actually be a problem even if individuals \naren’t necessarily biased. I’ll give you an example where you can’t actually fault \nthe humans per se, or their own biases, but that instead shows us how our society \nworks in ways that create these challenges. Take the case of policing. We know that, \nfor example, some neighborhoods are more policed than others and by definition, \nwhenever neighborhoods are more policed, there’s a lot more data collected about \nthose neighborhoods for algorithms to use. \nSo, if we take two neighborhoods, one that is highly policed and one that is not—\nwhether deliberately or not—the fact is that the data sampling differences across \nthose two communities will have an impact on the predictions about crime. The \nactual collection itself may not have shown any bias, but because of oversampling \nin one neighborhood and undersampling in another, the use of that data could lead \nto biased predictions. \nAnother example of undersampling and oversampling can be seen in lending. In this \nexample, it works the other way, where if you have a population that has more available \ntransactions because they’re using credit cards and making electronic payments, we \nhave more data about that population. The oversampling there actually helps those \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 459
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n280\npopulations, because we can make better predictions about them, whereas if you then \nhave an undersampled population, because they’re paying in cash and there is little \navailable data, the algorithm could be less accurate for those populations, and as a \nresult, more conservative in choosing to lend, which essentially biases the ultimate \ndecisions. We have this issue too in facial recognitions systems which has been \ndemonstrated in the work of Timnit Gebru, Joy Buolamwini, and others. \nIt may not be the biases that any human being has in developing the algorithms, \nbut the way in which we’ve collected the data that the algorithms are trained \non that introduces bias. \nMARTIN FORD: What about other kinds of risks associated with AI? One issue that’s \ngotten a lot of attention lately is the possibility of existential risk from superintelligence. \nWhat do you think are the things we should legitimately worry about?\nJAMES MANYIKA: Well, there are lots of things to worry about. I remember a \ncouple of years ago, a group of us, that included many of the AI pioneers and \nother luminaries, including the likes of Elon Musk and Stuart Russell, met in \nPuerto Rico to discuss progress in AI as well concerns and areas that needed \nmore attention. The group ended up writing about what some of the issues are, \nin a paper that was published by Stuart Russell, and what we should worry about, \nand pointing out where there was not enough attention and research going into \nanalyzing these areas. Since that meeting, the areas to worry about have begun to \nchange a little bit in the last couple of years, but those areas included everything—\nincluding things like safety questions. \nHere is one example. How do you stop a runaway algorithm? How do you stop a \nrunaway machine that gets out of control? I don’t mean in a Terminator sense, but \neven just in the narrow sense of an algorithm that is making wrong interpretations, \nleading to safety questions, or even simply upsetting people. For this we may need \nwhat has been referred to as the Big Red Button, something several research teams \nare working on DeepMind’s work with gridworlds, for example, has demonstrated that \nmany algorithms could theoretically learn how to turn off their own “off-switches”. \nAnother issue is explainability. Here, explainability is a term used to discuss the \nproblem that with neural networks: we don’t always know which feature or which \ndataset influenced the AI decision or prediction, one way or the other. This can \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 460
  },
  {
    "chunk_full": "JAMES MANYIKA\n281\nmake it very hard to explain an AI’s decision, to understand why it might be \nreaching a wrong decision. This can matter a great deal when predictions and \ndecisions have consequential implications that may affect lives for example when \nAI is used in criminal justice situations or lending applications, as we’ve discussed. \nRecently, we’ve seen new techniques to get at the explainability challenge emerge. \nOne promising technique is the use of Local-Interpretable-Model Agnostic \nExplanations, or LIME. LIME tries to identify which particular data sets a trained \nmodel relies on most to make a prediction. Another promising technique is the \nuse of Generalized Additive Models, or GAMs. These use single feature models \nadditively and therefore limit interactions between features, and so changes in \npredictions cane be determined as features are added. \nYet another area we should think about more is the “detection problem,” which is \nwhere we might find it very hard to even detect when there’s malicious use of an AI \nsystem—which could be anything from a terrorist to a criminal situation. With other \nweapons systems, like nuclear weapons, we have fairly robust detection systems. It’s \nhard to set off a nuclear explosion in the world without anybody knowing because \nyou have seismic tests, radioactivity monitoring, and other things. With AI systems, \nnot so much, which leads to an important question: How do we even know when \nan AI system is being deployed?\nThere are several critical questions like this that still need a fair amount of technical \nwork, where we must make progress, instead of everybody just running away and \nfocusing on the upsides of applications for business and economic benefits. \nThe silver lining of all this is that groups and entities are emerging and starting \nto work on many of these challenges. A great example is the Partnership on AI. If \nyou look at the agenda for the Partnership, you’ll see a lot of these questions are \nbeing examined, about bias, about safety, and about these kinds of existential threat \nquestions. Another great example is the work that Sam Altman, Jack Clarke and \nothers at OpenAI are doing, which aims to make sure all of society benefits from AI. \nRight now, the entities and groups that are making the most progress on these \nquestions have tended to be places that have been able to attract the AI superstars, \nwhich, even in 2018, tends to be a relatively small group. That will hopefully \ndiffuse over time. We’ve also seen some relative concentrations of talent go to \nplaces that have massive computing power and capacity, as well as places that have \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 461
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n282\nunique access to lots of data, because we know these techniques benefit from \nthose resources. The question is, in a world in which there’s a tendency for more \nprogress to go to where the superstars are, and where the data is available, and \nwhere the computer capacity is available, how do you make sure this continues \nto be widely available to everybody? \nMARTIN FORD: What do you think about the existential concerns? Elon Musk \nand Nick Bostrom talk about the control problem or the alignment problem. One \nscenario is where we could have a fast takeoff with recursive improvement, and \nthen we’ve got a superintelligent machine that gets away from us. Is that something \nwe should be worried about at this point?\nJAMES MANYIKA: Yes, somebody should be worrying about those questions—\nbut not everybody, partly because I think the time frame for a super intelligent \nmachine is so far away, and because the probability of that is fairly low. But \nagain, in a Pascal-wager like sense, somebody should be thinking about those \nquestions, but I wouldn’t get society all whipped up about the existential \nquestions, at least not yet. \nI like the fact that a smart philosopher like Nick Bostrom is thinking about it, I \njust don’t think that it should be a huge concern for society as a whole just yet. \nMARTIN FORD: That’s also my thinking. If a few think tanks want to focus on these \nconcerns, that seems like a great idea. But it would be hard to justify investing \nmassive governmental resources at this point. And we probably wouldn’t want \npoliticians delving into this stuff in any case.\nJAMES MANYIKA: No, it shouldn’t be a political issue, but I also disagree with \npeople who say that there is zero probability that this could happen and say that \nno-one should worry about it. \nThe vast majority of us shouldn’t be worried about it. I think that we should \nbe more worried about these more specific questions that are here now, such \nas safety, use and misuse, explainability, bias, and the economic and workforce \neffects questions and related transitions. Those are the bigger, more real \nquestions that are going to impact society beginning now and running over the \nnext few decades.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 462
  },
  {
    "chunk_full": "JAMES MANYIKA\n283\nMARTIN FORD: In terms of those concerns, do you think there’s a place for \nregulation? Should governments step in and regulate certain aspects of AI, or should \nwe rely on industry to figure it out for themselves?\nJAMES MANYIKA: I don’t know what form regulation should take, but somebody \nshould be thinking about regulation in this new environment. I don’t think that \nwe’ve got any of the tools in place, any of the right regulatory frameworks in \nplace at all right now. \nSo, my simple answer would be yes, somebody should be thinking about what the \nregulation of AI should look like. But I think the regulation shouldn’t start with \nthe view that its goal is to stop AI and put back the lid on a Pandora’s box, or \nhold back the deployment of these technologies and try and turn the clock back. \nI think that would be misguided because first of all, the genie is out of the bottle; \nbut also, more importantly, there’s enormous societal and economic benefit from \nthese technologies. We can talk more about our overall productivity challenge, \nwhich is something these AI systems can help with. We also have societal “moonshot” \nchallenges that AI systems can help with. \nSo, if regulation is intended to slow things down or stop the development of AI \nthen I think that’s wrong, but if regulation is intended to think about questions of \nsafety, questions of privacy, questions of transparency, questions around the wide \navailability of these techniques so that everybody can benefit from them—then I \nthink those are the right things that AI regulation should be thinking about. \nMARTIN FORD: Let’s move on to the economic and business aspects of this. I \nknow the McKinsey Global Institute has put out several important reports on the \nimpact of AI on work and labor.\nI’ve written quite a lot on this, and my last book makes the argument that we’re \nreally on the leading edge of a major disruption that could have a huge impact on \nlabor markets. What’s your view? I know there are quite a few economists who \nfeel this issue is being overhyped.\nJAMES MANYIKA: No, it is not overhyped. I think we’re on the cusp and we’re \nabout to enter a new industrial revolution. I think these technologies are going to \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 463
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n284\nhave an enormous, transformative and positive impact on businesses, because of \ntheir efficiency, their impact on innovation, their impact on being able to make \npredictions and to find new solutions to problems, and in some case go beyond \nhuman cognitive capabilities. The impact of AI on business to me, based on our \nresearch at MGI, is for the businesses undoubtedly positive.\nThe impact on the economy is also going to be quite transformational too, \nmostly because this is going to lead to productivity gains, and productivity is the \nengine of economic growth. This will all take place at a time when we’re going \nto have aging and other effects that will create headwinds for economic growth. \nAI and automation systems, along with other technologies, are going to have \nthis transformational and much-needed effect on productivity, which in the long \nterm leads to economic growth. These systems can also significantly accelerate \ninnovation and R&D, which leads to new products and services and even business \nmodels that will transform the economy. \nI’m also quite positive about the impact on society in the sense of being able to \nsolve the societal “moonshot” challenges I hinted at before. This could a new project \nor application that yields new insights into a societal challenge or proposes a radical \nsolution or leads to the development of a breakthrough technology. This could be \nin healthcare, climate science, humanitarian crises or in discovering new materials. \nThis is another area that my colleagues and I are researching where it’s clear that \nAI techniques from image classification to natural language processing and object \nidentification can make a big contribution in many of these domains. \nHaving said all of that, if you say AI is good for business, good for economic \ngrowth, and helps tackle societal moonshots, then the big question is—what \nabout work? I think this is a much more mixed and complicated story. But I \nthink if I were to summarize my thoughts about jobs, I would say there will be \njobs lost, but also jobs gained.\nMARTIN FORD: So, you believe the net impact will be positive, even though a lot \nof jobs will be lost?\nJAMES MANYIKA: While there will be jobs lost, there’ll also be jobs gained. In \nthe “jobs gained” side of the story, jobs will come from the economic growth itself, \nand from the resulting dynamism. There’s always going to be demand for work, \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 464
  },
  {
    "chunk_full": "JAMES MANYIKA\n285\nand there are mechanisms, through productivity and economic growth, that lead \nto the growth of jobs and the creation of new jobs. In addition, there are multiple \ndrivers of demand for work that are relatively assured in the near- to mid-term, \nthese include, again, rising prosperity around the world as more people enter the \nconsuming class and so on. Another thing which will occur is something called “jobs \nchanged,” and that’s because these technologies are going to complement work in \nlots of interesting ways, even when we don’t fully replace people doing that work. \nWe’ve seen versions of these three ideas of jobs lost, jobs gained, and jobs changed \nbefore with previous eras of automation. The real debate is, what are the relative \nmagnitudes of all those things, and where do we end up? Are we going to have \nmore jobs lost than jobs gained? That’s an interesting debate. \nOur research at MGI suggests that we will come out ahead, that there will be more \njobs gained than jobs lost; this of course is based on a set of assumptions around \na few key factors. Because it’s impossible to make predictions, we have developed \nscenarios around the multiple factors involved, and in our midpoint scenarios we \ncome out ahead. The interesting question is, even in a world with enough jobs, what \nwill be the key workforce issues to grapple with, including the effect on things like \nwages, and the workforce transitions involved? The jobs and wages picture is more \ncomplicated than the effect on business and the economy, in terms of growth, which \nas I said, is clearly positive. \nMARTIN FORD: Before we talk about jobs and wages, let me focus on your first \npoint: the positive impact on business. If I were an economist, I would immediately \npoint out that if you look at the productivity figures recently, they’re really not that \ngreat—we are not seeing any increases in productivity yet in terms of the macro-\neconomic data. In fact, productivity has been pretty underwhelming, relative to \nother periods. Are you arguing that there’s just a lag before things will take off? \nJAMES MANYIKA: We at MGI recently put out a report on this. There are a lot of \nreasons why productivity growth is sluggish, one reason being that in the last 10 \nyears we’ve had the lowest capital intensity period in about 70 years. \nWe know that capital investment, and capital intensity, are part of the things that you \nneed to drive productivity growth. We also know the critical role of demand—most \neconomists, including here at MGI, have often looked at the supply-side effects of \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 465
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n286\nproductivity, and not as much at the demand side. We know that when you’ve got \na huge slowdown in demand you can be as efficient as you want in production, \nand measured productivity still won’t be great. That’s because the productivity \nmeasurement has a numerator and a denominator: the numerator involves growth in \nvalue-added output, which requires that output is being soaked up by demand. So, if \ndemand is lagging for whatever reason, that hurts growth in output, which brings down \nproductivity growth, regardless of what technological advances there may have been. \nMARTIN FORD: That’s an important point. If advancing technology increases \ninequality and holds down wages, so it effectively takes money out of the pockets \nof average consumers, then that could dampen down demand further.\nJAMES MANYIKA: Oh, absolutely. The demand point is absolutely critical, especially \nwhen you’ve got advanced economies, where anywhere between 55% and 70% of \nthe demand in those economies is driven by consumer and household spending. \nYou need people earning enough to be able to consume the output of everything \nbeing produced. Demand is a big part of the story, but I think there is also the \ntechnology lag story that you mentioned. \nTo your original question, I had the pleasure between 1999 and 2003 to work with \none of the academic advisors of the McKinsey Global Institute, Bob Solow, the Nobel \nlaureate. We were looking at the last productivity paradox back in the late 1990s. In \nthe late ‘80s, Bob had made the observation that became known as The Solow Paradox, \nthat you could see computers everywhere except in the productivity numbers. That \nparadox was finally resolved in the late ‘90s, when we had enough demand to drive \nproductivity growth, but more importantly, when we had very large sectors of the \neconomy—retail, wholesale, and others—finally adopting the technologies of the day: \nclient-server architectures, ERP systems. This transformed their business processes and \ndrove productivity growth in very large sectors in the economy, which finally had a \nbig enough effect to move the national productivity needle. \nNow if you fast-forward to where we are today, we may be seeing something similar \nin the sense that if you look at the current wave of digital technologies, whether \nwe’re talking about cloud computing, e-commerce, or electronic payments, we \ncan see them everywhere, we all carry them in our pockets, and yet productivity \ngrowth has been very sluggish for several years now. But if you actually systematically \nmeasure how digitized the economy is today, looking at the current wave of digital \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 466
  },
  {
    "chunk_full": "JAMES MANYIKA\n287\ntechnologies, the surprising answer is: not so much, actually, in terms of assets, \nprocesses, and how people work with technology. And we are not even talking \nabout AI yet or the next wave of technologies with these assessments of digitization. \nWhat you find is that the most digitized sectors—on a relative basis—are sectors \nlike the tech sector itself, media and maybe financial services. And those sectors \nare actually relatively small in the grand scheme of things, measuring as a share of \nGDP or as a share of employment, whereas the very large sectors are, relatively \nspeaking, not that digitized. \nTake a sector like retail and keep in mind that retail is one of the largest sectors. \nWe all get excited by the prospect of e-commerce and what Amazon is doing. But \nthe amount of retail that is now done through e-commerce is only about 10%, and \nAmazon is a large portion of that 10%. But retail is a very large sector with many, \nmany small- and medium-sized businesses. That already tells you that even in retail, \none of the large sectors which we’d think of as highly digitized, in reality, it turns \nout we really haven’t yet made much widespread progress yet. \nSo, we may be going through another round of the Solow paradox. Until we get \nthese very large sectors highly digitized and using these technologies across business \nprocesses, we won’t see enough to move the national needle on productivity. \nMARTIN FORD: So, you’re saying that globally we haven’t even started to see to \nthe impact of AI and advanced forms of automation yet?\nJAMES MANYIKA: Not yet. And that gets to another point worth making: we’re \nactually going to need productivity growth even more than we can imagine, and \nAI, automation and all these digital technologies are going to be critical to driving \nproductivity growth and economic growth. \nTo explain why, let’s look at the last 50 years of economic growth, and you look at \nthat for the G20 countries (which make up a little more than 90% of global GDP), \nthe average economic GDP growth over the last 50 years where we have the data, so \nbetween 1964 and 2014, was 3.5%. This was the average GDP growth across those \ncountries. If you do classic growth decomposition and growth accounting work, it \nshows that GDP and economic growth comes from two things: one is productivity \ngrowth, and the other is expansions in the labor supply.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 467
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n288\nOf the 3.5% of average GDP growth we’ve had in the last 50 years, 1.7% has \ncome from expansions in the labor supply, and the other 1.8% has come from \nproductivity growth over those 50 years. If you look to the next 50 years, the \ngrowth from expansions in the labor supply is going to come crashing down \nfrom the 1.7% that it’s been the last 50 years to about 0.3%, because of aging \nand other demographic effects. \nSo that means that in the next 50 years we’re going to rely even more than we \nhave in the past 50 years on productivity growth. And unless we get big gains \nin productivity, we’re going to have a downdraft in economic growth. If we \nthink productivity growth matters right now for our current growth, which \nit does, it’s going to matter even more for the next 50 years if we still want \neconomic growth and prosperity.\nMARTIN FORD: This is kind of touching on the economist Robert Gordon’s \nargument that may be there’s not going to be much economic growth in the future.1\nJAMES MANYIKA: While Bob Gordon’s saying there may not be economic \ngrowth, he’s also questioning whether we’re going to have big enough innovations, \ncomparable to electrification and other things like that, to really drive economic \ngrowth. He’s skeptical that there’s going to be anything as big as electricity and \nsome of the other technologies of the past.\nMARTIN FORD: But hopefully AI is going to be that next thing?\nJAMES MANYIKA: We hope it will be! It is certainly a general-purpose \ntechnology like electricity, and in that sense should benefit multiple activities \nand sectors of the economy. \nMARTIN FORD: I want to talk more about The McKinsey Global Institute’s reports \non what’s happening to work and wages. Could you go into a bit more detail about \nthe various reports you’ve generated and your overall findings? What methodology \ndo you use to figure out if a particular job is likely to be automated and what \npercentage of jobs are at risk?\n1  Robert Gordon’s 2017 book The Rise and Fall of American Growth, offers a very pessimistic view of \nfuture economic growth in the United States.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 468
  },
  {
    "chunk_full": "JAMES MANYIKA\n289\nJAMES MANYIKA: Let’s take this in three parts: “jobs lost,” “jobs changed,” and then \n“jobs gained,” because there’s something to be said about each of these pathways. \nIn terms of “jobs lost,” there’s been lots of research and reports, and it’s become a \ncottage industry speculating on the jobs question. At MGI the approach we’ve taken \nwe think is a little bit different in two ways. One is that we’ve conducted a task-\nbased decomposition, and so we’ve started with tasks, as opposed to starting with \nwhole occupations. We’ve looked at something like over 2,000 tasks and activities \nusing a variety of sources, including the O*NET dataset, and other datasets that \nwe’ve got by looking at tasks. Then, the Bureau of Labor Statistics in the US tracks \nabout 800 occupations; so, we mapped those tasks into the actual occupations. \nWe’ve also looked at 18 different kinds of capabilities required to perform these \ntasks, and by capabilities, I’m talking everything from cognitive capabilities to \nsensory capabilities, to physical motor skills that are required to fulfill these tasks. \nWe’ve then tried to understand to what extent technologies are now available to \nautomate and perform those same capabilities, which then we can map back to \nour tasks and show what tasks machines can perform. We’ve looked at what we’ve \ncalled “currently demonstrated technology,” and what we’re distinguishing there \nis technology that has actually been demonstrated, either in a lab or in an actual \nproduct, not just something that’s hypothetical. By looking at these “currently \ndemonstrated technologies,” we can provide a view into the next decade and a half \nor so, given typical adoption and diffusion rates.\nBy looking at all this, we have concluded that on a task level in the US economy, \nroughly about 50% of activities—not jobs, but tasks, and it’s important to emphasize \nthis—that people do now are, in principle, automatable. \nMARTIN FORD: You’re saying that half of what workers do could conceivably be \nautomated right now, based on technology we already have?\nJAMES MANYIKA: Right now, it is technically feasible to automate 50% of activities \nbased on currently demonstrated technologies. But there are also separate questions, \nlike how do those automatable activities then map into whole occupations? \nSo, when we then map back into occupations, we actually find that only about \n10% of occupations have more than 90% of their constituent tasks automatable. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 469
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n290\nRemember this is a task number, not a jobs number. We also find that something like \n60% of occupations have about a third of their constituent activities automatable—\nthis mix of course varies by occupation. This 60-30 already tells you that many \nmore occupations will be complemented or augmented by technologies than will \nbe replaced. This leads to the “jobs changed” phenomena I mentioned earlier.\nMARTIN FORD: I recall that when your report was published, the press put a \nvery positive spin on it—suggesting that since only a portion of most jobs will be \nimpacted, we don’t need to worry about job losses. But if you had three workers, \nand a third of each of their work was automated, couldn’t that lead to consolidation, \nwhere those three workers become two workers?\nJAMES MANYIKA: Absolutely, that’s where I was going to go next. This is a task \ncomposition argument. It might give you modest numbers initially, but then you \nstart to realize that work could be reconfigured in lots of interesting ways.\nFor instance, you can combine and consolidate. Maybe the tipping point is not that \nyou need all of the tasks in an occupation to be automatable; rather, maybe when \nyou get close to say, 70% of the tasks being automatable, you may then say, “Let’s \njust consolidate and reorganize the work and workflow altogether.” So, the initial \nmath may begin with modest numbers, but when you reorganize and consolidate \nthe work, the number of impacted jobs start to get bigger. \nHowever, there is yet another set of considerations that we’ve looked at in our \nresearch at MGI which we think have been missing in some of the other assessments \non the automation question. Everything that we have described so far is simply \nasking the technical feasibility question, which gives you those 50% numbers, but \nthat is really only the first of about five questions you need to ask. \nThe second question is around the cost of developing and deploying those technologies. \nObviously, just because something’s technically feasible, doesn’t mean it will happen. \nLook at electric cars. It’s been demonstrated we could build electric cars, and in \nfact that was a feasible thing to do more than 50 years ago, but when did they \nactually show up? When the costs of buying it, maintaining it, charging it, etc., \nbecame reasonable enough that consumers wanted to buy them and companies want \nto deploy them. That’s only happened very recently.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 470
  },
  {
    "chunk_full": "JAMES MANYIKA\n291\nSo, the cost of deployment is clearly an important consideration and will vary a lot, \ndepending on whether you’re talking about systems that are replacing physical work, \nversus systems that are replacing cognitive work. Typically, when you’re replacing \ncognitive work, it’s mostly software and a standard computing platform, so the \nmarginal cost economics can come down pretty fast, so that doesn’t cost very much. \nIf you’re replacing physical work, on the other hand, then you need to build a \nphysical machine with moving parts; and the economics of those things, while \nthey’ll come down, they’re not going to come down as fast as where things are \njust software. So, the cost of deployment is the second important consideration, \nwhich then starts to slow down deployment rates that might initially be suggested \nby simply looking at technical feasibility. \nThe third consideration is labor-market demand dynamics, taking into account \nlabor quality and quantity, as well as the wages associated with that. Let me \nillustrate this by thinking in terms of two different kinds of jobs. We’ll look at an \naccountant, and we’ll look at a gardener. First let’s see how these considerations \ncould play out in these occupations. \nFirst, it is technically easier to automate large portions of what the accountant does, \nmostly data analysis, data gathering, and so forth, whereas it’s still technically harder to \nautomate what a gardener does, which is mostly physical work in a highly unstructured \nenvironment. Things in these kinds of environments aren’t quite lined up exactly \nwhere you want them to be—as they would be in a factory, for example, and there’s \nunforeseen obstacles that can be in the way. So, the degree of technical difficulty of \nautomating those tasks, our first question, is already far higher than your accountant. \nThen we get to the second consideration: the cost of deploying the system, which \ngoes back to the argument I just made. In the case of the accountant, this requires \nsoftware with near zero-marginal cost economics running on a standard computing \nplatform. With the gardener, it’s a physical machine with many moving parts. The \ncost economics of deploying a physical machine is always going to be—even as costs \ncome down, and they are coming down for robotic machines—more expensive than \nthe software to automate an accountant. \nNow to our third key consideration, that is the quantity and quality of labor, and \nthe wage dynamics. Here again it favors an automating the accountant, rather than \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 471
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n292\nautomating the gardener. Why? Because we pay a gardener, on average in the United \nStates, something like $8 an hour; whereas we pay an accountant something like \n$30 an hour. The incentive to automate the accountant is already far higher than the \nincentive to automate the gardener. As we work our way through this, we start to \nrealize that it may very well be that some of these low-wage jobs may actually be \nharder to automate, from both a technical and economic perspective. \nMARTIN FORD: This sounds like really bad news for university graduates. \nJAMES MANYIKA: Not so fast. Often the distinction that’s made is high wage versus low \nwage; or high skill versus low skill. But I really don’t know if that’s a useful distinction. \nThe point I want to make is that the activities likely to be automated don’t line up \nneatly with traditional conceptions of wages structures or skills requirements. If the \nwork that’s being done looks like mostly data collection, data analysis, or physical \nwork in a highly structured environment, then much of that work is likely to be \nautomated, whether it’s traditionally been high wage or low wage, high skill or \nlow skill. On the other hand, activities that are very difficult to automate also cut \nacross wage structures and skills requirements, including tasks that require judgment \nor managing people, or physical work in highly unstructured and unexpected \nenvironments. So many traditionally low wage and high wage jobs are exposed to \nautomation, depending on the activities, but also many other traditionally low wage \nand high wages jobs may be protected from automation. \nI want to make sure we cover all the different factors at play here, as well. The \nfourth key consideration has to do with benefits including and beyond labor \nsubstitution. There are going to be some areas where you’re automating, but it’s not \nbecause you’re trying to save money on labor, it is because you’re actually getting a \nbetter result or even a superhuman outcome. Those are places where you’re getting \nbetter perception or predictions that you couldn’t get with human capabilities. \nEventually, autonomous vehicles will likely be an example of this, once they reach \nthe point where they are safer and commit fewer errors than humans driving. When \nyou start to go beyond human capabilities and see performance improvements, that \ncan really speed up the business case for deployment and adoption. \nThe fifth consideration could be called societal norms, which is a broad term for \nthe potential regulatory factors and societal acceptance factors we may encounter. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 472
  },
  {
    "chunk_full": "JAMES MANYIKA\n293\nA great example of this can be seen in driverless vehicles. Today, we already fully \naccept the fact that most commercial planes are only being piloted by an actual \npilot less than 7% of the time. The rest of the time, the plane is flying itself. The \nreason no-one really cares about the pilot situation, even if it goes down to 1%, \nis because no-one can see inside the cockpit. The door is closed, and we’re sitting \non a plane. We know there’s a pilot in there, but whether we know that they’re \nflying or not doesn’t matter because we can’t see. Whereas with a driverless car, \nwhat often freaks people out is the fact that you can actually look in the driver’s \nseat and there’s no-one there; the car’s moving on its own. \nThere’s a lot of research going on now looking at people’s social acceptance or \ncomfort with interacting with machines. Places like MIT are looking at social \nacceptance across different age groups, across different social settings, and across \ndifferent countries. For example, in places like Japan, having a physical machine in \na social environment is a bit more acceptable than in some other countries. We also \nknow that, for example, different age groups are more or less accepting of machines, \nand it can vary depending on different environments or settings. If we move to a \nmedical setting, with a doctor who goes into the back room to use a machine, out \nof view, and then just comes back with your diagnosis—is that okay? Most of us \nwould accept that situation, because we don’t actually know what happened in the \nback room with the doctor. But if a screen wheels into your room and a diagnosis \njust pops up without a human there to talk you through it, would we be comfortable \nwith that? Most of us probably wouldn’t be. So, we know that social settings affect \nsocial acceptance, and that this is going to also affect where see these technologies \nadopted and applied in the future.\nMARTIN FORD: But at the end of the day, what does this mean for jobs across the board?\nJAMES MANYIKA: Well, the point is that as you work your way through these five \nkey considerations, you start to realize that the pace and extent of automation, and \nindeed the scope of the jobs that are going to decline, is actually a more deeply \nnuanced picture that’s likely to vary from occupation to occupation and place to place. \nIn our last report at MGI, which considered the factors I just described, and \nin particular considered wages, costs and feasibility, we developed a number of \nscenarios. Our midpoint scenario suggests that as many as 400 million jobs could \nbe lost globally by 2030. This is an alarmingly large number, but as a share of \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 473
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n294\nthe global labor force that is about 15%. It will be higher, though, in advanced \ncountries than in developing countries, given labor-market dynamics, especially \nwages, that we’ve been discussing. \nHowever, all these scenarios are obviously contingent on whether the technology \naccelerates even faster, which it could. If it did, then our assumption about “currently \ndemonstrated technology” would be out of the window. Further, if the costs of \ndeploying come down even faster than we anticipate, that would also change things. \nThat’s why we’ve got these wide ranges in the scenarios that we’ve actually built \nfor how many jobs would be lost. \nMARTIN FORD: What about the “jobs gained” aspect?\nJAMES MANYIKA: The “jobs gained” side of things is interesting because we know \nthat whenever there’s a growing and dynamic economy, there will be growth in jobs \nand demand for work. This has been the history of economic growth for the last 200 \nyears, where you’ve got vibrant, growing economies with a dynamic private sector. \nIf we look ahead to the next 20 years or so, there are some relatively assured drivers \nof demand for work. One of them is rising global prosperity as more people around \nthe work enter the consuming class and demand products and services. Another is \naging; and we know that aging is going to create a lot of demand for certain kinds \nof work that will lead to growth in a whole host of jobs and occupations. Now \nthere’s a separate question as to whether those will turn into well-paying jobs or \nnot, but we know that the demand for care work and other things is going to go up. \nAt MGI we’ve also looked at other catalysts, like whether we’re going to ramp up \nadaptation for climate change, retrofitting our systems and our infrastructure—which \ncould drive demand for work above and beyond current course and speed. We also \nknow that if societies like the United States and others finally get their act together \nto look at infrastructure growth, and make investments in infrastructure, then that’s \nalso going to drive demand for work. So, one place where work’s going to come \nfrom is a growing economy and these specific drivers of demand for work. \nAnother whole set of jobs are going to come from the fact that we’re actually going \nto invent new occupations that didn’t previously exist. One of the fun analyses we \ndid at MGI—and this was prompted by one of our academic advisors, Dick Cooper \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 474
  },
  {
    "chunk_full": "JAMES MANYIKA\n295\nat Harvard—was to look at the Bureau of Labor Statistics. This typically tracks \nabout 800 occupations, and there’s always a line at the bottom called “Other.” This \nbucket of occupations called “Other” typically reflects occupations that in the current \nmeasurement period have not yet been defined and didn’t exist, so the Bureau \ndoesn’t have a category for them. Now, if you had looked at the Labor Statistics \nlist in 1995, a web designer would have been in the “Other” category because it \nhadn’t been imagined previously, and so it hadn’t been classified. What’s interesting \nis that the “Other” category is the fastest-growing occupational category because \nwe’re constantly inventing occupations that didn’t exist before. \nMARTIN FORD: This is an argument that I hear pretty often. For example, just \n10-years ago, jobs that involve social media did not exist. \nJAMES MANYIKA: Exactly! If you look at 10-year periods in the United States, at \nleast 8% to 9% of jobs are jobs that didn’t exist in the prior period—because we’ve \ncreated them and invented them. That’s going to be another source of jobs, and we \ncan’t even imagine what those will be, but we know they’ll be there. Some people \nhave speculated that category will include new types of designers, and people who \ntrouble shoot and manage machines and robots. This undefined, new set of jobs \nwill be another driver of work.\nWhen we’ve looked at the kind of the jobs gained, and considered these different \ndynamics, then unless the economy tanks and there’s massive stagnation, the numbers \nof jobs gained are large enough to more than make up for the jobs lost. Unless, of \ncourse, some of variables change catastrophically underneath us, such as a significant \nacceleration in the development and adoption of these technologies, or we end up \nwith massive economic stagnation. Any combination of those things and then yes, \nwe’ll end up with more jobs lost than jobs gained. \nMARTIN FORD: Ok, but if you look at the employment statistics, aren’t most \nworkers employed in pretty traditional areas, such as cashiers, truck drivers, nurses, \nteachers, doctors or office workers? These are all job categories that were here 100 \nyears ago, and that’s still where the vast majority of the workforce is employed.\nJAMES MANYIKA: Yes, the economy is still made up of a large chunk of those \noccupations. While some of these will decline, few will disappear entirely and \ncertainly not as quickly as some are predicting. Actually, one of the things that \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 475
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n296\nwe’ve looked at is where, over the last 200 years, we’ve seen the most massive \njob declines. For example, we studied what happened to manufacturing in the \nUnited States, and the shift from agriculture to industrialization. We looked at \n20 different massive job declines in different countries and what happened in \neach, compared to the range of scenarios for job declines due to automation and \nAI. It turned out the ranges that we anticipate now are not out of the norm, \nat least in the next 20 years anyway. Now beyond that, who knows? Even with \nsome very extreme assumptions, we’re still well within the ranges of shifts that \nwe have seen historically. \nThe big question, at least in the next 20 or so years, is whether there will be enough \nwork for everybody. As we discussed, at MGI we conclude there will be enough \nwork for everybody, unless we get to those very extreme assumptions. The other \nimportant question we must ask ourselves is how big are the scale of transitions \nthat we’ll see between those occupations that are declining, and those occupations \nthat are be growing? What level of movement will we see from one occupation to \nanother, and how much will the workplace need to adjust and adapt to machines \ncomplementing people as opposed to people losing their jobs? \nBased on our research, we’re not convinced that on our current course and speed \nwe’re well set up to manage those transitions in terms of skilling, educating, and \non-the-job training. We actually worry more about that question of transition than \nabout the “Will there be enough work?” question. \nMARTIN FORD: So, there really is the potential for a severe skill mismatch \nscenario going forward?\nJAMES MANYIKA: Yes, skill mismatches is a big one. Sectoral and occupation \nchanges, where people have to move from one occupation to another, and adapt to \nhigher or lower skill, or just different skills. \nWhen you look at the transition in terms of sectoral and geographic locational \nquestions, say in the United States, there will be enough work, but then you go \ndown to the next level to look at the likely locations for that work, and you see \nthe potential for geographic locational mismatches, where some places look like \nthey’ll be more in a hole than other places. These kinds of transitions are quite \nsubstantial, and it’s not quite clear if we’re ready for them. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 476
  },
  {
    "chunk_full": "JAMES MANYIKA\n297\nThe impact on wages is another important question. If you look at the likely \noccupational shifts, so many of the occupations that are likely to decline have \ntended to be the middle-wage occupations like accountants. Many well-paying \noccupations have involved data analysis in one form or another. They have also \ninvolved physical work in highly structured environments, like manufacturing. \nAnd so that’s where many of the occupations that are going to decline sit on the \nwage spectrum. Whereas many of the occupations that are going to grow—like \nthe care work we just talked about—are occupations that, at today’s current wage \nstructures, don’t pay as well. These occupational mix shifts will likely cause a \nserious wage issue. We will need to either change the market mechanisms for \nhow these wage dynamics work or develop some other mechanisms that shape \nthe way these wages are structured. \nThe other reason to worry about the wage question comes from a deeper \nexamination of the narrative that many of us as technologists have been saying \nso far. When we say, “No, don’t worry about it. We’re not going to replace \njobs, machines are going to complement what people do,” I think this is true, \nour own MGI analysis suggests that 60% of occupations will only have about \na third of their activities automated by machines, which means people will be \nworking alongside machines. \nBut if we examine this phenomenon with wages in mind, it’s not so clear-cut because \nwe know that when people are complemented by machines, you can have a range of \noutcomes. We know that, for example, if a highly skilled worker is complemented \nby a machine, and the machine does what it does best, and the human is still doing \nhighly value-added work to complement the machine, that’s great. The wages for \nthat work are probably going to go up, productivity will go up and it’ll all work \nout wonderfully well all round, which is a great outcome. \nHowever, we could also have the other end of the spectrum, where if the person’s \nbeing complemented by a machine—even if the machine is only 30% of the work, \nbut the machine is doing all the value-added portion of that work—then what’s \nleft over for the human being is deskilled or less complex. That can lead to lower \nwages because now many more people can do those tasks that previously required \nspecialized skills, or required a certification. That means that what you’ve done \nby introducing machines into that occupation could potentially put pressure on \nwages in that occupation. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 477
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n298\nThis idea of complementing work has this wide range of potential outcomes, and \nwe tend just to celebrate the one end of the result spectrum, and not talk as much \nabout the other, deskilled, end of the spectrum. This by the way also increases the \nchallenge of reskilling on an ongoing basis as people work alongside ever evolving \nand increasingly capable machines. \nMARTIN FORD: A good example of that is the impact of GPS on London taxi drivers.\nJAMES MANYIKA: Yes, that’s a great example of where the labor-supplied limiting \nportion was really “the Knowledge” of all the streets and shortcuts in the minds of the \nLondon taxi drivers. When you devalue that skill because of GPS systems, what’s left \nover is just the driving, and many more people can drive and get you from A to B.\nAnother example here, in an old form of deskilling, is to think about call center \noperators. It used to be that your call center person actually had to know what \nthey were talking about often at a technical level in order to be helpful to you. \nToday, however, organizations embedded that knowledge into the script that they \nread. What’s left over for the most part is just someone who can read a script. \nThey don’t really need to know the technical details, at least not as much as before; \nthey just need to be able to follow and read the script, unless they get to a real \ncorner case, where they can escalate to a deep expert. \nThere are many examples of service work and service technician work, whether it’s \nthrough the call center, or even people physically showing up to done on-site repairs, \nwhere some portions of that work are going through this massive deskilling—because \nthe knowledge is embedded in either technology, or scripts, or some other way to \nencapsulate the knowledge required to solve the problem. In the end, what’s left \nover is something much more deskilled.\nMARTIN FORD: So, it sounds like overall, you’re more concerned about the impact \non wages than outright unemployment? \nJAMES MANYIKA: Of course you always worry about unemployment, because you \ncan always have this corner-case scenario that could play out, which results in a \ngame over for us as far as employment is concerned. But I worry more about these \nworkforce transition issues, such as skills shifts, occupational shifts and how will we \nsupport people through these transitions. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 478
  },
  {
    "chunk_full": "JAMES MANYIKA\n299\nI also worry about the wage effects, unless we evolve how we value work in our \nlabor markets. In a sense this problem has been around for a while. We all say that \nwe value people who look after our children, and we value teachers; but we’ve \nnever quite reflected that in the wage structure for those occupations, and this \ndiscrepancy could soon get much bigger, because many of the occupations that are \nlikely to grow are going to look like that.\nMARTIN FORD: As you noted earlier, that can feed back into the consumer-demand \nproblem, which in itself dampens down productivity and growth.\nJAMES MANYIKA: Absolutely. That would create a vicious cycle that further hurts \ndemand for work. And we need to move quickly. The reason why the reskilling and \non-the-job training portions are a really important thing is, first of all, because those \nskills are changing pretty rapidly, and people are going to need to adapt pretty rapidly. \nWe already have a problem. We have pointed this out in our research that if you \nlook across most advanced economies at how much these countries spend on on-\nthe-job training, the level of on-the-job training has been declining in the last 20 \nto 30 years. Given that on-the-job training is going to be a big deal in near the \nfuture, this is a real issue.\nThe other measure you can also look at is what is typically called “active labor-\nmarket supports.” These are things that are separate from on-the-job training and \nare instead the kind of support you provide workers when they’re being displaced, \nas they transition from one occupation to another. This is one of the things I think \nwe screwed up in the last round of globalization. \nWith globalization, one can argue all day along about how globalization was great \nfor productivity, economic growth, for consumer choice, and for products. All true, \nexcept when you look at the question of globalization through the worker lens; then \nit’s problematic. The thing that didn’t happen effectively was providing support for \nthe workers who were displaced. Even though we know the pain of globalization was \nhighly localized in specific places and sectors, they were still significant enough and \nreally affected many real people and communities. If you and your 9 friends worked \nin apparel manufacturing in the US in 2000, a decade later only 3 of those jobs \nstill exist, and the same is true if you and your 9 friends worked in a textile mill. \nTake Webster County in Mississippi where one third of jobs were lost due to what \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 479
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n300\nhappened to apparel manufacturing, which was a major part of that community. We \ncan say this will probably work out at an overall level, but that isn’t very comforting \nif you’re one of the workers in these particularly hard-hit communities.\nIf we say that we’re going to need to support both workers who have been, \nand those who are going to be, dislocated through these work transitions and \nwill need to go from one job to another, or one occupation to another, or one \nskill-set to another, then we’re starting from behind. So, the worker transition \nchallenges are a really big deal.\nMARTIN FORD: You’re making the point that we’re going to need to support \nworkers, whether they’re unemployed or they’re transitioning. Do you think a \nuniversal basic income is potentially a good idea for doing that? \nJAMES MANYIKA: I’m conflicted about the idea of universal basic income in \nthe following sense. I like the fact that we’re discussing it, because it’s an \nacknowledgment that we may have a wage and income issue, and it’s provoking \na debate in the world. \nMy issue with it is that I think it misses the wider role that work plays. Work is a \ncomplicated thing because while work provides income, it also does a whole bunch \nof other stuff. It provides meaning, dignity, self-respect, purpose, community and \nsocial effects, and more. By going to a UBI-based society, while that may solve the \nwage question, it won’t necessarily solve these other aspects of what work brings. \nAnd, I think we should remember that there will still be lots of work to be done.\nOne of the quotes that really sticks with me and I find quite fascinating is from \nPresident Lyndon B. Johnson’s Blue-Ribbon Commission on “Technology, Automation, \nand Economic Progress,” which incidentally included Bob Solow. One of the report’s \nconclusions is that “The basic fact is that technology eliminates jobs, not work.”\nMARTIN FORD: There’s always work to be done, but it might not be valued by \nthe labor market.\nJAMES MANYIKA: It doesn’t always show up in our labor markets. Just think about \ncare work, which in most societies tends to be done by women and is often unpaid. \nHow do we reflect the value of that care work in our labor markets and discussions \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 480
  },
  {
    "chunk_full": "JAMES MANYIKA\n301\non wages and incomes? The work will be there. It’s just whether it’s paid work, or \nrecognized as work, and compensated in that way. \nI like the fact that UBI is provoking the conversation about wages and income, \nbut I’m not sure it solves the work question as effectively as other things might \ndo. I prefer to consider concepts like conditional transfers, or some other way to \nmake sure that we are linking wages to some kind of activity that reflects initiative, \npurpose, dignity, and other important factors. These questions of purpose, meaning \nand dignity may in the end be what defines us.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 481
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n302\nJAMES MANYIKA is a senior partner at McKinsey & Company and chairman of the \nMcKinsey Global Institute (MGI). James also serves on McKinsey’s Board of Directors. \nBased in Silicon Valley for over 20 years, James has worked with the chief executives \nand founders of many of the world’s leading technology companies on a variety of issues. \nAt MGI, James has led research on technology, the digital economy, as well as growth, \nproductivity, and globalization. He has published a book on AI and robotics, another on \nglobal economic trends as well as numerous articles and reports that have appeared in \nbusiness media and academic journals. \nJames was appointed by President Obama as vice chair of the Global Development Council at \nthe White House (2012-16) and by Commerce Secretaries to the US Commerce Department’s \nDigital Economy Board of Advisors and the National Innovation Advisory Board. He serves \non the boards of the Council on Foreign Relations, John D. and Catherine T. MacArthur \nFoundation, Hewlett Foundation, and Markle Foundation.\nHe also serves on academic advisory boards including the Oxford Internet Institute, MIT’s \nInitiative on the Digital Economy. He is on the standing committee for the Stanford-\nbased 100 Year Study on Artificial Intelligence, a member of the AIIndex.org team, and \na fellow at DeepMind.\nJames was on the engineering faculty at Oxford University and a member of the \nProgramming Research Group and the Robotics Research Lab, a fellow of Balliol College, \nOxford, a visiting scientist at NASA Jet Propulsion Labs, and a faculty exchange fellow at \nMIT. A Rhodes Scholar, James received his DPhil, MSc, and MA from Oxford in Robotics, \nMathematics, and Computer Science, and a BSc in electrical engineering from University \nof Zimbabwe as an Anglo-American scholar.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 482
  },
  {
    "chunk_full": "JAMES MANYIKA\n303\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 483
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n304\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 484
  },
  {
    "chunk_full": "GARY MARCUS\n305\nGARY MARCUS\nFOUNDER AND CEO, GEOMETRIC INTELLIGENCE (ACQUIRED BY UBER)  \nPROFESSOR OF PSYCHOLOGY AND NEURAL SCIENCE, NYU\nGary Marcus was Founder and CEO of Geometric Intelligence, a machine \nlearning company acquired by Uber, and is a professor of psychology and neural \nscience at New York University, as well as the author and editor of several \nbooks, including The Future of the Brain and the bestseller Guitar Zero. \nMuch of Gary’s research has focused on understanding how children learn and \nassimilate language. His current work is on how insights from the human mind \ncan inform the field of artificial intelligence. \nIt’s not clear to me that you get to the accuracy levels  \nyou need for driving in Manhattan simply by adding  \nmore data to these big data-driven systems. You might  \nget to 99.99% accuracy, but if you do the numbers on  \nthat, that’s much worse than humans. \n“ \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 485
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n306\nMARTIN FORD: You wrote a book, Kluge, about how the brain is an imperfect \norgan; presumably, then, you don’t think the route to AGI is to try to perfectly \ncopy the human brain?\nGARY MARCUS: No, we don’t need to replicate the human brain and all of its \ninefficiencies. There are some things that people do much better than current \nmachines, and you want to learn from those, but there are lots of things you \ndon’t want to copy. \nI’m not committed to how much like a person an AGI system will look. However, \nhumans are currently the only system that we know of that can make inferences \nand plans over very broad ranges of data and discuss them in a very efficient way, \nso it pays to look into how people are doing that.\nThe first book that I wrote, published in 2001, was titled The Algebraic Mind, and \nit compared neural networks with humans. I explored what it would take to make \nneural networks better, and I think those arguments are still very relevant today. \nThe next book I wrote was called The Birth of the Mind, and was about understanding \nhow genes can build the innate structures in our mind. It comes from the Noam \nChomsky and Steven Pinker tradition of believing that there are important things \nbuilt into the mind. In the book, I tried to understand what innateness might mean \nin terms of molecular biology and developmental neuroscience. Again, I think the \nideas there are quite relevant today. \nIn 2008 I published Kluge: The Haphazard Evolution of the Human Mind. For those \nwho may not know, “kluge” is an old engineer’s term for a clumsy solution to a \nproblem. In that book, I argued that in many ways the human mind was actually \nsomething like that. I examined discussions about whether humans are optimal—to \nwhich I think they’re clearly not—and tried to understand from an evolutionary \nperspective why we’re not optimal.\nMARTIN FORD: That’s because evolution has to work from an existing framework \nand build from there, right? It can’t go back and redesign everything from scratch.\nGARY MARCUS: Exactly. A lot of the book was about our memory structure, \nand how that compares to other systems. For example, when you compare our \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 486
  },
  {
    "chunk_full": "GARY MARCUS\n307\nauditory systems to what’s theoretically possible, we come very close to optimal. \nIf you compare our eyes to the theoretical optimum, we’re again close—given \nthe right conditions, you can see a single photon of light, and that’s amazing. Our \nmemory, however, is not optimal. \nYou could very quickly upload the complete works of Shakespeare to a computer, \nor in fact, most of what’s been written ever, and a computer won’t forget any of it. \nOur memories are nowhere near theoretically optimal in terms of their capacity or \nin terms of the stability of the memory that you store. Our memories tend to blur \ntogether over time. If you park in the same space every day you can’t remember \nwhere you parked today, because you can’t keep today’s memory distinct from \nyesterday’s memory. A computer would never have trouble with that. \nThe argument I made in the book was that we could examine and understand \nwhy humanity had such crummy memories, in terms of what our ancestors \nneeded from their memory. It was mostly broad statistical summaries like: \n“there’s more food up the mountain than down the mountain.” I don’t need \nto remember what individual days I derived those memory traces from, I just \nneed the general trend that it’s more fertile up the mountain as opposed to \ndown the mountain. \nVertebrates evolved that kind of memory—instead of what computers use, which \nis a location-addressable memory where every single location in the memory \nis assigned to a particular stable function. That’s what allows you to store \nessentially infinite information on a computer without having the problem of \nblurring things together. Humans went down a different path in the evolutionary \nchain, and it would be very costly in terms of the number of genes that we \nwould need to change in order to just rebuild the system from scratch around \nlocation-addressable memory. \nIt’s actually possible to build hybrids. Google is a hybrid, as it has location-\naddressable memory underneath and then cue-addressable memory, which is what \nwe have, on top. That’s a much better system. Google can take reminder cues as \nwe can, but then it has a master map of where everything is, so it serves up the \nright answer instead of arbitrarily distorting the answer.\nMARTIN FORD: Could you explain that in more detail? \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 487
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n308\nGARY MARCUS: Cue-addressable memory is where memories are triggered or aided \nby other factors. There are crazy versions of this like posture-dependent memory. \nThis is where if you learned something standing up then you’ll remember it better \nif you try to recall it standing up than if you’re lying down. The most notorious \none is state-dependent memory. For example, if you study for an exam while you’re \nstoned, you might actually be better off being stoned when you take the exam. \nI don’t suggest doing that…the point is that the state and the cues around you \ninfluence what you remember. \nOn the other hand, you can’t say, “I want memory location 317” or “the thing \nI learned on March 17, 1997.” As a human, you can’t pull things out the way a \ncomputer could. A computer has these indexes that are actually like a set of post-\noffice boxes, and what is put in box number 972 stays there indefinitely, unless you \ndeliberately tamper with it. \nIt doesn’t even appear that our brain has a handle on this. The brain does not \nhave an internal addressing system to know where individual memories are \nstored. Instead, it seems like the brain does something more like an auction. \nIt says, “Is there anything out there that can give me information about what I \nshould be doing in a car on a sunny day?” What you get back is a set of relevant \nmemories without knowing, at least consciously, where they are physically \nstored in the brain. \nThe problem is sometimes they blur together, and that leads for example, to \nproblems with eyewitness testimonies. You can’t actually keep the state of what \nhappened at a particular moment, separate from what you thought about later, or \nwhat you saw on television or read in the newspaper. All these things blur together \nbecause they’re not distinctly stored. \nMARTIN FORD: That’s interesting. \nGARY MARCUS: The first central claim of my book Kluge was that there are \nbasically two kinds of memory and that humans got stuck with the one that’s \nless useful. I further argued that once we have that in our evolutionary history, \nit becomes astonishingly unlikely that you’re going to start from scratch, so you \njust build on top of that. This is like Stephen Jay Gould’s famous arguments \nabout the panda’s thumb. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 488
  },
  {
    "chunk_full": "GARY MARCUS\n309\nOnce you have that kind of memory, other things come with it, such as confirmation \nbias. Confirmation bias is where you remember facts that are consistent with your \ntheory better than facts that are inconsistent with your theory. A computer doesn’t \nneed to do that. A computer can search for everything that matches a zip code or \neverything that doesn’t match a zip code. It can use NOT operators. Using a computer, \nI can search for everybody that is male and over 40 in my zip code, or equally \neverybody that doesn’t match those criteria. The human brain, using cue-addressable \nmemory, can only search for matches within data. Everything else is much harder. \nIf I have a theory then I can find material that matches my theory, but anything \nthat doesn’t match doesn’t come to mind as easily. I can’t systematically search for \nit. That’s confirmation bias. \nAnother example is the focusing illusion, where I ask you two questions in one of \ntwo orders. I either ask you how happy are you with your marriage and then how \nhappy are you with your life, or in the other order. If I ask you first how happy you \nare with your marriage, that influences how you think about your life in general. \nYou should be able to keep the two things completely separate.\nMARTIN FORD: That sounds like Daniel Kahneman’s anchoring theory, where he \ntalks about how you can give people a random number, and then that number will \ninfluence their guess about anything.\nGARY MARCUS: Yes, it’s a variation. If I asked you when the Magna Carta was \nsigned, after first asking you to look at the last three digits on a dollar bill, those \nthree digits on the dollar bill anchor your memory.\nMARTIN FORD: Your career trajectory is quite different from a lot of other people \nin the field of AI. Your early work focused on understanding human language and \nthe way children learn it, and more recently you co-founded a startup company \nand helped launch Uber’s AI labs.\nGARY MARCUS: I feel a bit like Joseph Conrad (1857-1924), who spoke Polish \nbut wrote in English. While he wasn’t a native speaker of English, he had a lot of \ninsights into the workings of it. In the same way, I think of myself as not a native \nspeaker of machine learning or AI, but as someone who is coming to AI from the \ncognitive sciences and has fresh insights. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 489
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n310\nI did a lot of computer programming throughout my childhood and thought a \nlot about artificial intelligence, but I went to graduate school more interested \nin the cognitive sciences than artificial intelligence. During my time at graduate \nschool, I studied with the cognitive scientist Steven Pinker, where we looked \nat how children learn the past tense within a language and then examined that \nusing the precursors to deep learning that we had at the time, namely multi-\nlayer and two-layer perceptrons. \nIn 1986, David Rumelhart and James L. McClelland published a paper titled \nParallel Distributed Processing: explorations in the microstructure of cognition, which \nshowed that a neural network could learn the past tense of English. Pinker and I \nlooked at the paper in some detail, and although it was true that you could get a \nneural network to overregularize and say things like “goed” or “breaked” like kids \ndo, all of the facts about when and how they made those errors were actually \nquite different. In response to the paper, we hypothesized that kids use a hybrid \nof both rules and neural networks.\nMARTIN FORD: You’re talking about irregular word endings, where kids will \nsometimes make them regular by mistake.\nGARY MARCUS: Right, kids sometimes regularize irregular verbs. I once did an \nautomated machine-driven analysis of 11,000 utterances of kids talking to their \nparents with past-tense verbs. In my study, I was looking at when kids made these \noverregularization errors and plotting the time course of the errors and which verbs \nwere more vulnerable to these errors. \nThe argument that we made was that children seem to have a rule for the regulars. \nFor example, they add -ed, but at the same time, they also had something of an \nassociative memory, which you might think of nowadays as a neural network, to do \nthe irregular verbs. The idea is if you’re inflecting the verb “sing” as “sang” in the past \ntense, you might be just using your memory for that. If your memory understands \n“sing” and “sang,” it’ll help you to remember “ring” and “rang.” \nHowever, if you inflect a word that doesn’t sound like anything you’ve heard before, \nlike to “rouge,” which would be to apply rouge to your face, then the word doesn’t \nneed to sound like anything you’ve heard before. You’ll still know to add -ed to it. \nYou’d say, “Diane rouged her face yesterday.” \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 490
  },
  {
    "chunk_full": "GARY MARCUS\n311\nThe point of that was that while neural networks are very good at things that work by \nsimilarity, they’re very weak at things where you don’t have a similarity but where you \nstill understand the rule. That was 1992, 25 years later and that basic point still persists \ntoday. Most neural networks still have the problem that they’re very data-driven, and \nthey don’t induce a high level of abstraction relative to what they’ve been trained on. \nNeural networks are able to capture a lot of the garden-variety cases, but if you think \nabout a long-tail distribution, they’re very weak at the tail. Here’s an example from \na captioning system: a system might be able to tell you that a particular image is of \na group of kids playing frisbee, simply because there are a lot of pictures that are \nlike that, but if you show it a parking sign covered with stickers then it might say \nit’s a refrigerator filled with food and drinks. That was an actual Google captioning \nresult. That’s because there aren’t that many examples of parking signs covered with \nstickers in the database, so the system performs miserably. \nThat key problem of neural networks not being able to generalize well outside \nof some core situations has been something that’s interested me for my entire \ncareer. From my point of view, it’s something that the machine learning field has \nstill not really come to grips with. \nMARTIN FORD: Understanding human language and learning is clearly one of the \npillars of your research. I was wondering if you could delve into some real-life \nexperiments that you’ve undertaken?\nGARY MARCUS: During my years of studying this from the perspective of understanding \nhuman generalization, I did research with children, adults, and ultimately with babies \nin 1999, all of which pointed to humans being very good at abstraction. \nThe experiment with babies showed that seven-month-olds could hear two minutes \nof an artificial grammar and recognize the rules of sentences constructed by that \ngrammar. Babies would listen to sentences like “la ta ta” and “ga na na” for two \nminutes with A-B-B grammar and would then notice that “wo fe wo” had a different \ngrammar (an A-B-A grammar) as opposed to “wo fe fe” that had the same grammar \nas the other sentences that they’d been trained on. \nThis was measured by how long they would look. We found that they would look \nlonger if we changed the grammar. That experiment really nailed that from very early \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 491
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n312\non in life babies have an ability to recognize pretty deep abstractions in the language \ndomain. Another researcher later showed that newborns could do the same thing. \nMARTIN FORD: I know that you have a great interest in IBM’s Watson, and that \nit drew you back into the field of AI. Could you talk about why Watson reignited \nyour interest in artificial intelligence?\nGARY MARCUS: I was skeptical about Watson, so I was surprised when it first won \nat Jeopardy in 2011. As a scientist, I’ve trained myself to pay attention to the things \nthat I get wrong, and I thought natural language understanding was too hard for \na contemporary AI to do. Watson should not be able to beat a human in Jeopardy, \nand yet it did. That made me start thinking about AI again\nI eventually figured out that the reason Watson won is because it was actually a \nnarrower AI problem than it first appeared to be. That’s almost always the answer. \nIn Watson’s case it’s because about 95% of the answers in Jeopardy turn out to \nbe the titles of Wikipedia pages. Instead of understanding language, reasoning \nabout it and so forth, it was mostly doing information retrieval from a restricted \nset, namely the pages that are Wikipedia titles. It was actually not as hard of a \nproblem as it looked like to the untutored eye, but it was interesting enough that \nit got me to think about AI again.\nAround the same time, I started writing for The New Yorker, where I was producing \na lot of pieces about neuroscience, linguistics, psychology, and also AI. In my pieces, \nI was trying to use what I knew about cognitive science and everything around \nthat—how the mind and language work, how children’s minds develop, etc.—in \norder to give me a better understanding of AI and the mistakes people were making.\nAround the same time, I starting writing and thinking a lot more about AI. One was \na critical piece on one of Ray Kurzweil’s books. Another was about self-driving cars \nand how they would make a decision if an out-of-control school bus were hurtling \ntoward them. Another, very prescient, piece criticized deep learning, saying that I \nthink, as a community, we should understand it as one tool among many, not as \na complete solution to AI. When I wrote that piece five years ago, I said that I \ndidn’t think deep learning would be able to do things like abstraction and causal \nreasoning, and if you look carefully, you’ll see that deep learning is still struggling \nwith exactly that set of problems.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 492
  },
  {
    "chunk_full": "GARY MARCUS\n313\nMARTIN FORD: Let’s talk about the company you started in 2014, Geometric \nIntelligence. I know that was eventually bought by Uber, shortly after which \nyou moved to Uber and became the head of their AI labs. Can you take us \nthrough that journey? \nGARY MARCUS: Back in January 2014 it occurred to me that instead of writing \nabout AI I should actually try to start a company of my own. I recruited some \ngreat people, including my friend Zoubin Ghahramani, who is one of the best \nmachine learning people in the world, and I spent the next couple of years \nrunning a machine learning company. I learned a lot about machine learning and \nwe built on some ideas of how to generalize better. That became our company’s \ncore intellectual property. We spent a lot of time trying to make algorithms \nlearn more efficiently from data. \nDeep learning is incredibly greedy in terms of the amount of data that it needs \nin order to solve a problem. That works well in artificial worlds, such as the \ngame of Go, but it doesn’t work that well over in the real world, where data \nis often expensive or difficult to obtain. We spent a lot of our time trying to \ndo better in that area and had some nice results. For example, we could learn \narbitrary tasks like the MNIST character recognition task with half as much \ndata as deep learning. \nWord got around, and eventually, we sold to Uber in December 2016. This entire \nprocess taught me quite a bit about machine learning, including its strengths and \nweaknesses. I worked briefly at Uber, helping with the launch of Uber AI labs, and \nthen moved on. Since then, I’ve been researching into how AI and medicine can be \ncombined, and also thinking a lot about robotics. \nIn January of 2018, I wrote two papers1 as well as a couple of pieces on Medium. \nOne strand of that was about deep learning and how although it’s very popular \nand our best tool for AI at the moment, it’s not going to get us to AGI (artificial \ngeneral intelligence). The second piece was about innateness, saying that, at least \nin biology, systems start with a lot of inherent structure, whether you’re talking \nabout the heart, the kidney, or the brain. The brain’s initial structure is important \nfor how we go about understanding the world. \n1  https://arxiv.org/abs/1801.00631\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 493
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n314\nPeople talk about Nature versus Nurture, but it’s really Nature and Nurture working \ntogether. Nature is what constructs the learning mechanisms that allow us to make \nuse of our experience in interesting ways.\nMARTIN FORD: That’s something that’s demonstrated by experiments with very \nyoung babies. They haven’t had time to learn anything, but they can still do \nessential things like recognize faces.\nGARY MARCUS: That’s right. My research with eight-month-olds also bears that \nout, and a recent paper in Science suggests that children are able to do logical \nreasoning after just the first year of life. Keep in mind that innate doesn’t mean \nexactly at birth. My ability to grow a beard is not something I began at birth, it \nwas timed to hormones and puberty. A lot of the human brain actually develops \noutside the womb, but relatively early in life. \nIf you look at precocial species like horses, they can walk almost right away after \nbeing born, and they have fairly sophisticated vision and obstacle detection. Some \nof those mechanisms for humans get wired up in the first year of life. You’ll often \nhear people say that a baby learns to walk, but I don’t think that’s actually the \ncase. There’s certainly some learning and calibration of muscle forces and so on, \nbut some of it is maturation. A head containing a fully developed human brain \nwould be too big to pass through the birth canal. \nMARTIN FORD: Even if you had an innate ability to walk, you’d have to wait for \nthe muscles to develop before you could put it into operation.\nGARY MARCUS: Right, and those aren’t fully developed either. We come out not quite \nfully hatched, and I think that confuses people. A lot of what’s going on in the first \nfew months is still pretty much genetically controlled. It’s not about learning per se. \nLook at a baby ibex. After a couple of days, it can scramble down the side of a \nmountain. It doesn’t learn that by trial-and-error—if it falls off the side of a mountain \nthen it’s dead—yet it can do spectacular feats of navigation and motor control. \nI think our genomes wire a very rich first draft of how our brains should operate, \nthen there’s lots of learning on top of that. Some of that first draft is, of course, \nabout making the learning mechanisms themselves. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 494
  },
  {
    "chunk_full": "GARY MARCUS\n315\nPeople in AI often try to build things with as little prior knowledge as they can \nget away with, and I think that’s foolish. There’s actually lots of knowledge about \nthe world that’s been gathered by scientists and ordinary people that we should be \nbuilding into our AI systems, instead of insisting, for no really good reason, that \nwe should start from scratch.\nMARTIN FORD: Any innateness that exists in the brain has to be the result of \nevolution, so with an AI you could either hardcode that innateness, or perhaps you \ncould use an evolutionary algorithm to generate it automatically.\nGARY MARCUS: The problem with that idea is that evolution is pretty slow \nand inefficient. It works over trillions of organisms and billions of years to get \ngreat results. It’s not clear that you’d get far enough with evolution in a lab in \na reasonable timeframe.\nOne way to think about this problem is that the first 900 million years of evolution \nwere not that exciting. Mostly you had different versions of bacteria, which is not \nthat exciting. No offense to the bacteria. \nThen suddenly things pick up and you get vertebrates, then mammals, then primates, \nand finally, you get us. The reason that the pace of evolution increased is because \nit’s like having more subroutines and more library code in your programming. The \nmore subroutines you have, the quicker you can build more complicated things on \ntop of that. It’s one thing to build a human on top of a primate brain with 100 or \n1,000 important genetic changes, but you wouldn’t be able to make a similar leap \nfrom bacteria to a human brain. \nPeople working on evolutionary neural networks often start too close to the bone. \nThey’re trying to evolve individual neurons and connections between them, when \nmy belief is that in the biological evolution of, say, humans, you already had very \nsophisticated sets of genetic routines. Essentially, you’ve got cascades of genes \non which to operate and people haven’t really figured out how to do that in the \nevolutionary programming context. \nI think they will eventually, but partly because of prejudice they haven’t so far. The \nprejudice is, “I want to start from scratch in my lab and show that I can be God by \ncreating this in seven days.” That’s ridiculous; it’s not going to happen. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 495
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n316\nMARTIN FORD: If you were going to build this innateness into an AI system, do \nyou have a sense of what that would look like? \nGARY MARCUS: There are two parts to it. One is functionally what it should do, \nand the other is mechanically how you should do it.\nAt the functional level, I have some clear proposals drawing from my own work, \nand that of Elizabeth Spelke at Harvard. I laid this out in a paper that I wrote \nearly in 2018, where I talked about ten different things that would be required2. \nI won’t go into them in depth here, but things like symbol manipulation and the \nability to represent abstract variables, which computer programs are based on; \noperations over those variables, which is what computer programs are; a type-token \ndistinction, recognizing this bottle as opposed to bottles in general; causality; spatial \ntranslation or translation invariance; the knowledge that objects tend to move on \npaths that are connected in space and time; the realization that there are sets of \nthings, places, and so on.\nIf you had things like that, then you could learn about what particular kinds of \nobjects do when they’re in particular kinds of places and they’re manipulated by \nparticular kinds of agents. That would be better than just learning everything from \npixels, which is a very popular but I think ultimately inadequate idea that we are \nseeing in the field right now.\nWhat we see at the moment is people doing deep reinforcement learning over \npixels of, for example, the Atari game Breakout, and while you get results that look \nimpressive, they’re incredibly fragile. \nDeepMind trained an AI to play Breakout, and when you watch it, it looks like \nit’s doing great. It’s supposedly learned the concept of breaking through the wall \nand trapping the ball at the top so it can ricochet across a lot of blocks. However, \nif you were to move the paddle three pixels up, the whole system breaks because \nit doesn’t really know what a wall is or what a ricochet is. It’s really just learned \ncontingencies, and it’s interpolating between the contingencies that it’s memorized. \nThe programs are not learning the abstraction that you need, and this is the problem \nwith doing everything from pixels and very low-level representations.\n2  https://arxiv.org/abs/1801.05667\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 496
  },
  {
    "chunk_full": "GARY MARCUS\n317\nMARTIN FORD: It needs a higher level of abstraction to understand objects and concepts.\nGARY MARCUS: Exactly. You may also need to actually build in certain notions. like \n“object.” One way to think about it is like the ability to learn to process color. You \ndon’t start with black-and-white vision and eventually learn that there is color. It \nstarts by having two different color-receptor pigments that are sensitive to particular \nparts of the spectrum. Then, from there, you can learn about particular colors. You \nneed some piece to be innate before you can do the rest. Maybe in a similar way, \nyou might need to have innately the notion that there’s an object, and maybe the \nconstraint that objects don’t just randomly appear and disappear. \nImagine a world in which there was a Star Trek transporter, and anything could \nappear at any place at any moment. You’d never be able to learn from that. What \nallows us to learn about the world is the fact that objects do move on paths that \nare connected in space and time, and over a billion years of evolution that might \nhave been wired in as a way of getting you off the ground faster.\nMARTIN FORD: Let’s talk about the future. What do you see as the main hurdles \nto getting to AGI, and can we get there with current tools? \nGARY MARCUS: I see deep learning as a useful tool for doing pattern classification, \nwhich is one problem that any intelligent agent needs to do. We should either \nkeep it around for that, or replace it with something that does similar work more \nefficiently, which I do think is possible.\nAt the same time, there are other kinds of things that intelligent agents need to \ndo that deep learning is not currently very good at. It’s not very good at abstract \ninference, and it’s not a very good tool for language, except things like translation \nwhere you don’t need real comprehension, or at least not to do approximate \ntranslation. It’s also not very good at handling situations that it hasn’t seen before \nand where it has relatively incomplete information. We therefore need to supplement \ndeep learning with other tools.\nMore generally, there’s a lot of knowledge that humans have about the world that \ncan be codified symbolically, either through math or sentences in a language. \nWe really want to bring that symbolic information together with the other \ninformation that’s more perceptual. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 497
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n318\nPsychologists talk about the relationship between top-down information and \nbottom-up information. If you look at an image, light falls on your retina and \nthat’s bottom-up information, but you also use your knowledge of the world \nand your experience of how things behave to add top-down information to your \ninterpretation of the image.\nDeep learning systems currently focus on bottom-up information. They can \ninterpret the pixels of an image, but don’t then have any knowledge of the object \nthe image contains. \nAn example of this recently was the Adversarial Patch paper3. In the paper, they \nshow how you can fool a deep learning system by adding a sticker to an image. \nThey take a photo of a banana that is recognized with great confidence by a deep \nlearning system and then add a sticker that looks like a psychedelic toaster next to \nthe banana in the photo. Any human looking at it would say it was a banana with \na funny looking sticker next to it, but the deep learning system immediately says, \nwith great confidence, that it’s now a picture of a toaster. \nThe deep learning system is just trying to say what the most salient thing in the \nimage is, and the high-contrast psychedelic toaster grabs its attention and it ignores \nthe perfectly clear banana. \nThis is an example of how deep learning systems are only getting the bottom-up \ninformation, which is what your occipital cortex does. It’s not capturing at all what \nyour frontal cortex does when it reasons about what’s really going on. \nTo get to AGI, we need to be able to capture both sides of that equation. Another \nway to put it is that humans have all kinds of common-sense reasoning, and that \nhas to be part of the solution. It’s not well captured by deep learning. In my \nview, we need to bring together symbol manipulation, which has a strong history \nin AI, with deep learning. They have been treated separately for too long, and \nit’s time to bring them together.\nMARTIN FORD: If you had to point to one company or project that’s going on now \nthat is the closest to being on the path to AGI, who would you point to?\n3  https://arxiv.org/pdf/1712.09665.pdf\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 498
  },
  {
    "chunk_full": "GARY MARCUS\n319\nGARY MARCUS: I’m very excited about Project Mosaic at the Allen Institute for \nAI. They’re taking a second crack at the problem Doug Lenat was trying to solve, \nwhich was how you take human knowledge and put it in computable form. This \nis not about answering questions like where was Barack Obama born—computers \nactually represent that information pretty well and can extract it from available data. \nThere’s a lot of information, though, that’s not written anywhere, for example, \ntoasters are smaller than cars. The likelihood is that no one says that on Wikipedia, \nbut we know it to be true and that allows us to make inferences. If I said, “Gary \ngot run over by a toaster,” you would think that’s weird because a toaster’s not that \nbig an object, but “run over by a car” makes sense.\nMARTIN FORD: So this is in the area of symbolic logic? \nGARY MARCUS: Well, there are two related questions. One question is, how \ndo you get that knowledge at all? The other is, do you want symbolic logic as \na way to manipulate that?\nMy best guess is that symbolic logic is actually pretty useful for it, and we \nshouldn’t throw it out the window. I’m open to somebody finding another way \nto deal with it, but I don’t see any ways in which people have dealt with it \nwell, and I don’t see how we can build systems that really understand language \nwithout having some of that common sense. This is because every time I say \na sentence to you, there’s some common-sense knowledge that goes into your \nunderstanding of that sentence. \nIf I tell you I’m going to ride my bicycle from New York to Boston, I don’t have \nto tell you that I’m not going to fly through the air, go underwater, or take a \ndetour to California. You can figure all that stuff out for yourself. It’s not in \nthe literal sentence, but it’s in your knowledge about humans that they like to \ntake efficient routes.\nYou, as a human, can make a lot of inferences. There’s no way you can understand \nmy sentences without filling in those inferences, where you’re effectively reading \nbetween the lines. We read an enormous amount between the lines, but for that \nwhole transaction to work there has to be shared common sense, and we don’t have \nmachines that have that shared common sense yet. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 499
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n320\nThe biggest project to do that was Doug Lenat’s Cyc, which started around 1984 \nand by most accounts, it didn’t work very effectively. It was developed 30 years ago \nin a closed form. Nowadays we know much more about machine learning, and the \nAllen Institute for AI is committed to doing things in open-source ways in which \nthe community can participate. We know more about big data now than we did \nback in the 1980s, but it’s still a very difficult problem. The important thing is that \nthey’re confronting it when everybody else is hiding from it.\nMARTIN FORD: What do you think the timeframe is for AGI?\nGARY MARCUS: I don’t know. I know most of the reasons why it’s not here now \nand the things that need to be solved, but I don’t think you can put a single date \non that. What I think is that you need a confidence interval—as a statistician would \ndescribe it—around it.\nI might tell you that I think it’ll come between 2030 if we’re phenomenally lucky \nand more likely 2050, or in the worst case 2130. The point is that it’s very hard \nto give an exact date. There are lots of things we just don’t know. I always think \nabout how Bill Gates wrote the book The Road Ahead in 1994, and even he didn’t \nreally realize that the internet was going to change things as it did. My point is that \nthere could be all kinds of things that we’re just not anticipating.\nRight now, machines are weak at intelligence, but we don’t know what people \nare going to invent next. There’s a lot of money going into the field, which could \nmove things along, or alternatively it could be much harder than we think that \nit is. We just really don’t know.\nMARTIN FORD: That’s still a fairly aggressive time frame. You’re suggesting as soon \nas 12 years away or as far away as 112 years.\nGARY MARCUS: And those figures could of course be wrong. Another way to look \nat it is while we’ve made a lot of progress on narrow intelligence, we haven’t made \nnearly as much progress so far on general intelligence, AGI.\nApple’s Siri, which began life in 2010, doesn’t work that much differently from \nELIZA, an early natural language computer program created in 1964, which matched \ntemplates in order to give an illusion of understanding language that it didn’t really. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 500
  },
  {
    "chunk_full": "GARY MARCUS\n321\nA lot of my optimism comes from how many people are working at the problem \nand how much money businesses are investing to try and solve it. \nMARTIN FORD: It definitely is a massive change in terms of AI not being something \njust done as a research project at a university. Now AI is central to the business \nmodels of big companies like Google and Facebook.\nGARY MARCUS: The amount of money being spent on AI far eclipses anything before, \nalthough there certainly was a lot of money spent in the 1960s and early 1970s before \nthe first so-called AI Winter. It’s also important to acknowledge that money is not a \nguaranteed solution to the problems of AI, but is very likely a prerequisite. \nMARTIN FORD: Let’s focus on a prediction for a much narrower technology: \nthe self-driving car. \nWhen are we going to be able to call for something like an Uber that’s driven by \nnothing but an AI, and that can pick you up at a random location and then take \nyou to a destination that you specify?\nGARY MARCUS: It’s at least a decade away, and probably more. \nMARTIN FORD: You’re almost getting into the same territory as your AGI prediction.\nGARY MARCUS: That’s right, and for the principal reason that if you’re talking \nabout driving in a very heavy metropolitan location like Manhattan or Mumbai, \nthen the AI will face a lot of unpredictability. It’s one thing to have a driverless \ncar in Phoenix, where the weather is good and the population is a lot less densely \npacked. The problem in Manhattan is that anything goes at any moment, nobody \nis particularly well-behaved and everybody is aggressive, the chance of having \nunpredictable things occur is much higher. \nEven simple road elements like barricades to protect people can cause issues for an \nAI. These are complex situations that humans deal with by using reasoning. Right \nnow, driverless cars navigate by having highly detailed maps and things like LIDAR, \nbut no real understanding of the motives and behavior of other drivers. Humans \nhave an OK visual system, but a good understanding of what’s out there and what \nthey’re doing when they’re driving. Machines are trying to fake their way around \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 501
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n322\nthat with big data, and it’s not clear to me that you get to the accuracy levels you \nneed for driving in Manhattan simply by adding more data to these big data-driven \nsystems. You might get to 99.99% accuracy, but if you do the numbers on that, \nthat’s much worse than humans, and it’s far too dangerous to have that scale on the \nroad, especially on busy streets like in Manhattan.\nMARTIN FORD: Maybe then there’s a nearer term solution, where rather than a \nlocation of your choice, it takes you to a predefined location? \nGARY MARCUS: There’s a possibility that very soon we may well have that in \nPhoenix, or another limited location. If you can find a route where you never need \nto take a left turn, where humans are unlikely to be in the way, and the traffic \nis civilized, you might be able to do that. We already have monorails at airports \nthat work in a similar way following a predefined path.\nThere’s a continuum from super-controlled circumstances like the monorail at the \nairport where nobody should be on that track, to the Manhattan streets where \nanybody and anything could be there at any time. We also have other factors like \nthe fact that weather is much more complicated than in Phoenix. We get everything. \nSleet, slush, hail, leaves, things that fall off trucks; everything.\nThe more you go into an unbounded open-ended system, the more challenge there \nis and the more you need to be able to reason the way an AGI system does. It’s \nstill not as open-ended as AGI per se, but it starts to approach that, and that’s why \nmy numbers are not totally different.\nMARTIN FORD: Let’s talk about an area that I’ve focused on a lot: the economic \nand job market impact of AI. \nMany people believe we’re on the leading edge of a new Industrial Revolution; \nsomething that’s going to completely change the way the labor market looks. Would \nyou agree with that? \nGARY MARCUS: I do agree with that, though on a slightly slower time frame. \nDriverless cars are harder than we thought, so paid drivers are safe for a while, \nbut fast-food workers and cashiers are in deep trouble, and there’s a lot of them \nin the workplace. I do think these fundamental changes are going to happen. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 502
  },
  {
    "chunk_full": "GARY MARCUS\n323\nSome of them will be slow, but in the scale of, say, 100 years, if something \ntakes an extra 20 years, it’s nothing.\nThere is going to be a problem with AI robots and employment sometime in this \ncentury, whether it’s 2030 or 2070. At some point we need to change how we \nstructure our societies because we are going to get to a point where there’s less \nemployment available but still a working-age population. \nThere are counterarguments, like when most agricultural jobs disappeared they \nwere just replaced by industrial jobs, but I don’t find them to be compelling. The \nmain issue we will face is scale and the way that once you have a solution, you \ncan use it everywhere relatively cheaply. \nGetting the first driverless car algorithm/database system that works might be \n50 years of work and cost billions of dollars in research, but once we have them, \npeople are going to roll them out at scale. As soon as we reach that point, millions \nof truck drivers are going to be put in a position where they could lose their \njobs within a matter of years.\nIt’s not clear that we are going to have new jobs appear that can replace existing \njobs at the scale of the truck-driving industry. A lot of the new jobs that have \narisen need fewer people. For example, a YouTube entrepreneur is a great job. \nYou can make millions of dollars staying at home making videos. That’s terrific, \nbut maybe 1,000 people do that, not a million people and not enough to replace \nall the potentially lost truck driving jobs. \nIt’s easy to come up with jobs that we will have that we didn’t have before, but it’s \nhard to come up with new industries that will employ large numbers of people in \nan era where you can build something like Instagram with 18 people.\nMARTIN FORD: Probably something like half the current workforce is engaged in \nfundamentally predictable activities. What they’re doing is encapsulated in the data \nand ultimately is going to be susceptible to machine learning over some time frame.\nGARY MARCUS: True, but things like that that are pretty hard right now. AI systems \njust don’t really understand the data as a natural language like humans do. For example, \nextricating information from medical records is something that’s very hard for machines \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 503
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n324\nto do right now. It’s predictable, and it’s not that hard work, but doing it well with a \nmachine is a while away. In the long run, though, I agree with you. Natural language \nunderstanding will get better and eventually those predictable jobs will go away. \nMARTIN FORD: Given that you believe job loss to AI will happen at some point, \nwould you support a basic income as a potential solution to that?\nGARY MARCUS: I see no real alternative. We will get there, but it’s a question of \nwhether we get there peacefully through a universal agreement or whether there \nare riots on the street and people getting killed. I don’t know the method, but I \ndon’t see any other ending. \nMARTIN FORD: You could argue that technology is already having an impact of that \nsort. We do have an opioid epidemic in the US at the moment, and automation \ntechnology in factories has likely played a role in that in terms of middle-class job \nopportunities disappearing. Perhaps opioid use is tied to a perceived loss of dignity \nor even despair among some people, especially working-class men?\nGARY MARCUS: I would be careful about making that assumption. It may be true, \nbut I don’t think the links are ironclad. A better analogy, in my opinion, is how \na lot of people use their phones as an opioid, and that smartphones are the new \nopium of the people. We may be moving toward a world where a lot of people \njust hang out in virtual reality, and if the economics work they may be reasonably \nhappy. I’m not sure where that’s all going to go.\nMARTIN FORD: There’s a range of risks associated with AI that have been raised. \nPeople like Elon Musk have been especially vocal about existential threats. What \ndo you think we should be worried about in terms of the impacts and risks of AI?\nGARY MARCUS: We should be worrying about people using AI in malevolent \nways. The real problem is what people might do with the power that AI holds as \nit becomes more embedded in the grid and more hackable. I’m not that worried \nabout AI systems independently wanting to eat us for breakfast or turn us into \npaper clips. It’s not completely impossible, but there’s no real evidence that we’re \nmoving in that direction. There is evidence, though, that we’re giving more and more \npower to those machines, and that we have no idea how to solve the cybersecurity \nthreats in the near term. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 504
  },
  {
    "chunk_full": "GARY MARCUS\n325\nMARTIN FORD: What about long-term threats, though? Elon Musk and Nick Bostrom \nare very concerned about the control problem with AI; the idea that there could \nbe a recursive self-improvement cycle that could lead to an intelligence explosion. \nYou can’t completely discount that, right? \nGARY MARCUS: I don’t completely discount it, I’m not going to say the \nprobability is zero but the probability of it happening anytime soon is pretty low. \nThere was recently a video circulated of robots opening doorknobs, and that’s \nabout where they are in development. \nWe don’t have AI systems that can robustly navigate our world at all, nor do we \nhave robotic systems that know how to improve themselves, except in constrained \nways like tailoring their motor control system to a particular function. This is not \na current problem. I think it’s fine to invest some money in the field and have \nsome people think about those problems. My issue is that, as we saw with the \n2016 US election, there are more pressing problems like using AI to generate and \ntarget fake news. That’s a problem today.\nMARTIN FORD: Earlier you said AGI is conceivable as early as 2030. If a system is \ngenuinely intelligent, potentially superintelligent, do we need to make sure that its \ngoals are aligned with what we want it to do?\nGARY MARCUS: Yes, I think so. I will be surprised if we get there that quickly, \nbut it’s for that reason why I think that we should have some people thinking about \nthese problems. I just don’t think that they’re our most pressing problems right \nnow. Even when we do get to an AGI system, who’s to say that the AGI system is \ngoing to have any interest whatsoever in meddling in human affairs?\nWe’ve gone from AI not being able to win at checkers about 60 years ago \nto being able to win at Go, which is a much harder game, in the last year. \nYou could plot a game IQ, and make up a scale to say that game IQ has gone \nfrom 0 to 60 in 60 years. You could then do a similar thing for machine \nmalevolence. Machine malevolence has not changed at all over that time. \nThere’s no correlation, there is zero machine malevolence. There was none, and \nthere is none. It doesn’t mean that it’s impossible—I don’t want to make the \ninductive argument that because it never happened, it never will—but there’s \nno indication of it. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 505
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n326\nMARTIN FORD: It sounds to me like a threshold problem, though, you can’t have \nmachine malevolence until you have AGI. \nGARY MARCUS: Possibly. Some of it has to do with motivational systems and you \ncould try to construct an argument saying that AGI is a prerequisite for machine \nmalevolence, but you couldn’t say that it’s a necessary and sufficient condition.\nHere’s a thought experiment. I can name a single genetic factor that will increase \nyour chance of committing violent acts by a factor of 5. If you don’t have it, your \nproclivity to violence is pretty low. Are machine’s going to have this genetic factor, \nor not? The genetic factor, of course, is male versus female. \nMARTIN FORD: Is that an argument for making AGI female? \nGARY MARCUS: The gender is a proxy, it’s not the real issue, but it is an argument \nfor making AI nonviolent. We should have restrictions and regulations to reduce \nthe chance of AI being violent or of coming up with ideas of its own about what \nit wants to do with us. These are hard and important questions, but they’re much \nless straightforward than Elon’s quotes might lead a lot of people to think.\nMARTIN FORD: What he’s doing in terms of making an investment in OpenAI \ndoesn’t sound like a bad thing, though. Somebody ought to be doing that work. It \nwould be hard to justify having the government invest massive resources in working \non AI control issues, but having private entities doing that seems positive.\nGARY MARCUS: The US Department of Defense does spend some money on these \nthings, as they should, but you have to have a risk portfolio. I’m more worried about \ncertain kinds of bioterrorism than I am about these particular AI threats, and I’m \nmore worried about cyber warfare, which is a real going concern. \nThere are two key questions here. One is, do you think that the probability of X is \ngreater than 0? The answer is clearly yes. The other is, relative to the other risks that \nyou might be concerned about, where would you rank this? To which I would say, these \nare somewhat unlikely scenarios, and there are other scenarios that are more likely.\nMARTIN FORD: If at some point we succeed in building an AGI, do you think it would \nbe conscious, or is it possible to have an intelligent zombie with no inner experience?\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 506
  },
  {
    "chunk_full": "GARY MARCUS\n327\nGARY MARCUS: I think it’s the latter. I don’t think that consciousness is a \nprerequisite. It might be an epiphenomenon in humans or maybe some other \nbiological creatures. There’s another thought experiment that says, could we have \nsomething that behaves just like me but isn’t conscious? I think the answer is yes. \nWe don’t know for sure, because we don’t have any independent measure of what \nconsciousness is, so it’s very hard to ground these arguments. \nHow would we tell if a machine was conscious? How do I know that you’re conscious? \nMARTIN FORD: Well, you can assume I am because we’re the same species.\nGARY MARCUS: I think that’s a bad assumption. What if it turns out that \nconsciousness is randomly distributed through our population to one-quarter of the \npeople? What if it’s just a gene? I have the supertaster gene that makes me sensitive \nto bitter compounds, but my wife doesn’t. She looks like she’s from the same species \nas me, but we differ in that property, and so maybe we differ in the consciousness \nproperty also? I’m kidding, but we can’t really use an objective measure, here.\nMARTIN FORD: It sounds like an unknowable problem.\nGARY MARCUS: Maybe someone will come up with a cleverer answer, but so \nfar, most of the academic research is focused on the part of consciousness we call \nawareness. At what point does your central neural system realize logically that \ncertain information is available? \nResearch has shown that if you only see something for 100 milliseconds then you \nmight not realize you’d seen it. If you see it for half a second, you’re pretty sure \nyou actually saw it. With that data we can start to build up a characterization of \nwhich neural circuits at which time frame contribute information that you can \nreflect on, and we can call that awareness. That we’re making progress on, but not \nyet general consciousness.\nMARTIN FORD: You clearly think AGI is achievable, but do you think it’s inevitable? Do \nyou think there is any probability that maybe we can never build an intelligent machine?\nGARY MARCUS: It’s almost inevitable. I think the primary things that would keep \nus from getting there are other extinction-level existential risks, such as getting \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 507
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n328\nhit by an asteroid, blowing ourselves up, or engineering a super-disease. We’re \ncontinuously accumulating scientific knowledge, we’re getting better at building \nsoftware and hardware, and there’s no principled reason why not to do it. I think \nit will almost certainly happen unless we reset the clock, which I can’t rule out.\nMARTIN FORD: What do you think about the international arms race toward \nadvanced AI, particularly with countries like China? \nGARY MARCUS: China has made AI a major center of its ambitions and been very \npublic about it. The United States for a while had no response whatsoever, and I \nfound that disturbing and upsetting.\nMARTIN FORD: It does seem that China has many advantages, such as a much larger \npopulation and fewer privacy controls, which means more data. \nGARY MARCUS: They’re much more forward-thinking because they realize how \nimportant AI is, and they are investing in it as a nation.\nMARTIN FORD: How do you feel about regulation of the field? Do you think that \nthe government should get involved in regulating AI research?\nGARY MARCUS: I do, but it’s not clear to me what those regulations should be. I think a \nsignificant portion of AI funding should address those questions. They’re hard questions.\nFor example, I don’t love the idea of autonomous weapons, but to simply ban them \noutright is maybe naive and creates more problems, where some people have them, \nand others don’t. What should those regulations be, and how should we enforce \nthem? I’m afraid I don’t have the answer.\nMARTIN FORD: Do you believe that AI is going to be positive for humanity?\nGARY MARCUS: Hopefully, but I don’t think that is a given. The best way in which \nAI could help humanity is by accelerating scientific discovery in healthcare. Instead, \nAI research and implementation right now is mostly about ad placement.\nAI has a lot of positive potential, but I don’t think there’s enough focus on that \nside of it. We do some, but not enough. I also understand that there are going \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 508
  },
  {
    "chunk_full": "GARY MARCUS\n329\nto be risks, job losses, and social upheaval. I’m an optimist in a technical sense \nin that I do think AGI is achievable, but I would like to see a change in what we \ndevelop and how we prioritize those things. Right now, I’m not totally optimistic \nthat we’re heading in the right direction in terms of how we’re using AI and how \nwe’re distributing it. I think there’s serious work to be done there to make AI have \nthe positive impact on humanity that it could.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 509
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n330\nGARY MARCUS is a professor of psychology and neural science at New York University. Much \nof Gary’s research has focused on understanding how children learn and assimilate language, \nand how these findings might inform the field of artificial intelligence.\nHe is the author of several books, including The Birth of the Mind, Kluge: The Haphazard \nConstruction of the Human Mind, and the bestselling Guitar Zero, in which he explores \ncognitive challenges involved as he learns to play the guitar. Gary has also contributed \nnumerous articles on AI and brain science to The New Yorker and the New York Times. \nIn 2014 he founded and served as CEO of Geometric Intelligence, a machine learning startup \nthat was later acquired by Uber.\nGary is known for his criticism of deep learning and has written that current approaches \nmay soon “hit a wall.” He points out that the human mind is not a blank slate, but comes \npreconfigured with significant structure to enable learning. He believes that neural networks \nalone will not succeed in achieving more general intelligence, and that continued progress \nwill require incorporating more innate cognitive structure into AI systems.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 510
  },
  {
    "chunk_full": "GARY MARCUS\n331\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 511
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n332\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 512
  },
  {
    "chunk_full": "BARBARA J. GROSZ\n333\nBARBARA J. GROSZ\nHIGGINS PROFESSOR OF NATURAL SCIENCES, HARVARD UNIVERSITY\nBarbara J. Grosz is Higgins Professor of Natural Sciences at Harvard University. \nOver the course of her career, she has made ground-breaking contributions in \nartificial intelligence that have led to the foundational principles of dialogue \nprocessing that are important for personal assistants like Apple’s Siri or \nAmazon’s Alexa. In 1993, she became the first woman to serve as president of \nthe Association for the Advancement of Artificial Intelligence.\nI’m thrilled that AI is actually out there in the world  \nmaking a difference because I didn’t think that it  \nwould happen in my lifetime—because it seemed  \nthe problems were so hard.\n“ \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 513
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n334\nMARTIN FORD: What initially drove you to be interested in artificial intelligence, \nand how did your career progress? \nBARBARA GROSZ: My career was a series of happy accidents. I went to college \nthinking I would be a 7th-grade math teacher because my 7th-grade math teacher \nwas the only person I had met in my first 18 years of life who thought that women, \nin general, could do mathematics, and he told me that I was quite good at math. \nMy world really opened up though when I went to Cornell for college, as they \nhad just started a computer science faculty. \nAt the time there was no undergraduate major in computer science anywhere in the \nUS, but Cornell provided the opportunity to take a few classes. I started in numerical \nanalysis, a rather mathematical area of computer science, and ended up going to \nBerkeley to graduate school, initially for a master’s, then I moved into the PhD program.\nI worked in what would come to be called computational science and then \nbriefly in theoretical computer science. I decided that I liked the solutions in the \nmathematical areas of computer science, but not the problems. So when I needed \na thesis topic, I talked with many people. Alan Kay said to me, “Listen. You have to \ndo something ambitious for your thesis. Why don’t you write a program that will \nread a children’s story and tell it back from one of the character’s points of view?” \nThat’s what spurred my interest in natural language processing and is the root of \nmy becoming an AI researcher.\nMARTIN FORD: Alan Kay? He invented the graphical user interface at Xerox PARC, \nright? That’s where Steve Jobs got the idea for the Macintosh.\nBARBARA GROSZ: Yes, right, Alan was a key player in that Xerox PARC work. I \nactually worked with him on developing a programming language called Smalltalk, \nwhich was an object-oriented language. Our goal was to build a system suitable \nfor students [K-12] and learning. My children’s story program was to be written in \nSmalltalk. Before the Smalltalk system was finished, though, I realized that children’s \nstories were not just stories to be read and understood, but that they’re meant to \ninculcate a culture, and that Alan’s challenge to me was going to be really hard to meet. \nDuring that time, the first group of speech-understanding systems were also being \ndeveloped through DARPA projects, and the people at SRI International who were \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 514
  },
  {
    "chunk_full": "BARBARA J. GROSZ\n335\nworking on one of them said to me, “If you’re willing to take the risk of working \non children’s stories, why don’t you come work with us on a more objective kind \nof language, task-oriented dialogues, but using speech not text?” As a result, I got \ninvolved in the DARPA speech work, which was on systems that would assist people \nin getting tasks done, and that’s really when I started to do AI research.\nIt was that work which led to my discovery of how dialogue among people, when \nthey’re working on a task together, has a structure that depends on the task \nstructure—and that a dialogue is much more than just question-answer pairs. From \nthat insight, I came to realize that as human beings we don’t in general ever speak \nin a sequence of isolated utterances, but that there’s always a larger structure, much \nlike there is for a journal article, a newspaper article, a textbook, even for this \nbook, and that we can model that structure. This was my first major contribution \nto natural-language processing and AI. \nMARTIN FORD: You’ve touched on one of the natural language breakthroughs that \nyou’re most known for: an effort to somehow model a conversation. The idea that a \nconversation can be computed, and that there’s some structure within a conversation \nthat can be represented mathematically. \nI assume that this has become very important, because we’ve seen a lot of progress \nin the field. Maybe you could talk about some of the work you’ve done there and \nhow things have progressed. Has it astonished you where things are at now in \nterms of natural language processing, compared to where they were back when \nyou started your research?\nBARBARA GROSZ: It absolutely has astonished me. My early work was exactly in \nthis area of how we might be able to build a computer system that could carry on \na dialogue with a person fluently and in a way that seemed natural. One of the \nreasons I got connected to Alan Kay, and did that work with him, was because we \nshared an interest in building computer systems that would work with and adapt \nto people, rather than require people to adapt to them. \nAt the time that I took that work on, there was a lot of work in linguistics on \nsyntax and on formal semantics in philosophy and linguistics, and on parsing \nalgorithms in computer science. People knew there was more to language \nunderstanding than an individual sentence, and they knew that context mattered, \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 515
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n336\nbut they had no formal tools, no mathematics, and no computational constructs \nto take that context into account in speech systems. \nI said to people at the time that we couldn’t afford to just hypothesize about what \nwas going on, that we couldn’t just carry on introspecting, that we had to get \nsamples of how people actually carry on a dialogue when they’re doing a task. As \na result, I invented this approach, which later was dubbed the “The Wizard of Oz” \napproach by some psychologists. In this work, I sat two people—in this case, an \nexpert and an apprentice—in two different rooms, and I had the expert explain \nto the apprentice how to get something done. It was by studying the dialogues \nthat resulted from their working together that I recognized the structure in these \ndialogues and its dependence on task structure.\nLater, I co-wrote a paper with Candy Sidner titled Attention, Intentions, and the \nStructure of Discourse. In that paper we argue that dialogues have a structure that \nis in part the language itself and is in part the intentional structure of why you’re \nspeaking, and what your purposes are when speaking. This intentional structure \nwas a generalization of task structure. These structural aspects are then moderated \nby a model of the attentional state. \nMARTIN FORD: Let’s fast forward and talk about today. What’s the biggest \ndifference that you’ve seen?\nBARBARA GROSZ: The biggest difference I see is going from speech systems that \nwere essentially deaf, to today’s systems that are incredibly good at processing \nspeech. In the early days we really could not get much out of speech, and it \nproved very hard to get the right kinds of parses and meaning back then. We’ve \nalso come a long way forward with how incredibly well today’s technology can \nprocess individual utterances or sentences, which you can see in modern search \nengines and machine translation systems.\nIf you consider any of the systems that purport to carry on dialogues, however, the \nbottom line is they essentially don’t work. They seem to do well if the dialogue \nsystem constrains the person to following a script, but people aren’t very good \nat following a script. There are claims that these systems can carry on a dialogue \nwith a person, but in truth, they really can’t. For instance, the Barbie doll that \nsupposedly can converse with a child is script-based and gets in trouble if the child \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 516
  },
  {
    "chunk_full": "BARBARA J. GROSZ\n337\nresponds in a way the designers didn’t anticipate. I’ve argued that the mistakes it \nmakes actually raise some serious ethical challenges. \nSimilar examples arise with all the phone personal assistant systems. For example, if \nyou ask where the nearest emergency room is, you’ll get an answer of the nearest \nhospital to wherever you are when you ask, but if you ask where you can go to get \na sprained ankle treated, the system is likely to just take you to a web page that \ntells you how to treat a sprained ankle. That’s not a problem for a sprained ankle, \nbut if you’re asking about a heart attack because you think someone’s had one, it \ncould actually lead to death. People would assume a system that can answer one of \nthose questions you can answer the other. \nA related problem arises with dialogue systems based on learning from data. Last \nsummer (2017), I was given the Association for Computational Linguistics Lifetime \nAchievement Award and almost all the people listening to my talk at the conference \nwork on deep learning based natural-language systems. I told them, “if you want to \nbuild a dialogue system, you have to recognize that Twitter is not a real dialogue.” \nTo build a dialogue system that can handle dialogues of the sort people actually \nengage in, you need to have real data of real people having real dialogues, and that’s \nmuch harder to get than Twitter data.\nMARTIN FORD: When you talk about going off script, it seems to me that this is \nthe blurry line between pure language processing and real intelligence. The ability \nto go off script and deal with unpredictable situations is what true intelligence is \nall about; it’s the difference between an automaton or robot and a person.\nBARBARA GROSZ: You’re exactly right, and that’s exactly the problem. If you think \nabout having a lot of data, that, with deep learning, enables you to, say, go from a \nsentence in one language to the same sentence in another language; or to go from a \nsentence with a question in it to an answer to that question; or from one sentence to \na possible following sentence, there’s no real understanding of what those sentences \nactually mean, so there’s no way to work off script with them. \nThis problem links back to a philosophical idea that was elaborated in the 1960s by \nPaul Grice, J. L. Austin, and John Searle that language is action. For example, if \nI say to the computer, “The printer is broken,” then what I don’t want is for it to \nsay back to me, “Thanks, fact recorded.” What I actually want is for the system to \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 517
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n338\ndo something that will get the printer fixed. For that to occur, the system needs \nto understand why I said something. \nCurrent deep-learning based natural-language systems perform poorly on these \nkinds of sentences in general. The reasons are really deeply rooted. What we’re \nseeing here, is that these systems are really good at statistical learning, pattern \nrecognition and large-scale data analysis, but they don’t go below the surface. They \ncan’t reason about the purposes behind what someone says. Put another way, they \nignore the intentional structure component of dialogue. Deep-learning based systems \nmore generally lack other hallmarks of intelligence: they cannot do counterfactual \nreasoning or common-sense reasoning. \nYou need all these capabilities to participate in a dialogue, unless you tightly \nconstrain what a person says and does; but that makes it very hard for people to \nactually do what they want to do!\nMARTIN FORD: What would you point to as being state-of-the-art right now? I was \npretty astonished when I saw IBM Watson win at Jeopardy! I thought that was really \nremarkable. Was that as much of a breakthrough as it seemed to be, or would you \npoint to something else as really being on the leading edge?\nBARBARA GROSZ: I was impressed by Apple’s Siri and by IBM’s Watson; they \nwere phenomenal achievements of engineering. I think that what is available today \nwith natural language and speech systems is terrific. It’s changing the way that we \ninteract with computer systems, and it’s enabling us to get a lot done. But these \nsystems are nowhere near the human capacity for language, and you see that when \nyou try to engage in a dialogue with them. \nWhen Siri came out it in 2011, it took me about three questions to break the \nsystem. Where Watson makes mistakes is most interesting in that it shows us where \nit is not processing language like people do.\nSo yes, on the one hand, I think the progress in natural language and speech systems is \nphenomenal. We are far beyond what we could do in the ‘70s, partly because computers \nare way more powerful, and partly because there’s a lot more data out there. I’m \nthrilled that AI is actually out in the world making a difference because I didn’t think \nthat it would happen in my lifetime—because it seemed the problems were so hard.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 518
  },
  {
    "chunk_full": "BARBARA J. GROSZ\n339\nMARTIN FORD: Really, you didn’t think it would happen in your lifetime?\nBARBARA GROSZ: Back in the 1970s? No, I didn’t.\nMARTIN FORD: I was certainly very taken aback by Watson and especially \nby the fact that it could handle, for example, puns, jokes, and very complex \npresentations of language.\nBARBARA GROSZ: But just going back to “The Wizard of Oz” analogy, you look \nbehind what’s actually in those systems, and you realize they all have limitations. \nWe’re at a moment where it’s really important to understand what these systems \nare good at and where they fail. \nThis is why I think it’s very important for the field, and frankly for the world, to \nunderstand that we could make a lot more progress on AI systems that would be \ngood for people in the world if we didn’t aim to replace people, or build generalized \nartificial intelligence—but if we instead focus our understanding on what all these \ngreat capabilities are both good and not good for, and how to complement people \nwith these systems, and these systems with the people.\nMARTIN FORD: Let’s focus on this idea of going off script and being able to really \nhave a conversation. That relates directly to the Turing test, and I know you’ve done \nsome additional work in that area. What do you think Turing’s intentions were in \ncoming up with that test? Is it a good test of machine intelligence?\nBARBARA GROSZ: I remind people that Turing proposed his test in 1950, a time \nwhere people had new computing machines that they thought were amazing. Now \nof course, those systems could do nothing compared to what a smartphone can do \ntoday, but at the time many people wondered if these machines could think like a \nhuman thinks. Remember, Turing used “intelligence” and “thinking” similarly—he wasn’t \ntalking about intelligence like say, Nobel prize-winning science type of intelligence.\nTuring was posing a very interesting philosophical question, and he made some \nconjectures about whether or not machines could exhibit a certain kind of behavior. \nThe 1950s was also at a time where psychology was rooted in behaviorism, and \nso his test is not only an operational test but also a test where there would be no \nlooking below the surface. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 519
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n340\nThe Turing test is not a good test of intelligence. Frankly, I would probably fail \nthe Turing test because I’m not very good at social banter. It’s also not a good \nguide for what the field should aim to do. Turing was an amazingly smart person, \nbut I’ve conjectured, somewhat seriously, that if he were alive today—and if he \nknew what we now know about how learning works, how the brain and language \nwork, and how people develop intelligence and thinking, then he would have \nproposed a different test. \nMARTIN FORD: I know that you’ve proposed some enhancements or even a \nreplacement for the Turing test.\nBARBARA GROSZ: Who knows what Turing would have proposed, but I have \nmade a proposal that, given that we know that the development of human \nintelligence depends on social interaction, and that language capacity depends on \nsocial interaction, and that human activity in many setting is collaborative—then I \nrecommend that we aim to build a system that is a good team partner, and works \nso well with us that we don’t recognize that it isn’t human. I mean, it’s not that \nwe’re fooled into the idea that a laptop, robot, or phone is a human being, but \nthat you don’t keep wondering “Why did it do that?” when it makes a mistake \nthat no human would. \nI think that this is a better goal for the field, in part because it has several advantages \nover the Turing test. One advantage is that you can meet it incrementally—so if \nyou pick a small enough arena in which to build a system, you can build a system \nthat’s intelligent in that arena, and it works well on that kind of task. We could \nfind systems out there now that we would say are intelligent in that way—and of \ncourse children, as they develop, are intelligent in different limited ways, and then \nthey get more and different kinds of smart in more varied kinds of ways. \nWith the Turing test, a system either succeeds or it fails, and there’s no guide for \nhow to incrementally improve its reasoning. For science to develop, you need to be \nable to make steps along the way. The test I proposed also recognizes that for the \nforeseeable future people and computer systems will have complementary abilities, \nand it builds on that insight rather than ignoring it. \nI first proposed this test in a talk in Edinburgh on the occasion of the 100th anniversary \nof Turing’s birth. I said given all the progress in computing and psychology, “We should \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 520
  },
  {
    "chunk_full": "BARBARA J. GROSZ\n341\nthink of new tests.” I asked the attendees at that talk for their ideas, and in subsequent \ntalks. To date, the main response has been that this test is a good one. \nMARTIN FORD: I’ve always thought that once we really have machine intelligence, \nwe’ll just kind of know it when we see it. It’ll just be somehow obvious, and maybe \nthere’s not a really explicit test that you can define. I’m not sure there’s a single test \nfor human intelligence. I mean, how do you know another human being is intelligent?\nBARBARA GROSZ: That’s a really good observation. If you think about what I said \nwhen I gave this example of “where’s the nearest emergency room and where can \nI go to get a heart attack treated?”, no human being you would consider intelligent \nwould be able to answer one of those questions and not the other one. \nThere’s a possibility that the person you asked might not be able to answer \neither question, say if you plonked them in some foreign city; but if they could \nanswer one question, they could answer the other question. The point is, if you \nhave a machine that answers both questions, then that seems intelligent to you. \nIf you have a machine that answers only one and not the other question, then \nit doesn’t seem so intelligent.\nWhat you just said actually fits with the test that I proposed. If the AI system is \ngoing along and acting, as it were, as intelligently as you would expect another \nhuman to act, then you’d think it is intelligent. What happens right now with many \nAI systems, is that people think the AI system is smart and then it does something \nthat takes them aback, and then they think it’s completely stupid. At that point, the \nhuman wants to know why the AI system worked that way or didn’t work the way \nthey expected, and by the end they no longer think it’s so smart.\nBy the way, the test that I proposed is not time-limited; in fact, it is actually \nsupposed to be extended in time. Turing’s test was also not supposed to have a \ntime limit, but that characteristic has been frequently forgotten, in particular in \nvarious recent AI competitions.\nMARTIN FORD: That seems silly. People aren’t intelligent for only half an hour. It \nhas to be for an indefinite time period to demonstrate true intelligence. I think \nthere’s something called the Loebner Prize where Turing tests are run under \ncertain limited conditions each year.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 521
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n342\nBARBARA GROSZ: Right, and it proves what you say. It also makes clear what we \nlearned very early on in the natural-language processing arena, which is that if you \nhave only a fixed task with a fixed set of issues (and in this case, a fixed amount \nof time), then cheap hacks will always win over real intelligent processing, because \nyou’ll just design your AI system to the test!\nMARTIN FORD: The other area that you have worked in is multi-agent systems, \nwhich sounds pretty esoteric. Could you talk a little about that and explain \nwhat that means?\nBARBARA GROSZ: When Candy Sidner and I were developing the intentional \nmodel of discourse that I mentioned earlier, we first tried to build on the work \nof colleagues who were using AI models of planning developed for individual \nrobots to formalize work in philosophy on speech act theory. When we \ntried to use those techniques in the context of dialogue, we found that they \nwere inadequate. This discovery led us to the realization that teamwork or \ncollaborative activity, or working together, cannot be characterized as simply \nthe sum of individual plans. \nAfter all, it’s not as if you have a plan to do a certain set of actions and I have a \nplan to do a certain set of actions, and they just happen to fit together. At the time, \nbecause AI planning researchers often used examples involving building stacks of \ntoy blocks, I used the particular example of one child having a stack of blue blocks \nand another child having a stack of red blocks, and they build a tower that has both \nred and blue blocks. But it’s not that the child with the blue blocks has a plan with \nthose blocks in spaces that just happen to match where the plan of the child with \nred blocks has empty spaces. \nSidner and I realized, at this point, that we had to come up with a new way \nof thinking about—and representing in a computer system—plans of multiple \nparticipants, whether people or computer agents or both. So that’s how I got into \nmulti-agent systems research. \nThe goal of work in this field is to think about computer agents being situated \namong other agents. In the 1980s, work in this area mostly concerned situations \nwith multiple computer agents, either multiple robots or multiple software agents, \nand asked questions about competition and coordination. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 522
  },
  {
    "chunk_full": "BARBARA J. GROSZ\n343\nMARTIN FORD: Just to clarify: when you talk about a computer agent, what you \nmean is a program, a process that goes and performs some action or retrieves some \ninformation or does something. \nBARBARA GROSZ: That’s right. In general, a computer agent is a system able \nto act autonomously. Originally, most computer agents were robots, but for \nseveral decades AI research has involved software agents as well. Today there \nare computer agents that search and ones that compete in auctions, among many \nother tasks. So, an agent doesn’t have to be a robot that’s actually out there \nphysically in the world. \nFor instance, Jeff Rosenheim had some really interesting work in the early years \nof multi-systems agents research, which considered situations like having a bunch \nof delivery robots, and they need to get things all over the city, and maybe if they \nexchanged packages they could do it more efficiently. He considered questions like \nwhether they would tell the truth or lie about the tasks they actually had to do, \nbecause if an agent lied, it might come out ahead. \nThis whole area of multi-agent systems now addresses a wide range of situations \nand problems. Some work focuses on strategic reasoning; other on teamwork. And, \nI’m thrilled to say, more recently, much of it is now really looking at how computer \nagents can work with people, rather than just with other computer agents.\nMARTIN FORD: Did this multi-agent work lead directly to your work in \ncomputational collaboration?\nBARBARA GROSZ: Yes, one of the results of my work in multiple-agent systems \nwas to develop the first computational model of collaboration. \nWe asked, what does it mean to collaborate? People take an overall task and divide \nit up, delegating tasks to different people and leaving to them figuring out the \ndetails. We make commitments to one another to do subtasks, and we (mostly) \ndon’t wander off and forget what we committed to doing. \nIn business, a common message is that one person doesn’t try to do everything, \nbut delegates tasks to other people depending on their expertise. This is the \nsame in more informal collaborations.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 523
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n344\nI developed a model of collaboration that made these intuitions formal, in work \nwith Sarit Kraus, and then generated many new research questions including how \nyou decide who’s capable of doing what, what happens if something goes wrong, \nand what’s your obligation to the team. So, you don’t just disappear or say, “Oh, I \nfailed, Sorry. Hope you guys can do the task without me.” \nIn 2011-2012 I had a year’s sabbatical in California and I decided that I wanted to see \nif this work on collaboration could make a difference in the world. So, pretty much \nsince then, I have been working in the healthcare arena developing new methods for \nhealthcare coordination, working with Stanford pediatrician Lee Sanders. The particular \nmedical setting is children who have complex medical conditions and see 12 or 15 \ndoctors. In this context, we’re asking: how can we provide systems that help those \ndoctors share information and more successfully coordinate what they’re doing. \nMARTIN FORD: Would you say that health care is one the most promising areas for \nresearch for AI? It certainly seems like the part of the economy that most needs \nto be transformed and made more productive. I’d say we’d be much better off as a \nsociety if we could give transforming medicine a higher priority than having robots \nthat flip hamburgers and produce cheaper fast food.\nBARBARA GROSZ: Right, and healthcare is an area, along with education, where \nit’s absolutely crucial that we focus on building systems that complement people, \nrather than systems that replace people.\nMARTIN FORD: Let’s talk about the future of artificial intelligence. What do you \nthink about all of the focus right now on deep learning? I feel a normal person \nreads the press and could come away with the impression that AI and deep learning \nare synonymous. What would you point to, speaking of AI generally, as the things \nthat are absolutely on the forefront? \nBARBARA GROSZ: Deep learning is not deep in any philosophical sense. The name \ncomes from there being many layers to the neural network. It isn’t that deep learning \nis more intelligent in the sense of being a deeper “thinker” than other kinds of AI \nsystems or learning. It functions well because it mathematically has more flexibility. \nDeep learning is tremendously good for certain tasks, essentially ones that fit its \nend-to-end processing: a signal comes in and you get an answer out; but it is also \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 524
  },
  {
    "chunk_full": "BARBARA J. GROSZ\n345\nlimited by the data it gets. We see this limitation in systems that can recognize white \nmales much better than other kinds of people because there are more white males \nin the training data. We see it also in machine translation that works very well for \nliteral language, where it’s had a lot of examples, but not for the kind of language \nyou see in novels or anything that’s literary or alliterative. \nMARTIN FORD: Do you think there will be a backlash against all the hype \nsurrounding deep learning when its limitations are more widely recognized?\nBARBARA GROSZ: I have survived numerous AI Winters in the past and I’ve come \naway from them feeling both fearful and hopeful. I’m fearful that people, once they \nsee the limitations of deep learning will say, “Oh, it doesn’t really work.” But I’m \nhopeful that, because deep learning is so powerful for so many things, and in so \nmany areas, that there won’t be an AI Winter around deep learning. \nI do think, however, that to avoid an AI Winter for deep learning, people in the field \nneed to put deep learning in its correct place, and be clear about its limitations. \nI said at one point that “AI systems are best if they’re designed with people in \nmind.” Ece Kamar has noted that the data from which these deep learning systems \nlearn, comes from people. Deep learning systems are trained by people. And these \ndeep learning systems do better if there are people in the loop correcting them \nwhen they’re getting something wrong. On the one hand, deep learning is very \npowerful, and it’s enabled the development of a lot of fantastic things. But deep \nlearning is not the answer to every AI question. It has, for instance, so far shown \nno usefulness for common sense reasoning!\nMARTIN FORD: I think people are working on, for example, figuring out how to \nbuild a system so it can learn from a lot less data. Right now, systems do depend \non enormous datasets in order to get them to work at all. \nBARBARA GROSZ: Right, but notice the issue is not just how much data they need, \nbut the diversity of the data. \nI’ve been thinking about this recently; simply put, why does it matter? If I or you \nwere building a system to work in New York City or San Francisco, that would \nbe one thing. But these systems are being used by people around the world from \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 525
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n346\ndifferent cultures, with different languages, and with different societal norms. \nYour data has to sample all of that space. And we don’t have equal amounts of \ndata for different groups. If we go to less data, we have to say something like \n(and I’m being a bit facetious here), “This is a system that works really well for \nwhite men, upper income.”\nMARTIN FORD: But is that just because the example you’re using is facial recognition \nand they’re feeding in photographs of white people mostly? If they expanded and \nhad data from a more diverse population, then that would be fixed, right?\nBARBARA GROSZ: Right, but that’s just the easiest example I can give you. Let’s \ntake healthcare. Until only a few years ago, medical research was done only on \nmales, and I’m not talking only about human males, I’m even talking about only \nmale mice in basic biomedical research. Why? Because the females had hormones! If \nyou’re developing a new medicine, a related problem arises with young people versus \nold people as older people don’t need the same dosages as young people. If most of \nyour studies are on younger people, you again have a problem of biased data. The \nface data is an easy example, but the problem of data bias permeates everything.\nMARTIN FORD: Of course, that’s not a problem that’s exclusive to AI; humans are \nsubject to the same issues when confronted with flawed data. It’s a bias in the data \nthat results from past decisions that people doing research made. \nBARBARA GROSZ: Right, but now look what’s going on in some areas of \nmedicine. The computer system can, “read all the papers” (more than a person \ncould) and do certain kinds of information retrieval from them and extract \nresults, and then do statistical analyses. But if most of the papers are on scientific \nwork that was done only on male mice, or only on male humans, then the \nconclusions the system is coming to are limited. \nWe’re also seeing this problem in the legal realm, with policing and fairness. So, \nas we build these systems, we have to think, “OK. What about how my data can \nbe used?” Medicine is a place where I think it’s really dangerous to not be careful \nabout the limitations of the data that you’re using.\nMARTIN FORD: I want to talk about the path to AGI. I know you feel very strongly \nabout building machines that work with people, but I can tell you from having \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 526
  },
  {
    "chunk_full": "BARBARA J. GROSZ\n347\ndone these interviews that a lot of your colleagues are very interested in building \nmachines that are going to be independent, alien intelligences. \nBARBARA GROSZ: They read too much science fiction! \nMARTIN FORD: But just in terms of the technical path to true intelligence, I guess \nthe first question is if you think that AGI is achievable? Maybe you think it can’t \nbe done at all. What are the technical hurdles ahead?\nBARBARA GROSZ: The first thing I want to tell you is that in the late 1970s, as \nI was finishing my dissertation, I had this conversation with another student who \nsaid, “Good thing we don’t care about making a lot of money, because AI will \nnever amount to anything.” I reflect on that prediction often, and I know I have \nno crystal ball about the future. \nI don’t think AGI is the right direction to go. I think the focus on AGI is actually \nethically dangerous because it raises all sorts of issues of people not having jobs, \nand robots run amok. Those are fine issues to think about, but they are very far in \nthe future. They’re a distraction. The real point is we have any number of ethical \nissues right now, with the AI systems we have now, and I think it’s unfortunate to \ndistract attention from those because of scary futuristic scenarios. \nIs AGI a worthwhile direction to go or not? You know, people have been wondering \nsince at least The Golem of Prague, and Frankenstein, for many hundreds of years, if \nhumanity could create something that is as smart as a human. I mean, you can’t stop \npeople from fantasizing and wondering, and I am not going to try, but I don’t think that \nthinking about AGI is the best use of the resources we have, including our intelligence. \nMARTIN FORD: What are the actual hurdles to AGI?\nBARBARA GROSZ: I mentioned one hurdle, which is getting the wide range of data \nthat would be needed and getting that data ethically because you’re essentially being \nBig Brother and watching a lot of behavior and from that, taking a lot of data from \na lot of people. I think that may be one of the biggest issues and biggest hurdles.\nThe second hurdle is that every AI system that exists today is an AI system with \nspecialized abilities. Robots that can clean your house or systems that can answer \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 527
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n348\nquestions about travel, or restaurants. To go from that kind of individualized \nintelligence to general intelligence that flexibly moves from one domain to another \ndomain, and takes analogs from one domain to another, and can think not just about \nthe present but also the future, those are really hard questions. \nMARTIN FORD: One major concern is that AI is going to unleash a big economic \ndisruption and that there might be a significant impact on jobs. That doesn’t require \nAGI, just narrow AI systems that do specialized things well enough to displace \nworkers or deskill jobs. Where do you fall on the spectrum of concern about the \npotential economic impact? How worried should we be?\nBARBARA GROSZ: So yes, I am concerned, but I’m concerned in a somewhat \ndifferent way from how many other people are concerned. The first thing I want \nto say is that it’s not just an AI problem, but a wider technology problem. It’s a \nproblem where those of us who are technologists of various sorts are partially \nresponsible, but the business world carries a lot of responsibility as well. \nHere’s an example. You used to call in to get customer service when something \nwasn’t working, and you got to talk to a human being. Not all of those human \ncustomer service agents were good, but the ones who were good understood your \nproblem and got you an answer. \nOf course, human beings are expensive, so now they’ve been replaced in many \ncustomer service settings by computer systems. At one stage, companies got rid \nof more intelligent people and hired the cheaper people who could only follow a \nscript, and that wasn’t so good. But now, who needs a person who can only follow \na script when you have a system? This approach makes for bad jobs, and it makes \nfor bad customer service interactions. \nWhen you think about AI and the increasingly intelligent systems, there are going \nto be more and more opportunities where you can think, “OK, we can replace the \npeople.” But it’s problematic to do that if the system isn’t fully capable of doing \nthe task it’s been assigned. It’s also why I’m on the soapbox about building systems \nthat complement people.\nMARTIN FORD: I’ve written quite a lot about this, and I guess the point I would \nmake is that this is very much at the intersection of technology and capitalism.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 528
  },
  {
    "chunk_full": "BARBARA J. GROSZ\n349\nBARBARA GROSZ: Exactly!\nMARTIN FORD: There is an inherent drive within capitalism to make more \nmoney by cutting costs and historically that has been a positive thing. My view \nis that we need to adapt capitalism so that it can continue to thrive, even if \nwe are at an inflection point, where capital will really start to displace labor \nto an unprecedented extent.\nBARBARA GROSZ: I’m with you entirely on that. I spoke about this recently at \nthe American Academy of Arts and Sciences, and for me there are two key points.\nMy first point was that it’s not a question of just what systems we can build but \nwhat systems we should build. As technologists, we have a choice about that, even \nin a capitalist system that will buy anything that saves money. \nMy second point was that we need to integrate ethics into the teaching of computer \nscience, so students learn to think about this dimension of systems along with \nefficiency and elegance of code.\nTo the corporate and marketing people at this meeting, I gave the example of \nVolvo, who made a competitive advantage out of building cars that were safe. We \nneed it to be a competitive advantage for companies to make systems that work \nwell with people. But to do that is going to require engineers who don’t just think \nabout replacing people, but who work with social scientists and ethicists to figure \nout, “OK. I can put this kind of capability in, but what does it mean if I do that? \nHow does it fit with people?”\nWe need to support building the kind of systems we should build, not just the \nsystems that in the short-term look like they’ll sell and save money. \nMARTIN FORD: What about AI risks beyond the economic impact? What do you \nthink we should be genuinely concerned about in terms of artificial intelligence, \nboth in the near term and further out? \nBARBARA GROSZ: From my perspective, there is a set of questions around the \ncapabilities AI provides, the methods it has and what they can be used for, and the \ndesign of AI systems that go out in the world. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 529
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n350\nAnd there’s a choice. Even with weapons, there’s a choice. Are they fully \nautonomous? Where are the people in the loop? Even with cars, Elon Musk had \na choice. He could have said that what Tesla cars had was driver-assist instead of \nsaying he had a car with autopilot, because of course he doesn’t have a car with \nautopilot. People get in trouble because they buy into the autopilot idea, trust it \nwill work, and then have accidents. \nSo, we have a choice in what we put in the systems, what claims we make about the \nsystems, and how we test, verify and set up the systems. Will there be a disaster? \nThat depends on what choices we make. \nNow is an absolutely crucial time for everyone involved in building systems \nthat incorporate AI in some way—because those are not just AI systems: they’re \ncomputer systems that have some AI involved. Everyone needs to sit down and \nhave, as part of their design teams, people who are going to help them think more \nbroadly about the unintended consequences of the systems they’re building. \nI mean, the law talks about unintended consequences, and computer scientists talk \nabout side effects. It’s time to stop, across technology development, as far as I’m \nconcerned, saying, “Oh, I wonder if I can build a thing that does thus and such,” \nand then build it and foist it on the world. We have to think about the long-range \nimplications of the systems we’re building. That’s a societal problem. \nI have gone from teaching a course on Intelligent Systems: Design and Ethical Challenges \nto now mounting an effort with colleagues at Harvard, which we call Embedded \nEthiCS, to integrate the teaching of ethics into every computer science course. I \nthink that people who are designing systems, should not only be thinking about \nefficient algorithms and efficient code, but they should also be thinking about the \nethical implications of the system.\nMARTIN FORD: Do you think there’s too much focus on existential threats? Elon \nMusk has set up OpenAI, which I think is an organization focused on working on \nthis problem. Is that a good thing? Are these concerns something that we should \ntake seriously, even though they may only be realized far in the future?\nBARBARA GROSZ: Somebody could very easily put something very bad on a \ndrone, and it could be very damaging. So yes, I’m in favor of people who are \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 530
  },
  {
    "chunk_full": "BARBARA J. GROSZ\n351\nthinking about how they can design safe systems and what systems to build as \nwell as how they can teach students to design programs that are more ethical. I \nwould never say not to do that.\nI do think that it’s too extreme, however, as some people are saying, that we \nshouldn’t be doing any more AI research or development until we have figured out \nhow to avoid all such threats. It would be harmful to stop all of the wonderful ways \nin which AI can make the world a better place, because of perceived existential \nthreats in the longer term. \nI think we can continue to develop AI systems, but we have to be mindful of the \nethical issues and to be honest about the capabilities and limitations of AI systems\nMARTIN FORD: One phrase that you’ve used a lot is “we have a choice.” Given \nyour strong feeling that we should build systems that work with people, are you \nsuggesting that these choices should be made primarily by computer scientists and \nengineers, or by entrepreneurs? Decisions like that are pretty heavily driven by the \nincentives in the market. Should these choices be made by society as a whole? Is \nthere a place for regulation or government oversight?\nBARBARA GROSZ: One thing I want to say is that even if you don’t design the \nsystem to work with people, it’s got to eventually work with people, so you’d \nbetter think about people. I mean, the Microsoft Tay bot and Facebook fake \nnews disasters are examples of designers and systems where people didn’t think \nenough about how they were releasing systems into the “wild,” into a world \nthat is full of people, not all of whom are trying to be helpful and agreeable. \nYou can’t ignore people!\nSo, I absolutely think there’s room for legislation, there’s room for policy, and \nthere’s room for regulation. One of the reasons I have this hobbyhorse about \ndesigning systems to work well with people is that I think if you get social \nscientists and ethicists in the room when you’re thinking about your design, \nthen you design better. As a result, the policies and the regulations will be \nneeded only to do what you couldn’t do by design as opposed to over-reacting \nor retrofitting badly designed systems. I think we’ll always wind up with better \nsystems if we design them to be the best systems they can be, and then the \npolicy is on top of that. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 531
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n352\nMARTIN FORD: One concern that would be raised about regulation, within a \ncountry, or even in the West, is that there is an emerging competitive race with \nChina. Is that something we should worry about, that the Chinese are going \nto leap ahead of us and set the pace, and that too much regulation might leave \nus at a disadvantage?\nBARBARA GROSZ: There are two separate answers here right now. I know I sound \nlike a broken record, but if we stop all AI research and development or severely \nrestrict it, then the answer is yes. \nIf, however, we develop AI in a context which takes ethical reasoning and thinking into \naccount as well as the efficiency of code then no, because we’ll keep developing AI. \nThe one place where there’s extraordinary danger is with weapons systems. A key \nissue is what would happen if we didn’t build AI-driven weapons and an enemy did; \nbut that topic is so large that it would take another hour conversation.\nMARTIN FORD: To wind up, I wanted to ask you about women in the field. Is there \nany advice you would offer to women, or men, or to students just getting started? \nWhat would you want to say about the role of women in the field of AI and how \nthings have evolved over the course of your career?\nBARBARA GROSZ: The first thing I would say to everybody is that this field \nhas some of the most interesting questions of any field in the world. The set of \nquestions that AI raises has always required a combination of thinking analytically, \nthinking mathematically, thinking about people and behavior, and thinking about \nengineering. You get to explore all sorts of ways of thinking and all sorts of design. \nI’m sure other people think their fields are the most exciting, but I think it’s even \nmore exciting now for us in AI because we have much stronger tools: just look at \nour computing power. When I started in the field I had a colleague who’d knit a \nsweater waiting for a carriage return to echo!\nLike all of computer science and all of technology, I think it’s essential that we \nhave the broadest spectrum of people involved in designing our AI systems. I mean \nnot just women as well as men, I mean people from different cultures, people \nof different races, because that’s who’s going to use the systems. If you don’t, \nyou have two big dangers. One is the systems you design are only appropriate \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 532
  },
  {
    "chunk_full": "BARBARA J. GROSZ\n353\nfor certain populations, and the second is that you have work climates that aren’t \nwelcoming to the broadest spectrum of people and therefore benefit from only \ncertain subpopulations. We’ve got to all work together. \nAs for my experience, there were almost no women involved in AI at the beginning, \nand my experience depended entirely on what the men with whom I worked \nwere like. Some of my experiences were fantastic, and some were horrible. Every \nuniversity, every company that has a group doing technology, should take on the \nresponsibility of making sure the environments encourage women as well as men, \nand people from under-represented minorities because, in the end, we know that \nthe more diverse the design team, the better the design. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 533
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n354\nBARBARA GROSZ is Higgins Professor of Natural Sciences in the School of Engineering \nand Applied Sciences at Harvard University and a member of the External Faculty of \nSanta Fe Institute. She has made groundbreaking contributions to the field of artificial \nintelligence through pioneering research in natural language processing and in theories \nof multi-agent collaboration and their application to human-computer interaction. Her \ncurrent research explores ways to use models developed in this research to improve health \ncare coordination and science education. \nBarbara received an AB in mathematics from Cornell University, and a master’s and PhD in \ncomputer science from the University of California, Berkeley. Her many awards and distinctions \ninclude election to the National Academy of Engineering, the American Philosophical Society, \nand the American Academy of Arts and Sciences, and as a fellow of the Association for the \nAdvancement of Artificial Intelligence and the Association for Computing Machinery. She \nreceived the 2009 ACM/AAAI Allen Newell Award, the 2015 IJCAI Award for Research \nExcellence, and the 2017 Association for Computational Linguistics Lifetime Achievement \nAward. She is also known for her leadership of interdisciplinary institutions and contributions \nto the advancement of women in science.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 534
  },
  {
    "chunk_full": "BARBARA J. GROSZ\n355\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 535
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n356\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 536
  },
  {
    "chunk_full": "JUDEA PEARL\n357\nJUDEA PEARL\nPROFESSOR OF COMPUTER SCIENCE AND STATISTICS,  \nUNIVERSITY OF CALIFORNIA, LOS ANGELES  \nDIRECTOR OF THE COGNITIVE SYSTEMS LABORATORY \nJudea Pearl is known internationally for his contributions to artificial intelligence, \nhuman reasoning, and philosophy of science. He is particularly well known in the \nAI field for his work on probabilistic (or Bayesian) techniques and causality. He is \nthe author of more than 450 scientific papers and three landmark books: Heuristics \n(1984), Probabilistic Reasoning (1988), and Causality (2000; 2009). His 2018 \nbook, The Book of Why, makes his work on causation accessible to a general \naudience. In 2011, Judea received the Turing Award, which is the highest honor \nin the field of computer science and is often compared to the Nobel Prize. \nThe current machine learning concentration on  \ndeep learning and its non-transparent structures  \nis a hang-up. They need to liberate themselves from \nthis data-centric philosophy.\n“ \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 537
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n358\nMARTIN FORD: You’ve had a long and decorated career. What path led you to get \nstarted in computer science and artificial intelligence?\nJUDEA PEARL: I was born in Israel in 1936, in a town named Bnei Brak. I \nattribute a lot of my curiosity to my childhood and to my upbringing, both as \npart of Israeli society and as a lucky member of a generation that received a \nunique and inspiring education. My high-school and college teachers were top-\nnotch scientists who had come from Germany in the 1930s, and they couldn’t \nfind a job in academia, so they taught in high schools. They knew they would \nnever get back to academia, and they saw in us the embodiment of their academic \nand scientific dreams. My generation were beneficiaries of this educational \nexperiment—growing up under the mentorship of great scientists who happened \nto be high-school teachers. I never excelled in school, I was not the best, or \neven second best, I was always third or fourth, but I always got very involved in \neach area taught. And we were taught in a chronological way, focusing on the \ninventor or scientist behind the invention or theorem. Because of this, we got \nthe idea that science is not just a collection of facts, but a continuous human \nstruggle with the uncertainties of nature. This added to my curiosity.\nI didn’t commit myself to science until I was in the army. I was a member of a \nKibbutz and was about to spend my life there, but smart people told me that I \nwould be happier if I utilized my mathematical skills. As such, they advised me to \ngo and study electronics in Technion, the Israel Institute of Technology, which I did \nin 1956. I did not favor any particular specialization in college; but I enjoyed circuit \nsynthesis and electromagnetic theory. I finished my undergraduate degree and got \nmarried in 1960. I came to the US with the idea of doing graduate work, getting \nmy PhD, and going back.\nMARTIN FORD: You mean you planned to go back to Israel? \nJUDEA PEARL: Yes, my plan was to get a degree and come back to Israel. I first \nregistered at the Brooklyn Polytechnic Institute (now part of NYU), which was one \nof the top schools in microwave communication at the time. However, I couldn’t \nafford the tuition, I ended up employed at the David Sarnoff Research Center at the \nRCA laboratory in Princeton, New Jersey. There, I was a member of the computer \nmemory group under Dr. Jan Rajchman, which was a hardware-oriented group. \nWe, as well as everybody else in the country, were looking for different physical \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 538
  },
  {
    "chunk_full": "JUDEA PEARL\n359\nmechanisms that could serve as computer memory. This was because magnetic core \nmemories became too slow, too bulky, and you had to string them manually.\nPeople understood that the days of core memory were numbered, and everybody—\nIBM, Bell Labs, and RCA Laboratories—was looking for various phenomena that \ncould serve as a mechanism to store digital information. Superconductivity was \nappealing at that time because of the speed and the ease of preparing the memory, \neven though it required cooling to liquid helium temperature. I was investigating \ncirculating currents in superconductors, again for use in memory, and I discovered \na few interesting phenomena there. There’s even a Pearl vortex named after me, \nwhich is a turbulent current that spins around in superconducting films, and gives \nrise to a very interesting phenomenon that defies Faraday’s law. It was an exciting \ntime, both on the technological side and on the inspirational, scientific side.\nEveryone was also inspired by the potential capabilities of computers in 1961 and \n1962. No one had any doubt that eventually, computers would emulate most human \nintellectual tasks. Everyone was looking for tricks to accomplish those tasks, even \nthe hardware people. We were constantly looking for ways of making associative \nmemories, dealing with perception, object recognition, the encoding of visual scenes; \nall the tasks that we knew are important for general AI. The management at RCA \nalso encouraged us to come up with inventions. I remember our boss Dr. Rajchman \nvisiting us once a week and asking if we had any new patent disclosures. \nOf course, all work on superconductivity stopped with the advent of \nsemiconductors, which, at the time, we didn’t believe would take off. We \ndidn’t believe that miniaturization technology would succeed as it did. We also \ndidn’t believe they could overcome the vulnerability problem where the memory \nwould be wiped if the battery ran out. Obviously, they did, and semiconductor \ntechnology wiped out all its competitors. At that point, I was working for a \ncompany called Electronic Memories, and the rise of semiconductors left me \nwithout a job. That was how I came to academia, where I pursued my old dreams \nof doing pattern recognition and image encoding.\nMARTIN FORD: Did you go directly to UCLA from Electronic Memories? \nJUDEA PEARL: I tried to go to the University of Southern California, but they \nwouldn’t hire me because I was too sure of myself. I wanted to teach software, \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 539
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n360\neven though I’d never programmed before, and the Dean threw me out of his \noffice. I ended up at UCLA because they gave me a chance of doing the things \nthat I wanted to do, and I slowly migrated into AI from pattern recognition, image \nencoding, and decision theory. The early days of AI were dominated by chess and \nother game-playing programs, and that enticed me in the beginning, because I saw \nthere a metaphor for capturing human intuition. That was and remained my life \ndream, to capture human intuition on a machine. \nIn games, the intuition comes about in the way you evaluate the strength of a \nmove. There was a big gap between what machines can do and what experts can \ndo, and the challenge was to capture experts’ evaluation in the machine. I ended \nup doing some analytical work and came up with a nice explanation of what \nheuristics is all about, and an automatic way of discovering heuristics, it is still \nin use today. I believe I was the first to show that alpha-beta search is optimal, \nas well other mathematical results about what makes one heuristic better than \nanother. All of that work was compiled in my book, Heuristics, which came out \nin 1983. Then expert systems came to the scene, and people were excited about \ncapturing different kinds of heuristics—not the heuristic of a chess master, but \nthe intuition of highly-paid professionals, like a physician or a mineral explorer. \nThe idea was to emulate professional performance on a computer system, either \nto replace or to assist the professional. I looked at expert systems as another \nchallenge of capturing intuition.\nMARTIN FORD: Just to clarify, expert systems are mostly based on rules, correct? \nIf this is true, then do that, etc.\nJUDEA PEARL: Correct, it was based on rules, and the goal was to capture the \nmode of operation of an expert, what makes an expert decide one way or the other \nwhile engaging in professional work.\nWhat I did, was to replace it with a different paradigm. For example, instead of \nmodeling a physician—the expert—we modeled the disease. You don’t have to ask \nthe expert what they do. Instead, you ask, what kind of symptoms you expect to see \nif you have malaria or if you have the flu; and what do you know about the disease? \nOn the basis of this information, we built a diagnosis system that could examine a \ncollection of symptoms and come out with the suspected disease. It also works for \nmineral exploration, for troubleshooting, or for any other expertise.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 540
  },
  {
    "chunk_full": "JUDEA PEARL\n361\nMARTIN FORD: Was this based on your work on heuristics, or are you referring \nnow to Bayesian networks?\nJUDEA PEARL: No, I left heuristics the moment my book published in 1983, and I \nstarted working on Bayesian networks and uncertainty management. There were many \nproposals at the time for managing uncertainties, but they didn’t gel with the dictates \nof probability theory and decision theory, and I wanted to do it correctly and efficiently. \nMARTIN FORD: Could you talk about your work on Bayesian networks? I know \nthey are used in a lot of important applications today. \nJUDEA PEARL: First, we need to understand the environment at the time. There \nwas a tension between the scruffies and the neaties. The scruffies just wanted to \nbuild a system that works, not caring about guarantees or whether their methods \ncomply with any theory or not. The neaties wanted to understand why it worked \nand make sure that they have performance guarantees of some kind.\nMARTIN FORD: Just to clarify, these were nicknames for two groups of people \nwith different attitudes. \nJUDEA PEARL: Yes. We see the same tension today in the machine learning community, \nwhere some people like to get machines to do important jobs, regardless of whether \nthey’re doing it optimally or whether the system can explain itself, as long as the job \nis being done. The neaties would like to have explainability and transparency, systems \nthat can explain themselves and systems that have performance guarantees. \nWell, at that time, the scruffies were in command, and they still are today, because \nthey have a good conduit to funders and to industry. Industry, however, is short-\nsighted and requires short-term success, which creates an imbalance in research \nemphasis. It was the same in the Bayesian network days; the scruffies were in \ncommand. I was among the few loners who advocated doing things correctly by the \nrules of probability theory. The problem was that probability theory, if you adhere to \nit in the traditional way, would require exponential time and exponential memory, \nand we couldn’t afford these two resources. \nI was looking for a way of doing it efficiently, and I was inspired by the work of \nDavid Rumelhart, a cognitive psychologist who examined how children read text \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 541
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n362\nso quickly and reliably. His proposal was to have a multi-layered system going from \nthe pixel level to the semantic level, then the sentence level and the grammatical \nlevel, and they all shake hands and pass messages to each other. One level doesn’t \nknow what the other’s doing; it’s simply passing messages. Eventually, these messages \nconverge on the correct answer when you read a word like “the car” and distinguish \nit from “the cat,” depending on the context in the narrative. \nI tried to simulate his architecture in probability theory, and I couldn’t do it \nvery well until I discovered that if you have a tree as a structure connecting the \nmodules, then you do have this convergence property. You can propagate messages \nasynchronously, and eventually, the system relaxes to the correct answer. Then we \nwent to a polytree, which is a fancier version of a tree, and eventually, in 1995, \nI published a paper about general Bayesian networks. \nThis architecture really caught us by surprise because it was very easy to program. \nA programmer didn’t have to use a supervisor to oversee all the elements, all they \nhad to do was to program what one variable does when it wakes up and decides \nto update its information. That variable then sends messages to its neighbors. The \nneighbors send messages to their neighbors, and so on. The system eventually \nrelaxes to the correct answer. \nThe ease of programming was the feature that made Bayesian networks acceptable. It \nwas also made acceptable by the idea that you can program the disease and not the \nphysician—the domain, and not the professional that deals with the domain—that \nmade the system transparent. The users of the system understood why the system \nprovided one result or another, and they understood how to modify the system when \nthings changed in the environment. You had the advantage of modularity, which you \nget when you model the way things work in nature. \nIt’s something that we didn’t realize at the time, mainly because we didn’t \nrealize the importance of modularity. When we did, I realized that it is causality \nthat gives us this modularity, and when we lose causality, we lose modularity, \nand we enter into no-man’s land. That means that we lose transparency, we \nlose reconfigurability, and other nice features that we like. By the time that I \npublished my book on Bayesian networks in 1988, though, I already felt like an \napostate because I knew already that the next step would be to model causality, \nand my love was already on a different endeavor. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 542
  },
  {
    "chunk_full": "JUDEA PEARL\n363\nMARTIN FORD: We always hear people saying that “correlation is not causation,” \nand so you can never get causation from the data. Bayesian networks do not offer \na way to understand causation, right?\nJUDEA PEARL: No, Bayesian networks could work in either mode. It depends on \nwhat you think about when you construct it.\nMARTIN FORD: The Bayesian idea is that you update probabilities based on new \nevidence so that your estimate should get more accurate over time. That’s the basic \nconcept that you’ve built into these networks, and you figured out a very efficient \nway to do that for a large number of probabilities. It’s clear that this has become a \nreally important idea in computer science and AI because it’s used all over the place. \nJUDEA PEARL: Using Bayes’ rule is an old idea; doing it efficiently was the \nhard part. That’s one of the things that I thought was necessary for machine \nlearning. You can get evidence and use the Bayesian rule to update the system \nto improve its performance and improve the parameters. That’s all part of the \nBayesian scheme of updating knowledge using evidence, it is probabilistic, not \ncausal knowledge, so it has limitations.\nMARTIN FORD: But it’s used quite frequently, for example, in voice recognition \nsystems and all the devices that we’re familiar with. Google uses it extensively \nfor all kinds of things.\nJUDEA PEARL: People tell me that every cellphone has a Bayesian network doing \nerror correction to minimize transmission noise. Every cellphone has a Bayesian \nnetwork and belief propagation, that’s the name we gave to the message passing \nscheme. People also tell me that Siri has a Bayesian network in it, although Apple \nis too secretive about it, so I haven’t been able to verify it. \nAlthough Bayesian updating is one of the major components in machine learning \ntoday, there has been a shift from Bayesian networks to deep learning, which is less \ntransparent. You allow the system itself to adjust the parameters without knowing \nthe function that connects input and output. It’s less transparent than Bayesian \nnetworks, which had the feature of modularity, and which we didn’t realize was \nso important. When you model the disease, you actually model the cause and \neffect relationship of the disease, not the expert, and you get modularity. Once \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 543
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n364\nwe realize that, the question begs itself: What is this ingredient that you and I call \n“cause and effect relationships”? Where does it reside, and how do you handle it? \nThat was the next step for me.\nMARTIN FORD: Let’s talk about causation. You published a very famous book on \nBayesian networks, and it was really that paper that led to Bayesian techniques \nbecoming so popular in computer science. But before that book was even published, \nyou were already starting to think about moving on to focus on causation? \nJUDEA PEARL: Causation was part of the intuition that gave rise to Bayesian networks, \neven though the formal definition of Bayesian networks is purely probabilistic. You do \ndiagnostics, you make predictions, and you don’t deal with interventions. If you don’t \nneed interventions, you don’t need causality—theoretically. You can do everything \nthat a Bayesian network does with purely probabilistic terminology. However, in \npractice, people noticed that if you structure the network in the causal direction, \nthings are much easier. The question was why. \nNow we understand that we were craving for features of causality that we didn’t even \nknow come from causality. These were: modularity, reconfigurability, transferability, \nand more. By the time I looked into causality, I had realized that the mantra \n“correlation does not imply causation” is much more profound than we thought. \nYou need to have causal assumptions before you can get causal conclusions, which \nyou cannot get from data alone. Worse yet, even if you are willing to make causal \nassumptions, you cannot express them.\nThere was no language in science in which you can express a simple sentence like \n“mud does not cause rain,” or “the rooster does not cause the sun to rise.” You \ncouldn’t express it in mathematics, which means that even if you wanted to take it \nfor granted that the rooster does not cause the sun to rise, you couldn’t write it \ndown, you couldn’t combine it with data, and you couldn’t combine it with other \nsentences of this kind.\nIn short, even if you agree to enrich the data with causal assumptions, you couldn’t \nwrite down the assumptions. It required a whole new language. This realization \nwas really a shock and a challenge for me because I grew up on statistics, and I \nbelieved that scientific wisdom lies in statistics. Statistics allows you to do induction, \ndeduction, abduction, and model updating. And here I find the language of statistics \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 544
  },
  {
    "chunk_full": "JUDEA PEARL\n365\ncrippled in hopeless helplessness. As a computer scientist, I was not scared because \ncomputer scientists invent languages to fit their needs. But what is the language that \nshould be invented, and how do we marry this language with the language of data? \nStatistics speaks a different language—the language of averages, of hypothesis testing, \nsummarizing data and visualizing it from different perspectives. All of this is the \nlanguage of data, and here comes another language, the language of cause and effect. \nHow do we marry the two so that they can interact? How do we take assumptions \nabout cause and effect, combine them with the data that I have, and then get \nconclusions that tell me how nature works? That was my challenge as a computer \nscientist and as a part-time philosopher. This is essentially the role of a philosopher, \nto capture human intuition and formalize it in a way that it can be programmed on \na computer. Even though philosophers don’t think about the computer, if you look \nclosely at what they are doing, they are trying to formalize things as much as they \ncan with the language available to them. The goal is to make it more explicable and \nmore meaningful so that computer scientists can eventually program a machine to \nperform cognitive functions that puzzle philosophers.\nMARTIN FORD: Did you invent the technical language or the diagrams that are \nused for describing causation?\nJUDEA PEARL: No, I didn’t invent that. The basic idea was conceived in 1920 by a \ngeneticist named Sewall Wright, who was the first to write down a causal diagram \nwith arrows and nodes, like a one-way city map. He fought all his life to justify \nthe fact that you can get things out of this diagram that statisticians could not get \nfrom regression, association, or from correlation. His methods were primitive, but \nthey proved the point that he could get things that the statisticians could not get. \nWhat I did was to take Sewall Wright’s diagrams seriously and invested into \nthem all my computer science background, reformalized them, and exploited \nthem to their utmost. I came up with a causal diagram as a means of encoding \nscientific knowledge and as a means of guiding machines in the task of figuring \nout cause-effect relationships in various sciences, from medicine, to education, to \nclimate warming. These were all areas where scientists worry about what causes \nwhat, how nature transmits the information from cause to effect, what are the \nmechanisms involved, how do you control it, and how do you answer practical \nquestions which involve cause-effect relationships. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 545
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n366\nThis has been my life’s challenge for the past 30 years. I published a book on \nthat in 2000, with the second edition in 2009, called Causality. I co-authored \na gentler introduction in 2015. And this year, I co-authored The Book of Why, \nwhich is a general audience book explaining the challenge in down-to-earth \nterms, so that people can understand causality even without knowing equations. \nEquations of course help to condense things and to focus on things, but you \ndon’t have to be a rocket scientist to read The Book of Why. You just have to \nfollow the conceptual development of the basic ideas. In that book, I look at \nhistory from a causal lens perspective; I asked what conceptual breakthroughs \nmade a difference in the way we think, rather than what experiments discovered \none drug or another.\nMARTIN FORD: I’ve been reading The Book of Why and I’m enjoying it. I think one \nof the main outcomes of your work is that causal models are now very important \nin the social and natural sciences. In fact, I just saw an article the other day, written \nby a quantum physicist who used causal models to prove something in quantum \nmechanics. So clearly your work has had a big impact in those areas.\nJUDEA PEARL: I read that article. In fact, I put it on my next-to-read list because \nI couldn’t quite understand the phenomena that they were so excited about. \nMARTIN FORD: One of the main points I took away from The Book of Why is that, \nwhile natural and social scientists have really begun to use the tools of causation, \nyou feel that the field of AI is lagging behind. You think AI researchers will have to \nstart focusing on causation in order for the field to progress. \nJUDEA PEARL: Correct. Causal modeling is not at the forefront of the current \nwork in machine learning. Machine learning today is dominated by statisticians \nand the belief that you can learn everything from data. This data-centric \nphilosophy is limited.\nI call it curve fitting. It might sound derogatory, but I don’t mean it in a derogatory \nway. I mean it in a descriptive sense that what people are doing in deep learning and \nneural networks is fitting very sophisticated functions to a bunch of points. These \nfunctions are very sophisticated, they have thousands of hills and valleys, they’re \nintricate, and you cannot predict them in advance. But they’re still just a matter of \nfitting functions to a cloud of points. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 546
  },
  {
    "chunk_full": "JUDEA PEARL\n367\nThis philosophy has clear theoretical limitations, and I’m not talking about opinion, \nI’m talking about theoretical limitations. You cannot do counterfactuals, and you \ncannot think about actions that you’ve never seen before. I describe it in terms \nof three cognitive levels: seeing, intervening, and imagining. Imagining is the top \nlevel, and that level requires counterfactual reasoning: how would the world look \nlike had I done things differently? For example, what would the world look like \nhad Oswald not killed Kennedy, or had Hillary won the election? We think about \nthose things and can communicate with those kinds of imaginary scenarios, and \nwe are quite comfortable to engage in this “let’s pretend” game.\nThe reason why we need this capability is to build new models of the world. \nImagining a world that does not exist gives us the ability to come up with new \ntheories, new inventions, and also to repair our old actions so as to assume \nresponsibility, regret, and free will. All of this comes as part of our ability to \ngenerate worlds that do not exist but could exist, but still generate them widely, not \nwildly. We have rules for generating plausible counterfactuals that are not whimsical. \nThey have their own inner structure, and once we understand this logic, we can \nbuild machines that imagine things, that assume responsibility for their actions, and \nunderstand ethics and compassion. \nI’m not a futurist and I try not to talk about things that I don’t understand, but \nI did some thinking, and I believe I understand how important counterfactuals \nare in all these cognitive tasks that people dream of which eventually will be \nimplemented on a computer. I have a few basic sketches of how we can program \nfree will, ethics, morality, and responsibility into machines, but these are in the \nrealm of sketches. The basic thing is that we know today what it takes to interpret \ncounterfactuals and understand cause and effect. \nThese are the mini-steps toward general AI, but there’s a lot we can learn from \nthese steps, and that’s what I’m trying to get the machine learning community \nto understand. I want them to understand that deep learning is a mini-step \ntoward general AI. We need to learn what we can from the way theoretical \nbarriers were circumvented in causal reasoning, so that we can circumvent \nthem in general AI.\nMARTIN FORD: So, you’re saying that deep learning is limited to analyzing data and \nthat causation can never be derived from data alone. Since people are able to do \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 547
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n368\ncausal reasoning, the human mind must have some built-in machinery that allows \nus to create causal models. It’s not just about learning from data.\nJUDEA PEARL: To create is one thing, but even if somebody creates it for us, our \nparents, our peers, our culture, we need to have the machinery to utilize it. \nMARTIN FORD: Right. It sounds like a causal diagram, or a causal model is really \njust a hypothesis. Two people might have different causal models, and somewhere \nin our brain is some kind of machinery that allows us to continuously create these \ncausal models internally, and that’s what allows us to reason based on data. \nJUDEA PEARL: We need to create them, to modify them, and to perturb them \nwhen the need arises. We used to believe that malaria is caused by bad air, now \nwe don’t. Now we believe it’s caused by a mosquito called Anopheles. It makes \na difference because if it is bad air, I will carry a breathing mask the next time \nI go to the swamp; and if it’s an Anopheles mosquito, I’ll carry a mosquito net. \nThese competing theories make a big difference in how we act in the world. \nThe way that we get from one hypothesis to another was by trial and error; I \ncall it playful manipulation. \nThis is how a child learns causal structure, by playful manipulation, and this is how \na scientist learns causal structure—playful manipulation. But we have to have the \nabilities and the template to store what we learn from this playful manipulation so \nwe can use it, test it, and change it. Without the ability to store it in a parsimonious \nencoding, in some template in our mind, we cannot utilize it, nor can we change \nit or play around with it. That is the first thing that we have to learn; we have to \nprogram computers to accommodate and manage that template.\nMARTIN FORD: So, you think that some sort of built-in template or structure \nshould be built into an AI system so it can create causal models? DeepMind uses \nreinforcement learning, which is based on practice or trial and error. Perhaps that \nwould be a way of discovering causal relationships? \nJUDEA PEARL: It comes into it, but reinforcement learning has limitations, too. \nYou can only learn actions that have been seen before. You cannot extrapolate to \nactions that you haven’t seen, like raising taxes, increasing the minimum wage, \nor banning cigarettes. Cigarettes have never been banned before, yet we have \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 548
  },
  {
    "chunk_full": "JUDEA PEARL\n369\nmachinery that allows us to stipulate, extrapolate, and imagine what could be \nthe consequences of banning cigarettes. \nMARTIN FORD: So, you believe that the capability to think causally is critical to \nachieving what you’d call strong AI or AGI, artificial general intelligence?\nJUDEA PEARL: I have no doubt that it is essential. Whether it is sufficient, I’m not \nsure. However, causal reasoning doesn’t solve every problem of general AI. It doesn’t \nsolve the object recognition problem, and it doesn’t solve the language understanding \nproblem. We basically solved the cause-effect puzzle, and we can learn a lot from \nthese solutions so that we can help the other tasks circumvent their obstacles.\nMARTIN FORD: Do you think that strong AI or AGI is feasible? Is that something \nyou think will happen someday? \nJUDEA PEARL: I have no doubt that it is feasible. But what does it mean for me \nto say no doubt? It means that I am strongly convinced it can be done because I \nhaven’t seen any theoretical impediment to strong AI. \nMARTIN FORD: You said that way back around 1961, when you were at RCA, people \nwere already thinking about this. What do you think of how things have progressed? \nAre you disappointed? What’s your assessment of progress in artificial intelligence? \nJUDEA PEARL: Things are progressing just fine. There were a few slowdowns, \nand there were a few hang-ups. The current machine learning concentration on \ndeep learning and its non-transparent structures is such a hang-up. They need to \nliberate themselves from this data-centric philosophy. In general, the field has been \nprogressing immensely, because of technology and because of the people that the \nfield attracts. The smartest people in science.\nMARTIN FORD: Most of the recent progress has been in deep learning. You seem \nsomewhat critical of that. You’ve pointed out that it’s like curve fitting and it’s not \ntransparent, but actually more of a black-box that just generates answers.\nJUDEA PEARL: It’s curve fitting, correct, it’s harvesting low-hanging fruits. \nMARTIN FORD: It’s still done amazing things. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 549
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n370\nJUDEA PEARL: It’s done amazing thing because we didn’t realize there are so many \nlow-hanging fruits. \nMARTIN FORD: Looking to the future, do you think that neural networks are going \nto be very important? \nJUDEA PEARL: Neural networks and reinforcement learning will all be essential \ncomponents when properly utilized in causal modeling. \nMARTIN FORD: So, you think it might be a hybrid system that incorporates not \njust neural networks, but other ideas from other areas of AI?\nJUDEA PEARL: Absolutely. Even today, people are building hybrid systems when \nyou have sparse data. There’s a limit, however, to how much you can extrapolate \nor interpolate sparse data if you want to get cause-effect relationships. Even if you \nhave infinite data, you can’t tell the difference between A causes B and B causes A. \nMARTIN FORD: If someday we have strong AI, do you think that a machine could \nbe conscious, and have some kind of inner experience like a human being? \nJUDEA PEARL: Of course, every machine has an inner experience. A machine has \nto have a blueprint of some of its software; it could not have a total mapping of \nits software. That would violate Turing’s halting problem. \nIt’s feasible, however, to have a rough blueprint of some of its important connections and \nimportant modules. The machine would have to have some encoding of its abilities, of \nits beliefs, and of its goals and desires. That is doable. In some sense, a machine already \nhas an inner self, and more so in the future. Having a blueprint of your environment, \nhow you act on and react to the environment, and answering counterfactual questions \namount to having an inner self. Thinking: What if I had done things differently? What \nif I wasn’t in love? All this involves manipulating your inner self.\nMARTIN FORD: Do you think machines could have emotional experiences, that a \nfuture system might feel happy, or might suffer in some way? \nJUDEA PEARL: That reminds me of The Emotion Machine, a book by Marvin Minsky. \nHe talks about how easy it is to program emotion. You have chemicals floating in \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 550
  },
  {
    "chunk_full": "JUDEA PEARL\n371\nyour body, and they have a purpose, of course. The chemical machine interferes \nwith, and occasionally overrides the reasoning machine when urgencies develop. So, \nemotions are just a chemical priority-setting machine.\nMARTIN FORD: I want to finish by asking you about some of the things that \nwe should worry about as artificial intelligence progresses. Are there things we \nshould be concerned about? \nJUDEA PEARL: We have to worry about artificial intelligence. We have to \nunderstand what we build, and we have to understand that we are breeding a new \nspecies of intelligent animals. \nAt first, they are going to be domesticated, like our chickens and our dogs, but \neventually, they will assume their own agency, and we have to be very cautious \nabout this. I don’t know how to be cautious without suppressing science and \nscientific curiosity. It’s a difficult question, so I wouldn’t want to enter into a \ndebate about how we regulate AI research. But we should absolutely be cautious \nabout the possibility that we are creating a new species of super-animals, or in the \nbest case, a species of useful, but exploitable, human beings that do not demand \nlegal rights or minimum wage.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 551
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n372\nJUDEA PEARL was born in Tel Aviv and is a graduate of the Technion-Israel Institute \nof Technology. He came to the United States for postgraduate work in 1960, and the \nfollowing year he received a master’s degree in electrical engineering from Newark College \nof Engineering, now New Jersey Institute of Technology. In 1965, he simultaneously \nreceived a master’s degree in physics from Rutgers University and a PhD from the Brooklyn \nPolytechnic Institute, now Polytechnic Institute of New York University. Until 1969, he held \nresearch positions at RCA David Sarnoff Research Laboratories in Princeton, New Jersey \nand Electronic Memories, Inc. Hawthorne, California.\nJudea joined the faculty of UCLA in 1969, where he is currently a professor of computer science \nand statistics and director of the Cognitive Systems Laboratory. He is known internationally \nfor his contributions to artificial intelligence, human reasoning, and philosophy of science. \nHe is the author of more than 450 scientific papers and three landmark books: Heuristics \n(1984), Probabilistic Reasoning (1988), and Causality (2000; 2009).\nA member of the National Academy of Sciences, the National Academy of Engineering and a \nfounding Fellow of the American Association for Artificial Intelligence, Judea is the recipient \nof numerous scientific prizes, including three awarded in 2011: the Association for Computing \nMachinery A.M. Turing Award for his fundamental contributions to artificial intelligence \nthrough the development of a calculus for probabilistic and causal reasoning, the David E. \nRumelhart Prize for Contributions to the Theoretical Foundations of Human Cognition, and \nthe Harvey Prize in Science and Technology from Technion—Israel Institute of Technology. \nOther honors include the 2001 London School of Economics Lakatos Award in Philosophy of \nScience for the best book in the philosophy of science, the 2003 ACM Allen Newell Award for \n“seminal contributions that extend to philosophy, psychology, medicine, statistics, econometrics, \nepidemiology and social science,” and the 2008 Benjamin Franklin Medal for Computer and \nCognitive Science from the Franklin Institute.\n \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 552
  },
  {
    "chunk_full": "JUDEA PEARL\n373\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 553
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n374\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 554
  },
  {
    "chunk_full": "JEFFREY DEAN\n375\nJEFFREY DEAN\nGOOGLE SENIOR FELLOW, HEAD OF AI AND GOOGLE BRAIN\nJeff Dean joined Google in 1999, and has played a role in developing many \nof Google’s core systems in areas like search, advertising, news and language \ntranslation, as well as in the design of the company’s distributed computing \narchitecture. In recent years, he has focused on AI and machine learning and \nworked on the development of TensorFlow, Google’s widely-used open source \nsoftware for deep learning. He currently guides Google’s future path in AI as \ndirector of artificial intelligence and head of the Google Brain project. \nWe’re all working together on trying to build really  \nintelligent, flexible AI systems. We want those systems  \nto be able to come into a new problem and use pieces  \nof knowledge that they’ve developed from solving  \nmany other problems to all of a sudden be able to  \nsolve that new problem in a flexible way, which is  \nessentially one of the hallmarks of human intelligence.  \nThe question is, how can we build that capability into  \ncomputer systems?\n“ \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 555
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n376\nMARTIN FORD: As the Director of AI at Google and head of Google Brain, what’s \nyour vision for AI research at Google?\nJEFF DEAN: Overall, I view our role as to advance the state of the art in \nmachine learning, to try and build more intelligent systems by developing new \nmachine learning algorithms and techniques, and to build software and hardware \ninfrastructure that allows us to make faster progress on these approaches and allow \nother people to also apply these approaches to problems they care about. TensorFlow \nis a good example of that.\nGoogle Brain is one of several different research teams that we have within the \nGoogle AI research team, and some of those other teams have slightly different \nfocuses. For instance, there’s a large team focused on machine perception problems, \nand another team focused on natural language understanding. It’s not really hard \nboundaries here; interests overlap across the teams, and we collaborate quite heavily \nacross many of these teams for many of the projects that we’re working on.\nWe do deep collaborations with the Google product teams sometimes. We’ve \ndone collaborations in the past with our search ranking team to try to apply deep \nlearning to some of the problems in search ranking and retrieval. We’ve also done \ncollaborations with both the Google Translate and Gmail team, as well as many \nother teams throughout Google. The fourth area is researching new and interesting \nemerging areas, where we know machine learning will be a significantly new and \nimportant piece of solving problems in that domain. \nWe have quite a lot of work, for example, in the use of AI and machine learning \nfor healthcare, and also AI and machine learning for robotics. Those are two \nexamples, but we’re also looking at earlier-stage things. We have 20 different \nareas where we think there’s a real key aspect of some of the problems in that \narea that machine learning, or our particular kind of expertise, could really help \nwith. So, my role is basically to try to have us be as ambitious as possible in \nall these different kinds of projects, and also to push us in new and interesting \ndirections for the company.\nMARTIN FORD: I know that DeepMind is heavily focused on AGI. Does that \nmean that the other artificial intelligence research at Google is geared toward \nmore narrow and practical applications?\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 556
  },
  {
    "chunk_full": "JEFFREY DEAN\n377\nJEFF DEAN: That’s correct that DeepMind is more focused on AGI, and I think they \nhave a structured plan where they believe if they solve this and this and this, that may \nlead to AGI. That’s not to say that the rest of Google AI doesn’t think about it. A lot \nof researchers in the Google AI research organization are also focused on building new \ncapabilities for generally intelligent systems, or AGI if you want to call it that. I would \nsay that our path is a bit more organic. We do things that we know are important but \nthat we can’t do yet, and once we solve those, then we figure out what is the next \nset of problems that we want to solve that will give us new capabilities. \nIt’s really a slightly different approach, but ultimately, we’re all working together \non trying to build really intelligent, flexible AI systems. We want those systems \nto be able to come into a new problem and use pieces of knowledge that they’ve \ndeveloped from solving many other problems to all of a sudden be able to solve that \nnew problem in a flexible way, which is essentially one of the hallmarks of human \nintelligence. The question is, how can we build that capability into computer systems?\nMARTIN FORD: What was the path that led to you becoming interested in AI and \nthen to your current role at Google?\nJEFF DEAN: My dad got a computer when I was 9 that he assembled from a kit, and \nI learned to program on that through middle and high school. From there, I went \non to do a double degree in Computer Science and Economics at the University of \nMinnesota. My senior thesis was on parallel training of neural networks, and this \nwas back when neural networks were hot and exciting in the late 1980s and early \n1990s. At that time, I liked the abstraction that they provided; it felt good. \nI think a lot of other people felt the same way, but we just didn’t have enough \ncomputational power. I felt like if we could get 60-times the speed on those 64-bit \nprocessor machines then we could actually do great things. It turns out that we \nneeded more like a million-times the speed, but we have that now. \nI then went to work for the World Health Organization for a year, doing statistical \nsoftware for HIV and AIDS surveillance and forecasting. After that, I went to \ngraduate school at the University of Washington, where I got a PhD in Computer \nScience, doing mostly compiler optimization work. I went on to work for DEC in \nPalo Alto in their industrial research lab, before joining a startup—I lived in Silicon \nValley, and that was the thing to do!\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 557
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n378\nEventually, I ended up at Google back when it only employed around 25 people, and \nI’ve been here ever since. I’ve worked on a number of things at Google. The first thing \nI did here was working on our first advertising system. I then worked for many years \non our search systems and features like the crawling system, query-serving system, the \nindexing system, and the ranking functions, etc. I then moved on to our infrastructure \nsoftware, things like MapReduce, Bigtable and Spanner, and also our indexing systems.\nIn 2011, I started to work on more machine learning-oriented systems, because \nI started to get very interested in how we could apply the very large amounts of \ncomputation that we had to train very large and powerful neural nets.\nMARTIN FORD: You’re the head, and one of the founders, of Google Brain, which \nwas one of the first real applications of deep learning and neural networks. Could \nyou sketch out the story of Google Brain, and the role it plays at Google?\nJEFF DEAN: Andrew Ng was a consultant in Google X for one day a week, and I \nbumped into him in the kitchen one day, and I said, “What are you up to?” He said, \n“Oh, I’m still figuring things out here, but at Stanford, my students are starting \nto look at how neural networks can be applied to different kinds of problems, and \nthey’re starting to work.” I had experience with neural networks from doing my \nundergraduate thesis 20 years ago, so I said, “That’s cool, I like neural networks. \nHow are they working?” We started talking, and we came up with the relatively \nambitious plan of trying to use as much computation as we could throw at the \nproblem to try to train neural networks. \nWe tackled two problems: the first was the unsupervised learning of image data. \nHere, we took 10 million frames from random YouTube videos and tried to use \nunsupervised learning algorithms to see what would happen if we trained a very \nlarge network. Maybe you’ve seen the famous cat neuron visualization?\nMARTIN FORD: Yes. I remember that got a lot of attention at the time.\nJEFF DEAN: That was a sign that there was something interesting going on there \nwhen you trained these models at scale with large amounts of data.\nMARTIN FORD: Just to emphasize, this was unsupervised learning, in the sense that \nit figured out the concept of a cat organically, from unstructured, unlabeled data? \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 558
  },
  {
    "chunk_full": "JEFFREY DEAN\n379\nJEFF DEAN: Correct. We gave it the raw images from a bunch of YouTube videos, \nand had an unsupervised algorithm that was trying to build a representation that \nwould allow it to reconstruct those images from that compact representation. One \nof the things it learned to do was to discover a pattern that would fire if there was \na cat of some sort in the center of the frame because that’s a relatively common \noccurrence in YouTube videos, so that was pretty cool. \nThe other thing we did was to work with the speech recognition team on applying \ndeep learning and deep neural networks to some of the problems in the speech \nrecognition system. At first, we worked on the acoustic model, where you try to \ngo from raw audio waveforms to a part-of-word sound, like “buh,” or “fuh,” or \n“ss”—the things that form words. It turned out we could use neural networks to \ndo that much better than the previous system they were using. \nThat got very significant decreases in word error rate for the speech recognition \nsystem. We then just started to look and collaborate with other teams around \nGoogle about what kinds of interesting perception problems that it had in the \nspeech space or in the image recognition or video processing space. We also \nstarted to build software systems to make it easy for people to apply these \napproaches to new problems, and where we could automatically map these \nlarge computations onto multiple computers in a relatively easy way that the \nprogrammer didn’t have to specify. They’d just say, “Here’s a big model and \nI want to train it, so please go off and use 100 computers for it.” And that \nwould happen. That was the first generation of software that we built to address \nthese kinds of problems. \nWe then built the second generation, that is, TensorFlow, and we decided we would \nopen source that system. We were really designing it for three objectives. One \nwas to be really flexible, so we could try out lots of different research ideas in \nthe machine learning space quickly. The second was to be able to scale and tackle \nproblems where we had lots of data, and we wanted very large, computationally \nexpensive models. The third was that we wanted to be able to go from a research \nidea to a production-serving system for a model that worked in the same sort of \nunderlying software system. We open sourced that at the end of 2015, and since \nthen it’s had quite a lot of adoption externally. Now there’s a large community \nof TensorFlow users across a range of companies, academic institutions, and both \nhobbyists and public users using it. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 559
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n380\nMARTIN FORD: Is TensorFlow going to become a feature of your cloud server so \nthat your customers have access to machine learning?\nJEFF DEAN: Yes, but there’s a bit of nuance here. TensorFlow itself is an open \nsource software package. We want our cloud to be the best place to run TensorFlow \nprograms, but you can run them wherever you want. You can run them on your \nlaptop, you can run them on a machine with GPU cards that you bought, you can \nrun them on a Raspberry Pi, and on Android.\nMARTIN FORD: Right, but on Google Cloud, you’ll have tensor processors and the \nspecialized hardware to optimize it?\nJEFF DEAN: That’s correct. In parallel with the TensorFlow software development, \nwe’ve been working on designing custom processors for these kinds of machine \nlearning applications. These processors are specialized for essentially low-precision \nlinear algebra, which forms the core of all of these applications of deep learning \nthat you’ve been seeing over the last 6 to 7 years. \nThe processors can train models very fast, and they can do it more power-efficiently. \nThey can also be used for inference, where you actually have a trained model, and \nnow you just want to apply it very quickly with high throughput for some production \nuse, like Google Translate, or our speech recognition systems, or even Google Search. \nWe’ve also made the second-generation Tensor Processing Units (TPUs), available \nto cloud customers in several ways. One is under the covers in a few of our cloud \nproducts, but the other is they can just get a raw virtual machine with a cloud TPU \ndevice attached, and then they can run their own machine learning computations \nexpressed in TensorFlow on that device.\nMARTIN FORD: With all of this technology integrated into the cloud, are we getting \nclose to the point where machine learning becomes available to everybody, like a utility? \nJEFF DEAN: We have a variety of cloud products that are meant to appeal to \ndifferent constituencies in this space. If you’re fairly experienced with machine \nlearning, then you can get a virtual machine with one of these TPU devices on \nit, and write your own TensorFlow programs to solve your particular problem in \na very customizable way. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 560
  },
  {
    "chunk_full": "JEFFREY DEAN\n381\nIf you’re not as much of an expert, we have a couple of other things. We have \npre-trained models that you can use that require no machine learning expertise. \nYou can just send us an image or a clip of audio, and we will tell you what’s in \nthat image. For instance, “that’s a picture of a cat,” or “people seem happy in the \nimage,” or “we extracted these words from the image.” In the audio case, it’s “we \nthink this is what the people said in this audio clip.” We also have translation models \nand video models. Those are very good if what you want is a general-purpose task, \nlike reading the words in an image. \nWe also have a suite of AutoML products, which are essentially designed for \npeople who may not have as much machine learning expertise, but want a \ncustomized solution for a particular problem they have. Imagine if you have \na set of images of parts that are going down your assembly line and there are \n100 kinds of parts, and you want to be able to identify what part it is from the \npixels in an image. There, we can actually train you a custom model without \nyou having to know any machine learning through this technique called AutoML. \nEssentially, it can repeatedly try lots and lots of machine learning experiments \nas a human-machine learning expert would, but without you having to be a \nmachine learning expert. It does it in an automated way, and then we give you \na very high-accuracy model for that particular problem, without you needing to \nhave machine learning expertise. \nI think that’s really important because if you think about the world today, \nthere are between 10,000 to 20,000 organizations in the world that have hired \nmachine learning expertise in-house and are productively employing it. I’m \nmaking up that number, but it’s roughly that order of magnitude. Then, if you \nthink about all the organizations in the world that have data that could be used \nfor machine learning, it’s probably 10 million organizations that have some sort \nof machine learning problem. \nOur aim is to make that approach much easier to use, so that you don’t need \na master’s-level course on machine learning to do this. It’s more at the level of \nsomeone who could write a database query. If users with that level of expertise \nwere able to get a working machine learning model, that would be quite powerful. \nFor example, every small city has lots of interesting data about how they should set \ntheir stop light timers. Right now, they don’t really do that with machine learning, \nbut they probably should.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 561
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n382\nMARTIN FORD: So, a democratization of AI is one of the goals that you’re \nworking toward. What about the route to general intelligence, what are some of \nthe hurdles that you see there?\nJEFF DEAN: One of the big problems with the use of machine learning today is \nthat we typically find a problem we want to solve with machine learning, and then \nwe collect a supervised training dataset. We then use that to train a model that’s \nvery good at that particular thing, but it can’t do anything else. \nIf we really want generally intelligent systems, we want a single model that can do \nhundreds of thousands of things. Then, when the 100,001st thing comes along, it \nbuilds on the knowledge that it gained from solving the other things and develops \nnew techniques that are effective at solving that new problem. That will have several \nadvantages. One of them is that you get this incredible multitask benefit from using \nthe wealth of your experience to solve new problems more quickly and better, \nbecause many problems share some aspects. It also means that you need much less \ndata, or fewer observations, to learn to do a new thing.\nUnscrewing one kind of jar lid is a lot like unscrewing another kind of jar lid, \nexcept for maybe a slightly different kind of turning mechanism. Solving this math \nproblem is a lot like these other math problems, except with some sort of twist. \nI think that’s the approach we really need to be taking in these things, and I think \nexperimentation is a big part of this. So, how can systems learn from demonstrations \nof things? Supervised data is like that, but we’re doing a bit of work in this space \nin robotics as well. We can have humans demonstrate a skill, and then robots can \nlearn from video demonstrations of that skill and learn to pour things with relatively \nfew examples of humans pouring things. \nAnother hurdle is that we need very large computational systems, because if we \nreally want a single system that solves all of our machine learning problems, \nthat’s a lot of computation. Also, if we really want to try different approaches \nof this, then you need the turnaround time on those kinds of experiments to \nbe very fast. Part of the reason we’re investing in building large-scale machine \nlearning accelerator hardware, like our TPUs, is that we believe that if you \nwant these kinds of large, single, powerful models, it’s really important that \nthey have enough computational capability to do interesting things and allow \nus to make fast progress.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 562
  },
  {
    "chunk_full": "JEFFREY DEAN\n383\nMARTIN FORD: What about the risks that come along with AI? What are the things \nthat we really need to be concerned about?\nJEFF DEAN: Changes in the labor force are going to be significant things that \ngovernments and policymakers should really be paying attention to. It’s very clear \nthat even without significant further advances in what we can do, the fact that \ncomputers can now automate a lot of things that didn’t use to be automatable even \nfour or five years ago, is a pretty big change. It’s not just one sector; it’s an aspect \nthat cuts across multiple different jobs and employment. \nI was on a White House Office of Science and Technology Policy Committee, which was \nconvened at the end of the Obama administration in 2016, and which brought together \nabout 20 machine learning people and 20 economists. In this group, we discussed what \nkinds of impact this would have on the labor markets. It’s definitely the kind of thing \nwhere you want governments to be paying attention and figuring out for people whose \njobs change or shift, how can they acquire new skills or get new kinds of training that \nmake them able to do things that are not at risk of automation? That’s an important \naspect that governments have a strong, clear role to play in.\nMARTIN FORD: Do you think someday we may need a universal basic income?\nJEFF DEAN: I don’t know. It’s very hard to predict because I think any time we’ve \ngone through technological change, that has happened; it’s not like this is a new \nthing. The Industrial Revolution, the Agricultural Revolution, all these things have \ncaused imbalance to society as a whole. What people do in terms of their daily \njobs has shifted tremendously. I think this is going to be similar, in that entirely \nnew kinds of things will be created that people will do, and it’s somewhat hard to \npredict what those things will be. \nSo, I do think it’s important that people be flexible and learn new things throughout \ntheir career. I think that’s already true today. Whereas 50 years ago, you could go \nto school and then start a career and be in that career for many, many years, today \nyou might work in one role for a few years and pick up some new skills, then do \nsomething a bit different. That kind of flexibility is, I think, important. \nIn terms of other kinds of risks, I’m not as worried about the Nick Bostrom \nsuperintelligence aspect. I do think that as computer scientists and machine learning \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 563
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n384\nresearchers we have the opportunity and the ability to shape how we want machine \nlearning systems to be integrated and used in our society. \nWe can make good choices there, or we can make some not so good choices. As \nlong as we make good choices, where these things are actually used for the benefit \nof humanity, then it’s going to be fantastic. We’ll get better healthcare and we’ll be \nable to discover all kinds of new scientific discoveries in collaboration with human \nscientists by generating new hypotheses automatically. Self-driving cars are clearly \ngoing to transform society in very positive ways, but at the same time, that is going \nto be a source of disruption in the labor markets. There are nuances to many of \nthese developments that are important. \nMARTIN FORD: One cartoon view of this is that a small team—maybe at Google—\ndevelops AGI, and that small group of people are not necessarily tied into these broader \nissues, then it turns out that these few people are making the decision for everyone. \nDo you think there is a place for regulation of some AI research or applications?\nJEFF DEAN: It’s possible. I think regulation has a role to play, but I want regulation \nto be informed by people with expertise in the field. I think sometimes regulation \nhas a bit of a lag factor, as governments and policymakers catch-up to what is now \npossible. Knee-jerk reactions in terms of regulation or policymaking are probably \nnot helpful, but informed dialog with people in the field is important as government \nfigures out what role it wants to play in informing how things should play out. \nIn respect to the development of AGI, I think it’s really important that we do this \nethically and with sound decision-making. That’s one reason that Google has put \nout a clear document of the principles by which we’re approaching these sorts of \nissues1. Our AI principles document is a good example of the thought we’re putting \ninto not just the technical development of this, but the way in which we want to \nbe guided in what kinds of problems we want to tackle with these approaches, how \nwe will approach them, and what we will not do.\n1  https://www.blog.google/technology/ai/ai-principles/\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 564
  },
  {
    "chunk_full": "JEFFREY DEAN\n385\nJEFFREY DEAN joined Google in 1999, and is currently a Google Senior Fellow in the \nResearch Group, where he leads the Google Brain project and is the overall director of artificial \nintelligence research at the company.\nJeff received a PhD in Computer Science from the University of Washington, working with Craig \nChambers on whole-program optimization techniques for object-oriented languages in 1996. \nHe received a BS, summa cum laude from the University of Minnesota in Computer Science \n& Economics in 1990. From 1996 to 1999, he worked for Digital Equipment Corporation’s \nWestern Research Lab in Palo Alto, where he worked on low-overhead profiling tools, design of \nprofiling hardware for out-of-order microprocessors, and web-based information retrieval. From \n1990 to 1991, Jeff worked for the World Health Organization’s Global Programme on AIDS, \ndeveloping software to do statistical modeling, forecasting, and analysis of the HIV pandemic.\nIn 2009, Jeff was elected to the National Academy of Engineering, and he was also named \na Fellow of the Association for Computing Machinery (ACM) and a Fellow of the American \nAssociation for the Advancement of Sciences (AAAS).\nHis areas of interest include large-scale distributed systems, performance monitoring, \ncompression techniques, information retrieval, application of machine learning to search and \nother related problems, microprocessor architecture, compiler optimizations, and development \nof new products that organize existing information in new and interesting ways.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 565
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n386\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 566
  },
  {
    "chunk_full": "DAPHNE KOLLER\n387\nDAPHNE KOLLER\nCEO AND FOUNDER, INSITRO \nADJUNCT PROFESSOR OF COMPUTER SCIENCE, STANFORD\nDaphne Koller was the Rajeev Motwani Professor of Computer Science at \nStanford University (where she is currently an Adjunct Professor) and is one \nof the founders of Coursera. She is focused on the potential benefits of AI \nin healthcare and worked as the Chief Computing Officer at Calico, an \nAlphabet subsidiary researching longevity. She is currently the Founder and \nCEO of insitro, a biotech startup using machine learning to research and \ndevelop new drugs.\nStopping progress by stopping technology is the  \nwrong approach. [...] If you don’t make progress  \ntechnologically, someone else will, and their intent  \nmight be considerably less beneficial than yours.\n“ \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 567
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n388\nMARTIN FORD: You’ve just started a new role as CEO and founder of insitro, a \nstartup company focused on using machine learning for drug discovery. Could you \ntell me more about that? \nDAPHNE KOLLER: We need a new solution in order to continue driving progress \nin drug research forward. The problem is that it is becoming consistently more \nchallenging to develop new drugs: clinical trial success rates are around the mid-\nsingle-digit range; the pre-tax R&D cost to develop a new drug (once failures are \nincorporated) is estimated to be greater than $2.5B. The rate of return on drug \ndevelopment investment has been decreasing linearly year by year, and some analyses \nestimate that it will hit zero before 2020. One explanation for this is that drug \ndevelopment is now intrinsically harder: Many (perhaps most) of the “low-hanging \nfruit”—in other words, druggable targets that have a significant effect on a large \npopulation—have been discovered. If so, then the next phase of drug development \nwill need to focus on drugs that are more specialized — whose effects may be \ncontext-specific, and which apply only to a subset of patients. Figuring out the \nappropriate patient population is often hard, making therapeutic development more \nchallenging, and that leaves many diseases without effective treatment and lots of \npatients with unmet needs. Also, the reduced market size forces an amortization \nof high development costs over a much smaller base.\nOur hope at insitro is that big data and machine learning, applied to drug discovery, \ncan help make the process faster, cheaper, and more successful. To do that, we \nplan to leverage both cutting-edge machine learning techniques, as well as the \nlatest innovations that have occurred in life sciences, which enable the creation \nof the large, high-quality data sets that may transform the capabilities of machine \nlearning in this space. Seventeen years ago, when I first started to work in the \narea of machine learning for biology and health, a “large” dataset was a few dozen \nsamples. Even five years ago, data sets with more than a few hundred samples \nwere a rare exception. We now live in a different world. We have human cohort \ndata sets (such as the UK Biobank), which contain large amounts of high-quality \nmeasurements—molecular as well as clinical—for hundreds of thousands of \nindividuals. At the same time, a constellation of remarkable technologies allow \nus to construct, perturb, and observe biological model systems in the laboratory \nwith unprecedented fidelity and throughput. Using these innovations, we plan to \ncollect and use a range of very large data sets to train machine learning models \nthat will help address key problems in the drug discovery and development process. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 568
  },
  {
    "chunk_full": "DAPHNE KOLLER\n389\nMARTIN FORD: It sounds like insitro is planning to do both wet-lab experimental \nwork and high-end machine learning. These are not often done within a single \ncompany. Does that integration pose new challenges? \nDAPHNE KOLLER: Absolutely. I think the biggest challenge is actually cultural, in \ngetting scientists and data scientists to work together as equal partners. In many \ncompanies, one group sets the direction, and the other takes a back seat. At insitro, \nwe really need to build a culture in which scientists, engineers, and data scientists \nwork closely together to define problems, design experiments, analyze data, and \nderive insights that will lead us to new therapeutics. We believe that building this \nteam and this culture well is as important to the success of our mission as the \nquality of the science or the machine learning that these different groups will create.\nMARTIN FORD: How important is machine learning in the healthcare space? \nDAPHNE KOLLER: When you look at the places where machine learning has made \na difference, it’s really been where we have an accumulation of large amounts of \ndata and we have people who can think simultaneously about the problem domain \nand how machine learning can solve that. \nYou can now get large amounts of data from resources like the UK Biobank or \nAll of Us, which gather a lot of information about people and enable you to start \nthinking about the health trajectories of actual humans. On the other side, we have \namazing technologies like CRISPR, DNA synthesis, next-generation sequencing, \nand all sorts of other things that are all coming together at the same time to be \nable to create large datasets on a molecular level. \nWe are now in the position where we can begin to deconvolute what is to my \nmind the most complex system that we’ve seen: the biology of humans and other \norganisms. That is an unbelievable opportunity for science, and is going to require \nmajor developments on the machine learning side to figure out and create the kinds \nof interventions that we need to live longer, healthier lives.\nMARTIN FORD: Let’s talk about your own life; how did you get started in AI?\nDAPHNE KOLLER: I was a PhD student at Stanford working in the area of \nprobabilistic modeling. Nowadays it would look like AI, but it wasn’t really known \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 569
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n390\nas artificial intelligence back then; in fact, probabilistic modeling was considered \nanathema to artificial intelligence, which was much more focused on logical \nreasoning at the time. Things changed, though, and AI expanded into a lot of other \ndisciplines. In some ways, the field of AI grew to embrace my work rather than \nme choosing to go into AI. \nI went to Berkeley as a postdoc, and there I started to really think about how what \nI was doing was relevant to actual problems that people cared about, as opposed \nto just being mathematically elegant. That was the first time I started to get into \nmachine learning. I then returned to Stanford as faculty in 1995 where I started to \nwork on areas relating to statistical modeling and machine learning. I began studying \napplied problems where machine learning could really make a difference.\nI worked in computer vision, in robotics, and from 2000 on biology and health \ndata. I also had an ongoing interest in technology-enabled education, which led to \na lot of experimentation at Stanford into ways in which we could offer an enhanced \nlearning experience. This was not only for students on campus, but also trying to \noffer courses to people who didn’t have access to a Stanford education. \nThat whole process led to the launch of the first three Stanford MOOCs (Massive \nOpen Online Courses) in 2011. That was a surprise to all of us because we \ndidn’t really try and market it in any concerted way. It was really much more \nof a viral spread of information about the free courses Stanford was offering. It \nhad an unbelievable response where each of those courses had an enrollment of \n100,000 people or more. That really was the turning point of, “we need to do \nsomething to deliver on the promise of this opportunity,” and that’s what led to \nthe creation of Coursera.\nMARTIN FORD: Before we jump into that I want talk more about your research. \nYou focused on Bayesian networks and integrating probability into machine learning. \nIs that something that can be integrated with deep learning neural networks, or is \nthat a totally separate or competing approach? \nDAPHNE KOLLER: This is a subtle answer that has several aspects. Probabilistic \nmodels lie on a continuum between those that try to encode the domain structure \nin an interpretable way—a way that makes sense to humans—and those that just try \nto capture the statistical properties of the data. The deep learning models intersect \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 570
  },
  {
    "chunk_full": "DAPHNE KOLLER\n391\nwith probabilistic models—some can be viewed as encoding a distribution. Most \nof them have elected to focus on maximizing the predictive accuracy of the model, \noften at the expense of interpretability. Interpretability and the ability to incorporate \nstructure in the domain has a lot of advantages in cases where you really need to \nunderstand what the model does, for instance in medical applications. It’s also a way \nof dealing effectively with scenarios where you don’t have a lot of training data, and \nyou need to make up for it with prior knowledge. On the other hand, the ability \nto not have any prior knowledge and just let the data speak for themselves also has \na lot of advantages. It’d be nice if you could merge them somehow. \nMARTIN FORD: Let’s talk about Coursera. Was it a case of seeing the online \nclasses that you and others taught at Stanford do really well, and deciding to start \na company to continue that work? \nDAPHNE KOLLER: We struggled trying to figure out what was the right way to take \nthe next steps. Was it continuing this Stanford effort? Was it launching a nonprofit \norganization? Was it creating a company? We thought about it a fair bit and decided \nthat creating a company was the right way to maximize the impact that we could \nhave. So, in January of 2012, we started the company which is now called Coursera. \nMARTIN FORD: Initially, there was enormous hype about MOOCs and that people all \nover the world were going to get a Stanford education on their phone. It seems to \nhave evolved more along the lines of people that already have a college degree going \nto Coursera to get extra credentials. It hasn’t disrupted undergraduate education \nin the way that some people predicted. Do you see that changing, going forward? \nDAPHNE KOLLER: I think it’s important to recognize that we never said this is \ngoing to put universities out of business. There were other people who said that, but \nwe never endorsed that and we didn’t think it was a good idea. In some ways, the \ntypical Gartner hype cycle of MOOCs was compressed. People made these extreme \ncomments, in 2012 it was, “MOOCs are going to put universities out of business,” \nthen 12 months later it was “universities are still here, so obviously MOOCs have \nfailed.” Both of those comments are ridiculous extremes of the hype cycle.\nI think that we actually have done a lot for people who don’t normally have access \nto that level of education. About 25% of Coursera learners don’t have degrees, \nand about 40% of Coursera learners are in developing economies. If you look at \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 571
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n392\nthe percentage of learners who say that their lives were significantly transformed \nby access to this experience, it is disproportionately those people with low \nsocioeconomic status or from developing economies who report that level of benefit. \nThe benefit is there, but you’re right that the large majority are the ones who have \naccess to the internet and are aware that this possibility exists. I hope that over \ntime, there is the ability to increase awareness and internet access so that larger \nnumbers of people can get the benefit of these courses. \nMARTIN FORD: There is a saying that we tend to overestimate what happens in the \nshort term and underestimate in the long term. This sounds like a classic case of that.\nDAPHNE KOLLER: I think that’s exactly right. People thought we were going to \ntransform higher education in two years. Universities have been around for 500 \nyears, and evolve slowly. I do think, however, that even in the five years that we’ve \nbeen around there has been a fair amount of movement. \nFor instance, a lot of universities now have very robust online offerings, often at a \nconsiderably lower cost than on-campus courses. When we started, the very notion \nthat a top university would have an online program of any kind was unheard of. \nNow, digital learning is embedded into the fabric of many top universities.\nMARTIN FORD: I don’t think Stanford is going to be disrupted over the next 10 \nyears or so, but an education at the 3,000 or so less selective (and less well-\nknown) colleges in the US is still very expensive. If an inexpensive and effective \nlearning platform arose that gave you access to Stanford professors, then you \nbegin to wonder why someone would enroll much less prestigious college when \nthey could go to Stanford online. \nDAPHNE KOLLER: I agree. I think that transformation is going to come first in \nthe graduate education space, specifically professional master’s degrees. There’s \nstill an important social component to the undergraduate experience: that’s where \nyou go to make new friends, move away from home, and possibly meet your \nlife partner. For graduate education, however, it’s usually employed adults with \ncommitments: a job, a spouse, and a family. For most of them, to move and do a \nfull-time college experience is actually a negative, and so that’s where we’ll see \nthe transformation happen first. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 572
  },
  {
    "chunk_full": "DAPHNE KOLLER\n393\nDown the line, I think we might see people at those smaller colleges begin to \nwonder whether that’s the best use of their time and money, especially those that \nare part-time students because they need to work for a living while they do their \nundergraduate degrees. I think that’s where we’re going to see an interesting \ntransformation in a decade or so. \nMARTIN FORD: How might the technology evolve? If you have huge numbers of \npeople taking these courses, then that generates lots and lots of data. I assume \nthat data is something that can be leveraged by machine learning and artificial \nintelligence. How do you see those technologies integrated into these courses in the \nfuture? Are they going to become more dynamic, more personalized, and so forth? \nDAPHNE KOLLER: I think that’s exactly right. When we started Coursera, the \ntechnology was limited in innovating on new pedagogy; it was mostly just taking \nwhat was already present in standard teaching and modularizing it. We made \ncourses more interactive with exercises embedded in the course material, but it \nwasn’t a distinctly different experience. As more data is gathered and learning \nbecomes more sophisticated, you will certainly see more personalization. I believe \nthat you will see something that looks more like a personalized tutor who keeps \nyou motivated and helps you over the hard bits. All of these things are not that \ndifficult to do with the amount of data that we have available now. That wasn’t \navailable when we started Coursera, where we didn’t have the data and we just \nneeded to get the platform off the ground. \nMARTIN FORD: There’s enormous hype focused on deep learning at the moment \nand people could easily get the impression that all of artificial intelligence is nothing \nbut deep learning. However, there have recently been suggestions that progress in \ndeep learning may soon “hit a wall” and that it will need to be replaced with another \napproach. How do you feel about that?\nDAPHNE KOLLER: It’s not about one silver bullet, but I don’t think it needs to be \nthrown out. Deep learning was a very significant step forward, but is it the thing \nthat’s going to get us to full, human-level AI? I think there’s at least one, probably \nmore, big leaps that will need to occur before we get to human-level intelligence. \nPartly, it has to do with end-to-end training, where you optimize the entire network \nfor one particular task. It becomes really good at that task, but if you change the \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 573
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n394\ntask, you have to train the network differently. In many cases, the entire architecture \nhas to be different. Right now, we’re focused on really deep and narrow vertical \ntasks. Those are exceedingly difficult tasks and we’re making significant progress \nwith them, but each vertical task doesn’t translate to the one next to it. The thing \nthat makes humans really special is that they’re able to perform many of these tasks \nusing the same “software,” if you will. I don’t think we’re quite there with AI. \nThe other place where we’re not quite there in terms of general intelligence is that \nthe amount of data that’s required to train one of these models is very, very large. \nA couple of hundred samples are not usually enough. Humans are really good at \nlearning from very small amounts of data. I think it’s because there’s one architecture \nin our brain that serves all of the tasks that we have to deal with and we’re really \ngood at transferring general skills from one path to the other. For example, it \nprobably takes five minutes to explain how to use a dishwasher to someone who’s \nnever used one before. For a robot, it’s not going to be anywhere close to that. \nThat’s because humans have these generally transferable skills and ways of learning \nthat we haven’t been able to give to our artificial agents yet. \nMARTIN FORD: What other hurdles are there in the path to AGI? You’ve talked about \nlearning in different domains and being able to cross domains, but what about things \nlike imagination, and being able to conceive new ideas? How do we get to that? \nDAPHNE KOLLER: I think those things that I mentioned earlier are really central: \nbeing able to transfer skills from one domain to the other, being able to leverage that \nto learn from a very limited amount of training data, and so on. There’s been some \ninteresting progress on the path to imagination, but I think we’re fairly far away.\nFor instance, consider GANs (Generative Adversarial Networks). They are great at \ncreating new images that are different from the images that they’ve seen before, but \nthese images are amalgams, if you will, of images that they were trained on. You \ndon’t have the computer inventing Impressionism, and that’s something that would \nbe quite different than anything that we’ve done before. \nAn even more subtle question is that of relating emotionally to other beings. I’m not \nsure that’s even well defined, because as a human you can fake it. There are people \nwho fake an emotional connection to others. So, the question is, if you can get a \ncomputer to fake it well enough, how do you know that’s not real? That brings to \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 574
  },
  {
    "chunk_full": "DAPHNE KOLLER\n395\nmind the Turing test regarding consciousness, to which the answer is that we can \nnever know for sure if another being is really conscious, or what that even means; if \nthe behavior aligns with what we consider to be “conscious,” we just take it on faith. \nMARTIN FORD: That’s a good question. In order to have true artificial general \nintelligence, does that imply consciousness or could you have a superintelligent \nzombie? Could you have a machine that’s incredibly intelligent, but with nothing \nthere in terms of an inner experience? \nDAPHNE KOLLER: If you go back to Turing’s hypothesis, which is what gave rise \nto the Turing test, he says that consciousness is unknowable. I don’t know for \na fact that you are conscious, I just take that on faith because you look like me \nand I feel like I’m conscious and because there’s that surface similarity, I believe \nthat you’re conscious too.\nHis argument was that when we get to a certain level of performance in terms of \nbehavior we will not be able to know whether an intelligent entity is conscious or not. \nIf it’s not a falsifiable hypothesis then it’s not science, and you just have to take it on \nfaith. There is an argument that says that we will never know because it is unknowable. \nMARTIN FORD: I want to ask now about the future of artificial intelligence. What would \nyou point to as a demonstration of things that are currently at the forefront of AI? \nDAPHNE KOLLER: The whole deep learning framework has done an amazing job \nof addressing one of the key bottlenecks in machine learning, which is having to \nengineer a feature space that captures enough about the domain so that you can get \nvery high performance, especially in contexts where you don’t have a strong intuition \nfor the domain. Prior to deep learning, in order to apply machine learning you had \nto spend months or even years tweaking the representation of the underlying data \nin order to achieve higher performance. \nNow, with deep learning combined with the amount of data that we are able to \nbring to bear, you can really let the machine pick out those patterns for itself. \nThat is remarkably powerful. It’s important to recognize, though, that a lot of \nhuman insight is still required in constructing these models. It’s there in a different \nplace: in figuring out what the architecture of the model is that captures the \nfundamental aspects of a domain. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 575
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n396\nIf you look at the kind of networks, for instance, that one applies to machine \ntranslation, they’re very different to the architectures that you apply to computer \nvision, and a lot of human intuition went into designing those. It’s still, as of today, \nimportant to have a human in the loop designing these models, and I’m not convinced \nyet by the efforts to get a computer to design those networks as well as a human \ncan. You can certainly get a computer to tweak the architecture and modify certain \nparameters, but the overall architecture is still one that a human has designed. That \nbeing said, there are a couple of key advances that are changing this. The first is being \nable to train these models with very large amounts of data. The second is the end-to-\nend training that I mentioned earlier, where you define the task from beginning to end, \nand you train the entire architecture to optimize the goal that you actually care about.\nThis is transformative because the performance differential turns out to be quite \ndramatic. Both AlphaGo and AlphaZero are really good examples of that. The model \nthere was trained to win in a game, and I think end-to-end training, combined with \nunlimited training data (which is available in that context) is what’s driven a lot of \nthe huge performance gains in those applications. \nMARTIN FORD: Following these advances, how much longer will it be before we \nreach AGI, and how will we know when we’re close to it? \nDAPHNE KOLLER: There are a number of big leaps forward that need to happen \nin the technology to get us there, and those are stochastic events that you can’t \npredict. Someone could have a brilliant idea next month or it could take 150 years. \nPredicting when a stochastic event is going to happen is a fool’s errand. \nMARTIN FORD: But if these breakthroughs take place, then it could happen quickly?\nDAPHNE KOLLER: Even if the breakthrough happens, it’s going to require a lot \nof engineering and work to make AGI a reality. Think back to those advances of \ndeep learning and end-to-end training. The seeds of those were planted in the \n‘50s and the ideas kept coming back up every decade or so. We’ve made continual \nprogress over time, but there were years of engineering effort to get us to the \ncurrent point. And we’re still far from AGI. \nI think it’s unpredictable when the big step forward will come. We might not \neven recognize it when we see it at the first, second, or third time. For all we \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 576
  },
  {
    "chunk_full": "DAPHNE KOLLER\n397\nknow, it might already have been made, and we just don’t know it. There’s still \ngoing to be decades of work after that discovery to really engineer this until \nthe point that it works. \nMARTIN FORD: Let’s talk about some of the risks of AI, starting with economics. \nThere is an idea that we’re on the leading edge of something on the scale of a new \nindustrial revolution, but I think a lot of economists actually disagree with that. Do \nyou think that we are looking at a big disruption? \nDAPHNE KOLLER: Yes, I think that we are looking at a big disruption on the \neconomic side. The biggest risk/opportunity of this technology is that it will take \na lot of jobs that are currently being done by humans and have those be taken over \nto a lesser or greater extent by machines. There are social obstacles to adoption \nin many cases, but as robust increased performance is demonstrated, it will follow \nthe standard disruptive innovation cycle.\nIt is already happening to paralegals and cashiers at the supermarket, and it \nwill soon happen to the people who stack the shelves. I think that all of that \nis going to be taken over in five or ten years by robots or intelligent agents. \nThe question is to what extent can we carve out meaningful jobs around that \nfor humans to do. You can identify those opportunities in some cases, and in \nothers it’s less clear. \nMARTIN FORD: One of the disruptive technologies that people focus on is self-\ndriving cars and trucks. What’s your sense of when you’ll be able to call a driverless \nUber and it will take you to your destination. \nDAPHNE KOLLER: I think that it’ll be a gradual transition, where you might have \na fallback human remote driver. I think that is where a lot of these companies are \nheading as an intermediate step to full autonomy. \nYou’ll have a remote driver sitting in an office and controlling three or four \nvehicles at once. These vehicles would call for help when they get stuck in a \nsituation that they simply don’t recognize. With that safeguard in place, I would \nsay probably within five years we’ll have a self-driving service available in some \nplaces. Full autonomy is more of a social evolution than a technical evolution, \nand those are harder to predict. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 577
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n398\nMARTIN FORD: Agreed, but even so that’s a big disruption coming quite soon in \none industry with a lot of drivers losing their jobs. Do you think a universal basic \nincome is a possible solution to this job loss? \nDAPHNE KOLLER: It is just too early to make that decision. If you look back \nat some of the previous significant revolutions in history: The Agricultural \nRevolution, the Industrial Revolution, there were all the same predictions of \nmassive workforce disruption and huge numbers of people being out of jobs. \nThe world changed and those people found other jobs. It is too early to say \nthat this one is going to be completely different to the others, because every \ndisruption is surprising.\nBefore we focus on universal basic income, we need to be a lot more thoughtful \nand deliberate about education. The world in general, with a few exceptions, \nhas underinvested in educating people for this new reality, and I think it’s really \nimportant to consider the kind of skills that people will need in order to be \nsuccessful moving forwards. If after doing that we still have no idea of how to keep \nthe majority of the human population employed then that’s when we need to think \nabout a universal basic income. \nMARTIN FORD: Let’s move on to some of the other risks associated with artificial \nintelligence. There are two broad categories, the near-term risks, such as privacy \nissues, security, and the weaponization of drones and AI, and the long-term risks \nsuch as AGI and what that means. \nDAPHNE KOLLER: I’d say that all of those short-term risks already exist without \nartificial intelligence. For instance, there are already many complex, critical systems \ntoday that enemies could hack into. \nOur electricity grid is not artificially intelligent at this point, but it’s a significant \nsecurity risk for someone to hack into that. People can currently hack into your \npacemaker—again, it’s not an artificially intelligent system, but it’s an electronic \nsystem with the opportunity for hacking. As for weapons, is it impossible for \nsomeone to hack into the nuclear response system of one of the major superpowers \nand cause a nuclear attack to take place? So yes, there are security risks to AI \nsystems, but I don’t know that they’re qualitatively different to the same risks \nwith older technologies. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 578
  },
  {
    "chunk_full": "DAPHNE KOLLER\n399\nMARTIN FORD: As the technology expands, though, doesn’t that risk expand? Can \nyou imagine a future where self-driving trucks deliver all our food to stores, and \nsomeone then hacks into those and brings them to a halt?\nDAPHNE KOLLER: I agree, it’s just that it’s not a qualitative difference. It’s an \nincreasing risk that grows as we rely more on electronic solutions that, by virtue of \nbeing larger and more interconnected, have a greater risk for a single point of failure. \nWe started with individual drivers delivering goods to stores. If you wanted to disrupt \nthose, you’d have to disrupt every single driver. We then moved on to large shipping \ncompanies directing large numbers of trucks. Disrupt one of those and you disrupt a \nlarger proportion of deliveries. AI-controlled driverless trucks are the next step. As \nyou increase centralization you increase the risks of a single point of failure. \nI’m not saying those systems aren’t more of a risk, I’m just saying that to me AI doesn’t \nseem qualitatively different in that regard. It’s the same progression of increasing risk \nas we rely more and more on complex technologies with a single point of failure. \nMARTIN FORD: Going back to the military and the weaponization of AI and \nrobotics, there’s a lot of concern about advanced commercial technologies being \nused in nefarious ways. I’ve also interviewed Stuart Russell, who made a video, \nSlaughterbots, about that subject. Are you concerned that this technology could \nbe used in threatening ways?\nDAPHNE KOLLER: Yes, I think it is possible that this technology can get into the \nhands of anyone, but of course that is true for other dangerous technologies as \nwell. The ability to kill larger numbers of people using increasingly easier ways \nhas been another aspect of human evolution. In the early days, you needed a knife, \nand you could kill one person at a time. Then you had guns, and you could kill \nfive or six. Then you had assault rifles, and you could kill 40 or 50. Now you \nhave the ability to create dirty bombs in ways that don’t require a huge amount of \ntechnological know-how. If you think about biological weapons and the ability to \nedit and print genomes to the point where people can now create their own viruses, \nthat’s another way of killing a lot of people with an accessible modern technology.\nSo yes, the risks of misusing technology are there, but we need to think about them \nmore broadly than just AI. I wouldn’t say that stories of intelligent killer drones \nare more dangerous than someone synthesizing a version of smallpox and letting it \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 579
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n400\nloose. I don’t think we currently have a solution for either of those scenarios, but \nthe latter actually seems much more likely to kill a lot of people quickly. \nMARTIN FORD: Let’s move on to those long-term risks, and in particular AGI. \nThere’s the notion of a control problem where a superintelligence might set its \nown goals or implement the goals we set it in ways that we don’t expect or that \nare harmful. How do you feel about that concern? \nDAPHNE KOLLER: I think it is premature. In my opinion, there are several \nbreakthroughs that need to happen before we are at that point, and too many \nunknowns before we can come to a conclusion. What nature of intelligence might \nbe formed? Will it have an emotional component? What will determine its goals? \nWill it even want to interact with us humans, or will it just go off on its own? \nThere are just so many unknowns that it seems premature to start planning for \nit. I don’t think it is on the horizon, and even once we get to that breakthrough \npoint there’s going to be years or decades of engineering work that needs to be \ndone. This is not going to be an emergent phenomenon that we just wake up to \none day. This is going to be an engineered system, and once we figure out what \nthe key components are, that would be a good time to start thinking about how \nwe modulate and structure them so as to get the best outcomes. Right now, it’s \njust very ephemeral. \nMARTIN FORD: There are already a number of think-tank organizations springing \nup, such as OpenAI. Do you think those are premature in terms of the resources \nbeing invested, or do you think it’s a productive thing to start working on?\nDAPHNE KOLLER: OpenAI does multiple things. A lot of what it does is to create \nopen source AI tools to democratize access to a truly valuable technology. In \nthat respect, I think it’s a great thing. There’s a lot of work being done at those \norganizations thinking about the other important risks of AI. For instance, at a recent \nmachine learning conference (NIPS 2017) there was a very interesting talk about \nhow machine learning takes implicit biases in our training data and amplifies them \nto the point that it becomes really horrifying in capturing the worst behaviors (e.g., \nracism or sexism). Those are things that are important for us to be thinking about \ntoday, because those are real risks and we need to come up with real solutions to \nameliorate them. That’s part of what these think tanks are doing. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 580
  },
  {
    "chunk_full": "DAPHNE KOLLER\n401\nThat’s very different from your question of how we build safeguards into an as-yet-\nnon-existent technology that will prevent it from consciously trying to exterminate \nhumans for reasons that are unclear at this point. Why would they even care about \nexterminating humans? It just seems too early to start worrying about that. \nMARTIN FORD: Do you think there’s a need for government regulation of AI? \nDAPHNE KOLLER: Let’s just say that I think the level of understanding that \nthe government has of this technology is limited at best, and it’s a bad idea for \ngovernments to regulate something that they don’t understand. \nAI is also a technology that is easy to use and already available to other \ngovernments that have access to a lot of resources and are not necessarily bound \nby the same ethical scruples as our government might be. I don’t think regulating \nthis technology is the right solution. \nMARTIN FORD: There’s a lot of focus in particular on China. In some ways, they \nhave an advantage: they’ve got enormous amounts of data because their population \nis so large, and they don’t have to worry so much about privacy. Are we at risk of \nfalling behind there, and should we be worried? \nDAPHNE KOLLER: I think the answer to that is yes, and I think it’s important. If you’re \nlooking for a place for government intervention that would be beneficial, I would \nsay it’s in enabling technological advancements that could maintain competitiveness \nnot only with China but also with other governments. That includes an investment in \nscience. It includes an investment in education. It includes the ability to get access to \ndata in a way that is privacy-respecting and enables progress to be made. \nIn the healthcare space that I’m interested in, there are things that one can do \nthat would hugely ease the ability to make progress. For instance, if you talk to \npatients you’ll find that most of them are happy to have their data used for research \npurposes to drive progress toward cures. They realize that even if it doesn’t help \nthem it can help others down the line, and they really want to do that. However, \nthe legal and technological hoops that one needs to jump through before medical \ndata is shared are so onerous right now that it just doesn’t happen. That really \nslows down our progress towards the ability to aggregate data for multiple patients \nand to figure out likely cures for certain subpopulations, and so on. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 581
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n402\nThis is a place where government-level policy change, as well as a change in \nsocietal norms, can make a difference. As an example of what I mean, look at the \ndifference in organ donation rates between countries where there is an opt-in for \norgan donation versus countries where there’s an opt-out. Both give equal amounts \nof control over whether a person’s organs are going to be donated should they die, \nbut the countries that have opt-out have a much higher organ donation rate than the \ncountries that have opt-in. You create the expectation that people naturally opt in for \nsomething although you give them every opportunity to opt out. A similar system \nfor data sharing would make it much more available and would make publishing \nnew research much faster. \nMARTIN FORD: Do you believe that the benefits of AI, machine learning, and all \nthese technologies are going to outweigh these risks?\nDAPHNE KOLLER: Yes, I do. I also think that stopping progress by stopping \ntechnology is the wrong approach. If you want to ameliorate risks, you need to \nbe thoughtful about how to change societal norms and how to put in appropriate \nsafeguards. Stopping technology is just not a feasible approach. If you don’t make \nprogress technologically, someone else will, and their intent might be considerably \nless beneficial than yours. We need to let technology progress and then think about \nthe mechanisms to channel it towards good rather than bad. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 582
  },
  {
    "chunk_full": "DAPHNE KOLLER\n403\nDAPHNE KOLLER was the Rajeev Motwani Professor of Computer Science at Stanford \nUniversity. Daphne has made significant contributions to AI, especially in the field of Bayesian \n(probabilistic) machine learning and knowledge representation. In 2004, she was the recipient \nof a MacArthur Foundation fellowship for her work in this area.\nIn 2012, Daphne, along with her Stanford colleague, Andrew Ng, founded the online education \ncompany Coursera. Daphne served as co-CEO and president of the company. Her current \nresearch focuses especially on the use of machine learning and data science in healthcare, \nand she had a role as Chief Computing Officer at Calico, a Google/Alphabet company that \nis reportedly working on increasing human longevity. Daphne is currently CEO and founder \nof insitro, a startup biotech company focused on using machine learning for drug discovery.\nDaphne received her undergraduate and masters degrees at Hebrew University of Jerusalem \nin Israel and her PhD in computer science at Stanford in 1993. She has received numerous \nawards for her research and is a fellow of the Association for the Advancement of Artificial \nIntelligence. She was inaugurated into the National Academy of Engineering in 2011. In \n2013, Daphne was named one of the world’s 100 most influential people by Time magazine.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 583
  },
  {
    "chunk_full": "",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 584
  },
  {
    "chunk_full": "DAVID FERRUCCI\n405\nDAVID FERRUCCI\nFOUNDER, ELEMENTAL COGNITION  \nDIRECTOR OF APPLIED AI, BRIDGEWATER ASSOCIATES\nDavid Ferrucci built and led the IBM Watson team from its inception to its \nlandmark success in 2011 when Watson defeated the greatest Jeopardy! players \nof all time. In 2015 he founded his own company, Elemental Cognition, focused \non creating novel AI systems that dramatically accelerate a computer’s ability \nto understand language. \nI don’t think, as other people might, that we don’t  \nknow how to do [AGI] and we’re waiting for some  \nenormous breakthrough. I don’t think that’s the  \ncase, I think we do know how to do it, we just  \nneed to prove that.\n“ \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 585
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n406\nMARTIN FORD: How did you become interested in computers? What’s the path \nthat led you to AI? \nDAVID FERRUCCI: I started back before computers were an everyday term. My \nparents wanted me to become a medical doctor, and my dad hated the fact that I \nwould be home during the school holidays without anything to do. In the summer \nof my junior year at high school, my dad looked in the paper and found a math \nclass for me at a local college. It turned out that it was actually a programming \nclass using BASIC on DEC computers. I thought it was phenomenal because you \ncould give this machine instructions, and if you could articulate the procedure or \nthe algorithm that you’re going through in your head you could get the machine \nto do it for you. The machine could store the data AND the thought process. I \nimagined this was my way out! If I could get the machine to think and memorize \neverything for me, then I wouldn’t have to do all of that work to become a doctor.\nIt got me interested in what it meant to store information, to reason over it, to \nthink, and to systematize or to turn into an algorithm whatever process was going \non in my brain. If I could just specify that in enough detail, then I could get the \ncomputer to do it, and that was enthralling. It was just a mind-altering realization.\nI didn’t know the words “artificial intelligence” at the time, but I got very interested \nin the whole notion of coordinated intelligence from a mathematical, algorithmic, \nand philosophical perspective. I believed that modeling human intelligence in the \nmachine was possible. There was no reason to think that it wasn’t.\nMARTIN FORD: Did you follow that with computer science at college?\nDAVID FERRUCCI: No, I had no idea about careers in computer science or AI, \nso I went to college and majored in biology to become a medical doctor. During \nmy studies, I got my grandparents to buy me an Apple II computer, and I just \nstarted programming everything I could think of. I ended up programming a lot \nof software for my college, from graphing software for experimental lab work, to \necology simulation software, to analog-to-digital interfacing for lab equipment. This, \nof course, was before any of this stuff even existed, never mind being able to just \ndownload it form the internet. I decided to do as much computer science as I could \nin my last year of college, so I did a minor in it. I graduated with the top biology \naward and I was ready to go to medical school, when I decided it just wasn’t for me. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 586
  },
  {
    "chunk_full": "DAVID FERRUCCI\n407\nInstead, I went to graduate school for computer science, and AI in particular. I \ndecided that was what I was passionate about, and that’s what I wanted to study. \nSo, I did my master’s at Rensselaer Polytechnic Institute (RPI) in New York, where \nI developed a semantic network system as part of my thesis. I called it COSMOS, \nwhich I am sure stood for something related to cognition and sounded cool, but \nI can’t remember the precise expansion. COSMOS represented knowledge and \nlanguage, and could perform limited forms of logical reasoning. \nI was giving a presentation of COSMOS at a sort of industrial science fair at RPI \nin 1985 when some folks from the IBM Watson Research Center, who had just \nstarted their own AI project, saw me presenting and they asked me if I wanted a \njob. My original plan had been to stay on and get my PhD, but a few years before \nthis I’d seen an ad in a magazine to become an IBM Research Fellow where you \ncould research whatever you want with unlimited resources—that sounded like my \ndream job, so I’d cut that ad out and pinned it on my bulletin board. When these \npeople from IBM’s Research Center offered me that job, I took it.\nSo, in 1985 I started working on an AI project at IBM Research, but then a couple of \nyears later, the 1980s’ AI winter had hit, and IBM was going around canceling every \nproject that was associated with AI. I was told that they would be able to put me to \nwork on other projects, but I didn’t want to work on other projects, I wanted to \nwork on AI, so I decided to quit IBM. My dad was mad at me. He was already pissed \nI didn’t become a doctor, then by some miracle I had gotten a good job anyway and \nnow I was quitting two years later. That just did not sound like a good thing to him.\nI went back to RPI and did my PhD on non-monotonic reasoning. I designed and \nbuilt a medical expert system called CARE (Cardiac and Respiratory Expert) and \njust learned a lot more about AI during that period. To support my studies, I also \nworked on a government contract building an object-oriented circuit design system \nat RPI. After completing my PhD, I needed to look for work. My dad had gotten \npretty sick and he lived down in Westchester, where IBM was also based. I wanted \nto be near him, so I called some people I knew from my earlier IBM days and \nended up going back to IBM Research. \nIBM was not an AI company at that point, but 15 years later, with Watson and other \nprojects, I had helped to shape it in that direction. I never gave up my desire to work \non AI, and I built a skilled team over the years and engaged in every opportunity to \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 587
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n408\nwork in areas like language processing, text and multimedia analytics, and automatic \nquestion answering. By the time there was this interest in doing Jeopardy!, I was the \nonly one in IBM who believed it could be done and had a team capable of doing it. \nWith Watson’s huge success, IBM was able to transform itself into an AI company. \nMARTIN FORD: I don’t want to focus much on your work with Watson, as that’s \nalready a very well-documented story. I’d like to talk about how you were thinking \nabout AI, after you left IBM.\nDAVID FERRUCCI: The way I think about AI is that there’s perception—recognizing \nthings, there’s control—doing things, and there’s knowing—building, developing, and \nunderstanding the conceptual models that provide the foundation of communication, \nand the development of theories and ideas. \nOne of the interesting things I learned working on the Watson project was that \npure statistical approaches were limited in the “understanding” part, that’s their \nability to produce casual and consumable explanations for their predictions or \ntheir answers. Purely data-driven or statistical approaches to prediction are very \npowerful for perception tasks, such as pattern recognition, voice recognition, and \nimage recognition, and control tasks, such as driverless cars and robotics, but in \nthe knowledge space AI is struggling. \nWe’ve seen huge advances in voice and image recognition and in general, \nperception-related stuff. We’ve also seen huge advances in the control systems that \nyou see driving drones and all kinds of robotic driverless cars. When it comes to \nfluently communicating with a computer based on what it has read and understood, \nwe’re not even close to there yet. \nMARTIN FORD: More recently in 2015 you started a company called Elemental \nCognition. Could you tell us more about that?\nDAVID FERRUCCI: Elemental Cognition is an AI research venture that’s trying to do \nreal language understanding. It’s trying to deal with that area of AI that we still have not \ncracked, which is, can we create an AI that reads, dialogs, and builds understanding? \nA human being might read books and develop rich models of how the world works \nin their head, and then reason about it and fluently dialog about it and ask questions \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 588
  },
  {
    "chunk_full": "DAVID FERRUCCI\n409\nabout it. We refine and compound our understanding through reading and dialoging. \nAt Elemental Cognition, we want our AI to do that.\nWe want to look beyond the surface structure of language, beyond the patterns \nthat appear in word frequencies, and get at the underlying meaning. From that, \nwe want to be able to build the internal logical models that humans would create \nand use to reason and communicate. We want to ensure a system that produces \na compatible intelligence. That compatible intelligence can autonomously learn \nand refine its understanding through human interaction, language, dialog, and \nother related experiences. \nThinking about what knowing and understanding means is a really interesting part \nof AI. It’s not as easy as providing labeled data for doing image analysis, because \nwhat happens is that you and I could read the same thing, but we can come up with \nvery different interpretations. We could argue about what it means to understand \nthat thing. Today’s systems do more text matching and looking at the statistical \noccurrences of words and phrases, as opposed to developing a layered and logical \nrepresentation of the complex logic that is really behind the language. \nMARTIN FORD: Let’s pause to make sure people grasp the magnitude of \nthis. There are lots of deep learning systems today that can do great pattern \nrecognition and could, for example, find a cat in a picture and tell you there’s \na cat in the image. But there is no system in existence that really understands \nwhat a cat is, in the way that a person does.\nDAVID FERRUCCI: Well yes, but you and I could also argue about what a cat is. \nThat’s the interesting part because it asks what does it mean to actually understand. \nThink about how much human energy goes into helping each other to develop \nshared understandings of things. It’s essentially the job of anyone compiling or \ncommunicating information, any journalist, artist, manager, or politician. The job \nis to get other people to understand things the way they understand them. That’s \nhow we as a society can collaborate and advance rapidly. \nThat’s a difficult problem because in the sciences we’ve developed formal \nlanguages that are completely unambiguous for the purposes of producing value. \nSo, engineers use specification languages, while mathematicians and physicists use \nmathematics to communicate. When we write programs, we have unambiguous \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 589
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n410\nformal programming languages. When we talk, though, using natural language, \nwhich is where we’re absolutely prolific and where our richest and most nuanced \nthings happen, there it’s very ambiguous and it’s extremely contextual. If I take \none sentence out of context, it can mean lots of different things. \nIt’s not just the context in which the sentence is uttered, it’s also what is in \nthat person’s mind. For you and I to confidently understand each other, it is \nnot enough for me just to say things. You have to ask me questions, and we \nhave to go back and forth and get in sync and align our understandings until \nwe are satisfied that we have a similar model in our heads. That is because \nthe language itself is not the information. The language is a vehicle through \nwhich we communicate the model in our heads. That model is independently \ndeveloped and refined, and then we align them to communicate. This notion \nof “producing” an understanding is a rich, layered, highly contextual thing that \nis subjective and collaborative.\nA great example was when my daughter was seven years old and doing some school \nwork. She was reading a page in a science book about electricity. The book says \nthat it’s energy that’s created in different ways, such as by water flowing over \nturbines. It ends by asking my daughter a simple question, “How is the electricity \nproduced?” She looks back at the text, and she’s doing text matching, saying well \nit says electricity is created and “created” is a synonym of “produced,” and then it \nhas this phrase, “by water flowing over turbines.” \nShe comes to me and says, “I can answer this question by copying this phrase, \nbut I have no understanding of what electricity is or how it is produced.” She \ndidn’t understand it at all, even though she could get the question right by doing \ntext matching. We then discussed it and she gained a richer understanding. That \nis more-or-less how most language AI works today—it doesn’t understand. The \ndifference is that my daughter knew she didn’t understand. That is interesting. She \nexpected much more from her underlying logical representation. I took that as a \nsign of intelligence, but I may be have been biased in this case. Ha!\nIt’s one thing to look at the words in a passage and take a guess at the answer. It’s \nanother thing to understand something enough to be able to communicate a rich \nmodel of your understanding to someone and then discuss, probe, and get in sync \nto advance your understanding as a result.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 590
  },
  {
    "chunk_full": "DAVID FERRUCCI\n411\nMARTIN FORD: You’re imagining a system that has a genuine understanding of \nconcepts and that can converse and explain its reasoning. Isn’t that human-level \nartificial intelligence or AGI?\nDAVID FERRUCCI: When you can produce a system that can autonomously learn, \nin other words, it can read, understand, and build models then converse, explain, \nand summarize the models to a person that it’s talking to, then you’re approaching \nmore of what I would call holistic intelligence. \nAs I said, I think there are three parts to a complete AI, perception, control, and \nknowing. A lot of the stuff that’s going on with deep learning is remarkable regarding \nthe progress that we’re making on the perception and the control pieces, the real \nissue is the final piece. How do we do the understanding and the collaborative \ncommunication with humans so that we can create a shared intelligence? That’s super \npowerful, because our main means for building, communicating, and compounding \nknowledge is through our language and building human-compatible models. That’s \nthe AI that I’m endeavoring to create with Elemental Cognition.\nMARTIN FORD: Solving the understanding problem is one of the holy grails of AI. \nOnce you have that, other things fall into place. For example, people talk about \ntransfer learning or the ability to take what you know and apply it in another \ndomain, and true understanding implies that. If you really understand something, \nyou should be able to apply it somewhere else. \nDAVID FERRUCCI: That’s exactly right. One of the things that we’re doing at \nElemental Cognition is testing how a system understands and compounds the \nknowledge that it reads in even the simplest stories. If it reads a story about \nsoccer, can it then apply that understanding to what’s going on in a lacrosse game \nor a basketball game? How does it reuse its concepts? Can it produce analogous \nunderstandings and explanations for things, having learned one thing and then \ndoing that reasoning by analogy and explaining it in a similar way? \nWhat’s tricky is that humans do both kinds of reasoning. They do what we might \nthink of as statistical machine learning, where they process a lot of data points \nand then generalize the pattern and apply it. They produce something akin to a \ntrendline in their head and intuit new answers by applying the trend. They might \nlook at some pattern of values and when asked what is next, intuitively say the \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 591
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n412\nanswer is 5. When people are doing that, they’re doing more pattern matching \nand extrapolation. Of course, the generalization might be more complicated than \na simple trend line, as it certainly can be with deep learning techniques.\nBut, when people sit down and say, “Let me explain to you why this makes sense to \nme—the answer is 5 because...,” now they have more of a logical or causal model that \nthey’ve built up in their head, and that becomes a very different kind of information \nthat is ultimately much more powerful. It’s much more powerful for communication, \nit’s much more powerful for an explanation, and it’s much more powerful for extension \nbecause now I could critique it and say, “Wait, I see where your reasoning is faulty,” \nas opposed to saying “It’s just my intuition based on past data. Trust me.” \nIf all I have is inexplicable intuition, then how do I develop, how do I improve, \nand how do I extend my understanding of the world around me? That’s the \ninteresting dilemma I think we face when we contrast these two kinds of \nintelligences. One that is focused on building a model that is explicable, that \nyou can inspect, debate, explain, and improve on, and one that says, “I count \non it because it’s right more often than it’s wrong.” Both are useful, but they’re \nvery different. Can you imagine a world where we give up agency to machines \nthat cannot explain their reasoning? That sounds bad to me. Would you like to \ngive agency up to humans that cannot explain their reasoning?\nMARTIN FORD: Many people believe that deep learning, that second model that \nyou describe, is enough to take us forward. It sounds like you think we also \nneed other approaches.\nDAVID FERRUCCI: I’m not a fanatic one way or the other. Deep learning and neural \nnetworks are powerful because they can find nonlinear, very complex functions in \nlarge volumes of data. By function, I mean if I want to predict your weight given \nyour height, that could be a very simple function represented by a line. Predicting the \nweather is less likely to be represented by a simple linear relationship. The behavior \nof more complex systems is more likely represented by very complex functions over \nmany variables (think curvy and even discontinuous and in many dimensions). \nYou can give a deep learning system huge amounts of raw data and have it find a \ncomplex function, but in the end, you’re still just learning a function. You might \nfurther argue that every form of intelligence is essentially learning a function. But \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 592
  },
  {
    "chunk_full": "DAVID FERRUCCI\n413\nunless you endeavor to learn the function that outputs human intelligence itself \n(what would be the data for that?), then your system may very well produce answers \nwhose reasons are inexplicable.\nImagine I have a machine called a neural network where if I load in enough data, \nit could find an arbitrarily complex function to map the input to the output. You \nwould think, “Wow! Is there any problem it can’t solve?” Maybe not, but now the \nissue becomes, do you have enough data to completely represent the phenomenon \nover all time? When we talk about knowing or understanding, we have first to \nsay, what’s the phenomenon? \nIf we’re talking about identifying a cat in a picture, it’s very clear what the \nphenomenon is, and we would get a bunch of labeled data, and we would train the \nneural network. If you say: “How do I produce an understanding of this content?”, \nit’s not even clear I can get humans to agree on what an understanding is. Novels \nand stories are complex, multilayered things, and even when there is enough \nagreement on the understanding, it’s not written down enough for a system to \nlearn the immensely complex function represented by the underlying phenomenon, \nwhich is human intelligence itself.\nTheoretically, if you had the data you needed that mapped every kind of English \nstory to its meaning, and there was enough there to learn the meaning mapping—to \nlearn what the brain does given an arbitrary collection of sentences or stories—then \ncould a neural network learn it? Maybe, but we don’t have that data, we don’t know \nhow much data is required, and we don’t know what it takes to learn it in terms \nof the complexity of the function a neural network could potentially learn. Humans \ncan do it, but that’s because the human brain is constantly interacting with other \nhumans and it’s prewired for doing this kind of thing. \nI would never take a theoretical position that says, “I have a general function finder. \nI can do anything with it.” At some levels, sure, but where’s the data to produce \nthe function that represents human understanding? I don’t know. \nThe methodology for engaging and acquiring that information is something I don’t \nknow how to do with a neural network right now. I do have ideas on how to do \nthat, and that doesn’t mean I don’t use neural networks and other machine learning \ntechniques as part of that overarching architecture.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 593
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n414\nMARTIN FORD: You had a part in a documentary called Do You Trust This Computer? and \nyou said “In three to five years, we’ll have a computer system that can autonomously \nlearn to understand and how to build understanding, not unlike the way a human \nmind works.” That really struck me. That sounds like AGI, and yet you’re giving it \na three- to five-year time frame. Is that really what you’re saying?\nDAVID FERRUCCI: It’s a very aggressive timeline, and I’m probably wrong about \nthat, but I would still argue that it’s something that we could see within the next \ndecade or so. It’s not going to be a 50- or a 100-year wait. \nI think that we will see two paths. We will see the perception side and the \ncontrol side continue to get better in leaps and bounds. That is going to have \na dramatic impact on society, on the labor market, on national security, and \non productivity, which is all going to be very significant, and that’s not even \naddressing the understanding side. \nI think that will lead to a greater opportunity for AI to engage humans, with \nthings like Siri and Alexa engaging humans more and more in language and \nthinking tasks. It’s through those ideas, and with architectures like we’re building \nat Elemental Cognition, that we will start to be able to learn how to develop \nthat understanding side. \nMy three- to five-year estimate was a way of saying, this is not something that we \nhave no idea how to do. This is something we do have an idea how to do, and it’s \na matter of investing in the right approach and putting in the engineering necessary \nto achieve it. I would make a different estimate if it was something I thought was \npossible, but that I had no idea how to get there. \nHowever long the wait is depends a lot on where the investment goes. A lot \nof the investment today is going into the pure statistical machine learning stuff \nbecause it’s so short-term and so hot. There are just a lot of low-hanging fruit \nreturns. One of the things I’m doing is getting investment for another technology \nthat I think we need in order to develop that understanding side. It all depends \non how the investment gets applied and over what time frame. I don’t think, as \nother people might, that we don’t know how to do it and we’re waiting for some \nenormous breakthrough. I don’t think that’s the case, I think we do know how \nto do it, we just need to prove that.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 594
  },
  {
    "chunk_full": "DAVID FERRUCCI\n415\nMARTIN FORD: Would you describe Elemental Cognition as an AGI company?\nDAVID FERRUCCI: It’s fair to say we’re focused on building a natural intelligence \nwith the ability to autonomously learn, read, and understand, and we’re achieving \nour goals for fluently dialoging with humans in that way.\nMARTIN FORD: The only other company I’m aware of that is also focused on that \nproblem is DeepMind, but I’m struck by how different your approach is. DeepMind \nis focused on deep reinforcement learning through games and simulated environments, \nwhereas what I hear from you is that the path to intelligence is through language.\nDAVID FERRUCCI: Let’s restate the goal a little bit. Our goal is to produce an \nintelligence that is anchored in logic, language and reason because we want to \nproduce a compatible human intelligence. In other words, we want to produce \nsomething that can process language the way humans process language, can learn \nthrough language, and can deliver knowledge fluently through language and reason. \nThis is very specifically the goal. \nWe do use a variety of machine learning techniques. We use neural networks to do \na variety of different things. The neural networks, however, do not alone solve the \nunderstanding problem. In other words, it’s not an end-to-end solution. We also use \ncontinuous dialog, formal reasoning, and formal logic representations. For things \nthat we can learn efficiently with neural networks, we do. For the things we can’t, \nwe find other ways to acquire and model that information.\nMARTIN FORD: Are you also working on unsupervised learning? Most AI that we \nhave today is trained with labeled data, and I think real progress will probably \nrequire getting these systems to learn the way that a person does, organically \nfrom the environment. \nDAVID FERRUCCI: We do both. We do corpus and large corpus analysis, which \nis unsupervised. We do unsupervised learning from large corpora, but we also do \nsupervised learning from annotated content as well.\nMARTIN FORD: Let’s talk about the future implications of AI. Do you think there \nis the potential for a big economic disruption in the near future, where a lot of \njobs are going to be deskilled or to disappear? \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 595
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n416\nDAVID FERRUCCI: I think it’s definitely something that we need to pay attention \nto. I don’t know if it’ll be more dramatic than in previous examples of when a \nnew technology has rolled in, like in the Industrial Revolution, but I think this AI \nrevolution will be significant and comparable to the industrial revolution. \nI think there will be displacements and there will be the need to transition the \nworkforce, but I don’t think it’s going to be catastrophic. There’s going to be some \npain in that transition, but in the end, my guess is that it’s likely to create more \njobs. I think that’s also what has happened historically. Some people might get \ncaught in that and they have to retrain; that certainly happens, but it doesn’t mean \nthere’ll be fewer jobs overall.\nMARTIN FORD: Do you think there’s likely to be a skill mismatch problem? For \ninstance, if a lot of the new jobs created are for robotics engineers, deep learning \nexperts, and so forth?\nDAVID FERRUCCI: Certainly, those jobs will get created, and there’ll be a skills \nmismatch, but I think other jobs will be created as well where there’ll be greater \nopportunities just for refocusing and saying, “What do we want humans doing if \nmachines are doing these other things?” There are tremendous opportunities in \nhealthcare and caregiving, where things like human contact are important. \nThe future we envision at Elemental Cognition has human and machine \nintelligence tightly and fluently collaborating. We think of it as thought-\npartnership. Through thought-partnership with machines that can learn, reason, \nand communicate, humans can do more because they don’t need as much training \nand as much skill to get access to knowledge and to apply it effectively. In \nthat collaboration, we are also training the computer to be smarter and more \nunderstanding of the way we think. \nLook at all the data that people are giving away for free today, that data has value. \nEvery interaction you have with a computer has value because that computer’s \ngetting smarter. So, to what extent do we start paying for that, and paying for that \nmore regularly? We want computers to interact in ways that are more compatible \nwith humans, so why aren’t we paying humans to help us achieve that? I think the \neconomics of the human-machine collaboration is interesting in and of itself, but \nthere will be big transitions. Driverless cars are inevitable, and there are quite a \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 596
  },
  {
    "chunk_full": "DAVID FERRUCCI\n417\nfew people who have decent blue-collar jobs driving, and I think that’ll evolve. I \ndon’t know if that will be a trend, but that will certainly be a transition.\nMARTIN FORD: How do you feel about the risks of superintelligence that Elon \nMusk and Nick Bostrom have both been talking about?\nDAVID FERRUCCI: I think there’s a lot of cause to be concerned anytime you give a \nmachine leverage. That’s when you put it in control over something that can amplify \nan error or the effect of a bad actor. For instance, if I put machines in control \nof the electrical grid, over weapon systems, or over the driverless car network, \nthen any mistake there can be amplified into a significant disaster. If there’s a \ncybersecurity problem or an evil actor hacks the system, it’s going to amplify the \nimpact of the error or the hack. That’s what we should be super concerned about. \nAs we’re putting machines in control of more and more things like transportation \nsystems, food systems, and national security systems, we need to be super careful. \nThis doesn’t have anything specifically to do with AI, only that you must design \nthose systems with concern about error cases and cybersecurity. \nThe other thing that people like Nick Bostrom talk about is how the machine \nmight develop its own goals and decide it’s going to lay waste to the human race \nto achieve its goals. That’s something I’m less concerned about because there \nare fewer incentives for machines to react like that. You’d have to program the \ncomputer to do something like that. \nNick Bostrom talks about the idea that you could give the machine a benign goal \nbut because it’s smart enough it will find a complex plan that will have unintended \ncircumstances when it executes that plan. My response to that is simple, why would \nyou do that? I mean, you don’t give a machine that has to make paper clips leverage \nover the electrical grid, it comes back to thoughtful design and design for security. \nThere are many other human problems I would put higher on the list of concerns \nthan the notion that an AI would suddenly come up with its own desires and goals, \nand/or plan to sacrifice the human race to make more paper clips.\nMARTIN FORD: What do you think about the regulation of AI, is there a need for that? \nDAVID FERRUCCI: The idea of regulation is something we do have to pay \nattention to. As an industry, we have to decide broadly who’s liable for what \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 597
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n418\nwhen we have machines making decisions that affect our lives. That’s the case \nwhether it’s in health care, policymaking, or any of the other fields. Are we, as \nindividuals who are affected by decisions that are made by machines, entitled to \nan explanation that we can understand? \nIn some sense, we already face these kinds of things today. For example, in \nhealthcare we’re sometimes given explanations that say, “We think you should do \nthis and we highly recommend it because 90% of the time this is what happens.” \nThey’re giving you a statistical average rather than particulars about an individual \npatient. Should you be satisfied with that? Can you request an explanation as to \nwhy they’re recommending that treatment based on this individual patient? It’s \nnot about the probabilities, it’s about the possibilities for an individual case. It \nraises very interesting questions.\nThat is one area where governments will need to step in and say, “Where does \nthe liability fall and what are we owed as individuals who are potential subjects \nof machine decision-making?” \nThe other area, which we talked a little bit about, was, what are the criteria when \nyou design systems that have dramatic leverage, where negative effects like errors \nor hacking can be dramatically amplified and have broad human societal impact? You \ndon’t want to slow down the advancement of technology, but at the same time, you \ndon’t want to be too casual about the controls around deploying systems like that. \nAnother area for regulation that’s a little dicey is the labor market. Do you slow \nthings down and say, “you can’t put machines in this job because we want to protect \nthe labor market”? I think there’s something to be said for helping society transition \nsmoothly and avoiding dramatic impacts, but at the same time, you don’t want to \nslow down our advance as a society over time. \nMARTIN FORD: Since you departed IBM, they’ve built a big business unit around \nWatson and are trying to commercialize that with mixed results. What do you think \nof IBM’s experience and the challenges they’ve faced, and does that relate to your \nconcern about building machines that can explain themselves? \nDAVID FERRUCCI: I’m many miles away from what’s going on there nowadays, but \nmy sense of that from a business perspective, is that they seized Watson as a brand \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 598
  },
  {
    "chunk_full": "DAVID FERRUCCI\n419\nto help them get into the AI business, and I think it’s given them that opportunity. \nWhen I was at IBM, they were doing all kinds of AI technology, it was very spread \nout throughout the company in different areas. I think that when Watson won the \nJeopardy! competition and demonstrated to the public a really palpable AI capability, \nall that excitement and momentum helped IBM to organize and integrate all their \ntechnology under a single brand. That demonstration gave them the ability to position \nthemselves well, both internally and externally. \nWith regard to the businesses, I think IBM is in a unique place regarding the \nway they can capitalize on this kind of AI. It’s very different than the consumer \nspace. IBM can approach the market broadly through business intelligence, data \nanalytics, and optimization. And they can deliver targeted value, for example \nin healthcare applications. \nIt’s tough to measure how successful they’ve been because it depends on what you \ncount as AI and where you are in the business strategy. We will see how it plays \nout. As far as the consumer mindshare these days it seems to me like Siri and \nAmazon’s Alexa are in the limelight. Whether or not they’re providing good value \non the business side is a question I can’t answer.\nMARTIN FORD: There are concerns that China may have an advantage given that \nthey have a larger population, more data, and fewer concerns about privacy. Is \nthat something we should worry about? Do we need more industrial policy in the \nUnited States in order to be more competitive?\nDAVID FERRUCCI: I think that there is a bit of an arms race in the sense that these \nthings will affect productivity, the labor markets, national security, and consumer \nmarkets, so it matters a lot. To stay competitive as a nation you do have to invest \nin AI to give a broad portfolio. You don’t want to put all your eggs in one basket. \nYou have to attract and maintain talent to stay competitive, so I think there’s no \nquestion that national boundaries create a certain competition because of how much \nit affects competitive economics and security. \nThe challenging balancing act is how do you remain competitive there and at the \nsame time, think carefully about controls, regulation, and other kinds of impacts, \nsuch as privacy. Those are tough issues, and I think one of the things that the \nworld’s going to need is more thoughtful and knowledgeable leaders in this space \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 599
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n420\nwho can help set policy and make some of those calls. That’s a very important \nservice, and the more knowledgeable you are, the better, because if you look \nunder the hood, this is not simple stuff. There’s a lot of tough questions, a lot of \ntechnology issues to make choices on. Maybe you need AI for that!\nMARTIN FORD: Given these risks and concerns, are you optimistic with regard to \nthe future of artificial intelligence?\nDAVID FERRUCCI: Ultimately, I’m an optimist. I think it’s our destiny to pursue \nthis kind of thing. Step back to what interested me when I first started on my path \nin AI: Understanding human intelligence; understanding it in a mathematical and \nsystematic way; understanding what the limitations are, how to enhance it, how \nto grow it, and how to apply it. The computer provides us with a vehicle through \nwhich we can experiment with the very nature of intelligence. You can’t say no to \nthat. We associate our sense of self with our intelligence, and so how do we not \ndo everything we can to understand it better, to apply it more effectively, and to \nunderstand its strengths and its weaknesses? It’s more our destiny than anything \nelse. It’s the fundamental exploration—how do our minds work?\nIt’s funny because we think about how humanity wants to explore space and beyond \nto find other intelligences, when in fact, we have one growing right next to us. What \ndoes it even mean? What’s the very nature of intelligence? Even if we were to find \nanother species, we’ll know more about what to expect and what’s both possible \nand impossible as we explore the very fundamental nature of intelligence. It’s our \ndestiny to cope with this, and I think that ultimately, it will dramatically enhance our \ncreativity and our standard of living in ways we can’t even begin to imagine today. \nThere is this existential risk, and I think it’s going to impact a change in how we \nthink about ourselves, and what we consider unique about being human. Coming \nto grips with that is going to be a very interesting question. For any given task, \nwe can get a machine that does it better, so where does our self-esteem go? Where \ndoes our sense of self go? Does it fall back into empathy, emotion, understanding, \nand things that might be more spiritual in nature? I don’t know, but these are the \ninteresting questions as we begin to understand intelligence in a more objective \nway. You can’t escape it.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 600
  },
  {
    "chunk_full": "DAVID FERRUCCI\n421\nDAVID FERRUCCI is the award-winning AI researcher who built and led the IBM Watson \nteam from its inception in 2006 to its landmark success in 2011 when Watson defeated the \ngreatest Jeopardy! players of all time.\nIn 2013, David joined Bridgewater Associates as Director of Applied AI. His nearly 30 years \nin AI and his passion to see computers fluently think, learn, and communicate inspired him \nto found Elemental Cognition LLC in 2015 in partnership with Bridgewater. Elemental \nCognition is focused on creating novel AI systems that dramatically accelerate automated \nlanguage understanding and intelligent dialog.\nDavid graduated from Manhattan College, with a BS degree in biology and from Rensselaer \nPolytechnic Institute with a PhD degree in computer science specializing in knowledge \nrepresentation and reasoning. He has over 50 patents and has published papers in the areas \nof AI, automated reasoning, NLP, intelligent systems architectures, automatic story generation, \nand automatic question-answering.\nDavid was awarded the title of IBM Fellow (fewer than 100 of 450,000 hold this technical \ndistinction) and has won many awards for his work creating UIMA and Watson, including the \nChicago Mercantile Exchange’s Innovation Award and the AAAI Feigenbaum Prize.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 601
  },
  {
    "chunk_full": "",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 602
  },
  {
    "chunk_full": "RODNEY BROOKS\n423\nRODNEY BROOKS\nCHAIRMAN, RETHINK ROBOTICS \nRodney Brooks is widely recognized as one of the world’s foremost roboticists. \nRodney co-founded iRobot Corporation, an industry leader in both consumer \nrobotics (primarily the Roomba vacuum cleaner) and military robots, such as \nthose used to defuse bombs in the Iraq war (iRobot divested its military robotics \ndivision in 2016). In 2008, Rodney co-founded a new company, Rethink \nRobotics, focused on building flexible, collaborative manufacturing robots that \ncan safely work alongside human workers. \nWe don’t have anything anywhere near as good as an  \ninsect, so I’m not afraid of superintelligence showing  \nup anytime soon.\n“ \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 603
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n424\nMARTIN FORD: While at MIT, you started the iRobot company, which is now one \nof the world’s biggest distributors of commercial robots. How did that come about?\nRODNEY BROOKS: I started iRobot back in 1990 with Colin Angle and Helen \nGreiner. At iRobot we had a run of 14 failed business models and didn’t get a \nsuccessful one until 2002, at which point we hit on two business models that \nworked in the same year. The first one was robots for the military. They were \ndeployed in Afghanistan to go into caves to see what was in them. Then, during \nthe Afghanistan and Iraq conflicts, around 6,500 of them were used to deal \nwith roadside bombs. \nAt the same time in 2002, we launched the Roomba, which was a vacuum \ncleaning robot. In 2017, the company recorded full-year revenue of $884 million \nand has, since launch, shipped over 20 million units. I think it’s fair to say the \nRoomba is the most successful robot ever in terms of numbers shipped, and that \nwas really based on the insect-level intelligence that I had started developing at \nMIT around 1984. \nWhen I left MIT in 2010, I stepped down completely and started a company, \nRethink Robotics, where we build robots that are used in factories throughout the \nworld. We’ve shipped thousands of them to date. They’re different from conventional \nindustrial robots in that they’re safe to be with, they don’t have to be caged, and \nyou can show them what you want them to do. \nIn the latest version of the software we use, Intera 5, when you show the robots \nwhat you want them to do, they actually write a program. It’s a graphical program \nthat represents behavior trees, which you can then manipulate if you want, but you \ndon’t have to. Since its launch, more sophisticated companies wanted to be able to \nget in and tweak exactly what the robot was doing after it had been shown what \nto do, but you don’t have to know what the underlying representation is. These \nrobots use force feedback, they use vision, and they operate in real environments \nwith real people around them 24 hours a day, seven days a week, 365 days a year, \nall over the world. I think certainly they are the most advanced artificial intelligence \nrobots currently in mass deployment. \nMARTIN FORD: How did you come to be at the forefront of robotics and AI? Where \ndoes your story begin?\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 604
  },
  {
    "chunk_full": "RODNEY BROOKS\n425\nRODNEY BROOKS: I grew up in Adelaide, South Australia, and in 1962 my \nmother found two American How and Why Wonder Books. One was called Electricity \nand the other, Robots and Electronic Brains. I was hooked, and I spent the rest of \nmy childhood using what I’d learned from the books to explore and try to build \nintelligent computers, and ultimately robots. \nI did an undergraduate degree in mathematics and started a PhD in artificial \nintelligence in Australia but realized there was a little problem in that there were no \ncomputer science departments or artificial intelligence researchers in the country. \nI applied to the three places that I’d heard of that did artificial intelligence, MIT \n(Massachusetts Institute of Technology), Carnegie Mellon (Pittsburgh, USA), and \nStanford University. I got rejected by MIT but got accepted to Carnegie Mellon \nand Stanford, starting in 1977. I chose Stanford because it was closer to Australia.\nMy PhD at Stanford was on computer vision with Tom Binford. Following on from \nthat, I was at Carnegie Mellon for a postdoc, then onto another postdoc at MIT, \nfinally ending back at Stanford in 1983 as a member of the tenure-track faculty. In \n1984 I moved back to MIT as a member of the faculty, where I stayed for 26 years. \nWhile at MIT as a postdoc, I started working more on intelligent robots. By the \ntime I moved back to MIT in 1984 I realized just how little progress we’d made in \nmodeling robot perception. I got inspired by insects with a hundred thousand neurons \noutperforming any robot we had by fantastic amounts. I then started to try and model \nintelligence on insect intelligence, and that’s what I did for the first few years. \nI then ran the Artificial Intelligence Lab at MIT that Marvin Minsky had founded. \nOver time, that merged with the Laboratory of Computer Science and formed \nCSAIL, the Computer Science and Artificial Intelligence Lab, which is, today, \nstill the largest lab at MIT.\nMARTIN FORD: Looking back, what would you say is the highlight of your career \nwith either robots or AI? \nRODNEY BROOKS: The thing I’m proudest of was in March 2011 when the \nearthquake hit Japan and the tidal wave knocked out the Fukushima Nuclear Power \nPlant. About a week after it happened, we got word that the Japanese authorities \nwere really having problems in that they couldn’t get any robots into the plant \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 605
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n426\nto figure out what was going on. I was still on the board of iRobot at that time, \nand we shipped six robots in 48 hours to the Fukushima site and trained up the \npower company tech team. As a result, they acknowledged that the shutdown of \nthe reactors relied on our robots being able to do things for them that they on \ntheir own were unable to do. \nMARTIN FORD: I remember that story about Japan. It was a bit surprising because \nJapan is generally perceived as being on the very leading edge of robotics, and yet \nthey had to turn to you to get working robots. \nRODNEY BROOKS: I think there’s a real lesson there. The real lesson is that the \npress hyped up things about them being far more advanced than they really are. \nEveryone thought Japan had incredible robotic capabilities, and this was led by \nan automobile company or two, when really what they had was great videos and \nnothing about reality. \nOur robots had been in war zones for nine years being used in the thousands every \nday. They weren’t glamorous, and the AI capability would be dismissed as being \nalmost nothing, but that’s the reality of what’s real and what is applicable today. I \nspend a large part of my life telling people that they are being delusional when they \nsee videos and think that great things are around the corner, or that there will be \nmass unemployment tomorrow due to robots taking over all of our jobs. \nAt Rethink Robotics, I say, if there was no lab demo 30 years ago, then it’s too \nearly to think that we could make it into a practical product now. That’s how long \nit takes from a lab demo to a practical product. It’s certainly true of autonomous \ndriving; everyone’s really excited about autonomous driving now. People forget that \nthe first automobile that drove autonomously on a freeway at over 55 miles an hour \nfor 10 miles was in 1987 near Munich. The first time a car drove across the US, \nhands off the wheel, feet off the pedals coast to coast, was No Hands Across America \nin 1995. Are we going to see mass-produced self-driving cars tomorrow? No. It \ntakes a long, long, long time to develop something like this, and I think people \nare still overestimating how quickly this technology will be deployed. \nMARTIN FORD: It sounds to me like you don’t really buy into the Kurzweil Law \nof Accelerating Returns. The idea that everything is moving faster and faster. I get \nthe feeling that you think things are moving at the same pace? \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 606
  },
  {
    "chunk_full": "RODNEY BROOKS\n427\nRODNEY BROOKS: Deep learning has been fantastic, and people who are outside \nthe field of it come in and say, wow. We’re used to exponentials because we had \nexponentials in Moore’s Law, but Moore’s Law is slowing down because you can \nno longer halve the feature size. What it’s leading to though is a renaissance of \ncomputer architecture. For 50 years, you couldn’t afford to do anything out of \nthe ordinary because the other guys would overtake you, just because of Moore’s \nLaw. Now we’re starting to see a flourishing of computer architecture and I think \nit’s a golden era for computer architecture because of the end of Moore’s Law. \nThat gets back to Ray Kurzweil and people who saw those exponentials and think \nthat everything is exponential. \nCertain things are exponential, but not everything. If you read Gordon Moore’s 1965 \npaper, The Future of Integrated Electronics, where Moore’s Law originated from, the \nlast part was devoted to what the law doesn’t apply to. Moore said it doesn’t apply \nto power storage, for example, where it’s not about the information abstraction of \nzeroes and ones, it’s about bulk properties. \nTake green tech as an example. A decade ago, venture capitalists in Silicon Valley \ngot burned because they thought Moore’s Law was everywhere, and that it would \napply to green tech. No, that’s not how it works. Green tech relies on bulk, it relies \non energy, it’s not something that is halve-able physically and you still have the \nsame information content. \nGetting back to deep learning, people think because one thing happened and \nthen another thing happened, it’s just going to get better and better. For deep \nlearning, the fundamental algorithm of backpropagation was developed in the \n1980s, and those people eventually got it to work fantastically after 30 years of \nwork. It was largely written off in the 1980s and the 1990s for lack of progress, \nbut there were 100 other things that were also written off at the same time. No \none predicted which one out of those 100 things would pop. It happened to be \nthat backpropagation came together with a few extra things, such as clamping, \nmore layers, and a lot more computation, and provided something great. You could \nnever have predicted that backpropagation and not one of those 99 other things \nwere going to pop through. It was by no means inevitable.\nDeep learning has had great success, and it will have more success, but it won’t go \non forever providing more or greater success. It has limits. Ray Kurzweil is not going \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 607
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n428\nto be uploading his consciousness any time soon. It’s not how biological systems \nwork. Deep learning will do some things, but biological systems rely on hundreds of \nalgorithms, not just one algorithm. We will need hundreds more algorithms before \nwe can make that progress, and we cannot predict when they will pop. Whenever \nI see Kurzweil I remind him that he is going to die. \nMARTIN FORD: That’s mean. \nRODNEY BROOKS: I’m going to die too. I have no doubt about it, but he doesn’t \nlike to have it pointed out because he’s one of these techno-religion people. There \nare different versions of techno religion. There are the life extension companies \nbeing started by the billionaires in Silicon Valley, then there’s the upload yourself \nto a computer person like Ray Kurzweil. I think that probably for a few more \ncenturies, we’re still mortal. \nMARTIN FORD: I tend to agree with that. You mentioned self-driving cars, let me \njust ask you specifically how fast you see that moving? Google supposedly has real \ncars with nobody inside them on the road now in Arizona. \nRODNEY BROOKS: I haven’t seen the details of that yet, but it has taken a lot longer \nthan anyone thought. Both Mountain View (California) and Phoenix (Arizona) are \ndifferent sorts of cities to much of the rest of the US. We may see some demos there, \nbut it’s going to be a few years before there is a practical mobility-as-a-service operation \nthat turns out to be anything like profitable. By profitable, I mean making money almost \nat the rate at which Uber is losing money, which was $4.5 billion last year. \nMARTIN FORD: The general thought is that since Uber loses money on every ride, \nif they can’t go autonomous it’s not a sustainable business model. \nRODNEY BROOKS: I just saw a story this morning, saying that the median \nhourly wage of an Uber driver is $3.37, so they’re still losing money. That’s not \na big margin to get rid of and replace with those expensive sensors required for \nautonomous driving. We haven’t even figured out what the practical solution is \nfor self-driving cars. The Google cars have piles of expensive sensors on the roof, \nand Tesla tried and failed with just built-in cameras. We will no doubt see some \nimpressive demonstrations and they will be cooked. We saw that with robots from \nJapan, those demonstrations were cooked, very, very cooked. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 608
  },
  {
    "chunk_full": "RODNEY BROOKS\n429\nMARTIN FORD: You mean faked?\nRODNEY BROOKS: Not faked, but there’s a lot behind the curtain that you don’t \nsee. You infer, or you make generalizations about what’s going on, but it’s just not \ntrue. There’s a team of people behind those demonstrations, and there will be teams \nof people behind the self-driving demonstrations in Phoenix for a long time, which \nis a long way from it being real.\nAlso, a place like Phoenix is different from where I live in Cambridge, Massachusetts, \nwhere it’s all cluttered one-way streets. This raises questions, such as where does \nthe driving service pick you up in my neighborhood? Does it pick you up in the \nmiddle of the road? Does it pull into a bus lane? It’s usually going to be blocking \nthe road, so it’s got to be fast, people will be tooting horns at them, and so on. It’s \ngoing to be a while before fully autonomous systems can operate in that world, so I \nthink even in Phoenix we’re going to see designated pickup and drop-off places for \na long time, they won’t be able to just slot nicely into the existing road network. \nWe’ve started to see Uber rolling out designated pick-up spots for their services. \nThey now have a new system, which they were trying in San Francisco and Boston \nand has now expanded to six cities, where you can stand in line at an Uber rank \nwith other people getting cold and wet waiting for their cars. We’re imagining self-\ndriving cars are going to be just like the cars of today except with no driver. No, \nthere’s going to be transformations of how they’re used. \nOur cities got transformed by cars when they first came along, and we’re going to \nneed a transformation of our cities for this technology. It’s not going to be just like \ntoday but with no drivers in the cars. That takes a long time, and it doesn’t matter \nhow much of a fanboy you are in Silicon Valley, it isn’t going to happen quickly. \nMARTIN FORD: Let’s speculate. How long will it take to have something like \nwhat we have with Uber today, a mass driverless product where you could be in \nManhattan or San Francisco and it will pick you up somewhere and take you to \nanother place you specify? \nRODNEY BROOKS: It’s going to come in steps. The first step may be that you walk \nto a designated pick-up place and they’re there. It’s like when you pick up a Zipcar \n(an American car-sharing company scheme) today, there are designated parking spots \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 609
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n430\nfor Zipcars. That will come earlier than the service that I currently get from an \nUber where they pull up and double park right outside my house. At some point, I \ndon’t know whether it is going to be in my lifetime, we’ll see a lot of self-driving \ncars moving around our regular cities but it’s going to be decades in the making \nand there’s going to be transformations required, but we haven’t quite figured out \nyet what they’re going to be. \nFor instance, if you’re going to have self-driving cars everywhere, how do you refuel \nthem or recharge them? Where do they go to recharge? Who plugs them in? Well, some \nstartups have started to think about how fleet management systems for electric self-\ndriving cars might work. They will still require someone to do the maintenance and the \nnormal daily operations. A whole bunch of infrastructure like that would have to come \nabout for autonomous vehicles to be a mass product, and it’s going to take a while.\nMARTIN FORD: I’ve had other estimates more in the range of five years until something \nroughly the equivalent to Uber is ready. I take it that you think that’s totally unrealistic?\nRODNEY BROOKS: Yes, that’s totally unrealistic. We might get to see certain \naspects of it, but not the equivalent. It’s going to be different, and there’s a whole \nbunch of new companies and new operations that have to support it that haven’t \nhappened yet. Let’s start with the fundamentals. How are you going to get in the \ncar? How’s it going to know who you are? How do you tell if you’ve changed your \nmind when you’re driving and you want to go to a different location? Probably \nwith speech, Amazon Alexa and Google Home have shown us how good speech \nrecognition is, so I think we will expect the speech to work.\nLet’s look at the regulatory system. What can you tell the car to do? What can \nyou tell the car to do if you don’t have a driver’s license? What can a 12-year-old, \nwho’s been put in the car by their parents to go to soccer practice, tell the car to \ndo? Does the car take voice commands from 12-year-olds, or does it not listen to \nthem? There’s an incredible number of practical and regulatory problems that people \nhave not been talking about that remain to be solved. At the moment, you can put \na 12-year-old in a taxi and it will take him somewhere. That isn’t going to happen \nfor a long time with self-driving cars.\nMARTIN FORD: Let’s go back to one of your earlier comments on your previous \nresearch into insects. That’s interesting because I’ve often thought that insects are \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 610
  },
  {
    "chunk_full": "RODNEY BROOKS\n431\nvery good biological robots. I know you’re no longer a researcher yourself, but \nI was wondering what’s currently happening in terms of building a robot or an \nintelligence that begins to approach what an insect is capable of, and how does \nthat influence our steps toward superintelligence? \nRODNEY BROOKS: Simply put, we don’t have anything anywhere near as good \nas an insect, so I’m not afraid of superintelligence showing up anytime soon. \nWe can’t replicate the learning capabilities of insects using only a small number \nof unsupervised examples. We can’t achieve the resilience of the insect in being \nable to adapt in the world. We certainly can’t replicate the mechanics of an \ninsect, which are amazing. No one has anything that approaches an insect’s level \nof intent. We have great models that can look at something and classify it and \neven put a label on it in certain cases, but that’s so much different to even the \nintelligence of an insect. \nMARTIN FORD: Think back to the ‘90s and the time you started iRobot, do you \nthink since then robotics has met or even exceeded your expectations, or has it \nbeen disappointing? \nRODNEY BROOKS: When I came to the United States in 1977, I was really \ninterested in robots and ended up working on computer vision. There were three \nmobile robots in the world at that point. One of those robots was at Stanford, where \nHans Moravec would run experiments to get the robot to move 60 feet across a \nlarge room in six hours, another one was at NASA’s Jet Propulsion Laboratory \n(JPL), and the last was at the Laboratory for Analysis and Architecture of Systems \n(LAAS) in Toulouse, France. \nThere were three mobile robots in the world. iRobot now ships millions of mobile \nrobots per year, so from the point of view of how far that’s come, I’m pretty \nhappy. We made it big and we’ve moved a long, long way. The only reason that \nthose advances in robotics haven’t been a bigger story is because in that same \ntime frame we’ve gone from room-size mainframe computers to having billions of \nsmartphones throughout the world. \nMARTIN FORD: Moving on from insects, I know you’ve been working on creating \nrobotic hands. There have been some amazing videos of robotic hands from various \nteams. Can you let me know how that field is progressing? \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 611
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n432\nRODNEY BROOKS: Yes, I wanted to differentiate that mobile commercial robot \nwork that I was doing at iRobot from what I was doing with my students at MIT, \nso my research at MIT changed from insects to humanoids and as a result, I started \nto work there with robot arms. That work is progressing slowly. There are various \nexciting things happening in lab demos, but they’re focusing on one particular task, \nwhich is very different from the more general way in which we operate. \nMARTIN FORD: Is that slow progress due to a hardware or a software problem, \nand is it the mechanics of it or just the control? \nRODNEY BROOKS: It’s everything. There are a whole bunch of things that you have \nto make progress on in parallel. You have to make progress on the mechanics, on \nthe materials that form the skin, on the sensors embedded throughout the hand, \nand on the algorithms to control it, and all those things have to happen at once. \nYou can’t race ahead with one pathway without the others alongside it. \nLet me give you an example to drive this home. You’ve probably seen those plastic \ngrabber toys that have a handle at one end that you squeeze to open a little hand \nat the other end. You can use them to grab hard-to-reach stuff, or to reach a light \nbulb that you can’t quite get to on your own. \nThat really primitive hand can do fantastic manipulation beyond what any robot can \ncurrently do, but it’s an amazingly primitive piece of plastic junk that you’re using \nto do that manipulation with. That’s the clincher, you are doing the manipulation. \nOften, you’ll see videos of a new robot hand that a researcher has designed, and \nit’s a person holding the robot hand and moving it around to do a task. They could \ndo the same task with this little plastic grabber toy, it’s the human doing it. If it \nwas that simple, we could attach this grabber toy to the end of a robot arm and \nhave it perform the task—a human can do it with this toy at the end of their arm, \nwhy can’t a robot? There’s something dramatic missing. \nMARTIN FORD: I have seen reports that deep learning and reinforcement learning is \nbeing used to have robots learn to do things by practicing or even just by watching \nYouTube videos. What’s your view on this?\nRODNEY BROOKS: Remember they’re lab demos. DeepMind has a group using our \nrobots and they’ve recently published some interesting force feedback work with \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 612
  },
  {
    "chunk_full": "RODNEY BROOKS\n433\nrobots attaching clips to things, but each of these is painstakingly worked on by a \nteam of really smart researchers for months. It’s nowhere near the same as a human. \nIf you take any person and show them something to do dexterously, they can do it \nimmediately. We are nowhere close to anything like that from a robot’s perspective. \nI recently built some IKEA furniture and I’ve heard people say this would be a great \nrobot test. Give them an IKEA kit, give them the instructions that come with it, and \nhave them make it. I must have done 200 different dexterous sorts of tasks while \nbuilding that furniture. Let’s say we took my robots, that we sell in the thousands \nand are state of the art and have more sensors in them than any other robot that is \nsold today, and we tried to replicate that. If we worked for a few months in a very \nrestricted environment we might get a coarse demonstration of one of those 200 \ntasks that I just knew and did. Again, it’s imagination running wild here to think a \nrobot could soon do all of those tasks, the reality is very different. \nMARTIN FORD: What is the reality? Thinking 5 to 10 years ahead, what are we going \nto see in the field of robotics and artificial intelligence? What kinds of breakthroughs \nshould we realistically expect? \nRODNEY BROOKS: You can never expect breakthroughs. I expect 10 years from now \nthe hot thing will not be deep learning, there’ll be a new hot thing driving progress. \nDeep learning has been a wonderful technology for us. It is what enables the speech \nsystems for Amazon Echo and Google Home, and that’s a fantastic step forward. \nI know deep learning is going to enable other steps forward too, but something \nwill come along to replace it. \nMARTIN FORD: When you say deep learning, do you mean by that neural \nnetworks using backpropagation? \nRODNEY BROOKS: Yes, but with lots of layers. \nMARTIN FORD: Maybe then the next thing will still be neural networks but with \na different algorithm or Bayesian networks?\nRODNEY BROOKS: It might be, or it might be something very different, that’s \nwhat we don’t know. I guarantee, though, that within 10 years there’ll be a new \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 613
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n434\nhot topic that people will be exploiting for applications, and it will make certain \nother technologies suddenly pop. I don’t know what they will be, but in a 10-year \ntime frame we’re certainly going to see that happen. \nIt’s impossible to predict what’s going to work and why, but you can in a predictable \nway say something about market pull, and market pull is going to come from a few \ndifferent megatrends that are currently taking place. \nFor example, the ratio of elderly retired people to working-age people is changing \ndramatically. Depending on whose numbers you look at, the ratio is changing from \nsomething like nine working-age people to every one retired person (9:1) to two \nworking-age people to every retired person (2:1). There are a lot more elderly \npeople in the world. It depends on the country and other factors, but that means \nthere will be a market pull toward helping the elderly get things done as they get \nfrailer. We’re already seeing this in Japan at robotics trade shows, where there are \na lot of lab demos of robots helping the elderly to do simple tasks, such as getting \ninto and out of bed, getting into and out of the bathroom, just simple daily things. \nThose things currently require one-to-one human help, but as that ratio of working-\nage to elderly changes, there isn’t going to be the labor force to fulfil that need. \nThat’s going to pull robotics into helping the elderly.\nMARTIN FORD: I agree that that elder care segment is a massive opportunity for the \nrobotics and AI industry, but it does seem very challenging in terms of the dexterity \nthat’s required to really assist an elderly person in taking care of themselves.\nRODNEY BROOKS: It is not going to be a simple substitution of a robotic system \nfor a person, but there is going to be a demand so there will be motivated \npeople working on trying to come up with solutions because it is going to be \nan incredible market. \nI think we will also see a pull for construction work because we are urbanizing \nthe world at an incredible rate. Many of the techniques that we use in \nconstruction were invented by the Romans, there’s room for a little technological \nupdate in some of those. \nMARTIN FORD: Do you think that would be construction robots or would it be \nconstruction scale 3D printing? \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 614
  },
  {
    "chunk_full": "RODNEY BROOKS\n435\nRODNEY BROOKS: 3D printing may come in for aspects of it. It’s not going to \nbe printing the whole building, but certainly we might see printed pre-formed \ncomponents. We’ll be able to manufacture a lot more parts off-site, which will \nin turn lead to innovation in delivering, lifting, and moving those parts. There’s \nroom for a lot of innovation there. \nAgriculture is another industry that will potentially see robotics and AI innovation, \nparticularly with climate change disrupting our food chain. People are already \ntalking about urban farming, bringing farming out of a field and into a factory. This \nis something where machine learning can be very helpful. We have the computation \npower now to close a loop around every seed we need to grow and to provide it \nwith the exact nutrients and conditions that it needs without having to worry about \nthe actual weather outside. I think climate change is going to drive automation of \nfarming in a different way than it has so far. \nMARTIN FORD: What about real household consumer robots? The example people \nalways give is the robot that would bring you a beer. It sounds like that might \nstill be some way off.\nRODNEY BROOKS: Colin Angle, the CEO of iRobot, who co-founded it with me \nin 1990, has been talking about that for 28 years now. I think that I’m still going \nto be going to the fridge myself for a while.\nMARTIN FORD: Do you think that there will ever be a genuinely ubiquitous \nconsumer robot, one that saturates the consumer market by doing something that \npeople find absolutely indispensable? \nRODNEY BROOKS: Is Roomba indispensable? No, but it does something of value at \na low enough cost that people are willing to pay for it. It’s not quite indispensable, \nit’s a convenience level. \nMARTIN FORD: When do we get there for a robot that can do more than move around \nand vacuum floors? A robot that has sufficient dexterity to perform some basic tasks? \nRODNEY BROOKS: I wish I knew! I think no one knows. Everyone’s saying robots \nare coming to take over the world, yet we can’t even answer the question of when \none will bring us a beer. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 615
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n436\nMARTIN FORD: I saw an article recently with the CEO of Boeing, Dennis \nMuilenburg, saying that they’re going to have autonomous drone taxis flying people \naround within the next decade, what do you think of his projection? \nRODNEY BROOKS: I will compare that to saying that we’re going to have flying \ncars. Flying cars that you can drive around in and then just take off have been a \ndream for a long time, but I don’t think it’s going to happen. \nI think the former CEO of Uber, Travis Kalanick, claimed that they were going to \nhave flying Ubers deployed autonomously in 2020. It’s not going to happen. That’s \nnot to say that I don’t think we’ll have some form of autonomous personal transport. \nWe already have helicopters and other machines that can reliably go from place to \nplace without someone flying them. I think it’s more about the economics of it that \nwill determine when that happens, but I don’t have an answer to when that will be.\nMARTIN FORD: What about artificial general intelligence? Do you think it is achievable \nand, if so, in what timeframe do you think we have a 50% chance of achieving it? \nRODNEY BROOKS: Yes, I think it is achievable. My guess on that is the year 2200, \nbut it’s just a guess. \nMARTIN FORD: Tell me about the path to get there. What are the hurdles we’ll face? \nRODNEY BROOKS: We already talked about the hurdle of dexterity. The ability to \nnavigate and manipulate the world is important in understanding the world, but \nthere’s a much wider context to the world than just the physical. For example, \nthere isn’t a single robot or AI system out there that knows that today is a \ndifferent day to yesterday, apart from a nominal digit on a calendar. There is no \nexperiential memory, no understanding of being in the world from day to day, \nand no understanding of long-term goals and making incremental progress toward \nthem. Any AI program in the world today is an idiot savant living in a sea of now. \nIt’s given something, and it responds. \nThe AlphaGo program or chess-playing programs don’t know what a game is, \nthey don’t know about playing a game, they don’t know that humans exist, they \ndon’t know any of that. Surely, though, if an AGI is equivalent to a human, it’s \ngot to have that full awareness. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 616
  },
  {
    "chunk_full": "RODNEY BROOKS\n437\nAs far back as 50 years ago people worked on research projects around those \nthings. There was a whole community that I was a part of in the 1980s through \nthe 1990s working on the simulation of adaptive behavior. We haven’t made much \nprogress since then, and we can’t point to how it’s going to be done. No one’s \ncurrently working on it, and the people that claim to be advancing AGI are actually \nre-doing the same things that John McCarthy talked about in the 1960s, and they \nare making about as much progress. \nIt’s a hard problem. It doesn’t mean you don’t make progress on the way in a lot \nof technologies, but some things just take hundreds of years to achieve. We think \nthat we’re the golden people at the critical time. Lots of people have thought that \nat lots of times, it doesn’t make it true for us right now and I see no evidence of it. \nMARTIN FORD: There are concerns that we will fall behind China in the race to \nadvanced artificial intelligence. They have a larger population, and therefore more \ndata, and they don’t have as strict privacy concerns to hold back what they can do \nin AI. Do you think that we are entering a new AI arms race?\nRODNEY BROOKS: You’re correct, there is going to be a race. There’s been a race \nbetween companies, and there will be a race between countries. \nMARTIN FORD: Do you view it as a big danger for the West if a country like \nChina gets a substantial lead in AI? \nRODNEY BROOKS: I don’t think it’s as simple as that. We will see uneven \ndeployment of AI technologies. I think we are seeing this already in China in their \ndeployment of facial recognition in ways that we would not like to see here in \nthe US. As for new AI chips, this is not something that a country like the US can \nafford to even begin to fall behind with. However, to not fall behind would require \nleadership that we do not currently have. \nWe’ve seen policies saying that we need more coal miners, while science budgets \nare cut, including places like the National Institute of Standards and Technology. It’s \ncraziness, it’s delusional, it’s backward thinking, and it’s destructive. \nMARTIN FORD: Let’s talk about some of the risks or potential dangers associated with \nAI and robotics. Let’s start with the economic question. Many people believe we are \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 617
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n438\non the cusp of a big disruption on the scale of a new Industrial Revolution. Do you \nbuy into that? Is there going to be a big impact on the job market and the economy? \nRODNEY BROOKS: Yes, but not in the way people talk about. I don’t think it’s AI \nper se. I think it’s the digitalization of the world and the creation of new digital \npathways in the world. The example I like to use is toll roads. In the US, we’ve \nlargely gotten rid of human toll takers on toll roads and toll bridges. It’s not \nparticularly done with AI but it’s done because there’s a whole bunch of digital \npathways that have been built up in our society over the last 30 years. \nOne of the things that allowed us to get rid of toll takers is the tag that you can \nput on your windscreen that gives a digital signature to your car. Another advance \nthat made it practical to get rid of all the human toll lanes is computer vision, \nwhere there is an AI system with some deep learning that can take a snapshot of \nthe license plate and read it reliably. It’s not just at the toll gate, though. There \nare other digital chains that have happened to get us to this point. You are able to \ngo to a website and register the tag in your car and the particular serial code that \nbelongs to you, and also provide your license number so that there’s a backup. \nThere’s also digital banking that allows a third party to regularly bill your credit card \nwithout them ever touching your physical credit card. In the old days you had to \nhave the physical credit card, now it’s become a digital chain. There’s also the side \neffect for the companies that run the toll booth, that they no longer need trucks to \ncollect the money and take it to the bank because they have this digital supply chain.\nThere’s a whole set of digital pieces that came together to automate that service \nand remove the human toll taker. AI was a small, but necessary piece in there, \nbut it wasn’t that overnight that person was replaced by an AI system. It’s those \nincremental digital pathways that enable the change in labor markets, it’s not a \nsimple one-for-one replacement. \nMARTIN FORD: Do you think those digital chains will disrupt a lot of those \ngrass roots service jobs? \nRODNEY BROOKS: Digital chains can do a lot of things but they can’t do \neverything. What they leave behind are things that we typically don’t value very \nmuch but are necessary to keep our society running, like helping the elderly in \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 618
  },
  {
    "chunk_full": "RODNEY BROOKS\n439\nthe restroom, or getting them in and out of showers. It’s not just those kinds \nof tasks—look at teaching. In the US, we’ve failed to give schoolteachers the \nrecognition or the wages they deserve, and I don’t know how we’re going to \nchange our society to value this important work, and make it economically \nworthwhile. As some jobs are lost to automation, how do we recognize and \ncelebrate those other jobs that are not?\nMARTIN FORD: It sounds like you’re not suggesting that mass unemployment will \nhappen, but that jobs will change. I think one thing that will happen is that a lot \nof desirable jobs are going to disappear. Think of the white-collar job where you’re \nsitting in front of a computer and you’re doing something predictable and routine, \ncranking out the same report again and again. It’s a very desirable high-paying job \nthat people go to college to get and that job is going to be threatened, but the \nmaid cleaning the hotel room is going to be safe. \nRODNEY BROOKS: I don’t deny that, but what I do deny is when people say, oh \nthat’s AI and robots doing that. As I say, I think this is more down to digitalization. \nMARTIN FORD: I agree, but it’s also true that AI is going to be deployed on that \nplatform, so things may move even faster. \nRODNEY BROOKS: Yes, it certainly makes it easier to deploy AI given that \nplatform. The other worry, of course, is that the platform is built on totally insecure \ncomponents that can get hacked by anyone.\nMARTIN FORD: Let’s move on to that security question. What are the things \nthat we really should worry about, aside from the economic disruption? What \nare the real risks, such as security, that you think are legitimate and that we \nshould be concerned with? \nRODNEY BROOKS: Security is the big one. I worry about the security of these \ndigital chains and the privacy that we have all given up willingly in return for a \ncertain ease of use. We’ve already seen the weaponization of social platforms. Rather \nthan worry about a self-aware AI doing something willful or bad, it’s much more \nlikely that we’re going to see bad stuff happen from human actors figuring out how \nto exploit the weaknesses in these digital chains, whether they be nation states, \ncriminal enterprises, or even lone hackers in their bedrooms. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 619
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n440\nMARTIN FORD: What about the literal weaponization of robots and drones? Stuart \nRussell, one of the interviewees in this book, made a quite terrifying film called \nSlaughterbots about those concerns.\nRODNEY BROOKS: I think that kind of thing is very possible today because it \ndoesn’t rely on AI. Slaughterbots was a knee-jerk reaction saying that robots and \nwar are a bad combination. There’s another reaction that I have. It always seemed \nto me that a robot could afford to shoot second. A 19-year-old kid just out of high \nschool in a foreign country in the dark of night with guns going off around them \ncan’t afford to shoot second. \nThere’s an argument that keeping AI out of the military will make the problem go \naway. I think you need to instead think about what it is you don’t want to happen \nand legislate about that rather than the particular technology that is used. A lot \nof these things could be built without AI. \nAs an example, when we go to the Moon next, it will rely heavily on AI and \nmachine learning, but in the ‘60s we got there and back without either of those. \nIt’s the action itself that we need to think about, not which particular technology \nis being used to perform that action. It’s naive to legislate against a technology \nand it doesn’t take into account the good things that you can do with it, like have \nthe system shoot second, not shoot first. \nMARTIN FORD: What about the AGI control problem and Elon Musk’s comments \nabout summoning the demon? Is that something that we should be having \nconversations about at this point? \nRODNEY BROOKS: In 1789 when the people of Paris saw hot-air balloons for the \nfirst time, they were worried about those people’s souls getting sucked out from \nup high. That’s the same level of understanding that’s going on here with AGI. We \ndon’t have a clue what it would look like. \nI wrote an essay on The Seven Deadly Sins of Predicting the Future of AI1, and they are \nall wrapped up in this stuff. It’s not going to be a case of having exactly the same \nworld as it is today, but with an AI super intelligence in the middle of it. It’s going \n1 https://rodneybrooks.com/the-seven-deadly-sins-of-predicting-the-future-of-ai/\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 620
  },
  {
    "chunk_full": "RODNEY BROOKS\n441\nto come very gradually over time. We have no clue at all about what the world or \nthat AI system are going to be like. Predicting an AI future is just a power game \nfor isolated academics who live in a bubble away from the real world. That’s not \nto say that these technologies aren’t coming, but we won’t know what they will \nlook like before they arrive.\nMARTIN FORD: When these technology breakthroughs do arrive, do you think \nthere’s a place for regulation of them? \nRODNEY BROOKS: As I said earlier, the place where regulation is required is on \nwhat these systems are and are not allowed to do, not on the technologies that \nunderlie them. Should we stop research today on optical computers because they \nlet you perform matrix multiplication much faster, so you could apply greater \ndeep learning much more quickly? No, that’s crazy. Are self-driving delivery trucks \nallowed to double park in congested areas of San Francisco? That seems to be a \ngood thing to regulate, not what the technology is. \nMARTIN FORD: Taking all of this into account, I assume that you’re an optimist \noverall? You continue to work on this so you must believe that the benefits of all \nthis are going to outweigh any risks.\nRODNEY BROOKS: Yes, absolutely. We have overpopulated the world, so we have \nto go this way to survive. I’m very worried about the standard of living dropping \nbecause there’s not enough labor as I get older. I’m worried about security and \nprivacy, to name two more. All of these are real and present dangers, and we can \nsee the contours of what they look like. \nThe Hollywood idea of AGIs taking over is way in the future, and we have no clue \neven how to think about that. We should be worried about the real dangers and \nthe real risks that we are facing right now. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 621
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n442\nRODNEY BROOKS is a robotics entrepreneur who holds a PhD in Computer Science from \nStanford University. He’s currently the Chairman and CTO of Rethink Robotics. For a decade \nbetween 1997 and 2007, Rodney was the Director of the MIT Artificial Intelligence Laboratory \nand later the MIT Computer Science and Artificial Intelligence Laboratory (CSAIL). \nHe’s a fellow to several organizations, including The Association for the Advancement of \nArtificial Intelligence (AAAI), where he is a founding fellow. So far in his career he’s won \na number of awards for his work within the field, including the Computers and Thought \nAward, the IEEE Inaba Technical Award for Innovation Leading to Production, the Robotics \nIndustry Association’s Engelberger Robotics Award for Leadership and the IEEE Robotics \nand Automation Award. \nRodney even starred as himself in the 1997 Error Morris movie, Fast, Cheap and Out \nof Control. A movie named after one of his papers, and which currently holds a 91% \nRotten Tomatoes score. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 622
  },
  {
    "chunk_full": "RODNEY BROOKS\n443\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 623
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n444\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 624
  },
  {
    "chunk_full": "CYNTHIA BREAZEAL\n445\nCYNTHIA BREAZEAL \nDIRECTOR OF THE PERSONAL ROBOTS GROUP, MIT MEDIA LABORATORY \nFOUNDER, JIBO, INC.\nCynthia Breazeal is the Director of the Personal Robotics Group at the MIT Media \nLab, as well as the founder of Jibo, Inc. She is a pioneer of social robotics and \nhuman-robot interaction. In 2000 she designed Kismet, the world’s first social robot, \nas part of her doctoral research at MIT. Jibo was featured on the cover of TIME \nmagazine, recognized as Best Inventions 2017. At the Media Lab, she has developed \na variety of technologies focused on human-machine social interaction, including \nthe development of new algorithms, understanding the psychology of human-robot \ninteraction, as well as new social robot designs for applications in early childhood \nlearning, home AI and personal robots, aging, healthcare and wellness, and more. \nI am not nearly as concerned about super intelligence  \nenslaving humanity as I am around people using the  \ntechnology to do harm.\n“ \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 625
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n446\nMARTIN FORD: Do you have a sense of when personal robots will become a true \nmass consumer product, so that we’ll all want one in the same way we have a \ntelevision set or a smartphone?\nCYNTHIA BREAZEAL: Yes, I actually think we’re already starting to see it. Back in \n2014, when I was raising funds for my startup Jibo, a social robot for the home, \neverybody thought that our competitor was the smartphone, that the technology \nin the home that people were going to use to interact and control everything \nwith was going to be a touchscreen. That Christmas, Amazon announced Alexa, \nand now we know that these VUI (Voice User Interface) assistants are actually the \nmachines that people will use in their homes. It’s opened up the whole opportunity \nspace because you can see that people are willing to use voice devices because \nit’s easy and it’s convenient. \nBack in 2014, most people interacting with AI at a consumer level were those \nwith Siri or Google Assistant on their phones. Now, only four years later you’ve \ngot everyone from young children to 98-year-olds talking to their voice-enabled \nAI smart devices. The type of people who are interacting with AI is fundamentally \ndifferent now than it was even back in 2014. So, are the current talking speakers \nand devices going to be where it ends? Of course not. We’re in the primordial \nage of this new way of interacting with ambient AIs that coexist with us. A lot of \nthe data and evidence that we have gathered even through Jibo shows very clearly \nthat this deeper collaborative social-emotional, personalized, proactive engagement \nsupports the human experience in such a deeper way.\nWe’re starting with these transactional VUI AIs who get the weather or the \nnews, but you can see how that’s going to grow and change into critical domains \nof real value for families, like extending education from the school to the home, \nscaling affordable healthcare from the healthcare institutions to the home, allowing \npeople to age in place, and so on. When you’re talking about those huge societal \nchallenges, it’s about a new kind of intelligent machine that can collaboratively \nengage you over an extended longitudinal relationship and personalize, grow, and \nchange with you. That’s what a social robot’s about, and that’s clearly where this \nis all going to go, and right now I think we’re at the beginning. \nMARTIN FORD: There are real risks and concerns associated with this kind of \ntechnology, though. People worry about the developmental impact on children if \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 626
  },
  {
    "chunk_full": "CYNTHIA BREAZEAL\n447\nthey’re interacting with Alexa too much, or take a dystopian view of robots being \nused as companions for elderly people. How do you address those concerns?\nCYNTHIA BREAZEAL: Let’s just say there’s the science that needs to be done, and \nthere’s the fact of what these machines do now. Those present a design opportunity \nand challenge to create these technologies in a way that is both ethical and beneficial \nand supports our human values. Those machines don’t really exist yet. So yes, you \ncan have dystopian conversations about what may happen 20 to 50 years from now, \nbut the problem to be solved at this moment is: we have these societal challenges, \nand we have a range of technologies that have to be designed in the context of human \nsupport systems. The technologies alone are not the solution, they have to support our \nhuman support systems, and they have to make sense in the lives of everyday people. \nThe work to be done is to understand how to do that in the right way. \nSo yes, of course there will always be critics and people wringing their hands and \nthinking, “oh my god, what could happen,” and you need that dialog. You need those \npeople being able to throw up the flares to say watch out for this, watch out for that. \nIn a way, we’re living in a society where the alternative is unaffordable; you can’t afford \nthe help. These technologies have the opportunity for scalable, affordable, effective, \npersonalized support and services. That’s the opportunity, and people do need help. \nGoing without help is not a solution, so we’ve got to figure out how to do it. \nThere needs to be a real dialog and a real collaboration with the people who are \ntrying to create solutions that are going to make a difference in people’s lives—you \ncan’t just critique it. At the end of the day, everybody ultimately wants the same \nthing; people building the systems don’t want a dystopian future. \nMARTIN FORD: Can you talk a bit more about Jibo and your vision for where \nyou see that going? Do you anticipate that Jibo will eventually evolve into a robot \nthat runs around the house doing useful things, or is it intended to be focused \nmore on the social side?\nCYNTHIA BREAZEAL: I think there’s going to be a whole bunch of different kinds \nof robots, and Jibo is the first of its kind that’s out there and is leading the way. \nWe’re going to see other companies with other types of robots. Jibo is meant to \nbe a platform that has extensible skills, but other robots may be more specialized. \nThere’ll be those kinds of robots, but there’s also going to be physical assistance \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 627
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n448\nrobots. A great example is the Toyota Research Institute, who are looking at mobile \ndexterous robots to provide physical support for elderly people, but they completely \nacknowledge those robots also need to have social and emotional skills.\nIn terms of what comes into people’s homes, it’s going to depend on what the \nvalue proposition is. If you’re a person aging in place, you’re probably going to \nwant a different robot than parents of a child who want that child to learn a second \nlanguage. In the end, it’s all going to be based on what the value proposition is \nand what role that robot has in your home, including all the other factors like the \nprice point. This is an area that’s going to continue to grow and expand, and these \nsystems are going to be in homes, in schools, in hospitals, and in institutions.\nMARTIN FORD: How did you become interested in robotics?\nCYNTHIA BREAZEAL: I grew up in Livermore, California, which has two National \nLabs. Both my parents worked in those as computer scientists, so I was really bought \nup in a home where engineering and computer science were seen as a really great \ncareer path with a lot of opportunities. I also had toys like Lego, because my parents \nvalued those kinds of constructive media. \nWhen I was growing up, there wasn’t nearly as much around for kids to do with \ncomputers as there is now, but I could go into the National Labs where they would \nhave various activities for kids to do—I remember the punch cards! Because of \nmy parents, I was able to get into computers at a much earlier age than a lot of \nmy peers and, not surprisingly my parents were some of the first people to bring \nhome personal computers. \nThe first Star Wars movie came out when I was around 10 years old, and that \nwas the first epiphany moment that set me on my particular career trajectory. I \nremember just being fascinated by the robots. It was the first time I had seen robots \nthat were presented as full-fledged and collaborative characters, not just drones or \nautomatons but mechanical beings who had emotions and relationships with each \nother and people. It really wasn’t just about the amazing things they could do; it \nwas also around the human interpersonal connection they also formed with those \naround them that really struck that emotional chord. Because of that film, I grew \nup with this attitude that robots could be like that and I think that’s shaped a lot \nof what my research has been about. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 628
  },
  {
    "chunk_full": "CYNTHIA BREAZEAL\n449\nMARTIN FORD: Rodney Brooks, who is also interviewed in this book, was your \ndoctoral adviser at MIT. How did that influence your career path?\nCYNTHIA BREAZEAL: At the time I decided that what I really wanted to do when \nI grew up was to be an astronaut mission specialist, so I knew I needed to get a \nPhD in a relevant field, and so I decided that mine was going to be space robotics. \nI applied to a bunch of graduate schools and one of the schools I was admitted to \nwas MIT. I went to a visit week at MIT and I remember my first experience in \nRodney Brooks’ mobile robot lab.\nI remember walking into his lab and seeing all these insect-inspired robots that were \ncompletely autonomous going around doing a variety of different tasks depending \non what the graduate students were working on. For me that was the Star Wars \nmoment all over again. I remember thinking if there were ever going to be robots \nlike I saw in Star Wars, it was going to happen in a lab like that. That’s where it was \ngoing to begin, and quite possibly in that very lab, and I decided I had to be there \nand that’s really what clinched the deal for me. \nSo, I went to MIT for graduate school, where Rodney Brooks was my academic \nadviser. Back then, Rod’s philosophy was always a very biologically inspired \nphilosophy to intelligence, which was not typical for the overall field. During the \ncourse of my graduate degree, I started reading a lot of literature on intelligence, \nnot just on AI and computational methods, but natural forms of intelligence and \nmodels of intelligence. The deep interplay between psychology and what we can \nlearn from ethology and other forms of intelligence and machine intelligence has \nalways been a thread and a theme of my work. \nAt that time, Rodney Brooks was working on small-legged robots and he wrote \na paper, Fast, Cheap and Out of Control: A Robot Invasion of the Solar System, where \ninstead of sending up one or two very large, very expensive rovers, he was \nadvocating for sending many, many small autonomous rovers, and if you did \nthat then you could actually explore Mars and other kinds of celestial bodies \nmuch more easily. That was a very influential paper, and my master’s thesis was \nactually developing the first primordial planetary Micro-Rover-inspired robots. I \nhad the opportunity as a graduate student to work with JPL (the Jet Propulsion \nLaboratory), and I like to think that some of that research contributed to \nSojourner and Pathfinder. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 629
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n450\nYears later, I was finishing up my master’s thesis and about to embark on my \ndoctoral work when Rod went on sabbatical. When he came back he pronounced \nthat we were going to do humanoids. This came as a shock because we all thought \nit was going to go from insects to reptiles, and maybe to mammals. We thought \nwe were going to be developing up the evolutionary chain of intelligence, so to \nspeak, but Rod insisted it had to be humanoids. It’s because when he was in Asia, \nparticularly in Japan, they were already developing humanoids and he saw that. \nI was one of the senior graduate students at that time, so I stepped up to lead \nthe effort on developing these humanoid robots to explore theories of embodied \ncognition. That hypothesis was about the nature of physical embodiment having a \nvery strong constraint and influence on the nature of intelligence a machine can \nhave or learn to develop. \nThe next step occurred literally on the date that NASA landed the Sojourner Mars \nPathfinder rover on July 5th, 1997. On that day, I was working on my doctorate on \na very different topic and I remember thinking at that moment, here we are in this \nfield where we’re sending robots to explore the oceans and volcanoes, because the \nvalue proposition of autonomy was that machines can do tasks that are far too dull, \ndirty, and dangerous for people. The rover was really about the autonomy allowing \npeople to do work in hazardous environments apart from people, and that’s why \nyou needed them. We could land a robot on Mars, but they weren’t in our homes.\nIt was from that moment that I started thinking quite a lot about how we in \nacademia were developing these amazing autonomous robots for experts, but nobody \nwas really embracing the scientific challenge of designing intelligent robots and \nresearching the nature of intelligent robots that you need in order to have them \ncoexist with people in society—from children to seniors, and everyone in between. \nIt’s like how computers used to be huge and very expensive devices that experts \nused, and then there was a shift to thinking about a computer on every desk in \nevery home. This was that moment in autonomous robotics.\nWe already recognized that when people interacted with or talked about autonomous \nrobots, they would anthropomorphize them. They would engage their social thinking \nmechanisms to try to make sense of them, so the hypothesis was that the social, \ninterpersonal interface would be the universal interface. Up to that time, the focus \non the nature of intelligence of machines was more around how do you engage and \nmanipulate the physical inanimate world. This was now a complete shift to thinking \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 630
  },
  {
    "chunk_full": "CYNTHIA BREAZEAL\n451\nabout building a robot that can actually collaborate, communicate, and interact with \npeople in a way that’s natural for people. That’s a very different kind of intelligence. \nIf you look at human intelligence we have all these different kinds of intelligences, \nand social and emotional intelligence are a profoundly important, and of course \nunderlies how we collaborate and how we live in social groups and how we coexist, \nempathize, and harmonize. At the time, no one was really working on that.\nAt this point I was quite far into my PhD, but I walked into Rod’s office on that \nday, and I said, “I have to change everything I’m doing about my PhD. My PhD has \ngot to be about robots and the lives of everyday people; it’s got to be about robots \nbeing socially and emotionally intelligent.” To his credit, Rod understood that this \nwas a really important way to think about these problems and that it was going to \nbe key to having robots become part of our everyday lives, so he let me go for it. \nFrom that point, I built a whole new robot, Kismet, which is recognized as the \nworld’s first social robot.\nMARTIN FORD: I know Kismet is now in the MIT museum. \nCYNTHIA BREAZEAL: Kismet was really the beginning of it. It’s the robot that \nstarted this field of the interpersonal human-robot social interaction, collaboration, \nand partnership, much more akin to the droids in Star Wars. I knew I could not build \nan autonomous robot that could rival adult social and emotional intelligence because \nwe are the most socially and emotionally sophisticated species on the planet. The \nquestion was what kind of entity can I model, because I’m coming from a lab where \nwe’re very biologically inspired, and the only entities that exhibit this behavior are \nliving things, mainly people. So, I thought the place to start looking at this was the \ninfant-caregiver relationship and looking at where does our sociability originate and \nhow does that develop over time? Kismet was modeling that nonverbal, emotive \ncommunication at the infant stage, because if a baby cannot form its emotional \nbond with its caregiver, the baby can’t survive. The caregiver has to sacrifice and \ndo many things in order to care for an infant. \nPart of our survival mechanism is to be able to form this emotional connection \nand to have enough sociability there that the caregiver—the mother, the father, or \nwhoever—is compelled to treat the newborn or young infant as a fully-fledged \nsocial and emotional being. Those interactions are critical to us actually developing \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 631
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n452\ntrue social and emotional intelligence, it’s a whole bootstrapping process. That’s \nanother moment of just acknowledging that even human beings, with all of our \nevolutionary endowments, don’t develop these capabilities if we don’t grow up in \nthe right kind of social environment. \nIt became a really important intersection of not only what you program in and \nendow an AI robot with, you have to also think deeply about the social learning \nand how you create the behaviors in the entity so that people will treat it as a \nsocial, emotionally responsive entity that they can empathize with and form that \nconnection with. It’s from those interactions that you can develop and grow and \ngo through another developmental trajectory to develop full adult social and \nemotional adult intelligence. \nThat was always the philosophy, which is why Kismet was modeled to be not like \na baby literally, but instead being altricial. I remember reading a lot of animation \nliterature too, which raised questions like, how do you design something that pulls on \nthose social, emotive, nurturing instincts within people so people would interact with \nKismet in a subconscious way and nurture it naturally? Because of the way the robot \nwas designed, every aspect about its quality of movement, its appearance, and its \nvocal quality was all about trying to create the right social environment that would \nallow the robot to engage, interact, and eventually be able to learn and develop. \nIn the early 2000s, a lot of the work was in understanding the mechanics of \ninterpersonal interaction and how people really communicate, not just verbally but \nimportantly nonverbally. A huge part of human communication is nonverbal, and \na lot of our social judgments of trustworthiness and affiliation, etc., are heavily \ninfluenced by our nonverbal interaction. \nWhen you look at voice assistants today, the interaction is very transactional; it \nfeels a lot like playing chess. I say something, the machine says something, I say \nsomething, the machine says something, and so on. When you look at human \ninterpersonal interaction, developmental psychology literature talks about the \n“dance of communication.” The way we communicate is constantly mutually adapted \nand regulated between the participants; it’s a subtle, nuanced dance. First, I’m \ninfluencing the listener, and while I’m talking and gesturing the listener is proving \nme nonverbal cues in dynamic relation to my own. All the while, their cues are \ninfluencing me and shaping my inferences about how the interaction is going, and \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 632
  },
  {
    "chunk_full": "CYNTHIA BREAZEAL\n453\nvice versa. We’re a dynamically coupled, collaborative duo. That’s what human \ninteraction and human communication really is, and a lot of the early work was \ntrying to capture that dynamic and appreciating how critical the nonverbal aspects \nwere as well as the linguistic side of it.\nThe next phase was to actually create an autonomous robot that could collaborate \nwith people in this interpersonal way, still pushing on the social and emotional \nintelligence and the theory of other minds, now to do cooperative activities. In AI \nwe have this habit of thinking that just because there’s a competence that’s easy for \nus as humans to do because we’ve evolved to do it, then it must not be that hard, \nbut actually, we are the most socially and emotionally sophisticated species on the \nplanet. Building social and emotional intelligence into machines is very, very hard.\nMARTIN FORD: And also, very computationally challenging? \nCYNTHIA BREAZEAL: Right. Arguably more so than a lot of other capabilities, \nlike vision or manipulation, when we think about how sophisticated we are. The \nmachine has to dovetail its intelligence and behavior with our own. It has to be able \nto infer and predict our thoughts, intents, beliefs, desires, etc. from context. What \nwe do, what we say. Our pattern of behavior over time. What if you can build a \nmachine that can engage people in this partnership where it doesn’t have to be about \nphysical work or physical assistance, but instead is about assistance and support in \nthe social and emotional domains? We started looking at new applications for robots \nthat these intelligent machines could have a profound impact on, like education, \nbehavior change, wellness, coaching, aging… but people hadn’t even thought about \nyet because they’re so hung up on the physical aspect of physical work.\nWhen you start to look at areas where social and emotional support is known to be \nreally important, these are often areas of growth and transformation of the human \nthemselves. If the task of the robot isn’t just to get a thing built, what if the thing \nyou’re actually trying to help improve or build is the person themselves? Education \nis a great example. If you can learn something new, you are transformed. You are \nable to do things that you could not do otherwise, and you have opportunities now \navailable to you that you didn’t have otherwise. Aging in place or managing chronic \ndisease are other examples. If you can stay healthier, your life is transformed because \nyou’re going to be able to do things and access opportunities you would not have \nbeen able to do otherwise.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 633
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n454\nSocial robots broaden the relevance and application of huge areas of social \nsignificance beyond manufacturing and autonomous cars. Part of my life’s work \nis trying to show people that you have physical competence in one dimension but \northogonal to that, which is critically important, is the ability for these machines \nto interact, engage, and support people in a way that unlocks our human potential. \nIn order to do that, you need to be able to engage people and all of our ways of \nthinking and understanding the world around us. We are a profoundly social and \nemotional species, and it’s really critical to engage and support those other aspects \nof human intelligence in order to unlock human potential. The work within the \nsocial robotics community has been focused on those huge impact areas. \nWe’re now just recently starting to see that an appreciation of robots or AI that \nwork collaboratively with people is actually really important. For a long, long time \nhuman-AI or human-robot collaboration was not a widely adopted problem that \npeople thought we had to figure out, but now I think that’s changed. \nNow that we’re seeing the proliferation of AI impacting so many aspects of our \nsociety, people are appreciating that this field of AI and robotics is no longer just a \ncomputer science or engineering endeavor. The technology has come into society in \na way that we have to think much more holistically around the societal integration \nand impact of these technologies. \nLook at a robot like Baxter, built by Rethink Robotics. It’s a manufacturing \nrobot that’s designed to collaborate with humans on the assembly line, not to \nbe roped off far from people but to work shoulder-to-shoulder with them. In \norder to do that, Baxter has got a face so that coworkers can anticipate, predict, \nand understand what the robot’s likely to do next. Its design is supporting our \ntheory of mind so that we can collaborate with it. We can read those nonverbal \ncues in order to make those assessments and predictions, and so the robot has \nto support that human way of understanding so that we can dovetail our actions \nand our mental states with those of the machine, and vice versa. I would say \nBaxter is a social robot; it just happens to be a manufacturing social robot. I \nthink we’ll have broad genres of robots that will be social, which means they’re \nable to collaborate with people, but they may do a wide variety of tasks from \neducation and healthcare to manufacturing and driving, and any other tasks. I \nsee it as a critical kind of intelligence for any machine that is meant to coexist \nwith human beings in a human-centered way that dovetails with the way we think \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 634
  },
  {
    "chunk_full": "CYNTHIA BREAZEAL\n455\nand the way we behave. It doesn’t matter what the physical task or capabilities \nof the machine are; if it’s collaborative it is also a social robot. \nWe’re seeing a wide variety of robots being designed today. They’re still going into \nthe oceans and on manufacturing lines, but now we’re also seeing these other kinds \nof robots coming in to human spaces in education and therapeutic applications \nfor autism, for instance. It’s worth remembering, though, that the social aspect \nis also really hard. There’s still a long way to go in improving and enhancing the \nsocial and emotional collaborative intelligence of this kind of technology. Over \ntime, we’ll see combinations of the social, emotional intelligence with the physical \nintelligence, I think that’s just logical.\nMARTIN FORD: I want to ask you about progress toward human-level AI or AGI. \nFirst of all, do you think it’s a realistic objective?\nCYNTHIA BREAZEAL: I think the question actually is, what is the real-world impact \nwe want to achieve? I think there is the scientific question and challenge of wanting \nto understand human intelligence, and one way of trying to understand human \nintelligence is to model it and to put it in technologies that can be manifested in \nthe world, and trying to understand how well the behavior and capabilities of these \nsystems mirror what people do. \nThen, there’s the real-world application question of what value are these systems \nsupposed to be bringing to people? For me, the question has always been about how \nyou design these intelligent machines that dovetail with people—with the way we \nbehave, the way we make decisions, and the way we experience the world—so that by \nworking together with these machines we can build a better life and a better world. \nDo these robots have to be exactly human to do that? I don’t think so. We already \nhave a lot of people. The question is what’s the synergy, what’s the complementarity, \nwhat’s the augmentation that allows us to extend our human capabilities in terms of \nwhat we do that allows us to really have greater impact in the world. \nThat’s my own personal interest and passion; understanding how you design for \nthe complementary partnership. It doesn’t mean I have to build robots that are \nexactly human. In fact, I feel I have already got the human part of the team, and \nnow I’m trying to figure out how to build the robot part of the team that can \nactually enhance the human part of the team. As we do these things, we have to \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 635
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n456\nthink about what people need in order to be able to live fulfilling lives and feel that \nthere’s upward mobility and that they and their families can flourish and live with \ndignity. So, however we design and apply these machines needs to be done in a way \nthat supports both our ethical and human values. People need to feel that they can \ncontribute to their community. You don’t want machines that do everything because \nthat’s not going to allow for human flourishing. If the goal is human flourishing, \nthat gives some pretty important constraints in terms of what is the nature of that \nrelationship and that collaboration to make that happen.\nMARTIN FORD: What are some of the breakthroughs that need to take place in \norder to reach AGI?\nCYNTHIA BREAZEAL: What we know how to do today is to build special-purpose \nAI that, with sufficient human expertise, we can craft, and hone, and polish so that \nit can exceed human intelligence with narrow domains. Those AIs, however, can’t \ndo multiple things that require fundamentally different kinds of intelligence. We \ndon’t know how to build a machine that can develop in the same way as a child \nand grow and expand its intelligence in an ongoing way. \nWe have had some recent breakthroughs with deep learning, which is a supervised \nlearning method. People learn in all kinds of ways, though. We haven’t seen the \nsame breakthrough in machines that can learn from real-time experience. People \ncan learn from very few examples and generalize. We don’t know how to build \nmachines that can do that. We don’t know how to build machines that have \nhuman-level common sense. We can build machines that can have knowledge and \ninformation within domains, but we don’t know how to do the kind of common \nsense we all take for granted. We don’t know how to build a machine with deep \nemotional intelligence. We don’t know how to build a machine that has a deep \ntheory of mind. The list goes on. There’s a lot of science to be done, and in \nthe process of trying to figure these things out we’re going to come to a deeper \nappreciation and understanding of how we are intelligent. \nMARTIN FORD: Let’s talk about some of the potential downsides, the risks and the \nthings we should legitimately worry about.\nCYNTHIA BREAZEAL: The real risks right now that I see have to do with people \nwith nefarious intents using these technologies to hurt people. I am not nearly \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 636
  },
  {
    "chunk_full": "CYNTHIA BREAZEAL\n457\nas concerned about superintelligence enslaving humanity as I am around people \nusing the technology to do harm. AI is a tool, and you can apply it to both benefit \nand help people, but also to hurt people or to privilege one group of people over \nothers. There’s a lot of legitimate concern around privacy and security because \nthat’s tied to our freedom. There is a lot of concern around democracy and what \ndo you do when we have fake news and bots proliferating falsehoods, and people \nare struggling to understand what’s true and to have a common ground. Those \nare very real risks. There are real risks around autonomous weapons. There’s also \na question of a growing AI gap where AI exacerbates the divide instead of closing \nit. We need to start working on making AI far more democratized and inclusive \nso we have a future where AI can truly benefit everyone, not just a few. \nMARTIN FORD: But are superintelligence and the alignment or control problem \nultimately real concerns, even if they lie far in the future? \nCYNTHIA BREAZEAL: Well, you have to then really get down to the brass tacks \nof what do you mean by super intelligence, because it could mean a lot of different \nthings. If it is a superintelligence, why are we assuming the same evolutionary \nforces that drove the creation of our motivations and drives would be anything \nlike those of the super intelligence? A lot of the fear I hear is basically mapping \nonto AI our human baggage that we evolved with to survive in a hostile complex \nworld with competitive others. Why assume that a super intelligence is going to \nbe saddled with the same machinery? It’s not human, so why would it be? \nWhat are the practical driving forces to create that? Who’s going to build it and \nwhy? Who’s going to invest the time and effort and money? Will it be universities \nor will it be corporations? You’ve got to think about the practicalities of what are \nthe societal and economic drivers that would lead to the creation of something like \nthat. It’s going to require enormous amounts of talent and funding and people in \norder to do that instead of working on something else important.\nMARTIN FORD: There is definitely a lot of interest. People like Demis Hassabis \nat DeepMind, are definitely interested in building AGI, or at least getting much \ncloser to it. It’s their stated goal.\nCYNTHIA BREAZEAL: People may be interested in building it, but where are the \nresources, time, and talent coming from at massive scale? My question is, what are \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 637
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n458\nthe actual societal driving conditions and forces that would lead to the investment \nnecessary to create that versus what we see now? I’m just asking a very practical \nquestion. Think about what the path is given the amount of investment it’s going \nto take to get there. What is the driver that’s going to lead to that? I don’t see the \nmotivation of agencies or entities to fund what it’s going to take to achieve real \nsuperhuman AGI right now.\nMARTIN FORD: One potential driver of interest and investment might be the \nperceived AI arms race with China, and perhaps other countries as well. AI does \nhave applications in the military and security space, so is that a concern? \nCYNTHIA BREAZEAL: I think we’re always going to be in a race with other \ncountries around technology and resources, that’s just the way it is. That doesn’t \nnecessitate leading to general-purpose intelligence; everything you’ve just said \nwouldn’t necessarily require general intelligence, they could be broader, more \nflexible, but still more bounded AI.\nAll I’m pushing on is that there’s the general super intelligence thing versus what the \ndriving forces are right now by the entities that can fuel the work and the people and \nthe talent to work on those problems. I see much more reason and rationale for the \nmore domained aspects of AI versus the true general super intelligence. Certainly, \nwithin academia and research, people are absolutely very interested in creating that \nand people will continue to work on it. But when you get to the brass tacks of \nresources and time, talent, and patience for a very long-term commitment to do \nthat, it’s not obvious to me who’s going to push that forward in a very practical sense \njust by the nature of who’s going to provide those resources. I don’t see that yet.\nMARTIN FORD: What do you think about the potential impact on the job market? \nAre we on the leading edge of a new Industrial Revolution? Is there potential for \na massive impact on employment or on the economy?\nCYNTHIA BREAZEAL: AI is a powerful tool that can accelerate technology-driven \nchange. It’s something that right now very few people know how to design, and \nvery few entities have the expertise and resources to be able to deploy it. We’re \nliving in a time where there is a growing social-economic divide, where I feel that \none of my biggest concerns is whether AI is going to be applied to close that divide \nor exacerbate it. If only a few people know how to develop it, design with it, and \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 638
  },
  {
    "chunk_full": "CYNTHIA BREAZEAL\n459\ncan apply it to the problems they care about, you’ve got a hell of a lot of people \nin the world who aren’t going to be able to really benefit from that.\nOne solution to democratizing the benefit of AI to everyone is through education. \nRight now, I have put significant effort in trying to address things like K-12 AI. \nToday’s children are growing up with AI; they’re no longer digital natives, they \nare now AI natives. They’re growing up in a time when they will have always been \nable to interact with intelligent machines, so it’s imperative these not be black \nbox systems to them. Today’s children need to start to be educated about these \ntechnologies, to be able to create things with these technologies, and in doing that, \ngrow up with an attitude of empowerment so that they can apply these technologies \nand solve problems that matter to them and their community on a global scale. In \nan increasingly AI-powered society, we need an AI-literate society. This is something \nthat has to happen, and from the industry standpoint, there’s already a shortage of \nhighly qualified people with this level of expertise, you can’t hire these people fast \nenough. People’s fears about AI can be manipulated because they don’t understand it.\nEven from that standpoint, I think there’s a lot of stakeholder interest from the \ncurrent organizations in wanting to open the tent and be much more inclusive \nto a much broader diversity of people who can develop that expertise and that \nunderstanding. Just like you can have early math and early literacy, I think you \ncan have early AI. It’s about understanding what’s the level of curriculum, the \nsophistication of concepts and hands-on activities and communities so that students \ncan grow up with more levels of sophistication about understanding AI and making \nstuff with AI. They don’t have to wait until university to be able to get access to \nthis stuff. We need to have a much broader diversity of people able to understand \nand apply these technologies to problems that matter to them.\nMARTIN FORD: You seem to be focusing on people headed toward professional \nor technical careers, but most people are not college graduates. There could be a \nhuge impact on jobs like driving a truck or working in a fast food restaurant, for \nexample. Do we need policies to address that?\nCYNTHIA BREAZEAL: I think clearly there’s going to be disruption, and I think that \nright now, the big one people talk about is autonomous vehicles. There’s disruption, \nand the problem is that those people whose jobs either change or get displaced \nneed to be trained so that they can continue to be competitive in the workforce. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 639
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n460\nAI can also be applied to retrain people in an affordable, scalable way to keep our \nworkforce vibrant. AI education can be developed for vocational programs. For me, \none of the big AI application areas that we should be focusing on is AI education and \npersonalized education systems. A lot of people can’t afford to have a personal tutor \nor to go to an institution to get educated. If you could leverage AI to make access \nto those skills, knowledge, and capabilities much more scalable and affordable, then \nyou’re going to have way more people who are going to be much more agile and \nresilient over their lifetime. To me, that just argues that we need to double down \nand really think about the role of AI in empowering people and helping our citizens \nto be resilient and adaptive to the reality of jobs that continue to be changing.\nMARTIN FORD: How do you feel about regulation of the AI field? Is that something \nyou would support going forward?\nCYNTHIA BREAZEAL: In my particular research field it’s still pretty early. We need \nto understand it more before you could come up with any policies or regulations \nthat would be sensible for social robots. I do feel that the dialogs that are happening \nright now around AI are absolutely important ones to have, because we’re starting \nto see some major unintended consequences. We need to have a serious ongoing \ndialog to figure these things out, and we get down to privacy, security and all of \nthese things, which are critically important. \nFor me, it really just gets down to the specifics. I think we’re going to start with \na few high-impact areas, and then maybe from that experience we will be able to \nthink more broadly about what the right thing to do is. You’re obviously trying to \nbalance the ability to ensure human values and civil rights are supported with these \ntechnologies, as well as wanting to support innovation to open up opportunities. \nIt’s always that balancing act, and so, to me, it gets down to the specifics of how \nyou walk that line so that you achieve both of those goals.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 640
  },
  {
    "chunk_full": "CYNTHIA BREAZEAL\n461\nCYNTHIA BREAZEAL is an Associate Professor of Media Arts and Sciences at the Massachusetts \nInstitute of Technology where she founded and directs the Personal Robots Group at the Media \nLab. She is also founder of Jibo, Inc. She is a pioneer of social robotics and human robot \ninteraction. She authored the book Designing Sociable Robots, and she has published over \n200 peer-reviewed articles in journals and conferences on the topics of social robotics, human-\nrobot interaction, autonomous robotics, artificial intelligence, and robot learning. She serves on \nseveral editorial boards in the areas of autonomous robots, affective computing, entertainment \ntechnology and multi-agent systems. She is also an Overseer at the Museum of Science, Boston.\nHer research focuses on developing the principles, techniques, and technologies for personal \nrobots that are socially intelligent, interact and communicate with people in human-centric \nterms, work with humans as peers, and learn from people as an apprentice. She has developed \nsome of the world’s most famous robotic creatures, ranging from small hexapod robots, to \nembedding robotic technologies into familiar everyday artifacts, to creating highly expressive \nhumanoid robots and robot characters. \nCynthia is recognized as a prominent global innovator, designer and entrepreneur. She is a \nrecipient of the National Academy of Engineering’s Gilbreth Lecture Award and an ONR \nYoung Investigator Award. She has received Technology Review’s TR100/35 Award, and \nTIME magazine’s Best Inventions of 2008 and 2017. She has received numerous design \nawards, including being named a finalist in the National Design Awards in Communication. \nIn 2014 she was recognized as an entrepreneur as Fortune Magazine’s Most Promising \nWomen Entrepreneurs, and she was also a recipient of the L’Oréal USA Women in Digital \nNEXT Generation Award. The same year, she received the 2014 George R. Stibitz Computer \nand Communications Pioneer Award for seminal contributions to the development of social \nrobotics and human-robot interaction.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 641
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n462\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 642
  },
  {
    "chunk_full": "JOSHUA TENENBAUM\n463\nJOSHUA TENENBAUM\nPROFESSOR OF COMPUTATIONAL COGNITIVE SCIENCE, MIT \nJosh Tenenbaum is Professor of Computational Cognitive Science in the \nDepartment of Brain and Cognitive Sciences at the Massachusetts Institute of \nTechnology. He studies learning and reasoning in humans and machines, with \nthe twin goals of understanding human intelligence in computational terms and \nbringing artificial intelligence closer to human-level capacities. He describes his \nresearch as an attempt to “reverse engineer the human mind” and to answer the \nquestion “How do humans learn so much from so little?”\nIf we could just get something at the level of the  \nmind of a one-and-a-half-year-old into the robotic  \nhardware that we already have, that would be  \nincredibly useful as a technology.\n“ \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 643
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n464\nMARTIN FORD: Let’s begin by talking about AGI or human-level AI. Do you consider \nthat to be feasible and something that we will ultimately achieve? \nJOSH TENENBAUM: Let’s be concrete about what we mean by that. Do you mean \nsomething like an android robot, similar to C-3PO or Commander Data?\nMARTIN FORD: Not necessarily in terms of being able to walk around and \nmanipulate things physically, but an intelligence that can clearly pass a Turing test \nwith no time limit. Something you could have a wide-ranging conversation with for \nhours, so that you’d be convinced that it’s genuinely intelligent. \nJOSH TENENBAUM: Yes, I think it’s completely possible. Whether or when we \nwill build it is hard to know, because that all depends on choices that we make as \nindividuals in society. It’s definitely possible, though—our brains and our existence \nprove that you can have machines that do this.\nMARTIN FORD: What does progress toward AGI look like? What are the most \nimportant hurdles that you think we would need to overcome to reach that point?\nJOSH TENENBAUM: One question is whether it’s possible, but the other question is \nwhat version of it is most interesting or desirable? That has a lot to do with what is \nlikely to happen sooner, because we can decide which versions of AGI are interesting \nand desirable and we can pursue those. I’m not actively working on machines that \nwill do what you’re saying—that will just be a disembodied language system that you \ncan talk to for hours. I think it’s exactly right to say that the system must reach the \nheights of human intelligence to have that kind of conversation. What we mean by \nintelligence is inextricably linked to our linguistic ability—our ability to communicate \nand to express our thoughts to others, and to ourselves, using the tools of language. \nLanguage is absolutely at the heart of human intelligence, but I think that we have \nto start with the earlier stages of intelligence that are there before language, but that \nlanguage builds on. If I was to sketch out a high-level roadmap to building some form \nof AGI of the sort you’re talking about, I would say you could roughly divide it into \nthree stages corresponding to three rough stages of human cognitive development. \nThe first stage, is basically the first year and a half of a child’s life, which is building \nall the intelligence we have prior to really being linguistic creatures. The main \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 644
  },
  {
    "chunk_full": "JOSHUA TENENBAUM\n465\nachievement is to develop a common-sense understanding of the physical world and \nother people’s actions. What we call intuitive physics, intuitive psychology: goals, \nplans, tools, and the concepts around those. The second stage, from about one and \na half to three, is to use that foundation to build language, to really understand \nhow phrases work, and to be able to construct sentences. Then, there’s the third \nstage, from the age of three and up, which is now you’ve built language, use \nlanguage to build and learn everything else.\nSo, when you talk about an AGI system that can pass a Turing test, and that you \ncould have conversations with for hours, I would agree that reflects in some sense \nthe height of human intelligence. However, my view is that it’s most interesting \nand valuable to get there by going through these other stages. Both because that’s \nhow we’re going to understand the construction of human intelligence, and because \nI think if we’re using human intelligence and its development as a guide and an \ninspiration for AI, then that’s the way to do it. \nMARTIN FORD: Very often, we think about AGI in binary terms: either we’ve \ngot true human-level intelligence, or else it’s just narrow AI of the type that we \nhave now. I think that what you are saying is that there might be a big middle \nground there, is that right?\nJOSH TENENBAUM: Yes. For example, in talks, I often show videos of 18-month-\nold humans doing remarkably intelligent things, and it’s very clear to me that if we \ncould build a robot that had the intelligence of a one-and-a-half-year-old, I would \ncall that a kind of AGI. It’s not adult-human level, but one and a half-year-olds have \na flexible general-purpose understanding of the world that they live in, which is \nnot the same world that adults live in.\nYou and I live in a world that extends backward in time thousands of years to the \nearliest recorded human history, and we can imagine hundreds of years forward \ninto the future. We live in a world that includes many different cultures that we \nunderstand because we’ve heard about them and we’ve read about them. The typical \none-and-a-half-year-old doesn’t live in that world, because we only have access to \nthat world through language. And yet, in the world that they live in, in the world of \ntheir immediate spatial and temporal environment, they do have a flexible, general-\npurpose, common-sense intelligence. That, to me, is the first thing to understand, \nand if we could build a robot that had that level of intelligence, it would be amazing. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 645
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n466\nIf you look at today’s robots, robotics on the hardware side is making great progress. \nBasic control algorithms allow robots to walk around. You only have to think about \nBoston Dynamics, which was founded by Mark Raibert. Have you heard about them?\nMARTIN FORD: Yeah. I’ve seen the videos of their robots walking and opening \ndoors and so forth.\nJOSH TENENBAUM: That stuff is real, that’s biologically inspired. Mark Raibert \nalways wanted to understand legged locomotion in animals, as well as in humans, \nand he was part of a field that built engineering models of how biological systems \nwalked. He also understood that the best way to test those models was to build \nreal robots and to see how biological legged locomotion worked. He realized that \nin order to test that idea, he needed the resources of a company to actually make \nthose things. So, that’s what led to Boston Dynamics. \nAt this point, whether it’s Boston Dynamics or other robots, such as Rodney \nBrooks’ work with the Baxter Robots, we’ve seen these robots do impressive \nthings with their bodies, like pick up objects and open doors, yet their minds \nand brains hardly exist at all. The Boston Dynamics robots are mostly steered \nby a human with a joystick, and the human mind is setting their high-level goals \nand plans. If we could just get something at the level of the mind of a one-and-\na-half-year-old into the robotic hardware that we already have, that would be \nincredibly useful as a technology.\nMARTIN FORD: Who would you point to as being at the absolute forefront of \nprogress toward AGI now? Is DeepMind the primary candidate, or are there other \ninitiatives out there that you think are demonstrating remarkable progress?\nJOSH TENENBAUM: Well, I think we’re at the forefront, but everybody does what \nthey do because they think it’s the right approach. That being said, I have a lot of \nrespect for what DeepMind is doing. They certainly do a lot of cool things and \nget a lot of well-deserved attention for what they’re doing, motivated by trying \nto build AGI. But I do have a different view than they do about the right way to \napproach more human-like AI. \nDeepMind is a big company, and they represent a diversity of opinion, but in general, \ntheir center of gravity is on building systems that are trying to learn everything from \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 646
  },
  {
    "chunk_full": "JOSHUA TENENBAUM\n467\nscratch, which is just not the way humans work. Humans, like other animals, are \nborn with a lot of structure in our brains just like in our bodies, and my approach \nis to be more inspired by human cognitive development in that way. \nThere are some people within DeepMind who think similarly, but the focus of \nwhat the company has been doing, and really the ethos of deep learning, is that \nwe should learn as much as we can from scratch, and that’s the basis for building \nthe most robust AI systems. That’s something that I just think is not true. I think \nthat’s a story that people tell themselves, and I think it’s not the way biology works. \nMARTIN FORD: It seems clear that you believe there’s a lot of synergy between AI \nand neuroscience. How did your interest in the two fields evolve?\nJOSH TENENBAUM: Both of my parents were deeply interested in things that \nrelated to intelligence and AI. My father, Jay Tenenbaum—often known as Marty, \nwas an early AI researcher. He was an MIT undergraduate and one of Stanford’s first \nPhDs in AI after John McCarthy went to set up the AI lab effort there. He was an \nearly leader in computer vision and one of the founders of AAAI, the professional \norganization for AI in America. He also ran an early industry AI lab. Essentially, as \na child I lived through the previous big wave of excitement in AI in the late 1970s \nand 1980s, which allowed me to go to AI conferences as a kid.\nWe grew up in the Bay Area, and one-time my father took us to Southern California \nbecause there was an Apple AI conference taking place, and this was in the Apple \nII era. I remember that Apple had bought out Disneyland for the evening for all \nof the attendees of the big AI conference. So, we flew down for the day just to be \nable to go on Pirates of the Caribbean 13 times in a row, which, looking back, tells \nyou something about just how big AI was even then. \nIt’s hyped now, but it was the same back then. There were startups, there were \nbig companies, and AI was going to change the world. Of course, that time-\nperiod didn’t lead to the kinds of successes that were promised in the short term. \nMy dad was also for a while director of the Schlumberger Palo Alto Research \nLab, a major industry AI lab. I hung out around there as a kid and through \nthat, I got to meet many great AI leaders. At the same time, my mother Bonnie \nTenenbaum was a teacher and got a PhD in education. She was very interested \nin kids’ learning and intelligence from that perspective and she would expose \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 647
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n468\nme to various puzzles and brainteasers—things that were not too different from \nsome of the problems we work on now in the AI field.\nI was always interested in thinking and intelligence while I was growing up, and so \nwhen I was looking at college, I thought I would major in philosophy or physics. I \nwound up as a physics major, but I never thought of myself as a physicist. I took \npsychology and philosophy classes, and I was interested in neural networks, which \nwere at the peak of their first wave in 1989 when I was at college. Back then, it \nseemed that if you wanted to study the brain or the mind, you had to learn how \nto apply math to the world, which is what people advertise physics as being about, \nso physics seemed like a generally good thing to do. \nI really got into the field in a serious way after taking a class on neural networks \nin my sophomore year in college, which would have been 1991. During that time, \nmy dad introduced me to a friend and colleague of his at Stanford named Roger \nShepard, who was one of the great cognitive psychologists of all time. Although \nhe’s long retired, he was one of the people who pioneered the scientific and \nmathematical study of mental processes through the 1960s, ‘70s, and ‘80s, when I \nworked with him. I wound up getting a summer job with him programming some \nneural network implementations of a theory that Roger had been working on. The \ntheory was of how humans, and many other organisms, solve the basic problem of \ngeneralization, which turned out to be an incredibly deep problem. \nPhilosophers have thought about this for hundreds, if not thousands, of years. Plato \nand Aristotle considered this, as did Hume, Mill, and Compton, not to mention many \n20th century philosophers of science. The basic problem is, how do we go beyond \nspecific experiences to general truths? Or from the past to the future? In the case \nthat Roger Shepard was thinking about, he was working on the basic mathematics of \nhow might an organism, having experienced a certain stimulus to have some good \nor negative consequence, figure out which other things in the world are likely to \nhave that same consequence? \nRoger had introduced some mathematics based on Bayesian statistics for solving \nthat problem, which was a very elegant formulation of the general theory of how \norganisms could generalize from experience and he was looking to neural networks \nto try to take that theory and implement it in a more scalable way. Somehow, I \nwound up working with him on this project. Through that, I was exposed to both \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 648
  },
  {
    "chunk_full": "JOSHUA TENENBAUM\n469\nneural networks, as well as to Bayesian analyses of cognition early on, and you \ncan view most of my career since then as working through those same ideas and \nmethods. I was just very lucky to have been exposed to exciting ideas from great \nthinkers and people who wanted to work with me from an early age, and then that \nled to me going into graduate school in the field.\nI ended up going to graduate school at MIT—in the same department that I am \nnow a professor in. After my PhD, Roger was very supportive of me and helped to \nbring me to Stanford, where I spent a couple of years as an assistant professor in \npsychology before I moved back to MIT and Brain and Cognitive Science, where I \nam now. A key feature of this route is that I came to AI from the natural science \nside, thinking about how human minds and brains work, or biological intelligence \nmore generally. I was trying to understand human intelligence in mathematical, \ncomputational, and engineering terms. \nI describe what I do as “reverse engineering the mind,” and what that means is \ntrying to approach the basic science of how intelligence works in the human mind \nas an engineer. The goal is to understand and to build models in the language and \nwith the technical tools of engineering. We view the mind as an incredible machine \nthat has been engineered through various processes, such as both biological and \ncultural evolution, learning, and development, and is developed to solve problems. \nIf we approach it like an engineer to try to understand what problems it has been \ndesigned to solve and how it solves them, then we think that it is the best way that \nwe can formulate our science. \nMARTIN FORD: If you were advising a younger person who was considering a \ncareer in AI research, would you say that studying brain science and human \ncognition are important? Do you think that there is too much emphasis put on \npure computer science?\nJOSH TENENBAUM: I always saw these two things as being two sides of the same \ncoin; it just made sense to me. I was interested in computer programming, and \nI was interested in the idea that you could program an intelligent machine. But I \nwas just always more animated by what is clearly one of the biggest scientific and \neven philosophical questions of all time. The idea that it could be linked up and \nhave a common purpose with building intelligent machines was the most exciting \nidea, as well as being a promising one. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 649
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n470\nMy background training is not especially in biology, but more like what you might \ncall psychology or cognitive science. More about the software of the mind, rather \nthan the hardware of the brain, although the only reasonable scientific view is to see \nthose as being deeply connected because, of course, they are. That’s partly what led \nme to MIT, where we have this department of Brain and Cognitive Science. In the \nmid-1980s, it used to be called the Department of Psychology, but it was always a \nvery biologically grounded psychology department. \nTo me, the most interesting and biggest questions are the scientific ones. The \nengineering side is a way toward building more intelligent machines, but to me \nthe value of that is as a proof of concept that our scientific models are doing the \nwork they’re supposed to be doing. It’s a very important test, a sanity check, \nand rigor check because there are so many models on the scientific side that may \nfit a data set that somebody collected on human behavior or neural data, but if \nthose models don’t solve the problem that the brain and the mind must solve, \nthen they probably aren’t right.\nTo me it’s always been an important source of constraint that we want our models \nof how the brain and mind work to actually fit with all of the data that we have \non the scientific side, but also to actually be implementable as engineering models \nthat take the same kind of inputs that come into the brain and gives the same kind \nof outputs. That is also going to lead to all sorts of applications and payoffs. If \nwe can understand how intelligence works in the mind and brain in engineering \nterms, then that is one direct route for translating the insights from neuroscience \nand cognitive science into various kinds of AI technologies. \nMore generally, I think that if you approach science like an engineer, and you say \nthe point of neuroscience and cognitive science is not just to collect a bunch of \ndata, but to understand the basic principles—the engineering principle by which \nbrains and minds work—then that’s a certain viewpoint on how to do the science, \nbut then your insights are directly translatable into useful ideas for AI.\nIf you look at the history of the field, I think it’s not unreasonable to say that \nmany, if not most, of the best, interesting, new, and original ideas in artificial \nintelligence came from people who were trying to understand how human \nintelligence works. That includes the basic mathematics of what we now call \ndeep learning and reinforcement learning, but also much further back to Boole as \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 650
  },
  {
    "chunk_full": "JOSHUA TENENBAUM\n471\none of the inventors of mathematical logic, or Laplace in his work on probability \ntheory. In more recent times, Judea Pearl, in particular, was fundamentally \ninterested in understanding the mathematics of cognition and the way people \nreason under uncertainty and that led to his seminal work on Bayesian networks \nfor probabilistic inference and causal modeling in AI. \nMARTIN FORD: You described your work as an attempt to “reverse engineer the \nmind.” Tell me about your actual methodology for attempting that. How are you \ngoing about it? I know you do a lot of work with children.\nJOSH TENENBAUM: In the first part of my career, the big question that I would always \nstart from and come back to was the question of, how do we get so much from so \nlittle? How do humans learn concepts not from hundreds or thousands of examples, \nas machine learning systems have always been built for, but from just one example?\nYou can see that in adults, but you can also see that in children when they are \nlearning the meaning of a word. Children can often learn a new word from seeing \njust one example of that word used in the right context, whether it’s a word like \na noun that refers to an object, or a verb that refers to an action. You can show a \nyoung child their first giraffe, and now they know what a giraffe looks like; you \ncan show them a new gesture or dance move, or how you use a new tool, and \nright away they’ve got it; they may not be able to make that move themselves, or \nuse that tool, but they start to grasp what’s going on.\nOr think about learning causality, for example. We learn in basic statistics classes \nthat correlation and causation are not the same thing, and correlation doesn’t always \nimply causation. You can take a dataset, and you can measure that the two variables \nare correlated, but it doesn’t mean that one causes the other. It could be that A \ncauses B, B causes A, or some third variable causes both.\nThe fact that correlation doesn’t uniquely imply causation is often cited to show how \ndifficult it is to take observational data and infer the underlying causal structure of \nthe world, and yet humans do this. In fact, we solve a much harder version of this \nproblem. Even young children can often infer a new causal relation from just one \nor a few examples—they don’t even need to see enough data to detect a statistically \nsignificant correlation. Think about the first time you saw a smartphone, whether \nit was an iPhone or some other device with a touchscreen where somebody swipes \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 651
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n472\ntheir finger across a little glass panel, and suddenly something lights up or moves. \nYou had never seen anything like that before, but you only need to see that once \nor a couple of times to understand that there’s this new causal relation, and then \nthat’s just your first step into learning how to control it and to get all sorts of useful \nthings done. Even a very young child can learn this new causal relation between \nmoving your finger in a certain way and a screen lighting up, and that is how all \nsorts of other possibilities of action open to you. \nThese problems of how we make a generalization from just one or a few examples \nare what I started working on with Roger Shepard when I was just an undergraduate. \nEarly on, we used these ideas from Bayesian statistics, Bayesian inference, and \nBayesian networks, to use the mathematics of probability theory to formulate how \npeople’s mental models of the causal structure of the world might work.\nIt turns out that tools that were developed by mathematicians, physicists, and \nstatisticians to make inferences from very sparse data in a statistical setting were \nbeing deployed in the 1990s in machine learning and AI, and it revolutionized the \nfield. It was part of the move from an earlier symbolic paradigm for AI to a more \nstatistical paradigm. To me, that was a very, very powerful way to think about how \nour minds were able to make inferences from sparse data.\nIn the last ten years or so, our interests have turned more to where these mental \nmodels come from. We’re looking at the minds and brains of babies and young \nchildren, and really trying to understand the most basic kind of learning processes \nthat build our basic common-sense understanding of the world. For the first ten \nyears or so of my career, so from the late 1990s until the late 2000s, we made a \nlot of progress modeling individual aspects of cognition using these Bayesian models, \nsuch as certain aspects of perception, causal reasoning, how people judge similarity, \nhow people learn the meanings of words, and how people make certain kinds of \nplans, decisions, or understand other people’s decisions, and so on. \nHowever, it seemed like we still didn’t really have a handle on what intelligence is \nreally about—a flexible, general-purpose intelligence that allows you to do all of \nthose things that you can do. 10 years ago in cognitive science, we had a bunch of \nreally satisfying models of individual cognitive capacities using this mathematics of \nways people made inferences from sparse data, but we didn’t have a unifying theory. \nWe had tools, but we didn’t have any kind of model of common sense. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 652
  },
  {
    "chunk_full": "JOSHUA TENENBAUM\n473\nIf you look at machine learning and AI technologies, and this is as true now as it \nwas ten years ago, we were increasingly getting machine systems that did remarkable \nthings that we used to think only humans could do. In that sense, we had real AI, \nin the sense of these AI technologies, but we didn’t have any real AI. We still don’t \nhave any real AI in the sense of the original vision of the founders of the field, \nof what I think you might refer to as AGI—machines that have that same kind of \nflexible, general-purpose, common sense intelligence that every human uses to solve \nproblems for themselves. But we are starting to lay the foundations for that now.\nMARTIN FORD: Is AGI something that you’re focused on?\nJOSH TENENBAUM: Yes, in the last few years general-purpose intelligence has really \nbeen what I’ve been interested in. I’m trying to understand what that would be like, \nand how we could capture that in engineering terms. I’ve been heavily influenced \nby a few colleagues like Susan Carey, and Elizabeth Spelke, who are both professors \nat Harvard now, who studied these questions in babies and young children. I believe \nthat’s where we ought to look for this, it’s what all our intelligence starts with and \nit’s where our deepest and most interesting forms of learning happen. \nElizabeth Spelke is one of the most important people that anybody in AI should \nknow if they’re going to look to humans. She has very famously shown that from \nthe age of two to three months, babies already understand certain basic things \nabout the world, like how it’s made from physical objects in three dimensions that \ndon’t wink in and out of existence. It’s what we typically call object permanence. \nIt used to be thought that that was something that kids came to and learned by the \ntime they were one year old, but Spelke and others have shown that in many ways \nour brains are born already prepared to understand the world in terms of physical \nobjects, and in terms of what we call intentional agents. \nMARTIN FORD: There’s a debate over the importance of innate structure in AI. Is \nthis evidence that that kind of structure is very important?\nJOSH TENENBAUM: The idea that you could build machine intelligence by looking \nat how humans grow into intelligence—a machine that starts as a baby and learns \nlike a child—was famously introduced by Alan Turing in the same paper where he \nintroduced the Turing test, so it could really be the oldest good idea in AI. Back \nin 1950, this was Turing’s only suggestion on how you might build a machine that \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 653
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n474\nwould pass a Turing test because back then nobody knew how to do that. Turing \nsuggested that instead of trying to build a machine brain that was like an adult, we \nmight build a child brain and then teach it the way we teach children.\nIn making his proposal, Turing was effectively taking a position on the nature-nurture \nquestion. His thinking was that children’s brains presumably start off much simpler \nthan adults’ brains. He said, more or less, “Presumably a child’s brain is something \nlike a notebook when you buy it from the stationers: a rather little mechanism, \nand lots of blank sheets.” So, building a child machine would be a sensible starting \nplace on a scaling route to AI. Turing was probably right there. But he didn’t \nknow what we know now about the actual starting state of the human mind. What \nwe now from the work of people like Elizabeth Spelke, Renee Baillargeon, Laura \nSchulz, Alison Gopnik, and Susan Carey is that babies start off with a lot more \nstructure than we might have thought. We also know that the learning mechanisms \nthat children have are a lot smarter and more sophisticated. So, in some sense, our \ncurrent understanding from the scientific side is that the possibilities of both nature \nand nurture are more than we thought when the notion of AI was first proposed.\nIf you look at not just Turing’s suggestions, but the way many AI people have since \ninvoked that idea, you know that they are not looking at the real science of how \nbabies’ brains work, rather they’re appealing to that intuitive, but incorrect, idea that \nbabies’ brains start off very simple, or that some kind of simple trial and error or \nunsupervised learning takes place. These are often ways that people in AI will talk \nabout how children learn. Children do learn from trial and error, and they do learn \nin an unsupervised way, but it’s much more sophisticated, especially the ways in \nwhich they learn from much less data and with much deeper kinds of understanding \nand explanatory frameworks. If you look at what machine learning usually means \nby trial and error learning or unsupervised learning, you’re still talking about very \ndata-hungry methods that learn relatively superficial kinds of patterns. \nI’ve been inspired by the insights coming from cognitive scientists and developmental \npsychologists trying to explain and understand what we see and how we imagine \nthings that we haven’t seen, how we make plans and solve problems in the course \nof trying to make those things actually exist, and how learning is about taking these \nmental models that guide our explaining, our understanding, our planning, and our \nimagining and refining them, debugging them, and building new models. Our minds \ndon’t just find patterns in big data.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 654
  },
  {
    "chunk_full": "JOSHUA TENENBAUM\n475\nMARTIN FORD: Is this what you’ve been focusing on in your recent work with children? \nJOSH TENENBAUM: Yes, I’m trying to understand the ways in which even young \nchildren are able to build models of the world in their heads from very sparse \ndata. It’s really fundamentally a different kind of approach than the one that most \nmachine learning right now is working on. To me, just as Turing suggested, and \njust as many people in AI have realized, it’s not the only way that you might think \nabout building a human-like AI system, but it’s the only way that we know works.\nIf you look at human children, they’re the only scaling path to AI in the known \nuniverse that we know works. A scaling path that reliably, reproducibly, and \nrobustly starts out knowing far less than a full adult human then develops into \nadult-human-level intelligence. If we could understand how humans learn, then \nthat would certainly be a route to building much more real AI. It would also \naddress some of the greatest scientific questions of all time that cut right to our \nidentity, like what it means to be human. \nMARTIN FORD: How does all of that thinking relate to the current overwhelming \nfocus on deep learning? Clearly, deep neural networks have transformed AI, but \nlately I’ve been hearing more pushback against deep learning hype, and even some \nsuggestions that we could be facing a new AI Winter. Is deep learning really the \nprimary path forward, or is it just one tool in the toolbox? \nJOSH TENENBAUM: What most people think of as deep learning is one tool in the \ntoolbox, and a lot of deep learning people realize that too. The term “deep learning” \nhas expanded beyond its original definition.\nMARTIN FORD: I would define deep learning broadly as any approach using \nsophisticated neural networks with lots of layers, rather than using a very technical \ndefinition involving specific algorithms like backpropagation or gradient descent. \nJOSH TENENBAUM: To me, the idea of using neural networks with lots of layers is also \njust one tool in the toolkit. What that’s good at is problems of pattern recognition, and \nit has proven to be a practical, scalable route for it. Where that kind of deep learning \nhas really had success is either in problems that are traditionally seen as pattern \nrecognition problems, like speech recognition and object recognition, or problems \nthat can be in some way coerced into or turned into pattern recognition problems. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 655
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n476\nTake Go for example. AI researchers have long believed that playing Go would \nrequire some kind of sophisticated pattern recognition, but they didn’t necessarily \nunderstand that it could be solved using the same kind of pattern recognition \napproaches you would use for perception problems in vision and speech. However, \nnow people have shown that you can take neural networks, the same kind that were \ndeveloped in those more traditional pattern recognition domains, and you can use \nthem as part of a solution to playing Go, as well as chess, or similar board games. I \nthink those are interesting models because they use what we’re calling deep learning \nhere, but they don’t just do that, they also use traditional game tree search and \nexpected value calculations, and so on. AlphaGo is the most striking and best-known \nsuccess of deep learning AI, and it’s not even a pure deep learning system. It uses \ndeep learning as part of a system for playing a game and searching a game tree.\nThat already represents the way that deep learning expands beyond deep neural \nnetworks, but still, the secret sauce that makes it work so well is a deep neural \nnetwork and the methods of training it. Those methods are finding patterns in \nthe structure of gameplay that go way beyond the patterns people were able to \nfind in an automatic way before. If you look beyond any one task, like playing Go \nor playing chess, to the broader problems of intelligence, though, the idea that \nyou’re going to turn all of the intelligence into a pattern recognition problem is \nridiculous, and I don’t think any serious person can believe that. I mean maybe \nsome people will say that, but that just seems crazy to me. \nEvery serious AI researcher has to think two things simultaneously. One is they have \nto recognize that deep learning and deep neural networks have contributed a huge \namount to what we can do with pattern recognition, and that pattern recognition \nis going to be a part of probably any intelligent system’s success. At the same time, \nyou also have to recognize that intelligence goes way beyond pattern recognition \nin all the ways I was talking about. There are all these activities of modeling the \nworld, such as explaining, understanding, imagining, planning, and building out new \nmodels, and deep neural networks don’t really address that. \nMARTIN FORD: Is that limitation one of the things you’re addressing in your work?\nJOSH TENENBAUM: Well, with my work I’ve been interested in finding the other \nkinds of engineering tools that we need to address the aspects of intelligence that \ngo beyond pattern recognition. One of the approaches is to look to earlier waves \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 656
  },
  {
    "chunk_full": "JOSHUA TENENBAUM\n477\nof ideas in the field, including the ideas of graphical models and Bayesian networks, \nwhich were the big thing when I got into the field. Judea Pearl is probably the most \nimportant name associated with that era of the field. \nPerhaps most important of all is the earliest wave, often called “symbolic AI,” Many \npeople will tell a story that in the early days of AI we thought intelligence was \nsymbolic, but then we learned that was a terrible idea. It didn’t work, because \nit was too brittle, couldn’t handle noise and couldn’t learn from experience. So \nwe had to get statistical, and then we had to get neural. I think that’s very much \na false narrative. The early ideas that emphasize the power of symbolic reasoning \nand abstract languages expressed in formal systems were incredibly important and \ndeeply right ideas. I think it’s only now that we’re in the position, as a field, and \nas a community, to try to understand how to bring together the best insights and \nthe power of these different paradigms. \nThe three waves in the field of AI—the symbolic era, the probabilistic and causal \nera, and the neural networks era—are three of our best ideas on how to think \nabout intelligence computationally. Each of these ideas has had their rise and fall, \nwith each one contributing something, but neural networks have really had their \nbiggest successes in the last few years. I’ve been interested in how we bring these \nideas together. How do we combine the best of these ideas to build frameworks \nand languages for intelligent systems and for understanding human intelligence? \nMARTIN FORD: Do you imagine a hybrid that would bring together neural networks \nand other more traditional approaches to build something comprehensive?\nJOSH TENENBAUM: We don’t just imagine it, we actually have it. Right now, \nthe best examples of these hybrids go by the name of probabilistic programming. \nWhen I give talks or write papers, I often point to probabilistic programming as \nthe general tool that I’m using in my work. It’s one that some people know about. \nIt’s not nearly as broadly embraced to think about AI as neural networks are, but I \nthink it’s going to be increasingly recognized in its own form. \nAll these terms, like neural networks or probabilistic programming, are only vague \nterms that continually redefine themselves as the people working with these toolsets \nlearn more about what works, what doesn’t work, and what other things they need. \nWhen I talk about probabilistic programs, I sometimes like to say that they have \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 657
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n478\nabout as much to do with probability as neural networks have to do with neurons. \nNamely, neural networks were inspired by early abstractions of how a neuron \nworks, and the idea that if you wire neurons together into a network, whether it’s \nbiological or artificial, and you make that network complicated enough in certain \nways, that it becomes very powerful. The core meaning of a neuron stays around, \nthere are basic processing units that take linear combinations of their inputs and \npass them through a non-linearity, but if you look at the ways in which people are \nusing neural networks now, they go way beyond any kind of actual neuroscience \ninspiration. In fact, they bring ideas from probability and from symbolic programs \ninto them. I would say probabilistic programs are just approaching that same kind \nof synthesis but coming from a different direction. \nThe idea of probabilistic programs starts from work that people did in the 1990s \nwhere they tried to build systematic languages for large-scale probabilistic reasoning. \nPeople realized that you needed to have tools that didn’t just do probabilistic \nreasoning, but also had abstract, symbolic components that were more like earlier \neras of AI, in order to capture real common-sense knowledge. It wasn’t enough \nto work with numbers, you had to work with symbols. Real knowledge is not just \nabout trading off numbers for other numbers, which is what you do in probability \ntheory, it’s about expressing abstract knowledge in symbolic forms, whether it’s \nmath, programming languages, or logic. \nMARTIN FORD: So, this is the approach that you’ve been focusing on?\nJOSH TENENBAUM: Yes, I was very lucky to work with students and postdocs in \nmy group in the mid to late 2000s, especially Noah Goodman, Vikash Mansinghka, \nand Dan Roy, where we built a language that we called Church, named after Alonzo \nChurch. It was an example of bringing together higher-order logic languages based \non what we call the lambda calculus, which was Church’s framework for universal \ncomputation. That’s really the underlying formal basis of computer programming \nlanguages like Lisp and Scheme. \nWe took that formalism for representing abstract knowledge and used that to \ngeneralize patterns of probabilistic and causal reasoning. That turned out to be \nvery influential for both myself and others in terms of thinking about how to build \nsystems that had a common-sense reasoning capacity—systems that really reasoned \nand didn’t just find patterns in data, and that could have abstractions that could \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 658
  },
  {
    "chunk_full": "JOSHUA TENENBAUM\n479\ngeneralize across many situations. We used these systems to capture, for example, \npeople’s intuitive theory of mind—how we understand other people’s actions in \nterms of their beliefs and desires. \nUsing these tools of probabilistic programs over the last ten years, we were able to build \nfor the first time reasonable, quantitative, predictive, and conceptually correct models \nof how humans, even young children, understand what other people are doing, and see \npeople’s actions not just as movements in the world, but rather as the expressions of \nrational plans. We were also able to look how people can work backward from seeing \npeople move around in the world to figure out what they want and what they think, \nto infer their beliefs and desires. That’s an example of core common-sense reasoning \nthat even young babies engage in. It’s part of how they really break into intelligence; \nthey see other people doing something and they try to figure out why they are doing \nit and whether it’s a good guide for what they should do. To us, these were some of \nthe first really compelling applications of these ideas of probabilistic programs.\nMARTIN FORD: Can these probabilistic methods be integrated with deep learning?\nJOSH TENENBAUM: Yes, in the last couple of years, people have taken that \nsame toolset and started to weave in neural networks. A key challenge for these \nprobabilistic programs, as we were building them ten years ago and continue today, \nis that inference is difficult. You can write down probabilistic programs that capture \npeople’s mental models of the world, for example, their theory of mind or their \nintuitive physics, but actually getting these models to make inferences very fast from \nthe data that you might infer is a hard challenge algorithmically. People have been \nturning to neural networks and other kinds of pattern recognition technology as a \nway of speeding up inference in these systems. In the same way, you could think of \nhow AlphaGo uses deep learning to speed up inference and search in a game tree. \nIt’s still doing a search in the game tree, but it uses neural networks to make fast, \nquick, and intuitive guesses that guide its search.\nSimilarly, people are starting to use neural networks to find patterns in inference \nthat can speed up inferences in these probabilistic programs. The machinery of neural \nnetworks and the machinery of probabilistic programs are increasingly coming to \nlook a lot like each other. People are developing new kinds of AI programming \nlanguages that combine all these things, and you don’t have to decide which to use. \nThey’re all part of a single language framework at this point. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 659
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n480\nMARTIN FORD: When I talked to Geoff Hinton, I suggested a hybrid approach to \nhim, but he was very dismissive of that idea. I get the sense that people in the \ndeep learning camp are perhaps thinking not just in terms of an organism learning \nover a lifetime, but in terms of evolution. The human brain evolved over a very \nlong time, and in some earlier form or organism it must have been much closer to \nbeing a blank slate. So perhaps that offers support for the idea that any necessary \nstructure might naturally emerge?\nJOSH TENENBAUM: There’s no question that human intelligence is very much \nthe product of evolution, but by that, we also have to include biological evolution \nand cultural evolution too. A huge part of what we know, and how we know what \nwe know, comes from culture. It’s the accumulation of knowledge across multiple \ngenerations of humans in groups. There’s no question that a baby who just grew \nup on a desert island with no other humans around would be a lot less intelligent. \nWell, they might be just as intelligent in some sense, but they would know a lot \nless than we know. They would also in a strict sense be less intelligent because a \nlot of the ways in which we are intelligent, our systems of thinking—whether it’s \nmathematics, computer science, reasoning, or other systems of thought that we get \nthrough languages—are more generally the accumulation of many smart people \nover many generations. \nIt’s very clear when we look at our bodies that biological evolution has built \nincredibly complex structures with amazing functions. There’s no reason to think \nthat the brain is any different. When we look at the brain, it’s not as obvious what \nare the complex structures in the real neural networks that evolution has built, and \nit is not just a big blank slate mess of randomly wired connections. \nI don’t think any neuroscientist thinks that the brain is anything like a blank slate at \nthis point. Real biological inspiration has to take seriously that at least in any one \nindividual brain’s lifetime, there’s a huge amount of structure that’s built in, and \nthat structure includes both our most basic models for understanding the world, \nand also the learning algorithms that grow our models beyond that starting point. \nPart of what we get genetically, as well as culturally, are ways of learning that \nare much more powerful, much more flexible, and much faster than the kinds of \nlearning that we have in deep learning today. These methods allow us to learn \nfrom very few examples and to learn new things much more quickly. Anyone \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 660
  },
  {
    "chunk_full": "JOSHUA TENENBAUM\n481\nwho looks and takes seriously the way real human babies’ brains start and how \nchildren learn, has to think about that. \nMARTIN FORD: Do you think deep learning could succeed at achieving more general \nintelligence by modeling an evolutionary approach?\nJOSH TENENBAUM: Well, a number of people at DeepMind and others who follow \nthe deep reinforcement learning ethos would say they’re thinking about evolution \nin a more general sense, and that’s also a part of learning. They’d say their blank \nslate systems are not trying to capture what a baby does, but rather what evolution \nhas done over many generations.\nI think that’s a reasonable thing to say, but then my response to that would be to \nalso look to biology for inspiration, which is to say, okay, fine, but look at how \nevolution actually works. It doesn’t work by having a fixed network structure and \ndoing gradient descent in it, which is the way today’s deep learning algorithms \nwork; rather evolution actually builds complex structures, and that structure \nbuilding is essential for its power. \nEvolution does a lot of architecture search; it designs machines. It builds very \ndifferently, structured machines across different species or over multiple generations. \nWe can see this most obviously in bodies, but there’s no reason to think it’s any \ndifferent in brains. The idea that evolution builds complex structures that have \ncomplex functions, and it does it by a process which is very different to gradient \ndescent, but rather something more like search in the space of developmental \nprograms, is very inspiring to me. \nA lot of what we work on here is to think about how you view learning or evolution \nas something like search in a space of programs. The programs could be genetic \nprograms, or they could be cognitive-level programs for thinking. The point is, it \ndoesn’t look like gradient descent in a big fixed network architecture. You could \nsay, we’re going to just do deep learning in neural networks, and say that’s trying \nto capture what evolution does, and not what human babies do, but I don’t think \nit’s really what human babies or evolution does. \nIt is, however, a toolkit that has been highly optimized for, especially by the tech \nindustry. People have shown you can do valuable things with big neural networks \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 661
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n482\nwhen you amplify them with GPUs and then with big distributed computing \nresources. All the advances that you see from DeepMind or Google AI, to name \ntwo, are essentially enabled by these resources, and a great program of integrated \nsoftware and hardware engineering building them out specifically to optimize for \ndeep learning. The point I’m making is that when you have a technology that Silicon \nValley has invested a large amount of resources in optimizing for, it becomes very \npowerful. It makes sense for companies like Google to pursue that route to see \nwhere you can go with it. At the same time, I’m just saying when you look at how \nit works in biology, either in the lifetime of an individual human or over evolution, \nit really looks rather different from that. \nMARTIN FORD: What do you think of the idea of a machine being conscious? Is \nthat something that logically comes coupled with intelligence, or do you think that’s \nsomething entirely separate?\nJOSH TENENBAUM: That’s a hard thing to discuss because the notion of consciousness \nmeans many different things to different people. There are philosophers, as well as \ncognitive scientists and neuroscientists who study it in a very serious and in-depth \nway, and there’s no shared agreement on how to study it.\nMARTIN FORD: Let me rephrase it, do you think that a machine could have some sort \nof inner experience? Is that possible or likely or even required for general intelligence? \nJOSH TENENBAUM: The best way to answer that is to tease out two aspects of \nwhat we mean by consciousness. One is what people in philosophy have referred \nto as the sense of qualia or the sense of subjective experience that is very hard to \ncapture in any kind of formal system. Think of the redness of red; we all know \nthat red is one color and green is another color, and we also know that they feel \ndifferent. We take for granted that other people when they see red, they not only \ncall it red, but they experience subjectively the same thing we do. We know it’s \npossible to build a machine that has those kinds of subjective experiences because \nwe are machines and we have them. Whether we would have to do that, or \nwhether we would be able to do that in the machines that we’re trying to build \nright now, it’s very hard to say. \nThere’s another aspect of what we could call consciousness, which is what we might \nrefer to as the sense of self. We experience the world in a certain kind of unitary \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 662
  },
  {
    "chunk_full": "JOSHUA TENENBAUM\n483\nway, and we experience ourselves being in it. It’s much easier to say that those are \nessential to human-like intelligence. What I mean by this is that when we experience \nthe world, we don’t experience it in terms of tens of millions of cells firing.\nOne way to describe the state of your brain at any moment is at the level of what \neach neuron is doing, but that’s not how we subjectively experience the world. We \nexperience the world as consisting of objects, and all of our senses come together \ninto a unitary understanding of those things. That’s the way we experience the world, \nand we don’t know how to link that level of experience to neurons. I think if we’re \ngoing to build systems that are human-level intelligence, then they’re going to have \nto have that kind of unitary experience of the world. It needs to be at the level of \nobjects and agents, and not at the level of firings of neurons.\nA key part of that is the sense of self—that I’m here, and that I’m not just my \nbody. This is actually something that we’re actively working on in research right \nnow. I’m working with the philosopher Laurie Paul and a former student and \ncolleague of mine, Tomer Ullman, on a paper which is tentatively called Reverse \nEngineering the Self.\nMARTIN FORD: Along the same lines as reverse engineering the mind? \nJOSH TENENBAUM: Yes, it’s trying to take our reverse engineering approach and \nunderstand this one simple aspect of “self.” I call it simple, but it’s one small aspect \nof the big set of things you could mean by consciousness; to understand what is the \nbasic sense of self that humans have, and what would it mean to build a machine \nthis way. It’s a really interesting question. AI people, especially those who are \ninterested in AGI, will tell you that they are trying to build machines that think \nfor themselves or learn for themselves, but you should ask, “What does that mean \nto build a machine that actually thinks for itself or learns for itself?” Can you do \nthat unless it has a sense of self?\nIf we look at today’s systems in AI, whether it’s self-driving cars or systems like \nAlphaGo that in some sense are advertised as “learning for themselves.” They don’t \nactually have a self, that’s not part of them. They don’t really understand what \nthey’re doing, in the sense that I understand when I get into a car, and I’m in the \ncar, and I’m driving somewhere. If I played Go, I would understand that I’m playing \na game, and if I decide to learn Go, I’ve made a decision for myself. I might learn \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 663
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n484\nGo by asking someone to teach me; I might practice with myself or with others. \nI might even decide I want to become a professional Go player and go to the Go \nAcademy. Maybe I decide I’m really serious and I want to try to become one of \nthe best in the world. When a human becomes a world-class Go player, that’s how \nthey do it. They make a bunch of decisions for themselves very much guided by \ntheir sense of self at many different time scales. \nAt the moment we don’t have any notion like that in AI. We don’t have systems \nthat do anything for themselves, even at the high level. We don’t have systems that \nhave real goals the way a human has goals, rather we have systems that a human \nbuilt to achieve their goals. I think it’s absolutely essential that if we wanted to \nhave systems that have human-like, human-level AI, they would have to do a lot of \nthings for themselves that right now engineers are the ones doing, but I think it’s \npossible that they could do that. \nWe’re trying to understand in engineering terms what it is to make these large \ndecisions for an agent for itself to set up the problems that it’s trying to solve or \nthe learning problems that it is trying to solve, all of which are currently being \ndone by engineers. I think it’s likely that we would have to have machines like \nthat if they were going to be intelligent at the human level. I think it’s also a real \nquestion of whether we want to do that, because don’t have to do that. We can \ndecide what level of selfness or autonomy we really want to give to our machine \nsystems. They might well be able to do useful things for us without having the \nfull sense of self that humans have. That might be an important decision for us \nto make. We might think that’s the right way to go for technology and society. \nMARTIN FORD: I want to ask you about some of the potential risks associated with \nAI. What should we really be concerned about, both in the relatively near term \nand in the longer term, with regard to the impact that artificial intelligence could \nhave on society and the economy?\nJOSH TENENBAUM: Some of the risks that people have advertised a lot are that \nwe’ll see some kind of singularity, or superintelligent machines that take over the \nworld or have their own goals that are incompatible with human existence. It’s \npossible that could happen in the far future, but I’m not especially worried about \nthat, in part because of the things I was just talking about. We still don’t know \nhow to give machines any sense of self at all. The idea that they would decide for \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 664
  },
  {
    "chunk_full": "JOSHUA TENENBAUM\n485\nthemselves to take over the world at our expense is something that is so far down \nthe line, and there’s a lot of steps between now and then. \nHonestly, I’m a lot more worried about the shorter-term steps. I think between \nwhere we are right now, and any kind of human-level AGI, let alone super-human \nlevel, we are going to develop increasingly powerful algorithms, which can have all \nsorts of risks. These are algorithms that will be used by people for goals, some of \nwhich are good, and some of which are not good. Many of those not good goals \nare just people pursuing their own selfish ends, but some of them might actually \nbe evil or bad actors. Like any technology, they can be used for good, but they can \nalso be used for selfish purposes, and for evil or bad deeds. We should worry about \nthose things because these are very powerful technologies, which are already being \nused in all of these ways, for example, in machine learning. \nThe near-term risks that we need to think about are the ones that everybody’s \ntalking about. I wish I had good ideas on how to think about those, but I don’t. I \nthink that the broader AI community increasingly realizes that they need to think \nabout the near-term risks now, whether it’s about privacy or human rights. Even \ntopics like how AI or automation more generally is reshaping the economy and the \njob landscape. It’s much bigger than AI, it’s technology more broadly. \nIf we want to point to new challenges, I think one has to do with jobs, which is \nimportant. For pretty much all of human history, my understanding is that most \npeople found some kind of livelihood, whether it was hunting and gathering, \nfarming, working in a manufacturing plant, or whatever kind of business. You \nwould spend the first part of your life learning some things, including a trade or \nskills that would then set up some kind of livelihood for you, which you could \npursue until you died. You could develop a new skill set or change your line of \nwork, but you didn’t have to. \nNow, what we’re increasingly seeing is that technology is changing and has \nadvanced to the point that many jobs and livelihoods change or come into \nexistence or go out of existence on a faster time scale than an individual \nhuman adult work life. There was always technological change that made whole \nlines of work disappear, and others come to be, but it used to happen across \ngenerations. Now they’re happening within generations, which puts a different \nkind of stress on the workforce. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 665
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n486\nMore and more people will have to confront the fact that you can’t just learn \na certain set of skills and then use those to work for the rest of your life. You \nmight have to be continually retraining yourself because technology is changing. \nIt’s not just more advanced, but it’s advancing faster than it ever has. AI is part \nof that story, but it’s much bigger than just AI. I think those are things that we \nas a society have to think about.\nMARTIN FORD: Given that things could progress so rapidly, do you worry that \na lot of people inevitably are going to be left behind? Is a universal basic income \nsomething that we should be giving serious consideration to?\nJOSH TENENBAUM: We should think about a basic income, yes, but I don’t think \nanything is inevitable. Humans are a resilient and flexible species. Yes, it might \nbe that our abilities to learn and retrain ourselves have limitations to them. If \ntechnology keeps advancing, especially at this pace, it might be that we might have \nto do things like that. But again, we’ve seen that happen in previous eras of human \nhistory. It’s just unfolded more slowly. \nI think it would be fair to say that most of us who work for a living in the \nsocio-economic bracket that you and I live in, where we’re writers, scientists, or \ntechnologists, would find that if we went back thousands of years in human history, \nthey would say “That’s not work, that’s just playing! If you’re not laboring in the \nfields from dawn till dusk, you’re not actually working.” So, we don’t know what \nthe future of work is going to be like. \nJust because it might change fundamentally, it doesn’t mean that the idea that \nyou would spend eight hours a day doing something economically valuable goes \naway. Whether we’re going to have to have some kind of universal basic income, \nor just see the economy working in a different way, I don’t know about that, \nand I’m certainly no expert on that, but I think that AI researchers should be \npart of that conversation. \nAnother conversation that’s a much larger and much more urgent one is climate \nchange. We don’t know what the future of human-caused climate change is like, but \nwe do know that AI researchers are increasingly contributing to it. Whether it’s AI \nor Bitcoin mining, just look at what computers are being increasingly used for, and \nthe massive and accelerating energy consumption. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 666
  },
  {
    "chunk_full": "JOSHUA TENENBAUM\n487\nI think we as AI researchers should think about the ways in which what we’re doing \nis actually contributing to climate change, and ways we might contribute positively \nto solving some of those problems. I think that’s an example of an urgent problem \nfor society that AI researchers maybe don’t think about too much, but they are \nincreasingly part of the problem and maybe part of the solution.\nThere are also similar issues, like human rights and ways that AI technologies \ncould be used to spy on people, but researchers could also use those technologies \nto help people figure out when they’re being spied on. We can’t, as researchers, \nprevent the things that we in our field invent from being used for bad purposes, \nbut we can work harder to develop the good purposes, and also to develop and \nto use those technologies to push back against bad actors or uses. These are really \nmoral issues that AI researchers need to be engaging in.\nMARTIN FORD: Do you think there’s a role for a regulation to help ensure that AI \nremains a positive force for society?\nJOSH TENENBAUM: I think Silicon Valley can be very libertarian with their ethos \nthat says we should break things and let other people pick up the pieces. Honestly, \nI wish that both governments and the tech industry were less far apart and hostile \nto each other, and saw more of a common purpose. \nI am an optimist, and I do think that these different parties can and should \nbe working more together, and that AI researchers can be one of the standard \nbearers for that kind of cooperation. I think we need it as a community, and \nnot to mention as a society. \nMARTIN FORD: Let me ask you to comment more specifically on the prospect \nfor superintelligence and the alignment or control problem that Nick Bostrom has \nwritten about. I think his concern is that, while it might be a long time before \nsuperintelligence is achieved, it might take us even longer to work out how to \nmaintain control of a superintelligent system, and that’s what underlies his argument \nthat we should be focusing on this issue now. How would you respond to that? \nJOSH TENENBAUM: I think it’s reasonable for people to be thinking about that. \nWe think about that same thing. I wouldn’t say that should be the overriding goal \nof our thinking, because while you could imagine some kind of superintelligence \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 667
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n488\nthat would pose an existential risk to humanity, I just think we have other \nexistential risks that are much more urgent. There are already ways that machine \nlearning technologies and other kinds of AI technologies are contributing to big \nproblems that are confronting us right now as a human species, and some of \nthese grow to the level of existential risk. \nI want to put that in context and say that people should be thinking about \nproblems on all timescales. The issue of value alignment is difficult to address, \nand one of the challenges in addressing it right now is that we don’t know what \nvalues are. Personally, I think that when AI safety researchers talk about value \nalignment, they have a very simplistic and maybe naive idea of what a value \neven is. In some of the work that we do in our computational cognitive science, \nwe’re actually trying to understand and to reverse engineer what are values to \nhumans. What are moral principles, for example? These are not things that we \nunderstand in engineering terms.\nWe should think about these issues, but my approach is that we have to understand \nourselves better before we can work on the technology side. We have to understand \nwhat actually our values are. How do we as humans come to learn them, and come \nto know them? What are the moral principles? How do those work in engineering \nterms? I think if we can understand that, that’s an important part of understanding \nourselves, and it’s an important part of the cognitive science agenda. \nIt will be both useful and probably essential as machines not only become more \nintelligent but come to have more of an actual sense of self, where they become \nautonomous actors. It will be important for addressing these issues that you’re \ntalking about. I just think we’re far from understanding how to address them, and \nhow they work in natural intelligence. \nWe are also recognizing that there are nearer-term, really big risks and problems \nthat are not of the AI value alignment sort, but are things like, what are we doing \nto our climate? How are governments or companies using AI technologies today \nto manipulate people? \nThose are things we should worry about now. Parts of us should be thinking about \nhow do we become good moral actors, and how do we do things that really make \nthe world better and not worse. We should be engaging in things like that or \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 668
  },
  {
    "chunk_full": "JOSHUA TENENBAUM\n489\nclimate change, which are current, or near-term risks that AI can make better or \nworse. As opposed to super intelligence value alignment, which we should also be \nthinking about, but I think more from a basic science perspective—what does it \neven mean to have a value? \nAI researchers should work on all of these things. It’s just that the value alignment \nquestions are very basic research ones that are far from being put into practice or \nbeing needed to put into practice. We need to make sure that we don’t lose sight \nof the real current moral issues that AI needs to be engaged with. \nMARTIN FORD: Do you think that we’ll succeed in making sure that the benefits \nof artificial intelligence outweigh the downsides? \nJOSH TENENBAUM: I’m an optimist by nature, so my first response is to say \nyes, but we can’t take it for granted. It’s not just AI, but technology, whether it’s \nsmartphones or social media, is transforming our lives and changing how we interact \nwith each other. It really is changing the nature of human experience. I’m not sure \nit’s always for the better. It’s hard to be optimistic when you see a family where \neverybody’s just on their phones, or when you see some of the negative things that \nsocial media has led to. \nI think it’s important for us to realize, and to study, all the ways these \ntechnologies are doing crazy things to us! They are hacking our brains, our \nvalue systems, our reward systems, and our social interaction systems in a way \nthat is pretty clearly not just positive. I think we need more active immediate \nresearch to try to understand this and to try to think about this. This is a place \nwhere I feel that we can’t be guaranteed that the technology is leading us to \na good outcome, and AI right now, with machine learning algorithms, are not \nnecessarily on the side of good. \nI’d like the community to think about that in a very active way. In the long term, \nyes, I’m optimistic that we will build the kinds of AI that are, on balance, forces \nfor good, but I think this is really a key moment for all of us who work in this \nfield to really be serious about this. \nMARTIN FORD: Do you have any final thoughts, or is there anything I didn’t ask \nabout that you feel is important?\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 669
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n490\nJOSH TENENBAUM: The questions that animate the work we’re doing and that \nanimate many of us in this field are questions that people have thought about for \nas long as people have thought about anything. What is the nature of intelligence? \nWhat are thoughts? What does it mean to be human? It’s the most exciting thing \nthat we have the opportunity to work on these questions now in ways that we can \nmake both real engineering and real scientific progress on, and not simply consider \nas abstract philosophical questions. \nWhen we think about building AI of any big sort, but especially AGI, if we see that \nas not just a technology and an engineering problem, but as one side of one of \nthe biggest scientific questions that humanity has thought about ever. It’s along the \nsame line of thinking as, what is the nature of intelligence, or what are its origins \nin the universe? The idea to pursue that as part of that larger program is one that \nI think is tremendously exciting and that we should all be excited and inspired by. \nThat means thinking about ways of making technology that makes us smarter, and \ndoesn’t make us stupider. \nWe have the opportunity to both understand more about what it means to be \nintelligent in a human way, and learn how to build technology that can make us \nsmarter individually and collectively. It’s super exciting to be able to do that, but \nit’s also imperative that we take that seriously when we work on technology. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 670
  },
  {
    "chunk_full": "JOSHUA TENENBAUM\n491\nJOSH TENENBAUM is Professor of Computational Cognitive Science in the Department of Brain \nand Cognitive Sciences at the Massachusetts Institute of Technology. He is also a member of \nthe MIT Computer Science and Artificial Intelligence Laboratory (CSAIL), and the Center for \nBrains, Minds, and Machines (CBMM). Josh studies perception, learning and common-sense \nreasoning in humans and machines, with the twin goals of understanding human intelligence \nin computational terms and bringing artificial intelligence closer to human-level capabilities. \nJosh received his undergraduate degree in physics from Yale University in 1993, and his \nPhD from MIT in 1999. After a brief postdoc with the MIT AI Lab, he joined the Stanford \nUniversity faculty as Assistant Professor of Psychology and (by courtesy) Computer Science. \nHe returned to MIT as a faculty member in 2002.\nHe and his students have published extensively in cognitive science, machine learning and \nother AI-related fields, and their papers have received awards at venues across the AI landscape, \nincluding leading conferences in computer vision, reinforcement learning and decision-\nmaking, robotics, uncertainty in AI, learning and development, cognitive modeling and neural \ninformation processing. They have introduced several widely used AI tools and frameworks, \nincluding models for nonlinear dimensionality reduction, probabilistic programming, and \nBayesian approaches to unsupervised structure discovery and program induction. Individually, \nhe is the recipient of the Howard Crosby Warren Medal from the Society of Experimental \nPsychologists, the Distinguished Scientific Award for Early Career Contribution to Psychology \nfrom the American Psychological Association, and the Troland Research Award from the \nNational Academy of Sciences, and is a fellow of the Society of Experimental Psychologists \nand the Cognitive Science Society.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 671
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n492\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 672
  },
  {
    "chunk_full": "OREN ETZIONI\n493\nOREN ETZIONI\nCEO, THE ALLEN INSTITUTE FOR ARTIFICIAL INTELLIGENCE\nOren Etzioni is the CEO of the Allen Institute for Artificial Intelligence, an \nindependent organization established by Microsoft co-founder Paul Allen and \ndedicated to conducting high-impact research in artificial intelligence for the \ncommon good. Oren oversees a number of research initiatives, perhaps most \nnotably Project Mosaic, a $125 million effort to build common sense into an \nartificial intelligence system—something that is generally considered to be one \nof the most difficult challenges in AI. \nIf you look at a question like, “Would an elephant fit  \nthrough a doorway?”, while most people can answer  \nthat question almost instantaneously, machines will  \nstruggle. What’s easy for one is hard for the other,  \nand vice versa. That is what I call the AI paradox.\n“ \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 673
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n494\nMARTIN FORD: Project Mosaic sounds very interesting. Could you tell me about \nthat and the other projects that you’re working on at the Allen Institute?\nOREN ETZIONI: Project Mosaic is focused on endowing computers with common \nsense. A lot of the AI systems that humans have built, to date, are very good at \nnarrow tasks. For example, humans have built AI systems that can play Go very well, \nbut the room may be on fire, and the AI won’t notice. These AI systems completely \nlack common sense, and that’s something that we’re trying to address with Mosaic.\nOur over-arching mission at the Allen Institute for Artificial Intelligence is AI for \nthe common good. We’re investigating how you can use artificial intelligence to \nmake the world a better place. Some of that is through basic research, while the \nrest has more of an engineering flavor.\nA great example of this is a project called Semantic Scholar. In the Semantic Scholar \nproject, we’re looking at the problem of scientific search and scientific hypothesis \ngeneration. Because scientists are inundated with more and more publications, \nwe realize that scientists, just like all of us when we’re experiencing information \noverload, really need help in cutting through that clutter; and that’s what Semantic \nScholar does. It uses machine learning and natural language processing, along with \nvarious AI techniques, to help scientists figure out what they want to read and how \nto locate results within papers.\nMARTIN FORD: Does Mosaic involve symbolic logic? I know there was an older \nproject called Cyc that was a very labor-intensive process, where people would try to \nwrite down all the logical rules, such as how objects related, and I think it became \nkind of unwieldy. Is that the kind of thing you’re doing with Mosaic?\nOREN ETZIONI: The problem with the Cyc project is that, over 35 years in, it’s \nreally been a struggle for them, for exactly the reasons you said. But in our case, \nwe’re hoping to leverage more modern AI techniques—crowdsourcing, natural \nlanguage processing, machine learning, and machine vision—in order to acquire \nknowledge in a different way. \nWith Mosaic, we’re also starting with a very different point of view. Cyc started, \nif you will, inside out, where they said, “OK. We’re going to build this repository \nof common-sense knowledge and do logical reasoning on top of it.” Now, what \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 674
  },
  {
    "chunk_full": "OREN ETZIONI\n495\nwe said in response is, “We’re going to start by defining a benchmark, where we \nassess the common-sense abilities of any program.” That benchmark then allows us \nto measure how much common sense a program has, and once we’ve defined that \nbenchmark (which is not a trivial undertaking) we’ll then build it and be able to \nmeasure our progress empirically and experimentally, which is something that Cyc \nwas not able to do. \nMARTIN FORD: So, you’re planning to create some kind of objective test that can \nbe used for common sense?\nOREN ETZIONI: Exactly! Just the way the Turing test was meant to be a test for \nartificial intelligence or IQ, we’re going to have a test for common sense for AI.\nMARTIN FORD: You’ve also worked on systems that attempt to pass college \nexaminations in biology or other subjects. Is that one of the things you’re \ncontinuing to focus on?\nOREN ETZIONI: One of Paul Allen’s visionary and motivating examples, which he’s \ninvestigated in various ways even prior to the Allen Institute for AI, was the idea of \na program that could read a chapter in a textbook and then answer the questions \nin the back of that book. So, we formulated a related problem by saying, “Let’s \ntake standardized tests, and see to what extent we can build programs that score \nwell on these standardized tests.” And that’s been part of our Aristo project in the \ncontext of science, and part of our Euclid project in the context of math problems.\nFor us it is very natural to start working on a problem by defining a benchmark \ntask, and then continually improving performance on it. So, we’ve done that in \nthese different areas.\nMARTIN FORD: How is that progressing? Have you had successes there?\nOREN ETZIONI: I would say the results have been mixed, to be frank. I would say \nthat we’re state of the art in both science and math tests. In the case of science, we \nran a Kaggle competition, where we released the questions, and several thousand \nteams from all over the world joined. With this, we wanted to see whether we were \nmissing anything, and we found that in fact our technology did quite a bit better \nthan anything else out there, at least who participated in the test.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 675
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n496\nIn the sense of being state of the art and having that be a focus for research, \nand publishing a series of papers and datasets, I think it’s been very positive. \nWhat’s negative is that our ability on these tests is still quite limited. We find \nthat, when you have the full test, we’re getting something like a D, not a very \nstellar grade. This is because these problems are quite hard, and often they also \ninvolve vision and natural language. But we also realized that a key problem that \nwas blocking us was actually the lack of common sense. So, that’s one of the \nthings that led us to Project Mosaic.\nWhat’s really interesting here is that there’s something I like to call the AI paradox, \nwhere things that are really hard for people—like playing World Championship-\nlevel Go—are quite easy for machines. On the other hand, there are things that \nare easy for a person to do, for example if you look at a question like, “Would \nan elephant fit through a doorway?”, while most people can answer that question \nalmost instantaneously, machines will struggle. What’s easy for one is hard for the \nother, and vice versa. That is what I call the AI paradox.\nNow, the standardized test writers, they want to take a particular concept \nlike photosynthesis, or gravity, and have the student apply that concept in a \nparticular context, so that they demonstrate their understanding. It turned \nout that representing something like photosynthesis, at a 6th grade level, and \nrepresenting that to the machine is really quite easy, so we have an easy time \ndoing that. But where the machine struggles is when it’s time to applying \nthe concept in a particular situation that requires language understanding and \ncommon-sense reasoning. \nMARTIN FORD: So, you think your work on Mosaic could accelerate progress in \nother areas, by providing a foundation of common-sense understanding?\nOREN ETZIONI: Yes. I mean, a typical question is. “If you have a plant in a dark \nroom and you move it nearer the window, will the plant’s leaves grow faster, slower \nor at the same rate?” A person can look at that question and understand that if \nyou move a plant nearer to the window then there’s more light, and that more \nlight means the photosynthesis proceeds faster, and so the leaves are likely to grow \nfaster. But it turns out that the computer really struggles with this—because the AI \ndoesn’t necessarily understand what you mean when you say, “What happens when \nyou move a plant nearer the window.” \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 676
  },
  {
    "chunk_full": "OREN ETZIONI\n497\nThese are some examples that indicate what led us to Project Mosaic, and what \nsome of our struggles have been with things like Aristo and Euclid over the years. \nMARTIN FORD: What led you to work in AI, and how did you end up working \nat the Allen Institute? \nOREN ETZIONI: My foray into AI really started in high school when I read the book, \nGödel, Escher, Bach: An Eternal Golden Braid. This book explored the themes of logician \nKurt Gödel, the artist M. C. Escher, and the composer Johann Sebastian Bach, and \nexpounded many of the concepts that are relatable to AI, such as mathematics and \nintelligence. This is where my fascination with AI began. \nI then went to Harvard, for college, where they were just starting AI classes when \nI was a sophomore. So, I took my first AI class, and I was completely fascinated. \nThey were not doing much in the way of AI at the time but, just a short subway \nride away, I found myself at the MIT AI Lab and I remember that Marvin Minsky, \nthe co-founder of MIT’s AI lab, was teaching. And actually Douglas Hofstadter, \nthe author of Gödel, Escher, Bach, was a visiting professor, so I attended Douglas’s \nseminar and became even more enchanted with the field of AI. \nI got a part-time job as a programmer at the MIT AI Lab and for somebody who \nwas just starting their career, I was, as they say, over the moon. As a result, I \ndecided to go to graduate school to study AI. Graduate school for me was at \nCarnegie Mellon University where I worked with Tom Mitchell, who is one of the \nfounding fathers of the field of machine learning. \nThe next step in my career was when I became a faculty member at the University \nof Washington, where I studied many topics in AI. At the same time got involved \nin a number of AI-based start-ups, which I found to be very exciting. All of this \nresulted in me joining the Allen Institute of AI, and more specifically in 2013 \nPaul Allen’s team reached out to me saying that they wanted me to launch an \nInstitute for AI. So, in January 2014 we launched the Allen Institute for AI. Now \nfast forward to 2018 and here we are today.\nMARTIN FORD: As the leader of one of Paul Allen’s institutes, I assume you have \na lot of contact with him. What would you say about his motivation and vision \nfor the Allen Institute of AI?\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 677
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n498\nOREN ETZIONI: I’m really lucky in that I’ve had a lot of contact with Paul over \nthe years. When I was first contemplating this position, I read Paul’s book Idea Man, \nwhich gave me a sense of both his intellect and his vision. While reading Paul’s \nbook, I realized that he’s really operating in the tradition of the Medicis. He’s a \nscientific philanthropist and has signed the Giving Pledge that was started by both \nBill and Melinda Gates and Warren Buffett, where he’s publicly dedicated most of \nhis wealth to philanthropy. What drives him here is that he’s been fascinated by AI \nand the questions around how we can imbue semantics and an understanding of \ntext in machines since the 1970s.\nOver the years, Paul and I have had many conversations and email exchanges, \nand Paul continues to help shape the vision of the institute, not just in terms of \nthe financial support but in terms of the project choices, and the direction of the \ninstitute. Paul is still very much hands-on.\nMARTIN FORD: Paul has also founded the Allen Institute of Brain Science. Given \nthat the fields are related, is there some synergy between the two organizations? Do \nyou collaborate or share information with the brain science researchers?\nOREN ETZIONI: Yes, that’s correct. So, way back in 2003, Paul started the Allen \nInstitute of Brain Science. In our corner of the Allen Institutes, we call ourselves \n“AI2,” partly because it’s a bit kind of tongue-in-cheek as we’re the Allen Institute \nof AI but also because we’re the second Allen Institute. \nBut going back to Paul’s scientific philanthropy, his strategy is to create a series of \nthese Allen Institutes. There’s a very close exchange of information between us all. \nBut the methodologies that we use are really quite different, in that the Institute \nof Brain Science is really looking at the physical structure of the brain, while here \nat AI2 we’re adopting a rather more classical-AI methodology for building software.\nMARTIN FORD: So, at AI2 you’re not necessarily trying to build AI by reverse-\nengineering the brain, you’re actually taking more of a design approach, where \nyou’re building an architecture that’s inspired by human intelligence?\nOREN ETZIONI: That is exactly right. When we wanted to figure out flight, we \nended up with airplanes, and now we’ve developed Boeing 747s, which are very \ndifferent than birds in several ways. There are some of us within the AI field who \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 678
  },
  {
    "chunk_full": "OREN ETZIONI\n499\nthink that it is quite likely that our artificial intelligence will be implemented \nvery differently than human intelligence.\nMARTIN FORD: There’s enormous attention currently being given to deep learning and \nto neural networks. How do you feel about that? Do you think it’s overhyped? Is deep \nlearning likely to be the primary path forward in AI, or just one part of the story? \nOREN ETZIONI: I guess my answer would be all of the above. There have been \nsome very impressive achievements with deep learning, and we see that in machine \ntranslation, speech recognition, object detection, and facial recognition. When you have \na lot of labeled data, and you have a lot of computer power, these models are great. \nBut at the same time, I do think that deep learning is overhyped because some \npeople say that it’s really putting us on a clear path towards artificial intelligence, \npossibly general artificial intelligence, and maybe even superintelligence. And \nthere’s this sense that that’s all just around the corner. It reminds me of the \nmetaphor of a kid who climbs up to the top of the tree and points at the moon, \nsaying, “I’m on my way to the moon.” \nI think that in fact, we really have a long way to go and there are many unsolved \nproblems. In that sense, deep learning is very much overhyped. I think the reality is \nthat deep learning, and neural networks are particularly nice tools in our toolbox, \nbut it’s a tool that still leaves us with a number of problems like reasoning, \nbackground knowledge, common sense, and many others largely unsolved.\nMARTIN FORD: I do get the sense from talking to some other people, that they \nhave great faith in machine learning as the way forward. The idea seems to be that \nif we just have enough data, and we get better at learning—especially in areas like \nunsupervised learning—then common-sense reasoning will emerge organically. It \nsounds like you would not agree with that.\nOREN ETZIONI: The notion of “emergent intelligence” was actually a term that \nDouglas Hofstadter, the cognitive scientist, talked about back in the day. Nowadays \npeople talk about it in various contexts, with consciousness, and with common \nsense, but that’s really not what we’ve seen. We do find that people, including \nmyself, have all kinds of speculations about the future, but as a scientist, I like to \nbase my conclusions on the specific data that we’ve seen. And what we’ve seen \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 679
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n500\nis people using deep learning as high-capacity statistical models. High capacity is \njust some jargon that means that the model keeps getting better and better the \nmore data you throw at it. \nStatistical models that at their core are based on matrices of numbers being \nmultiplied, and added, and subtracted, and so on. They are a long way from \nsomething where you can see common sense or consciousness emerging. My feeling \nis that there’s no data to support these claims and if such data appears, I’ll be very \nexcited, but I haven’t seen it yet. \nMARTIN FORD: What projects would you point to, in addition to what you’re \nworking on, that are really at the forefront? What are the most exciting things \nhappening in AI? The places you’d look for the next big developments. Would that \nbe AlphaGo, or are there other things going on?\nOREN ETZIONI: Well, I think DeepMind is where some of the most exciting work \nis currently taking place. \nI’m actually more excited about what they called AlphaZero, than AlphaGo, and \nso the fact that they were able to achieve excellent performance without hand-\nlabeled examples, I think is quite exciting. At the same time, I think everybody \nin the community agrees that when you’re dealing with board games, it’s black \nand white, there’s an evaluation function, it’s a very limited realm. So, I would \nlook to current work on robotics, and work on natural language processing to see \nsome excitement. And I think that there’s also some work in fields called “transfer \nlearning,” where people are trying to map from one task to the other. \nI think Geoffrey Hinton is trying to develop a different approach to deep learning. \nI think at AI2, where we have 80 people who are looking at how do you put \ntogether the symbolic type of approaches and knowledge with the deep learning \nparadigm, I think that’s also very exciting.\nThere’s also “zero-shot learning,” where people are trying to build programs that \ncan learn when they see something even for the first time. And there is “one-shot \nlearning” where a program sees a single example, and they’re able to do things. I \nthink that’s exciting. Brenden Lake who’s an assistant professor of Psychology and \nData Science at NYU, is doing some work along those lines. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 680
  },
  {
    "chunk_full": "OREN ETZIONI\n501\nTom Mitchell’s work, with lifelong learning at CMU, is also very interesting—\nthey’re trying to build a system that looks more like a person: it doesn’t just run \nthrough a dataset and build a model and then it’s done. Instead, it continually \noperates and continually tries to learn, and then learn based on that, over a longer \nextended period of time. \nMARTIN FORD: I know there’s an emerging technique called “curriculum learning,” \nwhere you start with easier things and then move to the harder things, in the same \nway a human student would.\nOREN ETZIONI: Exactly. But if we just take a step back for a minute here, we can \nsee that AI is a field that’s rife with bombastic and overly grandiose misnomers. \nIn the beginning, the field was called “artificial intelligence,” and to me, that’s \nnot the best name. Then there’s “human learning” and “machine learning,” both of \nwhich sound very grandiose but actually, the set of techniques they use are often \nvery limited. All these terms that we just talked about—and curricular learning \nis a great example—refer to approaches where we’re simply trying to extend a \nrelatively limited set of statistical techniques, and to start to take on more of the \ncharacteristics of human learning. \nMARTIN FORD: Let’s talk about the path toward artificial general intelligence. \nDo you believe it is achievable, and if so, do you think it’s inevitable that we will \nultimately get to AGI?\nOREN ETZIONI: Yes. I’m a materialist, so I don’t believe there’s anything in \nour brain other than atoms and consequently, I think that thought is a form of \ncomputation and so I think that it’s quite likely that over some period of time we’ll \nfigure out how to do it in a machine. \nI do recognize that maybe we’re just not smart enough to do that, even with the help \nof a computer, but my intuition is that we will likely achieve AGI. As for the time \nline though, we’re very far from AGI because there are so many problems that need \nto be solved that we haven’t even been able to define appropriately for the machine. \nThis is one of the subtlest things in the whole field. People see these amazing \nachievements, like a program that beats people in Go and they say, “Wow! \nIntelligence must be around the corner.” But when you get to these more nuanced \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 681
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n502\nthings like natural language, or reasoning over knowledge, it turns out that we don’t \neven know, in some sense, the right questions to ask. \nPablo Picasso is famous for saying computers are useless. They answer questions \nrather than asking them. So, when we define a question rigorously, when we \ncan define it mathematically or as a computational problem, we’re really good \nat hammering away at that and figuring out the answer. But there are a lot of \nquestions that we don’t yet know how to formulate appropriately, such as how \ncan we represent natural language inside a computer? Or, what is common sense? \nMARTIN FORD: What are the primary hurdles we need to overcome to achieve AGI? \nOREN ETZIONI: When I talk to people working in AI about these questions, such as \nwhen we might achieve AGI, one of the things that I really like is to identify is what \nI call canaries in the coal mine. In the same way that the coal miners put canaries \nin the mines to warn them of dangerous gases, I feel like there are certain stepping \nstones—and that if we achieved those, then AI would be in a very different world. \nSo, one of those stepping stones would be an AI program that can really handle \nmultiple, very different tasks. An AI program that’s able to both do language and \nvision, it’s able to play board games and cross the street, it’s able to walk and chew \ngum. Yes, that is a joke, but I think it is important for AI to have the ability to \ndo much more complex things. \nAnother stepping stone is that it’s very important that these systems be a lot more \ndata-efficient. So, how many examples do you need to learn from? If you have an \nAI program that can really learn from a single example, that feels meaningful. \nFor example, I can show you a new object, and you look at it, you’re going to \nhold it in your hand, and you’re thinking, “I’ve got it.” Now, I can show you lots \nof different pictures of that object, or different versions of that object in different \nlighting conditions, partially obscured by something, and you’d still be able to say, \n“Yep, that’s the same object.” But machines can’t do that off of a single example \nyet. That would be a real stepping stone to AGI for me.\nSelf-replication is another dramatic stepping stone towards AGI. Can we have an AI \nsystem that is physically embodied and that can make a copy of itself? That would \nbe a huge canary in the coal mine because then that AI system could make lots of \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 682
  },
  {
    "chunk_full": "OREN ETZIONI\n503\ncopies of itself. People have quite a laborious and involved process for making copies \nof themselves, and AI systems cannot. You can copy the software easily but not the \nhardware. Those are some of the major stepping stones to AGI that come to mind.\nMARTIN FORD: And maybe the ability to use knowledge in a different domain \nwould be a core capability. You gave the example of studying a chapter in a \ntextbook. To be able to acquire that knowledge, and then not just answer questions \nabout it, but actually be able to employ it in a real-world situation. That would \nseem to be at the heart of true intelligence.\nOREN ETZIONI: I completely agree with you, and that question is only a step along \nthe way. It’s employment of AI in the real world, and also in unanticipated situations.\nMARTIN FORD: I want to talk about the risks that are associated with AI, but before \nwe do that, do you want to say more about what you view as some of the greatest \nbenefits, some of the most promising areas where AI could be deployed?\nOREN ETZIONI: There are two examples that stand out to me, the first being self-\ndriving cars, where we have upwards of 35,000 deaths each year on US highways \nalone, we have in the order of a million accidents where people are injured, \nand studies have shown that we could cut a substantial fraction of that by using \nself-driving cars. I get very excited when I see how AI can directly translate to \ntechnologies that save lives. \nThe second example, which we’re working on, is science—which has been such \nan engine of prosperity in economic growth, the improvement of medicine, and \ngenerally speaking for humanity. Yet despite these advancements, there are still so \nmany challenges, whether it’s Ebola, or cancer, or superbugs that are resistant to \nantibiotics. Scientists need help to solve these problems and just to move faster. \nWith a project like Semantic Scholar, it has the potential to save people’s lives by \nproviding better medical outcomes and better medical research. \nMy colleague, Eric Horvitz, is one of the most thoughtful people on these topics. He \nhas a great quote when he responds to people who are worried about AI taking lives. \nHe says that actually, it’s the absence of AI technology that is already killing people. \nThe third-leading cause of death in American hospitals is physician error, and a lot of \nthat could be prevented using AI. So, our failure to use AI is really what’s costing lives.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 683
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n504\nMARTIN FORD: Since you mentioned self-driving cars, let me try to pin you down \non a timeframe. Imagine you’re in Manhattan, in some random location, and you \ncall for a car. A self-driving car arrives with no one inside, and it’s going to take \nyou to some other random location. When do you think we will see that as a \nwidely available consumer service?\nOREN ETZIONI: I would say that is probably somewhere between 10 and 20 \nyears away from today. \nMARTIN FORD: Let’s talk about the risks. I want to start with the one that I’ve \nwritten a lot about, which is the potential economic disruption, and the impact on \nthe job market. I think it’s quite possible that we’re on the leading edge of a new \nindustrial revolution, which might really have a transformative impact, and maybe \nwill destroy or deskill a lot of jobs. What do you think about that? \nOREN ETZIONI: I very much agree with you, in the sense that I have tried, as \nyou have, not to get overly focused on the threats of superintelligence because we \nshould have fewer imaginary problems and more real ones. But we have some very \nreal problems and one of the most prominent of them, if not the most prominent, \nis jobs. There’s a long-term trend towards the reduction of manufacturing jobs, \nand due to automation, computer automation, and AI-based automation, we now \nhave the potential to substantially accelerate that timeline. So, I do think that \nthere’s a very real issue here. \nOne point that I would make, is that it’s also the case that the demographics are \nworking in our favor. The number of children we have as a species is getting \nsmaller on average, and the number of us living longer is increasing, and society \nis aging—especially after the baby boom. So, for the next 20 years, I think \nwe’re going to be seeing increasing automation, but we’re also going to be \nseeing the number of workers not growing as quickly as it did before. Another \nway that demographic factors work in our favor is that, while for the last two \ndecades, more women were entering the workforce, and the percentage of female \nparticipation in the workforce was going up, this affect has now plateaued. In \nother words, women who want to be in the workforce are now already there. \nSo again, I think that for the next 20 years we’re not going to see the numbers \nof workers increasing. The risk of automation taking jobs away from people is \nstill serious though I think.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 684
  },
  {
    "chunk_full": "OREN ETZIONI\n505\nMARTIN FORD: In the long run, what do you think of the idea of a universal basic \nincome, as a way to adapt society to the economic consequences of automation?\nOREN ETZIONI: I think that what we’ve already seen with agriculture, and with \nmanufacturing, is clearly going to recur. Let’s say we don’t argue about the exact \ntiming. It’s very clear that, in the next 10 to 50 years, many jobs are either going \nto go away completely or those jobs are going to be radically transformed—they’ll \nbe done a lot more efficiently, with fewer people. \nAs you know, the number of people working in agriculture is much smaller \nthan it was in the past, and the jobs involved in agriculture are now much more \nsophisticated. So, when that happens, we have this question: “What are the people \ngoing to do?” I don’t necessarily know, but I do have one contribution to this \nconversation, which I wrote up as an article for Wired in February 2017 titled \nWorkers displaced by automation should try a new job: Caregiver.1\nIn that Wired paper, I said some of the most vulnerable workers, in this economic \nsituation that we’re discussing here, are people who don’t have a high-school degree \nor those who don’t have a college degree. I don’t think it’s likely that we’re going \nto be successful in the principle of coal miners to data miners, that we’re going \nto give these people technical retraining, and that they’ll somehow become part of \nthe new economy very easily. I think that’s a major challenge. \nI also don’t think that universal basic income, at least given the current climate, \nwhere we can’t even achieve universal health care, or universal housing, is going \nto be easy either. \nMARTIN FORD: It seems pretty clear that any viable solution to this problem will \nbe a huge political challenge.\nOREN ETZIONI: I don’t know that there is a general solution or a silver bullet, but \nmy contribution to the conversation is to think about jobs that are very strongly \nhuman focused. Think of the jobs providing emotional support: having coffee with \nsomebody or being a companion who keeps somebody company. I think that those \nare the jobs that when we think about our elderly, when we think about our special-\n1  https://www.wired.com/story/workers-displaced-by-automation-should-try-a-new-job-caregiver/\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 685
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n506\nneeds kids, when we think about various populations like that, those are the ones \nthat we really want a person to engage with—rather than a robot. \nIf we want society to allocate resources toward those kinds of jobs, to give the \npeople engaged in those jobs better compensation and greater dignity, then I \nthink that there’s room for people to take on those jobs. That said, there are \nmany issues with my proposal, I don’t think it’s a panacea, but I do think it’s a \ndirection that’s worth investing in. \nMARTIN FORD: Beyond the job market impact, what other things do you think \nwe genuinely should be concerned about in terms of artificial intelligence in the \nnext decade or two?\nOREN ETZIONI: Cybersecurity is already a huge concern, and it becomes much \nmore so if we have AI. The other big concern for me is autonomous weapons, \nwhich is a scary proposition, particularly the ones that can make life-or-death \ndecisions on their own. But what we just talked about, the risks to jobs—that \nis still the thing that we should be most concerned about, even more so than \nsecurity and weapons.\nMARTIN FORD: How about existential risk from AGI, and the alignment or \ncontrol problem with regard to a superintelligence. Is that something that we \nshould be worried about?\nOREN ETZIONI: I think that it’s great for a small number of philosophers and \nmathematicians to contemplate the existential threat, so I’m not dismissing it out of \nhand. At the same time, I don’t think those are the primary things that we should \nbe concerned about, nor do I think that there’s that much that we can do at this \npoint about that threat.\nI think that one of the interesting things to consider is if a superintelligence \nemerges, it would be really nice to be able to communicate with it, to talk to \nit. The work that we’re doing at AI2—and that other people are also doing—\non natural language understanding, seems like a very valuable contribution to \nAI safety, at least as valuable as worrying about the alignment problem, which \nultimately is just a technical problem having to do with reinforcement learning \nand objective functions. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 686
  },
  {
    "chunk_full": "OREN ETZIONI\n507\nSo, I wouldn’t say that we’re underinvesting in being prepared for AI safety, and \ncertainly some of the work that we’re doing at AI2 is actually implicitly a key \ninvestment in AI safety.\nMARTIN FORD: Any concluding thoughts?\nOREN ETZIONI: Well, there’s one other point I wanted to make that I think people often \nmiss in the AI discussion, and that’s the distinction between intelligence and autonomy.2\nWe naturally think that intelligence and autonomy go hand in hand. But you can \nhave a highly intelligent system with essentially no autonomy, and the example of \nthat is a calculator. A calculator is a trivial example, but something like AlphaGo \nthat plays brilliant Go but won’t play another game until somebody pushes a button: \nthat’s high intelligence and low autonomy. \nYou can also have high autonomy and low intelligence. My favorite kind of tongue-\nin-cheek example is a bunch of teenagers drinking on a Saturday night: that’s high \nautonomy but low intelligence. But a real-world example, that we’ve all experienced \nwould be a computer virus that can have low intelligence but quite a strong ability \nto bounce around computer networks. My point is that we should understand that \nthe systems that we’re building have these two dimensions to them, intelligence and \nautonomy, and that it’s often the autonomy that is the scary part.\nMARTIN FORD: Drones or robots that could decide to kill without a human in the \nloop to authorize that action is something that is really generating a lot of concern \nin the AI community.\nOREN ETZIONI: Exactly, when they’re autonomous and they can make life-and-death \ndecisions on their own. Intelligence, on the other hand, could actually help save \nlives, by getting them more targeted, or by having them abort when the human \ncost is unacceptable, or when the wrong person or building is targeted. \nI want to emphasize the fact that a lot of our worries about AI are really worries \nabout autonomy, and I want to emphasize that autonomy is something that we can \nchoose as a society to meter out. \n2  https://www.wired.com/2014/12/ai-wont-exterminate-us-it-will-empower-us/\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 687
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n508\nI like to think of “AI” as standing for “augmented intelligence,” just as it is with \nsystems like Semantic Scholar and like with self-driving cars. One of the reasons \nthat I am an AI optimist, and feel so passionate about it, and the reason that I’ve \ndedicated my entire career to AI since high school, is that I see this tremendous \npotential to do good with AI.\nMARTIN FORD: Is there a place for regulation, to address that issue of autonomy? \nIs that something that you would advocate?\nOREN ETZIONI: Yes, I think that regulation is both inevitable and appropriate when \nit comes to powerful technologies. I would focus on regulating the applications of \nAI—so AI cars, AI clothes, AI toys, and AI in nuclear power plants, rather than \nthe field itself. Note that the boundary between AI and software is quite murky!\nWe’re in a global competition for AI, so I wouldn’t rush to regulate AI per se. Of \ncourse, existing regulatory bodies like the National Safety Transportation Board are \nalready looking at AI cars, and the recent Uber accident. I think that regulation is \nvery appropriate and that it will happen and should happen. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 688
  },
  {
    "chunk_full": "OREN ETZIONI\n509\nOREN ETZIONI is the CEO of the Allen Institute for Artificial Intelligence (abbreviated as \nAI2), an independent, non-profit research organization established by Microsoft co-founder \nPaul Allen in 2014. AI2, located in Seattle, employs over 80 researchers and engineers with \nthe mission of “conducting high-impact research and engineering in the field of artificial \nintelligence, all for the common good.” \nOren received a bachelor’s degree in computer science from Harvard in 1986. He then went \non to obtain a PhD from Carnegie Mellon University in 1991. Prior to joining AI2, Oren \nwas a professor at the University of Washington, where he co-authored over 100 technical \npapers. Oren is a fellow of the Association for the Advancement of Artificial Intelligence, and \nis also a successful serial entrepreneur, having founded or co-founded a number of technology \nstartups that were acquired by larger firms such as eBay and Microsoft, Oren helped to \npioneer meta-search (1994), online comparison shopping (1996), machine reading (2006), \nopen information extraction (2007), and semantic search of the academic literature (2015).\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 689
  },
  {
    "chunk_full": "",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 690
  },
  {
    "chunk_full": "BRYAN JOHNSON\nENTREPRENEUR \nFOUNDER, KERNEL & OS FUND\nBryan Johnson is the founder of Kernel, OS Fund, and Braintree. After the sale of \nBraintree to PayPal in 2013 for $800m, Johnson founded OS Fund in 2014 with \n$100m of those funds. His objective was to invest in entrepreneurs and companies \nthat develop breakthrough discoveries in hard science to address our most pressing \nglobal problems. In 2016, Johnson founded Kernel with another $100m of his \nfunds. Kernel is building brain-machine interfaces with the intention of providing \nhumans with the option to radically enhance their cognition.\nAI is the best thing since sliced bread. We should  \nembrace it wholeheartedly and understand the secrets \nof unlocking the human brain by embracing AI.  \nWe can’t do it by ourselves.\n“ \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 691
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n512\nMARTIN FORD: Could you explain what Kernel is? How did it get started, and \nwhat is the long-term vision? \nBRYAN JOHNSON: Most people start companies with a product in mind, and \nthey build that given product. I started Kernel with a problem identified—we \nneed to build better tools to read and write our neural code, to address disease \nand malfunction, to illuminate the mechanisms of intelligence, and to extend our \ncognition. Look at the tools we have to interface with our brain right now—we \ncan get an image of our brain via an MRI scan, we can do bad recordings via EEG \noutside the scalp that don’t really give us much, and we can implant an electrode \nto address a disease. Outside of that, our brain is largely inaccessible to the world \noutside of our five senses. I started Kernel with $100 million with the objective of \nfiguring out what tools we can build. We’ve been on this quest for two years, and \nwe still remain in stealth mode on purpose. We have a team of 30 people and we \nfeel very good about where we’re at. We’re working very hard to build the next \nbreakthroughs. I wish I could give you more details about where we’re at in the \nworld. We will have that out in time, but right now we’re not ready.\nMARTIN FORD: The articles I’ve read suggest that you’re beginning with medical \napplications to help with conditions like epilepsy. My understanding is that you \ninitially want to try an invasive approach that involves brain surgery, and you then \nwant to leverage what you learn to eventually move to something that will enhance \ncognition, while hopefully being less invasive. Is that the case, or are you imagining \nthat we’re all going to have chips inserted into our brain at some point? \nBRYAN JOHNSON: Having chips in our brain is one avenue that we’ve contemplated, \nbut we’ve also started looking at every possible entry point in neuroscience because \nthe key in this game is figuring out how to create a profitable business. Figuring out \nhow to create an implantable chip is one option, but there are many other options, \nand we’re looking at all of them.\nMARTIN FORD: How did you come to the idea of starting Kernel and OS Fund? \nWhat route did your early career take to bring you to that point? \nBRYAN JOHNSON: The starting point for my career was when I was 21, where I \nhad just returned from my Mormon mission to Ecuador. I lived among and witnessed \nextreme poverty and suffering. During my two years of living among extreme \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 692
  },
  {
    "chunk_full": "BRYAN JOHNSON\n513\npoverty, the only question that was weighing on my mind was, what could I do \nthat would create the most value for the greatest number of people in the world? \nI wasn’t motivated by fame or money, I just wanted to do good in the world. I \nlooked at all the options I could find, and none of them satisfied me. Because of \nthat, I determined to become an entrepreneur, build a business, and retire by the \nage of 30. In my 21-year-old mind that made sense. I got lucky, and fourteen years \nlater I sold my company Braintree for $800 million in cash to eBay in 2013. \nBy that point, I had also left Mormonism, which had defined my entire reality of \nwhat life was about, and when I left that I had to recreate myself from scratch. \nI was 35, fourteen years since my initial life decisions, and that drive to benefit \nhumanity hadn’t left me. I asked myself the question, what’s the one single thing \nthat I can do that will maximize the probability that the human race will survive. \nIn that moment of observation, it wasn’t clear to me that humans have what we \nneed to survive ourselves and survive the challenges we face. I saw two answers \nto that question, and they were Kernel and the OS Fund. \nThe idea behind OS Fund is that most people in the world who manage or have \nmoney do not have scientific expertise, and therefore, they typically invest in things \nthat they are more comfortable with, such as finance or transportation. That means \nthat there is insufficient capital going to science-based endeavors. My observation \nwas that if I could demonstrate as a non-scientist that I could invest in some of the \nhardest science in the world and be successful in doing this, I would create a model \nthat others could follow. So, I invested $100 million in my OS Fund to do that, \nand five years in, we are in the top decile of performance among US firms. We’ve \nmade 28 investments, and we’ve been able to demonstrate that we can successfully \ninvest in these science-based entrepreneurs that are doing world-changing technology.\nThe second thing was Kernel. In the beginning, I talked to over 200 really smart \npeople, asking them what they were doing in the world and why. From there, I’d \nask them follow-on on questions to understand the entire assumptions stack of \nhow they think, and the one thing that I walked away from is that the brain is \nthe originator of all things, everything we do as humans stems from our brains. \nEverything we build, everything we’re trying to become, and every problem \nwe’re trying to solve. It lives upstream from anything else, yet it was absent in \nanybody’s focus. There were efforts, for example from DARPA and the Allen \nBrain Institute, but most were focused on specific medical applications or basic \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 693
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n514\nresearch in neuroscience. There was nobody in the world that I could identify \nthat basically said, the brain is the most important thing in existence because \neverything sits downstream from the brain. It’s a really simple observation, but \nit was a blind spot everywhere. \nOur brain sits right behind our eyes, yet we focus on everything downstream from \nit. There is not an endeavor that is on a scale that’s relevant, something that lets \nus read and write neural code to read and write our cognition. So, with Kernel, \nI set out to do for the brain what we did for the genome, which is to sequence \na genome and then create a tool to write the genome. In 2018, we can read and \nedit the DNA—the software—that makes us humans, and I wanted to do the same \nthing for the brain, which is read and write our code. \nThere’s a bunch of reasons why I want to be able to read and write the human \nbrain. My fundamental belief behind all of this is that we need to radically up-level \nourselves as a species. AI is moving very quickly, and what the future of AI holds \nis anyone’s guess. The expert opinions are across the board. We don’t know if AI \nis growing on a linear curve, an S curve, an exponential curve, or a punctuated \nequilibrium, but we do know that the promise of AI is up and to the right. \nThe rate of our improvement as humans is flat. People hear this and say that we’re \nhugely improved over people 500 years ago, but we’re not. Yes, we understand \ngreater complexity, for example, more complex concepts in physics and mathematics, \nbut our species generally is exactly the same as we were thousands of years ago. \nWe have the same proclivities and we make the same mistakes. Even if you were \nto make the case that we are improving as a species, if you compare it to AI, \nhumans are flatlining. If you just simply look at the graph and say AI is up and to \nthe right, humans might be a little bit to the right. So the question is, how big is \nthat delta going to be between AI and ourselves when we begin to feel incredibly \nuncomfortable? It’s going to just run by us, and then what are we as a species? It \nis an important question to ask.\nAnother reason is based on the concept that we have this impending job crisis with \nAI. The most creative thing people are coming up with is universal basic income, \nwhich is basically waving the white flag and saying we can’t cope and we need \nsome money from the government. Nowhere in the conversation is radical human \nimprovement discussed. We need to figure out how to not just nudge ourselves \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 694
  },
  {
    "chunk_full": "BRYAN JOHNSON\n515\nforward, but to make a radical transformation. What we need to do is acknowledge \nthe reason that we need to improve ourselves radically is that we cannot imagine \nthe future. We are constrained in our imagination to what we are familiar with.\nIf you were to take humans and put them back with Gutenberg and the printing \npress, and say, paint me a miraculous vision of what’s possible, they wouldn’t be \nable to do it. They would never have guessed at what’s evolved like the internet or \ncomputers. The same is true of radical human enhancement. We don’t know what’s \non the other side. What we do know is that is if we are to be relevant as a species, \nwe must advance ourselves significantly. \nOne more reason is the idea that somehow AI became the biggest threat that we \nshould all care about, which in my mind is just silly. The biggest thing I’m worried \nabout is humans. We have always been our own biggest threat. Look at all of history, \nwe have done awful things to each other. Yes, we’ve done remarkable things with \nour technology, but we have also inflicted tremendous harm on each other. So, in \nterms of asking is AI a risk, and should we prioritize that? I would say AI is the best \nthing since sliced bread. We should embrace it wholeheartedly and understand the \nsecrets of unlocking the human brain by embracing AI. We can’t do it by ourselves.\nMARTIN FORD: There are a number of other companies in the same general space \nas Kernel. Elon Musk has Neuralink and I think both Facebook and DARPA are also \nworking on something. Do you feel that there are direct competitors out there, or \nis Kernel unique in its approach? \nBRYAN JOHNSON: DARPA has done a wonderful job. They have been looking \nat the brain for quite some time now, and they’ve been a galvanizer of success. \nAnother visionary in the field is Paul Allen and the Allen Institute for Brain \nScience. The gap that I identified was not understanding that the brain matters, \nbut identifying the brain as the primary entry point to everything in existence we \ncare about. Then through that frame, creating the tools to read and write neural \ncode. To read and write human. \nI started Kernel, and then less than a year later both Elon Musk and Mark \nZuckerberg did similar things. Elon started a company that was roughly in a similar \nvein as mine, a similar trajectory of trying to figure out how to re-write human \nto play well with AI, and then Facebook decided to do theirs focused on further \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 695
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n516\nengagement with their users within the Facebook experience. Though it’s still to \nbe determined whether Neuralink, Facebook, and Kernel will be successful over \nthe next couple of years, at least there’s a few of us going at it, which I think is \nan encouraging situation for the entire industry.\nMARTIN FORD: Do you have a sense of how long all this could take? When do you \nimagine that there will be some sort of device, or chip that is readily available that \nwill enhance human intelligence?\nBRYAN JOHNSON: It really depends upon the modality. If it’s implantable, there \nis a longer time frame, but if it’s not invasive, then that is a shorter time frame. \nMy guess on the time frame is that within 15 years neural interfaces will be as \ncommon as smartphones are today. \nMARTIN FORD: That seems pretty aggressive. \nBRYAN JOHNSON: When I say neural interfaces, I am not specifying the type. I \nam not saying that people have a chip implanted in their brain. I’m just saying that \nthe user will be able to bring the brain online. \nMARTIN FORD: What about the specific idea that you might be able to download \ninformation or knowledge directly into your brain? A simple interface is one thing. \nBut to actually download information seems especially challenging because I don’t \nbelieve we have any real understanding of how information is stored in the brain. So, \nthe idea that you could take information from another source and inject it directly \ninto your brain really seems like a strictly science-fiction concept. \nBRYAN JOHNSON: I agree with that, I don’t think anybody could intelligently speculate \non that ability. We have demonstrated methods for enhanced learning or enhanced \nmemory, but the ability to decode thoughts in the brain has not been demonstrated. \nIt’s impossible to give a date because we are inventing the technology as we speak. \nMARTIN FORD: One of the things that I have written a lot about is the potential \nfor a lot of jobs to be automated and the potential for rising unemployment and \nworkforce inequality. I have advocated the idea of a basic income, but you’re saying \nthe problem would be better solved by enhancing the cognitive capabilities of people. \nI think there are a number of problems that come up there. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 696
  },
  {
    "chunk_full": "BRYAN JOHNSON\n517\nOne is that it wouldn’t address the issue that a large fraction of jobs is routine \nand predictable, and they will eventually be automated by specialized machines. \nIncreasing the cognition of workers won’t help them keep those jobs. Also, everyone \nhas different levels of ability to begin with, and if you add some technology that \nenhances cognition, that might raise the floor, but it probably wouldn’t make \neveryone equal. Therefore, many people might still fall below the threshold that \nwould make them competitive. \nAnother point that is often raised with this kind of technology is that access to it \nis not going to be equal. Initially, it’s going to only be accessible to wealthy people. \nEven if the devices get cheaper and more people can afford them, it seems certain \nthat there would be different versions of this technology, with the better models only \naccessible to the wealthy. Is it possible that this technology could actually increase \ninequality, and maybe add to the problem rather than address it? \nBRYAN JOHNSON: Two points about this. At the top of everybody’s minds are \nquestions around inequality, around the government owning your brain, around \npeople hacking your brain, and around people controlling your thoughts. The \nmoment people contemplate the possibility of interfacing with their brain, they \nimmediately jump into loss mitigation mode—what’s going to go wrong?\nThen, different scenarios come to mind: Will things go wrong? Yes. Will people do bad \nthings? Yes. That’s part of the problem, humans always do those things. Will there be \nunintended consequences? Yes. Once you get past all these conversations, it opens up \nanother area of contemplation. When we ask those questions, we assume that somehow \nhumans are in this undisputed secure position on this planet and that we can forfeit \nall the considerations as a species, so we can optimize for equality and other things.\nMy fundamental premise is that we are at risk of going extinct by doing harm to \nourselves, and by exterior factors. I’m coming to this conversation with the belief \nthat whether we enhance ourselves is not a question of luxury. It’s not like should \nwe, or shouldn’t we? Or what are the pros and cons? I’m saying that if humans do \nnot enhance themselves, we will go extinct. By saying that, though, I’m not saying \nthat we should be reckless, or not thoughtful, or that we should embrace inequality.\nWhat I’m suggesting is that the first principle discussion of conversation is that it \nis an absolute necessity. Once we acknowledge that, then we can contemplate and \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 697
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n518\nsay, “Now given this constraint, how do we best accommodate everyone’s interest \nwithin society? How do we make sure that we march forward at a steady pace \ntogether? How do we ensure that we design into the system knowing that people \nare going to abuse it?” There is a famous quote that the internet was designed \nwith criminals in mind, so the question is, how do we design neural interfaces \nknowing that people are going to abuse it? How do we design it knowing that \nthe government is going to want to get into your brain? How do we do all of \nthose things? That is a conversation that is not currently happening. People stop \nat this luxury argument, which I think is short-sighted, and one of the reasons \nwhy we’re in trouble as a species. \nMARTIN FORD: It sounds like you’re making a practical argument that realistically \nwe may have to accept more radical inequality. We may have to enhance a group \nof people so that they can solve the problems we face. Then after the problems are \nsolved, we can turn our attention to making the system work for everyone. Is that \nwhat you’re saying?\nBRYAN JOHNSON: No, what I am suggesting is that we need to develop the \ntechnology. As a species we need to upgrade ourselves to be relevant in the \nface of artificial intelligence, and to avoid destroying ourselves as a species. We \nalready possess the weaponry to destroy ourselves today, and we’ve been on the \nverge of doing that for decades. \nLet me put it in a new frame. I think it’s possible that in 2050, humans look back \nand they say, “oh my goodness, can you believe that humans in 2017 thought it was \nacceptable to maintain weapons that could annihilate the entire planet?” What I am \nsuggesting is that there’s a future of human existence that is more remarkable than \nwe can even imagine. Right now, we’re stuck in our current conception of reality, \nand we can’t get past this contemplation that we might be able to create a future \nbased on harmoniousness instead of competition, and that we might somehow have \na sufficient amount of resources and a mindset for all of us to thrive together. \nWe immediately jump into the fact that we always strive to hurt one another. \nWhat I am suggesting is this is why we need enhancement to get past these limits \nand cognitive bias that we have. So, I am in favor of enhancing everybody at the \nsame time. That puts a burden on the development of the technology, but that’s \nwhat the burden needs to be.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 698
  },
  {
    "chunk_full": "BRYAN JOHNSON\n519\nMARTIN FORD: When you describe this, I get the sense that you’re thinking in \nterms of not just enhancing intelligence, but also morality and ethical behavior \nand decision making. Do you think that there’s potential for technology to make \nus more ethical and altruistic as well? \nBRYAN JOHNSON: To be clear, I find that intelligence is such a limiting word in \nits conception. People associate intelligence with IQ, and I’m not doing that at \nall. I don’t want to suggest only intelligence. When I talk about humans radically \nimproving themselves, I mean in every possible realm. For example, let me paint \na picture of what I think could happen to AI. AI is extremely good at performing \nlogistical components of our society, an example being it will be a lot better at \ndriving cars than humans. Give AI enough time, and it will be substantially better, \nand there will be fewer deaths on the road. We’ll look back and say, “can you believe \nhumans used to drive?” AI is a lot better at flying autopilot on an airplane; it’s a \nlot better at playing Go and chess. \nImagine a scenario where we can develop AI to a point where AI largely runs the \nlogistical aspects of everyone’s lives: transportation, clothing, personal care, health—\neverything is automated. In that world, our brain is now freed from doing what it \ndoes for 80% of the day. It’s free to pursue higher-order complexities. The question \nnow is, what will we do? For example, what if studying physics and quantum theory \nproduced the same reward system that watching the Kardashians does today? What \nif we found out that our brains could extend to four, five, or ten dimensions? What \nwould we create? What would we do? \nWhat I’m suggesting is the hardest concept in the entire world to grasp, because \nour brain convinces us that we are an all-seeing eye, that we understand all of the \nthings around us, and that current reality is the only reality. What I am suggesting \nis that there is a future in cognitive enhancement that we can’t even see, and that’s \nwhat limits our imaginations to contemplate it. It’s like going back in time and asking \nGutenberg to imagine all the kinds of books that will be written. Since then, the \nliterary world has flourished over the centuries. The same thing is true for neural \nenhancement, and so you start to get a scale of how gigantic a topic this is. \nBy traveling through this topic, we’ll get into the constraints of our imagination, \nwe’ll get into human enhancement, people will have to address all their fears \neven to get to a point where they’d be open to thinking about this. They have \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 699
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n520\nto reconcile with AI, they have to figure out if AI is a good thing or a bad \nthing. If we did enhance ourselves, what would it look like? To squeeze this \nall into a topic is really hard, and that’s why this stuff is so complex, but also \nso important. Yet, getting to a level where we can talk about this as a society \nis very hard, because you have to scaffold your way to all the different pieces \nwe have to get someone who is willing to scaffold to these different layers, and \nthat’s the hardest part of this.\nMARTIN FORD: Assuming you could actually build this technology, then how as a \nsociety do we talk about it and really wrestle with the implications, particularly \nin a democracy? Just look at what’s happened with social media, where a lot of \nunintended and unanticipated problems have clearly developed. What we’re talking \nabout here could be an entirely new level of social interaction and interconnection, \nperhaps similar to today’s social media, but greatly amplified. What would address \nthat? How should we prepare for that problem?\nBRYAN JOHNSON: The first question is, why would we expect anything different \nthan what’s happened with social media? It’s entirely predictable that humans will \nuse the tools they are given to pursue their own self-interests along the lines of \nmaking money, gaining status, respect, and an advantage over others. That’s what \nhumans do, and it’s how we’ve wired to do, and it how we’ve always done it. That’s \nwhat I am saying, we haven’t improved ourselves. We’re the same. \nWe would expect this to happen just like it did with social media; after all, humans \nare humans. We’ll always be humans. What I’m suggesting is this is the reason why \nwe enhance ourselves. We know what humans do with stuff, it’s a very proven model. \nWe have thousands and thousands of years of data to know what humans do with \nstuff. We need to go beyond humans, to something akin to humanity 3.0 or 4.0. \nWe need to radically improve ourselves as a species beyond what we can imagine, \nbut the issue is that we don’t have the tools to that right now.\nMARTIN FORD: Are you suggesting that all of this in some sense would have to be \nregulated? There’s a possibility that as an individual, I might not want my morality to \nbe enhanced. Perhaps I just want to enhance my intelligence, my speed, or something \nsimilar, so that I can profit from that without buying in to the other beneficial stuff \nthat you perceive happening. Wouldn’t you need some overall regulation or control \nof this to be sure that it’s used in a way that benefits everyone?\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 700
  },
  {
    "chunk_full": "BRYAN JOHNSON\n521\nBRYAN JOHNSON: May I adjust the framing of your question in two ways? First, \nyour statement about regulation implicitly assumes that our government is the \nonly group that can arbitrate interests. I do not agree with that assumption. \nThe government is not the only group in the entire world that can regulate \ninterests. We could potentially create self-sustaining communities of regulation; \nwe do not have to rely on government. The creation of new regulating bodies \nor self-regulating bodies can emerge that keep the government from being the \nsole keeper of that. \nSecond, your statement on morals and ethics assumes that you as a human have \nthe luxury to decide what morals and ethics you want. What I’m suggesting is \nthat if you look back through history, almost every biological species that has \never existed on this earth for the four-plus billion years it has existed have gone \nextinct. Humans are in a tough spot, and we need to realize we’re in a tough \nspot because we are not born in an inherent position of luxury. We need to \nmake very serious contemplations, which does not mean that we’re not going to \nhave moral ethics; it does. It just means that it needs to be balanced to realize \nthat we are in a tough spot. \nFor example, there’s a couple of books that have come out, like Factfulness: Ten \nReasons We’re Wrong About the World, and Why Things Are Better Than You Think, by \nHans Rosling, and Steven Pinker’s The Better Angels of Our Nature: Why Violence Has \nDeclined. Those books basically say that the world’s not bad, and that although \neveryone says how terrible it is, all the data says it’s getting better, and it’s getting \nbetter faster. What they’re not contemplating is that the future is dramatically \ndifferent to the past. We’ve never had a form of intelligence in the form of AI \nthat has progressed this fast. Humans have never had these types of tools that have \nbeen this destructive. We have not experienced this future before, and it’s our \nvery first time going through this. \nThat’s why I don’t buy the historical determinism argument that somehow because \nwe’ve done well in the past, we’re guaranteed to do well in the future. I would \nsay that I’m equal parts optimistic about what the future can bring, but I’m also \nequal parts cautious. I’m cautionary in terms of acknowledging that in order for \nus to be successful in the future, we must achieve future literacy. We must also \nbe able to start planning for, thinking about, and creating models for the future \nthat enable us to become future literate. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 701
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n522\nIf you look at us as a species now, we fly by the seat of our pants. We pay attention \nto things when they become a crisis and we can’t plan ahead, and as humans, we \nknow this. We typically do not get ahead in life if we don’t plan for it, and as \na species, we have no plan. So again, there are all these concepts that if we are \nhoping to survive in the future, what gives us confidence that we can do that? \nWe don’t plan for it, we don’t think about it, and we don’t look at anything else \nbeyond individuals, individual states, companies, or countries. We’ve never done \nit before. How do we deal with that in a thoughtful way so that we can maintain \nthe things we care about?\nMARTIN FORD: Let’s talk more generally about artificial intelligence. First of all, \nis there anything that you can talk about in terms of your portfolio companies \nand what they are doing? \nBRYAN JOHNSON: The companies that I invested in are using AI to push science \ndiscovery forward. That’s the one thing they all have in common, whether they’re \ndeveloping new drugs to cure disease, or finding new proteins for everything, for \ninputs into agriculture, for food, drugs, pharmaceuticals, or physical products. Whether \nthese companies are designing microorganisms, like synthetic bio, or they’re designing \nnew materials, like true nanotech, they’re all using some form of machine learning. \nMachine learning is a tool that is enabling discovery faster and better than anything \nwe’ve ever had before. A couple of months ago, Henry Kissinger wrote an open letter \nto The Atlantic saying that when he was aware of what AlphaGo did in chess and Go, \nhe was worried about “strategically unprecedented moves.” He literally sees the world \nas a board game because he was in politics in the cold-war era when the US and \nRussia were arch rivals, and we literally were, both in chess and as nation states. He \nsaw that when you apply AI to chess and Go—and human geniuses have been playing \nthose games for thousands of years—when we gave the game to AlphaGo within a \nmatter of days, the AI came up with genius moves that we had never seen before.\nSo, sitting underneath our nose the entire time was undiscovered genius. We \ndidn’t know, and we couldn’t see it ourselves, but AI showed it to us. Henry \nKissinger saw that, and he said, that makes me scared. I see that, and I say that’s \nthe best thing in the entire world because AI has the ability to show us what we \ncannot see ourselves. This is a limitation when humans cannot imagine the future. \nWe cannot imagine what radically enhancing ourselves means, we can’t imagine \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 702
  },
  {
    "chunk_full": "BRYAN JOHNSON\n523\nwhat the possibilities are, but AI can fill this gap. That’s why I think it’s the best \nthing that could ever happen to us; it is absolutely critical for us to survive. The \nissue is that most people, of course, have accepted this narrative of fear from \noutspoken people who have talked about it, and I think it’s terribly damaging that \nas a society that narrative is ongoing.\nMARTIN FORD: There is a concern expressed by people like Elon Musk and \nNick Bostrom, where they talk about the fast take-off scenario, and the control \nproblem related to superintelligence. Their focus is on the fear that AI could get \naway from us. Is that something we should worry about? I have heard the case \nmade that by enhancing cognitive capability we will be in a better position to \ncontrol the AI. Is that a realistic view? \nBRYAN JOHNSON: I’m appreciative of Nick Bostrom for being as thoughtful as \nhe has been about the risks that AI presents. He started this whole discussion, and \nhe’s been fantastic in framing it. It is a good use of time to contemplate how we \nmight anticipate undesired outcomes and work to fend those off, and I am very \nappreciative that he allocated his brain to do that. \nRegarding Elon, I think the fear mongering that he has done is a negative in society, \nbecause in comparison it has not been as thorough and thoughtful as Nick’s work. \nElon has basically just taken it out to the world, and both created and inflicted fear \namong a class of people that can’t comment intelligently on the topic, which I think \nis unfortunate. I also think we would be well suited as a species to be humbler in \nacknowledging our cognitive limitations and in contemplating how we might improve \nourselves in every imaginable way. The fact that it is not our number one priority \nas a species demonstrates the humility we need. \nMARTIN FORD: The other thing I wanted to ask you about is that there is a \nperceived race with other countries, and in particular China both in terms of AI, \nand potentially with the kind of neural interface technology you’re working on with \nKernel. What’s your view on that? Could competition be positive since it will result \nin more knowledge? Is it a security issue? Should we pursue some sort of industrial \npolicy to make sure that we don’t fall behind? \nBRYAN JOHNSON: It’s how the world works currently. People are competitive, \nnation states are competitive, and everybody pursues their self-interest above the \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 703
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n524\nother. This is exactly how humans will behave, and I come back to the same \nobservation every single time. \nThe future that I imagine for humans that paves the way for our success is one in \nwhich we are radically improved. Could it mean we live in harmoniousness, instead \nof a competition-based society? Maybe. Could it mean, something else? Maybe. \nCould it mean a rewiring of our ethics and morals so far that we won’t even be \nable to recognize it from our viewpoint today? Maybe. What I am suggesting is we \nmay need a level of imagination about our own potential and the potential of the \nentire human race to change this game, and I don’t think this game we’re playing \nnow is going to end well.\nMARTIN FORD: You’ve acknowledged that if the kinds of technologies that you are \nthinking about fell into the wrong hands, then that could pose a great risk. We’d \nneed to address that globally, and that seems to present a coordination problem. \nBRYAN JOHNSON: I totally agree, I think we absolutely need to focus on that \npossibility with the utmost attention and care. That’s how human and nation states \nare going to behave based on historical data. \nAn equal part to that is that we need to extend our imagination to a point \nwhere we can alter that fundamental reality to where we may not have to assume \nthat everyone’s going to just work on their own interests and that people will \ndo whatever they can to other people to achieve what they want. What I am \nsuggesting is that calling into question those fundamentals is something we are \nnot doing as a society. Our brain keeps us trapped in our current perception of \nwhat is reality because it’s very hard to imagine that the future would be different \nto what we currently live in. \nMARTIN FORD: You have discussed your concern that we might all become \nextinct, but overall, are you an optimist? Do you think that as a race we will \nrise to these challenges? \nBRYAN JOHNSON: Yes, I would definitely say I’m an optimist. I’m absolutely bullish \non humanity. The statements I make about the difficulties that we face are in order \nto create a proper assessment of our risk. I don’t want us to have our heads in \nthe sand. We have some very serious challenges as a species, and I think we need \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 704
  },
  {
    "chunk_full": "BRYAN JOHNSON\n525\nto reconsider how we approach these problems. That’s one of the reasons why I \nfounded OS Fund—we need to invent new ways to solve the problems at hand. \nAs you’ve heard me say many times now, I think we need to rethink the first \nprinciples on our existence as a human, and what we can become as a species. To \nthat end, we need to prioritize our own improvement above everything else, and AI \nis absolutely essential for that. If we do that to a point where we can prioritize our \nimprovement and get fully involved in AI, in a way that we both progress together, \nI think we can solve all the problems that we are facing, and I think we can create \nan existence that’s far more magical and fantastic than anything we can imagine. \n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 705
  },
  {
    "chunk_full": "526\nARCHITECTS OF INTELLIGENCE\nBRYAN JOHNSON is founder of Kernel, OS Fund and Braintree. \nIn 2016, he founded Kernel, investing $100M to build advanced neural interfaces to treat \ndisease and dysfunction, illuminate the mechanisms of intelligence, and extend cognition. \nKernel is on a mission to dramatically increase our quality of life as healthy lifespans extend. \nHe believes that the future of humanity will be defined by the combination of human and \nartificial intelligence (HI+AI).\nIn 2014, Bryan invested $100M to start OS Fund, which invests in entrepreneurs \ncommercializing breakthrough discoveries in genomics, synthetic biology, artificial intelligence, \nprecision automation, and the development of new materials.\nIn 2007, Bryan founded Braintree (and acquired Venmo), which he sold to PayPal in \n2013 for $800M. Bryan is an outdoor-adventure enthusiast, pilot, and the author of a \nchildren’s book, Code 7.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 706
  },
  {
    "chunk_full": "BRYAN JOHNSON\n527\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 707
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n528\nWhen Will Human-Level AI be Achieved? Survey Results\nAs part of the conversations recorded in this book, I asked each participant to give \nme his or her best guess for a date when there would be at least a 50 percent \nprobability that artificial general intelligence (or human-level AI) will have been \nachieved. The results of this very informal survey are shown below. \nA number of the individuals I spoke with were reluctant to attempt a guess at a \nspecific year. Many pointed out that the path to AGI is highly uncertain and that there \nare an unknown number of hurdles that will need to be surmounted. Despite my \nbest persuasive efforts, five people declined to give a guess. Most of the remaining \n18 preferred that their individual guess remain anonymous.\nAs I noted in the introduction, the guesses are neatly bracketed by two people willing \nto provide dates on the record: Ray Kurzweil at 2029 and Rodney Brooks at 2200. \nHere are the 18 guesses:\n2029...........11 years from 2018 \n2036...........18 years \n2038...........20 years \n2040...........22 years \n2068 (3)......50 years \n2080...........62 years \n2088...........70 years \n2098 (2)......80 years \n2118 (3)......100 years \n2168 (2)......150 years \n2188...........170 years \n2200...........182 years\nMean: 2099, 81 years from 2018\nNearly everyone I spoke to had quite a lot to say about the path to AGI, and many \npeople—including those who declined to give specific guesses—also gave intervals \nfor when it might be achieved, so the individual interviews offer a lot more insight \ninto this fascinating topic.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 708
  },
  {
    "chunk_full": "MARTIN FORD\n529\nIt is worth noting that the average date of 2099 is quite pessimistic compared \nwith other surveys that have been done. The AI Impacts website1 shows results for \na number of other surveys.\nMost other surveys have generated results that cluster in the 2040 to 2050 range \nfor human-level AI with a 50 percent probability. It’s important to note that most \nof these surveys included many more participants and may, in some cases, have \nincluded people outside the field of AI research. \nFor what it’s worth, the much smaller, but also very elite, group of people I spoke \nwith does include several optimists, but taken as a whole, they see AGI as something \nthat remains at least 50 years away, and perhaps 100 or more. If you want to see \na true thinking machine, eat your vegetables.\n1  https://aiimpacts.org/ai-timeline-surveys/\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 709
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n530\nAcknowledgments\nThis book has truly been a team effort. Packt acquisitions editor Ben Renow-Clarke \nproposed this project to me in late 2017, and I immediately recognized the value \nof a book that would attempt to get inside the minds of the foremost researchers \nresponsible for building the technology that will very likely reshape our world.\nOver the past year, Ben has been instrumental in guiding and organizing the project, \nas well as editing the individual interviews. My role primarily centered on arranging \nand conducting the interviews. The massive undertaking of transcribing the audio \nrecordings and then editing and structuring the interview text was handled by the \nvery capable team at Packt. In addition to Ben, this includes Dominic Shakeshaft, \nAlex Sorrentino, Radhika Atitkar, Sandip Tadge, Amit Ramadas, Rajveer Samra, and \nClare Bowyer for her work on the cover.\nI am very grateful to the 23 individuals I interviewed, all of whom were very \ngenerous with their time, despite extraordinarily demanding schedules. I hope and \nbelieve that the time they invested in this project has produced a result that will be \nan inspiration for future AI researchers and entrepreneurs, as well as a significant \ncontribution to the emerging discourse about artificial intelligence, how it will \nimpact society, and what we need to do to ensure that impact is a positive one.\nFinally, I thank my wife Xiaoxiao Zhao and my daughter Elaine for their patience \nand support as I worked to complete this project.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 710
  },
  {
    "chunk_full": "ARCHITECTS OF INTELLIGENCE\n546\nmapt.io\nMapt is an online digital library that gives you full access to over 5,000 books and \nvideos, as well as industry leading tools to help you plan your personal development \nand advance your career. For more information, please visit our website.\nWhy subscribe?\nz\nz\nSpend less time learning and more time coding with practical eBooks \nand Videos from over 4,000 industry professionals\nz\nz\nLearn better with Skill Plans built especially for you\nz\nz\nGet a free eBook or video every month\nz\nz\nMapt is fully searchable\nz\nz\nCopy and paste, print, and bookmark content\nPackt.com\nDid you know that Packt offers eBook versions of every book published, with PDF \nand ePub files available? You can upgrade to the eBook version at www.packt.com \nand as a print book customer, you are entitled to a discount on the eBook copy. \nGet in touch with us at service@packt.com for more details.\nAt www.packt.com, you can also read a collection of free technical articles, sign \nup for a range of free newsletters, and receive exclusive discounts and offers on \nPackt books and eBooks.\n",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 711
  },
  {
    "chunk_full": "",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 712
  },
  {
    "chunk_full": "",
    "book_id": "architects_of_intelligence",
    "book_title": "Architects of Intelligence",
    "book_author": "Martin Ford",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 713
  },
  {
    "chunk_full": "Produced in partnership with\nData strategies  \nfor AI leaders\nAs generative AI adoption reshapes the competitive \nlandscape, businesses without a strong data strategy  \nwill find their ambitions limited. \n",
    "book_id": "data-strategies-for-ai-leaders",
    "book_title": "Data-Strategies-for-AI-Leaders",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 714
  },
  {
    "chunk_full": "“\u0007AI is opening the door \nfor organizations to gain \ninsights from unstructured \ndata that they simply \ncouldn’t before.”\n Baris Gultekin, Head of AI, Snowflake\n2 \n\t\nMIT Technology Review Insights\nO\n \ngenerative AI and the possibilities. In 2024, we are \nstarting to see scaled implementations of responsible \ngenerative AI programs.” \nSome generative AI efforts remain modest. As Neil \nWard-Dutton, vice president for automation, analytics, \nand AI at IDC Europe, describes it, this is “a classic kind \nof automation: making teams or individuals more \nproductive, getting rid of drudgery, and allowing people \nto deliver better results more quickly.” \nMost companies, though, have much greater ambitions \nfor generative AI: they are looking to reshape how they \noperate and what they sell.\nGreat expectations for generative AI\nThe expectation that generative AI could fundamentally \nupend business models and product offerings is driven \nby the technology’s power to unlock vast amounts of \ndata that were previously inaccessible. “Eighty to  \n90% of the world’s data is unstructured,” says Baris \nGultekin, head of AI at AI data cloud company Snowflake. \n“But what’s exciting is that AI is opening the door for \norganizations to gain insights from this data that they \nsimply couldn’t before.”\nrganizations are starting the heavy lifting to \nget real business value from generative AI. \nAs Arnab Chakraborty, chief responsible  \nAI officer at Accenture, puts it, “2023 was \nthe year when clients were amazed with \nKey takeaways\nExecutives’ top ambition for generative \nAI adoption is driving increased \nefficiency or productivity (72%), far \nexceeding their interest in increasing \nrevenue (30%) or reducing costs (24%).\nStrong data capabilities will be essential \nunderpinnings to these aspirations, but \nonly 22% of businesses consider their \ndata foundations “very ready” to support \ngenerative AI applications today. \nThe rise of AI exacerbates longstanding \nchallenges in data management—data \ngovernance, security, and privacy (cited \nby 59%), data quality and timeliness \n(53%), and data integration (48%)—and \nmay supply the urgency needed to finally \naddress them.\nIn a poll conducted by MIT Technology Review Insights, \nglobal executives were asked about the value they \nhoped to derive from generative AI. Many say they are \nprioritizing the technology’s ability to increase efficiency \nand productivity (72%), increase market competitiveness \n(55%), and drive better products and services (47%). \nFew see the technology primarily as a driver of  \nincreased revenue (30%) or reduced costs (24%),  \nwhich is suggestive of executives’ loftier ambitions. \nRespondents’ top ambitions for generative AI seem to \nwork hand in hand. More than half of companies say new \nroutes toward market competitiveness are one of their \ntop three goals, and the two likely paths they might take to \nachieve this are increased efficiency and better products \nor services. \n1\n2\n3\nMIT Technology Review Insights conducted a poll on \nbusinesses’ data foundations for generative AI and \ntheir ambitions and challenges when deploying and \nscaling generative AI applications in May 2024. The \n275+ executive respondents represent a broad range of \nindustries and work at organizations across the globe.\nMethodology\n",
    "book_id": "data-strategies-for-ai-leaders",
    "book_title": "Data-Strategies-for-AI-Leaders",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 715
  },
  {
    "chunk_full": "For companies rolling out generative AI, these are not \nnecessarily distinct choices. Chakraborty sees a “thin  \nline between efficiency and innovation” in current activity.  \n“We are starting to notice companies applying generative \nAI agents for employees, and the use case is internal,”  \nhe says, but the time saved on mundane tasks allows \npersonnel to focus on customer service or more creative \nactivities. Gultekin agrees. “We’re seeing innovation with \ncustomers building internal generative AI products that \nunlock a lot of value,” he says. “They’re being built for \nproductivity gains and efficiencies.” \nChakraborty cites marketing campaigns as an example: \n“The whole supply chain of creative input is getting \nre-imagined using the power of generative AI. That is \nobviously going to create new levels of efficiency, but  \nat the same time probably create innovation in the way \nyou bring new product ideas into the market.” Similarly, \nGultekin reports that a global technology conglomerate \nand Snowflake customer has used AI to make “700,000 \npages of research available to their team so that they  \ncan ask questions and then increase the pace of their \nown innovation.” \nThe impact of generative AI on chatbots—in Gultekin’s \nwords, “the bread and butter of the recent AI cycle”— \nmay be the best example. The rapid expansion in chatbot \ncapabilities using AI borders between the improvement  \nof an existing tool and creation of a new one. It is \nunsurprising, then, that 44% of respondents see improved \ncustomer satisfaction as a way that generative AI will \nbring value.\nA closer look at our survey results reflects this overlap \nbetween productivity enhancement and product or \nservice innovation. Nearly one-third of respondents (30%) \nincluded both increased productivity and innovation in  \nthe top three types of value they hope to achieve with \ngenerative AI. The first, in many cases, will serve as the \nmain route to the other.\nBut efficiency gains are not the only path to product  \nor service innovation. Some companies, Chakraborty  \nsays, are “making big bets” on wholesale innovation with \ngenerative AI. He cites pharmaceutical companies as an \n3\nMIT Technology Review Insights\nexample. They, he says, are asking fundamental questions \nabout the technology’s power: “How can I use generative \nAI to create new treatment pathways or to reimagine my \nclinical trials process? Can I accelerate the drug discovery \ntime frame from 10 years to five years to one?” \nData strategy underlies AI innovation\nBehind the diversity of ways in which respondents hope \nto secure value from generative AI looms one common-\nality: the need for enormous quantities of the business’s \nown data, accessibly stored and ready to use. Off-the-\nshelf AI tools will not differentiate businesses when their \nadoption will soon be universal. For any enterprise AI \nuse case, says Ward-Dutton, “there is no value without \ngood business data” of the company’s own. \n“\u0007There is no value without good business data.”\nNeil Ward-Dutton, Vice President for Automation, Analytics, and AI, IDC Europe\nExecutive aspirations for generative  \nAI adoption\nWhat are the primary types of value your organization  \nhope to achieve from its generative AI efforts? \nSource: MIT Technology Review Insights poll, 2024\nIncreased efficiency or productivity\nFirst choice\nSecond choice\nThird choice\nIncreased market competitiveness\nInnovation in products or services\nImproved customer satisfaction\nIncreased revenue\nFaster decision-making\n13%\n23%\n36%\n17%\n14%\n24%\n22%\n13%\n12%\n19%\n18%\n7%\n9%\n11%\n10%\n13%\n10%\n6%\n8%\n10%\n6%\nReduced costs\n72%\n55%\n47%\n44%\n30%\n24%\n29%\n",
    "book_id": "data-strategies-for-ai-leaders",
    "book_title": "Data-Strategies-for-AI-Leaders",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 716
  },
  {
    "chunk_full": "4 \n\t\nMIT Technology Review Insights\nOne of the great benefits of generative AI is that it can \nmake use of unstructured data, which many companies \nhave in great quantities, such as wikis, documents, and \nwebpages. As Gultekin explains, “AI makes all of this  \ndata much more useful because now you can unlock  \na massive amount of it that wasn’t easily accessible \nbefore.” Moreover, humans can ask questions of their \ndata using natural language. This has a significant  \nimpact on enterprises, helping them deliver insights  \nfrom previously untapped sources of information.\nThis flood of newly accessible data, though, represents \nboth an opportunity and a competitive requirement. \nChakraborty describes the challenge: “To create \nsignificant differentiation that becomes a competitive \nasset, you need to start almost building your own large \nlanguage models, which means you need to train on \nmassive amounts of data harnessed from within your \nenterprise—from finance to HR to supply chain to \nmarketing—and marry that with external data.”\nHow ready, though, are most companies’ data estates  \nto support them in the race to generative AI value? \nGultekin puts it plainly: “The data foundation is at the core \nof generative AI capabilities.” Data foundations cover a \nbroad collection of processes and assets involved in  \nthe gathering, aggregation, storage, and accessibility  \nof organizational data. \nChakraborty identifies three specific data capabilities \nnecessary to support the effective deployment of \ngenerative AI: the quality of the data; the ability to \nintegrate multiple sources of data; and the timely \ndemocratization of data to relevant business users.  \nThese are persistent difficulties, he notes, saying “all  \nhave been issues that we have heard about for 10 years.” \nThese challenges will not easily be addressed this time, \neither, he warns: “We still will be 10 years from now, as  \n“\u0007To create significant differentiation that becomes a \ncompetitive asset, you need to start almost building your \nown large language models, which means you need to \ntrain on massive amounts of data harnessed from within \nyour enterprise and marry that with external data.”\nArnab Chakraborty, Chief Responsible AI Officer, Accenture \nwell, because data is very dynamic and the speed at which \nit is getting created is magnifying every month.”\nAt first glance, most poll respondents seem positive about \nthe state of their company data foundations. The majority \nrate their business “very ready” (22%) or “somewhat \nSource: MIT Technology Review Insights poll, 2024\nData foundations are “somewhat ready”  \nfor generative AI\nTo what extent are your organization’s data foundations  \nready to support generative AI applications?\nVery  \nready \n22%\nVery  \nunready \n8%\nSomewhat  \nready \n53%\nSomewhat  \nunready \n17%\nEfficiency gains and innovation go  \nhand in hand \nWhat are the primary types of value your organization  \nhopes to achieve from its generative AI efforts? \nSource: MIT Technology Review Insights poll, 2024\nSelected just  \ninnovation in \nproducts or \nservices\n17%\nSelected  \nboth\nSelected just \nincreased \nefficiency/\nproductivity\n30%\n42%\n",
    "book_id": "data-strategies-for-ai-leaders",
    "book_title": "Data-Strategies-for-AI-Leaders",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 717
  },
  {
    "chunk_full": "5\nMIT Technology Review Insights\nready” (53%) to support generative AI applications, while \nabout one-quarter acknowledge that their organization is \neither “somewhat unready” (17%) or “very unready” (8%). \nThis distribution is consistent with the experience of \nexperts. Ward-Dutton, for example, says that, in his \ninteractions with companies, “We consistently see a bell \ncurve. The people at the front end have already made \nsignificant investments in things like data governance and \ndata quality. There are also a bunch of people still using, \nbasically, Excel for everything.”\nChakraborty warns that being “somewhat ready” could \nconceal dangerous weaknesses. It might describe, for \nexample, an organization that can integrate data sets \nfrom across the business, but that also knows that  \nthe underlying data is not fully clean. If so, he adds, \n“Somewhat ready is not good enough. On accuracy and \nthe quality of the data, 50% ready is not good enough.  \nIt needs to be higher to create trust.” He adds, “On the \nability to democratize that data to business users”— \nto get users the data they need when they need it— \n“somewhat ready is also not good enough.”\nIDC’s research, Ward-Dutton says, shows that “somewhat \nready” is rarely “almost ready” in practice. The company’s \nsurveys have found that only 30 to 40% of businesses are \nconfident in their ability to perform each of the following \ndata controls in their AI work: strictly control sensitive \ndata with certainty that none will be leaked during model \ntraining or use; manage use of third-party IP included in \nthe models they are using and ensure that their own IP \ndoes not leak; and track and control how generative AI is \ninteracting with their own internal data. His conclusion \nfrom such data is that “overall, readiness is pretty \nequivocal.”\nNor is it all clear sailing for companies self-ranked “very \nready” by respondents. Instead, investment of resources \nand time in their data foundations may just have made \nclear their next set of challenges. \nThe main challenges of deploying generative AI at  \nscale are different for companies who say their data \nfoundations are “very ready.” Predictably, higher readiness \ncorrelates with fewer challenges related to access to \nscalable computing power, data silos and integration \nissues, and data governance. In contrast, “very ready” \ncompanies face more data quality issues, presumably \nbecause better access to the information has revealed  \nThe hallucination  \nchallenge\nHallucinations—or the tendency of generative AI models \nto produce confident, but incorrect outputs—are a major \nchallenge organizations face in deploying AI applications. \nAfter all, no company wants to deploy a chatbot that makes \nfalse promises about its return policies to its customers or \nan internal data tool that delivers unfounded insights to  \nits analysts. \nBaris Gultekin of Snowflake sees hallucinations as a \nmajor concern, and he has advocated for an insistence on \nhigher accuracy rates in the next generation of AI-based \ntools. “For large enterprises, AI accuracy is imperative, \nand providing users with trustworthy AI will be the leading \nfactor for businesses’ AI success at scale,” Gultekin \nnotes. Ensuring the quality and cleanliness of the data \nused to train AI models is of course an essential first step \nto improving their outputs, he continues—“garbage in, \ngarbage out” is a common refrain.\nCompanies are also addressing hallucinations through \nimproved techniques for ensuring accurate AI responses. \nRetrieval augmented generation (RAG), for example, is a \ntechnique used to ensure that AI outputs are grounded \nin verifiable outside data. Guardrails can impose firm \nboundaries around the language or topics generative AI \noutputs can contain, and human and computer review of \noutputs can iteratively improve an AI application’s results.\nAnd sometimes it’s best for AI to simply acknowledge \nthat it doesn’t know. Gultekin says, “We’ve been focused \non building products that know when to abstain from \nanswering a question. LLMs are blissfully ignorant about \nwhen they should not be answering, which is a dangerous \nslope for businesses’ critical decision-making. We’ve  \nbeen investing in making systems that know when not  \nto answer.”\n",
    "book_id": "data-strategies-for-ai-leaders",
    "book_title": "Data-Strategies-for-AI-Leaders",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 718
  },
  {
    "chunk_full": "6 \n\t\nMIT Technology Review Insights\nA wide range of AI deployment  \nand scaling challenges\nWhich of the following challenges does your organization \nface when it comes to deploying AI at scale?  \nSource: MIT Technology Review Insights poll, 2024\nits shortcomings. As Chakraborty says, “data-driven \ntransformation is not something where you can say, ‘I’ve \ndone it for the last two to three years, and now I’m done.’ \nIt’s a journey that will never be done.”\nThat said, generative AI’s benefits are becoming visible  \nto those companies farther along the road. Gultekin \nreports that companies that have invested heavily in data \nfoundations are “all now reaping the benefits, because \nthey are able to bring AI onto that data.” Ward-Dutton \nadds that this deployment of generative AI represents a \nbusiness leap as well as a technological one. Companies \nthat have invested in data governance and quality, he says, \n“typically have also got to the point where they’re really \nengaging business people in how to manage data.” Now, \nthe business people see, “‘Wow, this data actually has \nvalue for me.’”\nRoadblocks in the search for AI value\nNothing good comes easy. Nearly all poll respondents \nacknowledge challenges in deploying generative AI.  \nOnly 5% said that they did not face any of the challenges \nlisted in the question.\nA majority of respondents (59%) cite data governance, \nsecurity, or privacy as a challenge. Nearly as many (53%) \nsay the same of data quality or timeliness. Meanwhile, \nnearly half face difficulties with cost (49%) and with \novercoming data integration challenges (48%). \nThese are longstanding issues in data management,  \nbut the advent of AI complicates them further. It also,  \nas Ward-Dutton explains, increases the urgency of finally \ngrappling with them. “For a long time, many organizations \nhave been able to limp along, or even do relatively well, \nwithout being very good at data-related technical, cultural, \nand organizational capabilities,” he says. “We’re seeing a \nlot having to catch up fast.”\nIt is unsurprising that data governance, security, or  \nprivacy is the most widespread challenge. Corporate data \nrepresent a company’s “crown jewels,” says Gultekin. \nDeep concern about it is inevitable. Ward-Dutton adds \nthat, despite “quite good awareness at a high level” of the \nrisks involved, “people are still flailing around a bit to find \nthe right mix of responses.” \nGultekin summarizes the many governance concerns \nsurrounding generative AI: “At the foundational level, AI \nstarts with securing and governing data. Companies want \nData governance, security, or privacy\nData quality or timeliness\nCosts or resource investment\nData silos or data integration challenges\nAccess to scalable computing power\nCloud readiness\nNone of these\n59%\n53%\n49%\n48%\n25%\n13%\n5%\n",
    "book_id": "data-strategies-for-ai-leaders",
    "book_title": "Data-Strategies-for-AI-Leaders",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 719
  },
  {
    "chunk_full": "7\nMIT Technology Review Insights\ncapability piece and the organizational and cultural one \nare two sides of the same coin.”\nData silos and data integration remain a challenge for \nnearly half of organizations. Gultekin notes that generative \nAI has heightened awareness of this problem as well.  \nBy making large amounts of data all “much more useful \nand much more accessible,” he says, “it is shedding a lot \nof light on the data infrastructure that is needed.” He \nargues that investment in a single, standardized data \nfoundation across the organization will enable much  \nmore powerful generative AI uses. It will also reduce \ngovernance and security concerns: “When you keep  \nyour data in one place for one thing, another place for \nanother thing, governing and securing that data  \nbecomes really difficult,” he says.\nSpending and resource decisions, including those needed \nto shore up data foundations, are of course a challenge \nwhen it comes to any technology investment. On the \nbright side, the cost of generative AI itself is decreasing \nsubstantially. In particular, Gultekin reports, in recent \nmonths, enterprises have begun creating smaller LLMs \nthat remain extremely capable while being less expensive. \n“All these distilled models are still as good,” he says.  \n“They are also very cost-effective and very good from  \na latency perspective.”\nAs organizations feel increasing urgency to deploy  \nAI applications, they are realizing that their data is the  \nkey to how quickly and effectively they can unlock new \nvalue. Many will find that their generative AI ambitions  \nare just castles in the air if they don’t have the right data \nfoundations to support them. A strong data strategy, \nhowever, can guide them to surmount their data \nchallenges on the way to AI success.\nto bring AI closer to their data, ensuring that data security \nand privacy are upheld. On top of that, customers want \nassurances that they are not liable for the data that the \nlarge language model was trained with, and they want to \nensure that their data does not get used to improve the \nmodel for others without their permission. These are all \ntable stakes and should be the industry standard.”\nSafe use of generative AI requires careful governance  \nof its data sources. Chakraborty explains that the vast \namount of public and company data used to train  \na large language model brings with it inherent risks.  \n“You need a very surgical view in data governance,” he \nsays. From sourcing data to creating outputs, companies \nrequire very strong data governance, including clarity  \non who owns the data and who stewards it. Adding to  \nthe challenge, Gultekin explains, “is that the new data \ngenerative AI makes accessible may not itself be  \nfully governed.”\t\nData quality and timeliness is another predictable concern. \nAs Chakraborty puts it, “if your data quality is not clean, \nyou are going to get all kinds of garbage.” Yet because  \nof the opaque way in which the technology works, this \nmay not be obvious. This is where data lineage becomes \ncritical, ensuring transparency and traceability of data as \nit moves through systems. For those scaling up generative \nAI pilots, thereby giving the technology a greater role, \nsuch quality issues magnify, adds Gultekin.\nWhile IT departments are typically told to fix low-quality \ndata, the problem is caused where the information began \n“in the first place: that typically is the business,” says \nWard-Dutton. Employees who understand the value of \ntheir data “are much more likely to care about the quality \nof what they’re providing,” he says. “The technical or the \n“For a long time, many organizations have been able to \nlimp along, or even do relatively well, without being very \ngood at data-related technical, cultural, and organizational \ncapabilities. We’re seeing a lot having to catch up fast.”\nNeil Ward-Dutton, Vice President for Automation, Analytics, and AI, IDC Europe\n",
    "book_id": "data-strategies-for-ai-leaders",
    "book_title": "Data-Strategies-for-AI-Leaders",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 720
  },
  {
    "chunk_full": "8 \n\t\nMIT Technology Review Insights\nIllustrations\nCover art and spot illustrations created with Adobe Stock. \nFrom the sponsor\nSnowflake makes enterprise AI easy, efficient, and trusted. Thousands of companies around the globe, \nincluding hundreds of the world’s largest, use Snowflake’s AI Data Cloud to share data, build applications, and \npower their business with AI. The era of enterprise AI is here. Learn more at snowflake.com (NYSE: SNOW).\nWhat is the AI Data Cloud?\nThe AI Data Cloud is a unified service used by over 10,000 companies to power their businesses with  \ndata, AI, and applications. Snowflake’s AI Data Cloud consists of platform capabilities that support diverse data, \nAI, and applications workloads, as well as content—the datasets, models, and apps themselves—that are \navailable to share and consume natively in the AI Data Cloud. The AI Data Cloud platform includes: \n• Interoperable Storage: Snowflake-hosted and optimized storage (or extends to cloud data lakes)\n• Elastic Compute: a unified engine supporting many languages and runtime needs\n• Cortex AI: a managed AI layer including foundational LLMs, Chat API, and UI studio\n• Cloud Services: infrastructure delivered as a service, including high availability and maintenance\n• Snowgrid: a cross-region, cross-cloud network supporting data sharing and business continuity\n“Data strategies for AI leaders” is an executive briefing paper by MIT Technology Review Insights. We would like to thank \nall participants as well as the sponsor, Snowflake. MIT Technology Review Insights has collected and reported on all \nfindings contained in this paper independently, regardless of participation or sponsorship. Teresa Elsey was the editor  \nof this report, and Nicola Crepaldi was the publisher.\nWhile every effort has been taken to verify the accuracy of this information, MIT Technology Review Insights cannot accept any responsibility or liability for reliance by any person \non this report or any of the information, opinions, or conclusions set out in this report.\n© Copyright MIT Technology Review Insights, 2024. All rights reserved.\nAbout MIT Technology Review Insights\nMIT Technology Review Insights is the custom publishing division of MIT Technology Review, the world’s \nlongest-running technology magazine, backed by the world’s foremost technology institution—producing  \nlive events and research on the leading technology and business challenges of the day. Insights conducts \nqualitative and quantitative research and analysis in the US and abroad and publishes a wide variety of  \ncontent, including articles, reports, infographics, videos, and podcasts. And through its growing MIT Technology \nReview Global Insights Panel, Insights has unparalleled access to senior-level executives, innovators, and \nentrepreneurs worldwide for surveys and in-depth interviews.\n",
    "book_id": "data-strategies-for-ai-leaders",
    "book_title": "Data-Strategies-for-AI-Leaders",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 721
  },
  {
    "chunk_full": "MIT Technology Review Insights\nwww.technologyreview.com\ninsights@technologyreview.com\n",
    "book_id": "data-strategies-for-ai-leaders",
    "book_title": "Data-Strategies-for-AI-Leaders",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 722
  },
  {
    "chunk_full": "![cover-image, email-to-the-universe-6-26-2017](../Images/image-IQEBYT4Q.jpg)\n\n\n  \n\n![cover-image, email-to-the-universe-6-26-2017](../Images/image-IQEBYT4Q.jpg)\n\n\nEmail to the Universe\n\n\nand other alterations of consciousness\n\n\n#### Robert Anton Wilson\n\n  \n\nIllustrations by\n\nRichard Rasa\n\n  \n\nIntroduction by\n\nR. Michael Johnson\n\n  \n\nAfterword by\n\nPaul Krassner\n\n  \n\n￼\n\n![Hilaritas-Press-Logo-eBook-440.jpg](../Images/image-OM3VJPDD.jpg)\n\n  \n\n  \n\nCopyright © 2005 Robert Anton Wilson\n\n  \n\nAll rights reserved. No part of this book, in part or in whole, may be\nreproduced, transmitted, or utilized, in any form or by any means, electronic\nor mechanical, including photocopying, recording, or by any information\nstorage and retrieval system, without permission in writing from the\npublisher, except for brief quotations in critical articles, books and\nreviews.\n\n  \n\nFirst Edition 2005\n\nSecond Printing 2008\n\nThird Printing 2011\n\neBook Version 1.0—2017, Hilaritas Press\n\n  \n\nHilaritas Press Print Edition ISBN-10:0-9987134-0-6\n\neBook: ISBN: 978-1-952746-03-1\n\n  \n\nCover Design by amoeba\n\neBook Design by Pelorian Digital\n\n  \n\nHilaritas Press, LLC.\n\nP.O. Box 1153\n\nGrand Junction, Colorado 81502\n\n[www.hilaritaspress.com](http://www.hilaritaspress.com/)\n\n  \n\nto Arlen,\n\n  \n\ndove sta memora\n\n  \n\n  \n\nIt is dangerous to understand new things too quickly.\n\n  \n\n— Josiah Warren, True Civilization\n\n  \n\n  \n\n￼\n\n![0-Olga-standing.jpg](../Images/image-44J1L3Z2.jpg)\n\n\n#### CONTENTS\n\n  \n\n[Introduction by R. Michael Johnson](chapter0004.html)\n\n[Note](chapter0005.html)\n\n  \n\n[Part I: Brain Gym — Simple Exercizes](chapter0006.html)\n\n  \n\n[• Old Man On A Balcony: Views Of Monterey Bay #1](chapter0008.html)\n\n[The Passion Of The Antichrist](chapter0009.html)\n\n[• Old Man On A Balcony: Views Of Monterey Bay #2](chapter0010.html)\n\n[The One “Law\" Of Economics](chapter0011.html)\n\n[• Old Man On A Balcony: Views Of Monterey Bay #3](chapter0012.html)\n\n[The Celtic Roots Of Quantum Theory](chapter0013.html)\n\n[• Old Man On A Balcony: Views Of Monterey Bay #4](chapter0015.html)\n\n[Schrodinger’s Other Cat](chapter0016.html)\n\n[• Old Man On A Balcony: Views Of Monterey Bay #5](chapter0017.html)\n\n[Paranoia](chapter0018.html)\n\n[• Old Man On A Balcony: Views Of Monterey Bay #6](chapter0019.html)\n\n[Black Magick & Curses](chapter0020.html)\n\n[• Old Man On A Balcony: Views Of Monterey Bay #7](chapter0022.html)\n\n[Shocking Hidden Facts About Male Non-Violence](chapter0023.html)\n\n[• Old Man On A Balcony: Views Of Monterey Bay #8](chapter0024.html)\n\n[Language, Logic & Lunacy](chapter0025.html)\n\n[• Old Man On A Balcony: Views Of Monterey Bay #9](chapter0026.html)\n\n[Dreams Of Flying](chapter0027.html)\n\n[• Old Man On A Balcony: Views Of Monterey Bay #10](chapter0028.html)\n\n[God’s Morals](chapter0029.html)\n\n[• Old Man On A Balcony: Views Of Monterey Bay #11](chapter0030.html)\n\n  \n\n[Part II: Advanced Head Trips](chapter0031.html)\n\n  \n\n[Joyce & Daoism](chapter0033.html)\n\n[Movie Haiku](chapter0034.html)\n\n[He Who Thunders From On High](chapter0035.html)\n\n[Becoming What We “Are”](chapter0037.html)\n\n[• Old Man On A Balcony: Views Of Monterey Bay #12](chapter0038.html)\n\n[LSD, Dogs & Me](chapter0039.html)\n\n[• Old Man On A Balcony: Views Of Monterey Bay #13](chapter0040.html)\n\n[Keep Our Troops In Iraq!](chapter0041.html)\n\n[• Old Man On A Balcony: Views Of Monterey Bay #14](chapter0043.html)\n\n[Mary, Mary, Quite Contrary](chapter0044.html)\n\n[• Old Man On A Balcony: Views Of Monterey Bay #15](chapter0045.html)\n\n[Left And Right: A Non-Euclidean Perspective](chapter0046.html)\n\n[La Belle Dame Sans Merci](chapter0047.html)\n\n[The Relativity Of “Reality”](chapter0048.html)\n\n[• Old Man On A Balcony: Views Of Monterey Bay #16](chapter0049.html)\n\n[Committee For Surrealist Investigation Of Claims Of The](chapter0050.html)\n\n[Normal (CSICON)](chapter0050.html)\n\n  \n\n[Part III: In Defense of the Damned](chapter0051.html)\n\n  \n\n[• Old Man On A Balcony: Views Of Monterey Bay #17](chapter0053.html)\n\n[Guns &. Dope Party](chapter0054.html)\n\n[Damnation By Definition](chapter0055.html)\n\n[• Old Man On A Balcony: Views Of Monterey Bay #18](chapter0056.html)\n\n[CyberRevolution Montage](chapter0057.html)\n\n[Deforestation](chapter0058.html)\n\n[Piss Wars](chapter0059.html)\n\n[• Old Man On A Balcony: Views Of Monterey Bay #19](chapter0060.html)\n\n[The Horror On Howth Hill](chapter0061.html)\n\n[Sexual Alchemy](chapter0062.html)\n\n[• Old Man On A Balcony: Views Of Monterey Bay #20](chapter0062.html)\n\n  \n\n[Part IV: Q & A](chapter0063.html)\n\n  \n\n[• Old Man On A Balcony: Views Of Monterey Bay #21](chapter0065.html)\n\n[Questions Answered](chapter0066.html)\n\n[• Old Man On A Balcony: Views Of Monterey Bay #22](chapter0066.html)\n\n[More Questions Answered](chapter0067.html)\n\n[• Old Man On A Balcony: Views Of Monterey Bay #23](chapter0067.html)\n\n[Still More Questions Answered](chapter0068.html)\n\n  \n\n[Part V: On My Way Out](chapter0069.html)\n\n  \n\n[Escape From CNN](chapter0071.html)\n\n[Cheerful Reflections On Death And Dying](chapter0072.html)\n\n[On My Way Out](chapter0073.html)\n\n[Afterword by Paul Krassner](chapter0074.html)\n\n  \n\n#### Introduction\n\n  \n\nBy R. Michael Johnson\n\n  \n\nThe genesis for this book — half of which consists of a compendia of fugitive\nwritings by Robert Anton Wilson spanning 1959-2003 — may seem non-ordinary, so\nhere goes: In the mid-to-late 1990s a devoted coterie of Robert Anton Wilson\nfans (etymology from “fanatics”) met each other digitally and virtually on the\nold Usenet group alt.fan.rawilson, and we exchanged at times our own extended,\nmulti-paragraphed views on “RAW.” At one point, I mentioned the interview in\nthe library reference book Contemporary Authors, in which Wilson guessed he’d\nsold 1500 (or was it 2000?) articles for various print publications, beginning\nin 1959. He added he’d rather be “rhino gored” than to see some of those\narticles re-surface. On alt-fan-rawilson, we began to wonder about all those\n“lost” articles; we loved Wilson’s writings so much we agreed that even his\nephemera would be pretty good, but RAW had never published an exhaustive\nbibliography, so we had to guess at some likely small periodicals, based on\nhints from his published books.\n\nMike Gathers soon notified me that he’d found some of RAW’s lost work by using\n“Robert Anton Wilson” as a keyword on eBay, so I started doing the same. We’d\nbuy old issues of magazines like Oui, Cavalier, Green Egg, Gnostica, Critique:\nA Journal of Conspiracies and Metaphysics, New Libertarian, Spit In The Ocean,\nHeavy Metal, Spin, Neurolog, Starship, Future Life, High Times, Way Out, No\nGovernor, The Realist, Fact, Mattachine Review, Fortean Times, Conspiracy\nDigest, Journal of Human Relations, The Thresher and Magical Blend, among many\nothers. I found Wilson’s first published article from 1959, from the James\nJoyce Review (included in this volume: see “Joyce and Daoism”) via\ninterlibrary loan.\n\nAs we announced our finds, other Wilson fanatics stepped in to add they had\nsome rare or obscure Wilson material that had never made it into his books.\nFor this Gathers and I have to thank Eric Wagner, Dan Clore, Marc Lutter, and\nTed Hand. Jesse Walker often cited where other articles could be found and\nlater pitched in with his own Wilson ephemera, but I don’t think any of it\nmade it into this book.\n\nMike Gathers then decided, and we all agreed, that these pieces should be\ndigitized and shared, and Gathers did yeoman service on what turned out to be\nrawilsonfans.com (now rawilsonfans.org), stocked with previously-lost\narticles, interviews, and other unpublished writings that one of us had found\non Internet. Indeed, we thought the dredged articles were of high quality,\nsome of it of exceedingly fine merit. Our sole purpose was to share with RAW\nfandom worldwide and at large, for free.\n\nIt turns out Wilson had a contract, circa 2002, with New Falcon for a book\ncalled The Tale of the Tribe, which looks to have been an abundantly ambitious\nwork that he’d been thinking about and making notes for, for a long time. (To\nget a glimpse of the précis for this book, see the last pages of Wilson’s\nTSOG: The Thing That Ate the Constitution.) Wilson never finished his intended\nTale of the Tribe.\n\nHowever, around the year 2000, Wilson (b: 1932) began experiencing\ndebilitating health issues related to his bout with polio as a child. Muscle\ncells in his legs had been damaged and his Post-Polio Syndrome symptoms began\nto haunt him. He’d suffer falls. He was in constant pain. His body temperature\nfelt 15 degrees colder than it “really” was.\n\nIn an effort to fulfill his contractual obligations, he’d spied many of those\nlong-lost pieces that we’d put up at rawilsonfans.com.\n\nIt turns out there were plenty of Wilson articles there that didn’t make him\nfeel like he’d rather be “rhino-gored,” and soon his publisher politely asked\nGathers to take those selected ones down, and Gathers complied. Many of us\nthink these old pieces rank among his finest non-fiction writing.\n\nAs RAW writes on the first page of this book:\n\n  \n\nI wrote these polemics, poems, neurolinguistic experiments and assorted\nmeanderings over a period of about 45 years; they represent part of my life’s\nwork not-previously available in book form — a part that I would now like\npreserved in that (relatively) Hard Copy.\n\n  \n\nAs I recall, Gathers got a free copy of Email To The Universe from this. The\nrest of us were delighted that we’d inadvertently helped Wilson compile\nanother book to add to his massive oeuvre.\n\nThe new, original material for the book consists of the series of haiku, “Old\nMan on a Balcony: Scenes From Monterey Bay.” He enjoyed a wonderful view from\nhis condominium’s balcony overlooking the Pacific near Santa Cruz, smoking\ncannabis (which he had been dedicated to for decades, but now it helped with\nhis post-polio syndrome immensely). Also included are one or two page pieces\nthat often addressed his world in 2003. This is where RAW utilizes Ezra\nPound’s ideogrammic method to stellar effect. I’d point to his extended piece\non his own political party, the Guns and Dope Party, which contains a type of\nhumor that Wilson once referred to as like the literature of the Russian\nDecembrists: RAW juxtaposes movie quotes, short paragraphs about an issue,\nGuns and Dope party platform positions, quotes from historical figures, play\nwith fonts and typeface size, absurdist humor and satire, coded language for\ninsiders, odd photos, open-ended questions, obscure allusions, neologisms,\nand, well see for yourself. The “Guns and Dope Party” essay might be\nclassified as surrealist/neo-Decembrist pamphlet literature, even a sort of\nsamizdat. One of RAW’s favored forms of rhetoric was using humor to make very\nserious points. At this he was a master.\n\nBut RAW really did run for Governor of California under this party, joining\nhis old friend Timothy Leary, who’d run for the same office in 1969, against\nRonald Reagan.\n\nBesides his pieces from the early aughts, there are a few articles that he\npublished online including “Language, Logic and Lunacy” and “Shocking Hidden\nFacts About Male Non-Violence\", from the online ‘zine Backlash!\n\n  \n\nMany of Wilson’s revived pieces had their titles altered from the original; in\naddition, he lightly edited many of the older pieces and liked to add post-\nscriptum-like footnotes as further commentary.\n\nSome notes on the origins of a few of the resurrected articles:\n\n“The Passion of the Antichrist,” came from maverick publisher Ralph Ginzburg’s\nFact, March-April 1964. Even in the years since this was re-published in Email\nTo The Universe it’s taken on a new significance in that we gain a profound\nperspective on what Madelyn Murray went through as an open atheist in early\n1960s U.S., compared to the astonishing traction the so-called New Atheists\n(Richard Dawkins, Sam Harris, Bill Maher, Daniel Dennett, Christopher\nHitchens, et.al) have enjoyed since the 9/11 attacks.\n\n“The Celtic Roots of Quantum Theory” (original source unknown at time of\npress) provides a link to the Irish mathematical genius William Rowan Hamilton\nand his role in quantum theoretical thought, which is usually overlooked in\nbooks written on the origins of quantum theory.\n\nOne day an e-Bay purchase arrived and it was a little self-pressed magazine\nI’d never heard of called Neurolog, which is where “The Relativity of\n‘Reality’” came from. This 1978 piece still seems quite avant-garde, and as I\nwrite in the first month of the Trump Presidency, I can’t help but think if\nmore people read this short gem of an article, the world would be a safer and\nsaner place. The article was embedded among other writers’ works, and I’ve\noften wondered if Wilson got paid at all to write it; Neurolog seems quite\nobscure and looks like one of the thousands of ‘zines published in the late\n1980s/early 90s. The topic of “reality” was always a major issue with Wilson,\nand only now, when the President cites The National Enquirer as a reference to\nbolster claims and the President and others claim media outlets they don’t\nlike as “fake news,” Wilson seems to be avant here too.\n\n“Left and Right: A Non-Euclidean Perspective,” first ran in Critique: A\nJournal of Conspiracies and Metaphysics, in 1988. It has since appeared in\nmany places on the Net, and for good reason: it’s writing about political\nthought that is so lucid and creative and sane it would inevitably be\nforwarded all over the Net, as geopolitics became crazier and more unstable\nunder the acceleration of information in Western culture that RAW called “The\nJumping Jesus Phenomenon.” It’s still stark staring germane, and you will\nprobably want to force this into the hands of a friend or colleague, because,\nsurely, ’tis not an ill wind yet blows many minds.\n\n“Black Magic and Curses” originally appeared in the hard-copy version of The\nThresher in 2003.\n\nSome of the topics Wilson addresses in this book are well-known to Wilson\nreaders: atheism, model agnosticism, quantum theory, the many problems of\nhard-core ideologues, androphobia, James Joyce, dreams and Carl Jung,\nKorzybski and neurosemantics, magick, Vico and “theotopology,” the\nsubconscious mind and movies, psychedelic drugs and expanded perception,\nNietzsche and self-perception, the labyrinthine enigmas and conspiracies\ninvolving a small church in the south of France and Vatican banking\nconspiracies and the Mafia, drug-dealing and modern European fascism; Philip\nK. Dick, anarchism and libertarian thought, Timothy Leary, Einstein, the\nerroneous perception of what’s commonly referred to as “normal,” multi-valued\nlogics, alternative economic ideas, literary modernist figures, sexual magick,\nthe occult and secret societies, and the poverty of Euclidean “Left-Right”\nframing in political thought. Earlier in his career Wilson wrote about\nlongevity and human immortality; in this work he writes about death.\n\nNear the end of the book RAW included snippets of interviews he did from\n1977-2002, the last of which was conducted by his longtime friend Paul\nKrassner in 2002; Krassner brought in Wilson for his legendary countercultural\nsatire magazine The Realist in 1959, when Wilson was 27, giving Wilson his\nfirst regular writing platform with a column titled “Negative Thinking.\"\n\nIn addition, there are heaping doses of what RAW once referred to as\n\"guerrilla ontology”: a zany and Erisian mix of verifiable facts, absurdities,\nfiction disguised as fact and vice-versa, footnotes, a melange of Joyce, Flann\nO’Brien, H.P. Lovecraft, dense allusions, parodies of living epistemologists\nhe perennially disagreed with, and the late 20th century serious-but-joking\n“new religions” of Discordianism and the Church of the Subgenius, of which\n“The Horror of Howth Hill” includes all this and seems to defy classification.\n\nThe form of the book is left for the Reader to discern; Wilson wrote in an at-\ntimes gnomish fashion about the subconscious effects of the Form of books. In\nthis he was heavily influenced by the Modernist tradition of Joyce and Pound.\n\nFor the reader willing to go the whole nine, pay very close attention to the\nvery first pages of the book. Two brief notes on the section titled “Note” . .\n.\n\n  \n\n1.) RAW admits to a variant of a stance of “Intelligent Design.” Have you seen\nthis particular take before?\n\n  \n\n2.) In Wilson’s acknowledgment of the “debt” he owes to meta-modes of thought\npromulgated by Remy de Gourmont, Korzybski, Fuller, Bandler, Shannon and\nWiener, and Ezra Pound, it is my own personal experience, and that of many\nothers with whom I’ve come into personal contact, that each of these ideas or\nany one of them can be studied and implemented by the Reader/Writer/Artist for\na lifetime, without exhausting them. These meta-models for thinking and acting\ncreatively can be thought of as disciplines in the sense that yoga or learning\na musical instrument is a discipline.\n\n  \n\nWilson was the epitome of the freelance writer: outside academe, free to roam\nacross multiple disciplines, not beholden to any Institution and so free to\nwrite what others shied away from, astonishingly erudite, seemingly the ideal\nthinker who sees more and so has a fuller view of the world than\njournalistic/academic/ThinkTank thinkers; he was one of a group of thinkers\nthat the Father of the Sociology of Knowledge, Karl Mannheim, called the\nfreischwebende Intelligenz, or “socially unattached intelligentsia” — a rare\nwriter/thinker/artist who, because of his or her “situated-ness” in the social\nscheme, has views less occluded than usual intellectuals and offers novel and\nnuanced takes on social reality because of this.\n\n  \n\n— R. Michael Johnson\n\n  \n\nPenngrove, CA\n\n  \n\n4 February, 2017\n\n\n#### Note\n\n  \n\n￼ ￼ ￼\n\nThis book intends to change your way of perceiving/conceiving the world,\nwithout drugs or drums or Voodoo, simply by using words in certain special\nways.\n\n  \n\n￼ ￼\n\nI wrote these polemics, poems, neurolinguistic experiments and assorted\nmeanderings over a period of about 45 years; they represent part of my life’s\nwork not previously available in book form — a part that I would now like\npreserved in that (relatively) Hard Copy.\n\nI hereby acknowledge the debts my works owe to Remy de Gourmont, for his\nmethod of dissociation of ideas; to Alfred Korzybski, for his formulations of\nGeneral Semantics; to Richard Bandler, for his invention of neurolinguistic\nprogramming; to Buckminster Fuller for his synergetics; to Claude Shannon and\nNorbert Weiner for their studies of control and communication between animals\nand/or machines; and to Ezra Pound for Ideogrammic Method.\n\nNone of them deserve any blame for my errors and blunders.\n\n  \n\n￼\n\nI don’t believe anything, but I have many suspicions. I strongly suspect that\na world “external to,” or at least independent of, my senses exists in some\nsense.\n\nI also suspect that this world shows signs of intelligent design, and I\nsuspect that such intelligence acts via feedback from all parts to all parts\nand without centralized sovereignty, like the internet; and that it does not\nfunction hierarchically, in the style an Oriental despotism, an American\ncorporation or Christian theology.\n\nI somewhat suspect that Theism and Atheism both fail to account for such\ndecentralized intelligence, rich in circular-causal feedback.\n\nI more-than-half suspect that all “good” writing, or all prose and poetry that\none wants to read more than once, proceeds from a kind of “alteration in\nconsciousness,” i.e., a kind of controlled schizophrenia. (Don’t become\nalarmed — I think good acting comes from the same place.)\n\nI sometimes suspect that what Blake called Poetic Imagination expresses this\nexact thought in the language of his age, and that visits by “angels” and\n“gods” state it in even more archaic argot.\n\nThese suspicions have grown over 72 years, but as a rather slow and stupid\nfellow I do not have the Chutzpah to proclaim any of them as certitudes. Give\nme another 72 years and maybe I’ll arrive at firmer conclusions.\n\n\nPART I\n\n\n#### BRAIN GYM — SIMPLE EXERCIZES\n\n  \n\nneuro-semantic challenges to such readers who think they know who they “are,”\nwhere they “are” and what the hell “is\" going on around here\n\n  \n\nNUMBER SIX: I “am” not a number! I “am” a free man!\n\n— The Prisoner\n\n  \n\nNUMBER FIVE: No malfunction! Number Five is alive!\n\n— Short Circuit\n\n  \n\nHANNIBAL LECTER, M.D.: A census taker tried to quantify me once. I ate his\nliver with some fava beans and a nice Chianti.\n\n— The Silence of the Lambs\n\n\nOld Man On A Balcony:\n\nViews Of Monterey Bay #1\n\n  \n\nClear blue bay at sunset\n\nAnd I am stoned and placid—\n\nFree of grief. almost.\n\n\n#### The Passion of the Antichrist\n\n  \n\nArticle II. As the Government of the United States of America is not, in any\nsense, founded on the Christian religion; as it has in itself no character of\nenmity against the laws, religion, or tranquility, of Mussulmen; and, as the\nsaid States never entered into any war, or act of hostility against any\nMahometan nation, it is declared by the parties, that no pretext arising from\nreligious opinions, shall ever produce an interruption of the harmony existing\nbetween the two countries.\n\n  \n\n— TREATY WITH TRIPOLI written by John Adams, vice-president, 1796; passed by\nCongress 1797; signed by John Adams, president, 1797.\n\n  \n\nIf you ever believed our founders intended this nation to “be” a Christian\ncountry — i.e., to enforce Christianity on all citizens and residents, even\nagnostics, Buddhists, Jews, Muslims, atheists, Daoists, Sihks, etc. — perhaps\nyou should read some of our early history. I suggest that you start with the\nabove treaty, then take a look at the First Amendment to the Constitution, and\nthen read the Jefferson-Adams correspondence 1812-1826.\n\nDe jure, this is not a Christian nation.\n\nOf course, this has become a Christian nation de facto, by hook and by crook —\nmostly by crook. This means that non-Christians theoretically have the same\nlegal rights as Christians but in fact they have to fight every hour of every\nday of every year to prove it, in a system where almost all judges and\npoliticians either “are” Christians or prudently pretend that they “are.”\n\nI wrote the original of this in 1965 for a now-defunct journal called Fact. It\nseems worth resurrecting 40 years later because, with Bozo in the White House,\nthe Christians have gotten rambunctious and downright ugly again . . .\n\n  \n\nFor four years, Baltimore endured an atheist in its midst. Not just any\natheist, mind you, but the most infamous atheist in America: Madalyn Murray,\nthe woman who filed a lawsuit and got the Supreme Court to kick monotheistic\nprayers out of the public schools. Ever since the lawsuit brought her to their\nattention, the good people of Baltimore strove to get rid of Madalyn Murray,\nand in June 1964, they finally did it. As a result of the methods they used,\nMadalyn lives now in exile in Hawaii, her arm is partly paralyzed, her hair is\nalmost white at 44, her organization — The Free Thought Society of America —\nhas been wrested away from her, her brother is unemployed, and her son is\nunder a psychiatrist’s care. The worst victim of all, however, has been the\nU.S. Constitution, which has emerged from the affair even more battered than\nthe Murray family.\n\nThose people traditionally concerned about civil liberties have not protested\nmuch about the Madalyn Murray case, probably because they find it simply\nincredible. When I visited Hawaii and spoke to Madalyn Murray’s present-day\nlawyer, Hyman Greenstein, he frankly told me that he himself did not\ncompletely believe Madalyn’s story when he first agreed to represent her. “She\nwas a human being in trouble,” he said. “That was obvious. But I was sure she\nwas exaggerating and dramatizing what had happened. I just didn’t believe\nthese things could happen in the United States. Then I went to Baltimore and\ninvestigated the facts. Believe me, Jack Ruby didn’t face worse prejudgment in\nDallas than Madalyn Murray has faced in Baltimore.”\n\nIn fact, to understand the Madalyn Murray story, one must first understand the\nCity of Baltimore and the State of Maryland, and nothing in America prepares a\nperson for such an understanding. If the founders did not intend this to “be”\na Christian nation, Maryland remains emphatically a Christian state.\n\nImagine Spain, in the days of the Inquisition, transferred within our borders.\nMaryland is named for the Virgin Mary; it was founded by Catholics; it is\nstill predominantly Catholic; 17% of all property in the State belongs to the\nCatholic Church, which pays no taxes on it. Maryland is the only state in the\nUnion that demands a religious qualification for judges; the only state that\ndemands a religious qualification for jurors; the only state that demands a\nreligious qualification for witnesses. Madalyn Murray literally could not\ntestify in her own behalf in any trial there, nor could any other atheist\ntestify for her.\n\nIn addition, the legal code has not been substantially revised since 1789, and\nit perpetuates many old English common-law punishments that have been\nabolished elsewhere. Particularly crucial to Madalyn Murray, who is under\nindictment on eight counts of assault against policemen (she charges that the\npolice actually assaulted her), the Maryland laws do not fix a maximum\nsentence for the crime of assault. The judge can make the prison term as long\nas he wishes — and Baltimore judges are not noted for their partiality to\nMadalyn Murray.\n\nIf Maryland’s laws are Medieval, its folk culture, with its persistent\nviolence, deserves to be called Fascist. It is part of the South: the stink of\nhatred permeates the air like smog in Los Angeles and grime in New York. Negro\nhomes have been bombed in the past year. Talk to a cabdriver in Baltimore\nabout the “color” problem and hate sprays from him like odor from a skunk — in\nthree minutes he will improvise 90% of the tortures it took de Sade years to\ndream up, with “Martin Luther Coon” as the principal victim and [U.S. Supreme\nCourt Chief Justice] Earl Warren next in line.\n\nA celebrated lynching in Baltimore not so long ago ended with the hanged man’s\ntoes and ears being hacked off by a member of the mob. The ears and toes are\nprobably on somebody’s mantelpiece today, and the owner is probably proud of\nthem. Bet on it. He shows them to guests: “Got these babies fighting\nCommunism.”\n\nIn this little pocket of 13th-century life, Madalyn Murray stood up and\ndeclared herself an atheist, an anarchist, and an integrationist. Here she\nstarted, and fought to a Supreme Court victory, a suit to end prayers in the\npublic schools. Here she took into her home, and into her Freethought Society\nof America, Mae Mallory, a feisty Negro militant wanted by the authorities in\nNorth Carolina,\n\nAnd here, Madalyn Murray, after winning her school-prayer case, started a\nlawsuit to force the United States government to tax church property the same\nas any other property.\n\nIn the March-April 1964 issue of Fact, I wrote the first profile of Madalyn\nMurray to appear in a major magazine. In it I described some typical reactions\nto Madalyn’s activities:\n\n— Day after day the letters from holy people pour in... “You should be shot!”\n“Why don’t you go peddle your slop in Russia?” “YOU WICKID ANAMAL” “I will\nKILL you!”\n\n— The day before Christmas a rock was thrown through the window, causing $67\nworth of damage...\n\n— The phone calls are a barrage of insult, obscenity, threat and psychotic\nrambling...\n\n— Her elder son, Bill, now 17, has been beaten up by gangs of Catholic\nadolescents more than 100 times.\n\n— Her younger son Garth, who is 9, has begun to have nightmares because of\nfrequent assaults by other boys.\n\n— Sitting in her office interviewing her I heard a school bus go by. Every\nchild stuck his head out of the window and shouted, “Commie, Commie, Commie!”*\n\n  \n\n~•~\n\n*Only possible in the dark days of McCarthyism and witch-hunts . . . Forty years later, the American people have grown and matured. The kids today would shout \"Arab-lover.”\n\n~•~\n\n  \n\nMy article appeared on the newsstands on April 1, 1964. A few weeks later,\nMadalyn Murray wrote to me to say that reporters from Time and Life were\ncoming in squads and battalions to interview her, carrying my article and\nasking their questions from it.\n\n(Both Time and Life later swiped my title, “The Most Hated Woman in America”)\n\n“They’re all trying to find errors in your Fact piece,” Madalyn told me.\n“They’re sore as hell about Fact’s expose of errors in Time and they want to\nget even.” They never found any errors, although once they thought they had. A\nMr. Michael McManus, of Time’s Washington office, called Madalyn and announced\nthat she had lied to me about her Army career. “You weren’t on Eisenhower’s\nstaff,” he crowed, or croaked, “you never left North Carolina.”\n\nMadalyn’s maiden name was Madalyn Mays, and Time had gotten ahold of the WAC\nrecord of a different Madalyn Mays.\n\nThe Time article appeared on May 15, and Madalyn wrote to tell me that now\nEsquire and the Saturday Evening Post were doing stories on her. Baltimore,\nmore and more, found itself spotlighted as the nation’s atheism capital, and\nBaltimore did not like it.\n\nMadalyn’s cat was strangled.\n\nA series of letters, postmarked Baltimore, became progressively uglier:\n\n“You had better read this carefully! It may be the last one you read. Somebody\nis going to put a bullet through your fat ass, you scum, you masculine lesbian\nbitch!”\n\n“You will be killed before too long. Or maybe your pretty little baby boy. The\nqueer looking bastard. You are a bitch and your son is a bastard.”\n\n“Slut! Slut! Slut! Bitch slut from the devil!”\n\nMadalyn files all such letters in a folder which she someday hopes to publish\nunder the title, Letters from Christians. But the growing murderousness of the\ncorrespondence, as national publicity about her increased, began to get under\nher skin, and she bought Tsar, a large German shepherd, and trained him to\nattack on command.\n\nMeanwhile, somebody in the Baltimore Post Office began systematically\nunderlining the first three letters in her name, so that all of her mail\nreached her insultingly addressed, “Madalyn Murray.” Madalyn complained to the\nBaltimore Postmaster and was told that an investigation had failed to unearth\nthe culprit, although her mail continued to arrive disfigured.\n\nThen, suddenly, all mail stopped. Madalyn complained to the Baltimore\nPostmaster and to the Postmaster General in Washington, with no immediate\nresults.\n\nThen an unidentified Communist* called and told her that her mail was being\ndelivered to the Communist Party of Maryland. The C. P. leaders, having a\nlong-standing grudge against Madalyn “(All Communists have a long-standing\ngrudge against all anarchists,” Madalyn says), had not bothered to notify her\nthat they were receiving her mail. Madalyn again complained to the Postmaster\nGeneral and soon began to receive her mail anew. Not long after, the “Madalyn\nMurray” underlinings were resumed.\n\n  \n\n~•~\n\n*Yes, Virginia, real Communists roamed the land in those days, and Senator Joseph McCarthy didn’t imagine them all. He just invented the technique of using “Communist” as a label for anybody he didn’t like, knowing that the Terminally Gullible (who cannot distinguish between labels and persons labeled) make up a majority in many voting districts.\n\n~•~\n\n  \n\nThe good Christian people of Baltimore devised other harassments.\n\nThe garbage cans at Madalyn’s office were dumped onto the ground every day,\nbefore they could be collected. Her son Bill received traffic tickets almost\nevery time he went out driving.\n\nSomebody entered the backyard of her home at night, was attacked by Tsar, and\nrammed a piece of wood down the dog’s throat.\n\nComing into her office one morning, she found two officials of the City zoning\nboard going through her correspondence, and when she tried to have them\narrested for trespassing, no judge would issue a warrant.\n\nEach of Madalyn’s efforts to cope with these harassments brought on further\ndifficulties. To handle the garbage problem, she boned up on Baltimore law and\nfound that a business firm could use its own incinerator if the incinerator\nwas a specific legal size. She bought an incinerator that met the\nrequirements, but the first time she used it several fire trucks rushed to the\nscene with sirens blaring and extinguished the blaze.\n\nWhen Madalyn quoted the law to the fire chief, he informed her that in his\njudgment the incinerator was unsafe.\n\nMadalyn picked the most flagrant of Bill Murray’s traffic indictments and\nfought it in court. Although two witnesses, one a policeman’s son, testified\nthat Bill had not committed the violation (driving through a red light), the\ncourt found him guilty.\n\nMadalyn Murray continued to fight back. Her lawyer at that time, Leonard\nKerpelman, found in his law books that a citizen unable to obtain redress from\na judge could appeal directly to a grand jury. Madalyn persuaded him to make\nthis last attempt to register charges against the zoning-board inspectors who\nhad been caught in her office.\n\nA few hours later, Madalyn received a frantic phone call. Kerpelman was in\njail. He had knocked on the office door of the grand jury and was immediately\narrested for contempt of court. Rushed before Judge T. Barton Harrington,\nKerpelman was quickly convicted and fined $25. Having only $24.78 in his\npockets, Kerpelman was taken to jail.\n\nMadalyn paid his fine and got him out, but he was shaken by the experience and\nbegan to show increasing disinclination to represent her further. He also was\nworried that Madalyn’s enemies might use the contempt conviction to try to\nhave him disbarred. To head this off, he appealed his case. Strangely, he was\nrepresented by William L. Marbury and Marvin Braiterman. Marbury acted as the\nattorney for the Roman Catholic Church in Madalyn’s “tax the churches” suit,\nand Braiterman as the attorney for the Episcopal Church in the same suit.\n\nThey appeared before Judge Michael J. Manley and persuaded him to drop the\ncase against Kerpelman. This was the first, and only, case ever won in the\nCity of Baltimore by anyone associated with Madalyn Murray.\n\nKerpelman subsequently broke with Madalyn and is now publicly working against\nher.\n\nThe next act of the melodrama began, like the Fall of Troy, with a runaway\ngirl. The fair Helen in this case was 17-year-old Susan Abramowitz, who met\nBill Murray in high school. Bespectacled, timid, and “intellectual,” Susan\nsoon became emotionally involved with Madalyn’s elder son.\n\nWhat happened after that remains subject to dispute. Susan’s parents, Leonard\nand Jeanne Abramowitz, charge that the Murrays “induced Susan to abandon her\nJewish faith” and to move into the Murray household. Susan claims that her\nparents beat her cruelly for associating with Bill, broke her glasses, cracked\nher teeth, and blackened her eyes, and that she sought refuge in the Murray\nhome only after her own parents threw her out of theirs.\n\nThe Baltimore papers printed all of the charges made by Mr. and Mrs.\nAbramowitz, but not a single word of the countercharges by Susan and the\nMurrays. When Madalyn complained, an editor told her that her charges were\nlibelous and that he could be sued for printing them. (Actually, the charges\nagainst Mr. and Mrs. Abramowitz are legally protected against libel action,\nbeing contained in a brief filed by Susan Abramowitz, William Murray, and\nMadalyn Murray in the Criminal Court of Baltimore, under Article 26, Sections\n91-101 of the Baltimore Code. Among other complaints of cruelty, this document\ncharges, on Susan’s testimony, that her father struck her on one occasion so\nhard that he fractured a bone in his own hand.)\n\nThe Abramowitzes obtained an order from Judge James Cullen on June 2 placing\nSusan in custody of an aunt and uncle. Susan immediately fled to New York City\nand took refuge with a friend. Two weeks later, she and Bill returned to\nMaryland and were secretly married.\n\nThen they returned to the Murray household on June 20. A neighbor recognized\nSusan and called the police. “You’d think it was Dillinger they were after,”\nMadalyn says. “A whole fleet of squad cars came racing to our house.” In their\nhaste, the police forgot to obtain a warrant for Susan’s arrest, so the\nMurrays refused to open the door. The police tore open a screen door and\nrushed in.\n\nWhat happened next is again a matter of dispute. The Murrays charge that they\nwere brutally beaten by the police. According to the police version, Madalyn\nMurray singlehandedly assaulted eight policemen. (The next day, only five\npolicemen claimed to have been assaulted by her, but two days later three\nadditional policemen pressed charges.)\n\nMadalyn’s mother, Leddie Mays, an elderly woman suffering from arthritis, is\naccused of assaulting still another policeman. Mrs. Mays admits touching a\npoliceman. “He had Bill on the ground and kept clubbing him, so I grabbed his\nshoulders from behind and yelled at him to stop. ‘You’re killing the boy!’ I\nsaid.” For her crime, 73-year-old Mrs. Mays was promptly knocked unconscious\nby the club of another guardian of the peace.\n\nWhen I asked the plump 44-year-old Madalyn how in the world she managed to\nassault eight armed policemen, she grinned. “You didn’t know I was such an\nAmazon, did you?”\n\nMore seriously, she said, “I bet every hood in the country will migrate to\nBaltimore when word gets out that eight of their policemen can be assaulted by\none overweight, middle-aged housewife.”\n\nMadalyn was taken to University Hospital for injuries, her mother was taken to\nUnion Memorial Hospital, and Bill was taken to jail, where he claims the\npolice beat him all night long while one of them read the Bible aloud to him.\n“We’ll make a Christian out of you yet, you cocksucker,” he quotes one of his\ntormentors as saying.*\n\n  \n\n~•~\n\n*And you thought it only happened in Iraq?\n\n~•~\n\n  \n\nThe next day the Murrays were released, and they carefully hid a tape-\nrecording that Bill had made of the tussle, in which Sgt. Charles Kelly is\nclearly heard admitting that the police had no search warrant. The matter of\nthe warrant apparently began worrying the authorities at this point, for State\nAttorney W.J. O’Donnell suddenly called a press conference to explain that the\npolice do not need to have a warrant in their possession when entering a house\nif they have reason to believe a warrant has been issued.\n\nThis legal theory appears startlingly new. I called the Attorney General’s\noffice in Washington to inquire about this and was told, “I never heard of\nsuch a doctrine.” When I asked if I could quote this, my informant hastily\nadded that the Attorney General’s office does not officially utter opinions on\nthe law for the press and suggested that I call the American Civil Liberties\nUnion.\n\nAt the A.C.L.U., Mr. Alan Reitman, a lawyer, stated flatly, “There is no such\ndoctrine in American law. If a search is to be made, the police must have a\nwarrant.”\n\nMadalyn’s Hawaiian lawyer, Hyman Greenstein, says bluntly, “O’Donnell’s\ndoctrine wouldn’t last as long as a snowball in hell in any court outside\nMaryland. Even in Maryland, it wouldn’t stand up against anybody but Madalyn\nMurray.”*\n\n~•~\n\n* Regard these legal facts as dated 1965 — i.e., 35 BB. [before Bozo].\n\n~•~\n\n  \n\nMadalyn and her family held a conference. Considering her 100% record of\ndefeat in all Baltimore courts, they decided that if she remained in Baltimore\nshe would undoubtedly be convicted on assault charges. They recalled that the\nprison sentence for assault, in Maryland, can be as high as the judge chooses\nto make it. That night the Murrays, with Bill’s new wife, Susan, drove to\nWashington and took a plane to Hawaii.\n\nBaltimore was at last rid of its atheist.\n\nThe holy folk of Baltimore were not satisfied yet. Leo Murphy, a Baltimore\nartist who had done a drawing for the cover of Madalyn’s magazine, American\nAtheist, began to receive phone calls from people threatening to kill him or\nto throw acid in his face and blind him.\n\nAn Ida D. Collins wrote gleefully to the Baltimore Sun, “Madalyn Murray took\nthe wrong route when she left us this week. Instead of Hawaii, she should have\ntaken a ‘slow boat to China’ and do us all a favor and stay there.” The\ninsurance company cancelled the insurance on her house and, although the\nmortgage payments were up-to-date, the bank began court action to foreclose\nbecause the house no longer was insured. And in Hawaii, Madalyn watched her\nson Bill begin to slip into a mental breakdown.\n\nBill had taken his share of punishment during the previous four years with\nSpartan solidarity. After his night in the Baltimore jail, however, he\nsuddenly broke into screams before Judge Joseph G. Finnerty and shouted, “You\nChristian, you Catholic, I won’t go back to that cell and be worked over\nagain!” In Hawaii, Bill began to sit for long periods in his room, utterly\nsilent. Occasionally, he would come out of his stupor and attack his mother\nverbally, saying she had ruined his life by getting him mixed up in the\nschool-prayers case. Then he locked himself in his room and refused to talk to\nanyone for nearly a week. He is now under the care of psychiatrist Linus\nPauling Jr. He has come out of his silent depression, but retains a violent\nhatred of his mother, whom he blames for all his troubles.\n\nBack in Baltimore, Madalyn was tried in absentia for contempt of court and\nsentenced to one year in jail. The Baltimore authorities also got busy and\ncreated a new law that fixed a minimum 20-year sentence for each count of\nassault against a policeman. Madalyn Murray, the Baltimore Sun announced, now\nfaces at least 160 years’ imprisonment if she ever returns to Baltimore. I\nasked Madalyn’s lawyer, Hyman Greenstein, about this: “Doesn’t the\nConstitution prohibit such ex post facto punishments?” “Yes,” he said, “but\nthe Constitution also prohibits trials in absentia, and Baltimore has already\ndone that to her.” He added: “Assault, you know, is a misdemeanor. If they get\naway with it, she’ll be the first American ever to serve life for eight\nmisdemeanors.”\n\nMeanwhile, a gang of people moved into Madalyn’s business office, announced\nthat they were the “Freethought Society of America,” and tried to use the bank\naccount Madalyn kept under the society’s name. Madalyn’s fight against the\ncoup d’etat has followed the traditional pattern in Baltimore courts: She has\nlost every single hearing.\n\nHeading the group occupying Madalyn’s office is Lemoin Cree, a 26-year-old\nbiologist who works at Fort Detrick, where the U.S. Army carries on research\nin the creation of artificial bubonic-plague epidemics, anthrax and other\nmethods of biological warfare. Mr. Cree and his associates insist they were\nappointed by the “board of directors” of the Freethought Society. Madalyn\nMurray insists there is no board of directors of the Freethought Society, and\nshowed me the by-laws to prove it.\n\nMadalyn is convinced that Cree and his group are “Catholic agents.” A friend\nof mine, who knows the atheist movement the way Clark Kent knows the inside of\nthe phone booth at the Daily Planet, laughed at this. “Madalyn is breaking\nunder the strain,” he said.\n\n“The Church has given her such a hard time, she’s beginning to see priests\neverywhere.” According to this informant, Lemoin Cree and his associates are\nactually atheists, but atheists whose politics are Right-wing and who are\nembittered by the fact that Madalyn Murray, the only atheist to achieve\nnational publicity, is conspicuously Left-wing.\n\nSince the office contained several hundred dollars worth of furniture\nbelonging, not to the “Freethought Society of America,” but to Madalyn’s\nmother, Leddie Mays, Madalyn sold this furniture to her friend, Mae Mallory,\nwho thereupon tried to obtain a robbery warrant against the group in the\noffice. A Baltimore judge ruled that the bill of sale was not legal. The bill\nof sale had been witnessed by a notary public in Hawaii, and the judge\ndeclared that, under Maryland law, it had to have been witnessed by a clerk of\na Hawaiian court, not by a notary public.\n\nLawyer Joseph Wase, representing Mae Mallory in this matter, insists there is\nno such Maryland law.\n\nAccording to Miss Mallory, however, the judge involved had said of Madalyn,\n“That atheist doesn’t have any rights in this State.”\n\nYes, all this is happening in Baltimore, Maryland, in the United States of\nAmerica, in the Year of Their Lord 1965.\n\nGoing from Baltimore to Honolulu must be like ascending from the “nethermost”\nor darkest circle of hell to the pinnacle of paradise. In every way, Hawaii\nseems the antithesis of Baltimore. It is the most cosmopolitan of American\nstates, and the most tolerant. Racial harmony is so good that even the year-\nlong parade of tourists — with its high percentage of Legionnaires,\nwerewolves, warlocks, Storm Troopers, monsters, and miscellaneous Ugly\nAmericans — does not undermine it.\n\nShortly after her well-publicized arrival in Hawaii, Madalyn telephoned lawyer\nGreenstein and asked to see him. Hyman Greenstein is a legend throughout\nHawaii. Everybody told me he was the model for Lieutenant Greenwald in Herman\nWouk’s The Caine Mutiny, that he is a fanatical devotee of sports-car racing,\nthat he loves “impossible” cases, and that during World War II he won so many\n“impossible” courts-martial that Admiral Halsey personally intervened to have\nhim transferred out of the Pacific area.\n\nIn one notorious court-martial, the president of the court lost his head and\ncalled Greenstein “a son of a bitch.” Greenstein calmly turned to the court\nclerk and asked, “Did you get that down?” Court was immediately adjourned. It\nreconvened a few minutes later to dismiss the charges against Greenstein’s\nclients.\n\nA short, soft-spoken man, Greenstein always wears green bow ties and his\noffice is decorated in shades of green. Madalyn warned me, “The green is some\nkind of personal symbol to him. He is not amused when somebody says, ‘Oh, are\nyou Irish, Mr. Greenstein?’”\n\nWhen it became known that Madalyn had called for an appointment, Greenstein’s\nstaff was dismayed. His secretary told the lawyer, “Everybody wants to know if\nyou’re going to take that awful woman’s case.” Greenstein called the entire\nstaff into his office and left the door open. “That door is always open to\npeople in trouble, whatever their beliefs,” he said. “Does anybody want to\nquit?”\n\nNobody did.\n\nMr. Greenstein has prepared a blockbuster of a brief against Madalyn’s\nextradition. He charges that “No court in the State of Maryland is legally\nconstituted” because of that State’s religious qualifications for judges,\njuries, and witnesses, and that, therefore, “The entire judicial system of\nMaryland is in violation of and repugnant to the Constitution of the United\nStates.” He further argues that Maryland’s failure to prescribe maximum\npenalties for assault is “barbaric, outmoded; and repugnant to the\nConstitutional guarantees against cruel and unusual punishment.”\n\nNot only has Madalyn found a conscientious and capable lawyer in Hawaii, but\nshe has also come upon some truly good Christians. Eighteen Hawaiian\nclergymen, including a Catholic priest, signed a petition urging Governor John\nA. Burns not to approve the extradition of Madalyn back to “religious\npersecution in Maryland.” In fact, as soon as she landed on the island she was\noffered help by a church. The Rev. Gene Bridges, of the Unitarian Church,\ncalled her on the phone to ask if she had found a home yet. When he learned\nthat she hadn’t, he invited her whole family to spend the night in the back\nroom of his church. Mr. Bridges immediately thereafter started calling the\nboard of directors of his church for approval. The board has 15 members. After\ncalling eight and receiving 7 approvals, he invited the Murrays to stay until\nthey found a home. They remained in the church for two weeks.\n\n“Madalyn has mellowed a lot, due to the Unitarian Church,” one Unitarian told\nme. Madalyn now attends the Unitarian services every Sunday and sends her son\nGarth, 10, to the church’s Sunday School. I attended services with Madalyn at\nMr. Bridges’s church one Sunday. It began with some recorded music by Dizzy\nGillespie, then Mr. Bridges read selections from Anne Morrow Lindbergh’s Gift\nFrom the Sea and e.e. cummings’s I: 6 non-lectures. Madalyn listened\nenthralled and said to me as we came out, “Isn’t he wonderful?”\n\nThat afternoon, Madalyn and I visited the largest Buddhist church in Honolulu\nand she picked up several free pamphlets of Buddhist sermons. “You’re not\ngetting religious, are you?” I joked.\n\n“Hell, no,” she said. “I’m just curious.”\n\nFor Madalyn Murray remains unshakable — and unsinkable. Sitting on the veranda\nof her little rented house at 1060 Spencer Street on the side of Punchbowl\nVolcano, with the panorama of Honolulu and the looming whale-like hump of\nDiamond Head spread before us, she told me eagerly of her plans in the “tax\nthe churches” suit.\n\n“We’re going to subpoena the Archbishop of Baltimore, Lawrence Sheehan,” she\nsaid, “and make him tell how much money the church collects from its property\nin Baltimore, how much of that remains in Baltimore, how much remains in the\nUnited States, and how much goes to Rome. That information has never been\navailable before, but it will be now. People can add and subtract, you know.\nWait ’til the American public starts figuring out how low its taxes would be\nif all that untaxed money weren’t flowing out of the country.”\n\nMadalyn is also planning to run for Governor of Hawaii, on a platform in which\na fourth branch of government — the economic — would be added to the\nexecutive, legislative, and judicial. She is broke, in debt to the chin, the\nBaltimore courts won’t let her use her bank account, and she is still riding\n“at a gallop, high in heart.”\n\nThe other victims are less buoyant. Bill Murray is still under psychiatric\ncare. Garth, Madalyn’s other son, has frequent nightmares about “seven-foot\ntall cops” beating his Mommy. Old Mrs. Mays is subdued and anxious. Madalyn’s\nbrother Irving, 48, gave up a good factory job, not wanting to be the only\nMurray in Baltimore and a standing target for the remaining hatred, and he has\nnot found a new job yet. As for the victim that has suffered most — the U.S.\nConstitution — it is not flesh and blood and, hence, doesn’t feel its wounds,\nbut if it could speak it would probably whimper softly.\n\n  \n\nPostscript: Madalyn Murray disappeared in Texas in 1995 and police found her\nburied body about two years later. Murder. The Texas cops say another atheist\ndid it.\n\nAll of the “shocking” and unconstitutional persecutions she faced have become\nlegal and normal now, thanks to the War on [Some] Drugs, the War on [Some]\nTerrorists and the U.S.A.PATRIOT Act.\n\nBut don’t fret; the targets of choice all seem mid-eastern: Muslims or those\nwho “look like” Muslims to the ignorant, including some Sihks and Hindus.\n\n\nOld Man On A Balcony:\n\nViews Of Monterey Bay #2\n\n  \n\nAfter the fog lifts.\n\n  \n\nA naked beauty: blue sky\n\n  \n\nwith buttermilk clouds\n\n\n#### The One “Law” of Economics\n\n  \n\nI have read a great deal of economic theory for over 50 years now, but have\nfound only one economic “law” to which I can find NO exceptions:\n\n  \n\nWhere the State prevents a free market, by banning any form of goods or\nservices, consumer demand will create a black market for those goods or\nservices, at vastly higher prices.\n\n  \n\nCan YOU think of a single exception to this law?\n\n  \n\nTHOUGHTS TO PONDER\n\n  \n\nFirst of all, if the State takes upon itself the right to kill, then\ninevitably those who oppose the State will arrogate to themselves the same\nright. Revolutionaries and terrorists do in fact use that argument with some\nsincerity. “If the State can take life, then we can also take life.” After\nall, they generally claim that they represent the people and that the State\ndoesn’t. I am opposed to the cheapening of human life created by that rhetoric\non both sides.\n\n  \n\nSean MacBride\n\nWhere memory dwells*\n\nLove takes its Throne\n\n  \n\n— Guido Cavalcanti [1260-1300]\n\n  \n\n~•~\n\n* dove sta memora\n\n~•~\n\n\nOld Man On A Balcony:\n\nViews Of Monterey Bay #3\n\n  \n\nLights across the bay —\n\n  \n\nWhite jewels scattered, shattered\n\n  \n\nIn a deep black box\n\n\n#### The Celtic Roots of Quantum Theory\n\n  \n\nThe reality of metaphysics is the reality of masks.\n\n  \n\n— Oscar Wilde\n\n  \n\nWe lived in Los Angeles and I thought I had a movie deal when I wrote this for\nan Irish magazine c. 1990. As far as I remember, they never paid for it and,\nprobably, never published it . . . But I think it deserves an audience, and it\nseems appropriate for a volume of guerrilla neurolinguistics.\n\nThe movie deal dropped dead, or went into coma, too.\n\nAccording to “conventional wisdom,” and/or conventional folly, the ontological\nroots of Quantum Mechanics lie in German Idealist philosophy of the 19th\nCentury. I dare to offer a different view here.\n\n  \n\nThe day in 1982 when my wife, Arlen, and I arrived in Ireland we tried her\nbattery-operated radio to listen avidly to whatever we might find: our way of\ndipping our toes in the new culture before plunging in to its alien waters\ntotally. By the kind of coincidence that I don’t regard as coincidental, we\nfound an RTE* interviewer discussing local legends about the pooka with a\nKerry farmer. As a longtime pookaphile, I found the conversation spellbinding,\nbut the best part came at the end:\n\n“But do you believe in the pooka yourself?” asked the RTE man.\n\n“That I do not.” the farmer replied firmly, “and I doubt much that he believes\nin me either!”\n\n  \n\n~•~\n\n* RTE = Radio Telefís na hEirenn, the State-owned but feisty and independent radio-TV monopoly.\n\n~•~\n\n  \n\nI knew then that I had indeed found my spiritual homeland, wherever I may\notherwise roam, and that Yeats and Joyce and O’Brien had not risen out of a\nvacuum. We had planned to stay six months; we eventually stayed six years.\n\n  \n\nAnthony Burgess once argued that English English, American English and all the\nother varieties of Anglophonics have become rational and pragmatic (closure-\noriented), but Irish English remains ludic and esthetic (open-oriented). The\nrest of us speak dry prose; the Irish speak playful poetry.\n\nWhile I see some truth in that formulation, I would prefer to describe all-\nother-English as belonging to what Neurolinguistic therapist Dr. Richard\nBandler calls the meta-model (statements we can logically judge as true or\nfalse), and Irish English as belonging to the Milton-model (statements not\ncontainable in true-false logic but capable of seducing us into sudden new\nperceptions).\n\nThe Milton-model, named after Dr. Milton Erickson — “the greatest therapeutic\nhypnotist of the 20th Century,” in the opinion of his peers — contains no\npropositions subject to proof or disproof, uses language the way that Kerry\nfarmer did, and can cause both intellectual and physiological transformations.\nBecause of his many successes in curing the allegedly incurable, Dr. Erickson\noften became proclaimed “the Miracle Worker.”\n\nOddly, most of Dr. Erickson’s patients did not think they had undergone\nhypnosis at all. They just remembered having a friendly chat with an unusually\nsympathetic doctor.\n\nAccording to the Korzybski-Whorf-Sapir hypothesis, the language a people speak\nhabitually influences their sense perceptions, their “concepts” and even the\nway they feel about themselves and the world in general. “A change in language\ncan transform our appreciation of the cosmos,” as Whorf stated the case.\n\nThe clinical record of Erickson and his school indicates that language tricks\ncan even make us ill or make us well again.\n\nThe Irish neurolinguistic system illustrates these theorems uncommonly well.\n\nWhether you call it ludic language, Ericksonian hypnosis, or the verbal\nequivalent of throwing LSD into the linguistic drinking water, Irish English\neven in the professional hands of all of Ireland’s greatest writers shows the\nsame non-Aristotelian “illogic” or Zen humor as that Kerry farmer.\n\nWitness:\n\n  \n\nDeath and life were not\n\ntill man made up the whole,\n\nMade lock, stock and barrel\n\nout of his bitter soul\n\n  \n\n— W.B. Yeats\n\n  \n\nTry taking all literary, scientific, theological and philosophic connotations\nout of “death” and “life” see them merely as two predicaments of grammar — and\nthen — ?\n\n“Men are born liars.” — Liam O’Flaherty, in the first sentence of his\nautobiography.\n\nLogicians call this an Empedoclean paradox. To an Irish stylist, it does not\nappear Empedoclean nor paradoxical, but merely another pregnant bull. Since\nO’Flaherty belonged to the class of all men, he lied; but if he lied, his\nstatement does not carry conviction, so maybe he told the truth . . .\n\n“Are the commentators on Hamlet really mad or only pretending to be mad?” —\nOscar Wilde.\n\n  \n\nThy spirit keen through radiant mien\n\nThy shining throat and smiling eye\n\nThy little palm, thy side like foam —\n\nI cannot die!\n\n  \n\nO woman, shapely as the swan,\n\nIn a cunning house hard-reared was I:\n\nO bosom white, O well-shaped palm,\n\nI shall not die!\n\n  \n\n— Padraic Colum\n\n  \n\n(A Romantic poem, in style; anti-Romantic in content — whether you think of\nthe female as a human lady or a symbol of Ireland a la Cathleen ni Houlihan,\nDark Rosaline or shan van vocht, Colum still will not die for Her.)\n\n“Durtaigh disloighal reibel aighris dogs.” — Myles na gCopaleen\n\n(It only makes sense if you pronounce it as Gaelic, and then it becomes\nordinary English, expressing an ordinary English attitude toward \"their\nHibernian neighbors.)\n\n“They shall come to know good.” — James Joyce. (Read it silently, then read it\naloud.)\n\n“There is in mankind a certain ************************** Hic multa\n**************************************************** disiderantur\n***************************************. And this I take to be a clear\nsolution of the matter.” — Jonathan Swift [all expurgations in Swift’s\noriginal text.]\n\n“I considered it desirable that he should know nothing about me but it was\neven better if he knew several things that were quite wrong.”— Flann O’Brien\n\nOr, to take a few examples that lend themselves better to condensation than\nquotation:\n\nConsider Swift’s “pamphlet war” with the astrologer Partridge, in which Swift\nclaimed Partridge had died and Partridge vehemently insisted on his continued\nviability. Swift won hands down by pointing out that just because a man claims\nhe’s alive does not compel us to accept his uncorroborated testimony.\n\nOr: Bishop Berkeley, proving with meticulous logic that the universe doesn’t\nexist, although God admittedly has a persistent delusion that it does.\n\nOr: the scandalous matter of Molly Bloom’s adulterous affairs in Ulysses,\nwhich number between one (Hugh Boylan) and more than thirty (including a few\npriests and Lords Mayor and one Italian organ grinder), depending on which of\nJoyce’s 100+ narrators one chooses to believe. This grows more perplexing when\none realizes that some of the “narrators” seem more like styles than persons:\nstyles masquerading as persons.\n\nOr maybe the ghosts of departed stylists, in the sense that Berkeley called\nNewton’s infinitesimals the ghosts of departed quantities?\n\nColonized and post — Colonized peoples learn much about text and sub-text; and\nYeats did not develop his mystique of Mask and Anti-Mask out of Hermetic\nmetaphysics alone. In my six years sampling Dublin pubs (1982-88) I overheard\nmany conversations in the form:\n\n  \n\n— I saw your man last night.\n\n— Oh? And?\n\n— All going well there.\n\n  \n\nWho the devil is “your man”? Does this concern hashish from Amsterdam for the\nPunk Rock crowd, gelignite on its way to Derry, or just ingrained habits Masks\nand Anti-Masks — shaped by 800 years of Occupation? After all, the speakers\nmight simply refer to tickets for a soccer game . . . (You will find a\nsimilarly oblique dialogue in the second section of the “Wandering Rocks”\nmontage in Ulysses, except that “your man” has become “that certain party.”\nPalestinians have probably become that “Irish” by now.)\n\nI do not claim that Sassanach conquest alone produced Ireland’s elusive wit\nand ludic poesy; but it sharpened tendencies already there as far back as Finn\nMac Cumhal. Yeats says somewhere that Ireland was part of Asia until the\nBattle of the Boyne; but that dating merely represents W.B.’s reactionary\nRomanticism. Joyce knew that Ireland remained part of Asia; Finnegans Wake\nexplicitly tells us it emerged from “the Haunted Ink bottle, no number,\nBrimstone Walk, Asia in Ireland.”\n\nYou can test one level of truth in this by simply asking directions in both\nTokyo and Dublin. In either place you will encounter old-fashioned politeness\nand friendliness unknown in most of the industrial world, and you will get\nsent in the wrong direction. Hostile humor? I think not. Asiatic languages,\nincluding Irish English, simply do not accommodate themselves to Newtonian\ngrids, either spatial or temporal.\n\nArlen and I used to play a game in Dublin: whenever we saw two clocks we would\ncompare them. They never agreed.\n\nIn Cork, the four clocks on the City Hall tower always show four different\ntimes; locals call them “the Four Liars.”\n\nThe sociologist may class this as “post-Colonial syndrome” — based on the\nbaleful suspicion that the English invented time to make a man work more than\nthe Good Lord ever intended — but Joyce noted that the only three world-class\nphilosophers of Celtic genealogy, Erigena, Berkeley and Bergson, all denied\nthe reality of time (and only Berkeley lived under English rule).\n\nA Dublin legend tells of an Englishman who, noting that the two clocks in\nPadraic Pearse station do not agree, commented loudly that this discordance\n“is so damned typically bloody Irish.” A Dubliner corrected him: “Sure now, if\nthey agreed, one of them would be superfluous.”\n\nEven more in the Daoist tradition: Two Cork men meet on the street. “Filthy\nweather for this time of year,” ventures the first.\n\n“Ah, sure,” replies the second, “it isn’t this time of year at all, man.”\n\nCompare the Chinese proverb, “Summer never becomes winter, infants never grow\nold.” Einstein’s relativity and Dali’s melting clocks belong to the same\nuniverse as these Hiberno-Chinese Eccentricities.\n\nIn County Clare and the West generally one often hears the grammatical form,\n“My uncle was busy feeding the pigs one night and I a girl of six years . . .”\n(One also hears this in Synge’s plays — all of them.) Elsewhere in the\nEnglish-speaking world one would hear, “My uncle was busy feeding the pigs one\nnight when I was a girl of six years . . . ” The Irish English retains the\ngrammar of Irish Gaelic, but it thereby retains the timeless or Daoist sense\nof a world where every now exists but no now ever “becomes” another now.\n\nNor does this neurolinguistic grid — or reality-tunnel — only manifest in\nIrish speech and literature. William Rowan Hamilton, one of Eire’s greatest\nmathematicians — probably the greatest of all — made many contributions, but\ntwo have special interest for us here:\n\nOne — Hamilton invented non-commutative math, which I shall try to explain. In\narithmetic, 2 x 3 = 3 x 2, or they both equal 6 (if you haven’t raised too\nmany pints that night). Ordinary algebra, the only kind most of us ever\nlearned in school, follows the same rule: a x b = b x a. Everybody knows that,\nright? Well, in Hamilton’s algebra, a x b does NOT = b x a.\n\nMore “Asiatic” influence? More of the Celtic Twilight? Well, in Pure\nMathematics, you can invent any system you want as long as it remains\ninternally consistent; finding out if it has any resemblance to the\nexperiential world remains the job of the physicist, or the engineer. It\nrequired about 100 years to find a “fit” for Hamiltonian algebra, and then it\nrevolutionized physics. Hamilton’s math describes the sub-atomic (quantum)\nworld, and ordinary math does not.\n\nThe reader may classify Hamilton’s feat as a variety of precognition, or maybe\njust as more of the Hibernian compulsion to challenge everything the Saxon\nregards as unquestionable.\n\nTwo — Physicists of Hamilton’s day endlessly debated whether light travels as\n“waves” like water or as discrete “particles” like bullets. He supported both\ntotally contradictory models, although in different contexts. Among\nFundamentalist Materialists, they call this the Heresy of “perspectivism,” but\nagain, after 100 years, it became part of quantum mechanics, although usually\ncredited to Niels Bohr, who only rediscovered it. Perspectivism also haunts\npostmodern literary theory, cultural anthropology and, especially, the Joyce\nIndustry, as more and more Joyce scholars realize that all of the 100+\nnarrative “voices” in Ulysses seem equally true in some sense, equally untrue\nin some sense, and equally beyond either/or logic in any sense.\n\nQuantum Mechanics owes a second huge debt, and a perpetual headache, to\nanother Irish physicist, John Stewart Bell.\n\nBell’s Theorem, a mathematical demonstration by Dr. Bell published in 1965,\nhas become more popular than Tarot cards with New Agers, who think they\nunderstand it but generally don’t. Meanwhile it remains controversial with\nphysicists, some of whom think they understand it but many of whom frankly\nadmit they find it as perplexing as Mick Jagger with his guitar hopping around\nlike a chicken on LSD in the middle of a Beethoven string quartet.\n\nIn a (hazardous) attempt to translate Bell’s math into the verbal forms in\nwhich we discuss what physics “means,” Bell seems to have proved that any two\n“particles” once in contact will continue to act as if connected no matter how\nfar apart they move in “space” or “time” (or in space-time). You can see why\nNew Agers like this: it sounds like it supports the old magick idea that if\nyou get ahold of a hair from your enemy, anything you do to the hair will\naffect him.\n\nMost physicists think a long series of experiments, especially those of Dr.\nAlain Aspect and others in the 1970’s and Aspect in 1982 have settled the\nmatter. Quantum “particles” (or “waves”) once in contact certainly seem\n“connected,” or correlated, or at least dancing in the same ballet . . . But\nnot all physicists have agreed. Some, the AntiBellists, still publish\ncriticisms of alleged defects in the experiments. These arguments seem too\ntechnical to be summarized here, and only a small minority still cling to\nthem, but this dissent needs to be mentioned since most New Agers don’t know\nabout it, and regard Bell’s math with the same reverence Catholics have for\nPapal dogma.\n\nThe most daring criticism of Bell comes from Dr. N. David Berman of Columbia,\nwho believes he has refined the possible interpretations of Bell down to two:\n\n(l) non-locality (“total rapport”) and\n\n(2) solipsism.\n\nWe will explain non-locality below, but Dr. Berman finds it so absurd that he\nprefers solipsism. (“Is The Moon There When Nobody Looks?” Physics Today,\nApril 1985. He says the moon, and everything else, doesn’t exist until\nperceived; Bishop Berkeley has won himself one more convert.)\n\nAmong those who accept Bell’s Theorem, Dr. David Bohm of the University of\nLondon offers three interpretations of what it means:\n\n  \n\nIt may mean that everything in the universe is in a kind of total rapport, so\nthat whatever happens is related to everything else; or it may mean that there\nis some kind of information that can travel faster than the speed of light; or\nit may mean that our concepts of space and time have to be modified in some\nway that we don’t understand. [London Times, 20 Feb 1983.]\n\n  \n\nBohm’s first model, “total rapport,” also called non-locality, brings us very\nclose — very, very close — to Oriental monism: “All is One,” as in Vedanta,\nBuddhism and Daoism. It also brings us in hailing distance of Jungian\nsynchronicity, an idea that seems “occult” or worse to most scientists, even\nif it won the endorsement of Wolfgang Pauli, a quantum heavyweight and Nobel\nlaureate. You can see why New Agers like this; you will find it argued with\nunction and plausibility in Capra’s The Tao of Physics. It means atomic\nparticles remain correlated because everything always remains correlated.\n\nI suggest that physicists often explain this in Chinese metaphors because they\ndon’t know as much about Ireland as they do about China, and because they\nhaven’t read Finnegans Wake.\n\nThe strongest form of this non-local model, called super-determinism, claims\nthat everything “is” one thing, or at least one process. From the Big Bang to\nthe last word of this sentence and beyond, nothing can become other than it\n“is,” since everything remains part of a correlated whole. Nobody has openly\nexpressed this view but several (Stapp, Herbert, et al.) have accused others,\nespecially Capra, of unknowingly endorsing it.\n\n  \n\nBohm’s second alternative, information faster-than-light, brings us into\nrealms previously explored only in science fiction. Bell’s particles may be\ncorrelated because they act as parts of an FTL (faster than light) cosmic\nInternet. If I can send an FTL message to my grandpa, it might change my whole\nuniverse to the extent that I wouldn’t exist at all. (E.g., he might suffer\nsuch shock that he would drop dead on the spot and not survive to reproduce.)\nWe must either reject this as impossible, or else it leads to the “parallel\nuniverse” model: I’m here in this universe, but in the universe next door the\nmessage removed me, so I never sent it there. Remind you, a bit, of that Kerry\nfarmer?\n\nEven more radical offshoots of this notion have come forth from Dr. John\nArchibald Wheeler. Dr. Wheeler has proposed that every atomic or subatomic\nexperiment we perform changes every particle in the universe everywhichway in\ntime, back to the Big Bang. The universe becomes constant creation, as in\nSufism, but atomic physicists, not Allah, serve as its creators. Yeats again\nwakes? (He would, of course, place Bards as the creators, not mere measurers\nand calculators, but still the human mind has “made up the whole.”)\n\nDr. Bohm’s third alternative, modification of our ideas of space and time,\ncould lead us anywhere . . . including back to the Berkeleyan/Kantian notion\nthat space and time do not exist, except as human projections, like persistent\noptical illusions. (Some think Relativity already demonstrates that . . . and\nsome will recall Mr. Yeats again, and that Kerry farmer . . .) All particles\nremain correlated because they never move in space or time, because space and\ntime only exist “in our heads.”\n\nMeanwhile, a Dr. Harrison suggests that we may have to abandon Aristotelian\nlogic; i.e., give up classifying things into only the two categories of “true\nand real” and “untrue and unreal.” In between, in Aristotle’s excluded middle,\nwe may have the “maybe” proposed by von Neumann in 1933, the probabilistic\nlogics (percentages/gambles) suggested by Korzybski, the four-valued logic of\nRapoport (true, false, indeterminate and meaningless), or some system the non-\nHibernian world hasn’t found yet. The Kerry farmer would handle all of this\nbetter than the typical graduate of any university outside Ireland.\n\nAnd so we see that two Irishman, Hamilton and Bell, have the majority of\nphysicists arguing about issues that make them sound like a symposium among\nBerkeley, Swift, Yeats, O’Brien and Joyce. Through their literature, speakers\nraised in Irish English have transformed the printed page; now their\nmathematicians, raised in the same neurolinguistic grid, have revolutionized\nour basic notions of “reality,” which in the light of what we have seen, badly\nneeds the dubious quotes I just hung on it.\n\n  \n\nAfterthought 2004: Two of the giants of quantum math, Schrödinger and Dirac,\nboth spent time at the Institute for Advanced Studies in Dublin. Schrödinger,\nin fact, wrote his most important non-mathematical book there, What Is Life?\n(1948), in which he defined life as a function of negative entropy. This\nthought seemed so radical and far-out that nobody began to grasp it until\nWiener and Shannon showed that information also behaves like negative entropy.\nInformation = that part of a message you didn’t expect; the unpredictable\npart.\n\nOr, as Wiener once said, great poetry contains high information and political\nspeeches contain virtually none. And, therefore, Life = negative entropy =\nhigh information = surprise and initial confusion = tuning-in the previously\nnot-tuned-in . . .\n\nGot it?\n\n\n#### THOUGHTS TO PONDER\n\n  \n\nThe challenge before us today, the challenge before our nation and the world\nis whether we accept the beneficence of Lincoln’s Prayer to create “. . . a\ngovernment of the people, by the people and for the people,” or whether we\ntimidly accept the economic, social and political consequences of a government\nof the corporations, by the corporations and for the corporations.\n\n  \n\n— Dennis J. Kucinich\n\n\nOld Man On A Balcony:\n\nViews Of Monterey Bay #4\n\n  \n\n“Weep, weep!” cries a bird\n\n  \n\nLost somewhere in fog and mist.\n\n  \n\nSunrise with no sun.\n\n\n#### Schrödinger’s Other Cat\n\n  \n\nA review of Dirk Gently’s Holistic Detective Agency\n\nby Douglas Adams\n\n  \n\nI just found this in the “saved” file on my computer; I think I wrote it\naround 1982 in Ireland and it probably got published somewhere.\n\nMaybe.\n\n  \n\nSome people may wonder what a holistic detective agency does, but this new\nbook by Douglas Adams, author of the famous Hitchhiker’s Guide to the Galaxy,\nwill explain that for them, with such transcendental clarity that the mind, as\nin Dante’s Paradise, is nearly blinded by the light.\n\nCan you believe that the disappearance of a cat in London seven years ago\ncannot only “be” caused by, but equally “be” the cause of the miraculous\nappearance of the music of J. S. Bach more than two hundred years earlier?\n\nIf this thought is incomprehensible to you, then you should either study\nquantum physics or read Dirk Gently ’s Holistic Detective Agency.\n\nMr. Adams not only explains the relationship between the missing cat and the\nGoldberg Variations, but also demonstrates how a sofa can get wedged into a\nstairwell in such a way that you not only cannot get it out, but mathematized\ncomputer analysis will prove that it never could have gotten wedged in that\nposition in the first place. Not in this universe, anyway.\n\nOddly, there is no fantasy in this book. Dirk Gently is as logical as Sherlock\nHolmes, and all the macoronic inter-connections he masters are necessary parts\nof the world of modern physics.\n\nIt may seem startling to contemplate probability matrices in which everything\n“is” the cause of everything in one sense and nothing “is” the cause of\nanything in another sense, but such is the probable world in which we probably\nlive according to current science, and if in one probability matrix Dirk\nGently has to move a sofa through a solid wall (and incidentally save humanity\nfrom extinction — for which he does not charge extra), the missing cat is then\nlocated.\n\nUnfortunately, the cat is dead.\n\nBut that’s only in one probability matrix. In the matrix next door, the cat is\nprobably alive, but we’ve seemingly lost Bach. While cat-lovers and music-\nlovers ponder that conundrum, at least the matrix in which humanity is\ndestroyed has been avoided.\n\nBut the damned couch is still stuck in the stairwell, in the probability\nmatrix where we lost Bach and saved the cat.\n\nAlas, I fear that those who talk of “holistic medicine” have little inkling of\nhow holistic sub-atomic physics can get. I can only urge that all who wish a\nglimpse of how our probable universe probably operates should rush right out\nand buy this marvelous book, which works equally well as a thriller, a\nmystery, a farce and the most scientific novel of the year.\n\n\nOld Man On A Balcony:\n\nViews Of Monterey Bay #5\n\n  \n\nBay like blackboard grey\n\n  \n\nMonterey lost in white fog\n\n  \n\nShortest day draws nigh\n\n  \n\nTHOUGHTS TO PONDER\n\n  \n\nnothing matters but the quality\n\nof the affection —\n\nin the end — that has carved the trace in the mind\n\ndove sta memora\n\n  \n\n— Ezra Pound, Canto 76\n\n\n#### Paranoia\n\n  \n\nA few pages back, I wrote;\n\nWhere the State prevents a free market, by banning any form of goods or\nservices, consumer demand will create a black market for those goods or\nservices, at vastly higher prices.\n\n  \n\nRemember?\n\nThose who profit continually from this black market will never, never, never,\nof course, contribute financial aid or other goods and services to the\npoliticians whose prohibitions and inhibitions prevent the lower prices of the\nprevious free market.\n\nOf course not.\n\nThat “is” a Conspiracy Theory, and all Conspiracy Theories “are” whacko.\n\nOf course.\n\nAnd Saddam Hussein made all those Wicked Weapons of Mass Destruction disappear\nby sprinkling them with fairy dust.\n\nOf course.\n\n\nOld Man On A Balcony:\n\nViews Of Monterey Bay #6\n\n  \n\nMIDNIGHT HAIKU\n\n  \n\nMottled blueblack sky.\n\n  \n\nA sudden moon — briefly! Then:\n\n  \n\nBlueblack mottled sky ...\n\n\nBlack Magick & Curses\n\n\nSecrets of ye Dark Arte call'd Ducdame\n\n  \n\nZounds! I was never so bethump’d with words\n\nSince I first call’d my brother’s father dad.\n\n  \n\n— The Bastard in King John Act 11, Scene 1\n\nby Wm. Shakespeare\n\n  \n\nPeople sometimes ask me, “Doctor Bandler, do you have to use that kind of\nlanguage?” And my answer is “Fuck, yes!”\n\n  \n\n— Dr. Richard Bandler, Neuro-Linguistic Programming Workshop, Los Angeles,\n1999\n\n  \n\nDr. Harold Garfinkle, a UCLA sociologist, has written a whole book recounting\nexperiments that demonstrate that it takes remarkably little breaching of\nlocal Game Rules before subjects begin to show disorientation, anxiety, anger,\npanic, delusions, “inappropriate” emotions, etc. — wigging out, or going\nballistic in lay language.\n\nEven standing with your nose closer to a person’s face than the social norm\nfor conversation can provoke remarkable uneasiness with remarkable alacrity;\nit may even trigger “homosexual panic.” Doc Garfinkle did experiments to prove\nit.\n\nTo treat one’s parents with the politeness and formality usually given to\nlandlords and landladies can produce memorable freak-outs, sometimes involving\npleas for psychiatric intervention. Etc. (More experiments: See Garfinkle,\nStudies in Ethnomethodology, Prentice-Hall, NJ, 1967.)\n\nGarfinkle’s data demonstrates that humans at this primitive stage of\nterrestrial evolution have so many taboos that they cannot remember or\narticulate most of them; but they quickly become physiologically “disturbed”\nwhen even one of the rules seems even temporarily suspended. This disturbance\nmay culminate in serious injury, or death.\n\nThus, when I first moved to Santa Cruz, the world capital of Moral & Political\nCorrectness, I made the mistake of quoting a George Carlin routine at a party.\nOne line of this shtick goes, more or less:\n\n  \n\nWhy, why, why do all the women you see at anti-abortion protests look like\nnobody would want to fuck them in the first place?\n\n  \n\nA psychiatrist standing nearby said to me, sourly, “I don’t like cursing.”\nThis caused me considerable confusion. I had obviously violated a local taboo,\nbut I did not know which one, and worse yet, I had never considered “fuck” as\na curse or malediction. I felt like a guy who wanders into the local branch of\nAl Qaeda under the impression that he has found the Department of Motor\nVehicles, or — even more — like a ginkus who opens a door in his own house and\nfinds The Three Stooges in a phaser-gun shoot-out with Darth Vader and Mother\nTeresa.\n\nI feel grateful to that psychiatrist now, of course. Mulling over how he came\nto classify “fuck” in the category of curses, led me to review all that I knew\nabout the art and science of effective Cursing and about Black Magick in\ngeneral. The results of my meditations will appear as we proceed. (Thanks,\nDoc!)\n\nThis sort of head-banger or mind-bender happens more and more in our\npostmodern & multicultural world, especially if you travel as much as I do. A\nbasic sociological and anthropological law holds that while every culture (and\nevery sub-culture) has different Game Rules regarding speech and behavior,\neach tends to believe that its own tribal rules represent the only “correct”\nway for humans to interact with each other. Among savages, you must learn the\nlocal taboo system quickly or your life may pay for your ignorance.\n\nOf course, as Veblen pointed out long ago, among the Higher Barbarians, they\nwill not take your life but only your liberty; yet because confinement in a\ncage causes much suffering in all mammals, including humans, this threat\nterrifies the majority as much as the threat of death.\n\nAmong the Politically Correct, milder reprisals for taboo-breakers vary from\neconomic arse-kicking (denial of tenure) to cruel & unusual punishments\n(compulsory “Sensitivity” Training).\n\nI first experienced this sociological phenomenon when, after three years in\nIreland, I had a lecture-tour in the United States. I found that taboo systems\nhad changed rapidly in some places but not in others: no city on the trip\nprepared me for the Game Rules in the next city. E.g., in Dallas, they still\nthought it polite to hold a door for a lady and boorish not to, but in New\nYork they thought it insulting to hold the door for a lady, thereby making it\nnecessary for me to navigate with extreme delicacy to avoid either holding the\ndoor or allowing it to slam rudely in her face.\n\nIf you fully understand the anthropological significance of the above, you\nknow enough to write a whole book on black magic. Otherwise, read on. I will\nreveal the secret inner dynamics of how to hurl a truly nefarious curse —\nknowledge previously reserved only to the greatest Adepts of the Art called\nDucdame.\n\nWe all, to some degree, think in “magical” categories. Books on anthropology\nhave sold better than any others in social science because they all shed as\nmuch light on our own tribal taboos as on whatever so-called “primitives” they\ndepict. We need to understand Magick to understand ourselves.\n\nWhat do we mean by Magick?\n\nAs Aleister Crowley, Epopt of the Illuminati, 97th degree Order of Memphis and\nMizraim, 33rd degree Scotch Rite, 10th degree Ordo Templi Orientis, “Baphomet”\nto the profane and “Phoenix” within the Sanctuary of the Gnosis, the Great\nBeast 666, etc. wrote:\n\n  \n\nMAGICK is the Science and Art of causing Change to occur in Conformity with\nWill.\n\n  \n\n. . . Illustration: it is my Will to inform the World of certain facts within\nmy knowledge. I therefore take “magical weapons,” — pen, ink and paper; I\nwrite “incantations” — these sentences — in the “magical language,” i.e., that\nwhich is understood by the people I wish to instruct; I call forth “spirits,”\nsuch as printers, publishers, booksellers, and so forth, and constrain them to\nconvey my message to those people . . .\n\n  \n\n\\-- Magick, by Aleister Crowley, Weiser, 1997, p. 126\n\n  \n\nIn other words, the distinction between “magick” and “communication” exists\nonly in our traditional ways of thinking. The uncanny Egyptians attributed\nboth inventions to a single deity, Thoth, god of speech and other illusions.\n\nIn the existential world — in the sensory-sensual continuum — Thoth still\nreigns and language still has magick. All communication contains sorcery\nand/or hypnosis, because humans use howls, snarls, yaps, purrs, gargles,\ngurgles, etc. — noises of many sorts — to create a neuro — semantic “grid”\nprojected upon all incidents and events. We generally call these grids\nlanguages.\n\nWe literally “see” incidents and events only as they register upon that grid.\n\nIf I use certain words that cause you to have certain predictable neuro-\nsomatic reactions, I have cast a spell upon you. I have enchanted you. I may\neven have cursed you.\n\n(Sure you want to know more about this?)\n\nMy method of spellbinding or enchanting or cursing may not involve the\ntraditional drums and rattles of the tribal shaman, but the laws of\nneurolinguistic programming governing the transactions do not differ. I once\ntriggered widespread scotoma, primate herd panic and psychoclonism in one nut\ncult called CSICOP simply by ridiculing them. They thought of themselves as\nRationalists, but I “magically” turned them into terrorized savages acting\nexactly like the ancient Irish kings who ordained death for any Bard writing\nsatire against them. (No applause, please.)\n\nTo understand the language of magick one must first understand the magick of\nlanguage.\n\nLet me define certain key terms. It may help disperse the fog of ignorance and\nsuperstition that has covered this subject for centuries.\n\nBy the sensory-sensual continuum I mean all that humans can experience, as\ndistinguished from those “things” (or non-things, or nothings) that they can\nonly make noises or chatter about.\n\nExamples: [A] I can say “If you open that box of candy, you will find three\nchocolates inside.” Going to the box and opening it, in the sensory-sensual\ncontinuum, will quickly confirm or refute my statement, because you will\ninevitably find [1] fewer than three chocolates, [2] exactly three chocolates,\nor [3] more than three chocolates. Results [1] and [3] refute my statement;\n[2] confirms it.\n\nBut [B] I might also say “Opening God for similar investigation, you will find\nthree persons inside,” as, in fact, Romish Magick does say. No investigation\nof the sensory-sensual manifold can ever confirm or refute this. Scientific\nphilosophers generally describe such statements (about things beyond\nconfirmation or refutation) as “meaningless”. Without speaking that harshly, I\nventure that we cannot fathom our situation in space-time if we habitually\nconfuse ourselves by mixing type [A] statements with type [B] statements. We\nmay never achieve Total Clarity (short of infinity), but we should at least\nhave the ability to distinguish between what humans can experience and what\nthey can only blather about.\n\nDistinguishing between these two types of statements seems necessary for\nsanity and survival, because all forms of illusion, delusion, mob hysteria,\nhallucination, etc.; dogma, bigotry, “madness,” intolerance, etc.; “idealism,”\nideology, idiocy, obsession, etc. depend upon confusing them. The people who\nreleased poison gas in the Tokyo subways, the Nazis, the Marxists, nut-cults\nlike Objectivism, Heaven’s Gate, Scientology, CSICOP, etc. represent some of\nthe horrors and curses unleashed by mixing Class [A] statements with Class [B]\nstatements.\n\nAll forms of Black Magick therefore depend on confusing and mingling these two\nclasses: the nonverbal experiential and the verbal nonexperiential.\n\nBy the neuro-semantic field I mean the total vocabulary, grammar, syntax,\nlogic, etc. by which an extremely rapid system of feedbacks synergetically\nlinks the verbal centers of the brain to the neuro-muscular, neuro-chemical,\nneuro-immunological, neuro-respiratory, etc. systems of the organism-as-a-\nwhole. In other words, I explicitly reject, not only the traditional verbal\ndivision between “magick” and “communication,” but the equally fictitious\nsplits between “mind” and “body,” between “reason” and “emotion,” between\n“thought” and “reflex,” etc.\n\nAll words transmitted as sonic or visual signals--sound waves or light waves —\nrapidly become photons, electrons, neurotransmitters, hormones, colloidal\nreactions, reflex arcs, conditioned or imprinted “frames,” physiological\nresponses, etc. as they impact upon the total synergetic organism.\n\nLet’s take that a bit slower:\n\n  \n\nAll words transmitted as sonic or visual signals — sound waves or light waves\n—\n\nrapidly become photons,\n\nelectrons,\n\nneurotransmitters,\n\nhormones, colloidal reactions,\n\nreflex arcs,\n\nconditioned or imprinted “frames,”\n\nphysiological responses,\n\netc.\n\nas they impact upon the\n\ntotal\n\nsynergetic organism.\n\n“Perception” consists of a complex series of codings and decodings as in-form-\nation trans-forms itself through successive sub-systems of the organism-as-a-\nwhole.\n\n(Please re-read the last two sentences.)\n\nWe never experience “thoughts,” “feelings,” “perceptions,” “intuitions,”\n“sensations,” etc. We invent those categories after the fact. What we\nexperience, nanosecond by nanosecond, consists of continuous synergetic\nreactions of the organism-as-whole to the environment-as-a-whole, including\nincoming verbal signals from others in the same predicament. These incoming\nverbal signals also produce in us reactions of the organism-as-a-whole\nsometimes culminating in a return signal.\n\nThat much seems simple neurobiological savvy.\n\nBut suppose I point a shamanic death-bone at you? Or utter a Magick Word that\nalarms and threatens you as much as a simple “fuck” threatened that Santa Cruz\npsychiatrist?\n\n  \n\nWe never “know” organismically all that we know theoretically. Parts of us\nremain simian, childish, “ignorant,” murky, inertial, mechanical, etc.\n\nIllustration #l: Consciously and will-fully remind yourself that you can tell\nthe difference between a “movie” and “real life.” Then go to see the latest\nketchup-splattered horror/slasher classic and pay attention to how many times\nthe director “magically” tricks you into real gasps, internal or overt cringe-\nreflexes, dry mouth, clutching (seat-rails, coke can, companion’s arm, etc.),\nor other symptoms of minor but real (polygraph-diagnosable) anxiety and short-\nterm near-panic, sometimes verging on vomit-reflex.\n\nIllustration #2: With the same conscious and will-full reminders about the\ndifference between “movies” and “real life,” rent a hard-core XXX porno DVD.\nObserve how long it takes before physiological responses indicate that parts\nof you at least have lost track of that distinction.\n\nTo repeat an earlier point, in Neurolinguistic Programming (NLP), Dr. Bandler\nmakes a distinction between the “meta-model” and the “Milton model.” The meta-\nmodel, continually revised, updated and expanded, consists of the class of all\nscientifically meaningful statements available at this date. We should revise\nour meta-model every day, by keeping in contact with others in the same\npredicament. Since Scenario Universe always and only consists of — as Bucky\nFuller said — non-simultaneously apprehended events (coherent space-time\nsynergies), such continuous feedback appears necessary.\n\nIf everything happened at once, we would know Absolute Truth at once; but\nsince space-time events happen non-simultaneously, we need feedback.\n\nThe “Milton model,” on the other hand, named after Dr. Milton Erickson, “the\ngreatest hypnotist of the 20th Century,” consists of the class of all\nscientifically meaningless statements that “magically” make us feel much\nbetter, or much worse — or, in occult language, the class of all blessings and\nall curses.\n\n(General Semanticists call it the class of all purrs and all snarls.)\n\nThis Heap Big Magick, bwana. You can fucking kill a guy with this stuff. And,\nof course, if you have Dr. Erickson’s compassion, you can repeatedly heal the\nseemingly helpless.\n\nFour score and something years ago, Drs. Ogden and Richards, in The Meaning of\nMeaning, brought forth a distinction between the denotation of words and the\nconnotation of words.\n\nIn the denotation, any word or group of words belongs in the meta-model if it\nconforms to the test of the model; viz. scientifically meaningful reference in\nthe experiential-phenomenological world.\n\nAnd in the connotation, any word or group of words belongs in the Milton model\nif it conforms to the test of that model; viz. again, scientifically\nmeaningless reference to nothing-in-particular and everything-in-general so\npackaged as to make us feel better, or worse.\n\nOur major problem, in the elementary blessing and cursing game called social\nconversation, lies in the fact that quite often — very, very often — the same\nword may have “objective” denotations in the scientific meta-model but also\nhave “emotive” neurosemantic connotations in the magical Milton model. In\nother words, we hypnotize ourselves, and one another, with remarkable ease. In\nonly a few minutes, a dedicated dogmatist can have you heatedly shouting\nsomething in the form of the Primary Magick Theorem, which declares that any\nnon-verbal incident or event encountered and endured “really” “is” some noise\nor grunt we choose to label it with.\n\n(One corollary holds that sticking pins in a doll will hurt the person sharing\nthe doll’s label, and a second states that throwing darts at an image of the\nEnemy Leader will “help the war effort.”)\n\nIllustration: By persistent reiteration of medieval logical forms, the anti-\nchoice people in the abortion debate have hypnotized the pro-choice people\ninto interminable haggling about whether one non-verbal event inside a woman\n“really is” (the noise or grunt preferred by my side) and “really” “is” not\n(the gargle or gurgle preferred by the other side). Since the various noises,\ngrunts, gargles, gurgles, etc. have no experiential or experimental or\nphenomenological or existential referents in the sensory or sensual or\ninstrumental space-time manifold, this contest transpires in the Milton model,\neach side trying to hypnotize the other.\n\nBut, even more nefariously, this has the structure of what Watslavick called,\nin Pragmatics of Human Communication, the Game Without End. This Game — which\nword “really” “is” the non-word — gives great entertainment and self-esteem to\nthose who really like that kind of thing; but it causes Kafka-esque and\n“nightmarish” sensations throughout the organism-as-a-whole among those who\nwant to get out of the Game and go back where language made sense, but\nnonetheless remain spellbound & “cursed” for the seemingly infinite length of\nthe Game Without End.\n\nThe Game Without End begins with the attempt to decide which bark or howl\n\"really” “is” a nonverbal existential event.\n\nNone of this represents abstract theorems. The role of magick in all language\ntransactions has very concrete and exhilarating/terrifying implications:\n\nWell-documented case of a man literally killed by a shaman’s curse and a\n“death-bone.” (The Psychobiology of Mind-Body Healing, by Ernest Lawrence\nRossi, Norton, 1988, page 9-12.)\n\nEqually well-documented case of another man, a cancer patient, “miraculously”\nblessed by remission and recovery due to a placebo (with tumors shrunk to half\ntheir previous size), then cursed back into critical condition when learning\nof deaths of others receiving the same placebo. (Same book, page 3-8.)\n\nRobert Houdin, often called the greatest stage magician of the 19th Century,\nonce said, “A magician is only an actor — only an actor pretending to be a\nmagician.”\n\nSimilarly, what French anthropologists call participation mystique (“at-one-\nness” or even “holy union”) — a state allegedly limited to “savages” — occurs\nevery day, in every modern city, in nonpathological forms, at our theatres and\nmovie houses, and on our TVs, VCRs and DVDs.\n\nThis mystic trance, in which (for instance) Laurence Olivier becomes “Hamlet”\nright before our eyes, only mutates to the pathological if we cannot break the\nspell — if we continue to see, and relate to, Lord Olivier as Hamlet even if\nwe chance to meet him in a pub: “I say, old bean, you seem to suffer from\ncompulsive rumination, as the shrinks call it. Just kill the old bugger and\nmake a run for the frontier.”\n\nHere the Milton model has replaced the meta-model in the wrong space-time\nlocale (territory not defined as play-acting space). Madness lies but one step\nfurther.\n\nMy mother never stopped hating Charles Laughton for the sadistic glee he\nprojected in the punishment sequences of Mutiny on the Bounty. She’d never\nlook at another movie with Laughton in it.\n\nOrson Welles, with considerable experience as both actor and stage magician,\nsaid “I have been an acting-forger all my life.” He said it in his last film,*\na fake documentary about a partially fake biography of a totally fake painter\n— F For Fake, based on a seemingly true but partly bogus biography called,\neven more bluntly, Fake!\n\n  \n\n~•~\n\n* Not the last film he acted in, just the last film in which he had control as writer/producer/director/actor.\n\n~•~\n\n  \n\nSome of us have become postmodern whether we like it or not.\n\nAs the Poet wrote,\n\n  \n\nI saw a man upon the stair,\n\nA little man who wasn’t there;\n\nHe wasn’t there again today,\n\nGee, I wish he’d go away!\n\n  \n\nOf course, we all clearly understand that the little man who “wasn’t there”\nsimply “wasn’t there” and hence can’t go away, but the structure of Indo-\nEuropean grammar so spellbinds and enchants us that we illogically feel that\nthe spooky little bastard should go away, just to conform to the syntax.\n\nWhosoever speaks in any tongue gives birth to blessings and curses, & if the\nuncanny Egyptians made Thoth the father of both language and magick, the canny\nGreeks made Hermes the god of both language and fraud.\n\n\nOld Man On A Balcony:\n\nViews Of Monterey Bay #7\n\n  \n\nDolphins in the bay\n\n  \n\nPlaying, sporting, having fun —\n\n  \n\nWorld without money!\n\n  \n\nTHOUGHTS TO PONDER\n\n  \n\nThe hand that stocks the drug stores rules the world.\n\n  \n\n— Bokonon\n\n\n#### Shocking Hidden Facts About Male Non-Violence\n\n  \n\nI wrote this piece in April 1996 for a mag called Backlash, and have rewritten\nit only slightly. It should prove interesting not only to those in a currently\nscapegoated group, but to those NOT in such a group, because in the\naccelerating modern world we all eventually get assigned to the Shit-on role.\n\n  \n\nDid you know that over 98 percent of the men in the United States today have\nnever been convicted of any violent crime or served time in prison?\n\n— That, even though the U.S. imprisons a higher percentage of its citizens\nthan any other nation, over 98 percent of our men have never been convicted of\nrape, murder, child molestation, assault, battery, breaking and entering, or\nany kind of violence?\n\n— And almost half of the men who do land in prison are convicted of non-\nviolent crimes.*\n\n  \n\n~•~\n\n* Usually medical, religious or recreational Heresy — i.e., deciding for themselves which herbs, vitamins and compounds to use, instead of allowing a Tsar to decide for them. See my TSOG: The Thing That Ate the Constitution.\n\n~•~\n\n  \n\nThese basic statistical facts about male nonviolence have been hidden from us\nby an ideology/mythology which I call androphobia — fear and hatred of the\nmale. Androphobia has also hidden such facts as these:\n\nImportant Feminists of the past include such males as Clarence Darrow, John\nStuart Mill, Henrik Ibsen, Robert Dale Owen, James Joyce, and Bertrand\nRussell.\n\nPsychologists who measure IQ have never found any statistical difference\nbetween the intelligence of men and women. High, middle, and low IQs are found\nin both sexes! There is no scientific proof of male inferiority! The mythology\nof male brutishness and stupidity has been spread by the androphobes without a\nsingle shred of statistical evidence.\n\nDo you believe men are innately brutal? When no other human being was willing\nto nurse the lepers on Molokai Island, it was a male, Father Joseph Damien,\nwho went there to care for those unfortunates.\n\nConsider these further suppressed facts about maleness:\n\nAlthough they were men, Michelangelo, Sir Christopher Wren, and Frank Lloyd\nWright are almost universally considered great architects.\n\nThe first Feminist pamphlet published in this country was written by a man —\nTom Paine (who also wrote the first anti-slavery pamphlet).\n\nThe most original music of this century, Jazz, was created almost entirely by\nBlack males.\n\nFree public libraries, which made more knowledge available to more people than\nany invention before Internet, were founded on gifts made by Andrew Carnegie,\nwho was not just male but a rich white male — the accursed of the accursed . .\n.\n\nLeonardo da Vinci made hundreds of great contributions to both science and art\ndespite the triple handicaps of being Gay, left handed and male.\n\nMen including Martin Luther King Jr., Mahatma Gandhi, and Sean McBride have\nplayed important roles in the struggle for world peace.\n\nEven though Shakespeare, Dante, and Homer were males, they wrote poetry\ngenerally considered as good as anything by Amy Lowell.\n\nBeethoven, Mozart, and Bach were men and yet they wrote music at least as good\nas that of Hildegarde of Bingen.\n\nMales such as Newton, Einstein, and Archimedes made contributions to science\nas important as those of Marie Curie.\n\nThe cure for yellow fever, saving the lives of millions, was found by a man,\nMajor Walter Reed.\n\nDespite the androphobic mythology/ideology, at no time in history except the\npresent was maleness considered a shame, a disgrace, or a sign of inferiority.\n\nAll the “major” religions (those having millions of followers) were founded by\nmales born in Asia (Confucius, Lao-Dzu, Buddha, Moses, Jesus, Mohammed).\n\nMen were responsible for such discoveries as the sailing ship, the compass,\nthe steam engine, the electric light, the AC generator, the computer, and many\nothers. And males created over 90% of mathematics.\n\nAll of this sounds strange, bizarre, almost unbelievable, I know. We have all\nhad so much brainwashing by the androphobic meme that we scarcely can believe\nmales have ever done anything but shoot one another, rape women, and blow\npeople up. Androphobia remains the one respectable bigotry — the only form of\ngroup-libel that nearly everybody considers “politically correct” and which\ntherefore goes unchallenged almost everywhere. Male achievements, thus, have\nbeen systematically excluded from “the universe of discourse” — i.e., what\n“nice” people talk about.\n\nLet us clarify the ideology of androphobia. I define androphobia as the\ntransfer to all males of the negative stereotypes that the Ku Klux Klan and\nother neanderthal types assign only to black males:\n\n— mental inferiority, of course;\n\n— emotional childishness, or “inability to think rationally”;\n\n— brutality — i.e., sub-human status;\n\n— criminality;\n\n— sexual violence, etc.\n\n  \n\nYou see? All the old racist clichés — except “a great sense of rhythm.”\n\nI thus regard androphobia as merely a transmutation from racism to sexism, an\n“advance” that is not an advance at all.\n\nLet me make this very clear. I do not oppose Feminism; on the contrary, I\nreject all forms of group stereotyping and dehumanization. Androphobia (or\nmale-bashing) has no intrinsic or necessary link with Feminism, and many\nFeminists utterly reject androphobia. To use an analogy, Marx said that “anti-\nSemitism is the socialism of fools.” Similarly, I regard androphobia as the\nFeminism of imbeciles.\n\nI oppose androphobia as psychological gendercide. I believe it underlies the\nwidespread male depression (which psychotherapists recognize as “epidemic”),\nand also explains much of the soaring suicide rate among boys and young males.\n\nThe suicide rate among boys aged 16 to 19 runs four times higher than that of\nfemales, and the suicide rate of men between 20 and 24 soars to six times that\nof females (according to the U.S. Department of Health Statistics).\n\nThis self-destructiveness has increased steadily, among males, for 30 years —\nsince the rise of the androphobic ideology. Few want to grow up male in a\nsociety where maleness is defined as a sign of incurable inferiority or\ncriminality.\n\nAndrophobia has created the kind of tension that psychologists call a “double-\nbind.” A classic double-bind, as Gregory Bateson defined it in his pioneering\nwork on the subject, Communication: The Social Matrix of Psychiatry, involves:\n\n(a) an impossible choice one cannot escape, and,\n\n(b) just as crucial, a social rule that forbids verbal comment on the\nimpossibility of the situation.\n\nGays, blacks, Hispanics, and all other minorities retain the freedom to\ncomment on their situation — even to comment angrily or to protest in the\nstreets.\n\nHowever, one cannot comment on androphobia these days. It is not only\n“politically incorrect” but virtually unthinkable. To talk about the subject\nat all remains under a very big taboo — while millions of boys and men stagger\nfrom depression to suicide annually.\n\nFor instance, in 1979, psychologist Roy Schenk attempted to give a workshop on\nmen’s oppression at the annual conference of the Association for Humanistic\nPsychology. He announced in advance that the seminar would investigate what it\ndoes to the psyche of boys and men to grow up “being perceived as morally\ninferior to women.” The AHP would not allow the workshop.\n\nThis year, I tried again, offering a similar workshop at a New Age conference\nthat had had me as workshop leader several times in the past. They also would\nnot allow this subject to be discussed at all.\n\nConsider the “logic” of androphobia, and how it deliberately contradicts known\nfacts. Remember: 98% of the men in this country have never been in prison or\ncommitted a violent crime, but the androphobe insists that all men are\n“violent.” Some of the most tender, beautiful music in the world was written\nby men such as Bach, Mozart, and Beethoven, but the androphobe insists all men\nare “insensitive.” To repeat: all the major religions based on justice and\nlove were founded by men (Asiatic men, in fact) but the androphobe insists all\nmen are “greedy” and “competitive.” This kind of “logic,” based on totally\nignoring all inconvenient facts, seems common to all forms of racism,\nxenophobia and bigotry.\n\nIn fact, if you listen to the rantings of any leading androphobe (such as\nCarol Hemingway, Andrea Dworkin, or Robin Morgan) and mentally change the word\n“male” to “Jew” every time it appears, the result would be totally\nindistinguishable from the rantings of Hitler, because the “logic” of bigotry\nremains the same in all cases.\n\nIt is the “logic” of ascribing one essence to a miscellaneous group, which is\nonly possible when all sensory space-time facts become replaced by fungible\nabstractions; but this flight into abstraction is “politically correct” and\nvirtually nobody dares to challenge it.\n\nThus, the “evil” of maleness in our society today, like the “evil” of\nwitchcraft in medieval days, is beyond debate or discussion. The “no comment”\ntaboo applies, leading directly to the double-bind that triggers mental\nbreakdowns. Males, thus, have become the only minority that can be slandered\nand demeaned with any and all group stereotypes, in “respectable” media, and\nwith no rebuttal allowed. All other minorities can “fight back” against group\nlibel, but men who try to fight back against stereotypes and group libel are\nregarded as crazy, or “in denial,” or beyond the bounds of reasonable\ndiscourse.\n\nFortunately, this is beginning to change — a little. We look forward to a day\nwhen sanity and common sense triumph over bias, and all men and women, all\npeople of all races, are judged one at a time and not condemned by group\nstereotypes. Meanwhile, anti-Semites (and most other bigots) can only\ncirculate their lunatic rantings through ill-written URLs with infrequent\nvisitors, while the androphobes still have free access to all major media and\ncan endlessly spout the most idiotic forms of sexism while claiming to oppose\nsexism.\n\nAs Shakespeare said (with a few minor revisions and updates):\n\n  \n\nI am a man. Hath not a man eyes? Hath not a man hands, organs, dimensions,\nsenses, affections, passions? Fed with the same food, hurt with the same\nweapons, subject to the same diseases, healed by the same means, warmed, and\ncooled by the same winter and summer, as a woman is? If you prick us, do we\nnot bleed? If you tickle us, do we not laugh? If you poison us, do we not die?\n\n\nOld Man On A Balcony:\n\nViews Of Monterey Bay #8\n\n  \n\nFlock of gulls appears\n\n  \n\nAnd suddenly — disappears\n\n  \n\nGoing God-knows-where . . .\n\n\n#### Language, Logic & Lunacy\n\n  \n\nAnother piece for Backlash, from around the same time as the previous\nBlasphemy . . .\n\n  \n\nKung Fu Dzu, called Confucius among the Higher Barbarians, said, “The first\nrule of politics is to use the language precisely. Otherwise, nobody\nunderstands anybody else, and everything falls into chaos.”\n\nSome commentators regard the ideograms about using language precisely — ching\nming — as the single most important concept in Confucian philosophy.\n\nching as noun means officer or court official; as verb it means to correct\nerrors or to regulate one’s actions; cf. Catholic “examination of conscience,”\nor cybernetic “feedback.”\n\nming = mouth + moon — “moony” language, floating abstractions, vague\ngeneralities, meaningless propositions, etc.\n\nching ming = be sure brain turned on before setting mouth in motion.\n\nIn creating a defense league against the rabid androphobia of Steinem &\nCompany, we need to notice which misuses of language create the logical chaos\nthat reinforces and perpetuates the androphobic lunacy. I offer two small\ncorrections of language here.\n\n“White men still own all the corporations.” I heard this from a Hispanic\nradical on local TV recently. This sentence can serve as a perfect example of\nhow sloppy language habits create warped reality-tunnels, because it looks\nalmost true at first, but it actually contacts an enormous Nazi-like Big Lie.\n\nLeaving aside the facts that, internationally, many corporations belong to\nnonwhite males, and that, even nationally, a few corporations belong to\nfemales, let us assume that, within the US, the statement contains maybe 95\npercent accuracy. In other words, let us assume that per- haps 95 percent of\nall corporations active here have white male owners.\n\nThis statement obviously differs vastly from “95 percent of all white males\nown corporations.” In fact, even the Hispanic radical quoted above, if he\nopened his eyes, could see many, many white males working at lowly and menial\njobs in this part of the country. These poor whites do not own corporations.\nNeither do many others who don’t even have lousy jobs and survive by begging\non the street.\n\n“White men own all the corporations” does tend to get confused with “All white\nmen own corporations.” Listen closely to radicals in general, and Radical\nFeminists in particular, and you will hear, over and over, how this self-\nhypnosis works. They leap from the first partly true statement to the second\ntotally false one without even noticing that they have reversed their logical\nterms in the middle. They can literally walk past a homeless white man\nsleeping in an alley and not observe how his existence contradicts their\nracist/sexist ideology.\n\nNote that the same confusion existed in the foundation of the Nazi madness.\n“The Jews own the international banks” has lower accuracy than “white men own\nall corporations,” but even if it fit 100 percent — or at least 95% — which it\ndoesn’t — of all banks, it still would not mean the same as “all Jews own\ninternational banks.” Nonetheless, the Nazis somehow managed to convince\nthemselves that it did; the Holocaust followed.\n\nAs semanticists like Korzybski and Bourland have pointed out, this type of\nconfusion, and the bigotry it perpetuates, results from the very structure of\nour language. “White men” and “Jews” can serve as subjects of many sentences,\nbut they do not mean the same in all sentences.\n\nThus, “White men came down the path” refers to a definite number at a specific\noccasion; “White men own corporations” refers to a larger, but still smallish\nnumber, a statistically tiny segment of all white men; and “White men are not\neligible for affirmative action” refers to all white men in the U.S. today.\n\nWe tend to confuse these various meanings, unless we modify the key expression\nat once — e.g. “Three white men come down the path,” “5,000 white men own\ncorporations,” “100 million white men are not eligible for affirmative\naction.” (These figures represent estimates, or guesses, to convey the idea.\nThey do not claim to represent statistics I have not collected.)*\n\n~•~\n\n* I have elsewhere suggested that when generalizing without statistics we should use the term “sombunall” — some but not all — in every single case where we have not in fact examined all members of a set or class. Where you feel more sure of yourself than I usually do, you may use “mosbunall” — most but not all. But remember to encourage (not-discourage) feedback and never neglect examination of conscience.\n\n~•~\n\n  \n\nConsider next “the Patriarchy” against which we have heard so much heated\nrhetoric in recent decades. Does this term really fit our society? The Rad Fem\ncrowd repeats over and over that it does fit, but I suggest that it does not.\n\nIn a Patriarchy, a man continues to have custody of his children after a\ndivorce. In the U.S. today, the wife gets custody in about 90 percent of all\ncases, as noted by John Sample in the February 1996 Backlash. That seems to\nplace us closer to Matriarchy than to Patriarchy.\n\nMore important, however, since males in our society die seven years younger\nthan their wives, most families that own most of the wealth fall under female\ndomination eventually. And, of course, contrary to Rad Fem propaganda, even\nwhile the males remain alive, most of them share decision-making with their\nwives on many important occasions; they probably share decisions with their\nmistresses also; and women do most of the shopping and spending. The men only\nearn the money; the women dispose of it.\n\nI think we can only accept Oligarchy as the proper name for that system — not\nMatriarchy, as Philip Wylie wickedly suggested in the 1940’s and not\nPatriarchy, as the Feminists have insisted since the 1960’s. A group of rich\nfamilies, not merely the males, make all the important decisions. This type of\nsystem has existed in every post-tribal society in history, including the ones\nthat call themselves democratic, socialistic or even communistic. Oligarchy\nvirtually means the same as “civilization.” Ignoring this fact, and picking\nout some scapegoat group like Jews or males, utterly confuses our political\nthinking and can lead to nothing but madness.\n\nFinally, my own take on the Angry White Males who allegedly caused the recent\nRepublican risorgimento: as a boy, I learned to believe (as all my family\nbelieved) that the Republicans represented the Orangemen (English and Dutch\nbanking families) and the Democrats represented all the rest of us, but\nespecially us Irish Catholic working people. As my life took me further and\nfurther from that background, I lost all affiliation with Catholicism but\nretained an ethnic/class identification, of sorts, with the Irish and the\nworking class.\n\nIf the Democrats have truly lost the Irish and the workers, I can only think\nthey have done it by getting too cozy with Steinemism — too tightly associated\nwith those racist and sexist pseudo-radicals who don’t remember, or want to\nremember, that not all white men own corporations or meet weekly with David\nRockefeller at the Patriarchy Club to make all the decisions for our society.\n\n\nOld Man On A Balcony:\n\nViews Of Monterey Bay #9\n\n  \n\nMIDNIGHT HAIKU #2\n\n  \n\nDancing in the bay—\n\n  \n\nDolphins again? No, better:\n\n  \n\nReflected moonlight.\n\n\n#### Dreams of Flying\n\n  \n\nAnother article from my Los Angeles period (Magical Blend 1988) . . . Arlen ’s\nillness had not begun yet, and for the first time in my writing career I kept\nearning enough every year to stop worrying about money. . . almost . . . (Once\nyou hit bottom economically, as I did in 1972, you never earn enough to really\nstop worrying . . .)\n\n  \n\nI have recently read a most enjoyable novel called The Dream Illuminati by\nWayne Saalman (New Falcon Publications, Santa Monica, 1988). Mr. Saalman has\nfound an epic theme — dreams of flight, and the achievement of flight.\n\nHistorically, dreams of flying appeared in the collective unconscious before\nthe reality of flight existed in technology, and I suspect that if we\nunderstood our dreams better we would use our technology more wisely. Our\nmachines manifest our dreams in matter crafted to coherence, and a\npsychoanalysis of our culture could easily derive from an examination of how\nwe use science to materialize our fantasies and nightmares.\n\nMr. Saalman’s science-fantasy made me wonder: Why have we always dreamed of\nflying, and why have we built flying machines? This question seems “eminently”\nworth pondering in a world where 200,000,000 people pass through Kennedy\nInternational Airport every year, flying the Atlantic in one direction or the\nother.\n\nTo understand the profound, it often appears helpful to begin with clues that\nseem trivial. I suggest that we contemplate what our children look at every\nSaturday morning on TV. One of the most popular jokes in animated cartoons\nshows the protagonist walking off a cliff, without noticing what he has done.\nSublimely ignorant, he continues to walk — on air — until he notices that he\nhas been doing the “impossible,” and then he falls. I doubt very much that any\nreader has not seen that routine at least once; most of us have seen it a few\nhundred times.\n\nIt might seem pretentious to see a Jungian archetype adumbrated in crude form\nin this Hollywood cliché, but follow me for a moment.\n\nWhen Hollywood wishes to offer us the overtly mythic, it presents Superman,\nwho can “leap over tall buildings in a single bound,” and a more recent hero\nnamed Luke Skywalker.\n\nThe Tarot, that condensed encyclopedia of the collective unconscious, begins\nwith the card called The Fool, and the Fool is depicted walking off a cliff —\njust like Donald Duck or Wily Coyote in the cartoons.\n\nFunny coincidence, what?\n\nA Greek legend (which James Joyce took as the archetype of the life of the\nartist) tells us of Daedalus and Icarus: Daedalus who, imprisoned in a\nlabyrinth (conventional “reality”), invented wings and flew away, over the\nheads of his persecutors; and Icarus, the son of Daedalus, who flew too close\nto the Sun Absolute and fell back to Earth. Like Porky Pig walking off a\ncliff, Icarus’ fall contains a symbolism many have encountered in their own\ndreams.\n\nThe Sufi order employs as its emblem a heart with wings (and the Ordo Templi\nOrientis employs a circle — symbolizing both emptiness and completion — with\nwings). The Egyptian god of wisdom, Thoth, had the head of a winged creature,\nthe ibis; his Greek equivalent, Hermes, was portrayed as more human, but had\nbird’s wings on his sandals.\n\nThe Wright Brothers, who made flying possible for all of us, remain beloved\nfigures in the folk imagination — but how many readers can name the inventors\nof such equally marvelous (but earthbound) devices as the television, the\nvacuum cleaner, the computer, the laser, or the modern indoor toilet?\n\nYet while other geniuses seem “forgotten by the masses,” the classic put-down\nto satirize any conservative who sets limits to what human craft can\naccomplish remains “I told Wilbur and I told Orville, you’ll never get that\ncrate off the ground.”\n\nYou see? We even remember their first names.\n\nI suspect that part of the function of flight consists in destroying our\nconcept of limit, opening us to the insight Dr. John Lilly expressed so\neloquently in The Center of the Cyclone:\n\n  \n\nIn the province of the mind, what is believed to be true is true or becomes\ntrue, within limits to be found experimentally and experientially. These\nlimits are further beliefs to be transcended. In the province of the mind,\nthere are no limits.\n\n  \n\nThe poet Hart Crane, trying to describe what Wilbur and Orville Wright meant\nto his generation (he died in 1932), wrote that from Kitty Hawk onward, be\nsensed “the closer clasp of Mars.” By 1938 people tuning in on an Orson Welles\nradio program after the drama started, believed they were hearing a newscast\nand the Martians were already here. A quantum jump had occurred in the limits\nof our social imagination. Humanity had, like the poet, sensed the “closer\nclasp” of Mars.\n\nJust slightly more than 30 years later, Neil Armstrong walked on the moon,\nlike a character in the fiction of Jules Verne, and ten years later, our\ninstruments invaded the Martian desert already familiar to “us” through the\nvisions of Edgar Rice Burroughs and Ray Bradbury. If this does not confirm\nWilliam Blake’s notorious claim that “Poetic Imagination” should be considered\nanother name for “God,” it certainly suggests that Poetic Imagination may\nfunction as another name for Logical Destiny.\n\nPerhaps we should ponder more deeply on the fact that Daedalus means “artist”\nin Greek. Daedalus, designer of labyrinths, imprisoned by those he served in a\nlabyrinth he himself built — Daedalus, inventor of wings that took him from\nthe Earth to Outer Space — why does he represent Art, instead of Science?\n\nWell, to understand this we must remember that the ancient Greeks did not\ndistinguish “Art” from “Science” as we do. The genius of an artist, Aristotle\nsays, lies in his texne, the root from which we get our word “technology”; but\ntexne basically means skill or craft, or the ability to make things that never\nexisted before. Negative entropy, i.e., information.\n\nIn our age, by contrast, Stravinsky was regarded as “witty” or “paradoxical”\n(or deliberately enigmatic) when he called himself a “sound engineer.” An\nartist who considers himself a kind of engineer? That is a hard thought for us\nto grasp.\n\nYet a few moments reflection will show that as much precise structural\nknowledge can be found in Stravinsky’s music as in Roebling’s blueprints for\nthe Brooklyn Bridge — that edifice (considered “miraculous” when it was new)\nwhich Hart Crane took as a symbol of the unity of Art and Science.\n\nThe Occidental obsession with dichotomized and dualistic thinking has been\ndenounced so often lately that I hardly need to labor this point. I would\nprefer to suggest a possible common origin of both art and science.\n\nThe musician and the architect, the poet and the physicist — all inventors of\nnew realities — all such Creators may be best considered late evolutionary\ndevelopments of the type that first appears as the shaman. Please remember\nthat shamans in most cultures are known as “they who walk in the sky,” just\nlike our current shaman-hero, Luke Skywalker.\n\nIt should not be regarded as accidental or arbitrary that Swift put Laputa,\nthe home of the scientists, in the sky, in order to disparage the wild-eyed\nand Utopian scientists of his time for not having all four feet on the ground;\nAristophanes put Socrates in the clouds, to similarly disparage speculative\nagnostic philosophy.\n\nOuter Space seems the natural home of all descendants of the shaman, whether\nthey be called artists, philosophers or scientists.\n\nThe ironies of Swift and Aristophanes, and the myths of the fall of Icarus and\nDonald Duck, indicate that the collective unconscious contains a force opposed\nto our dreams of flight. This appears inevitable. As Jung, the foremost\nexplorer of the collective psyche, often pointed out, an ineluctable polarity\nexists in the symbols of both dream and myth, a “Law of Opposites” which Jung\ncompared to the Chinese concept of yin and yang energies.\n\nJekyll contains Hyde; love easily becomes hate; Cupid and Psyche reappear as\nthe Phantom of the Opera and Margaritta, and also as King Kong and Fay Wray.\n\nIn the present context, the Law of Opposites means that we yearn to soar, yet\nwe fear to fall. Our “inner selves” are mirrored not just in Orville Wright\nrising like a bird from Kill Devil Hills at Kitty Hawk, but also in Simon\nNewcomb, the great astronomer who “proved” mathematically that such flight was\nimpossible.\n\nAs I have elsewhere suggested, neophilia and neophobia — love of novelty and\nfear of novelty — result from the primal polarities of the first imprint of\nthe newborn infant. In other words, what Dr. Timothy Leary calls the bio-\nsurvival “circuit” of the nervous system — the oral bio-survival system, I\nprefer to call it, since it includes the immune, endocrine and neuropeptide\nsub-systems as well as the autonomic nervous system — always and only imprints\neither basic explorativeness or basic conservatism very quickly. That\nexplains, I think, why some babies “Chortle with delight” when tossed up in\nthe air and caught, while others scream with terror. Infants who like this\nexperience of flight, I suggest, already have the infophiliac imprint and\nthose who act terrified have the infophobic imprint.\n\nOf course, “the universe” can count above two (even if Aristotelian logicians\ncannot), and few of us are either pure neophilics or pure neophobics. Rather,\nwe wobble about on a gradient between neophilia and neophobia — between joy\nand anxiety, between conservatism and experimentalism, between yearning to\nsoar and fear of falling. At times we feel like Jonathan Livingston Seagull,\nconvinced that “a true Heaven has no limits” and trying to fly higher and\nfaster; other times we become the old Reaganite gulls, nervously warning that\nto fly too high too fast will ruin your brain and directly contradicts the\ntraditional mores of the flock. (“Just say no to soaring”).\n\nWe contain both Orville Wright leaping into the air toward a future “where no\nman has gone before” and Simon Newcomb proving that Orville will certainly\nfall and smash himself like Humpty Dumpty.\n\nAs Joyce so poetically writes:\n\n  \n\nMy great blue bedroom, the air so quiet, scarce a cloud. In peace and silence.\nI could have stayed up there for always only. It’s something fails us. First\nwe feel. Then we fall. I’ll seen him come down on me now under whitespread\nwings like he’d come from Arkangels, I sink I’d die down under his feet,\nhumbly dumbly, only to washup.\n\n  \n\nDespite the multiple dream-images here — the Irish rain falling to become the\nIrish river Anna Liffey, Lucifer and his hosts falling from Heaven, the falls\nof Adam and Eve and Humpty Dumpty, Mary receiving the divine seed from the\nArchangel, Magdalene washing the feet of the Saviour, the Paraclete descending\nas a dove to bring the Apostles the Gift of Tongues, a housewife washing up\nthe breakfast dishes — Joyce primarily invokes our deep awareness that gravity\n“pulls us down,” our deep yearning to break free of this “drag” and soar back\nto our home above the clouds.\n\nIn 1988, the ancient Egyptian and Gnostic belief that our origin and our\ndestiny reach far beyond Earth no longer seems as quaint and queer as it did\nin recent generations. In books like Dr. Timothy Leary’s Info-Psychology, Dr.\nFrancis Crick’s Cosmic Panspermia and Sir Fred Hoyle’s Evolution from Space,\nthere appears a body of evidence strongly suggesting that life did not begin\non this planet but arrived here from elsewhere in space.\n\nWhile the interpretations of these brilliant philosopher-scientists differ,\ntheir various kinds of evidence, from diverse fields of enquiry, do make a\nstrong case that evolution is older and more universal than we traditionally\nthink. One leaves their books suspecting that the orthodox biological view\nregarding Earthly evolution apart from Cosmic evolution results from unvoiced\npre-Copernican assumptions about Earth’s centrality and its isolation.\n\nIn addition to the sophisticated and learned works of Leary, Crick and Hoyle,\nwe have also recently witnessed the growth of a vast body of “vulgar,” or at\nleast popular, literature arguing the proposition that Ancient Astronauts\nseeded this planet, not with all life, but merely with (post-Neanderthal)\nhumanity. Instead of dissecting the flaws in the arguments of this seemingly\n“crank” literature, it might be more illuminating, I think, to wonder why this\npopular mythos provides the masses with an unsophisticated and anthropocentric\nform of the theories more soberly presented in works like Info-Psychology,\nCosmic Panspermia, and Evolution from Space.\n\nWhy do we find both first-rate and second-rate minds suddenly preoccupied with\nextraterrestrial evolution, while ninth-rate minds increasingly embrace Pop\nUFOlogy?\n\nAnd why, one may next wonder, does this theme also appear centrally in the\nmost beautiful, the most “haunting” and the most often-revived science-fiction\nfilm of all time — Kubrick’s magnificent 2001?\n\nWhen one Idea or Archetype appears in learned tomes, in tabloids, in folk-\nbelief, in new cults, and in great art, all at about the same time, one\nsuspects the presence of what Jung called, in his book Flying Saucers, “a\nshift in the constellation of the archetypes.”\n\nIn terms of current neuroscience, what Jung means, I think, we can now state\nthusly: the DNA/CNS “dialogue” — the neuropeptide “language” between genes and\ncells — is preparing us for a new evolutionary leap.\n\nIn The Dream Illuminati, the hero says bluntly:\n\n  \n\nI realized that l was only as free as I thought myself to be and that there\nwas no limit to how high we can fly!\n\n  \n\nHere we see again that the Archetype of flight carries always an umbilical\nconnection to the idea of the transcendence of all limits. (“What is believed\nto be true is true or becomes true . . .”)\n\nAnd we must wonder again if more than childish fantasy lurks in the concept of\nDonald Duck walking on air only until he “remembers” that this “is” officially\n“impossible” in our current reality-tunnel.\n\nIn 1904, when Einstein was starting to write his first paper on Relativity and\nthe Wright Brothers were testing the airplane design that finally worked after\nmany failures, Aleister Crowley, the most controversial mystic of our century,\n“received” — or created by Poetic Imagination — a document which he ever after\nclaimed was a communication from Higher Intelligence. In this work, called\nLiber Al or The Book of the Law, there is contained what purports to be a\nmessage from Nuit, the Egyptian star goddess, interpreted in Crowley’s\ncommentaries as the supreme consciousness of the cosmos, or the sum total of\nall synergetically interactive intelligences throughout space-time. Among\nother things, this “entity” — or corporation — told Crowley:\n\n  \n\nEvery man and every woman is a star . . .\n\nI am above you and in you. My ecstasy is in yours. My joy is\n\nto see your joy . . .\n\nFor I am divided for love’s sake, for the chance of union . . .\n\nPut on the wings, and arouse the coiled splendor within you:\n\ncome unto me!\n\n  \n\nMany interpretations of these verses are possible, of course. Of course.\n\nPersonally, after reading some of the current scientists who see evolution as\nboth terrestrial and extraterrestrial, I cannot look at the words of Liber Al\nwithout thinking that, in some sense, the interstellar creators who planted\nlife here may be sending us a signal to return to our home in the stars — that\n“great blue bedroom” which Joyce poetically invokes on the last page of\nFinnegans Wake and in which the astronaut, David Bowman, abruptly finds\nhimself at the climax of 2001.\n\nOf course, the language of poetic myth, like that of dream, should always be\nconsidered analogical and allegorical, not literal; to see only one meaning\nhere means that one will “fall into the pit of Because and perish with the\ndogs of Reason” (to cite Crowley again). The content of a true archetype\ncontains an “infinity” — or at least a heap big finity — of mirrors.\n\nFor instance, my Dream Diary for 23 April 1968 records that when I woke in the\nmorning I remembered the following images from my night’s hermetic journey:\n\n  \n\nI am in a Chicago nightclub once patronized by John Dillinger. I find that the\npresent patrons are also a group of gangsters. They regard me with hostility,\nand I become frightened. I try to leave; they try to stop me. I open a door.\n\nI find myself on the IRT subway in New York. I am riding in the front car,\nwatching the tunnel ahead of the train (as I did as a boy). Suddenly, I see a\nbrick wall ahead and realize the train is going to crash into it and kill\neverybody aboard, including me.\n\nI am out of the subway and walking in Cicero, Illinois. An angry mob surrounds\nme. They seem to know that I was in the recent Martin Luther King march\nagainst segregation here. I cannot escape them. Suddenly, I know intuitively\nwhat to do. I cry out, “Elohim! ” and sprout wings and fly above their heads.\nThe sky is beautiful and I feel free of all anxieties, at peace, unreasonably\nhopeful about everything.\n\n  \n\nWhen I awoke, I was thinking of Chesterton’s description of mystic experience\nas “absurd good news.”\n\nAt the time of this dream, I was involved with Chicago friends in propagating\nthe John Dillinger Died For You Society, a parody of Fundamentalist religions\nwhich, like all good jokes, had its serious side. I was fascinated by the way\nthat certain outlaws like Dillinger (or Jesse James, or Robin Hood) were\nvirtually forced to live to the full the archetypal myth of Osiris, Dionysus,\nAdonis, Christ and Dracula.\n\nI also meditated much on the way in which outlaws who did not even\napproximately “live” the myth subsequently had their lives rewritten in folk-\nimagination to conform to it. The first part of the dream-record confronts me\nwith the dark side of the archetype, and reminds me that real gangsters are\nnot the mythic figures imposed on them by Poetic Imagination but nasty and\nfrightening sociopaths.\n\nIn the second part of the dream, I enter into the Underground Initiation.\nAlthough using symbols from my own life (the subway), I find myself retracing\nthe steps of Ishtar in the land of the dead, Odysseus sailing to Hades for\nwisdom, Jesus and Dante descending to Hell, etc. In alchemy this was called\nnegrito, which Jung compares to the initial stages of psychotherapy.\n\nIn a sense, the Underworld Journey appears the reciprocal of, and preparation\nfor, the Achievement of Flight.\n\nDante had to walk through Hell before climbing Mount Purgatory and soaring\nabove the clouds to Heaven. In retrospect, I am especially delighted with the\nFreudian wit of the unconscious in using modern “Underworld” figures\n(gangsters) to represent the mythic Underworld.\n\nIn the third part of the dream, the traditional Wrathful Demons attack me,\npersonified by the citizens of Al Capone’s home town, Cicero, perhaps because\nthe people out there always reminded me of Wrathful Demons whenever I had to\nassociate with them. I escape by crying out a name from the Hebrew Bible,\nwhereupon I am able to fly, like Dante or Daedalus, from the Pit to the Stars.\n\nWhat I find most curious about these dream fragments is that, when I\nexperienced them in 1968, I knew nothing about Cabala. I was puzzled on\nawakening about the name Elohim and the way I magically used it in the dream.\nAll I knew about that name in those days was that it appears in the first\nchapter of Genesis and that there is a dispute between philologists and\ntheologians about whether it means “God” or “the gods” — i.e., whether the\nfirst chapter of the Bible is or isn’t a fragment left over from a\npolytheistic phase of Judaism.\n\nIt was over two years after this very Jungian dream that I became interested\nin Cabala and eventually learned that Elohim is therein considered a great\nName of Power — used in e.g., the Middle Pillar Ritual, which every Cabalist\nin training is expected to do at least once a day. The function of Cabalistic\nritual in general, and this ritual in particular, was once defined by Crowley\nas “to raise the mind of the student perpendicularly to Infinity” — beyond all\nlimits.\n\nThis is symbolized in my dream, as in many dreams and myths, by the imagery of\nflight and the conquest of gravity. The 1968 dream seems to contain\nprecognition of Cabalistic work I would be doing very seriously c. 1971-75.\n\nOf course, if one dares to suggest that a dream contains precognition, the\nRationalist immediately declares the connection between the dream image and\nlater waking events “is” “mere coincidence.” Those with a psychological block\nagainst recognizing electricity would probably say, similarly, that when you\nflick the switch and the light goes on that “is” also “mere coincidence.”\n\nAt the time I had this dream or set of dreams in 1968, I was suffering from a\nmoderately severe depression and the general symptoms of what we now call\n“mid-life crisis.” I had a very good job at Playboy magazine, with an\nexcellent salary for the 1960’s, but I was approaching 40 and wanted to write\nfull-time. (Three years later, after beginning Cabalistic work, I quit my job\nand have been writing full-time ever since. Although I have experienced the\nusual share of shocks, disappointments and bereavements, I have not suffered\nclinical depression again.)\n\nThe reader might find it illuminating to compare this record with a dream\nrecounted in Joseph Campbell’s The Hero With a Thousand Faces. In this case,\nthe dreamer saw a winged horse with one wing broken, struggling to fly and\nfalling continually back to Earth. Campbell does not even bother interpreting\nthis symbolism, merely informing us that the dreamer was a poet forced to work\nat a menial job to support his family; one understands immediately.\n\nIn a sense, we have all had our “wings” broken; it remains the major function\nof such “hallowed institutions” as organized religion and Free Compulsory\nEducation to see that our “wings” do get broken, or at least clipped, before\nwe reach adulthood. How else will society have the insectoid units it needs to\nfill the cubicles in its hive economy?\n\nBut what if we begin to regrow healthy organs of Poetic Imagination and\nflight? What if we “put on the wings and arouse the coiled splendor within” as\nLiber Al urges? Is it not predictable that society will react with the fury\ndescribed by Wayne Saalman in The Dream Illuminati? (Think of the careers of\nDr. Wilhelm Reich and Dr. Timothy Leary . . .) Joyce did not name his\nemblematic Artist merely Daedalus but Stephen Daedalus — after St. Stephen the\nProtomartyr, who reported a Vision and was stoned to death for it.\n\nAnd does it not appear ultimately beneficial, in evolutionary perspective,\nthat society should react in that manner? Those of us who have no avocation\nfor martyrdom must learn, when we realize how much neophobia remains built\ninto the contraptions of “society” and “the State,” the art of surviving in\nspite of them. In a word, we must “get wise” in both the Socratic meaning of\nthat phrase and in the most hardboiled street meaning.\n\nNeophobia functions as an Evolutionary Driver, forcing the neophiliac to get\nvery smart very fast.\n\nThis theme is inexhaustible, but my space and time are not. As a final bit of\nhermetic wisdom, I offer you Proposition 12 of Aleister Crowley’s masterwork,\nMagick:\n\n  \n\nMan is ignorant of the nature of his own being and powers. Even his idea of\nhis limitation is based on experience of the past, and every step in his\nprogress extends his empire. There is therefore no reason to assign\ntheoretical limits to what he may be, or to what he may do.\n\n\n#### Old Man On A Balcony:\n\n#### Views Of Monterey Bay #10\n\n  \n\nTWO FOR BISHOP BERKELEY\n\n  \n\nClouds (visible) float\n\n  \n\nabove hills (invisible);\n\n  \n\nAre the hills still there?\n\n  \n\nAt this hour of night\n\n  \n\nI see more “dolphins” than at\n\n  \n\nAny other time.\n\n  \n\nTHOUGHTS TO PONDER\n\n  \n\nWe have found a strange foot-print on the shores of the unknown. We have\ndevised profound theories, one after another, to account for its origin. At\nlast, we have succeeded in reconstructing the creature that made the\nfootprint. And Lo! It is our own!\n\n  \n\n— Sir Arthur Eddington\n\n\n#### God's Morals\n\n  \n\nWhat amateurs we all are compared to Him.\n\n  \n\n— Hannibal Lecter, MD.\n\n  \n\nI saw the hon. rev. Jerry Falwell on CNN this morning and found him as amusing\nas ever. According to rev. Falwell, his god joined Al Qaeda — or at least\naided and conspired with them — on 9/11, because the World Trade Center and\nPentagon employed large numbers of Gays and persons affiliated with the\nAmerican Civil Liberties Union.\n\nThis confirmed my low opinion of the morals (and intelligence) of Falwell’s\ngod. After all, even by Falwell’s standards, many “innocent” people — folks\nwho are neither Gay nor associated in any way with the ACLU — also died in\nthat atrocity.\n\nBut I wonder: Does anybody have any statistics on how many Gays and civil\nlibertarians worked at those places compared to the national average? Was it a\ncondition of employment at either venue to be Gay or liberty-oriented?\n\nOr has the rev. merely invented a sparkling new defense for shooting Gays and\nconstitutionalists — “I only wanted to prevent more terrorist attacks”?\n\n  \n\nTHOUGHTS TO PONDER\n\n  \n\nAnd the sun high over horizon hidden in cloud bank\n\nlit saffron the88\n\ncloud ridge\n\ndove sta memora\n\n  \n\n— Ezra Pound, Canto 76\n\n  \n\nA-Gnosis\n\n  \n\nWhenever you stop and reflect, “Maybe I just think or act that way because I’m\na Cosmic Schmuck,” you become — for a moment — a bit less of a Cosmic Schmuck.\n\nThe more often you have such suspicions, the less of a Cosmic Schmuck you will\nbecome. Continue relentlessly and you will make yourself ineligible for\npolitical office. Tsarists will call you a flip-flopper.\n\nOn the other hoof, if you NEVER suspect that you might think or act like a\nCosmic Schmuck, you will remain a Cosmic Schmuck forever. Continue on that\npath and you will accumulate so much power that nobody will dare tell you how\nenormous a Cosmic Schmuck you have become. You might even end your days in the\nOval Office.\n\nOr that’s what I suspect.\n\n\n#### Old Man On A Balcony:\n\n#### Views Of Monterey Bay #11\n\n  \n\nThe cat licks its paws:\n\n  \n\nI watch, three floors above: it\n\n  \n\nLooks up straight at me\n\n  \n\nTHOUGHTS TO PONDER\n\n  \n\nWe have certain preconceived ideas about location in space and time which have\ncome down to us from ape — like ancestors.\n\n  \n\n— Sir Arthur Eddington\n\n  \n\ndove sta memora\n\n  \n\nYou have not snared her,\n\nScarecrow Death:\n\nShe’s in my pulse,\n\nMy heart, my breath.\n\n  \n\nEye sees only\n\nLocal hardware;\n\nBrain conceives\n\nNonlocal software;\n\n  \n\nBrain knows more\n\nThan eye can see:\n\nBrain can scan\n\nEternity.\n\n\nPart II\n\n\n### ADVANCED HEAD TRIPS\n\n  \n\nWilson describes himself as a “guerrilla ontologist,” signifying his intent to\nattack language and knowledge the way terrorists attack their targets: to jump\nout from the shadows for an unprovoked attack, then slink back and hide behind\na hearty belly-laugh.”\n\n  \n\n— Robert Sheaffer, Skeptical Inquirer, Summer 1990\n\n  \n\n[Wilson “is”] a male feminist...a simpering pussy-whipped wimp.\n\n  \n\n— Lou Rollins, Lucifer’s Lexicon\n\n\n#### Joyce & Daoism\n\n  \n\nI wrote this sometime in 1958, and it appeared in the James Joyce Review the\nfollowing summer...which surprises me because I didn’t try LSD until 1962 . .\n. Sure sounds like an Acid Head wrote it, doesn’t it?\n\nMaybe I never needed all that acid after all. With James Joyce and Lao-Dzu as\nguides I might have ended up among the Terminally Bewildered anyway.\n\nBy the way, I learned the standard pre-Mao spellings of Chinese words about 40\nyear ago. In this book I attempt to use the current post-Mao spellings. Any\nblunders result from the clumsiness of an old dog trying to learn new tricks.\n\n  \n\nTo Whatever Abysses\n\n  \n\nThroughout the long day of Ulysses, the thoughts of Stephen Dedalus and Mr.\nBloom repeatedly return to the East; and this is not without reason. Ulysses\nis so profoundly Oriental in mood and conception that Carl Jung has\nrecommended it as a new Bible for the white race. Molly Bloom’s fervent “Yes”\nmirrors the author’s acceptance of life in its entirety — an acceptance that\ntranscends the dualisms of light and dark, good and evil, beautiful and\nsordid.\n\nBut every sensitive reader of Ulysses knows that this “acceptance” involved\nonly part of the author’s sensibility. The agony, the misanthropy, the (at\ntimes) Swiftian satire, all testify to Joyce’s incomplete realization of what\nhis instincts were trying to tell him. Only in Finnegans Wake does the true\nOriental note sing uninterruptedly from beginning to end. The morbid rebel\nagainst the most morbid Church in Christendom had to go the long way round to\nreach the shortest way home. The affirmation of Ulysses seems forced (not\n“insincere” any more than the neurotic’s desire to be cured is “insincere\");\nthe affirmation of the Wake engages every level of the author’s sensibility,\nfrom cortex to cojones — the whole man affirms, as in Nietzsche’s Zarathustra.\n\nThe purpose of this present brief essay is to show that the Chinese philosophy\nof the Dao contributed largely to the shape of Joyce’s affirmation. “Laotsey\ntaotsey” (p. 242) or Lao-Dzu’s doctrine of the Dao, explains a great many\nthings about Finnegans Wake: the river-woman symbol, the Shem-Shaun dualism,\nthe special quality of Joyce’s humor, the “process” philosophy underlying its\nform.\n\nChapter 6 of the Dao De Jing says:\n\n  \n\nValley spirit never dies\n\nI call it Eternal Female.\n\n  \n\nSome Sinologists trace this “Eternal Female” back to a Chinese “Urmutter” myth\nof pre-Chou times, but Lao-Dzu was far beyond primitive mythology. He was\nusing this myth as a pointer, to indicate the values that must have been in\nthe society which created the myth. The distinction between Patrist and\nMatrist cultures made in such books as Ian Suttie’s The Origins of Love and\nHate and G. Rattray Taylor’s Sex in History (not to mention Robert Graves’ The\nWhite Goddess and Dr. Reich’s The Mass Psychology of Fascism) places the\nTaoists as representatives of a Matrist social-ethical system living in\nConfucian Patrist China. The “Golden Age” of the Taoists did actually exist,\nwhether or not it deserves to be called Golden: it was the Matriarchal, pre-\nFeudal China destroyed by the Chou State and official Confucian philosophy.\nChapter 28 of the Dao De Jing defines the psychology and ethics of Daoism:\n\n  \n\nHe who knows the male, yet clings to the female,\n\nBecomes like a valley, receiving all things under heaven.\n\n  \n\nThe “female” qualities of receptivity, acceptance, passivity, etc. are\npreferred to the “masculine” ethical rigor of Confucianism. Kuan Dzu explains\nthis in its simplest terms:\n\n  \n\nThe sage follows after things, therefore he can control them.\n\n  \n\nEvery married man knows how typically feminine — and how effective — this is.\nWhat is not so obvious is that this is, really, the philosophy of modern\nscience. Bacon says: “We cannot command nature except by obeying her.” (Cf.\nthe Marxian “freedom as the recognition of necessity.”) A letter by — of all\npeople — Thomas Henry Huxley drives home the point, showing the innate\nconnection between religious humility and scientific method.\n\n  \n\nScience seems to me to teach in the highest and strongest manner the great\ntruth which is embodied in the Christian conception of entire surrender to the\nwill of God. Sit down before fact as a little child, be prepared to give up\nevery preconceived notion, follow humbly wherever and to whatever abysses\nNature leads, or you shall learn nothing.\n\n  \n\nThe Daoists saw this attitude represented most clearly by women and by water,\nand made these the chief symbols of their religion. Orthodox Christians can\nunderstand why this approach is valuable to the scientist, but that it is the\nhighest form of religion also, is certainly difficult for anyone conditioned\nto dogmatisms to accept. The Daoists put “open acceptance” where the West puts\n“dogmatic faith.”\n\nThe female also stands, in Daoist thought, for those two forces regarded with\nmost suspicion in Patrist societies: sex and love. The orthodox Freudians have\nsaid enough to familiarize us all with the neurotic illness that has come into\nWestern culture with the triumph of anti-sex religions; what is not so obvious\nis how love, also, is under a pall in our society — see the chapter on “The\nTaboo on Tenderness” in Ian Suttie’s The Origins of Love and Hate.*\n\n  \n\n~•~\n\n* To date (2004), porn movies have explored every aspect of human sexuality except tenderness.\n\n~•~\n\n  \n\nWater is, as we have said, the second great symbol of Daoism. It is, of\ncourse, the receptivity and yieldingness of water that recommends it to Lao-\nDzu and Juang Jou. The philosophy of Judo (a Taoist invention) has come out of\nthe observation of water, it is said. Judo co-operates with the attacking\nforce, as water molds itself to its environment. Water and the Judo student\nbend and survive where bamboo and the ordinary man stand firm and break.\n\nThe values that Daoism sees in woman and water are their harmony with the Dao.\nI have not translated this key term, and I do not intend to; but Ezra Pound’s\ntranslation — “the process” — seems to me more adequate than “the Way,” “the\nPath” and most of the other attempts.*\n\n  \n\n~•~\n\n* Daniel Coyle, Ph.D. has told me that “process” might fit the ideogram even better than “the process.” I suspect “processing” would work in some contexts.\n\n~•~\n\nStudents of General Semantics might understand if I say that the “Dao” comes\nvery close to meaning what they mean when they say “the process-world.” The\nDao is the flux, the constant change, amid which we live and in the nature of\nwhich we partake; or it is the “law” of this change. (But, of course, the\n“law” and the “change” itself are not different in reality, only in our\ngrammar and philosophy.)\n\nA Zen master, asked how to get in harmony with the Dao, replied, “Walk on!”\n\nWater and woman represent adjustment to the Law of Change, which “man, proud\nman, dressed in his little brief authority,” and his abstract dogmas, tries to\nresist.\n\nAnna Livia Plurabelle (ALP), the water woman, represents the values of the Dao\nin Finnegans Wake. The very first word of the book, “riverrun” — not the river\nand the running of the river, but “riverrun” — places us firmly in the\n“process-world” of modern physics, which is the world of the Dao. As Molly\nBloom does in Ulysses, Anna gets the last word in Finnegans Wake, and it is a\nword that transcends the dualisms (Bloom and Stephen, Shem and Shaun, Mookse\nand Gripes) and affirms the unity behind them.\n\nThe parable of the Mookse and the Gripes expresses this characteristic Daoist\nattitude with a quite characteristic Daoist humorous exaggeration. Adrian, the\nPapal Mookse, takes his stand on space, dogma and Aristotelian logic; the\nmystic Gripes verbally affirms time, relativity and the flux; but both are\nequally enmeshed in abstractions and both wither away in futile opposition to\neach other. Both, in short, are captives of the dualistic System they have\nthemselves created. Nuvoletta, the avatar of ALP in this episode, is the\nDaoist female, unimpressed by the “dogmad”, behaviour of the male. With Molly\nBloom’s resignation, she says:\n\n  \n\nI see. . .there are menner.\n\n  \n\nIt is important to grasp the distinction between the Gripes and Nuvoletta.\nSeemingly, they represent affirmation of the same cluster of things: time, the\nriver, flux, mysticism, relativity, sex, love, the earth, Nature.\n\nActually, the Gripes’ affirmation is verbal only, whereas Nuvoletta’s\naffirmation is anything but verbal. None of Joyce’s great Earth-Mother figures\nare given to philosophizing about “affirmation of Nature,” etc. — they just do\nit. This is a crucial difference. As Lao-Dzu says:\n\n  \n\nThose who speak do not know;\n\nThose who know do not speak.\n\n  \n\nShem is a “sham and a low sham” because he is a “forger.” Stephen Dedalus\nwanted to “forge in the smithy of my soul the uncreated conscience of my\nrace”; but Shem merely seeks “to utter an epochal forged cheque on the\npublic.” Shem is one of those who speak but do not know; that his career is a\nsatire on Joyce’s own is the kind of irony implied in Christ’s “Why callest\nthou me good? None is good but the Father,” or the Sixth Patriarch’s “I do not\nunderstand Buddhism.” Probably everyone who ever gains any experience with the\nDao begins by faking a little; it is really so much easier to verbalize about\nthis affirmation than to live it. Joyce’s portrait of the artist as a young\nforger is a self-confession that does penance for the whole race: “you and I\nare in him.”\n\nALP, the river-woman, does not have any such confession to make. Like the hen\nBelinda in Chapter Four, who “just feels she was kind of born to lay and love\neggs” (p. 112), ALP lives in the Dao without question and without making a\nfuss about it (wu-shih). Her polar opposite is that figure whom Joyce\ndescribes as “Delude of Israel,” “Gun, the Farther,” or “Swiney Tod, ye Demon\nBarber” — the “phallic-destructive” Hangman God whose “criminal thumbprint” on\nthe rock hangs over Ulysses and makes one realize that Molly Bloom’s\naffirmation was something Joyce had not yet quite experienced when he wrote\nthat saturnine masterpiece. In Finnegans Wake the Hangman God is securely put\nin his place, and from the first word, “riverrun,” to the last dying murmur “a\nway a lone a last a loved a long the,” the female figure of affirmation\ndominates the book.\n\n  \n\nSuch Me\n\n  \n\nPutting the Hangman God in his places does not mean abolishing him; it means\ntranscending him, in sweat and blood, rising above the dualistic delusion that\nmakes Him seem credible. Nietzsche’s “I write in blood, I will be read in\nblood,” is testimony as to the superhuman effort required for an Occidental to\nmake this transcendence.\n\nEarwicker, as typical a product of Western dualism in its advanced stages as\nwas Melville’s Ahab, is, like Ahab, split down the middle by his own dualistic\nthinking. Joyce does not symbolize this as Melville did — by the scar from\ncrown to toe that disfigures Ahab — but by projecting the two sides of\nEarwicker as Shem and Shaun, the Mookse and the Gripes, Mutt and Jute, Mercius\nand Justius, Glugg and Chuff, Muta and Juva, Butt and Taff, the Ondt and the\nGracehoper. The Daoist orientation of Joyce’s treatment of these dualities is\nindicated, on page 246, by the distortion of “Shem and Shaun” to “Yem and\nYan.”\n\nYin and Yang are the Taoist terms for the paired opposites whose innate\nconnectedness generates the entire world — process. Yin is feminine, dark,\nintuitive, etc.; Yang is masculine, light, rationalistic, etc. Neither can\nexist without the other, and both are parts of the Dao, and hence parts of\neach other.\n\nThe identity of the opposites, a central theme of Daoist thought, is indicated\nearly in Finnegans Wake. The very first appearance of Shem and Shaun is as\n“the Hindoo, Shimar Shin,” (p. 10) a single figure. Through the rest of the\nbook they are split into two figures, but they are constantly changing roles\nand merging into each other (For instance, in the “School Lesson” chapter,\nwhere the Shem-type notes, left side of the page, leap suddenly to the right\nside, and the Shaun-type notes leap from right to left ) Again, in the Mercius\nand Justius dispute, Shem and Shaun are picked up at the end and carried off\ntogether by ALP. “Sonnies had a scrap,” she says with feminine equanimity.\n\nThe two philosophers most frequently mentioned in the Wake, Nicholas of Cusa\nand Bruno of Nola, taught a dialectic of resolution of opposites. Joseph\nNeedham, in his monumental Science and Civilization in China, repeatedly\nmentions both Bruno and Nicholas as the only two Occidental philosophers\nbefore Liebnitz to have a basically Daoist outlook.\n\nEvery sensitive reader has noted the difference between the humor of Ulysses\nand the humor of Finnegans Wake. In writing Ulysses, Joyce’s intention seems\nto have still contained a large element of the motive expressed to his\npublisher when describing Dubliners: “to show Ireland its own ugly face in a\nmirror.” The humor in Ulysses is mostly satiric and negative, Swiftian; the\njoyous, Rabelaisian element is comparatively small. But in Finnegans Wake the\nhumor is not only Rabelaisian, but Carrollian: it has that element of nonsense\nand childishness which only the well-integrated can sustain for long.\n\nBut this humor is also Daoistic. It is now suspected by scholars that the\nchapter of the Confucian “Analects” (Lun Yu) which contains a description of\nthe Daoists as a band of madmen was interpolated by a Daoist writer! The\nrudely cheerful, very unselfconscious parody of Joyce himself in the “Shem the\nPenman” chapter has the same type of humor. Probably only an Irishman could\nunderstand that text about making oneself a fool for Christ’s sake as a Daoist\nwould understand it. Joyce, bending his incredible genius to the concoction of\nplace names like “Wazwollenzie Haven”* and “Havva-ban-Annah” (not to mention\n“the bridge called Tilt-Ass”) is exemplifying something that exists outside\nthe Wake only in Lewis Carroll, Edward Lear and the Sacred Scriptures of the\nDaoists.\n\n  \n\n~•~\n\n* German “Was wollen sie haben?” — What do you want?\n\n~•~\n\n  \n\n(“The Dao is in the dung-heap,” said Juang Jou.)\n\nTo the Daoists, humor was what paradox is to Chesterton: a manifestation of\ndivinity. Dao fa tsu-ran “The process just happens.” (The entire passage\nreads:\n\n  \n\nRen fa di,\n\ndi fa tien,\n\ntien fa Dao,\n\nDao fa tzu-ran.\n\n  \n\n“Man molded by earth, earth molded by universe, universe molded by process,\nprocess just happens.” Or — “process organizes itself”) In short, determinism\non one level results from chance on another level, as in thermodynamics.\n\nWhether you call this Organicism and wax as self-consciously profound as\nWhitehead, or call it Materialism and get as self-righteously priggish as the\nAmerican Association for the Advancement of Atheism, you still miss the point.\nThat the Dao just happens, that it has no purpose or goal, no regard for man’s\nself-importance (“Heaven treats us like straw dogs,” Lao-Dzu says) — this is\nnot a gloomy philosophy at all. When one understands this fully, on all levels\nof one’s being, the only possible response is to have a good laugh. Daoist\nhumor results from realization that the recognition of the most joyous truth\nof all seems to the egocentric man (you and me) frightening and gloomy.\n\nJoyce is nowhere more thoroughly Daoist than when he answers all the paradoxes\nand tragedies of life with the brief, koan-ish “Such me.” Genial bewilderment\n(“Search me!”) and calm acceptance (“Such I am”) meet here as they meet\nnowhere else but in Daoism, and its intellectual heirs, Zen and Shinshu\nBuddhism and the neo-Confucianism of Chu Hsi. We cannot understand; neither\ncan we escape — “Such me.” (p. 597)\n\nIt is this attitude — which women seem to be able to grasp much more easily\nthan men — that gives Finnegans Wake its air of goofy impartiality. The\nBuddhist (outside of the Zen school) labors strenuously to rise over the\nopposites; the Daoist dissolves them into a good horse-laugh. Joyce’s method\nis Daoistic.\n\n“Sonnies had a scrap;” “Now a muss was the little face;” “You were only\ndreamond, dear” — the tolerant, existentialist female voice, vastly\nunimpressed by masculine abstractions and ideologies, breaks in at every point\nwhere a Big Question is being debated. The Zen Patriarch who said, when he was\nasked for religious instruction, “When you finish your meal, wash your\nplates,” had this attitude.\n\n  \n\nThe Keys To\n\n  \n\nWyndham Lewis saw in Ulysses an implicit acceptance of Bergson’s time-\nphilosophy and denounced Joyce, in his Time and Western Man, for contributing\nto what he called “the Time Cult” (other members: Einstein, Ezra Pound,\nPicasso, Whitehead, the Futurist painters, Gertrude Stein). Lewis, a\nclassicist, set up the dualism of space philosophies (Aristotelian, rational,\nconservative, masculine, etc.) against time philosophies (oriental, intuitive,\nradical, feminine, etc.) Joyce wrote the Wake from “the Haunted Inkbottle, no\nnumber, Brimstone Walk, Asia in Ireland” (p. 182) placidly, even eagerly,\naccepting the non-Aristotelian position Lewis had attributed to him.\n\nAs is well known, the events of the Wake occur “at no spatial time” and cannot\nbe sharply defined because “every parson, place and thing in the chaosmos\nanywhere at all connected with it was moving and changing all the time” (p.\n118). In short, we are within the Einsteinian universe; and Joyce realizes, as\ndid Alfred Korzybski, that the Aristotelian “laws of thought” cannot hold in\nsuch a universe: “The sword of certainty which would identified the body never\nfalls” (p. 51). The Law of Identity, that is, cannot hold in a process-world\n“where,” as the mathematical physicist says, “every electron has a date and is\nnot identical to itself from one second to another.”\n\nThe Daoists were familiar with these relativistic considerations long before\nEinstein.\n\nJuang Jou writes:\n\n  \n\nThere is nothing under the canopy of heaven greater than the tip of an autumn\nspikelet. A vast mountain is a small thing. Neither is there any age greater\nthan that of a small child cut off in infancy. Bung Tzu* himself died young.\nThe universe and I came into being together; and I, and everything therein,\nare one.\n\n  \n\n~•~\n\n* Chinese isomorph of Methuselah.\n\n~•~\n\n  \n\nA better description anywhere of the “inner logic” of Finnegans Wake can\nhardly be found. To ask what “is really happening” on any page is like asking\na physicist whether light “is really” waves or particles. Jaun's sermon to the\nleap-year girls “is” a confession of Earwicker’s incestuous desires; “is” a\nbarrel rolling down the Liffey river; “is” a postman making his rounds; “is”\nJesus saying farewell to the Daughters of Jerusalem; etc . . . Anna Livia\nPlurabelle “is” a woman, and she \"is\" also a river. Earwicker “is” a man, a\nmountain, an insect, the current Pope, the Urvater of Freudian theory, Finn\nMacCool, and he is also both Shem and Shaun. He is, as a matter of fact, every\nperson, place and thing in the Wake — just as every man “is” the sum total of\nhis own perceptions and evaluations. Earwicker is finally able to accept and\naffirm his world, Joyce is finally able to accept and affirm his world,\nbecause they recognize that “I, and everything therein, are one.” “Such me.”\n\nPhysics, psychology, semantics and several other sciences have entirely\nrejected the view which sees the universe as a collection of block-like\nentities.\n\nWe now think in terms of relations and functions: iron rod A has no absolute\n“length,” but only length1, length2, length3, etc., as it moves through the\nspace-time continuum. Smithn has no absolute “self” but only a succession of\nroles in a succession of socio-psychological fields. A world of such inter-\nrelated processes is a seamless unity, and every perceiver “is” that unity at\nevery second. That is why Emerson could write — and Joyce could demonstrate —\nthat “The sphinx must solve his own riddle. All of history is in one man.”\n\nTo the space-consciousness of a Wyndham Lewis, a chair is a static “thing” out\nthere, apart from the observer; given, concrete, identifiable. To the time-\nmind of Joyce, the chair becomes a process, a joint phenomenon of observer and\nobserved, a stage in the transmutation of energy: “My cold cher’s gone\nashley,” he writes, (p. 213) seeing the future ashes in the present object.\n(Cf. Hiu Shih’s paradox, “An egg has feathers”)\n\nZen Buddhist teachers make this point, somewhat obliquely, by pointing to a\npicture of Bodhidharma (who was bearded), and asking the puzzled student, “Why\ndoesn’t that fellow have a beard?”\n\nThe answer of the witty Gracehoper to the conservative Ondt (p. 419):\n\n  \n\nYour genus is worldwide, your spacest sublime,\n\nBut Holy Saltmartin, why can’t you beat time?\n\n  \n\nis Joyce’s answer to Wyndham Lewis and the entire Western Tradition back to\nAristotle which backs him up.\n\nThe Gracehoper had “jingled through a jungle of life in debts and jumbled\nthrough a jingle of love in doubts” but, as the rhythm and vocabulary suggest,\nhe had vastly enjoyed himself doing so. Time, which strikes him down, will\neventually strike down the “anal-acquisitive” Ondt also. All the abstractions\nman invents to give himself control over events and stave off doubt, all the\npreparations man makes to stay out of debt, are as nothing before the\ninscrutable workings-out of the Dao; the search for security, Alan Watts has\nfrequently observed, is the main cause of insecurity. As Nuvoletta says, “Ise\nso silly to be flowing, but I no canna stay” (p. 159). The “secret” of Daoism,\nthe secret of Finnegans Wake, is very simply expressed in Poe’s “Descent Into\nthe Maelstrom,” whose hero saved himself by “studying the action of the\nwhirlpool and co-operating with it.”\n\nThis is the trick that explains Judo. It also explains Anna Livia Plurabelle’s\ncalm acceptance of her own end as she flows out to sea:\n\n  \n\nThe keys to. Given. Lps. A way a lone a last a loved a long the\n\n  \n\nThe only word that can possibly complete that sentence is the “riverrun” at\nthe beginning. We can find ourselves only by losing ourselves, all mystics\ntestify. Anna loses herself into the ocean, but what she becomes is the true\nself she has always been: “riverrun,” the process.\n\n  \n\nTHOUGHTS TO PONDER\n\n  \n\nIn short, philosophers, ancient and modern, appear to me as mad as Hindoos,\nMahomatons and Christians.\n\n  \n\n— John Adams to Thomas Jefferson, 16 July 1814\n\n\n#### Movie Haiku\n\n  \n\nFor a while there [circa 1999 — 2001] I got into writing haiku about all the\nmovies I really liked. Here’s some I decided to preserve.\n\n  \n\nHANNIBAL\n\n  \n\nLecter, too, grows old\n\n  \n\nBut remains quite amusing,\n\n  \n\nQuite terrifying\n\n  \n\nTEQUILA SUNRISE\n\n  \n\nA major coke deal—\n\n  \n\nTreachery in sun-bright places—\n\n  \n\nOne friendship survives\n\n  \n\nKING KONG\n\n  \n\nCan’t blame the big ape:\n\n  \n\nI, too, went a bit goofy\n\n  \n\nOver Fay Wray once\n\n  \n\nHONKY TONK MAN\n\n  \n\nAddictions killed him,\n\n  \n\nToo much booze and cigarettes.\n\n  \n\nThey still sing his songs.\n\n  \n\nAND THEN THERE WERE NONE\n\n  \n\nUnpleasantness and\n\n  \n\nRash Actions: Even servants\n\n  \n\nGet drunk and murdered.\n\n  \n\nWHITE HUNTER, BLACK HEART\n\n  \n\nArlen said it best:\n\n  \n\n“He had a good heart, really—\n\n  \n\njust too much Ego.”\n\n  \n\nON A CLEAR DAY YOU CAN SEE FOREVER\n\n  \n\n“Witchcraft” not spoken\n\n  \n\nBut still the best film ever\n\n  \n\nAbout Wise Women\n\n  \n\nUNFORGIVEN\n\n  \n\nDrunk sociopath\n\n  \n\nKills “guilty” and “innocent.”\n\n  \n\nSeemed like Justice, then.\n\n  \n\nLADY FROM SHANGHAI\n\n  \n\nA yacht called Circe:\n\n  \n\nTrial: Chinese drama:\n\n  \n\nCrazy house: Hall of mirrors:\n\n  \n\nSTARDUST MEMORIES\n\n  \n\nWoody’s rage breaks loose:\n\n  \n\nA comedy of terrors.\n\n  \n\nThe girl goes nuts, too.\n\n  \n\nMIDNIGHT IN THE GARDEN OF GOOD AND EVIL\n\n  \n\nCourtrooms and Voodoo\n\n  \n\nBoth leave us undecided—\n\n  \n\n“There ain’t no answers!”\n\n  \n\nINTOLERANCE\n\n  \n\nThose who would do good\n\n  \n\nOften do the worst evil—\n\n  \n\nIf they have True Faith . . .\n\n  \n\nBIRD\n\n  \n\nDid the junk ruin him\n\n  \n\nOr was it Whitey’s racism?\n\n  \n\nDon’t know. Bird is dead.\n\n  \n\nTHE OUTLAW JOSEY WALES\n\n  \n\nThe killing must stop—\n\n  \n\nAnd, guess what? this time it does:\n\n  \n\nNo final shoot-out.\n\n  \n\nTHE GHOST AND THE DARKNESS\n\n  \n\nThe whites see lions—\n\n  \n\nThe blacks see devils from Hell—\n\n  \n\nYou’ll wonder a bit . . .\n\n  \n\nTHE MALTESE FALCON\n\n  \n\nSeventeen long years\n\n  \n\nAnd God-knows-how-many murders\n\n  \n\nChasing a lead dream\n\n  \n\nBUS STOP\n\n  \n\nYou can’t discount it.\n\n  \n\nYou can’t forget it. It has\n\n  \n\nM*a*r*i*l*y*n M*o*n*r*o*e.\n\n  \n\nCHIMES AT MIDNIGHT\n\n  \n\nWinter: Wind, snow, chill:\n\n  \n\nMerrie England's dead and gone.\n\n  \n\nFalstaff, too, must die.\n\n  \n\nTHE EIGER SANCTION\n\n  \n\nThree times the Eiger\n\n  \n\nTried to kill him: And he looked\n\n  \n\nInto the abyss.\n\n  \n\nTHOUGHTS TO PONDER\n\n  \n\nI don’t think anybody ever really matures. Adults are just children who owe\nmoney.\n\n  \n\n— Kenneth Branagh\n\n\nHe Who Thunders From On High\n\n\nTheotopology & Theometeorology\n\n  \n\nI’ve recently noticed “as if for the first time” that when people pray they\nalways look “upward” — i.e., perpendicular to whatever place they’re standing\n— or kneeling or groveling. I deduce that they conceive of their “god” as\ntopologically isomorphic to a huge donut, about a thousand miles wider than\nEarth.*\n\n  \n\n~•~\n\n* Or maybe they still think of the Earth as flat?\n\n~•~\n\n  \n\n(Of course, if people ever pray at the north or south poles, this would have\nto change; then “god” would become isomorphic to a hollow sphere.)\n\nWhen I raised this issue in a blog recently, Paul Krassner asked “Does this\nmean that the pledge of allegiance should be changed to ‘one nation inside\ngod’?”\n\nNot necessarily. Although the Bible and Koran always speak of their god as\n“above,” Christians, Jews and Moslems can either accept what their rituals\nimply — a donut god — or return to a flat Earth . . .\n\nGiambattista Vico, “the father of sociology,” suggested in The New Science\nthat Thunder historically underlies the “god” idea; the Noisy Thing roaring in\nthe sky, seemingly in rage, had to be appeased.\n\nSometimes lightning came from that roaring monster, and sometimes lightning\nkilled somebody.\n\nHence Zeus bronnton (Zeus the thunderer)*; Jupiter, another thunder god; Thor,\nDonner, whose very name means thunder; etc . . . and Yahweh . . . and Allah .\n. .\n\n  \n\n~•~\n\n* Zeus, to Arlen, sounded like rain, and bronnton like thunder...\n\n~•~\n\n  \n\nJoyce uses this god = thunder equation repeatedly in Finnegans Wake (which\ndrove me to read Vico . . .).\n\nI have also observed that thunder on the sound-track — signaling on-coming\ntragedy or horror — appears in films as diverse as those of Orson Welles,\nJames Whale, Howard Hawks, Wes Craven, Monty Python, etc., etc . . . Listen\nfor it and note how bloody often it pops up...especially in thrillers . . .\n\nThe monotheistic idea implies a cruel and grumpy old electric donut\nsurrounding Earth and ever threatening it.\n\nI think this explains the “structural unconscious” or inarticulate\nneurosemantics of Bozo, Ariel Sharon and Osama bin Laden equally. They’re all\nheaping up human sacrifices, as at Stonehenge, to Him Who Thunders From On\nHigh.\n\n  \n\nTHOUGHTS TO PONDER\n\n  \n\nThe sum total of all minds is one.\n\n  \n\n— Erwin Schrödinger\n\n  \n\nGet Your New York Garbage Online\n\n  \n\nhttp://www.nycgarbage.com\n\nThis guy sells beautifully boxed New York City garbage online.\n\nI just saw him on CNN; he sez he started this er um enterprise to prove that\nAmericans will buy fookin’ ANYthing if it comes in an attractive package.\n\nHe also sez he’s sold 500 boxes so far. I wonder how many got remailed to Bozo\n@ the White House?\n\n\n#### Becoming What We “Are”\n\n  \n\nIf you stroll through a large art museum, you will notice that Van Gogh does\nnot paint the same world as Rembrandt, Picasso does not see things the way\nGoya did, Georgia O’Keefe doesn’t much resemble Rivera, Salvador Dali looks\nlike nobody but himself, and, in general, no world-class artist became a\n“classic” by doing what somebody else had already done or even what everybody\nelse in his/her own era did.\n\nAnd in science, the names of Einstein, Dirac, the Curies, Bohr, Heisenberg,\nSchrödinger, John Bell, etc. live on because none of them took Newton as Holy\nGospel: they all made unique and unpredictable innovations in basic theory.\n\nAnd, in case you think this applies only to “arts and sciences,” consider the\nmost successful people in industry. Henry Ford did not get rich copying\nFulton’s steamboat; he made a car so cheap that anybody could afford one.\nHoward Hughes produced movies that nobody else would have dared to attempt,\nand then went on to revolutionize the airline industry. Buckminster Fuller did\nnot copy the cubical form of previous architects, but invented the geodesic\ndome; at last count, over 300,000 of his buildings existed, making him the\nmost visibly successful architect in history. Steve Wozniak did not copy the\ncomputers of his day, but invented one that even a “bloody eejit” (like me)\ncould use (and even enjoy!) Bill Gates created new kinds of software. Etc.\n\nWe all need constant reiteration of these truisms because we live in a world\nwhere a multitude of very powerful forces have worked upon us, from birth\nthrough school to jobs, attempting to suppress our individuality, our\ncreativity and, above all, our curiosity — in short, to destroy everything\nthat encourages us to think for ourselves.\n\nOur parents wanted us to act like the other darling children in our\nneighborhood; they emphatically did not want a boy or girl who seemed “weird”\nor “different” or (Heaven forfend) “too damned clever by far.”\n\nThen we enter grade school, a fate worse than Death and Hell combined. Whether\nwe land in a public school or a private religious school, we learn two basic\nlessons: [1] There exists one correct answer for every question; and [2]\neducation consists of memorizing the one correct answer and regurgitating it\non an “examination.”\n\nThe same tactics continue through high school and, except in a few sciences,\neven to the university.\n\nAll through this “education” we find ourselves bombarded by organized\nreligion. Most religions, in this part of the world also teach us “one correct\nanswer,” which we should accept with blind faith; worse, they attempt to\nterrorize us with threats of post-mortem roasting, toasting, boiling,\nbroiling, charbroiling and freedomfrying if we ever dare to think at all, at\nall.\n\nAfter 18 to 30+ years of all this, we enter the job market, and learn to\nbecome, or try to become, almost deaf, dumb and blind. We must always tell our\n“superiors” what they want to hear, what suits their prejudices and/or their\nwishful fantasies. If we notice something they don’t want to know about, we\nlearn to keep our mouths shut. If we don’t—\n\n“One more word, Bumstead, and I’ll fire you!”\n\nAs my mahatmaguru J .R. “Bob” Dobbs says, “You know how dumb the average guy\nis? Well, mathematically, by definition, half of them are even dumber than\nthat.”\n\n“Bob” may have the average confused with the median, but otherwise he hit a\nbull’s eye. Half of the people you meet do indeed seem dumber than a box of\nturds; but they did not start out that way. Parents, peers, schools, churches,\nadvertisers and jobs made them that way. Every baby at birth has a\nrelentlessly curious and experimental temperament. It takes the first third of\nour lives to destroy that curiosity and experimentalism; but in most cases, we\nbecome placid parts of a docile herd.\n\nThis human herd all started out as potential geniuses, before the tacit\nconspiracy of social conformity blighted their brains. All of them can redeem\nthat lost freedom, if they work at it hard enough.\n\nI’ve worked at it for 50+ years now, and still find parts of me acting like a\nrobot or a zombie on occasion. Learning “how to become what you are” (in\nNietzsche’s phrase) takes a lifetime, but it still seems the best game in\ntown.\n\n  \n\n  \n\nTHOUGHTS TO PONDER\n\n  \n\nTo the States or any one of them, or any city of the States,\n\nRESIST MUCH, OBEY LITTLE,\n\nOnce unquestioning obedience, once fully enslaved;\n\nOnce fully enslaved, no nation, state, city of this Earth, ever afterward\nresumes its liberty.\n\n  \n\n— Walt Whitman\n\n\nOld Man On A Balcony:\n\nViews of Monterey Bay #12\n\n  \n\nBrother Raven, you\n\n  \n\nain’t no song-bird. You wusser\n\n  \n\nthan the kiss of death\n\n\n#### LSD, Dogs & Me\n\n  \n\nGreetings to Dr. Albert Hofmann 0n the 60th birthday of his “problem child!”\nAnd greetings to the Free World in general from the occupied U.S.A.!\n\n  \n\nTwo major factors have rendered me incapable of believing in the dominant\nmechanistic-materialist model of mind and the universe: [1] dogs, all of my\nlife, and [2] LSD, since 1962.\n\nAbout dogs I will write elsewhere; here I will say only that no matter how\nmuch mechanistic biology I read, no dog who ever lived as a guest in my house\never seemed like a machine to me. They all seemed like four-legged people.\n\nEvery LSD voyager has his or her own unique reports to offer; here I offer\nonly my own recollections of my own experiences, expressed in my own favorite\nmetaphors.\n\nAfter my first LSD voyage, dogs not only seemed even less like machines than\nbefore, but so did bugs and trees and birds and the starry sky itself. After\nmy 100th trip, even I seemed less like a machine.\n\nI have not embraced pantheism or even panpsychism as a philosophy; rather, I\nhave given up on philosophies entirely. I live amid wonders. which I file\nunder the law of general semantics which states that no map can ever show\n“all” the territory. In fact, I think we should ban the word “all” from\nordinary speech and restrict it solely to pure mathematics.\n\nLet me explain that a bit. Consider any large city you know well — Zurich,\nBerlin, Amsterdam, Los Angeles, whatever. For the sake of illustration, let me\nwrite “Dublin” and you may think of any other city you prefer. Do you think\nany map of Dublin can show the locations and directions of all the mice in\nthat city? Even if you regard this absurdity as theoretically possible, this\nmaus map still would not include the flowers, fleas, microbes, und so weiter;\nnor would it depict the emotions, joys, sufferings u.s.w. of the people (or\nthe dogs) — and it would remain relatively accurate for only seconds. (It\ncould not remain totally accurate for even a nanosecond.)\n\nNow consider our other kinds of “maps” — our beliefs, our arts, our sciences.\nDoes quantum mechanics tell “all” or even most of the reasons Bozo wants to\nkill lots and lots of people? Does Freudian theory, Marxism, postmodernism,\nbile samples, or oil prices — alone or combined into a mega-model — tell “all”\nabout that?\n\nDoes Van Gogh tell more or less about vegetation than Beethoven’s Sixth,\nDarwin’s Origin of Species, or the latest papers on botany? Which geometry\nreveals “all” the truth about the starry sky above Dublin — Euclid, Gauss,\nLobachevsky, Buckminster Fuller?\n\nTo fully grasp what I mean here, try the following simple experiment: try to\nsay “all” about the page (or computer screen) on which you see these words.\nAssuming you have it in hard copy, try to write down all you know about the\nchemical composition of the ink and the paper; if you don’t know enough, do\nsome research.\n\nTry to learn “all” about how it got from me to you, even if that requires six\nmonths of study of computer science and electronic theory. Who asked me to\nwrite this? Find out “all” you can about her or him. Don’t neglect the others\ninvolved in the production of this page — their salaries, their worries, their\nreligions if any, their politics, their sex-lives u.s.w.\n\nAnd don’t forget me: why did somebody ask me to write about LSD and why did I\nagree? Try to investigate “all” about me.\n\n(Hint: in doing this exercise, I discovered that among the infinite reasons I\nbecame a writer I could not omit the Danes over-fishing the North Sea 15\ncenturies ago.)*\n\n  \n\n~•~\n\n* My paternal grandmother had the name O’Lachlann, which means “son of the Dane” in Gaelic. The Danes took to invasion and conquest, of Ireland and elsewhere, after the fish problem arose . . .\n\n~•~\n\n  \n\nIf you continue this search for “allness” reasonably long enough (about two\nyears minimum), the page may have yellowed and the ink might have faded, which\nwill require more investigation into chemistry and even political history —\ne.g. the paper would last longer if made of hemp; why did the publisher use\nwood pulp instead?\n\nNow imagine these gigabytes of information entering your brain not in two\nyears, but in two nanoseconds, and radiating not just from this page but from\nthe fruit on the table, the wall paint, the pencil, the cars passing in the\nstreet . . . and the furthest stars.\n\nThat’s why LSD has altered the world for so many of us in the last 60 years.\nLike English poet William Blake, we have found “infinity in a grain of sand”\nand the deeper we look, the deeper the abyss grows. And like Nietzsche, we\noften suspect that as we gaze into the abyss, the abyss also gazes into us . .\n.\n\nLSD seems to suspend the imprinted and conditioned brain circuits that\nnormally control perception/emotion/thought, allowing a flood — an ocean — of\nnew information to break through.\n\nThe experience will seem either very frightening or exhilaratingly\neducational, depending on how rigidly you previously believed your current map\ncontained “all” the universe. Since I learned that no model equals the\ntotality of experience long before I tried LSD, I never had a bad trip; but I\nhave seen enough anxiety attacks and downright wig-outs in cases of the naive\nand dogmatic that I have never favored or advocated LSD’s promiscuous use by\nthe general population.\n\n  \n\nWhile splashing about and trying not to drown in this ocean of new\ninformation, you generally experience a second LSD surprise: an explosion of\nnewfound energy within your own body. Whether you call this kundalini or bio-\nelectricity or orgone or libido or Life Force, it can trigger muscle spasms,\nunbridled Eros or just “warm and melting” sensations — or all three in\nsuccession, or all three almost simultaneously — usually followed by something\nloosely called “near-death experience” or “out of body experience.”\n\nAgain, this can seem either psychotically terrifying or “religiously”\necstatic, and can imprint short- or long-term tendencies toward paranoia\n(“everything wants to destroy me”) or metanoia (“everything wants to help\nme”). In either case, one tends to retain a heightened awareness of those\npeculiar coincidences that Jung called synchronicities and Christian\nconspiracy buffs attribute to hostile occult forces.\n\nIn my case, after a few years I found myself seemingly forced to choose, not\nbetween paranoia and metanoia — both by then appeared pitiful\noversimplifications — but between mysticism and agnosticism. I solved that\nproblem, for myself anyway, by choosing agnostic mysticism in the tradition of\nLao-Dzu:\n\n  \n\nSomething unknown, unspeakable,\n\nbefore Earth or sky,\n\nbefore life or death,\n\nI do not know what to call it\n\nSo I call it Dao\n\n  \n\nWhat do I think we should do with Dr. Hoffman’s “problem child”? Well, no\ncommodity becomes safer when its manufacture, sale and distribution all fall\ninto the hands of professional criminals; and prohibition, of alcohol and all\nother drugs, inevitably has that effect, followed by police corruption and\npublic cynicism. Maybe governments should leave this arena entirely and let\nprofessional scientists, medical and otherwise, write the guidelines?\n\n\nOld Man On A Balcony:\n\nViews Of Monterey Bay #13\n\n  \n\nThe orange cloudbank:\n\n  \n\nOne bright touch in the grey sky\n\n  \n\nAbove a grey bay\n\n\n#### Keep Our Troops In Iraq!\n\n  \n\nI swear to God and/or Goddess I saw this and heard it, on CNN around 4 p.m.\nPST 14 April 2004:\n\n  \n\nUS Soldier in Iraq tells interviewer he doesn’t mind three extra months but\nresents his current duty “guarding property.” Sez he should be doing what he\nwas sent there to do.\n\n“What’s that?” prompts interviewer.\n\n“Kickin’ in doors and killin’ people,” he says, as honest and innocent as Dr.\nLecter announcing his gourmet preferences . . .\n\n  \n\nAs criminologists know, the group most likely to commit all violent crimes —\nbrawls, sports riots, drunk’n’disorderly, rape, mayhem, torture, murder, even\nsuicide — consists of males between 16 and 24. In imperialist/repressive\nsociety, I think MOST of us go whacko in less “colorful,” (i.e., less\ncriminal) ways for at least a few years in there. See Reich, Mass Psychology\nof Fascism.\n\nMaybe Dubya knows the crime statistics even if he don’t know from this Reich\nguy . . .\n\nMy god, do you really want those galoots back here roaming OUR streets?\n\n  \n\nTHOUGHTS TO PONDER\n\n  \n\nBELINDA: Ay, but you know we must return good for evil.\n\nLADY BRUTE: That may be a mistake in the translation.\n\n  \n\n— Sir John Vanbrugh, The Provoked Wife\n\n\n#### How to Win an Argument\n\n  \n\nThe Swift Boat Veterans for Truth convinces me — as does the behavior of\nCSICOP — that the oldest and most cynical view of politics remains true: if\nyou throw enough shit at the Enemy, some of it will stick, and he will stink.\n\nAt least in the minds of those who don’t pay close attention.\n\n\nOld Man on A Balcony:\n\nViews Of Monterey Boy #14\n\n  \n\nANOTHER MIDNIGHT HAIKU\n\n  \n\nDark, dark: no waves splash,\n\n  \n\nno barking dogs, no wind. Just\n\n  \n\nthe sound of no sound\n\n\n#### Mary, Mary, Quite Contrary\n\n  \n\nSay the magic word and the duck will come down and pay you $100.\n\n  \n\n— Marx\n\n  \n\nIn the small and otherwise little-known town of Rennes-le-Chateau in Southern\nFrance, near the Spanish border, stands a decidedly odd cathedral which has\nbecome a center of controversy, conspiracy theories and occult speculation for\nover a century. Although it belongs to the Roman Catholic church, and looks\nsuperficially orthodox from a distance, you don’t even have to go inside to\nbegin suspecting you have found the weirdest goddamn church in the entire\nChristian world, because over the entrance stand the ominous words\n\n  \n\nTHIS PLACE IS CURSED\n\n  \n\nIf nameless awe and Lovecraftian fears of cosmic horror do not drive you back,\nyou will proceed, and discover that this temple is dedicated to Mary\nMagdalene, the most poorly recorded, yet ill-reputed, of the disciples of\nJesus. In the Bible itself, she appears as a name and only a name. According\nto long-held legend, she was a common whore; and even after she reformed, she\nremains a bit of an embarrassment to the more puritanical Christians; i.e.,\nmost of them.\n\nAn “accursed” church named after the Monica Lewinsky of the New Testament does\npresent a puzzle, but the real mindfucks appear inside, on the Stations of the\nCross. One station seems to show shadowy figures smuggling Jesus’s body out of\nthe grave in the middle of the night (as if to fake the Resurrection?) and\nanother, even more unorthodox when you think it over, shows a Scotchman in\nkilts amid the crowd at the Crucifixion (as if to validate the secret\ntradition of Scotch Rite freemasonry . . . ?).\n\nLest you think all this the work of the Monty Python crew, the Church of Mary\nMagdalene was built in the 1890’s by the local parish priest, Father Beranger\nSauniere, but where he got the money for the construction seems even more\nproblematic than the eldritch edifice itself. Rennes-le-Chateau, a small town,\ncould barely afford a priest, and Father Sauniere in his early days often\nsurvived on free meals from his congregation, yet he suddenly became rich. In\naddition to the church, he built a Tower, also dedicated to Mary Magdalene,\nand a bridge, and other public works, but nobody knows where he got the money.\n\nSome legends soon grew in the village, claiming that Father Sauniere had found\nthe lost treasure of the Knights Templar (who had a castle in the area) or\nthat he had rediscovered the secret of alchemy. In L’Or de Rennes-le-Chateau\n(The Treasure of Rennes-le-Chateau), an odd bloke named Gerard de Sede claimed\nthat Sauniere had discovered some old parchments containing a “priceless”\nhistorical and occult revelation. He even reproduces the alleged parchments,\nwhich consist only of two pages from the New Testament, in Latin.\n\nThree other researchers named Lincoln, Baigent and Leigh later discovered that\nsome of the letters in these parchments do not follow the alignment of the\nrest of the text, but hang above it, like exponents in mathematics. These\nletters formed words, not in Latin but in French — but the words create a new\nmystery of their own. Slightly condensed, they say:\n\n  \n\nTHIS TREASURE BELONGS TO DAGOBERT II KING AND HE IS THERE DEAD SHEPHERDESS NO\nTEMPTATION THAT POUSSIN TENIERS HOLD THE KEY PEACE 681 BY THE CROSS AND THE\nHORSE OF GOD I COMPLETE THIS DEMON GUARDIAN AT NOON BLUE APPLES\n\n  \n\nWe shall return to this dazzling revelation, or surrealist hoax, but first we\nwill examine Father Sauniere a bit more deeply. This simple country priest\noften visited Paris and evidently mingled with the occult lodges there,\nincluding some of those associated with Aleister Crowley (a hint?). Before he\ndied, Sauniere made a final confession, as a good Catholic should; but the\npriest who heard the confession found it so terrible that he denied the last\nrites and refused to grant absolution. According to Catholic dogma, Sauniere\nimmediately went to Hell — for an accursed church, a Scotchman at the\nCrucifixion, noon blue apples, and some aeon-old horror that allegedly makes\nsense of all this . . .\n\nWait. It gets even weirder.\n\nGerard de Sede, whom I have already dared to call an odd bloke, produced\nanother book, La Race fabuleuse (The Fabulous Race), which deals with Stenay,\na town far from Rennes-le-Chatteau, which happens to have the head of Satan on\nits Coat of Arms. Although de Sede prominently mentions (but never does\nexplain) this blasphemy, he does have a lot of interesting things to say.\nFrogs often fall out of the sky onto Stenay, an annoyance to orthodox science,\nwhich cannot explain them.\n\nCharles Fort and the Fortean Society have catalogs of inexplicable frogfalls.\nAnd fishfalls. And some falls of strange metal objects. I hope that helps you,\nhere in the murk.\n\nThe Merovingian kings, a dark age dynasty (c. 400-700 e.v.), had a falling\nfrog on their Coat of Arms. (Less sinister than Satan, but more perplexing?)\nThe church in Stenay is built so that on midsummer day you can stand at the\naltar, look through the arched doors and see Sirius rising behind the sun. And\nDagobert II, a Merovingian king, was murdered by persons unknown in the\nArdennes Forest on 23 December, 679 c.e.\n\n  \n\nTHIS TREASURE BELONGS TO DAGOBERT II KING AND HE IS THERE DEAD . . .\n\n  \n\nHey, maybe some of this makes sense?\n\nDe Sede finally offers us a revelation, or part of one, thanks to one Marquis\nde B. (All the best conspiracy books have sources who cannot be identified.\nEven Woodward and Bernstein had “Deep Throat.”) The Marquis, himself descended\nfrom Dagobert, tells de Sede that the spooky Merovingians resulted from\nmatings between certain ancient Israelites of the Tribe of Benjamin and\nextraterrestrials from Sirius. They have lived in hiding and obscurity for\nmany centuries, because a certain powerful conspiracy has tried to murder them\nall, just like it murdered poor old Dagobert. Although neither de Sede nor de\nB. name this conspiracy, the evidence seems arranged so as to point a strong\nfinger of suspicion at the Vatican.\n\nAlthough the Marquis promised further revelations, he never got to provide\nthem. Like Dagobert II, he was murdered on 23 December (in 1972) in the\nArdennes forest. Or so de Sede claims.\n\nAnother part of the puzzle emerges from a Swiss source — journalist Mathieu\nPaoli, who, in a book titled Les Dessous (Undercurrents) exposed what he\nconsidered a conspiracy to restore monarchy in France, under the guise of two\ngroups called respectively [a] the Committee to Protect the Rights and\nPrivileges of Low-Cost Housing and [b] the Priory of Sion. His evidence\nactually seems to indicate that both groups act as fronts for something even\nolder and more esoteric.\n\nBoth of these secretive organizations had links with the Grand Loge Alpina in\nSwitzerland and the Committee for Public Safety, an office of the de Gaulle\ngovernment in Paris.\n\nThe Grand Loge Alpina ranks as the richest freemasonic lodge in the world,\nsince most of its members belong to the elite Swiss banking families that\nBritish Prime Minister Harold Wilson once claimed had more power than all the\ngovernments of Europe combined. He even called them “the Gnomes of Zurich.”\nTimothy Leary also used to say that the Cold War came to an end when the\nAmericans and Russians discovered that the Swiss own the whole world already.\n\nThe Committee for Public Safety seemed to consist of only Andre Malraux, Nobel\nLaureate in literature, and Pierre Plantard de Saint Clair, a fabulously rich\noccultist. Both men had served heroically in the Resistance, during the Nazi\noccupation, and had long personal friendships with de Gaulle. Yet Paoli’s\nevidence seemed to implicate them in a plot to replace de Gaulle’s democratic\n(if right-wing) government with a restored monarchy.\n\nIt does not compute, as Robby the Robot would say.\n\nBut dig this: Paoli reproduces the front page of one issue of Circuit, the\nofficial journal of the Committee to Protect the Rights and Privileges of Low-\nCost Housing and/or the Priory of Sion: it shows a map of France with a Star\nof David superimposed on it and a conventional “flying saucer” hovering above.\n\nWhat was it de Sede claimed about ancient Israelites who mated with\nextraterrestrials from Sirius? Hmmm . . . ?\n\nAfter publication of Les Dessous, Paoli went to Israel, where the government\narrested him for spying, convicted him, and shot him dead by firing squad, he\nthen quickly dying of natural causes as a result. Unless we want to let this\nstuff really weird us out, we better regard that as a mere coincidence. Even\nconsidering it a synchronicity might get us into deep and murky waters,\nespecially if we’re a little bit stoned.\n\nLa Race fabuleuse and Les Dessous both appeared in 1973. On 23 July that year,\nI had the first of a series of experiences which seemed like communications\nfrom Sirius, although, grown older and wiser, or at least more cautious, I now\ntend to attribute them to Too Much Acid. (See my Cosmic Trigger trilogy.)\nEarly the next year, sci-fi supergenius Philip K. Dick had a set of similar\nexperiences, which he at times attributed to communications from Sirius —\nalthough he also thought they might actually emanate from his dead friend,\nBishop James Pike, or from a Gnostic disciple of Jesus named Thomas.\n\nIn 1976 appeared The Sirius Mystery by Robert KG. Temple, a fellow of the\nRoyal Astronomical Society, who evidently had felt the Sirius Vibe in his own\nacademic way. His book argues that ancient intercourse between Earth and\nSirius had occurred about 4500 years ago in the mid-East, but unlike de Sede\nhe does not suggest sexual intercourse, merely the intellectual variety, and\nhe locates the contact point in Sumeria, not Israel . . . but still . . .\n\nThings heated up in 1982 with the publication of Holy Blood, Holy Grail by the\naforementioned Baigent, Lincoln and Leigh.\n\nIt had no references to Sirius, but among other things, it tried to prove that\nde Sede belonged to the Priory of Sion (the real brains behind the Committee\nto Protect the Rights and Privileges of Low-Cost Housing); that the Priory had\nexisted since the 14th Century and carried on the secret inner traditions of\nthe Knights Templar, the warrior-monks systematically exterminated by the\nInquisition 1300-1307 on charges of heresy; that Pierre Plantard de Saint\nClair acts as the current Grand Master of the Priory; and that the Priory\nserves to protect the Merovingians and their descendants from a murderous\nvendetta by the Vatican (a thesis only hinted at by de Sede).\n\nBaigent, Lincoln and Leigh even obtained an interview with Priory Grand Master\nPlantard de Saint Clair, who evaded most of their questions, but did admit\nthat Father Sauniere found a “treasure,” adding hermetically that the treasure\nwas not material but “spiritual,” that it belonged to Israel, and that it\nwould be forwarded thereto “at the proper time.” Well, that sure helps a lot,\ndoesn’t it?\n\nThe real bombshell falls at the end, when the authors offer their own solution\nto these enigmas. Jesus, they claim, married Mary Magdalene and they had a\nson. After the Crucifixion, the widow and the widow’s son fled to France, and\nhe became the progenitor of the Merovingians. They even produce a photo of the\nsepulcher of the widow’s son, which is quite near Rennes-le-Chateau, and point\nout its strong resemblance to a similar tomb in the painting, Shepherds of\nArcadia, by Nicholas Poussin.\n\n  \n\nSHEPHERDESS NO TEMPTATION THAT POUSSIN\n\nTENIERS HOLD THE KEY PEACE 681\n\n  \n\nThis painting shows three shepherds looking in awe at the tomb, and the tomb\nbears the inscription, Et in Arcadia ego . . . (“And in Arcadia, I . . .”)\nBaigent et al. point out that if you permute the letters of this fragment, you\ncan obtain I TEGO ARCANA DEI (“I conceal the secrets of God.”) I surmise that\nwith further ingenuity you could obtain “Noon Blue Apples” again, perhaps in\nLithuanian.\n\nDe Sede had already mentioned this cryptic painting, in La Race fabuleuse,\nhinting that it was linked to the Merovingians and Father Sauniere. He also\nclaimed that it once belonged to Louis XVI, who kept it in an isolated room\nwhere visitors to the palace could not see it.\n\nBut to return to the late Redeemer and his alleged paramour, Ms. Magdalene, if\none accepts them as the ancestors of the Merovingians, as Baigent et al. would\nhave it, and if one accepts the divinity of Jesus, as most Christians do, then\nthe medieval doctrine of “the divine right of kings” suddenly makes sense. The\nMerovingians seem to have intermarried with every other royal family in Europe\n— royals only marry royals, you know — so almost every king and queen of\nEurope from the middle ages onward has carried some of the holy “blood” of\nJesus by way of the holy grail of Mary’s uterus. If you translate “blood” as\ngenes, this makes sense, sort of.\n\nMaybe we should give up all the democratic heresy of the last 200 years and\naccept the genepool of Jesus and Mary Christ as our God-given rulers?\n\nWell, not if you think de Sede has a more plausible argument for the\nextraterrestrial/Hebraic origin of the Merovingians.\n\nOr you can skeptically regard all this as a complicated joke perpetrated by an\nodd consortium of aristocrats with too much time on their hands.\n\nBut then, why did the Swiss bankers get involved? They definitely do not have\ntoo much time on their hands. And where the hell did Sauniere get his sudden\nwealth and why did he use part of it to build a church for an allegedly\nreformed alleged hooker?\n\nBaigent and his associates also produce a heap of genealogical charts showing\nwho, in the modern world, belongs to the “divine” Merovingian genetic pool,\ntogether with an alleged list of Grand Masters of the Priory of Sion. Some\ninteresting names appear:\n\nPrince Bernhard of the Netherlands. He’s related to the Merovingians and,\nalthough this does not appear in the Baigent genealogy, he founded the\nBilderbergers, a mysterious group of rich white males who appear in dozens of\nconspiracy theories by both Leftwing and Rightwing opponents of the current\npower structure. Although never convicted of any real crime in any real court,\nthe Bilderbergers do indeed look conspiratorial to a lot of writers not rich\nenough, white enough or male enough to gain admittance; and they act with\nextreme secrecy. According to Lawrence Wilmot, writers for both the London\nEconomist and the French TV news admitted to him that they have orders not to\nmention the Bilderbergers, and other journalists responded with “ironic\nlaughter” when asked why they never touched on this subject.\n\n(A few known American members of the Bilderbergers: George Bush Sr., Bill\nClinton, David Rockefeller.)\n\n  \n\nDr. Otto von Hapsburg, heir of the longtime rulers of the Austro-Hungarian\nEmpire, descendent of the Merovingians and another Bilderberger. According to\nBaigent & Co., the von Hapsburg family financed Father Sauniere and the\nbuilding of the Church of Mary Magdalene in the last century. According to\nMaynard Solomon’s very scholarly and non-conspiracy-oriented biography,\nBeethoven, the Emperor Joseph von Hapsburg, in the 18th Century, appeared as a\nhero, an “Enlightened Monarch,” to the Bavarian Illuminati, who commissioned\nLudwig to immortalize him in the Emperor Joseph Cantata, where he is hailed as\n“foe of darkness and bringer of light.” Dr. Otto himself still carries the\nmysterious title, King of Jerusalem, which always belongs to the eldest male\nvon Hapsburg of every generation. (Because they are descended from King Jesus?\nOr from those Jewish Extraterrestrials?)\n\n  \n\nJean Cocteau, 23rd Grand Master of the Priory of Sion and a major figure in\nmodernist art, having done notable work in painting, film, drama, poetry,\nballet, etc. A Gay opium addict, related to much of the French aristocracy,\nCocteau had friendships with Ezra Pound, Dali, Picasso, Orson Welles, and\nalmost everybody important in High culture, and helped create the surrealist\nmovement. That may explain the Noon Blue Apples — if Sauniere didn’t really\nfind those parchments and Somebody forged them later . . .\n\n  \n\nAnd other revelations and/or hoaxes have surfaced . . .\n\nIn The Messianic Legacy [1987] Baigent, Lincoln and Leigh spend half the book\nproving links between the Priory of Sion and modern banking, implicating banks\nin England, Canada and the U.S. as well as the Usual Suspects in Switzerland.\nThe other half of the book concerns the equality of men and women in early\nChristianity, placing the Papist all-male priesthood as the first “heresy.”\n\nPierre Plantard de Saint Clair also appears again, for a brief interview, in\nwhich he announces that he has resigned as Grand Master of the Priory, refuses\nto name his successor, and drops dark hints that the whole megillah has\nsecretly come under the control of the Knights of Malta, a rightwing Catholic\norganization often accused elsewhere of plotting a revival of Fascism.\n\nAn undated pamphlet, Scandals of the Priory of Sion, signed “Cornelius,” has\ncirculated among conspiracy buffs for some time. It links the Priory to the\nMafia and the P2 conspiracy in Italy.\n\nYou’ve heard of the Mafia. P2, better known in Europe than over here, grew out\nof the CIA’s Project Gladio, created by James Jesus Angleton, Chief of Counter\nIntelligence — a man who appears in more conspiracy theories than anyone since\nAdam Weishaupt. Gladio, intended to influence Italian elections, had an\nItalian organizer named Licio Gelli, who had previously worked for both the\nGestapo and the Communist Underground during World War II, convincing each\nside that he was betraying the other. As soon as Angleton hired Gelli, Gelli\nrepeated his previous achievement and got on the payroll of the KGB, too,\nagain convincing each side that he was really loyal to them and betraying the\nother guys. Gelli also belonged to the Knights of Malta, by the way.\n\nOnce he had funding from both the CIA and the KGB, Gelli formed P2, a secret\nsociety recruited entirely from 30 members of the Grand Orient Lodge of\nEgyptian Freemasonry. P2 then became the “secret government” of Italy,\ninfiltrating over 900 members into the official government, laundering drug\nmoney through the Vatican Bank and Banco Ambrosiano, and assassinating\neverybody who seriously pissed them off. Murders charged to P2 include many\nleftwing labor leaders; Prime Minister Aldo Moro; Mino Pecorelli (the first\njournalist to expose their machinations); Roberto Calvi (president of Banco\nAmbrosiano, who after being indicted, seemed inclined to turn state witness);\nMichele “The Shar” Sindona (president of Franklin National Bank, who also\nseemed inclined to turn informer after being convicted of murdering a bank\nexaminer); and, probably, the previous Pope. Calvi and Sindona also belonged\nto the Knights of Malta — and so does Dr. Otto von Hapsburg (see above).\n\nAccording to “Cornelius,” P2 was a tool, a front, for the Priory of Sion;\nJames Jesus Angleton only thought he ran the show from CIA headquarters in\nLangley. (However, according to Larry Gurwin of the Institutional Investor,\nItalian investigators believe the real control came from a still-unidentified\nPuppet Master in Monte Carlo.) Cornelius also claims the Priory of Sion\nmurdered Giorgio Ambrosoli, the bank examiner whose death the courts had\nblamed on Michele “The Shark” Sindona of P2; and that Cardinal Jean Danielou\nalso belonged to the Priory.\n\nCardinal Danielou had literary friendships with Jean Cocteau, of the Priory of\nSion, and Nobel laureate Andre Malroux of de Gaulle’s Committee for Public\nSafety and the esoteric Committee for the Rights and Privileges of Low Cost\nHousing and/or the Priory of Sion.\n\nThe Cardinal himself died, somewhat oddly, in the apartment of a striptease\ndancer, in 1974.\n\nIn 1985 David Wood produced GENISIS — not a misprint, but a Joycean pun. (Gen-\nISIS — get it?) Based on the English science, or art, or group madness, called\nley hunting, this book seeks a mystic secret in the geographical arrangements\nof the sites important in the Priory/Magdalene mystery. You do this by\nconnecting all the key points with straight lines, and if nothing significant\nemerges, you may try curved lines if they are arcs of a circle. If that\ndoesn’t work, try a smaller map and a thicker pencil. Using the right map and\npencil, plus a few circles, Wood emerges with a design he calls the Vagina of\nNuit.\n\nAlthough it doesn’t look like any human vagina I ever saw outside of a Picasso\npainting, the Vagina of Nuit does yield some interesting geometrical\nproportions — numbers significant in mystic tradition. From these, Wood\ndeduces that Mary Magdalene never existed as a person; she is the Egyptian\nsky-goddess Nuit in disguise. Furthermore, the Merovingians came from\nAtlantis, not the stars, but the whole human race was genetically engineered\nby a group of extraterrestrial scientists from Sirius.\n\nI knew that Sirius would creep back into the story eventually.\n\nWood also asserts that members of the Priory of Sion must all amputate their\npenises to obtain initiation, as a sacrifice to Nuit, or Isis, or (if we must\nuse current mythology) Mary Magdalene.\n\nSounds less attractive even than Heaven’s Gate, which only wanted you to cut\noff your balls.\n\nBut, at this point, I cannot resist inserting the fact that several quite\nintelligent scientists have offered evolutionary theories as far out as\nWood’s. Sir Francis Crick, Nobel laureate and co-discoverer of the DNA\nmolecule, has long argued that the DNA contains too much information to have\nhappened by means of any finite series of “lucky accidents.” Since the word\n“God” remains taboo in scientific circles, Crick claims the designer of DNA,\nand hence of all life on Earth, must be an advanced extraterrestrial race.\nSimilar ideas have come forth from the distinguished astronomer, Sir Fred\nHoyle, and from Dr. Timothy Leary, among others.\n\nInside the “Men's Club”: Secrets of the Patriarchy, by “Hawthorne Abendsen”\n(no date: A-Albionic Research, Ferndale, Michigan) offers yet another\nperspective on all this weirdity. The Priory of Sion, Abendsen claims,\ncontrols all the other all-male secret societies you ever heard of, and thus\nall of our civilization. It worships Al-Shaddai (Lord of Battles), the god who\nappeared to Abraham, and it has created all later, gentler images of divinity\n(e.g., the God of Love) as deceptions to fool the masses. You might say\nHannibal Lecter, MD. is their High Priest.\n\nWorship of Al-Shaddai consists of making wars, as a God of Battles would wish,\nand also of periodic animal and human sacrifices of the sort Fundamentalist\nChristians attribute to Satanists. Satan has nothing to do with it, according\nto Abendsen: blood sacrifice, in or out of warfare, remains the central ritual\nof the Judaic-Christian-Moslem system, and anything else you’ve heard is just\npart of the cover-up, to conceal why our rulers do the murderous things they\ndo.\n\nAlthough this yarn sounds a lot like put-on or parody, Abendsen has a certain\nfamily resemblance to a great many serious thinkers of recent decades. Radical\nFeminists all consider our culture Patriarchal; Dr. Wilhelm Reich called it\nAuthoritarian-Patriarchal; Dr. James De Meo calls it Armored Patrist; etc. The\nlatest cuss word for it, logophallocentrist, contributed by the\npostmodernists, means that we have a social system based on belief in the\nspecial magic power of words and penises. Dr. Leonard Shlain, in The Alphabet\nVersus the Goddess, blames it all on the invention of the alphabet, an\nargument that out-McLuhans McLuhan.\n\n“Hawthorne Abendsen,” by the way, seems to have gotten borrowed or stolen from\nPhilip K. Dick, who used it as the name of the author of the book-within-the-\nbook, in his sci-fi classic, The Man in the High Castle.\n\nYes: the same Phillip K. Dick who later decided he was receiving messages from\nSirius . . .\n\nAs the French themselves say, it must make one furious to think and to jump up\nand down. And in Rennes-le-Chateau, the accursed church of Mary Magdalene\nstill stands, or lurks, still announcing its accursedness. A friend of mine,\nFred Lehrman of Nomad University, recently visited the site and tells me he\nmet an intrepid researcher there, who had discovered that one of the statues\ncontained a sliding panel with a German newspaper from 1904 hidden inside.\nSince some of the words in the paper had underlining in pen, this investigator\nhopes to find a code revealing Everything.\n\nI wish him luck; but I fear he will find something like “Stately plump Buck\nMulligan has never wept nor dashed a thousand kim JFK Dallas 1963 midnight\npurple bananas . . .”\n\n\nOld Man On A Balcony:\n\nViews Of Monterey Bay #15\n\n  \n\nThe stone Buddha sits\n\n  \n\nStill as the Eiger: silent . . .\n\n  \n\nThe waves crash and splash\n\n\n#### Left and Right:\n\n#### A Non-Euclidean Perspective\n\n  \n\nI have been invited to contribute an article on whether my politics are “left”\nor “right,” evidently because some flatlanders insist on classifying me as\nLeftist; and others, equally Euclidean, argue that I “am” obviously some\nvariety of Rightist.\n\nNaturally, this debate intrigues me. The Poet prayed that some power would\n“the giftie gie us /to see ourselves as ithers see us”; but every published\nwriter has that dubious privilege. I have been called a “sexist”(by Arlene\nMeyers) and a “male feminist . . . a simpering pussy-whipped wimp” (by LA.\nRollins), “one of the major thinkers of the modern age” (by Barbara Marx\nHubbard) and “stupid” (by Andrea Chaflin Antonoff), a “genius” (by SOUNDS,\nLondon) and “mentally deranged” (by Charles Platt), a “mystic” and “charlatan”\n(by the Bay Area Skeptics), and a “materialist” (by an anonymous gent in\nSeattle who also hit me with a pie); I am also frequently called a “Satanist”\nin some amusing, illiterate and usually anonymous crank letters from\nProtestant Fundamentalists.\n\nI can only conclude that I am indeed like a visitor from non-Euclidean\ndimensions whose outlines are perplexing to the Euclidean inhabitants of\nvarious dogmatic Flatlands. Or else, Lichtenberg was right when he said a book\n“is a mirror. When a monkey looks in, no philosopher looks out.”\n\nOf course, we live in curved space (as noted by Einstein); that should warn us\nthat Euclidean metaphors may prove misleading. Science has also discovered\nthat the Universe can count above two, which should make us leery of either/or\nchoices. There are eight — count ’em, eight — theories or models in quantum\nmechanics, all of which use the same equations but have radically different\nphilosophical meanings; physicists have accepted the multi-model approach (or\n“model agnosticism”) for over 80 years now.\n\nIn modern mathematics and logic, in addition to the two-valued (yes/no) logic\nof Aristotle and Boole, there are several three-valued logics (e.g., the yes,\nno and maybe Quantum Logic of von Neumann; the yes, no and po of psychologist\nEdward de Bono; etc.); at least one four-valued logic (the true, false,\nindeterminate and meaningless of Rapoport); and an infinite-valued logic\n(Korzybski). I myself have presented a multi-valued logic in my neuroscience\nseminars; the bare bones of this system can be found in my book, Quantum\nPsychology.\n\nTwo-valued Euclidean choices — left or right of an imaginary line — do not\nseem very “real” to me, in comparison to the versatility of modern science and\nmathematics.\n\nActually, it was once easy to classify me in simple Euclidean topology. To\nparaphrase a recent article by the brilliant Michael Hoy [Critique #19/20], I\nhad a Correct Answer Machine installed in my brain when I was quite young. It\nwas a right-wing Correct Answer Machine in general and Roman Catholic in\nparticular. It was installed by nuns who were very good at creating such\nmachines and implanting them in helpless children. By the time I got out of\ngrammar school, in 1945, I had the Correct Answer for everything, and it was\nthe Correct Answer that you will nowadays still hear from, say, William\nBuckley, Jr.\n\nWhen I moved on to Brooklyn Technical High School, I encountered many bright,\nlikable kids who were not Catholics and not at all right-wing in any respect.\nThey naturally angered me at first. (That is the function of Correct Answer\nMachines: to make you have an adrenaline rush, instead of a new thought, when\nconfronted with different opinions.) But these bright, non-Catholic kids —\nProtestants, Jews, agnostics, even atheists fascinated me in some ways. The\nresult was that I started reading all the authors the nuns had warned me\nagainst — especially Darwin, Tom Paine, Ingersoll, Mencken and Nietzsche.\n\nI found myself floating in a void of incertitude, a sensation that was\nunfamiliar and therefore uncomfortable. I retreated back to robotism by\nelecting to install a new Correct Answer Machine in my brain. This happened to\nbe a Trotskyist Correct Answer Machine, provided by the International\nSocialist Youth Party. I picked this Machine, I think, because, the\nalternative Correct Answer Machines then available were less “Papist”\n(authoritarian) and therefore less comfortable to my adolescent mind, still\nbent out of shape by the good nuns.\n\n(Why was I immune to Stalinism — an equally Papist secular religion? Because\nof my youth, probably. The only Stalinists left in the U.S. by the late 1940’s\nwere all middle-aged and “crystallized” as Gurdjieff would say. Those of us\nwho were younger could clearly see that Stalinism was not much different from\nHitlerism. The Trotskyist alternative allowed me to feel “radical” and modern,\nwithout becoming an idiot by denying the totalitarianism of the U.S.S.R., and\nit let me have a martyred redeemer again as I had in my Catholic childhood.)\n\nAfter about a year, the Trotskyist Correct Answer Machine began to seem a\nnuisance. I started to suspect that the Trotskyists were some secular clone of\nthe Vatican, whether they knew it or not, and that the dogma of Papal\ninfallibility was no whit more absurd than the Trotskyist submission to the\nCentral Committee. I decided that I had left one dogmatic Church and joined\nanother. I even suspected that if Trotsky had managed to hold on to power, he\nmight have been as dictatorial as Stalin.\n\nActually, what irritated me most about the Trots (and now seems most amusing)\nis that I already had some tendency toward individualism, or crankiness, or\nHeresy; I sometimes disputed the Party Line. This always resulted in my being\ndenounced for “bourgeoisie tendencies.” That was irritating then and amusing\nnow because I was actually the only member of that Trot cell who did not come\nfrom a middle-class background. I came from a working class family and was the\nonly genuine “proletarian” in the whole Marxist kaffeeklatsch.\n\nAt the age of 18, then, I returned to the void of incertitude. It began to\nseem almost comfortable there, and I began to rejoice in my agnosticism. It\nmade me feel superior to the dogmatists of all types, and adolescents love to\nfeel superior to everybody (especially their parents — or have you noticed\nthat?) Around the same time as my Trotskyist period, I began to read the first\nRevisionist historians, whom I had been warned about by my high school social\nscience teachers, in grave and awful tones, as if these men had killed a bat\nin the sacristy. My teachers were too Liberal to tell me I would go to Hell\nfor reading such books (as the nuns had told me about Darwin, for instance),\nbut they made it clear that the Revisionists were Evil, Awful, Unspeakable and\nprobably some form of Pawns of the Devil.\n\nI recognized the technique of thought control again, so I read all the\nRevisionists I could find. They convinced me that the New Deal Liberals had\ndeliberately lied and manipulated the U.S. into World War II and were still\nlying about what they did after the war was over. (In fact, they are still\nlying about it today.)\n\nThe Revisionist who impressed me most was Harry Elmer Barnes, a classic\nLiberal who was a bit of a Marxist (in methodology — i.e., in his way of\nlooking for economic factors behind political actions). I was amused and\ndisgusted by the attempt of the New Deal gang to smear Professor Barnes as a\nright-wing reactionary. Barnes, in fact, was an advocate of progressive ideas\nin education, economics, politics, criminology, sociology and anthropology all\nhis life.\n\nCharles Beard, another great historian of classic Liberal principles, agreed\nthat Roosevelt deliberately lied to us in World War II, and was smeared in the\nsame way as Professor Barnes. This did not encourage me to have Faith in any\nParty Line, even if it called itself the “modern, liberal, enlightened” Party\nLine.\n\n(I have never been convinced by the Holocaust Revisionists, however, simply\nbecause I have met a great many Holocaust eyewitnesses, or alleged\neyewitnesses, in the past 40 years. Most of these people I seemingly met by\naccident, in both Europe and America. A conspiracy that has that many liars\nplanted in that many places — or has always paid such special attention to me\nthat it placed these liars where I would meet them — is a conspiracy too\nomnipotent and omnipresent, and therefore too metaphysical, for me to take\nseriously. A conspiracy so Godlike in its powers could, in principle, deceive\nus about anything and everything, and I wonder why the Holocaust Revisionists\nstill believe that World War II itself occurred, or that any of past history\never happened.)\n\nI reached 20 and became an employee (i.e., a robot) in the McCarthy Era and\nthe Eisenhower years; my agnosticism became more total and so did my suspicion\nthat politics consists of a carnival of buncombe (as Mencken once said). It\nseemed obvious to me that, while Senator Joe was a liar of stellar magnitude,\na lot of the Liberals were lying their heads off, too, in attempts to hide\ntheir previous fondness for Stalinism. That was something I, as a former\nTrotskyist, knew about by experience. In bon ton East Coast intellectual\ncircles, before McCarthy, Stalinism was much more “permissible” than\nTrotskyism; it was almost chic.\n\nIf I still regard the McCarthy witch-hunt of the 1950’s as abominable, I also\nremember that some of the victims had engaged in similar witch-hunts against\nthe Trotskyists in the early 1940’s.\n\nIt is probably impossible for a social mammal to be totally “apolitical.” Even\nif I was allergic to Correct Answer Machines, my mind kept searching for some\ngeneral social ideas that I could take more or less seriously. For a while I\ndropped in and out of colleges and in and out of jobs and searched earnestly\nfor some pragmatic mock-up of “truth” without a Correct Answer Machine\nattached. And yet both Left and Right continued to appear intellectually\nbankrupt to me.\n\nComing from a working class family, I could never have much sympathy for the\nkind of Conservatism you find in America in this century. (I do have a deep\nrespect for the classic Libertarian Conservatives of the 18th Century,\nespecially Edmund Burke and John Adams.) *\n\n  \n\n~•~\n\n* This respect does not extend to our current [2004] neo-conservatives, who have junked both Adams and Burke, along with Coke, Blackstone and Magna Carta, to peddle Tsarism in red, white and blue.\n\n~•~\n\n  \n\nAfter I married and had children to support, the abominations of the\nCapitalist system and the wormlike ignominy of the employee role began to seem\nlike prisons to me; I was a poor candidate for the Conservative cause. On the\nother hand, the FDR Liberals, I was convinced, had lied about World War II;\nthey first smeared and then blacklisted the historians who told the truth; and\nthey had jumped on the Cold War bandwagon with ghoulish glee.\n\nI seem anti-war by “temperament” (whatever that means — early imprints or\nconditioning? Genes? I don’t know the exact cause of such a deep-seated and\nlife-long bias). Marxist dogma seemed as stupid to me as Catholic dogma and as\nmurderous as Hitlerism. I now thought of myself as an agnostic on principle. I\nwas not going to join any more “churches” or submit to anybody’s damned Party\nLine.\n\nMy agnosticism was also intensified by such influences as further reading of\nNietzsche, existentialism, phenomenology, General Semantics, and operational\nlogic. They have remained major influences on me and I want to say a few words\nabout each.\n\nNietzsche’s philosophy of the Superman did not turn me on in youth; coming\nfrom the proletariat, I could not see myself as one of his aristocratic\nUebermenschen. On the other hand, his criticism of language, and of the\nmetaphysical implications within languages, made a powerful impression on me;\nI still re-read one or two of his books every year, and get new semantic\ninsights from them. He is, as he bragged, a hard nut to digest all at once.\n\nExistentialism did not convert me back to Marxism (as it did to Sartre); it\nmerely magnified my Nietzschean distrust of capitalized nouns and other\nabstractions, and strengthened my preferences for sensory-sensual\n(“existential”) modes of perception/conception. The phenomenologists —\nespecially Husserl and the wild man of the bunch, Charles Fort — encouraged my\ntendency to suspect all general theories (religious, philosophical, even\nscientific), and to regard human sense experience as the primary datum.\n\nMy polemics against Materialist Fundamentalism in The New Inquisition and the\nAristotelian mystique of “natural law” (shared by Thomists and some\nLibertarians) in my Natural Law; or, Don’t Put a Rubber On Your Willy are both\nbased on this existentialist-phenomenologist choice that I will “believe” in —\nor gamble on — human experience, with all its muddle and uncertainty, more\nthan I will ever “believe” in capitalized Abstractions and “general\nprinciples.”\n\nGeneral Semantics, as formulated by Korzybski, increased this anti-\nmetaphysical bias in me. Korzybski also stressed that the best sensory data\n(as revealed by instruments that refine the senses) indicates that we live in\na non-Aristotelian, non-Euclidean and non-Newtonian continuum. I have\npracticed for 30 years the exercises Korzybski recommends to break down\nAristotelian-Euclidean-Newtonian ideas buried in our daily speech, and retrain\nmyself to perceive in ways compatible with what our instruments indicate about\nactuality.\n\nDue to Korzybski’s neurolinguistic training devices, it now feels “natural”\nfor me to think beyond either/or logic, to perceive the unity of\nobserver/observed, and to regard “objects” as human inventions abstracted from\na holistic continuum.\n\nMany physicists think I have studied more physics than I actually have; I\nmerely neurologically internalized the physics that I do know.\n\nOperational logic (as formulated by the American physicist Percy Bridgman and\nrecreated by the Danish physicist Niels Bohr as the Copenhagen Interpretation\nof science) seemed the approach to modern science that appealed to me in the\ncontext of the above working principles. The Bridgman-Bohr meta-model rejects\nas “meaningless” any statements that do not refer to concrete experiences of\nhuman beings. (Bridgman was influenced by Pragmatism, Bohr by Existentialism.)\nOperationalism also regards all proposed “laws” only as maps or models that\nare useful for a certain time. Thus, Operationalism seems the one “philosophy\nof science” that warns us, like Nietzsche and Husserl, only to use models\nwhere they’re useful and never to elevate them into Idols or dogmas.\n\nAlthough I dislike labels, if I had to label my attitude I would accordingly\nsettle for existentialist-phenomenologist-operationalist, as long as no one of\nthose three terms is given more prominence than the other two.\n\nIn the late 1950’s, I began to read widely in economic “science” (or\nspeculation) again, a subject that had bored the bejesus out of me since I\noverthrew the Marxist Machine in my brain ten years earlier. I became\nfascinated with a number of alternatives — or “excluded middles” — that\ntranscend the hackneyed debate between monopoly Capitalism and totalitarian\nSocialism. My favorite among these alternatives was, and to some extent still\nis, the individualist-mutualist anarchism of Proudhon, Josiah Warren, S.P.\nAndrews, Lysander Spooner and Benjamin Tucker.\n\nI do not have a real Faith that this system would work out as well in practice\nas it sounds in theory, but as theory it still seems to me one of the best\nideas I ever encountered.\n\nThis form of anarchism is called “individualist” because it regards the\nabsolute liberty of the individual as a supreme goal to be attained; it is\ncalled “mutualist” because it believes such liberty can only be achieved by a\nsystem of mutual consent, each agreeing to defend the liberty of all. Tucker\ndefined this as a non-invasion compact; the hippie version says “Nobody gets\non nobody’s back.” In this Utopia, free competition and free cooperation are\nboth encouraged; it is assumed that persons and groups will decide to compete\nor to cooperate based on the concrete specifics of each case. (This appeals to\nmy “existentialism” again, you see.)\n\nLand monopolies are discouraged in individualist — mutualist anarchism by\nabolishing State laws granting ownership to those who neither occupy nor use\nthe land; “ownership,” it is predicted, will then only be contractually\nrecognized where the “owner” actually occupies and uses the land, but not\nwhere he charges “rent” to “allow” others to occupy or use it.\n\nThe monopoly on currency, granted by the State, is also abolished, and any\ncommune, group, syndicate, etc., can issue its own competing currency; it is\nclaimed that this will drive interest down to approximately zero. With rent at\nzero and interest near zero, it is argued that the alleged goal of socialism\n(abolition of exploitation) will be achieved by free contract, without\ncoercion or totalitarian Statism. That is, the individualist-mutualist model\nargues that the land and money monopolies are the “bugger factors” that\nprevent Free Enterprise from producing the marvelous results expected by Adam\nSmith. With land and money monopolies abolished, it is predicted that\ncompetition (where there is no existential motive for cooperation) and\ncooperation (where this is recognized as being to the advantage of all) will\nprevent other monopolies from arising.\n\nSince monopolized police forces are notoriously graft-ridden and underlie the\npower of the state to bully and coerce, competing protection systems will be\navailable in an individualist-mutualist system. You won’t have to pay “taxes”\nto support a Protection Racket that is actually oppressing rather than\nprotecting you. You will only pay dues, where you think it prudent, to\nprotection agencies that actually perform a service you want and need. In\ngeneral, every commune or syndicate will make its own rules of the game, but\nthe mutualist-individualist tradition holds that, by experience, most communes\nwill choose the systems that maximize liberty and minimize coercion.\n\nBeing wary of Correct Answer Machines, I also studied and have given much\nserious consideration to other “Utopian” socio-economic theories.\n\nI am still fond of the system of Henry George (in which no rent is allowed,\nbut free enterprise is otherwise preserved); but I also like the ideas of\nSilvio Gesell (who would also abolish rent and all taxes but one — a demurrage\ntax on currency, which should theoretically abolish interest by a different\ngimmick than the competing currencies of the mutualists).\n\nI also see possible merit in the economics of C.H. Douglas, who invented the\nNational Dividend — lately re-emergent, somewhat mutated, or maybe mutilated,\nas Theobold’s Guaranteed Annual Wage and/or Nobel laureate Milton Friedman’s\nNegative Income Tax. And I am intrigued by the proposal of Pope Leo XIII that\nworkers should own the majority of stock in their companies.\n\nMost interesting of recent Utopias to me is that of Buckminster Fuller in\nwhich money is abolished, and computers manage the economy, programmed with a\nprime directive to advantage all without disadvantaging any — the same goal\nsought by the mutualist system of basing society entirely on negotiated\ncontract.\n\nSince I don’t have the Correct Answer, I don’t know which of these systems\nwould work best in practice. I would like to see them all tried in different\nplaces, just to see what would happen.\n\n(This multiple Utopia system was also suggested by Silvio Gesell, who was not\nconvinced he had a Correct Answer Machine; that’s another reason I like\nGesell.)\n\nMy own bias or hope or prejudice is that individualist-mutualist anarchism\nwith some help from Bucky Fuller’s computers would work best of all, but I\nstill lack the Faith to proclaim that as dogma.\n\nThere is one principle (or prejudice) which makes anarchist and libertarian\nalternatives attractive to me where State Socialism is totally repugnant to my\ngenes-or-imprints. I am committed to the maximization of the freedom of the\nindividual and the minimization of coercion. I do not claim this goal is\ndemanded by some ghostly or metaphysical “Natural Law,” but merely that it is\nthe goal that I, personally, have chosen — in the Existentialist sense of\nchoice. (In more occult language, such a goal is my True Will.) Everything I\nwrite, in one way or another, is intended to undermine the metaphysical and\nlinguistic systems which seem to justify some Authorities in limiting the\nfreedom of the human mind or in initiating coercion against the non-coercive.\n\n. . . and then came what Charles Slack calls “the madness of the sixties.” I\nwas an early, and enthusiastic, experimenter with LSD, peyote, magic mushrooms\nand any other compound that mutated consciousness. The result was that I\nbecame even more agnostic but less superior about it.\n\nWhat psychedelics taught me was that, just as theories and ideologies (maps\nand models) are human creations, not divine revelations, every perceptual grid\nor existential reality-tunnel is also a human creation — a work of art,\nconsciously or unconsciously edited and organized by the individual brain.\n\nI began serious study of other consciousness-altering systems, including\ntechniques of yoga, Zen, Sufism and Cabala. I, alas, became a “mystic” of some\nsort, although still within the framework of existentialism-phenomenology-\noperationalism. But, then, Buddhism — the organized mystic movement I find\nleast objectionable — is also existentialist, phenomenologist and\noperationalist . . .\n\nNietzsche’s concept of the Superhuman has at last become meaningful for me,\nalthough not in the elitist form in which he left it. I now think evolution\nstill continues and even accelerates: the human brain seems likely to evolve\nto a state that seems Superhuman compared to our previous history of\ndomesticated primatehood. My favorite science is neuroscience, and I am\nendlessly fascinated by every new tool or technique that breaks down robot\ncircuits in our brains (Correct Answer Machines) and spurs creativity, higher\nintelligence, expanded consciousness, and, above all, broader compassion.\n\nI see no reason to believe that only an elite is capable of this evolutionary\nleap forward, especially as the new tools and training techniques are becoming\nmore simple. In neuroscience, as in all technology, we seem to follow Bucky\nFuller’s rule that each breakthrough allows us to do more work with less\neffort and to create more wealth out of less raw matter.\n\nOnce I broke loose from the employee role and became self-supporting as a\nwriter, the “horrors of capitalism” seemed less ghoulish to me, since I no\nlonger had to face them every day. (As Shakespeare said, we can all bear a\ntoothache philosophically, except the pore bloke wot’s got it.) I prefer to\nlive in Europe rather than pay taxes to build more of Mr. Reagan’s goddam\nnuclear missiles, but I enjoy visiting the U.S. regularly for intellectual\nstimulation.\n\nI agree passionately with Maurice Nicoll (a physician who mastered both\nJungian and Gurdjieffian systems) when he wrote that the major purpose of\n“work on consciousness” is to “decrease the amount of violence in the world.”\nThe main difference between our world and Swift's is that while we have\nstopped killing each other over religious differences (outside the Near East\nand Northern Ireland), we have developed an insane passion for killing each\nother over ideological differences. I regard Organized Ideology with the same\nhorror that Voltaire had for Organized Religion.*\n\n  \n\n~•~\n\n* Especially now that they’re back in bed together, on both sides of the Terrorwar.\n\n~•~\n\n  \n\nConcretely, I am indeed a Male Feminist, as L.A. Rollins claimed (although\nseeing myself often on TV, I deny that I simper; I don’t even swish); like all\nlibertarians, I oppose victimless crime laws, all drug control laws, and all\nforms of censorship (whether by outright reactionaries, or Revolutionary\nCommittees of Radical Feminists).\n\nI passionately hate violence, but am not a Dogmatic Pacifist, since I don’t\nhave Joan Baez’ Correct Answer Machine in my head. I know I would kill an\narmed aggressor, in a concrete crisis situation where that was the only\ndefense of the specific lives of specific individuals I love, although I would\nnever kill a person or employ even minor violence, or physical coercion, on\nbehalf of capitalized Abstractions or Governments (who are all damned liars).\nAll these are matters of Existential Choice on my part, and not dogmas\nrevealed to me by some god or some philosopher-priest of Natural Law.\n\nI prefer the various Utopian systems I have mentioned to the Conservative\nposition that humanity is incorrigible, and I also think that if none of these\nUtopian scenarios are workable, some system will eventually arrive better than\nany we have ever known. I share the Jeffersonian (“Liberal”?) vision that the\nhuman mind can exceed all previous limits in a society where freedom of\nthought is the norm rather than a rare exception.\n\nDoes all of this make me a Leftist or a Rightist? I leave that for the\nEuclideans to decide.\n\n\n#### La Belle Dame Sans Merci\n\n  \n\nThe four weirdest and scariest drug stories I know all involve belladonna, a\nchemical for which I now have the same sincere respect as I have for hungry\ntigers, earthquakes, floods, wildfires, the IRS and Dr. Hannibal Lecter.\n\nThe first story I’ll tell comes from a younger friend, then a 1960’s drop-out\nhippie freak but now, in 2004, a Ph.D. in sociology. He tried belladonna\naround 1965 under the impression that it had much the same effects as LSD.\nWhen he immediately went into toxic convulsions, friends rushed him to a\nhospital where the ER staff pumped out his stomach — probably saving his life,\nbut a bit too late to save him from delirium, since the belladonna had already\nentered his bloodstream.\n\nWhen he returned to what seemed normal consciousness, he found himself in a\nhospital bed, surrounded by people in other beds with different ailments. Then\na Beautiful Blonde Nurse with Great Big Hooters entered the ward, accompanied\nby an olde style New Orleans jazz band.\n\nAs my friend watched entranced, the nurse proceeded to perform a classic Strip\nTease dance with plenty of tantalizing tease but eventual total nudity\nfollowed by even more bumps and grinds. The music seemed louder and raunchier\nthan any jazz he had ever heard, and came to a wild Dionysian climax when the\nnaked nurse crawled into bed with a delighted patient and proceeded to make\nlove to him, loudly and frequently and more ways than a dozen porn stars.\n\nMy friend never once suspected that this might be a hallucination. Nor did it\nseem an unusually innovative medical procedure. You don’t ask philosophic or\nontological questions during a belladonna journey the way you usually do on\nreal psychedelics. He only began to wonder if any of that sex stuff really\nhappened the following morning.\n\n. . . and that’s this whole story. Belladonna erases a great deal of your\nmemory of what you saw during the trip. He might have had dozens of other\nvisions that night but all he ever remembered was the nurse from Mitchell\nBrothers Clinic for the Horrendously Horny. I guess I would have remembered\nher, too.\n\nThe second, more perplexing yarn comes from another 1960’s veteran, but I lost\ntouch with him and have no idea how his life worked out. He told me he took\nthe belladonna in his dorm room at the college he attended and then waited for\npsychedelic fireworks and transcendental experiences.\n\nNothing happened for a while.\n\nThen his friend Joe entered the room and asked what he was doing. He told Joe\nabout the belladonna and said he was waiting to feel an effect. Joe asked him\nsomething but he didn’t quite hear it.\n\nThen his friend Joe entered the room and asked what he was doing. He told Joe\nabout the belladonna and said he was waiting to feel an effect. Joe asked him\nsomething but he got distracted by having two Joes in the room. He tried to\nexplain about the two Joes but then one of them vanished. He tried to tell Joe\n“Hey, you came in before you came in,” but his tongue seemed unable to\nfunction and he thought he was merely grunting like a hog.\n\nThen his friend Joe entered the room, and this time he got The Fear. He fled\nthe room and the dorm and hopped on his motorcycle to Get Away, speeding\nacross the campus and down the nearest highway as fast as he could gun her.\n\nHe didn’t even own a motorcycle. I often wonder what the other people on\ncampus and on the highway thought they saw when he went racing past them on\nhis phantom bike . . . ?\n\nMedieval witches used belladonna in their brews, and some scholars think\nthat’s why they believed they could fly through the sky on broomsticks. Modern\nwitches — at least the ones I’ve known — prudently substitute the kinder,\ngentler cannabis.\n\nThe next morning my friend returned to “consensus reality\" and found himself\nin a ditch several miles from campus. He had no bumps or bruises — and nobody\nelse’s motorcycle either — but his right shoe and right sock had disappeared.\nHe never did find them and never remembered anymore of that night either.\n\nMy longest yarn involves my own experience with belladonna, in 1962. What can\nI say about why I did it? I hadn’t heard the above stories yet, I was young, I\nwas a damned eejit, and the guy who gave it to me said it was “just like\npeyote.”\n\nLet me explain that this happened on a farm in the deep woods.\n\nA few minutes after I took the stuff — drank it as a tea, actually — my wife\nArlen developed a severe case of Fangs and quickly turned into a beautiful,\nsexy, red-headed vampire with malice in her eyes. I immediately rushed to the\nkitchen sink, stuck a finger down my throat and forced several painful fits of\nvomiting. When I could vomit no more I told her — she looked normal again for\na moment: beautiful, sexy, red-headed but friendly, not vampirish — “This is a\nBad Trip, but I’ll find my way back to you, I promise.”\n\nThose were the last sane words I spoke for the next 12 hours.\n\nI remember taking a long walk through a forest of magic green jewels with the\nTin Woodsman of Oz. Later, the next day, it became clear that this was Jeff, a\nfriend Arlen had phoned to help me through the Emergency. He was walking me\naround our cabin, thinking fresh air might help.\n\nI remember some dwarfs in Nazi uniforms trying to shove me into a furnace\nliterally “as hot as Hell.” I have never felt more terror in my life.\n\nBlank space: memory loss.\n\nI remember thinking the worst was over and trying to tell Arlen and Jeff that\nsome parts of it were quite good, really. I was lighting one cigarette after\nanother, chain-smoking I thought. Jeff and Arlen saw me striking the lighter\nrepeatedly but I never did have a cigarette in my mouth.\n\nI remember trying to explain something I had discovered Out There. Arlen wrote\nit down. The note said, “The literary critics will all have to be shot because\nof the Kennedy administration in Outer Space of the Nuremberg pickle that\nexploded.”\n\nNot quite as good as the last words of Dutch Schultz, I’d say, but a bit\nbetter than what William James brought back from his nitrous oxide adventure:\n“Over all, there is a smell of fried onions.”\n\nAround dawn, I had to go to the outhouse. Jeff accompanied me to make sure I\ndidn’t wander off into the Pink Dimension or get lost amid the buzzing and\nwhistling things in the Realm of Thud.\n\nI opened the outhouse door and found Jeff already in there. I closed the door\nand told him, “I can’t go in. You’re already in there.”\n\nHe persuaded me reasonably that he wasn’t in there, but outside with me, so I\nopened the door again, found nobody inside and took a healthy crap.\n\nI felt even closer to “normal” when I came out, but then I noticed King Kong\npeeking at me over the top of the trees. He seemed whimsical and\nunthreatening, and when I looked again he turned into just another tree.\n\nThe next day I moved slowly back into the ordinary world, and by evening I\nfelt well enough to go to a movie, Kurasawa’s The Seven Samurai. I enjoyed the\nfirst half, especially the innovative technique of alternating between black-\nand-white and color, but in the second half Toshiro Mifune’s nose started\ngrowing like Pinocchio’s and I knew I was hallucinating again, which vexed me\na bit.\n\nNo more flashbacks occurred for about a month and then one day all the people\nin the supermarket turned into iguanas. That only lasted a few seconds, and it\nwas the last of the trip. I never tried this nefarious chemical again, and I\nhope to gawd you won’t either.\n\nMy last story I heard from novelist William S. Burroughs, who bought some\n“morphine” once that some wiseacre had cut with belladonna. He never\nremembered anything of the experience, but a friend did: he said that at one\npoint William walked to the window, opened it and stuck a leg out.\n\n“What the fuck you doing?” the friend asked.\n\n“Going down for some cigarettes,” William replied. The friend grabbed him and\ndragged him back into the room, which was on the third floor.\n\n“Bella donna,” by the way, means beautiful lady in Italian. Go figure.\n\n  \n\nTHOUGHTS TO PONDER\n\n  \n\nThe State — all it has, it has stolen!\n\nIt even bites with stolen teeth!\n\n  \n\n— F.W. Nietzsche\n\n\n#### The Relativity of “Reality”\n\n  \n\n1\\. From the viewpoint of semantics, “reality” is a multi-ordinal concept,\nhaving different meanings on different levels of abstraction. On the lowest\nlevel of abstraction “reality” refers to immediate sensory consistency. “Is\nthere really a kangaroo in that chair?” can be answered by obtaining the\nconsensus of the group; or, if everybody is stoned, by bringing in some\nobjective observers with objective instruments, etc. On the highest level of\nabstraction, “reality” refers to logical consistency with a body of\nestablished scientific fact and theory. “Is entropy real?” can be answered by\nconsulting a reliable textbook on thermodynamics. Between the level of\nkangaroo and the level of entropy, there are many other levels of abstraction\nand, hence, many kinds of “reality.”\n\nFor instance, “Is the Gross National Product real?” is a question on a certain\nlevel of abstraction; and if equally intelligent people can, and do, argue\nabout this, it is because they are talking on different levels of abstraction\nand are not aware of the fact that there are different levels of abstraction\nand different kinds of “reality.”\n\nI call this the semantic relativity of “reality.”\n\n2\\. Every tribe has its own “reality — map,” or worldview, or weltanschauung.\nWhat is “real” to the Eskimo is not what is “real” to the Zuni Indian or the\nCongolese or the Japanese Buddhist or the German businessman or the Russian\ncommissar, etc. If you travel around the world with the naive assumption that\neverybody is living in the same “reality,” you will make numerous embarrassing\nmistakes, insult countless people unintentionally, make a splendid ass of\nyourself and generally contribute to the worldwide belief that tourists are a\nCurse of God sent to punish people for their sins. To recognize that every\nculture, and sub-culture, has its own “reality” is the prerequisite of\nsophistication, tact, and true tolerance. Otherwise you come on like the\nEnglishman who claimed all Chinese understand English if you just shout loud\nenough.\n\nI call this the anthropological, or cultural, relativism of “reality.”\n\n3\\. Every nervous system creates its own “reality.” Out of the billions, or\nbillions of billions, of energies intersecting the room in which you read\nthis, your brain, performing 100,000,000 processes per minute (almost all of\nthem unconscious to those circuits called the ego and recognized as “me”)\narranges a few hundred or thousand into the Gestalt which you experience as\nthe “reality” of the room. To demonstrate this, in my Info-Psychology classes,\nI will have the students describe the hall outside the lecture room; no two\nwill describe exactly the same hall.\n\nOr, I will have everybody write down what they hear in the room during a\nminute of clock-time; no two lists of these sounds will be identical. A\nvariety of chemicals introduced into the nervous system, or direct brain\nstimulation with electrical impulses, or yoga, etc., will create an entirely\ndifferent neurological “reality” while you are still sitting in the \"same”\nroom.\n\nI call this neurological relativism, or the relativity of perceived “reality.”\n\n4\\. Two scientists moving at different accelerations can measure the same\nphenomenon with equally accurate instruments and obtain totally different\nreadings of its extensions in the space and time dimensions. (Einstein,\nSpecial Relativity.) On the quantum level, a variety of different\nphilosophical reality-maps, or “models,” describe equally well both the\nexperimental data and the mathematical equations that are known to “fit” the\ndata. Any attempt to get around this by adding more sophisticated instruments\nleads to adding still more sophisticated instruments to monitor the first set,\nand so on, forever. (Von Neumann’s “catastrophe of the infinite regress.”)\n\nI call this physical Relativity, or the relativity of instrumental “reality.”\n\nIn conclusion, “reality” is a concept borrowed from the theologians who, being\nbankrupt, are in no position to loan anything to anybody. We would do better\nto restrict ourselves to questions that can be answered. Such questions take\nthe form, “At this date, with the knowledge presently possessed by humanity,\nwhich model best accords with the facts?”\n\nWhen it turns out, as it usually does these days, that several models work\nequally well, we might then ask: which models are most amusing? most\noptimistic? most worthy of our time and energy? most elegant and esthetic? And\nwe can keep in mind, too, biologist J.B.S. Haldane’s warning, “The universe\nmay be not only stranger than we think, but stranger than we can think.”\n\n\nOld Man On A Balcony:\n\nViews Of Monterey Bay #16\n\n  \n\nSome waves cry “Terror!”\n\n  \n\nHitting the beach like boulders:\n\n  \n\nDark night: darker thoughts.\n\n\n#### Committee for Surrealist\n\n#### Investigation of Claims of the Normal\n\n#### (CSICON)\n\n  \n\nI wrote this baby somewhere around 2000 for some website that no longer\nexists.\n\n  \n\nDublin, 1986. I had given a talk to the Irish Science-Fiction Society and the\nquestion period began.\n\n“Do you believe in UFOs?” somebody asked.\n\n“Yes, of course,” I answered.\n\nThe questioner, who looked quite young, then burst into a long speech,\n“proving” at least to his own satisfaction that all UFOs “really are” sun-dogs\nor heat inversions. When he finally ran down I simply replied, “Well, we both\nagree that UFOs exist. Our only difference is that you think you know what\nthey are and I’m still puzzled.”\n\nAn elderly gentleman with blonde-white hair and a florid complexion cried out\nin great enthusiasm, “By God, sir, you’re right. I myself am still puzzled\nabout everything!”\n\nAnd thus I met Timothy F.X. Finnegan, Dean of the Royal Sir Myles nu gCopaleen\nAstro-Anomalistic Society, Dalkey, sometime lecturer at Trinity College,\nDublin, and founder of the Committee for Surrealist Investigation of Claims of\nthe Normal.\n\nIn fact, Prof. Finnegan signed me up as a member of CSICON that very night, in\nthe Plough and Stars pub over our ninth or tenth pint of Ireland’s most\nglorious product, linn dubh, known as Guinness to the ungodly.\n\nNow I hear that Prof. Finnegan has died, or at least they took the liberty of\nburying him, and I feel that the world has lost a great man.\n\nCSICON, however, lives on and deserves more attention than it has received\nhitherto. Prof. Finnegan always asserted that the idea for CSICON derived from\na remark passed by an old Dalkey character named Sean Murphy, in the Goat and\nCompasses pub shortly before closing time on 23 July 1973.\n\nActually, it started with two old codgers named O’Brian and Nolan discussing\nthe weather. “Terrible rain and wind for this time of year,” O’Brian ventured.\n\n“Ah, faith,” Nolan replied, “I do not believe it is this time of year at all,\nat all.”\n\nAt this, Murphy spoke up. “Ah, Jaysus,” he said, “I’ve never seen a boogerin’\nnormal day.” He paused to set down his pint, then added thoughtfully, “And I\nnever met a fookin’ average man neither.”\n\n(About Sean Murphy nothing else appears in the record except a remark gleaned\nby Prof. LaPuta from one Nora Dolan, a housewife of the vicinity: “Sure, that\nMurphy lad never did any hard work except for getting up off the floor and\nnavigating himself back onto the barstool, after he fell off, and he only did\nthat twice a night.”)\n\nBut Murphy’s simple words lit a fire in the subtle and intricate brain of\nTimothy F.X. Finnegan, who had just finished his own fourteenth pint (de Selby\nsays his fifteenth pint). The next day the aging Finnegan wrote the first two-\npage outline of the new science he called ’patapsychology, a term coined in\nsalute to Alfred Jarry’s invention of ’pataphysics.\n\nFinnegan’s paper began with the electrifying sentence, “The average Canadian\nhas one testicle, just like Adolf Hitler — or, more precisely, the average\nCanadian has 0.96 testicles, an even sadder plight than Hitler’s, if the\naverage Anything actually existed.” He then went on to demonstrate that the\nnormal or average human lives in substandard housing in Asia, has 1.04\nvaginas, cannot read or write, suffers from malnutrition and never heard of\nSilken Thomas Fitzgerald or Brian Boru. “The normal,” he concluded “consists\nof a null set which nobody and nothing really fits.”\n\nThus began the science of ‘patapsychology, Prof. Finnegan’s most enduring, and\nendearing, contribution to the world — aside from the computer-enhanced photos\nof the Face on Mars with which he endeavored to prove the Face depicted Moishe\nHorwitz, his lifelong mentor and idol. This, of course, remains highly\ncontroversial, especially among disciples of Richard Hoagland, who believe the\nFace looks more like the Sphinx, those who insist it looks like Elvis to them,\nand the dullards who only see it as a bunch of rocks.\n\nNobody should confuse ’patapsychology with parapsychology, although this\nprecise misunderstanding evidently inspired the long and venomous diatribes\nagainst Finnegan by Prof. Sheissenhosen of Heidelberg.\n\n(We need not credit the allegations of Herr Doktor Hamburger that\nSheissenhosen also dispatched the three separate letter-bombs sent to Finnegan\nin 1982, 1983 and 1987. Even in the most heated academic debate some limits of\ndecorum should remain, one would hope.)\n\nSheissenhosen evidently believed that “parapsychology” represented an\nunprovoked attack on his language and thought, and that Finnegan often leaped\nfrom shadows; he even suspected the Dalkey sage of slinking and of hiding\nbehind a belly laugh, although the latter seems physiologically impossible. (I\ntried it once and found it made me more visible, not less.) In fact,\nSheissenhosen never did correct his original error of misreading\n’patapsychology as parapsychology. You will find more about the Sheissenhosen-\nFinnegan — LaPuta-Hamburger controversy in deSelby’s Finnegan: Enigma of the\nOccident, Tourneur’s Finnegan: Homme ou Dieu? and/or Sheissenhosen’s own\nFinneganismus und Dummheit, 6 volumes.\n\n  \n\n’Patapsychology begins from Murphy’s Law, as Finnegan called the First Axiom,\nadopted from Sean Murphy. This says, and I quote, “The normal does not exist.\nThe average does not exist. We know only a very large but probably finite\nphalanx of discrete space-time events encountered and endured.” In less\ntechnical language the Board of the College of ‘Patapsychology offers one\nmillion Irish punds (around $1,400,000 American) to any “normalist” who can\nexhibit “a normal sunset, an average Beethoven sonata, an ordinary Playmate of\nthe Month, or any thing or event in space-time that qualifies as normal,\naverage or ordinary.”\n\nIn a world where no two fingerprints appear identical, and no two brains\nappear identical, and an electron does not even seem identical to itself from\none nanosecond to another, ‘patapsychology seems on safe ground here.\n\nNo normalist has yet produced even a totally normal dog, an average cat, or\neven an ordinary Chickadee.\n\nAttempts to find an average Bird of Paradise, an ordinary haiku or even a\nnormal cardiologist have floundered pathetically. The normal, the average, the\nordinary, even the typical, exist only in statistics; i.e., the human\nmathematical mindscape. They never appear in external space-time, which\nconsists only and always non-normal events in non-normal series.\n\nThus, unless you’re an illiterate and malnourished Asian with exactly 1.04\nvaginas and 0.96 testicles, living in substandard housing, you do not qualify\nas normal but as abnormal, subnormal, supernormal, paranormal or some variety\nof non-normal.\n\nThe canny will detect here the usual Celtic impulse to make hash out of\neverything that seems obvious and incontrovertible to Saxons, grocers and\nother Fundamentalist Materialists.\n\nIn the patapsychological model, the normal having vanished, most\ngeneralizations, especially about nonmathematical groups, disappear along with\nit. The monorchoid Mr. Hitler, for instance, could not generalize about “the\nJews” within the patapsychological model, because first he would have to find\na normal or average Jew, which appears as intractable to demonstration as\nexhibiting the Ideal Platonic Jew (or the Ideal Platonic Chicken Farm complete\nwith Ideal Platonic Chickenshit).\n\nAs Korzybski the semanticist said, all we can ever find in space-time consists\nof Jew-1, Jew-2, Jew-3, etc. to Jew-n. (For the nonmathematical, that means a\nlist comprising Abraham, Sarah, Moses, Ruth, Jesus, Woody Allen, Richard\nBandler, Felix Mendelssohn, Sigmund Freud, Paulette Goddard, Betty Grable,\nNoam Chomsky, Bernard Baruch, Paul Newman, the Virgin Mary, Albert Einstein,\nLillian Hellman, Baron Rothschild, Ayn Rand, Max Epstein, Emma Goldman, Saul\nBellow, etc. etc. etc. to the final enumeration of all Jews alive or dead.)\n\nEach of these, on inspection, will have different fingerprints, different\nbrains, different neuro-immunological systems, different eyes, ears, noses,\netc.; different life histories, different conditioning and learning, etc.; and\ndifferent personalities, hobbies, passions, etc . . . and none will serve as a\nnorm or Ideal Form for all the others.\n\nTo say it otherwise, world Jewish population stood at about 10 million when\nHitler formed his generalizations.\n\nHe could not possibly have known more than at maximum about 500 of them well\nenough to generalize about them; considering his early prejudices, he probably\nknew a lot fewer than that. But taking 500 as a high estimate, we find he\ngeneralized about 10 million individual persons on the basis of knowledge\nlimited to around 1/20,000 or 0.00005% of them.\n\nIt seems, then, that Nazism could not have existed if Hitler knew the\ndifference between norms or averages (internal estimates, subject to error due\nto incomplete research or personal prejudice) and the phalanx of discrete non-\nnormal events and things (including persons) that we find in the sensory\nspace-time continuum outside.\n\nSimilarly, the male human population currently stands at 3 billion 3 million\n129 thousand, more or less (3,004,129,976, the last time I checked the World\nGame Website a while ago). Of these 3 billion+ discrete individuals, Robin\nMorgan, Andrea Dworkin and other Radical Feminists probably have not known\nmore than about 500 to generalize from. This means that Rad Fem dogma consists\nof propositions about 3 billion critters based on examination of less than\n0.00000001 percent of them. This amounts to a much more reckless use of\ngeneralization than Hitler’s thoughts on Judaism. You can no more find the\nmale norm from Gandhi, Bozo, Gen. George Custer, Buddha, Bill Clinton, Louis\nPasteur, Osama bin Laden, Kung Fu Dzu, Bruno, Father Damien, Michelangelo,\nMozart, Ted Bundy, etc. than you can find the Jewish norm from Emma Goldman,\nHarpo Marx, Felix Mendelssohn, Spinoza, Barbra Streisand, Nathaniel Branden,\nEmma Lazarus, Jerry Seinfeld, etc.\n\nNow you know how the word “feminazi” got into the language. The two ideologies\nhave a strong isomorphism. They both confuse the theoretical norm with a vast\narray of different individuals — and they both have no idea how to create even\na tolerably scientific norm (which will still differ in many respects from the\nactual series of individuals the norm allegedly covers).\n\nCSICON applies the same Deconstructive logic all across the board.\n\nFor instance, to return to our starting point, whatever your idea of the\n“normal” UFO — whether you consider it a spaceship, a secret U.S. government\nweapon, a hoax, or a hallucination, etc. — such a general idea will render you\nincapable of forming a truly objective view of the next UFO that comes along.\nThe only way to cancel such pre-judgment lies in 'patapsychology (and in\ngeneral semantics). You must remember the difference between the individual\nand unpredictable event that gets called a UFO and your past generalizations\nabout “the UFO” or the “normal UFO.”\n\nOtherwise you will only note how this UFO fits your Ideal UFO and will\nunconsciously ignore how it differs therefrom. This mechanical reflex will\nplease your ego, if you like to feel you know more than most people, but it\nwill prove hazardous to your ability to observe and think carefully.\n\nPeople who think they know all about Jews or males or UFOs never see a real\nJew or male or UFO. They see the generalized norm that exists only in their\nown brains. We never know “all” — we only know what I dub sombunall — some-\nbut-not-all. This applies also to dogs (the ’patapsychologist will not say “I\nlove them,” “I hate them,” “I fear them,” etc.), and to plumbers, bosses,\nright-wingers, left-wingers, cats, lizards, sitcoms, houses, nails, Senators,\nwaterfalls, ostriches and all other miscellaneous sets or groups.\n\nPersonally, I see two or three UFOs every week. This does not astonish me, or\nconvince me of the spaceship theory, because I also see about 2 or 3 UNFOs\nevery week — Unidentified Non-Flying Objects. These remain unidentified (by\nme) because they go by too fast or look so weird that I never know whether to\nclassify them as hedgehogs, hobgoblins or helicopters — or as stars or\nsatellites or spaceships — or as pookahs or pizza — trucks or probability\nwaves. Of course, I also see things that I feel fairly safe in identifying as\nhedgehogs or stars or pizza trucks, but the world contains more and more\nevents that I cannot identify fully and dogmatically with any norm or\ngeneralization. I live in a spectrum of probabilities, uncertainties and\nwonderments.\n\nPerhaps I got this way by studying Finnegan’s work. Or maybe I just drank too\nmuch linn dubh during my years in Ireland.\n\nO rare, Tim Finnegan!\n\n  \n\n￼\n\n![einstein-tongue-1951.jpg](../Images/image-TXLTFXM9.jpg)\n\n  \n\nTHOUGHTS TO PONDER\n\n  \n\nIf we knew what it was we were doing, it would not be called research, would\nit?\n\n  \n\n— Albert Einstein\n\n\nPart III\n\n\n### IN DEFENSE OF THE DAMNED\n\n  \n\nSecrecy — the first refuge of incompetents — must be at a bare minimum in a\ndemocratic society . . .\n\n  \n\n— House Committee on Government Operations, 1960\n\n  \n\nEverybody knows that corruption thrives in secret places . . . it is a fair\npresumption that secrecy means impropriety.\n\n  \n\n— Woodrow Wilson\n\n  \n\n[The Bush] administration is . . . even more secretive than the Nixon\nadministration.\n\n  \n\n— Larry Klayman, Judicial Watch\n\n  \n\nGeorge W. Bush and Richard B. Cheney have created the most secretive\npresidency of my lifetime. Their secrecy is far worse than during Watergate,\nand it bodes even more serious consequences.\n\n  \n\n— John W. Dean, former counsel to Richard Nixon\n\n\nOld Man on a Balcony:\n\nViews of Monterey Bay #17\n\n  \n\nNew bud on the vine:\n\n  \n\nBut three thousand miles due East\n\n  \n\nWall Street still smoulders.\n\n\n#### Guns & Dope Party\n\n  \n\nThis has passed through several drafts c. 2000-2004 and in 2002 I actually ran\nfor Governor of California on more or less this platform . . . Currently, I\nsupport Everybody for President; vide infra, dig?\n\n  \n\n￼\n\n![1-GADP-Flag.jpg](../Images/image-RS7856O9.jpg)\n\n  \n\nA free people ought not only to be armed and disciplined, but they should have\nsufficient arms and ammunition to maintain a status of independence from any\nwho might attempt to abuse them, which would include their own government.\n\n  \n\n— George Washington\n\n  \n\nMust we always choose the lesser of two Bonesmen?\n\n  \n\nMay we Suggest\n\n  \n\nEVERYBODY FOR PRESIDENT\n\n  \n\nWell, at least everybody who feels ready for the responsibility of self-\ngovernment. Those who still need a Big Daddy or a Big Momma to discipline and\ndominate them should vote for whatever fuehrer or saviour they like best.\n\nIf you want self-government don’t vote for the Two Lying Bastards of the\nDemocan and Republicrat parties . . . or for any minority party that also\nwants to govern you.\n\n  \n\nWRITE IN YOUR OWN NAME\n\n  \n\nThe Guns and Dope Party advocates:\n\n[1] guns for those who want them, no guns forced on those who don’t want them\n(pacifists, Quakers, etc.)\n\n[2] drugs for those who want them; no drugs forced on those who don’t want\nthem (Christian Scientists, Natural Hygienists, etc.)\n\n[3] an end to Tsarism and a return to constitutional democracy\n\n[4] equal rights for ostriches\n\n  \n\nI’m as mad as Hell, and I’m not going to take this anymore!\n\n  \n\n— Howard Beale\n\n  \n\n￼\n\n![9-Gadsden-Flag.jpg](../Images/image-P2P4K8EC.jpg)\n\n  \n\nPosition Paper #5\n\n  \n\nThe official flag: the Gadsden flag — the oldest American flag of all.\n\n  \n\nOfficial motto: “Like what you like, enjoy what you enjoy — and don’t take\ncrap from anybody!”\n\n  \n\nFirst order of business on assuming office: Fire 33% of the Congress (names\nselected at random), and replace them with full-grown adult ostriches, whose\nmysterious and awesome dignity will elevate the suidaen barbarity long\nestablished there.\n\n  \n\n￼\n\n![2-33PercentOstriches.jpg](../Images/image-5OLRXHE8.jpg)\n\n  \n\nBoth the gun owners and the dopers (medical, religious and/or recreational)\nfeel like minorities, and the TSOG (Tsarist Occupation Government) agrees with\nthis estimate of their weakness.\n\nOur contention holds that in the Western States both groups working together\nmake a MAJORITY.\n\nErgo, they have much to gain and nothing to lose in combining forces. We have\nNO Ideology, NO “theory” and NO arguments in favor of guns-n-dope people\njoining together — except this:\n\n  \n\nTOGETHER WE CAN WIN\n\n  \n\nEach side only has to realize this and agree: “We’ll tolerate their hobbies if\nthey’ll tolerate ours” and we can drive the Tsarists back to Russia!\n\n  \n\n￼\n\n![3-TolerateHabits.jpg](../Images/image-PL9ZR73Z.jpg)\n\n  \n\nThe Guns and Dope Pledge\n\n  \n\nWe will never, never, NEVER vote for any candidate who advocates destroying\nthe Second Amendment;\n\nWe will never, never, NEVER vote for any candidate who advocates destroying\nthe Tenth Amendment;\n\nWe will never, never, NEVER cease or rest in our efforts to abolish Tsarism\nand restore constitutional democracy in general and especially the First\nAmendment.\n\nIf you agree with this, why not print a few copies and send them to “your”\nrepresentatives in Congress\n\n  \n\nPosition Paper #23\n\n  \n\nLittle Tony was sitting on a park bench munching on one candy bar after\nanother.\n\nAfter the 6th candy bar, a man on the bench across from him said, “Son, you\nknow eating all that candy isn’t good for you. It will give you acne, rot your\nteeth, and make you fat.”\n\nLittle Tony replied, “My grandfather lived to be 107 years old.” The man\nasked, “Did your grandfather eat 6 candy bars at a time?” Little Tony\nanswered, “No, he minded his own fucking business.”\n\n  \n\n￼\n\n![5-Freetopia.jpg](../Images/image-HCAR1C98.jpg)\n\n  \n\nA Maybe Map of the Future\n\nPosition Paper 23e\n\n  \n\nThe goal of the Guns and Dope Party — return to constitutional democracy —\nwill probably remain unacceptable to many in this country (the Terminally\nGullible).\n\nEspecially in the middle of the continent, a majority seems to prefer the\ntyranny of TSOG and its associated “faith-based organizations.” Thus, Western\nSecession must remain on our agenda, at least as a distinct “maybe.”\n\nAfter we all vote to take the responsibility of self-government upon\nourselves, we will end all “faith-based” bans on scientific and medical\nfreedom, including the verbots against orgonomic medicine, LSD, cloning, stem-\ncell research, medical marijuana, alternative medicine, etc.\n\nEvery citizen will choose the type of health care he or she wants, just as\nthey did in the old U.S. before the Tsarist take-over.\n\nEvery scientist will research whatever she or he finds most interesting.\n\nIn short, we will become full members of the “civilized” world again, and\nostriches will have the respect they deserve.\n\n  \n\nPosition on Prostitution\n\n  \n\nIf fucking is legal,\n\nand selling is legal,\n\nthen selling fucking should be legal.\n\n  \n\n— paraphrased from the philosopher Carlin\n\n  \n\nAlso Sprach RAW\n\n  \n\nIf I announce (as I’ve considered) that God supports the Guns & Dope Party,\nhow many of you will consider that claim\n\n1\\. schizo or delusional\n\n2\\. genuine Divine intervention\n\n3\\. a con game\n\n4\\. a hoax, satire, jape, etc.\n\n  \n\nHow do you rank the similar claims of Bozo, Jerry Falwell, Son of Sam, the\nTsars of Russia, the Tsars of USA, Osama bin Laden, the popes of Rome, etc.?\n\nAnyway, God has personally endorsed the GUNS AND DOPE PARTY and cursed\nTsardom.\n\nHe told me so, speaking through an ostrich named Olga who co-starred with\nOrson Welles in a thriller called Southern Star.\n\nOlga spoke in Orson’s most sonorous and resonant voice, the one he used for\nFather Mapple in Moby Dick. (Orson, in another second-rate villain role, spoke\nin a lispy, squeaky, very Gay, upper-class English voice, which made the\ncharacter, a bandit chief, a lot more interesting.)\n\nAt the climax, Olga said, looking through the camera — at me! “I am the Lord\nGod. Do you believe that?”\n\nI giggled and said, “No . . . I think I just took too much pain medicine . .\n.”\n\n“Good,” said Olga/Orson/Father Mapple.\n\n“I’m sick and tired of gullible fools like Bozo and Son of Sam. Just keep an\nopen mind, old chum, and watch me rear back and work some Miracles for the\nGuns and Dope Party. Damn those pesky Tsarists!! By the way, don’t forget your\npromise to include 33% ostriches in your government.”\n\n  \n\n#### Governments lie.\n\n  \n\n— I.F. Stone\n\n  \n\nWhen I asked Olga how to contribute most to the coming unity of all\ncritterkind, instilling respect for \"all life however small\" as it says in the\nUpanishads, she suggested appointing ostriches as 1/3 of the legislature. Of\ncourse, some left-wing aardvarks have complained about this (they call it\n\"bipedal chauvinism\") but I trust Olga.\n\nMost humans haven’t gotten to the level of realizing the personhood of other\nraces yet, you know. Bipedalism represents a great leap forward toward\nuniversal critterkind, and you have to take these things one step at a time.\nThe six-legged majority still inspire fear and loathing in backward societies.\n\nIf Olga doesn’t talk to you, you need more pain medicine, and frankly I don’t\nunderstand how you’ve survived three years of Bozo without it.\n\nMaybe you should try the Bible or the Koran or Chinese fortune cookies.\n\n  \n\n￼\n\n![11-CNN.jpg](../Images/image-WDT3INAQ.jpg)\n\n  \n\nTaxes\n\n  \n\nQuestion: Would the Guns and Dope Party attempt to eliminate all taxes?\n\nAnswer: We’d follow Lysander Spooner’s voluntary tax plan combined with the\nlightspeed of Internet. Every citizen would receive a semi-annual Republic\nbudget, telling what the Republic of Freetopia wanted to do for them or to\nthem, and each would send in their share of the fee for whatever projects\nseemed sensible and useful to them. Nobody would pay a penny for anything that\nseemed pointless, useless, invasive, tyrannical or even annoying to them. If\nnobody paid for a project, it would get dumped for lack of funding.\n\nAs Spooner wrote earlier:\n\n  \n\nConstitutions are utterly worthless to restrain the tyranny of governments,\nunless it be understood that the people will by force compel the government to\nremain within constitutional limits. Practically speaking, no government knows\nany limits to its power except the endurance of the people.\n\n  \n\nVoluntary taxation expresses the endurance of the people directly and\nimmediately, \"before the horse gets out of the stable.\"\n\n  \n\n￼\n\n![4-Spooner-Ost.jpg](../Images/image-P44NXWEA.jpg)\n\n  \n\nA GOVERNMENT WHICH TAKES YOUR MONEY BY FORCE LIKE A COMMON THIEF WILL USE THIS\nSTOLEN MONEY TO FURTHER ENSLAVE YOU AND TO PREVENT ANY REBELLION ON YOUR PART.\n\n  \n\n— Olga Struthio\n\n  \n\nGod and Tsardom\n\n  \n\nTsarism represents an intermediate form between European monarchism and Asian\ndespotism, being, possibly, closer to the latter of these two.\n\n  \n\n— Leon Trotsky,\n\n  \n\nRussia’s Social Development and Tsarism\n\n  \n\n￼\n\n![6-PillBottle.jpg](../Images/image-LJLNNM3P.jpg)\n\n  \n\nThe Guns & Dope Party primarily wants to abolish Tsarism and restore\nconstitutional democracy in the California Republic. If our example inspires\nthe other 49 states, so much the better.\n\nWhy do we oppose Tsarism? How does the U.S. drug Tsar function?\n\nAllegedly, this Omniscient Official knows what drugs, herbs, compounds, etc.\nyou should use for your medical problems better than your doctor knows!!!!!!\n\nEven more magically, the Tsar \"knows\" this without doing any physical\nexamination of you, — blood pressure readings, other scientific tests, etc.\nthat your doctor does — and often from a distance of 3000 miles — and the Tsar\ndoes it without even looking at you, or talking to you!\n\nThe Tsar doesn’t even know if you have hangnail or cancer, AIDS or flu, belong\nto the senior set or haven’t even reached voting age yet. He can’t even\nclassify you as male, female or undecided.\n\nIn short, the Tsar knows nothing about you or your medical problems, by\nordinary data, but he still know more about your medical care than your doctor\nknows, by some supernatural means unknown to mere mortals.\n\nThis makes sense if and only if we have a devout faith that our Tsar, like the\nRussian Tsars \"of olde,\" receives guidance directly from \"God.\" No other, less\nspooky explanation fits the claims made by Tsardom.\n\nThe government accordingly spends more and more of our tax money financing\n\"faith-based organizations.\" Without faith we might relapse into scientific or\nrational thinking, which leads by a \"slippery slope\" toward constitutional\ndemocracy.\n\n  \n\n￼\n\n![8-TsarUncleSam.jpg](../Images/image-T7D3TJ6Y.jpg)\n\n  \n\nIt is not only the juror’s right, but his duty, to find the verdict according\nto his own best understanding, judgment and conscience, though in direct\nopposition to the directions of the court.\n\n  \n\n— John Adams\n\n  \n\nDo not annoy people at home. Do not pester them at work. Leave them alone, or\nthey will curse you.\n\n  \n\n— Lao-Dzu\n\n  \n\n￼\n\n![7-GADP-Flag2.jpg](../Images/image-ETW1XK3L.jpg)\n\n  \n\nWhy Olga Remains Essential\n\n  \n\nOlga remains essential to the serious, scientific and sincerely surrealist\naspects of the Guns and Dope Party. Personal liberty, scientific and medical\nfreedom, the rights of Imagination: all these appear dead or dying under the\ntyranny of Tsarism, and we all need to fight back \"by any means necessary.\"\n\nAfter all, this may become the last — the very last — battle for individual\nrights in this moribund Republic, before rampant medievalism closes down the\ndemocratic age.\n\nNONETHELESS, we all need Olga also. Without her, we might take ourselves — and\nfeatherless biped politics in general — too damned seriously, following the\nusual \"slippery slope\" downward from Ideology to Idiocy. We need the\nperspectives of our feathered cousins, no matter how weird they may sound at\ntimes.\n\nThus, while we stand beside the Gun Owners of America (www.gunowners.org) in\nstrict adherence to the Second Amendment we oppose what Jimmy Breslin called\n\"poor usage of a revolver.\"\n\nWe also oppose poor usage of napalm, bazookas, shrapnel, automatic rifles,\nnukes, etc. Common Errors in Usage of all of these seem rampant in the Tsarist\nStates, not only by the Goober government there, but increasingly by the\nbaffled and maddened citizens, which explains why we feel secession may become\nnecessary.\n\n  \n\nAs the philosopher William Claude Dukenfield [1889-1945] noted: \"Sooner or\nlater we must take the bull by the tail and look the facts in the face.\"\n\n  \n\nWHEN A GOVERNMENT FIRST TAKES YOUR MONEY BY FORCE AND THEN DISARMS YOU, IT\nDOES NOT HAVE YOUR BEST INTEREST AT HEART.\n\n  \n\n— \"Bob\"\n\n  \n\nRecommended URLs\n\n  \n\nPolitical philosophy in depth:\n\nwww.lysanderspooner.org\n\n  \n\nOur philosophical advisor:\n\nwww.rawilson.com\n\n  \n\nDeeper philosophy: www.madsci.org/~lynn/juju/surr/paranoia/CP.html\n\n  \n\nDeeper than deep:\n\nwww.kbuxton.com/discordia\n\n  \n\nMedical rights:\n\nwww.wamm.org\n\n  \n\nSelf-defense:\n\nwww.gunowners.org\n\n  \n\nMonetary policy: www.questionsquestions.net/docs04/declaration.html\n\n  \n\nTHOUGHTS TO PONDER\n\n  \n\nThe State is the coldest of all cold monsters and coldly it tells lies, and\nthis lie oozes from its lips: \"I, the State, am the people.\"\n\n  \n\n— F.W. Nietzsche\n\n  \n\n￼\n\n![10-Annie.jpg](../Images/image-GHL4MUFV.jpg)\n\n\n#### Damnation by Definition\n\n  \n\nThese fragments come from a book I started in 1964 called Authority and\nSubmission. When five publishers in a row rejected it, I gave up attempting\nbooks for six full years and only wrote shorter pieces. I still had a lot of\npessimism and masochism in those days.\n\nParts of Authority and Submission eventually got rewritten and incorporated\ninto Illuminatus! and Prometheus Rising.\n\n  \n\nThe most thoroughly and relentlessly Damned, banned, excluded, condemned,\nforbidden, ostracized, ignored, suppressed, repressed, robbed, brutalized and\ndefamed of all Damned Things is the individual human being. The social\nengineers, statisticians, psychologists, sociologists, market researchers,\nlandlords, bureaucrats, captains of industry, bankers, governors, commissars,\nkings, presidents, etc. are perpetually forcing this Damned Thing into\ncarefully prepared blueprints and perpetually irritated that the Damned Thing\nwill not fit into the slot assigned it. The theologians call it a sinner and\ntry to \"reform\" it. The governor calls it a criminal and tries to \"punish\" it.\nThe psychologist calls it a neurotic and tries to \"cure\" it. Still, the Damned\nThing will not fit into their slots.\n\nI once overheard two botanists arguing over a Damned Thing that had\nblasphemously sprouted in a college yard. One claimed that the Damned Thing\n\"was\" a tree and the other claimed that it \"was\" a shrub. They each had good\nscholarly arguments, and they were still debating when I left them.\n\nThe world is forever spawning Damned Things — things that are neither tree nor\nshrub, fish nor fowl, black nor white — and the categorical thinker can only\nregard the spiky and buzzing world of sensory fact as a profound insult to his\ncard-index system of classifications. Worst of all are the facts which violate\n\"common sense,\" that dreary bog of Stone Age prejudice and muddy inertia. The\nwhole history of science is the odyssey of a pixilated card-indexer\nperpetually sailing between such Damned Things and desperately juggling his\nclassifications to fit them in, just as the history of politics is the futile\nepic of a long series of attempts to line up the Damned Things and cajole them\nto march in regiment.\n\nEvery ideology is a mental murder, a reduction of dynamic living processes to\nstatic classifications, and every classification is a Damnation, just as every\ninclusion is an exclusion. In a busy, buzzing universe where no two snow\nflakes are identical, and no two trees are identical, and no two people are\nidentical — and, indeed, the smallest sub-atomic particle, we are assured, is\nnot even identical with itself from one microsecond to the next — every card-\nindex system is a delusion. \"Or, to put it more charitably,\" as Nietzsche\nsays, \"we are all better artists than we realize.\"\n\nIt is easy to see that the label \"Jew\" was a Damnation in Nazi Germany, but\nactually the label \"Jew\" is a Damnation anywhere, even where anti-Semitism\ndoes not exist. \"He is a Jew,\" \"She is a doctor,\" and \"He is a poet\" mean, to\nthe card indexing centre of the cortex, that my experience with him or her\nwill be like my experience with other Jews, other doctors, and other poets.\nThus, individuality is ignored when identity is asserted.\n\nAt a party, or any place where strangers meet, watch this mechanism in action.\nBehind the friendly overtures there is wariness as each person fishes for the\nlabel that will identify and Damn the other. Finally, it is revealed: \"Oh,\nshe’s an advertising copywriter\"; \"Oh, he’s an engine lathe operator.\" Both\nparties relax, for now they know how to behave, what roles to play in the\ngame. Ninety-nine percent of each has been Damned; the other is reacting to\nthe one percent that has been labeled by the card-index machine.\n\nCertain Damnations are socially and intellectually necessary, of course.\n\nA custard pie thrown in a comedian’s face is Damned by the physicist who\nanalyzes it according to the Newtonian laws of motion. These equations tell us\nwe want to know about the impact of the pie on the face, but nothing about the\nhuman meaning of pie-throwing.\n\nA cultural anthropologist, analyzing the social function of the comedian as\nshaman, court jester, and king’s surrogate, explains the pie-throwing as a\nsurvival of the Feast of Fools and the killing of the king’s double. This\nDamns the subject in another way.\n\nA psychoanalyst, finding an Oedipal castration ritual here, has performed a\nthird Damnation, and the Marxist, seeing an outlet for the worker’s repressed\nrage against the bosses, performs a fourth.\n\nEach Damnation has its values and uses, but is nonetheless a Damnation unless\nwe recognize its partial and arbitrary nature. The poet, who compares the pie\nin the comedian’s face with Decline of the West or his own lost love, commits\na fifth Damnation, but in this case the game element and the whimsicality of\nthe symbolism are safely obvious. At least, one would hope so; reading the New\nCritics occasionally raises doubts on this point.\n\nHuman society can be structured either according to the principle of authority\nor according to the principle of liberty.\n\nAuthority demands a static social configuration in which people act as\nsuperiors and inferiors: a sado-masochistic relationship.\n\nLiberty represents a dynamic social configuration in which people act as\nequals: an erotic relationship.\n\nIn every interaction between people, either Authority or Liberty becomes the\ndominant factor. Families, churches, lodges, clubs and corporations all seem\neither more authoritarian than libertarian or more libertarian than\nauthoritarian.\n\nIt becomes obvious as we proceed that the most pugnacious and intolerant form\nof authority is the State, which even today dares to assume absolutism which\nthe Church itself has long ago surrendered and to enforce obedience with the\nChurch’s old and shameful Inquisition. Every form of authoritarianism \"is,\" or\nat least acts like, a small \"State,\" even if it has a membership of only two.\nFreud’s remark to the effect that the delusion of one person is mental illness\nand the delusion of many persons is religion can be generalized: The\nauthoritarianism of one man is crime and the authoritarianism of many is\nState. Benjamin Tucker wrote quite accurately:\n\n  \n\nAggression is simply another name for government. Aggression, invasion,\ngovernment are interchangeable terms. The essence of government is control, or\nthe attempt to control. He who attempts to control another is a governor, an\naggressor, an invader; and the nature of such invasion is not changed, whether\nit be made by one man upon another man, after the manner of the ordinary\ncriminal, or by one man upon all other men, after the manner of an absolute\nmonarch, or by all other men upon one man, after the manner of a modern\ndemocracy.\n\n  \n\nTucker’s use of the word \"invasion\" is remarkably precise, considering that he\nwrote more than fifty years before the basic discovery of ethology.\n\nEvery act of authority is, in fact, an invasion of the psychic and physical\nterritory of another.\n\nEvery fact of science was once Damned. Every invention was considered\nimpossible. Every discovery was a nervous shock to some orthodoxy.\n\nEvery artistic innovation was denounced as fraud and folly. The entire web of\nculture and \"progress,\" everything on earth that is human-made and not given\nto us by nature, is the concrete manifestation of some person’s refusal to bow\nto Authority. We would own no more, know no more, and be no more than the\nfirst apelike hominids if it were not for the rebellious, the recalcitrant,\nand the intransigent. As Oscar Wilde truly said, \"Disobedience was man’s\nOriginal Virtue.\"\n\nThe human brain, which loves to read descriptions of itself as the universe’s\nmost marvelous organ of perception, is an even more marvelous organ of\nrejection. The naked facts of our economic game are easily discoverable and\nundeniable once stated, but conservatives — who are usually individuals who\nprofit every day of their lives from these facts — manage to remain oblivious\nto them or to see them through a very rose-tinted lens.\n\n(Similarly, the revolutionary ignores the total testimony of history about the\nnatural course of revolution, through violence, to chaos, back to the starting\npoint, in the form of a new tyranny.)\n\nWe must remember that \"thought\" means abstraction. In Einstein’s metaphor, the\nrelationship between a sensory or instrumental fact and our mental reception\nof that fact is not like the relationship between beef and beef-broth, a\nsimple extraction and condensation; rather, as Einstein goes on, it is like\nthe relationship between our overcoat and the ticket given us when we check\nour overcoat. In other words, human perception involves coding even more than\ncrude sensing.\n\nThe mesh of language, or of mathematics, or of a school of art, or of any\nsystem of human abstracting, gives to our mental constructs the structure, not\nof the original fact, but of the symbol system into which it is coded, just as\na mapmaker colors a nation purple not because it \"is\" purple but because his\ncode demands it. But every code excludes certain things, blurs other things,\nand overemphasizes still other things.\n\nNijinski’s celebrated leap through the window at the climax of Le Spectre de\nla Rose is best coded in the ballet notation system used by choreographers;\nverbal language falters badly in attempting to convey it; painting or\nsculpture could capture totally the magic of one instant, but one instant\nonly, of it; the physicist’s equation, Force = Mass x Acceleration, highlights\none aspect of it missed by all these other codes, but loses everything else\nabout it. Every perception is influenced, formed, and structured by habitual\ncoding habits-neurosemantic game habits — of the perceiver.\n\nAll authority is a function of coding, of game rules. Men have arisen again\nand again armed with pitchforks to fight armies with cannon; men have also\nsubmitted docilely to the weakest and most tottery oppressors. It all depends\non the extent to which coding distorts perception and conditions the physical\n(and \"mental\") reflexes.\n\nIt seems at first glance that authority could not exist at all if all men were\ncowards or if no men were cowards, but flourishes as it does because most men\nare cowards and some men are thieves. Actually, nowadays, the inner dynamics\nof cowardice and submission on the one hand and of heroism and rebellion on\nthe other are seldom consciously realized either by the ruling class or the\nservile class.\n\nSubmission is identified not with cowardice but with virtue, rebellion not\nwith heroism but with evil. To the Roman slave-owners, Spartacus was not a\nhero and the obedient slaves were not cowards; Spartacus was a villain and the\nobedient slaves were virtuous. The obedient slaves believed this also. The\nobedient always think of themselves as virtuous rather than cowardly.\n\nIf authority implies submission, liberation implies equality; authority exists\nwhen some persons obey others, and liberty exists when people do not obey\nother mere humans. Thus, to say that authority exists is to say that class and\ncaste exist, that submission and inequality exist.\n\nTo say that liberty exists is to say that classlessness exists, to say that\nbrotherhood and equality exist. Authority, by dividing people into classes,\ncreates dichotomy, disruption, hostility, fear, disunion. Liberty, by placing\nus all on an equal footing, creates association, amalgamation, union,\nsecurity. When the relationships between people are based on authority and\ncoercion, they are driven apart; when based on liberty and non-aggression,\nthey are drawn together. The facts are self-evident and axiomatic. If\nauthoritarianism did not possess the in-built, preprogrammed double-bind\nstructure of a Game Without End we would long ago have rejected it and\nembraced libertarianism.\n\nThe usual pacifist complaint about war, that young men are led to death by old\nmen who sit at home manning bureaucrats’ desks and taking no risks themselves,\nmisses the point entirely. Demands that the old should be drafted to fight\ntheir own wars, or that the leaders of the warring nations should be sent to\nthe front lines on the first day of battle, etc., are aimed at an assumed\n\"sense of justice\" that simply does not exist.\n\nTo the typical submissive citizen of authoritarian society, it is normal,\nobvious and \"natural\" that he should obey older and more dominant males, even\nat the risk of his life, even against his own kindred, and even in causes that\nare unjust or flagrantly absurd.\n\nThe mechanism by which authority and submission are implanted in the human\nmind is coding of perception. That which fits into the code is accepted; all\nelse is Damned to being ignored, brushed aside, unnoticed, and — if these fail\n— it is Damned to being forgotten. A worse form of Damnation is reserved for\nthose things which cannot be ignored. These are daubed with the brain’s\nprojected prejudices until, encrusted beyond recognition, they are capable of\nbeing fitted into the system, classified, card-indexed, buried. This is what\nhappens to every Damned Thing which is too prickly and sticky to be\nexcommunicated entirely. As Josiah Warren remarked, \"It is dangerous to\nunderstand new things too quickly.\" Almost always, we have not understood\nthem. We have murdered them and mummified their corpses.\n\nA monopoly on the means of communication may define a ruling elite more\nprecisely than the celebrated Marxian formula of \"monopoly in the means of\nproduction.\" Since humans extend their nervous systems though channels of\ncommunication like the written word, the telephone, radio, TV, Internet, etc.,\nwhoever controls these media controls part of the nervous system of every\nmember of society. The contents of these media become part of the contents of\nevery individual’s brain.\n\nThus, in preliterate societies, taboos on spoken word are more numerous and\nmore Draconic than at any more complex level of social organization.\n\nWith the invention of written speech — hieroglyphic, ideographic, or\nalphabetical — the taboos are shifted to this medium; there is less concern\nwith what people say and more concern with what people write. (Some of the\nfirst societies to achieve literacy, such as Egypt and the Mayan culture of\nancient Mexico, evidently kept a knowledge of hieroglyphs a religious secret\nwhich only the higher orders of the priestly and royal families were allowed\nto share.)\n\nThe same process repeats endlessly: Each step forward in the technology of\ncommunication is more heavily tabooed than the earlier steps.\n\nThus, in America today (post-Lenny Bruce), one seldom hears of convictions for\nspoken blasphemy or obscenity; prosecution of books still continues, but\nhigher courts increasingly interpret the laws in a liberal fashion, and most\nwriters feel fairly confident that they can publish virtually anything; movies\nare growing almost as decentralized as books, although the fight is still\nheated in this area; television, the newest medium, remains encased in\nneolithic taboo. (When the TV pundits committed lese majeste after an address\nby the then Dominant Male, a certain Richard Nixon, one of his lieutenants\nquickly informed them they had overstepped, and the whole tribe — except for\nthe dissident minority — cheered for the reassertion of tradition.) When a\nmore efficient medium [Internet?] arrives, the taboos on television will\ndecrease.\n\n\nOld Man on a Balcony:\n\nViews of Monterey Bay #18\n\n  \n\nGrey and pastel pink —\n\n  \n\nA water-color painting —\n\n  \n\nThis light before dawn.\n\n\n#### CyberRevolution Montage\n\n  \n\nwritten in Los Angeles 1989\n\n  \n\n1954: Bard College, Annandale-on-Hudson, NY . . . It was the first time I ever\nheard Buckminster Fuller speak. He said that by the late 1980’s we would all\nbe living in a \"one-town world.\" In 1988, I have been ostensibly \"living\" in\nLos Angeles, but in these twelve months I have visited or re-visited Maui, San\nJose (2 times), Berkeley, San Diego, Vancouver, Seattle (3 times), Phoenix,\nBoulder, Dallas (2 times), Philadelphia, Wilmington, New York (2 times),\nBoston, and — overseas — Dublin, Berlin, Hamburg, Heidelberg, Frankfurt,\nMunich, Berne and Vienna.\n\nI don’t suppose this travel log will impress many readers of Mondo 2000.\nStill, reliving 1954 in memory, I am astounded at the mutation that has\noccurred. Though many people still use the word \"jet-setter\" to mean some kind\nof millionaire, most of the folks who are hopping around the globe are not\nrich at all. They have simply redefined travel.\n\nThroughout evolution, the average mammal has never traveled more than ten\nmiles from the place it was born. Throughout human history, the average person\nhas never traveled more than ten miles from the place she or he was born . . .\n[Source: Sociobiology, Edward O. Wilson]\n\nSince 1900, the speed of travel has increased by a factor of 100; known energy\nresources by 1000; explosive power of weaponry by 1,000,000; and speed of\ncommunication by 10,000,000. [Source: J.R. Platt, Michigan State University]\n\nAmericans have also eaten 1.8x10,000,000,000 McDonald’s hamburgers . . .\n\n\n#### Deforestation . . .\n\n  \n\nAccording to Popular Mechanics, February 1938, a new invention would soon make\nit possible to end the cutting of trees to produce paper for our books,\noffices and newspapers. Popular Mechanics was so enthusiastic about this\ninvention that they predicted farmers would earn billions of dollars a year\nmaking paper this way and would never cut down another tree.\n\nAs you look around at our devastated forestlands, you might ask yourself, what\nthe hell happened in the past 50 years? Where did the wonderful invention go?\n\nWell, kiddies, the wonderful invention was a device that made it possible to\nharvest hemp more cheaply than ever before. Hemp was the chief ingredient in\npaper throughout most of history (our Declaration of Independence was written\non it, for instance) and paper made of hemp lasted a good long time compared\nto paper made of wood pulp. Ever notice how 19th or 18th century books or even\n17th century books like the original folio of Shakespeare’s plays, printed on\nhemp, are still around, while modern books printed on wood pulp fall apart in\nonly decades?\n\nOur books continue to rot away quickly, and our forests continue to be\ndestroyed because the U.S. Government declared war on hemp. They had found out\nthat some people smoke it and get happy.\n\nPuritanism, to quote H.L. Mencken, is \"the haunting fear that somebody,\nsomewhere, might be having a good time.\"\n\n\n#### Piss Wars\n\n  \n\nGeorge H.W. Bush volunteered to be one of the first Americans to take a urine\ntest for drugs. During the Iran-Contra investigations, however, Bush refused\nto take a lie detector test. As Paul Krassner astutely commented, it appears\nBush doesn’t want us to know whether he’s telling the truth or lying, but he\nwants us to be sure he’s not stoned while doing it.\n\nNeurologically, Piss Wars opens awesome possibilities. The most widely used\nurine test in the country detects traces of marijuana and cocaine but does not\ndetect LSD. The corporate structure of the short-term future will therefore\nthin out the ranks of pot smokers and coke freaks while the acid heads climb\nmerrily upward in the hierarchy. This would suggest that the sensuality of\ngrass and the wired aggression of coke will dwindle in Power Centers but the\nmorphogenetic/futuristic evolutionary visions of LSD will play an ever-larger\nrole in shaping policy.\n\nThink about it.\n\n  \n\nOne Ton a Day?\n\n  \n\nOn the other hand, a friend of mine in Silicon Gulch recently told me there is\na ton of grass smoked every day in that area — where most of the software of\nStar Wars is being produced.\n\nI couldn’t believe it at first, but he worked it out on his computer and\nshowed me. The population is 4 million. Assuming only half of them smoke grass\nand they smoke only one joint a day — reasonably conservative estimates, I\nthink — one comes out with a ton of weed, and a heavy log of cannabis vapor\ncirculating \"in the belly of the beast\" (as SDS used to say).\n\nMost of the companies in the Gulch are unwilling to institute Piss Wars. They\nknow if they did, they’d lose their most talented, diligent and inspired\nsoftware experts immediately.\n\nThe modern \"barbarians\" — the Cyberpunks — are not only within the gates, but\nhave penetrated the Citadel itself.\n\n  \n\nTHOUGHTS TO PONDER\n\n  \n\nThe rise of the Net and the Web represents a victory for the counterculture\nand the subculture. The next generation, raised on the Net as their primary\nmedium, won’t even know what consensus reality is.\n\n  \n\n— R.U. Sirius\n\n\nOld Man on a Balcony:\n\nViews of Monterey Bay #19\n\n  \n\n\"Sweet! Sweet!\" sings a bird —\n\n  \n\nOld Ez in Virginia\n\n  \n\nHeard one cry \"Tulip!\"\n\n\n#### The Horror on Howth Hill\n\n  \n\nIt was the rains, I swear — the interminable, unspeakable Irish rains— that\ndrove us over the edge. My old Gothic castle, located high atop the hill of\nHowth facing Dublin Bay, was not only damp, dank and dark (due to the\nomnipresent clouds), but rapidly becoming eldritch, noisome and foetid. In\nfact, it looked like the set for a Bela Lugosi film — an appropriate scene, I\nthought later, for the terrible encounter of Professor Timothy Finnegan and J.\nR. \"Bob\" Dobbs.\n\nThe rain had gone on for two months this time, bringing a clammy, enervating\nmuskiness to everything. In the library, even the pages of my prized German\ntranslation of the banned and forbidden Necronomicon (Dos Verichteraraberbuch,\nvon Juntz, 1848) and de Selby’s disturbing and debatable Teratologica\nOntologicum were sticking together.\n\nRancid, the butler, was falling-down drunk every day and I could hardly blame\nhim. The maids — dark, sensuous Immaculata and blonde, buxom Concepcion — were\nnot only dykes, as I suspected from the first, but speed freaks as well. They\nspent all day in their room, injecting and 69ing, injecting and 69ing. They\ntotally neglected their duties and the entire castle had begun to look like\nthe bottom of a box where the cat had kittens. Adam, my grand old gardener,\nhad been tripping his brains out on LSD since the third week of the rains and\nthe grounds had the ghoulish and nameless appearance of the swamps of Yuggoth\nredesigned by Salvador Dali. If the damnable downpour did not cease soon, I\nfeared that we all should become mad. I think I myself would have been sunk in\nlethargy and existential despair if it were not for my mescaline and XTC\nstashes.\n\nWorst of all, it was drawing near the aeon-cursed Walpurgis Night and\nProfessor Finnegan had come to pay his annual visit again.*\n\n  \n\n~•~\n\n* Finnegan was the most controversial Irish philosopher of the later twentieth century. For biographical details, see O’Brien, Dalkey Archive, Picador Books London, 1976, and/or Wilson, The Widow’s Son, formerly with New Falcon Publications, 2004\n\n  \n\nHighlights of the Finnegan furor will be found in Conneghen, The Finnegan\nCode, Royal Sir Myles na gCopaleen Anthropological Society Preas, Dalkey,\n1937; Flahive, Teratological Evolution, Royal Sir Myles na gCopaleen\nbiochemical Institute Press, Dalkey, 1972; Vinkenoog, Finnegan: De onbekende\nfilosoof, De Kosmos, Amsterdam, 1951; La Foumier, Finnegan — l ’Enigme de\nl’Occident, University of Paris, 1933; Han Tui Po, Finnegan Du Jhing, Univer-\nsity of Beijing, 1972; La Toumier (not to be confused with La Foumier),\nFinnegan: Homme ou Dieu?, Editions J’ai Lu, Paris, 1904; Sheissenhosen,\nFinneganismus und Dummheit (6 vols.), University of Heidelberg, 1942-52; La\nPuta, La Estupidez de Sheissenhosen, University of Madrid, 1975; Turn-und-\nTaxis, Ist Finnegan eine Droge oder haben wir sie nur falsch verstanden?,\nSphinx Verlag, Basel, 1922; O’Broichnan, A Chara, na caith tabac, Royal Sir\nMyles na gCopaleen Zoological Institute Press, Dalkey, 1992.\n\n~•~\n\n  \n\nOf course, I personally have always liked Finnegan, who is not at all a bad\nchap in his own weird way. But he lives always, not just in the turmoil of\nacademic controversy, but in the epicenter of a veritable spider’s web of\nclandestine operations: where Tim Finnegan walks, the CIA and KGB are sure to\nskulk close behind, and the IRA and even the PLO may be showing interest also,\nnot to mention the Knights of Malta,* the Illuminati,* the Priory of Sion,*\nthe Campus Crusade for Cthulhu* and the other secret societies and cults whose\nreputations are unsavory and whose goals remain inscrutable to ordinary\nwholesome men and women.\n\n  \n\n~•~\n\n* The Knights of Malta — or, more properly, the Sovereign Military Order of Malta (abbreviated SMOM) — is the eight-hundred-year-old Vatican \"secret police\" or \"dirty tricks bureau.\" According to Covert Action Information Bulletin #25, Winter 1986, notable recent members of SMOM have included Dr. Otto vou Hapsburg (a prime organizer of the infamous \"Bilderbergers\"), Franz von Papen (the man who persuaded President von Hindenburg to resign and appoint Hitler chancellor of Germany), William Casey (the CIA chief who died mysteriously during the Iran-Contra hearings), Major General Reinhard Gehlen, General Alexander Haig, Roberto Calvi, Michele Sindona and Licio Gelli. Baigent, Lincoln and Leigh in The Messianic Legacy (Henry Holt, New York, 1987) have added to the list of SMOM members Alexandre de Marenches, former chief of French intelligence, and claim mysterious links between SMOM and the Priory of Sion. Gordon Thomas and Max Wittman in The Year of Armageddon (Corgi, London, 1984) claim that SMOM members act as couriers between the Vatican and the CIA. Most scholars dissent vehemently from von Hanfkopf’s ill-documented charge that de Selby, Flahive, La Toumier, Finegan and the shadowy La Foumier are or were all members of SMOM.\n\n  \n\n* The Illuminati, founded in Bavaria in 1776, was (or is) a secret society within a secret society, since all members were first Freemasons before being invited into the Illuminati itself. See Nesta Webster, World Revolution, Christian Back and other secret societies and cults whose reputations are unsavory and whose goals remain inscrutable to ordinary wholesome men and women. Club of America, Hawthorne, California, n.d.; \"Inquire Within,\" The Trail of the Serpent, Christian Book Club of America, Hawthorne, California, n.d.; and Wilson, Cosmic Trigger, Falcon Press, Santa Monica, 1987. The Illuminati technique of forming a secret society within another secret society was later imitated by the Molly Maguires, an Irish revolutionary group within the Ancient Order of Hibernians, and the P2 conspiracy which recruited within the Grand Orient Lodge of Egyptian Freemasonry in Italy — although secretly managed, as noted above, by three members of the Vatican secret service, SMOM. Professor Flahive was under great personal stress when he began his campaign to convince the learned community that von Hanfkopf was actually the ringleader of an Illuminati conspiracy against Finnegan.\n\n  \n\n* According to Paoli (Les Dessous d’une ambition politique, Hurhaus Verlag, Basel, 1973), the Priory of Sion is a serious political conspiracy of aristocratic French Freemasons who intend to restore monarchy in France. According to de Sede (La Race fabuleuse, Editions J’ai Lu, Paris, 1973), the Priory is descended: from superhumans born of matings between ancient Hebrews and extraterrestrials from Sirius. According to Baigent, Leigh and Lincoln (Holy Blood, Holy Grail, Delacorte, 1982), the Priory is descended from the royal line of Jesus and Mary Magdalene. According to Michael Lame (Jules Verne, initiate et initiateur, Editions J’ai Lu, Paris, 1985), the Priory is a front for the Illuminati and Veme’s \"science fiction\" novels are subtle Illuminati recruiting manuals. Finnegan claims (Omni qua sunt, Royal Sir Myles na gCopaleen Philosophical Society Press, Dalkey, 1957) that the Illuminati/Priory axis is an attempt to spread electric light everywhere, thereby banishing the \"teratological molecules\" which move backwards in time and generate Chaos, but this must be considered one of the more imaginative flights of the Dalkey sage.\n\n  \n\n* The Campus Crusade for Cthulhu has been alleged to be responsible for the recent crop of child murders and cattle mutilations elsewhere attributed to Satanists; see Rev. Jedidiah Blather, The Cthulhu Cult, Interstellar Bankers and Punk Rock, True Christian Book Club of America, Tulsa, 1987. Although few credit this wild charge, the CCC is definitely responsible for the bumper stickers that say things like IT FOUND ME; ABDUL ALHAZRED WAS NOT MAD YOG SOTHOTH NEBLOD ZIN; etc. Von Hanfkopf’s attempts to link La Puta to the CCC are best described as tenuous and (as Ferguson said) \"clutching straws.\" It was after Professor Ferguson uttered these views on the BBC that the police of his hometown, Loch Pookah, received letters claiming he, Ferguson, was the Yorkshire Ripper. These letters were in clumsy English (\"rather like that of the Katzenjammer Kids,\" according to Inspector MacAndrew, who handled the investigation) and had Heidelberg postmarks.\n\n~•~\n\n  \n\nSome of these types would be beyond the comprehension of the Los Angeles Vice\nSquad or the specialists in abnormal psychology at the Kinsey Institute, I\nswear.\n\nAs usual, Finnegan has a new obsession this year. He is determined to discover\nthe exact dimensions of the penis of a fictitious gorilla. Any ordinary\nscholar, however eccentric, might decide to write a paper on the dimensions of\nthe wingwang of a real gorilla, dead or alive, but dear old Timothy wants to\ndiscover the magnitude of the Willy of a gorilla who never really existed at\nall — King Kong in the famous horror film of 1933. Naturally, being Finnegan,\nhe has reasons for this which no normal person can understand.*\n\n  \n\n~•~\n\n* The Finnegan/CSICON controversy originally erupted into political mania after Professor Sheissenhosen charged (see his Werke, vol. XXIII, pp. 506-666ff.) that some of the moneys embezzled from Banco Ambrosiano of Milan in the early 1980’s (by the bank’s president, Roberto Calvi, and his associates in the P2 conspiracy) had been \"laundered\" through a Dublin bank account which Finnegan allegedly used to finance IRA terrorism in Northern Ireland. Although this charge was unsubstantiated, Professor Flahive rebutted it at great length (Proceedings of the Royal Sir Myles na gCopaleen Institute of International Relations, vol. LVI, pp. 309-417) and it was after this that the Special Branch of the Gardia (the police of the Republic of Ireland) began receiving letters with a Heidelberg postmark charging (in broken English) that Flahive himself was involved in running guns for the IRA. This was immediately after the unfortunate and much-debated incident involving Professor Flahive and the fourteen-year-old Girl Scout from Sallynoggin, and the distressed savant, a devout Catholic and conservative, began making wild charges about \"intentional plots\" and \"frame-ups\" and, sadly, eventually degenerated to the same tactics as Sheissenhosen, claiming that the Heidelberg philosopher was formerly associated with the Gehlen apparat and the CIA’s \"Russian\" branch — the group, under Major General Reinhard Gehlen, Knights of Malta and former head of army intelligence for Hitler, which conducts espionage within the Soviet Union itself. Of course, the crude (and ineffective) letter bomb sent to Professor Flahive at this point, although postmarked Langley, Virginia, could have been sent by anybody (and one assumes the CIA are at least hip enough not to mail such devices from a city universally known to be their international headquarters); but after Roberto Calvi, President of Banco Ambrosiano, was found hanging from Blackfriars Bridge in London that same week, and his secretary, Ms. Graziella, fell or was pushed from a window of the Milan office of that bank, sheer paranoia descended upon all those involved in the Finnegan feud or even in the abstract mathematical arguments about Finnegan’s \"plenuminary time\" and \"teratalogical molecules.\" As La Puta has incisively remarked, \"The entire Finnegan furor is degenerating into the worst academic schlemozzle since the Bacon-Shakespeare lunacy.\"\n\n~•~\n\n  \n\nFinnegan says 1932 (when King Kong was being produced) was a pivot in\nevolution, in some mystic sense that only he comprehends.\n\n\"In 1932,\" he was telling me at breakfast this morning, \"Alice Pleasance\nLiddell died, and so did John Stanislaus Joyce.\"\n\n\"Who the hell were they?\" I asked irritably.\n\n\"Alice P. Liddell,\" he said somberly, \"was the model for Alice in Wonderland.\nCharles Dodgson and/or Lewis Carroll — the world’s most successful dual\npersonality — loved her um ah er 'not wisely but too well.’ Too well, at any\nrate, to avoid the speculations of Freudians. And John Stanislaus Joyce was\nthe father of James Joyce. Do you see the connection?\"\n\nI admitted that the linkage evaded me.\n\n\"Alice Pleasance Liddell or APL,\" Finnegan said simply, \"is one aspect of Anna\nLivia Plurabelle or ALP, the superwoman who contains all women, in Joyce’s\nFinnegans Wake.\"\n\n\"Oh,\" I said. It seemed the only adequate comment.\n\n\"I have wondered,\" de Selby went on, \"if one can equate APL with ALP on\nCabalistic grounds, since both equal 111, what of PLA?*\n\n  \n\n~•~\n\n* \"PLA\" is Dublin slang for Portlaois Lunatic Asylum, the institution which many of Finnegan’s critics claimed would be his ultimate destination. As La Foumier wrote (Finnegan; l’Enigme de la Occident, p. 23), \"While much about the sage of Dalkey remains in dispute, none have denied that he held a greater number of strikingly original ideas than any philosopher in history not known to have resided in a padded cell.\" Sheissenhosen’s claim that Le Foumier was a mask, a nonentity, a fiction, a stalking horse behind which Finnegan wrote commentaries on himself, in French no less, has not been conclusively verified, and La Puta claims to have refuted it entirely in his La Estupidez, op. cit. It was after this work was published that the Spanish police began receiving letters, with a Heidelberg postmark, alleging in bad Spanish that La Puta was the chief opium smuggler in Madrid and a KGB agent. Professor Hamburger’s attempts to link La Puta to the Illuminati (Proceedings of the London Musicological Society, vol. XXIII, pp. 7-133) do, however, appear to be well documented and possess some merit, although Hamburger’s argument that it was La Puta, not Finnegan, who laundered the cocaine money for the P2 conspiracy is far from convincing. As Penny Lernoux documents in her In Banks We Trust (Anchor Press/Doubleday, Garden City, New York, 1984), most of the cocaine money went through the World Finance Corporation in Miami and the Cisalpine Overseas Bank in the Bahamas, which was owned by the deceased Robert Calvi and Archbishop Marcinkus. The argument of Yallop (In God’s Name, Bantam, New York, 1984) that Calvi and Marcinkus collaborated in the murder of Pope John Paul I is, of course, highly speculative.\n\n~•~\n\n  \n\nBut that is an irrelevance, I’ve decided. What is important is that in 1932\nnot only did Alice P. Liddell and John S. Joyce die, but the atom was split\nfor the first time, and the 92nd chemical element was discovered — the last\nnatural element, you see. For the first time in history, humanity had access\nto the energy of the stars and possessed a full catalog of the basic building\nblocks of the universe.\n\n\"And, of course, Roosevelt II was elected in America, and Hitler in Germany,\nthat very same year, 1932, which incidentally adds numerologically to 15, the\nnumber of the Devil card in the Tarot. King Kong, you see, had to emerge from\nthe collective unconscious at exactly that point, especially since Cary Grant\nwas 28 years old on January 18 that year.\"\n\nProfessor Finnegan went on in that vein for quite a while, but I sort of lost\nthe thread of his argument — something that often happens to readers of his\nbooks, as numerous critics have complained. All I could ever remember\nafterwards was that Cary Grant was 28 when I was born and 28 is a number\nconnected with menstruation, the ancient Celtic moon goddess, Bridget, and the\nsynchronous link from Lewis Carroll’s obsession with premenstrual girls to\nCary Grant’s habit of avoiding the Academy Award dinners, staying home, taking\nLSD and watching the award ceremonies on TV while \"laughing uncontrollably and\njumping up and down on the bed,\" according to the testimony in his third\ndivorce trial.\n\nEventually, we finished our leisurely breakfast. It was ten thirty and the\npubs opened, so Timothy put on his brown mackintosh (he seems to have worn it\nsince 1904, I think) and sallied forth in search of Irish Inspiration.\n\nI went to the study and tried again to work on my new science-fiction novel,\nWigner’s Friend, which deals with a parallel universe where Moe Howard became\nPope and Adolf Hitler migrated to the United States and became a popular\nwriter of Western movies. As usual lately, my creativity was dampened by the\ndepressing rain, the eldritch, unhallowed and Peter Lorre-like giggles of the\ngardener after his day’s dose of LSD took effect and the strange, fetid and\nnameless fungi that have grown on the furniture since the maids got hooked on\nmethamphetamines and stopped even pretending to clean up.\n\nRancid, the butler, lurched into the study, staggered, knocked over a Ming\nvase, puked into the potted fern, and asked if I needed anything. I sent him\naway with no rancor. He was too drunk to understand anything I said, anyway. I\ndid wish, however, that he looked a little less like Boris Karloff as the\nalcoholic (and eventually homicidal) butler in The Old Dark House. The rain\ncontinued to fall and the sky remained overcast and gloomy, turning my\nthoughts to the most morbid subjects imaginable. I was actually happy when\nFinnegan returned, in a car driven by an American tourist he had met at the\nRoyal Howth, a Mr. J.R. \"Bob\" Dobbs.\n\n\"Bob,\" Finnegan said grandly, \"meet 'Bob.’\" I could see that he had put away\nat least five or six pints of Guinness stout already, and I tried not to\nbecome uneasy or let my imagination run riot over the simple fact that \"Bob\"\nhad a Campus Crusade for Cthulhu bumper sticker on his Toyota. Americans often\nhave a strange sense of humor. Nonetheless, as we entered the castle, I looked\nback at the car and shuddered involuntarily at the other words on the bumper.\n\n  \n\nHave you hugged your shoggoth today?\n\n  \n\nWe went to my study, where Finnegan, with his usual exuberant Celtic\ngenerosity, opened a bottle of my best Tullamore Dew and offered a healthy\ndouble shot to \"Bob.\" I was pleased when he offered some to me, too.\n\n\"'Bob’ has some real data on Kong’s dong,\" Finnegan began at once, finishing\nthe rest of the bottle in a gulp.\n\nI raised an enquiring eyebrow, a trick I had learned from Basil Rathbone\nmovies. \"Bob\" was busy relighting his Pipe for a moment but then he spoke in a\nmellow Texas drawl.\n\n\"The average man,\" he said, \"stands between about five foot eight and about\nsix foot, right? And the average human erection, at least according to my\nwife, 'Connie’ — who is more of an expert on males in heat than I am — is\nbetween five and seven inches. The nine-inchers and twelve-inchers you see\noccasionally in porn movies are freaks of nature like Watusis or basketball\nplayers who can be seven or eight feet tall. Follow me? So the average human\nmale, statistically, has about six inches. Kay? Now in the case of Kong, we\nhave an anthropoid standing at least twenty-four feet tall, as you can judge\nby the scene in the theater. That means he would have about four times as much\nas a man of six feet.\n\nFour times six is twenty-four, so Kong had twenty-four inches or two feet.\"\n\n\"No wonder Fay Wray did so much screaming,\" I said. \"She’d be in the position\nof the young lady from Sidney in the poem by T.S. Eliot.\" Finnegan raised an\nenquiring eyebrow (he’s seen a lot of Basil Rathbone movies, too) and\ncourteously opened another bottle of my Tullamore Dew. To explain my remark, I\nrecited the immortal lines from Ash Wednesday:\n\n  \n\nThere was a young lady from Sidney\n\nWho liked it right up to her kidney\n\nA man from Quebec\n\nShoved it up to her neck\n\nHe had a big one, didn’t he?\n\n  \n\nFinnegan refilled our glasses all around and sat down in an easy chair. He\nlooked troubled.\n\n\"Well,\" I said to him cheerfully. \"Your mystery is solved. There’s no prob\nwith 'Bob.’\"\n\n\"I don’t know,\" the Sage of Dalkey replied thoughtfully. \"We may be\napproaching this matter from the wrong angle entirely. 'Bob’ is treating Kong\nas a creature in biology, which is emphatically what the Big Fellow is not at\nall, at all. Kong is a creature in mythology, in um ah er the collective\nunconscious.\"\n\n\"Why, sure,\" said \"Bob\" quickly. \"Hellfire, boy, there ain’t no twenty-four-\nfoot gorillas in the real world. But if we grant that, for argument’s sake,\nhow in hell do we reason about Kong at all? What are the dimensions of a myth,\na dream, a Special Effect? Tell me that.\" And he grabbed the Tullamore Dew and\npoured another hearty slug. I could see we were in for a day of heavy going.\n\n\"Well,\" Finnegan said, \"we must take our clues from the records of the\ncollective unconscious itself. Kong is a Nature Divinity, to say the least of\nit, and, considering his um concupiscence — that means horniness in American,\n'Bob’ — he’s more specifically a Fertility God. We must approach this from the\nperspective of ’patapsychology.\"\n\n\"What are you getting at?\" I asked uneasily. In the distance, a dog barked\nand, further off, there was an ominous rumble of thunder.\n\n\"Well,\" Finnegan said. \"We know one thing about Fertility Gods.\nAnthropologists call them ithyphallique and not without reason. They make the\nstuds in porn movies look puny by comparison. Osiris is portrayed in Egyptian\nart as having about three times as much Willy as one would expect in a man, or\ngod, of his size. In Greece, Hermes was usually depicted with a tool almost\nthe size of his body — why, statues of him look almost like a bureau with the\nmiddle drawer pulled all the way out. As for Finn Mac Cool, some of the most\npowerful verses in the Finn epic — the most beautiful lines of Gaelic in our\ntradition, although usually expunged in English translations — describe him\nas, well, virtually a pole-vaulter with a built-in pole.\"\n\n\"Why, hell’s bells, son,\" said \"Bob\" chortling, \"that’s the most persistent of\nall legends. When I was young, everybody in the States believed Dillinger had\ntwenty-three inches and it was preserved in alcohol at the Smithsonian after\nhis death. Later on, the myth got attached to an actor named Errol Flynn. Long\ncrullers, the kind you call Berliner over here, were called Errol Flynns.\"\n\n\"Say,\" I interrupted, smitten with whimsy, \"when John Fitzgerald Kennedy went\nto Germany and said, 'Ich bin ein Berliner,’ was he jus being diplomatic, or\nwas he bragging?\"\n\nThey ignored me. \"Dillinger and Mr. Flynn had become semi-divine in folklore,\"\nthe professor said, pouring more Tullamore Dew, \"and so naturally they were\nexpected to have semi-divine prongs, two or three times the norm. Truly divine\nbeings have much, much more. Considering Osiris and Hermes, I would say a\ndivine being would have six times the norm, at least. As a fertility spirit,\nKong must have, not the mere two feet that a biological twenty-four-foot\ngorilla would possess, but around twelve feet.\"\n\n\"That fits with the anthropological books I’ve read,\" I agreed. \"The primitive\ntheory is, the greater the Willy, the greater the divinity indwelling.\"\n\nWe paused to consider the ’patapsychological ramifications of our theorizing.\nThunder rumbled closer to my castle and more dogs began howling in anxiety.\n\n\"You know, fellers,\" Dobbs said, filling his Pipe again — I had begun to\nrecognize the aroma of what he was smoking and understood why he always had\nthe same contented grin — \"I come from Texas, where we got ourselves almost as\nmany Catholics as here in Ireland. There’s a big donnybrook going on in the\nCatholic church these days because some nuns have become Feminists and are\ndemanding the right to say Mass. The Pope absolutely refuses to consider it.\nHe says you absolutely have to have a Willy to perform the sacrament.\"\n\nFinnegan had been hunting in my bar for more Tullamore, and, finding none,\nopened a bottle of my Jameson. \"Why, of course a priest must have a Willy in\nCatholic theology,\" he said mildly. \"The priest represents God, who has the\nbiggest Willy of all — even bigger than Kong’s.\"\n\n\"What was that?\" I objected. \"There was a quantum jump or something there. Run\nthat by me again.\"\n\n\"You said it yourself,\" Finnegan drawled. \"'The greater the Willy, the greater\nthe divinity indwelling.’ Yahweh, the Jewish God who became the Christian God,\nalways claimed to be bigger and better than any of the other Near Eastern gods\nwho competed with him. He would have to be endowed with a schlong that would\nmake Osiris or Dionysus, say, look almost impotent by comparison.\"\n\n\"Just how big would it be?\" I challenged. If Finnegan and \"Bob,\" with only two\nbottles of malt in them, could deduce the size of King Kong’s dong, I was sure\nthat with another bottle they could do the same for YHVH.\n\n\"Well,\" de Selby said, \"Yahweh himself isn’t much bigger than Kong. He walks\naround Eden at twilight — without smashing down the trees or causing any\nnotable wreckage of the sort Godzilla would leave in his wake. He shows his\nbackside to Moses and nobody in Greece or even Babylon sees that cosmic\nspectacle.\n\n\"I would say he couldn’t be more than forty or fifty feet tall. In biologic,\nhe should have about four to five feet of johnson. In mytho-logic, if he were\nany ordinary fertility god like Hermes or Finn, he would have six times that\nor around twenty-four to thirty feet. As the Lord of Lords and King of Kings,\netc., he would double our expectations at least. He should have around fifty\nfeet. In passion, he would be symmetrical, fifty feet high and fifty wide in\nthe middle, sort of like a giant F with the top stroke missing.\"\n\n\"I begin to feel the same sympathy for the Virgin Mary that I experienced\nearlier for Fay Wray,\" I said, finishing off my own shot of Jameson. But then\nanother thought struck me. \"Yahweh may have been about that size — probably\nwas that size, I think — back in Biblical times. The scriptures are full of\nlots of other references that show him about the height of Finn Mac Cool or\nZeus, say. But he has grown during the scientific epoch. Every new advance in\nastronomy has necessitated that the whole Judeo-Christian tradition has had to\nmake him bigger and uh er more gaseous, as it were. By the time of Newton, he\nhad to be at least millions of miles in circumference to create the known\nuniverse. Since we started finding other galaxies in the 1920’s, he has\nswollen to billions and billions of light-years — at least.\"\n\n\"Yes,\" said \"Bob\" thoughtfully. \"To be consistent with known cosmology, the\nJudeo-Christian God would have to be bodacious, to say the least of it. And\nthe size of his john thomas — gol dang, the mind spins at the thought.\"\n\n\"And yet, if we accept Christianity in any sense, even as metaphor like Mr.\nT.S. Eliot,\" Finnegan muttered pensively, \"the metaphor demands such a whang\nfor its divinity. Billions of zillions of parsecs from foreskin to base. The\nonly way out of that logic is the Feminist path. Neuter the divinity. He has\nno dong at all. He isn’t a he anymore. A cosmic eunuch.\"\n\n\"Well, there’s also the Radical Feminist-path,\" I suggested. \"He’s she.\"\n\n\"Lawdy, lawdy,\" said \"Bob\" dazedly, quickly gulping some more Jameson. \"Now we\nhave to try to visualize a vagina quadrillions of parsecs deep.\"*\n\n  \n\n~•~\n\n* I have often thought, later, that it was this conversation which inspired Finnegan’s most controversial essay, \"Can Goddess Create a Stone So Heavy That She Herself Cannot Lift It?,\" which he optimistically submitted to several Radical Feminist journals in San Francisco. It was after this that WITCH (the Women’s International Terrorist Conspiracy from Hell) began picketing Finnegan’s home in Dalkey. It is unfortunate that Flahive, in his passion to defend Finnegan against all detractors, attempted to prove the WITCHes were a \"front\" for the Knights of Malta. If Flahive had not been himself a former CIA agent and coincidentally present, like Kerfooey, in Dealey Plaza on November 22, 1963, not even the intemperate Hamburger would have claimed evidence foul play in Flahive’s subsequent tragic death in a hunting accident with Profesor La Puta.\n\n~•~\n\n  \n\nIt was at this point, alas, that the whiskey began to go to my head and I\nnodded off in my chair. Professor Finnegan and \"Bob\" politely did not try to\narouse me, reasoning that I needed the rest, and went ahead helping themselves\nto my rare cognacs, now that the Jameson was exhausted. In that hypnopompic\nstate midway between drunkenness and coma, I was half aware, or dreamed I was\nhalf aware, of the continuing conversation.\n\nSomehow Finnegan and \"Bob\" wandered from the high theological contemplation of\ndivine dongs back to the King himself, and were united in condemning the cheap\nremakes produced by some Japanese studio and the abominable caricatures of De\nLaurentiis. Still: They thought it was time for a \"sincere\" remake, and soon\nhad sketched out a film which I, in my reverie, could see as clearly as if\nthey had already shot it.\n\nAnn Darrow, this time, would be played by Marilyn Chambers, on the grounds\nthat Behind the Green Door was, psychoanalytically considered, already a part\nof the Kong mythos. Like Fay Wray in the original, Marilyn in Green Door is\nkidnapped and ordered as a mate to a divinely endowed Fertility Spirit. \"Bob\"\nand Finnegan agreed heartily that the black superstud in Door, with his\ngargantuan tool (and the \"savage\" bone in his nose) represented the same\nprimitive generative force as Kong. \"Pornography,\" I heard \"Bob\" say\nprofoundly, \"merely makes explicit what is implicit in folk art like Kong.\"\n\nIn the new Kong, Marilyn Chambers and a porno producer, played by Al Pacino,\nsail to Skull Island to make the ultimate wet-shot epic. Kong appears with his\nfive-foot whang clearly visible in every shot. \"No fig leaves!\" said \"Bob\"\nemphatically. The giant dinosaurs and other monsters run amok, as in the\noriginal, creating ample mayhem for the S-M crowd, and Marilyn is rescued by a\ndifferent crew member each time Kong or one of these reptiles menaces her; she\nexpresses her gratitude in traditional Chambers fashion, for the voyeur\nmajority.\n\nAt the climax, when Kong is running wild in New York, looking for his mate,\nMarilyn, his giant tool attracts the horrified notice of Andrea Dworkin,\nplaying herself. She quickly rounds up a crew of five hundred fat ladies from\ncircuses and they overrun and bring down the Big Fellow without any help from\nairplanes. They then emasculate him in gory detail, on wide screen with\nTechnicolor.\n\nThe offensive organ is then weighed down with a lead block and thrown in the\nEast River so it will never rise again.\n\nWhile Dworkin leads a horde of Radical Feminists in a victory celebration, the\nfilm cuts to a conference room at a university and switches to documentary\nstyle. Various leading spokescritters for the Committee for the Scientific\nInvestigation of Claims of the Paranormal — e.g., Carl Sagan, Martin Gardner,\nJames Randi and Professor Sheissenhosen — are then given equal time to\npersuade the audience that gorillas never grow to twenty-four feet tall and\nthat the film just shown has been fantasy and therefore nefarious.\n\nSheissenhosen gets the microphone first, but his talk soon degenerates into\nincoherent ravings about cocaine abuse in Hollywood, CIA plots, the \"Vatican-\nMafia axis,\" etc., and he is gently persuaded to relinquish the podium. Randi\nbegins denouncing everybody who disagrees with him about anything, saying they\nare all frauds, felons and child abusers.\n\nMartin Gardner gets the microphone away from him and argues that all the\nwreckage in midtown Manhattan does not prove the existence of giant apes and\ncan be \"more economically and scientifically explained\" by positing the crash\nof a giant meteor. Dr. Sagan then approaches the podium and urges everybody to\nbeware of wild and fanciful ideas. He rambles off into lyrical exposition\nabout \"billions and billions\" of galaxies with billions and billions of stars,\nand is about to proceed further in that vein when suddenly a huge black hand\ncrashes through the floor and grabs him by the testicles.\n\nAt that point, I drifted into deeper sleep. In a while, however, I was either\nstartled awake or fell into the worst nightmare of my life — I have never been\nsure which — but it seemed to me that Finnegan had returned to his original\nsubject, the dimensions of divine dongs, and was arguing that Catholicism\nremains the last survivor of the ithyphallic cults of the ancient\nMediterranean.\n\nNot only must one have a Willy to be a priest, he was saying, but the Pope\ncontinues to insist on that because the inner order within the church — I\nthink he meant the Knights of Malta — still holds the antediluvian credo about\nthe biggest Willy containing the greatest Animal Magnetism, or magick, or\nindwelling divinity, or something like that. He proposed a totally new, and\nshocking, theory as to how Popes are selected by the College of Cardinals and\nwhy these proceedings are always hidden from the public behind locked doors\nand no details are ever revealed.\n\nEvidently, he was seriously suggesting that, just as it requires a Willy to\nturn a piece of bread into the body of a dead Jew, it requires the biggest\nWilly on the planet to anoint others and pass on the power to perform this\nastounding alchemical transformation.\n\nWhile I was grappling with this thought, imagining the secret conclaves of the\nCuria looking like the casting sessions for male lead in a porn epic, and\nwondering why Kong had not been appointed at least an Honorary Pope. Rancid\nthe butler suddenly burst into the room, carrying a Thompson submachine gun.\n\n\"This has gone far enough!\" he shouted, glassy-eyed and foaming a bit.\n\n\"Come, come, old man — \" I began gently, as one must begin with drunks.\n\n\"Don’t ‘old man' me, you Unitarian pervert,\" he screamed hysterically. The\ntommy gun, aimed loosely at all of us before, now pointed directly at my gut.\n\"I am no damned butler. I am Cardinal Luigi Mozzarella, of the Holy Office for\nthe Doctrine of the Faith, and Grand Master of the Sovereign Military Order of\nMalta.\"\n\nThere was a \"pregnant\" or stifled or grisly silence, as we all took this in.\n\n\"We don’t have the Maltese Falcon, honestly,\" said \"Bob\" weakly.\n\n\"Fuck that damned bird,\" Cardinal Mozzarella shouted. \"We’ve wasted eight\nhundred years looking for it, and eight hundred years is more than enough on a\nlosing project. I am one of the thirty-two agents assigned to monitor the\nheresiarch, Finnegan, and it is just as we feared. You have guessed the inner\nsecrets of our Holy Order and you will have to be eliminated. All of you.\"\n\nHe raised the tommy gun and I felt that sinking sensation which Chandler, I\nbelieve, has defined as the acute consciousness that one is not bullet-proof.\n\n\"All right, Luigi, drop the gun!\"\n\nAll of us spun about to stare at the door, where Adam, the grand old gardener,\nstood, no longer grand or old. He had removed his white wig and abandoned his\ncrouched posture. He was a young and dangerous man, and he carried an\nautomatic rifle.\n\nCardinal Mozzarella dropped his tommy gun, stunned. Finnegan darted forward\nand picked it up.\n\n\"Permit me to introduce myself,\" said the stranger who had once been my\ngardener. \"I am Adam Weishaupt IX, primus illuminatus, and Grand Master of the\nOrdo Templi Orientus, the Scotch Rite, the York Rite, the Egyptian Rite and\nthe Rite of Memphis and Mizraim. In short,\" he summed up, \"I control every\nFreemasonic conspiracy on the planet. We have been watching and protecting you\nfor a long time, Professor Finnegan, since we knew the Knights of Malta would\neventually attempt to take your life.\"\n\nFinnegan carefully placed the tommy gun on the writing desk, in the corner. I\nabsently noticed that \"Bob\" wandered off in that direction and sat casually on\nthe edge of the desk, relighting his Pipe. Just then the French windows\nsmashed open and the maids, Immaculata and Concepcion, burst into the room,\neach carrying a bazooka. \"Put down that rifle, Illuminati dog,\" cried\nImmaculata. \"We are taking charge here.\"\n\n\"Who the hell are you?\" Cardinal Mozzarella gasped, evidently unable to\nbelieve there could be so many conspiracies afoot in one Gothic castle.\n\n\"We are the High Priestesses of the Paratheo-Anametamystikhood of Eris\nEsoteric, or POEE,\" Concepcion said. (POEE was pronounced \"pooey,\" at least in\nher dialect.)\n\n\"Eris?\" cried the primus illuminatus.\n\n\"Eris, goddess of chaos, discord, confusion, bureaucracy and international\nrelations,\" Immaculata explained. \"Our slogan is 'Disobedience was Woman’s\noriginal virtue.’ Too long has the world been run by male conspiracies. We are\nthe first all-female conspiracy.\"\n\n\"Heressssssssy,\" hissed the cardinal venomously.\n\n\"The inevitable yin balance to our yang energies,\" the Illuminatus muttered\nthoughtfully.\n\n\"Are you going to kill us?\" I asked, being practical about the situation.\n\n\"No, of course not,\" Immaculata said. \"Chaos is our Lady’s natural metier. We\ncame here to stop you from killing one another. We want you all alive, so you\ncan go on spreading disputation and confusion and Chaos will always steadily\nincrease. Hail Eris. All hail Discordia.\"\n\n\"So,\" Concepcion said, \"we must ask all of you to move the guns — with your\nfeet please — to the center of the room. And then you must leave by separate\ndoors. Go forth in peace,\" she added piously, \"and continue to preach false\ndoctrines.\"\n\n\"Just a minute, ladies,\" said Finnegan. \"I have a brief statement to make.\nProfessor Finnegan died in his sleep, peacefully, over ten years ago. I have\nbeen impersonating him ever since. I am a time traveler, in your terms. I was\noriginally born in Damascus over a thousand years ago. My name was Abdul\nAlhazred and I was the first to learn the art of positronic reincarnation. In\nlay terms, when one brain wears out with age, I simply move my quantum energy\ninto another brain. I took over Finnegan as he was dying and simply continued\nthe Great Work to which the Order of the Hashishim have been dedicated for a\nmillennium — the return of the Great Old Ones, or GOO, as we call them.\"\n\n\"Goo?\" Immaculata cried, stunned.\n\n\"Well, they are kind of slimy,\" Abdul admitted, \"but they are stronger than\nyour Eris, or the other gang’s Yahweh, or any of these recent parvenu gods.\nAnd now that I have the leaders of all the other and hence lesser cults\nassembled in one place, I shall summon Great Cthulhu to eat your souls.\" And\nhe began chanting in a nameless Elder Tongue:\n\n  \n\n#### \"Ia, Shub-Niggurath! Cthulhu fthagn! Yog Sothoth neblod zin! Ia! Io! Nov\nshmoz ka pop! Ph’nglui mgIw'nafl nagcopaleen Baile atha Cliath wgah’nagl\nfthagn Tsog!\"\n\n  \n\nAs he chanted this blasphemous and nameless invocation, the mad Arab began to\nmetamorphose before our very eyes, growing, swelling, becoming like unto a\nhuge bowl of green yogurt, then changing into a jellyfish with a million\nbloodshot eyes, then becoming a pit bull with AIDS, then a Republican attorney\ngeneral, a werewolf, every fearsome creature of nightmare and horror\nimaginable by a hashish-crazed brain, for all these horrific visions were, I\nnow realized, individual aspects of the multiple monstrosity that was Cthulhu,\nthe Interstellar Banker, source of all evil and conspiracy, inventor of punk\nrock, Eater of Souls — the Thing in the center of the Pentagon!!!\n\nAnd then, \"Bob,\" so drunk that he had lost track of who was in charge, tried\nto kick the tommy gun into the center of the room, as the Erisians had\ndemanded, and the gun began to spray bullets in all directions. I dived for\nthe window and rolled dizzily down the lawn, my brain temporarily unhinged by\nthe terrible visions I had seen.\n\nThey tell me that neighbors found me wandering in the rain, gibbering\nincoherently. They called an ambulance. I have been in St. John of God’s\nHospital for alcohol abusers for two weeks now. They think the terrible things\nI was muttering when brought here indicate too much Irish whiskey, and I am\nwilling to let them think that. I dare not tell the good nuns here how Popes\nare actually chosen, or why it requires a Willy to perform the\ntransubstantiation of molecules in the eucharist . . . or that in the last\nmind-numbing moment before \"Bob\" accidentally set off the tommy gun I saw the\nface of Cthulhu, the master of this Death Universe, and recognized that it was\nmy own . . . for now the positronic transformation is being accomplished\nagain. Yes, Abdul Alhazred lives anew, for I am he, and I know now that I was\nwrong in my youth to believe that good was better than evil because it is\ngenerally nicer. Now I know, from one thousand years of memories of many\nlives, that evil is better than good because it always wins in the end . . .\nIa! Shrug-Yrsh’ldrs! Notary sojac! Sinn fein amhain!\n\n\n### Sexual Alchemy\n\n  \n\nThe Chariot of Antimony by Basil Valentine (1642) contains the following\ntypical bit of Alchemical exposition:\n\n  \n\nLet the Lion and Eagle duly prepare themselves as Prince and Princess of\nAlchemy — as they may be inspired. Let the Union of the Red Lion and the White\nEagle be neither in cold nor in heat . . . Now then comes the time when the\nelixir is placed in the alembic retort to be subjected to the gentle warmth .\n. . If the Great Work be transubstantiation then the Red Lion may feed upon\nthe flesh and blood of the God, and also let the Red Lion duly feed the White\nEagle — yea, may the Mother Eagle give sustain-molt and guard the inner life.*\n\n  \n\n~•~\n\n* See \"The Triumphal Chariot of Antimony,\" reproduced in The Alchemical Tradition in the Late Twentieth Century, ed. Richard Grossinger, North Atlantic Books, Berkeley, 2nd edition 1983, pp. 34-47.\n\n~•~\n\n  \n\nIn general, the preceding passage is representative of the limpid clarity of\nexposition and crystalline lucidity of style to be found in alchemical\nliterature We can already see why so many Rationalist historians have\nconcluded that the alchemists simply went off their skulls from inhaling too\nmany narcotic and/or toxic vapors and wrote hallucinogenic gibberish.\n\nOccultists of various schools, of course, have other ideas. They all agree\nthat alchemical literature was written in code — because \"humanity is not\nready to receive certain knowledge,” say the esoteric, because any alchemist\nwho wrote clearly would bring down the wrath of the Inquisition on his head,\nsay the more pragmatic. Unfortunately, there are a few dozen theories about\nwhat the code means. What follows is the theory that I have found most\nsatisfactory over the years, although I am not smart enough to be absolutely\nsure it is the one and only correct theory.\n\nAccording to Louis T. Culling, Grandmaster of an occult lodge called the\nG.B.G. (short for Great Brotherhood of God), in his Manual of Sex Magick, the\nmain terms in the code, and their translations, are as follows:\n\n  \n\nRED LION — the male Alchemist, or his penis.\n\nWHITE EAGLE — the Alchemist’s mate, or her vagina.\n\nRETORT — the vagina and/or womb.\n\nTRANSMUTATION — (or transubstantiation) an altered state of consciousness.\n\nELIXIR — the semen.*\n\n  \n\n~•~\n\n* A Manual of Sex Magick, Louis T. Culling, Llwellyn Publications, St. Paul, Minnesota, 1971, p. 57.\n\n~•~\n\n  \n\nApplying this key to Valentine’s gnomic paragraph, we find that he is\ninstructing the novice alchemist to find a suitable mate, and to take a\n\"royal\" or lofty attitude — i.e., he is a Prince, she a Princess, ergo they\nare no longer ordinary people. (cf. Tim Leary’s 1960’s slogan, \"Every man a\nPriest, every woman a Priestess, every home a shrine.\")\n\nThe union of the alchemical mates should be \"neither in cold nor in heat —\nthey must be passionate, not indifferent to each other or merely sensual, but\nthey must not be too damned passionate. That is, they should not gallop toward\nClimax in the manner all too typical of our culture. The sexual communion, in\nshort, should be tantric, leading to the \"transubstantiation\" — a higher state\nof consciousness.\n\nThe late Dr. Francis Israel Regardie, a remarkable chap who had two separate\nselves and careers — as Dr. Francis Regardie he was a neo-Reichian\npsychotherapist, while as Israel Regardie he wrote a series of books which\nhave influenced contemporary American occultism more than the work of any\nother single author — also taught this interpretation of alchemy, but, unlike\nCulling, only in the traditional codes. For instance, in The Tree of Life\nRegardie offers the following advice on how the Cabalistic Magician may add\nalchemy to his working armory:\n\n  \n\nThrough the stimulus of warmth and spiritual Fire to the Athanor, there should\nbe a transfer, an ascent of the Serpent from that instrument to the Cucurbite,\nused as a retort. The alchemical marriage or the mingling of the two streams\nof force in the retort causes at once the chemical corruption of the serpent\nin the menstruum of the Gluten, this being the Solve part of the alchemical\nformula of Solve et coagula . . . The operation should not take less than an\nhour.*\n\n  \n\n~•~\n\n* The Tree of Life: A Study in Magic, Israel Regardie, Samuel Weiser, Ne York, 1975 edition, p. 251.\n\n~•~\n\n  \n\nDr. Regardie offers the further helpful hint that, complex as it sounds, the\noperation is \"no harder than riding a bicycle.\" In correspondence, Dr.\nRegardie cheerfully acknowledged that I had decoded this correctly. Culling\ndiffers from Regardie chiefly in claiming that the ascent of the Serpent\nrequires at least two hours.\n\nIf some readers still feel a bit in the dark about what is involved in the\nprolonged tantric act, consider the following broad hints from Thomas Vaughn,\nanother 17th Century alchemist roughly contemporary with Basil Valentine:\n\n  \n\nThe true furnace is a little simple shell . . . But I had almost forgot to\ntell thee that which is all in all, and is the greatest difficulty in all the\nart — namely the fire . . . The proportion and regimen of it is very\nscrupulous, but the best rule to know it by is that of the Synod: \"Let not the\nbird fly before the fowler.\" Make it sit while you give fire and then you are\nsure of your prey. For a close I must tell thee that the philosophers call\nthis fire their bath, but it is a bath of Nature, not an artificial one; for\nit is not of any kind of water . . . In a word, without this bath, nothing in\nthe world is generated.*\n\n  \n\n~•~\n\n* \"Coelum Terrae,\" in The Works of Thomas Vaughn, ed., A.E. Waite, University Books, New Hyde Park, NY, 1968, pp. 219 — 221.\n\n~•~\n\n  \n\nAs Kenneth Rexroth noted in his introduction to The Works of Thomas Vaughn,\nVaughn seems to have been less concerned with hiding the secret, like earlier\nalchemists, than with making it clear by progressively broader and broader\nhints. There is only one bath from which all creatures are generated and that\nis the bath of vaginal fluids, which is \"not of any kind of water.\" The\nfurnace that is also a shell is a nice poetic image of female anatomy, worthy\nof John Donne — whose poems sometimes suggest that he was in on the secret.\nNote especially Donne’s \"Love’s Alchemy,\" with its \"pregnant pot\" and \"The\nEcstasy,\" with its clear tantric emphasis.\n\nThe \"bird\" (English slang for woman, but also a cross-reference to the\ntraditional Eagle symbolism) must sit while the alchemist gives fire. This is,\nof course, the traditional tantric position, which slows down the sexual\ncommunion and creates maximum intimacy and tenderness. Similarly, the lovers\nin Donne’s \"The Ecstasy\" sit and make \"pictures\" in each other’s eyes, leading\nmost commentators to think no sexual connection was involved, but the yabyum\n(sitting) position of Tantra also demands communion by eye contact.\n\nJohn Donne and other Elizabethans who show signs of knowing this tradition —\nSir Philip Sydney and Sir Walter Raleigh, especially, but try rereading\nShakespeare’s sonnets with this model in mind — probably came under the\ninfluence of Giordano Bruno of Nola, who was lecturing at Oxford while Donne\nwas there. It was during those Oxford years that Bruno published his Eroica\nFurioso, which alternates love poems with prose passages on the union of the\nsoul with God. It is usually assumed that the poems are allegories about the\nsoul’s pilgrimage, but they may just as well be keys to the yoga that produces\nthe ultimate union and communion. (Incidentally, the historian Frances Yates\nbelieves that Bruno was the model for at least two of Shakespeare’s characters\n— Berowne in Love’s Labour’s Lost and Prospero in The Tempest.)*\n\n  \n\n~•~\n\n* Giordano Bruno and the Hermetic Tradition, Frances A. Yates, Univ. of Chicago Press, 1977, p. 357.\n\n~•~\n\n  \n\nBruno, of course, ultimately returned to Italy, where the Inquisition locked\nhim in a dungeon for eight years and then burned him at the stake. Most\nhistorians note only that the Nolan (as he liked to call himself) was\ncondemned for teaching the Copernican theory of astronomy, but actually he was\ncharged with 18 offenses, including practicing Magick and organizing secret\noccult societies dedicated to overthrowing the Vatican. Francis Yates suspects\nthat the latter might be true and finds a Bruno-esque influence in the first\nRosicrucian manifestoes.*\n\n  \n\n~•~\n\n* The Rosicrucian Enlightenment, Frances A. Yates, Routledge & Kegan Paul, Huston, 1974 ed., p. 216.\n\n~•~\n\n  \n\nCertainly, The Alchemical Marriage of Christian Rosycross shows more than a\ntinge of Bruno’s Tantrism, and \"dark sayings\" like \"It is only on the Cross\nthat the Rose may bloom\" strongly suggest both Bruno’s sex-magick and his love\nof paradox.*\n\n  \n\n~•~\n\n* Reprinted in Commentary on the Chymical Wedding, Gareth Knight and Adam McLean, Magnum Opus Hermetic Sourceworks #18, Edinburgh, 1984.\n\n~•~\n\n  \n\n(Two of the Nolan’s favorite koans were \"In filth, sublimity; in sublimity,\nfilth\" and \"In joy, tears; in tears, joy.\")\n\nThe question of how this tantric tradition got into Europe has no clear,\nunambiguous answer. Ezra Pound, in addition to his other achievements and\ninfamies, was one of the leading scholars in the area of early French poetry,\nand in the revised 1916 edition of The Spirit of Romance included a chapter\npresenting evidence that a tantric cult existed in Provence at the time of the\nTroubadours and is referred to guardedly in much of their poetry. In addition\nto the data presented by Pound, I have noted that the characteristic verse-\nform of the Troubadours, seven stanzas, may refer to the seven \"chakras\"\ninvolved in tantric yoga. Certainly, there is nothing earlier in European\nliterature (but much in Tantra) to foreshadow Pierre Vidal’s shocking, \"I\nthink I see God when I look upon my lady nude.\" That was hair-raising\nblasphemy when written; but even more in the inner tradition of Tantra is\nSordello’s lovely:\n\n  \n\nAnd if flee you not, Lady who has captured my soul,\n\nNo sight is worth the beauty of my thought\n\n  \n\nPound guessed (and admitting he was guessing) that this \"yoga of male and\nfemale energies\" had surfaced in medieval France after a thousand years of\nunderground existence as Gnostic heresy. Louis de Rougemont, however, in Love\nin the Western World, presents an impressive body of evidence that the\nTroubadour yoga had been brought back from the Middle East by crusaders who\nlearned it from Arab mystics, probably the more oddball Sufis.*\n\n  \n\n~•~\n\n* Love in the Western World, Denis de Rougemont, Harper & Row, New York 1974.\n\n~•~\n\n  \n\nLouis Culling, op. cit., claims that the tantric tradition in the West is of\ndefinite Sufi origin and is also coded into the Rubiyat of Oma Khayaam. This\nallegation is based, alas, on \"inner teachings\" of various occult orders and\nnot on sources recognized by historians. Surely, there seems to be a tantric\nelement in the 14th Century Sufi Mahmoud Shabistari who wrote, \"In every atom\na thousand rational beings are contained.\"\n\nThe Ordo Templi Orientis (of which Aleister Crowley was Outer Head for a\nquarter of a century) teaches the elements of Tantra in nine slow and\ncarefully scheduled \"degrees\" of initiation; the first degree unambiguously\nattributes this tradition to Sufism in general and, in particular, to Mansur\nel Hallaj — a Sufi martyr who was stoned to death for proclaiming the\neminently tantric (and vedantic) doctrine, \"I am the Truth and there is\nnothing within my turban but God.\" (Some O.T.O. initiates think the true story\nof Mansur is the origin of the myth of Hiram in orthodox Masonry.) In my Sex,\nDrugs & Magick: A Journey Beyond Limits (Falcon Press, 1988), I give some\ncredence to all these theories, but suggest that a major role was also played\nby Hassan i Sabbah, founder of the Ishmaelian sect of Islam, who used both\ndrugs and tantric sex to produce psychedelic experiences, which allegedly\ncaused many to believe they had literally been privileged to experience\nParadise while still alive.\n\nThis is the point at which most commentators on this Art tend to stumble or to\nwave their arms excitedly and start howling in rage. Some think all you have\nto do is adopt the \"right attitude\" during sex and — hey, presto — you are an\nalchemist or a magician or at least a Hermeticist of some sort. Others\nproclaim that all such yoga is \"black\" and \"left-hand\" and undoubtedly\ndiabolical. While I cannot hope to dissolve the prejudices of the latter group\nin a short article, I can at least jar the naiveté of the former group\nsomewhat.\n\nTantric yoga requires at least as much discipline as hatha yoga and as much\ncapacity for loving and giving of oneself as bhakti yoga. To be effective at\nall, that is, the Tantra of sex must have the delicacy of a first-rate ballet\ntroupe and the tenderness of true communion — in the religious sense of that\nterm.\n\nAleister Crowley, our century’s leading proponent of this yoga (and the\nteacher of Louis Culling, by the way) said this yoga requires \"the nine and\nninety rules of Art.\" Elsewhere Crowley expressed this in the mantram, which\nhas many additional meanings outside Tantra, \"Love is the law, love under\nwill.\" One only knows if the art has been mastered if one comes to a state of\nconsciousness in which one can immediately grasp, without doubt or hesitation,\nthe meaning of another of Crowley’s hermetic aphorisms, \"Every man and every\nwoman is a Star.\"\n\nThe power of Tantra may be indicated by the fact that Ezra Pound, who never\nstudied this art under a Master, learned enough from his years scrutinizing\nTroubadour texts that, by 1933, in his essay on Guido Cavalcanti, he speaks of\n\"magnetisms that border on the visible\" and consciousness \"extending several\nfeet beyond the body.\" These are characteristic signs of passing from ordinary\nsex to meta-sex, from the crude act Shakespeare called a \"momentary trick\"\n(and D.H. Lawrence called \"the sneeze in the loins\") to tantric transcendence.\nWhat happens beyond those magnetisms and that expansion of consciousness is\nnot worth discussing; those who know, know — and those who know not will\nsimply not believe.\n\nOne might venture, however, that the mingling of yang and yin magnetisms tends\nto produce a synergetic third which burns up or consumes the original\nelements. Kenneth Grant, an oddball Crowleyan obsessed with menstrual magick\n(\"the Mystery of the Red Gold\"), speaks of this as the \"bisexualization of\nboth partners.\"*\n\n  \n\n~•~\n\n* The Magical Revival, Kenneth Grant, Samuel Weiser, New York, 1974 p. 142.\n\n~•~\n\n  \n\nMore precisely, one can say that, in Chinese terms, active yang becomes\npassive yang, passive yin becomes active yin, and both tend to merge into the\nDao, to re-emerge in new and unexpected forms. Crowley’s notorious 2 = 0\nequation, which he alleged explained the universe and would eventually explain\nquantum mechanics, at least serves as a useful glyph for this stage of the\nalchemical mutation. And, although Crowley loved to play the bogie-man and\nterrorize the naive and nervous, one should take with some seriousness his\nwarning when he says in Magick:\n\n  \n\nThe Cup is said to be full of the Blood of the Saints; that is, every saint or\nmagician must give the last drop of his life’s blood to that cup in the true\nBridal chamber of the Rosy Cross . . . It is a woman whose cup must be Filled\n. . . the Cross is both Death and Generation, and it is on the Cross that the\nRose blooms.*\n\n  \n\n~•~\n\n* Magick in Theory and Practice, Aleister Crowley, Dover Publications, Ne York, 1976, pp. 41 — 42.\n\n~•~\n\n  \n\nOne has to be knowledgeable in both Freudian and Jungian analysis to\nunderstand this even dimly, until one has had the experience. But then\neverybody who did LSD in the 1960’s knows a little about Death and Rebirth; we\nare not a totally unprepared generation for these Mysteries.\n\nThis begins to sound too metaphysical. The processes involved can be defined\nvery materialistically, in terms of exercising to move the center of\nConsciousness from usual domination by the left brain hemisphere and the\nsympathetic (active) nervous system to balance between both hemispheres and a\ngrowing ability to relax into the parasympathetic (passive, receptive) nervous\nsystem. The old mystic terminology lingers on chiefly because it is poetically\nprecise and psychologically highly suggestive.\n\nIt is, however, worth quoting Dr. J. W. Brodie-Innes, an initiate of the\nHermetic Order of the Golden Dawn in England in the 1890’s, who said of the\nrelevance of traditional occult concepts:\n\n  \n\nWhether the Gods, the Qlipothic forces or the Secret Chiefs really exist is\ncomparatively unimportant; the point is that the universe behaves as though\nthey do. In a sense the whole philosophy of the practise of Magick is\nidentical with the Pragmatist position of Pierce the American philosopher.*\n\n  \n\n~•~\n\n* For more writings of Brodie-Innes, see: The Sorcerer and His Apprentice: Unknown Hermetic Writings of S.L. MacGregor Mathers and J. W. Brodie-Innes, rd. R.A. Gilbert, Aquarian Press, Wellingborough, Northamptonshire, 1983.\n\n~•~\n\n  \n\nIn other words, we never know \"the universe\" per se; we know the universe as\nfiltered through our consciousness, and when consciousness alters, the known\nuniverse alters. Crowley defined Magick as \"the art of causing change by act\nof will,\" and Dion Fortune defined it as \"the art of causing change in\nconsciousness by act of will,\" and neither was over-simplifying or being cute.\nThe traditional Aristotelian \"Iron Curtain\" between Mind and Universe has no\nmeaning in magick, for the same reason it no longer has any meaning in quantum\nphysics. As John Lilly wrote:\n\n  \n\n. . . if one plugs the proper beliefs into the metaprogrammatic levels of the\n(brain) . . . the computer will then construct (from the myriads of elements\nin memory) those possible experiences that fit this particular set of rules.\nThose programs will be run off and those displays made which are appropriate\nto the basic assumptions and their stored programming.*\n\n  \n\n~•~\n\n* Programming and Metaprogramming in the Human Biocomputer, John C. Lilly, Bantam Books, New York, 1974, p. 50.\n\n~•~\n\n  \n\nThe Puritan looking at the Playmate of the Month sees something disgusting,\nawful, diabolical, and sinful; Pierre Vidal would see another manifestation of\nthe glory of God. It all depends on the programs in the bio-computer. But all\nprograms have a tendency to become self-fulfilling prophecies; a classic case\nis the sad, melancholy man who sits often in the dark, shunning sunlight, or\nwalks around wearing dark glasses all the time, and gradually becomes even\ngloomier until he arrives at clinical depression. He has created the set and\nthe setting for depression.\n\nConversely, those who achieve Divine Union with a beloved sexual partner tend\nto create their own self-fulfilling prophecies, and the most common effect is\nthat all things become as beautiful as Vidal’s nude lady was when he saw Her\nas God. This transmutation of experience is technically called \"the\nmultiplication of the first matter\" and many alchemists said of it, wittily,\nthat this \"gold,\" unlike ordinary gold, could not be spent or used up, because\nthe more of it you pass on to others, the more of it you find you still have.\n\nAll religions preach charity and forgiveness; but those virtues are hard to\npractice when you are surrounded by sons of bitches. When the alchemical\n\"gold\" is found, when consciousness mutates, you are surrounded by gods and\ngoddesses, and the more of the \"gold\" you give away, the more comes back to\nyou from an increasingly divine Mother Eagle. Quite simply, it is a short and\nalmost inevitable step from Tantra to pantheism. It is no accident that\nWilliam Blake, who, like Shabistari, saw \"infinity in a grain of sand,\" also\npenned the most searing indictment ever written of the puritan and ascetic\nhatred of Eros:\n\n  \n\nChildren of a future age\n\nReading this indignant page\n\nKnow that in a former time\n\nLove, sweet love, was thought a crime.*\n\n  \n\n~•~\n\n* From \"A Little Girl Lost,\" Songs of Experience, William Blake, Dover Publications, NY, 1992.\n\n  \n\n~•~\n\n  \n\n#### Old Man on a Balcony:\n\n#### Views of Monterey Bay #20\n\n  \n\nCalm and quiet here\n\n  \n\nNo anthrax or mad bombers...\n\n  \n\nYet. ...but tomorrow?\n\n\nPart IV\n\n\n### Q&A\n\n  \n\nNothing is known. Everything is imagined.\n\n  \n\n— Federico Fellini\n\n  \n\nNothing is true. All is permissible.\n\n  \n\n— Hassan i Sabbah\n\n  \n\nHell, it’s even more relative than Einstein realized.\n\n  \n\n— J.R. \"Bob\" Dobbs\n\n\nOld Man On A Balcony:\n\nViews Of Monterey Bay #21\n\n  \n\nBiggest damned raven\n\n  \n\nI ever saw flies howling\n\n  \n\ncaw caw caw Lord Lord\n\n\n#### Questions Answered\n\n  \n\nFrom a 1977 interview-by-mail with Neal Wilgus\n\n  \n\nQ: Would I be right in saying you probably lean more toward the libertarian\nform of anarchism than the classical leftist variety?\n\n  \n\nA: My trajectory is perpendicular to the left-right axis of terrestrial\npolitics. I put some of my deepest idealism into both the Leftwing anarchism\nof Simon Moon and the Rightwing anarchism of Hagbard Celine in Illuminatus!,\nbut I am detached from both on another level.\n\nPolitics consists of demands, disguised or rationalized by pseudo philosophies\nor bogus \"social sciences\" (ideologies). The disguise seems an absurdity to me\nand \"should be\" removed. Make your demand explicit. My emphasis is on whatever\nwill make extraterrestrial migration possible — the sooner the better. I want\nto get the hell off Earth for the same reasons my ancestors left Europe:\nfreedom is found on the expanding, pioneering perimeter, never inside the\ncentralized State.*\n\n  \n\n~•~\n\n* Afterthought 2004: I no longer even call myself an anarchist, since that kind of society seems much more far-off and dreamy than it did before 2000. With Bozo in the Oval Office, I would settle for a return to old-fashioned constitutional democracy. That seems pretty damned radical right now, doesn’t it?\n\n~•~\n\n  \n\nTHOUGHTS TO PONDER\n\n  \n\nI never believed in God. Even as a child I thought if He did exist we should\nstart a Class Action suit against Him.\n\n  \n\n— Woody Allen\n\n  \n\nIn Spring 1981 we lived high up in the Berkeley hills and I did this\nconversation with Jeffery Elliot; Arlen read it and claimed I was stoned at\nthe time.\n\n  \n\nQ: What made you want to become a writer?\n\n  \n\nA: As far back as I can remember, I wanted to be a storyteller. When I was 8\nyears old, I started drawing comic strips, which I circulated among other kids\nin the neighborhood. When I was 12, I \"discovered\" that there were books made\nup of nothing but words!\n\nIt seemed much easier to just write the words rather than having to do the\ndrawings to accompany them. I wrote my first novel that year and, of course, I\ncouldn’t get it published. It was about a meek, mild reporter, somewhat like\nClark Kent, who drank a potion which turned him into a virtual Superman-type\ncharacter. His name was Danny Dingle, because it was a comedy rather than a\nmelodrama. In my youthful naiveté, I thought I could sell it as a movie\nstarring Danny Kaye. I wrote quite a few short stories in my teens, all of\nwhich were rejected. I knew I needed a money-making occupation until I became\na success as a writer. As a result, I decided to pursue engineering and write\nin the evenings. Well, after five years as an engineering aide, I realized I\ncouldn’t be a writer and an engineer at the same time. It was too demanding in\nterms of time, so I decided to become, instead, an English teacher.\n\nAlong the way, I got married and ended up in the advertising business instead\nof teaching English. I spent about three years in advertising and then\nescaped, thank God, \"relatively\" undamaged. I’ve spent most of my life since\nthen in various editorial positions at a number of publications.\n\nI also worked at various times as a medical orderly, a salesman, a\nlongshoreman, and an executive. I was an associate editor of Playboy for\nnearly six years. Once, I worked for a sweatshop in New York, where I edited\nfive magazines simultaneously. Actually, this meant I wrote practically\neverything in the magazines under a variety of pen names.\n\nThey had a very low budget. I got $125 a week before taxes for \"editing\"\nand/or writing the five publications.\n\nIt took me an awfully long time to get my first book into print. In fact, I\nsold over 2,000 articles and stories to various magazines before landing my\nfirst book sale. I suppose I have more articles in print (or out of print?)\nthan any other living author.\n\n  \n\nQ: Can you see in your writing any specific stylistic influences in terms of\nother writers whose work you admire?\n\n  \n\nA: Very definitely. I can easily look at my own prose and see whose voices are\nrepresented. There’s a great deal of Ezra Pound, a great deal of James Joyce,\na great deal of Raymond Chandler, a touch of William Faulkner, and a soupcon\nof H.L. Mencken.\n\n  \n\nQ: Did any of these writers prove helpful in the sense of teaching you about\nthe process of writing itself?\n\n  \n\nA: Yes. For example, from Pound I learned that every sentence should have a\nlife of its own. There should be no empty sentences. Basically, I see two\ntypes of writers: one type is interested in getting the damned thing done and\nsold, while the second type really enjoys writing and wants every sentence to\nhave its own wit, its own small surprise. Pound converted me into the second\ntype of writer. I want every sentence to contain a bit of pleasure for me and\nfor the attentive reader; those who snooze simply lose.\n\nFrom Faulkner, I learned how to write long sentences that are modern and\nswing. Henry James writes long, sometimes interminable sentences, but one gets\nlost in the syntax; one doesn’t get lost in Faulkner. Joyce taught me a great\ndeal about how to vary the tone of a paragraph and create emotional effects\nthat are almost subliminal, and how to convey very subtle psychological\nprocesses. Chandler was a major influence, in the sense that there’s not a\nsingle dull sentence in any of his books. I’ve tried to follow that practice\nin my own writing. It’s odd, but I can’t think of a single science-fiction\nwriter who has significantly influenced my style of writing. What I have\nlearned from science-fiction writers, though, is to have an open attitude\ntowards the future. In this sense they’ve influenced my philosophy more than\nmy style.\n\n  \n\nQ: What is it about writing that you find so personally rewarding?\n\n  \n\nA: Well, I think it’s a sexy kind of controlled schizophrenia. It’s also kind\nof yoga, especially novel-writing. Full-time fiction writing is a constant\ndaily exercise in getting outside one’s own head and thinking and feeling the\nway other people think and feel. I often think of story-telling in terms of\nGurdjieff’s work. Gurdjieff, the Russian mystic, devoted most of his energy to\nteaching his pupils how to get outside their own egos and see the world the\nway other people see it. I’ve become very interested in his work in the last\nfour or five years, and it has occurred to me that what he is teaching is what\nevery good novelist learns if he sticks with being a writer. One can’t create\ncharacters who are simply variations of oneself; that gets boring after a\nwhile. One must go way out and create characters who are nothing like oneself.\nWhen one does that, one really learns something about humanity. In that sense,\nI think novel-writing is more educational for the novelist than for the\nreader, especially when the most \"evil\" villains I can imagine start making\nclever remarks and developing ideas of their own and really \"come alive.\"\n\n  \n\nQ: Is a book fully organized in your mind before you start writing or does it\ntake shape as it unfolds?\n\n  \n\nA: Sometimes I have a clearer idea of where I’m going than other times, but it\nalways surprises me. In the course of writing, I’m always drawing on my\nunconscious creativity, and I find things creeping into my writing that I\nwasn’t aware of at the time. That’s part of the pleasure of writing. After\nyou’ve written something, you say to yourself, \"Where in the hell did that\ncome from?\" Faulkner called it the \"demon\" that directs the writer. The\nKabbalists call it the \"holy guardian angel.\" Every fiction writer experiences\nthis sensation. Robert E. Howard said he felt there was somebody dictating the\nConan stories to him. There’s some deep level of the unconscious that knows a\nlot more than the conscious mind of the writer knows.\n\n  \n\nQ: Are you a meticulous writer? Do you agonize over word choice and syntax?\n\n  \n\nA: I’m very meticulous, but I don’t \"agonize.\" It’s all a lot of fun, and no\nmore agonizing than anyone else’s favorite hobby. It varies, however,\naccording to what I’m writing. I’ve written some things as many as 16 times\nbefore I was satisfied with the finished product, but I enjoy myself the whole\ntime. Sometimes, I enjoy myself so much that I collapse from exhaustion. I’ve\nbeen known to work from 16 to 20 hours and fall into bed with a very stiff\nback and wake up the next morning with an acute case of conjunctivitis. Even\nthere, I enjoyed myself all the way through it.*\n\n  \n\n~•~\n\n* Afterthought 2004: \"If youth knew! If age could!\" as some French writer said . . .\n\n~•~\n\n  \n\nQ: Does writing come easily to you? Do the words flow smoothly and\neffortlessly?\n\n  \n\nA: Oh, yes. It comes as easily to me as tennis comes to a professional tennis\nplayer. It’s my game. To me, it’s the third best thing in the world — after\nsex and Chinese food.\n\n  \n\nQ: How do you feel about critics? Do their opinions affect you?\n\n  \n\nA: As William Butler Yeats asked, \"Was there ever a dog that loved its fleas?\"\nCritics have been very kind to me, personally. Of all the reviews of my\npublished books, something like 90 percent have been highly favorable, so I\nhave no personal grudge against critics.\n\nOn the other hand, in an impersonal way, I have a strong moral objection to\nnasty reviewers. Whenever I see a critic tearing a writer or actor or any\nartist to shreds in print, I feel a sense of revulsion. I write a lot of\ncriticism myself, but I only review things I like. I don’t admire people who\nlike to tear other people apart.\n\nI can only think of two unfavorable reviews I’ve written in my whole life, and\nI regret them.\n\n  \n\nPeople who like to write witty, nasty things about other people are not kindly\nor charitable, to put it mildly. We should all try to give out as much good\nenergy to other human beings as we possibly can. I honestly believe that every\nbit of bad energy we put out has adverse effects that go on forever. I sort of\naccept the Buddhist doctrine of karma. The Buddhists believe that every bit of\nanger, resentment, hate, and so on that you send out passes from the target to\nsomebody else convenient to the target, who then gets targeted, and so on,\nwithout stopping. The same is true of good energy: every bit of good energy\none puts out makes someone else feel a little bit better. I think if people\nwere really conscious of this psychological fact, they would try very, very\nhard to put out nothing but good energy, no matter what happened to them. They\nwould certainly not be so casual about passing on bad energy. All the bad\nenergy in the world builds up like a giant snowfall, until we have a huge\nwar.* Nowadays, it can mean a total nuclear Armageddon.\n\n  \n\n~•~\n\n* Yeah, Arlen got it right: I must have toked a bunch o’weed before delivering myself of that sermon...\n\n~•~\n\n  \n\nThis comes from traditional Buddhism, as I say, but I think it’s materialistic\ncommon sense, too. One only needs to study human behavior to realize it. I\nregard those people who make a career out of being nasty as emotional plague\ncarriers. Serial killers generally start out as children who torture animals;\nimagine how the average reviewer started out. Pulling wings off bugs?\n\n  \n\nQ: As you look back over those pieces you wrote early in your career, can you\ndetect clear signs of stylistic improvement?\n\n  \n\nA: I hope so. I would rather be gored by a rhinoceros than see some of my\n1950’s pieces be reprinted now! Even some of my 1960’s pieces, I hope, are\nlost forever.\n\n  \n\nQ: In what ways has your writing improved over the years?\n\n  \n\nA: I hope I’m less acerbic, less dogmatic, less \"moralistic,\" and more\ncharitable.\n\n  \n\nQ: Are you concerned that your work has didactic value, that people learn from\nit?\n\n  \n\nA: Absolutely! Didactic literature is very much out of style these days; if\none is suspected of having a message, it’s almost regarded as some kind of\nsecret vice. I think, however, that all first-rate literature leans toward the\ndidactic. The classic Greeks regarded Homer as didactic and allegorical to\nboot. Dante seems didactic. Shakespeare seems didactic. Melville seems\ndidactic. Science fiction is the most didactic literature around; that’s why I\nenjoy it so much.\n\nAll writers function as teachers, whether they’re conscious of it or not, or\nwhether they’ll admit it or not. For example, take Mickey Spillane. He used to\ngive interviews in which he said he only wrote books for money. However, if\nyou look at his work, it’s obvious he has very strong beliefs. He’s always\npitching them at the reader. They’re rather fascist beliefs, but they’re\nbeliefs nonetheless, and he’s a teacher, just like every other writer.\nUnfortunately, he’s only teaching a violent, fascist morality.\n\n  \n\n#### Old Man On A Balcony:\n\n#### Views Of Monterey Bay #22\n\n  \n\nPurple, vermilion:\n\n  \n\nEach part of the bay glitters\n\n  \n\nAnd none is just blue\n\n\n#### More Questions Answered\n\n  \n\n1988 — with David Jay Brown in Los Angeles\n\n  \n\nQ: It is April 23, 1988, a significant day in Robert Anton Wilson’s\nphilosophy. What is the significance of 23?\n\n  \n\nA: Well, 23 has popped up in my life connected with so many synchronicities\nand weird coincidences that it must mean something. In several of my books,\nincluding the Illuminatus! trilogy and Cosmic Trigger, I have given examples\nof a tremendous number of coincidences connected with 23. Take today as an\nexample, April 23: this is the anniversary of Shakespeare’s birth, April 23,\n1556 and his death, April 23, 1616. Also April 23, 1616, the same time\nShakespeare died in England, Cervantes, author of Don Quixote, died in Spain.\nApril 23, 1014 is when Brian Boru died; he was the first high king of Ireland\nto be a political as well as religious leader. He unified all Ireland and\ndrove the Danes out, and on April 23, 1014 he was killed by one of the Danes\nafter the battle of Clontarf, where he defeated the Danes for the final time,\nand liberated Ireland from foreign rule. August 23, 1170 is when the Normans\ncame in, and Ireland has been under foreign rule again, in whole or in part,\never since.\n\nOn August 23, 1920 James Joyce was discussing coincidences with a friend in a\nParis bar when he suddenly saw a giant black rat which scared the blue jesus\nout of him, by Christ; he fainted dead away. So that ties Joyce together with\nthe invasion of Ireland, and Shakespeare, and Brian Boru. All of this is in\nFinnegans Wake by the way.\n\n  \n\nQ: You have a whole series of books focusing on the Illuminati. What is the\nIlluminati, and how did it become an inspiration for so many books?\n\n  \n\nA: Well, the Illuminati was a secret society in Europe in the 18th Century. A\ncertain number of \"paranoid\" or at least unorthodox theorists believe the\nIlluminati still exists and has either taken over the world, or taken over\nmost of the world, or something like that.\n\nI discovered the anti-Illuminati literature in the late 1960’s when there were\nall sorts of weird conspiracy theories going around. And then I discovered\nthere were two ambiguities connected with the Illuminati. First, there are\nthose who say the Illuminati doesn’t still exist, versus those who say the\nIlluminati still exists; and then among those who say the Illuminati do exist,\nthere are two schools of thought: those who claim they’re the arch-villains of\nall history, and those who claim they’re the heroes who are trying to liberate\nthe human race from superstition and ignorance. And so, I decided a group that\nambiguous — where we don’t know whether they exist or not, and we don’t even\nknow, if they exist, whether they’re the good guys or the bad guys — they’re\nthe perfect synecdoche, to me, for all the confusions of the age we’re living\nthrough, and all of the rampant paranoia of our time.\n\n  \n\nQ: How did you first become interested in Aleister Crowley?\n\n  \n\nA: Sometime around 1969, I was having lunch with Alan Watts and I mentioned\nthe Illuminatus! trilogy, which I was working on at the time, and the\nsymbolism of the eye on the pyramid, which is the symbol of the Illuminati.\nAnd Alan said, that reminds me, the best book I’ve read all year is called The\nEye in the Triangle by Israel Regardie, and I took Alan Watts very seriously.\nI mean, he was a very funny man, but when Alan said something was worth\nreading, I took that seriously, so I went out and bought The Eye in the\nTriangle, and it turned out to be a biography of Aleister Crowley. Israel\nRegardie was Crowley’s secretary for a while in the 1930’s. Then, later, he\nwas a psychotherapist right here in Los Angeles. I got into correspondence\nwith Dr. Regardie for several years, before his death, and learned quite a bit\nfrom him about Crowley’s work.\n\n  \n\nQ: The average person would think of a magician as a side-show entertainer.\nWhat is a magician, in your definition?\n\n  \n\nA: Well, it’s an ambiguous word. It can refer to prestidigitation, conjuring,\nother show business tricks, or it can refer to the ancient science of the\nmagi, which is where the word magic comes from etymologically, it’s the\nscience of the magi. It’s the science of rapid, voluntary brain change, how to\nuse the human brain for fun and profit.\n\n  \n\nQ: That brings us to something you’ve written about called the HEAD\nRevolution: Hedonic Engineering and Development.\n\n  \n\nA: The HEAD Revolution is my term for what’s been happening since the 1960’s,\nthe discovery of newer and better technologies for rapid alteration of brain\nfunctioning. We’ve gone from psychedelic drugs, to biofeedback and Lilly\nisolation tanks, and a lot of fascinating new machines like the Mind Mirror,\nwhich is an accelerated biofeedback system that gives you a continuous profile\nof both hemispheres of your brain, and which frequencies they’re working on.\n\nI regard this as a great example of the evolutionary function of stupidity.\nWhen the government made psychedelic research illegal in the 1960’s\n(scientific, open, aboveboard research I mean — that did not stop research —\nthe research just went underground, together with a great deal of partying and\nhell-raising and whatnot with those drugs). I thought it was the stupidest\nthing the government ever did. But in retrospect I think stupidity has an\nevolutionary function, because when they stopped that research, all the\nleading researchers in the field went into other areas, and so we’ve\ndiscovered dozens of other ways of rapid brain change.\n\nLilly worked on his isolation tank; others went into biofeedback; Stan Grof,\nwho came to this country seeking scientific freedom because he felt he didn’t\nhave enough scientific freedom in Czechoslovakia, and over here they told him\nhe couldn’t do any more LSD research, so he went to work on breathing\ntechniques and the effect of sound on the brain, and has developed some very\ninteresting post-Reichian, post-yogic techniques of brain change. So, by and\nlarge, the stupider the establishment is, the smarter the rebels become.\nEstablishment stupidity is the greatest spur to creativity in evolutionary\nhistory. That’s why I think Reagan has been a godsend to this country. He’s\nbrought more stupidity to Washington than anybody in my lifetime, and there’s\nbeen a tremendous upsurge of creativity while he’s been in there.\n\n  \n\nQ: In the 1970’s you and Leary came up with the SMIILE formula, which stands\nfor Space Migration, Intelligence Increase and Life Extension. Do you still\nfind those three things to be important?\n\n  \n\nA: Very much so. Space migration feels tremendously exciting to me, because\nit’s the opening of a new frontier. Historically, every time a new frontier\nhas opened, there’s been a big upsurge of creative energies, a Renaissance\neffect, a creativity boom, and the human race badly needs that at this point.\nAlso, I think most of the energy problems that it’s fashionable to worry about\nwill be solved when we get out of the closed system of one planet and start\ndealing with many worlds. When we have hundreds and hundreds of space colonies\ndotted all over the earth-moon system, or as far out as the asteroid belt\nprobably, then there won’t be any more energy problem, there’s so damn much\nenergy out there compared to the energy available on the surface of the Earth.\nAnd it will also solve the population problem; more and more people will be\nmigrating into space, I’m sure. I want to go myself — some people think that’s\nwhimsical in a man my age, but I’m expecting rejuvenation technology will be\nalong in the next 15-20 years of bio-tech research.\n\n  \n\nQ: The Life Extension part of SMIILE.\n\n  \n\nA: Yes, I figure 20 years from now, I’ll be 20 years younger instead of 20\nyears older.\n\n  \n\nQ: Do you have a favorite of the books that you’ve written? I think my\npersonal favorite right now is the Schrödinger’s Cat trilogy.\n\n  \n\nA: Bless you, sir — that’s about to be reprinted, I’m happy to say. But when\nit first came out it got more bad reviews than anything else I’ve ever\nwritten; it only got two good reviews I ever saw. The LA Times said it was\n\"hilarious, multi-dimensional, a laugh a paragraph,\" something like that. New\nScientist in England had the other good review, they said it was \"the most\nscientific of all science-fiction novels.\" Everybody else bum-rapped it. One\nsensitive soul got so furious that he actually wrote three denunciatory\nreviews of it for three different sci-fi magazines. Like he would have buried\nit with a stake through its heart if he could have . . .\n\nAfter that, it went out of print quickly in this country and for seven years\nthe only money I made from it came from the German and English editions.*\n\n  \n\n~•~\n\n* It has remained in print even in America since the second edition, and some years even outsells Illuminatus! Caloo Calay! O frabjuous day! And, as for that guy with the three bad reviews, every now and then I remember all the snotty things he said and I sob all the way to the bank.\n\n~•~\n\n  \n\nTHOUGHTS TO PONDER\n\n  \n\nThe fundamental article of my political creed is that despotism, or unlimited\nsovereignty, or absolute power, is the same in a majority of a popular\nassembly, an aristocratical council, an oligarchical junta, and a single\nemperor: equally arbitrary, cruel, bloody, and in every respect diabolical.\n\n  \n\n— John Adams\n\n  \n\n1994 — with James Nye in London\n\n  \n\nQ: What are your current views on the alien abduction phenomenon?\n\n  \n\nA: Jeff Mishlove has edited an enormous book called The Roots of Consciousness\nwhich examines classic studies in parapsychology over the last hundred years.\nJeff has a masters in criminology, and the only Ph.D. in parapsychology given\nby the University of California. He’s made a study of the phenomenon and\nconcludes that there are various layers to it.\n\nThere are people who think they’ve been meddled with by \"visitors\"; others who\nthink that relatives took them to satanic rituals where they were sexually\nabused and sacrifices occurred; and others who think that relatives abused\nthem.\n\nJeff’s conclusion is that they were probably sexually abused in childhood and\nthis created a situation — a response to trauma — in which their fantasy life\nis just as \"real\" as their ordinary life, and they’re always working on\nvariations on their traumatic memory. The abusers — \"real\" or \"imagined\" —\nbecome aliens, devils, incubi or succubi. That’s one kind of case.\n\nOthers, I think, start out as sleep paralysis — a state I have experienced\ntwice in-my 62 years. In pure sleep paralysis, you simply feel paralyzed and\ndon’t know whether you’re dreaming or awake. In other cases, this is\naccompanied by a nightmare-like fantasy; in my two cases, this merely\nconsisted of a fearful sense that something awful was in the room. In each\ninstance, I awoke before it went further. But I think for some reason it might\nescalate to a \"real hallucination\" — lovely oxymoron! — in which the\n\"something awful\" becomes any kind of monster you have in your fantasy library\n— aliens, demons, whatever.\n\n  \n\nQ: What about apparent physical phenomena connected with visitation —\nradiation burns, spirit rappings? The Elizabethan magus John Dee reported\nstrange knockings which proceeded his visitation by \"angels,\" and Strieber\nalso alleges hearing knocking patterns . . .\n\n  \n\nA: In my book The New Inquisition I describe Persinger’s theory that there are\ntransient energy fluctuations in the Earth’s electromagnetic and gravitational\nfields which may account for poltergeist disturbances, cars stalling,\ntelevisions turning themselves on and off, ball lightning — a great deal of\nthe UFO experience. Persinger also describes how this might affect the brain\nand create hallucinations. I think Persinger has an explanation for much of\nthe phenomenon, but not quite all. We are surrounded by equipment whose\neffects on us are not fully known. One of Philip K. Dick’s favourite themes\nwas: How do we know that our brains aren’t continually being altered, that the\nreality we experience isn’t entirely programmed? The violence of Total Recall\nis not PhilDickian, but they really got the mood right in the scene where the\nhero is told what he thinks he’s experiencing on Mars is being done to him in\na laboratory, on Earth.\n\n  \n\nQ: I once had a dream communication from [Philip K.] Dick: \"Experience of\ntelepathy does not necessarily indicate psychosis\"!\n\n  \n\nA: That sounds like Phil! Ray Nelson was going to collaborate with Phil on a\nnovel when Phil died. Nelson then began having dreams in which Phil started\ndictating the plot — so he’s working on it and going to publish it as a joint\nnovel! Another friend of Dick’s is D. Scott Apel who co-edits my Trajectories\nnewsletter. He’s also working on a novel in dream collaboration with Dick. In\nthe first dream, Phil told him that \"the secret is in the centre of\nDisneyland.\" The curious thing is that another friend goes to Disneyland once\na year, takes acid and talks to Mickey Mouse. Whoever is in the suit gives\nanswers to this fellow’s questions that seem profound enough to satisfy him.\nHe is the only one I know whose god is visible, tangible and responsive.\n\n  \n\nQ: Dick thought at one time that he might have temporal lobe epilepsy — a type\nwhich might prompt visionary experiences. Strieber also tested (negatively)\nfor TLE, and I understand it is one of the parts of the brain Persinger is\ninterested in.\n\n  \n\nA: One of Phil’s therapists suggested that sexual abuse by his grandfather\nmight have been the root of his problems, so this ties Phil in with current\ntheories of the abduction phenomenon. But Phil had a much more developed mind\nthan some of these victims and drew a whole cosmology out of it — one of the\nmost fascinating world views I’ve ever studied. I often think his ideas make\nmore sense than Christianity or Hinduism, or atheism or Forteanism, and then I\nthink \"this is the ravings of a madman, how did I get sucked into this!\" But\nthen I read more, and start to wonder again . . .\n\n  \n\nQ: I often wonder how much social isolation has to do with this. I’m not just\nthinking of Biblical prophets and hermits, but people in solitary confinement\nwho sometimes start hallucinating within hours . . .\n\n  \n\nA: And yet some people do very well in solitary. Timothy Leary said it was one\nof the most productive periods of his life. He said the only person he had to\ntalk to was the most intelligent person he knew. He had a great time\nphilosophizing about the universe and his role in it.\n\nIt’s very strange that Leary’s books don’t sell well, but he does well on the\nlecture circuit. We’ve done a double act together: the Laurel and Hardy of the\nfuturist intelligentsia — or the space cadets, if you like. Leary’s books on\npsychology and cosmology are very far out; generally they are regarded as\nproof that his brain is blown by all the drugs he’s done. A few people I know\nunderstand them — we think they’re brilliant, but maybe our brains have been\nblown by those drugs, too. He’s also writing very successful computer\nprograms. For someone who’s supposed to be brain damaged by drugs, he’s pretty\ngood at designing software.\n\nLeary and I appeared at the Libertarian Party Convention in Chicago. Coming\nback on the plane we met Guns and Roses, who love him — everyone knows Leary.\nAnd Tim got drunker and drunker on his bottle of Scotch, and finally he says\n\"Fuck it! I’m gonna have a cigarette!\" You’re not allowed to smoke on U.S.\nairlines anymore, so the whole of Guns and Roses gathered round to conceal\nhim. At this point, one of the stewards sees Leary’s smoking and comes over,\nand he says to Tim, \"I just want to tell you I think you’re right about\neverything!\" When we got off the plane, Leary spotted a wheelchair and got a\nJoyce scholar to push it for him through the airport. I was a bit drunk, too,\nby then, so as we raced through the crowd, I pointed to Leary in the\nwheelchair and shouted \"Chromosome damage, chromosome damage!\" Wonderful\nnight, wonderful . . .\n\n  \n\nQ: What’s your connection with the Church of the SubGenius and its deity J.R.\n\"Bob\" Dobbs?\n\n  \n\nA: Well, Rev. Ivan Stang told me I was one of his main inspirations — but\nmaybe he says that to all writers he wants to get on the good side of. There\nare a lot of my ideas in the SubGenius mythos, so maybe \"Bob\" was named after\nme . . . Maybe I should start using the inverted commas?\n\n  \n\nQ: In your second volume of autobiography, Cosmic Trigger II, there is a hint\nof resignation. You say that you would like to be shot into space and listen\nto Scarlatti. Have you given up on mankind?\n\n  \n\nA: The book was an attempt to present different sides of my personality as\nthey’ve developed in time, and so you get the past mixed up with the present.\n\nThe past does not always unfold chronologically. It’s the same with ideas —\nsome I held for a long time, some I held for just one afternoon. The book’s an\nattempt to show that there is no consistent ego. It’s a Buddhist book. So the\nresignation was just a mood that George Bush [Sr.] put me in around the time\nof the Gulf War.\n\n  \n\nQ: One of the recurrent themes of your writing concerns belief . . .\n\n  \n\nA: Not believing in anything, not disbelieving in anything — that may be one\nof the most important of the ideas in my books, though I hardly invented it.\n\nIt’s characteristic of modern physicists to have that attitude. It also ties\nin with Fort’s notion that the product of minds is not acceptable as subject\nmatter for belief — except temporarily.\n\nCSICOP — the Committee for the Scientific Investigation of Claims of the\nParanormal — for instance are profound believers in conventional paradigms.\nThey call themselves \"skeptics,\" but Catholics are just as skeptical — only\nabout different things. Everybody has an area of belief and an area of\nskepticism. CSICOP’s dogmas are as rigid as anyone else’s. I heard a bloke\nfrom CSICOP denouncing chiropractors on the radio. I got so pissed off I\ncalled in and quoted the Office of Technology Assessment of the National\nScience Institute in Washington. They regard something as scientifically\nconfirmed if it has had a period of randomized double blind experiments which\nhave been published in several refereed scientific journals. By that standard,\n85% of American medicine hasn’t been verified, so CSICOP is in no position to\nthrow stones at chiropractors.\n\n  \n\nQ: Much of your early writing is influenced by Aleister Crowley. Do you have\nany reservations about him?\n\n  \n\nA: In Cosmic Trigger I, I said that Crowley’s philosophy is a combination of\nanarchism, fascism, and anti-Christian propaganda, which is not very congenial\nto my form of Libertarianism. So I’ve always tried to make a distinction\nbetween his method and his philosophy. He is part anarchist, part fascist —\nand I like the anarchist part.\n\n  \n\nQ: One Crowleyite told me that Crowley’s magick is \"qliphophthically booby-\ntrapped.\"\n\n  \n\nA: I’ve heard that — I don’t agree with it. I’ve done a lot of Crowley rituals\nand I don’t see any sign yet that I’ve been obsessed, possessed or otherwise\ntaken over by qliphophthic energies or entities. I think it’s a paranoid anti-\nCrowley idea that’s been spread, and like much else in that field, has become\na self-fulfilling prophecy. If you’re worried that Crowley’s system is booby-\ntrapped, and you start fooling around with it, you’re likely to suffer\nhallucinations that you are being attacked by demons. Similarly, the fears of\nthe dangers of LSD can precipitate a bad trip.\n\n  \n\nQ: In Cosmic Trigger I, you hypothesize about apparent telepathic\ncommunication emanating from Sirius. What’s your view about those experiences\nnow?\n\n  \n\nA: Sirius seems to have been rambunctious at the time. Doris Lessing wrote The\nSirian Experiments around the same time I was having my Sirius experience.\nPhil Dick had his extraterrestrial experience (which for one reason or\nanother, he connected with Sirius) about the same time. I used to think he got\nthe idea after he read Cosmic Trigger I, but one of the recent biographies of\nPhil makes it perfectly clear that he connected his experience with Sirius\nbefore he read Cosmic Trigger. So that makes it even more interesting . . .\n\n  \n\nQ: The composer Karlheinz Stockhausen may have got his notions about Sirius\nfrom Edgar Varese, who was involved with the late 19th Century Parisian\nRosicrucian revival, and perhaps got it from there — or from the writings of\nParacelsus with whom he was fascinated. I wonder if the Rosicrucians are the\nsource for Varese — especially with the importance of Sirius to occult groups\nsuch as the OTC. and A .·. A .·. which you have traced?\n\n  \n\nA: Well, there are a lot of occult traditions connected with Sirius. Among\nother things, Sirius is the brightest star in the sky, so if people are going\nto focus on anything out there — especially in the ancient world — Sirius\nwould be very important. Particularly in Egypt, where it happens to rise just\nat the same time the Nile starts its annual flooding. I mention in Cosmic\nTrigger I something I picked up from Theosophy: just as in yoga you activate\nthe heart chakra and then move the energy up to the crown chakra; this is\nhappening to the \"Cosmic Being\" which is trying to move the energy up from our\nSun to Sirius.\n\nIn Dublin I met somebody who told me — on the basis of God knows what\nauthority besides his own imagination — that above the 33rd degree of Masonry,\nunknown to the world, there is actually an illuminated inner circle which is\nin touch with Sirius. I thought I’d invented that myself, but this guy is\ntelling me this like it’s an inner secret of Masonry! But maybe that’s what\nHugh Kenner calls an \"Irish fact,\" which is quite unlike an English fact, an\nAmerican fact, or a French fact, and has no connection with a scientific fact.\nAn Irish fact has the wonderful Daliesque fluidity of a melting clock and the\nJoycean uncertainty of a rubber inch.\n\n  \n\nQ: When did Robert Temple’s book The Sirius Mystery come out in relation to\nyour experiences?\n\n  \n\nA: Well, it came out after I had my experiences (which I first attributed to\nSirius — and then to the Pookah, a giant white rabbit from County Kerry —\ndepending on which metaphor suited me at the time). His book came out after\nthe experiences, and just at the point when I was giving up Sirius as an\nexplanation for my experiences, and more inclined to look at it in terms of\nbrain processes: the left hemisphere and the right hemisphere talking to each\nother, learning to communicate. So I was just about through with the Sirius\nmodel, and then Temple’s book came out trying to show that there had been\nconnections between Earth and Sirius for about 4,000 years! So it did make me\nlook back and reconsider the Sirius aspect of it. And then along came Phil\nDick’s novel VALIS!\n\n  \n\nQ: So the Sirius model could be a screen for something more personal?\n\n  \n\nA: That’s what I think most of the time. Every now and then something about\nSirius comes to me from somewhere and I start thinking, \"Well who knows, maybe\nI should take it literally?\" But that’s 5% of the time; 95% of the time I tend\nto look at it as neurological evolution.\n\n  \n\nQ: How then do you account for the Dogon tribe of Mali knowing about Sirius B,\nthe dwarf companion to Sirius which cannot be seen by the naked eye — and was\nonly photographed using the most powerful telescopes in the early 1970’s?\n\n  \n\nA: I don’t account for that; I regard that as a mystery. I remember that a\nwriter in CSICOP’s journal The Skeptical Inquirer pointed out that the Dogon\ncould have learnt about this from a Jesuit missionary or a wandering explorer,\nor a merchant who digs astronomy — and I thought, yeah, all of that is\npossible. But then the writer concludes that therefore we don’t have to take\nit seriously. Hell, the writer’s mother could have got knocked up by the\ngrocer or the delivery boy, or the ice man, or the postman — therefore we\ndon’t have to consider the hypothesis that his conception might have been due\nto the guy actually known as his father!\n\nI didn’t bother sending that additional bit of skepticism to them because I\nknew they wouldn’t print it. They’re very selective about what they doubt.\n\n  \n\nQ: Temple also seems to have been at pains to point out that the Dogons got\ntheir information from ancient Egyptian sources as well — so the question is\nreally how did the Egyptians know of Sirius B’s existence?\n\n  \n\nA: I have an open mind about these things, but don’t have any dogmas. I await\nfurther enlightenment.\n\n  \n\nc. 2000 — with Sean Casteel\n\n  \n\nQ: You have an excellent sense of humor that keeps a reader engaged . . .\n\n  \n\nA: Without a sense of humor, life is utterly unbearable on this barbaric\nplanet.\n\n  \n\nQ: Yeah, I know what you’re saying. In your introduction to Everything Is\nUnder Control [Harper, 1999], you quote a poll that says three out of four\npeople believe the government is engaged in at least some kinds of\nconspiracies. Then you go on to say the government also mistrusts the people\nit governs. Would you expound on that vicious circle here?\n\n  \n\nA: Sure. The people mistrust the government for a variety of reasons: some of\nthem psychological, some of them sociological. We’ll come to that later. For\nthe present, we’ll just say that one of the reasons is that the government has\nbeen caught repeatedly telling outrageous lies, under both Republican and\nDemocratic administrations going back to the 1950‘s. And, as a matter of fact,\nyou can find some pretty outrageous lies even earlier than that. Eventually,\nrecognition of this does dawn on a large percentage of the population.\n\n  \n\nQ: Then you went on to say that the government also mistrusts us.\n\n  \n\nA: The government has no idea who we are. This is what I call the burden of\nomniscience. The government is supposed to know everything, but the power they\nwield guarantees that they generally know nothing. They never hear anything\nthat doesn’t suit their prejudices because nobody dares to tell them. The top\nechelon of the government has so much incredible power that everybody is\nterrified of it. So nobody ever tells it the truth. They tell it always and\nonly whatever they think will keep it from going ballistic. So the people at\nthe very top are told flattering lies filtered through several layers of\nflattering liars who’ve been lied to by those below them.\n\nI have been conducting workshops on neurolinguistics and general semantics for\na long time — four decades. And I frequently ask audiences, \"Has anybody ever\ntold the complete and utter truth without reservations to anybody from the\ngovernment?\" Nobody ever puts up their hand. Nobody claims to be that trusting\nand docile and submissive. Everybody lies a little or hides a little when\ndealing with the government. People lie as much as they think is necessary to\nsurvive, to go on living without getting this beast on top of them. The\ngovernment is armed and dangerous.\n\nAnd so the government has no idea who we are or what we want. So they distrust\nus profoundly, because every time they write laws they think we’re going to\nlike, we don’t like them. And so they’re continually running into opposition\nfrom us. And they don’t think we have any right to meddle in our own affairs\nanyway, to begin with, because they’re supposed to be the governors. We’re\nonly supposed to be the subjects or the serfs. The Constitution says they’re\nour servants, but none of them believe it. They think they’re our Masters, and\nthey act that way.\n\n  \n\nQ: You also talk about the government’s response to its own inability to trust\nus is to create further oppressions which then amplifies the mistrust of the\npeople, and it becomes like a vicious circle.\n\n  \n\nA: The more they spy on us, the more paranoid more people become about them.\nWhen they spy on our very innards, our bladder and urine, we’re beyond the\nstage of the Gestapo or KGB; we’re in the realm of Kafka. And the more\nparanoid the people become, the more they’re likely to resort to er um hostile\ngestures like the Oklahoma City bombing, for instance. And something even\nworse than that may be coming down the pike. Most people in this country don’t\ntrust the government, are terrified of it and kind of wish it would go away.\nAnd the government, accordingly, doesn’t trust us. As Bertold Brecht once\nsaid, \"Why don’t they find another people and go govern them?\"\n\nBut they don’t want to find another people to go govern. They insist on trying\nto govern us even while they don’t trust us. So they’re spying on us more and\nmore to see if we’re plotting to get rid of them. I think most of us would\nlike to get rid of them, but only a few nuts think it’s possible or can be\nachieved by dynamite, but the government thinks we’re all potential bombers.\nThey know we hate them. They know most of us don’t even bother voting, for\ninstance. They just don’t know when our passive disgust might turn into\nviolent revolution. That’s not totally irrational; we ourselves don’t know how\nmany Timothy McVeighs there are among us.\n\n  \n\nQ: What about the idea of people needing some kind of conspiracy to justify\ntheir day-to-day misery? That something is lurking out there that’s\nresponsible for all their personal pain?\n\n  \n\nA: That’s what I call the \"blame game.\" When you have problems, there are two\napproaches. One is to try to solve the problem. The other is to find somebody\nto blame for it so you don’t have to go to all the trouble of solving the\nproblem. And with humans being largely a bunch of lazy bums, the second\nsolution is much more popular. Don’t try to fix the problem, find somebody to\nblame for it. That is why there are so many totally nutty conspiracy theories\nfloating around.\n\n  \n\nQ: How much credence do you lend to the idea that genuine aliens could be\ninvolved in some of these conspiracies in real-world-terms? Do aliens exist\nfor you, and do you think they conspire with the government?\n\n  \n\nA: I think the literal form of that model, brought forth by Bill Cooper and\nWilliam Moore and others of that persuasion, is a wonderful metaphor, a great\nplot for a science-fiction story. But I can’t take it literally. I just can’t\nbelieve in it. The aliens in these scenarios come right out of bad 1950’s\nscience-fiction B-movies. I’d find it easier to believe that Snow White and\nthe Seven Dwarfs were piloting all the UFOs . . . or the Three Stooges . . .\n\nOn the other hand, the idea that there are forces we don’t understand involved\nin some of the shenanigans on this planet does have a certain plausibility to\nit. The more you look into these things, the more you feel that there is a\nplayer on the other side. I feel like Thomas Henry Huxley, the great agnostic\n— a guy who was an enemy of religion all his life — and yet in one passage in\none of his essays, he says we’re like people playing a chess game, where the\npieces are the phenomena of the universe, the rules of the game are the laws\nof nature we’ve discovered so far, but the player on the other side is still\ninvisible. I classify UFOs, and the paranormal in general, and Fortean\nphenomena as acts of the \"player\" on the other side that we don’t understand\nyet.\n\n  \n\nQ: You say at the end of the book that you wish all the conspiracies you had\nwritten about were as easy to dismiss as the Zionist Occupied Government\nconspiracy. What conspiracies do you have a hard time dismissing? What are the\ntop two or three that seem possible to you?\n\n  \n\nA: The Multi-Conspiracy Model, which I heard from Timothy Leary and later from\na District Attorney of, I think, Santa Barbara, whom I met at Big Sur. It’s\nalso the model used by historian Carl Oglesby.\n\nThis theory holds that any town, once it gets beyond being a one-horse town\nout of the Westerns — any town that has a bank and a grocery and a lot of real\nestate and a lot of people, even before it becomes a big city — there are\nalways a minimum of 24 gangs fighting over who’s going to dominate the town\nand own most of the real estate and make most of the profits. So they’re all\nconspiring against one another.\n\nWhen you get up to the size of a whole state, there are 24 bigger\nconspiracies, or 30 maybe. When you get up to the nations, there are God knows\nhow many of them. They’re all conspiring and they’re all willing to break the\nlaw whenever it’s in their interest. They even lie. I know you get called\nparanoid for saying it out loud, but bankers and politicians do tell lies\nsometimes.\n\nRoberto Calvi, who was one of the bankers in one of the biggest conspiracies,\nthe P2 conspiracy in Italy, often said, \"Read The Godfather. That shows you\nhow the world really works.\" In other words, all power groups act\nfundamentally like the Mafia. And the Mafia is not a monolithic conspiracy. It\nis a conspiracy or secret society that hangs together part of the time and\nmakes war on itself part of the time. Calvi worked intimately with the Mafia\nand with Arab terrorists and international bankers, and he thought they all\noperated like Don Corleone.\n\n  \n\nQ: So you’re talking then about a multiple conspiracy that’s mostly directed\nat making money?\n\n  \n\nA: Exactly. I think that there are multiple conspiracies and occasionally five\nor six of them will join together to make a Mega-Conspiracy for a given period\nof time to accomplish a given result. But I don’t see any evidence that\nthey’ve all worked together since the dawn of time to the present. Mostly\nthey’ve been fighting with one another.\n\n  \n\nQ: Do you see everything as a conspiracy?\n\n  \n\nA: No. Somebody once accused me of claiming that everything is subjective, but\nI don’t make statements about \"everything,\" I only make statements about\nsombunall things. I suspect conspiracy is very prevalent behavior on this\nbackward & barbaric planet. It even precedes humanity. Lions conspire — one\nlion will frighten a herd of antelope to get them running in a certain\ndirection where the other lions will be waiting there to eat them. That’s a\nconspiracy against antelopes, and I’m sure the antelopes are very pissed off\nabout it. \"Damned lions, can’t trust those motherfuckers no way.\"\n\nAnts conspire, they seize territory and drive off interlopers; rats have very\nvigorous conspiracies — when a rat from a strange pack gets into a house\nthey’ll hunt him down and kill him. It’s just like the Mafia: \"We don’t like\nyou moving in on our territory.\"\n\n  \n\nQ: Is it possible for a conspiracy to be benign?\n\n  \n\nA: I have to give you a \"Yes but\" answer on that.\n\nOne difference between a conspiracy and an affinity group is that when me and\nmy friends do it it’s an affinity group and when someone we don’t like does it\nit’s a goddam conspiracy. Conspiracies run the literary world, the art world,\netc.; marijuana arrives here due to conspiracies; etc. Modern \"liberal\"\nintellectuals are the first and only group to ever believe that conspiracies\nnever happen. That’s like claiming it never rains or snows; we just see other\nthings falling and we mistake them for rain and snow . . .\n\n  \n\nc 1996 — A chat with Randy Lee Payton\n\n  \n\nQ: Why do you claim you don’t believe anything?\n\n  \n\nA: \"The map is not the territory,\" as Korzybski said. Any map you make of the\ncity you live in can’t show the whole city. It would have to show you, and it\nwould have to show you drawing the map, and it would have to show you drawing\na map of the map . . . so every map is a simplification.\n\nAnd words are like maps . . . and how much can you put in a sentence? And\nbecause of this a lot of modern scientists believe we should drop the word\n\"is\" entirely because \"is\" tends to lead us to confuse our verbal categories\nin our heads with the non-verbal reality that we experience. So I try to\npractice describing what I’ve actually seen rather than saying \"is\"; instead\nof saying, \"There is a drunk coming down the street,\" I might say, \"I see a\nman approaching who looks drunk to me.\" Or you can say. \"I see a man\napproaching who may have a broken leg and needs help.\" You make yourself\nrealize there are alternative explanations. Once you say \"is\" you stop\nthinking about alternative explanations.\n\n  \n\nQ: Does this kind of mechanistic thinking, though perhaps serving an\nevolutionary function during the industrial period, only serve to hurt us all\nin this information processing era?\n\n  \n\nA: Yes. You take something like obscenity. There’s no way of saying how much\nobscenity exists in a book, a painting, a film, etc. We don’t have an\nobscenometer. You can’t point an obscenometer at a movie and say \"Oh this has\n50 chambers of obscenity. Oh this one has 75 chambers, and hey, this one went\nall the way up to 100 chambers!\" So if we don’t have any measurements, we\ndon’t have anything to talk about . . . When we’re not talking about anything\nout there measurable, we’re talking about our own neurological reactions we\nprobably learned from our parents. So when we say, \"That movie is obscene,\"\nwhat we mean is \"My parents wouldn’t have liked that movie.\" So you should say\nthat, instead of deluding yourself that you’re talking about the movie.\n\n  \n\nQ: You’ve been writing and talking for some time, Dr. Wilson, about an\nemerging society where high technology is put in the service of abundance for\nall. Alvin Toffler believes we’re halfway between the old industrial model and\nthe emerging, high tech information processing society. Do you agree?\n\n  \n\nA: I think we’re there. The problem is the people who run our society can’t\nfigure out how to make the adjustment because they’re still thinking in terms\nof an economy of scarcity. Actually, measurably, we’ve had an economy of\nabundance since 1974. There’s been more than enough, but our rulers and owners\njust don’t know how to run the new information society because the market and\neverything will jump in spooky ways when everybody realizes there’s plenty to\ngo around. Since the 1930’s the State has paid farmers not to grow food while\npeople are starving. Now if anyone tells you that this economy makes sense ask\nthem, how sane is a world where people are starving in one place and over here\npeople are being paid not to grow the food to feed them. How can anyone\ndescribe that as sanity?\n\n  \n\nQ: Do you think that such a post-scarcity society will make censorship\nsuperfluous in a lot of ways because censorship is based on ideological power\ngrabs . . . ?\n\n  \n\nA: Censorship is chiefly intended to kill brain cells. When you don’t get\nenough information, brain cells start dying, and anything that comes between\nthe brain and potential information is killing brain cells. This is necessary\nin a scarcity economy so people won’t figure out that hey, there’s a crowd\nover there who are eating all the food while we‘re starving. The best thing is\nto keep people stupid, but since we’re past that stage of evolution we don’t\nneed social institutions designed only to keep the people stupid, we can allow\nthem to develop their intelligence to the full now. As a matter of fact,\ndeveloping our intelligence to the full may now not only be \"allowed,\" but it\nprobably will prove to be a vast benefit for all of us.\n\n  \n\nQ: It is said that Clinton’s current sex scandals are the result of a right-\nwing conspiracy against him. Do you think there is any truth to that idea?\n\n  \n\nA: Some. But there is also the media frenzy for scandal. The President’s sex\nlife used to be taboo, but the taboo has broken down. Like all taboos, as soon\nas it gets broken down, you have a period of kind of sociopathic chaos where\nthere are no rules at all. Eventually a new set of rules will have to be\nestablished. Meanwhile, I wouldn’t run for President. I wouldn’t run for\ndogcatcher. I don’t want anybody going over my life the way the lives of\npoliticians get examined these days.\n\n  \n\nQ: My reaction was that I couldn’t believe my ears half the time. You’re\nsitting there watching the evening news and they’re talking about the\nPresident’s semen stains.\n\n  \n\nA: (laughs) It is like he’s a suspect on \"NYPD Blue.\" Everybody in Washington\nknew about Kennedy’s sexual romps, but their editors wouldn’t print it. Now\nit’s open season on politicians. Well, they deserve it.\n\n  \n\n  \n\n#### Old Man On A Balcony:\n\n#### Views Of Monterey Bay #23\n\n  \n\nANOTHER MIDNIGHT HAIKU\n\n  \n\nBlack Darkness only:\n\n  \n\nI see nothing but I hear\n\n  \n\nRain and wind and waves\n\n\n#### Still More Questions Answered\n\n  \n\nand now a 2002 romp with Paul Krassner\n\n  \n\nQ: You’ve written 34 books with the aid of pot. Could you describe that\nprocess?\n\n  \n\nA: It’s rather obsessive-compulsive, I think. I write the first draft\nstraight, then rewrite stoned, then rewrite straight again, then rewrite\nstoned again, and so on, until I’m absolutely delighted with every sentence,\nor irate editors start reminding me about deadlines — whichever comes first.\nHemingway and Raymond Chandler had similar compulsions but used the wrong\ndrug, booze, and they both attempted suicide. Papa succeeded but poor Ray\ndidn’t and just looked like a sloppy alcoholic. (He tried to shoot himself in\nthe head and missed.) Faulkner also had obsessive components and died by\nfalling off a horse, drunk. I don’t think booze is a very safe drug for us\nobsessive-compulsives. Almost as bad as becoming known as a Sage. By the way,\nCongress should impeach Bozo and impound Rumsfeld.\n\n  \n\nQ: The piss police read High Times. What would you like to tell them?\n\n  \n\nA: \"You are all equally blessed, equally empty, equally coming Buddhas.\" But\nsome of them are such assholes, it will take a long time to get from there to\nhere.\n\n  \n\nQ: Columnist Clarence Page recently wrote about the DEA raiding \"a legitimate\nhealth co-operative [WAMM, the Wo/Men’s Alliance for Medical Marijuana] that\nwas treating more than 200 patients, some of them terminally ill, in Santa\nCruz. Snatching medicine out of the hands of seriously ill patients sounds\nlike terrorism to me. In this case it was federally sponsored and taxpayer-\nfinanced.\" Tell me about your own relationship with WAMM.\n\n  \n\nA: Long before I needed WAMM, Valerie Corral, the founder, came regularly to\nmy Finnegans Wake reading/rapping group and I considered her incredibly\nbright. As I learned about her WAMM activities, distributing pot to terminal\ncancer and AIDS patients, sitting with them, giving love and support during\nthe death process, I decided she was also a saint. I never thought I would\nbecome another WAMM patient. My post-polio syndrome had been a minor nuisance\nuntil then; suddenly two years ago it flared up into blazing pain. My doctor\nrecommended marijuana and named WAMM as the safest and most legal source. By\nthen, I think I was on the edge of suicide; the pain had become like a\npermanent abscessed tooth in the leg. Nobody can or should endure that. Thanks\nto Valerie and WAMM, I never have that kind of torture for more than an hour\nthese days. I pop one of their pain pills and I’m up and back at the iMac in,\nwell, if not an hour, then at most two hours. By the way, Congress should\nimpeach Bozo and impound Rumy. Or did I say that already?\n\n  \n\nQ: I think you did.\n\n  \n\nA: Well, it bears repeating.\n\n  \n\nQ: When the City Council staged a public giveaway of medical marijuana, a DEA\nagent asked, \"What kind of message are city officials sending to the youth of\nSanta Cruz?\" How would you answer him?\n\n  \n\nA: \"The powers not delegated to the United States by the Constitution, nor\nprohibited by it to the States, are reserved to the States respectively, or to\nthe people.\"\n\nI didn’t invent that; I found it in the back of my dictionary, in a dusty old\nhistorical document called \"U.S. Constitution,\" which Bozo seemingly has never\nheard of, but it’s supposed to be the rules of our government. I wish more\npeople would look at that document, because it has a lot of other radical\nideas that seem worth thinking about; it’s based on the Massachusetts\nconstitution written by John Adams. Look it up before the Bush Crime Family\nforces dictionary publishers to remove it. Congress should impeach Bozo and\nimpound Rummy. Or does this begin to sound like an echo chamber?\n\n  \n\nQ: How does all that tie in with your new book, TSOG? First, what does TSOG\nmean, and how do you pronounce it?\n\n  \n\nA: TSOG means Tsarist Occupation Government and I pronounce it TSOG, so it\nsounds like a monster in a Lovecraft story. The book presents the evidence\nthat ever since the CIA-Nazi-Tsarist alliance of the 1940’s, the Tsarists have\ntaken over as the \"brains\" of the Control System and America has become a\nTsarist nation, with the Constitution only known to those who peek in the back\nof their dictionaries, like I did. Hell, we even have an official Tsar and he\nhas the alleged \"right\" — or at least the power — to come between my doctor\nand me, and decide how much excruciating pain I should suffer before dying.\n\nWhat next? Is the Tsar going to rule on controversial questions in physics and\nastronomy? In mathematical set theory? In biology? Believe me, there’s no Tsar\nmentioned in the Constitution. Personal doctor/patient matters are left to the\nindividuals. You see, this was once supposed to be a free country, not a\nTsarist despotism.\n\n  \n\nQ: You were brought up as a Catholic and became a Marxist when you were 16.\nWhat disillusioned you about each of those belief systems?\n\n  \n\nA: Their rigidity. All rigid Belief Systems (B.S.) censor and warp the\nprocesses of perception, thought and even empathy. They literally make people\nbehave like badly-wired robots. Philip K. Dick noticed this too, and worried a\nlot about the possible robots among us. Some people think he was crazy, but\nI’ve never met anybody with rigid beliefs who seemed fully human to me. Phil\ngot it right: a lot of them do act like robots. Especially in government\noffices and churches. Gort, Bozo barada nikto, dig?\n\n  \n\nQ: What was the purpose of what you call the Christian conspiracy?\n\n  \n\nA: Well, I regard the Bill of Rights as the result of a conspiracy by the\nintellectual freemasons of the Enlightenment Era. It’s always had a precarious\nexistence because of the rival Christian conspiracy to restore the dark ages —\nInquisitions, witch-hunts and all. With the Tsarist take-over, the Christians\nappear to have won. Not a single clause in the Bill of Rights hasn’t gotten\neither diluted or totally reversed.\n\n  \n\nQ: Why are you so skeptical about organized skepticism?\n\n  \n\nA: Like I keep saying, rigid Belief Systems frighten me and make me think of\nrobots, or \"humanoids\" — some kinda creepy mechanism like that. Organized\nskepticism in the U.S. today contains no true skeptics in the philosophical\nsense. They seem like just another gang of dogmatic lunatics at war with all\nthe other gangs of dogmatic fanatics, and, of course, with us model agnostics\nalso. Look at the Committee for Scientific Investigation of Claims of the\nParanormal. They never do any Scientific Investigation at all, at all. Why? My\nguess is that, like the Inquisitors who refused to look through Galileo’s\ntelescope, they have a deep fear that such research might upset their dogmas.\n\n  \n\nQ: What’s the basis of your obsession with Hannibal Lecter?\n\n  \n\nA: Hannibal Lecter, M.D., please. In the books, he seems one of the greatest\ncreations in literature to me. I admire Thomas Harris more than any novelist\nsince James Joyce. Everything about Dr. Lecter is likable and even admirable\nexcept that one Nasty Habit, but that habit’s so intolerable, even to\nlibertarians, we can never forget it even when we find him most likable and\nmost admirable. A paradox like that can inspire Ph.D. candidates for 1,000\nyears. I mean, how can you resist a psychiatrist who tells a lesbian patient,\nas Hannibal did once, \"There’s nothing wrong with being weird. You have no\nidea how weird I am\" — and really means it? In the films, of course, Dr.\nLecter also has the stupendous contribution of intelligence and eerie charm\nonly Anthony Hopkins can project. By the way, God bless Valerie Corral and God\ndamn Asa Hutchinson.\n\n  \n\nQ: I thought you don’t believe in God?\n\n  \n\nA: I have no \"beliefs,\" only probabilities; but I was not speaking literally\nthere. A poetic flourish, as it were.\n\n  \n\nQ: I know you don’t believe in life after death, but I’m intrigued by the\nnotion that, during 42 years of marriage, you and Arlen imprinted each other’s\nnervous systems. Could you elaborate on that?\n\n  \n\nA: I don’t \"believe\" in spiritualism, but that does not keep me from\nsuspecting an unbreakable link between those who have loved deeply. To avoid\nsounding esoteric, let me put it in nitty-gritty terms. I literally cannot\nlook at a movie on TV without knowing what she’d say about it. For instance,\nif a film starts out well and ends up a mess, I can virtually \"hear\" her\nsaying, \"Well, they had one Story Conference too many . . .\"\n\n  \n\nQ: Would you relate the tale of Arlen and the Encyclopedias?\n\n  \n\nA: She liked to collect old encyclopedias from second-hand bookstores, and at\none point we had eight of them. When I wrote my first historical novel — back\nin 1980, before I was online — I used them often as a research tool. For\ninstance, I learned that the Bastille was either 90 feet high or 100 feet or\n120 feet. This led me to formulate Wilson’s 22nd Law: \"Certitude belongs\nexclusively to those who only look in one encyclopedia.\"\n\n  \n\nQ: How has the Internet changed your life?\n\n  \n\nA: It has felt like a neurological quantum jump. Not only does the word\nprocessing software make my compulsive rewriting a lot easier than if I still\nhad to cut my words on rocks or use a typewriter or retreat to similar\nbarbarism, but the e-mail function provides most of my social life since I\nbecame \"disabled.\" I do most of my research on the World Wide Web, get my\nanswer in minutes and don’t have to hunt laboriously through my library for\nhours. It has improved my life a thousand ways. I also have a notion that\nInternet, as a feedback system, will eventually replace government, a no-\nfeedback system.\n\n  \n\nQ: How do you discern between conspiracy and coincidence?\n\n  \n\nA: The way Mr. and Mrs. Godzilla make love: verrrrry carefully.\n\n  \n\nQ: A dinner party was scheduled for March 31, 1981, the day after an\nassassination attempt on Ronald Reagan, which, if successful, would have\nelevated Vice President and former CIA chief George Bush to the presidency.\nThe dinner was immediately cancelled. It would have been held at the home of\nNeil Bush, and a guest was to be Scott Hinckley, brother of the would-be\nkiller. Hinckley’s father and Bush were friends and fellow oil industrialists.\nA PR firm issued a statement: \"This horrible coincidence has been devastating\nto the Bush Family. Our condolences go out to all involved. And we hope to get\nthe matter behind us as soon as possible.\" Congressman Larry MacDonald was the\nonly legislator who demanded an investigation, but his plane crashed. Whattaya\nthink — coincidence or conspiracy?\n\n  \n\nA: To me, it looks at first glance like coincidence by about 75% probability.\nI mean, who would be dumb enough to use an assassin with such obvious links to\nhis employers? But then again, the Bush Crime Family seem to think they can\nget away with anything, from S&L fraud to stealing an election in the clear\nlight of day with the whole world watching. They must have an even lower\nopinion of the intelligence of the American people than I do. Maybe I should\nchange the probability down to about 50%. I guess this does deserve further\ninvestigation by somebody who doesn’t fly in airplanes.\n\n  \n\nQ: Ishmael Reed said, \"The history of civilization is the history of warfare\nbetween secret societies.\" Do you agree?\n\n  \n\nA: Yes and no. I would say there is no history, singular; only histories,\nplural. The warfare between secret societies is a history, one that both\nIshmael and I have explored. There also exists a history of class war, a\nhistory of war (or competition) between gene pools, a history of\nprimate/canine relations, etc., ad infinitum. None of them contradicts the\nothers, except in the heads of aristotelian logicians, or Ideologists. They\neach supplement all the others.\n\n  \n\nQ: You and I have something in common. Lyndon LaRouche has revealed the truth\nabout each of us: You’re really the secret leader of the Illuminati; and I was\nbrainwashed at the Tavistock Institute in England. Do you think he actually\nbelieves such things, or is he consciously creating fiction, just as the FBI’s\ncounter-intelligence program did?\n\n  \n\nA: I still don’t understand some of my computer’s innards and you expect me to\nexplain a bizarre contraption like the brain of Lyndon LaRouche? I can only\nhazard that he seems more a case for a bile specialist than a psychiatrist.\n\n  \n\nQ: What was LaRouche’s factoid about the Queen of England?\n\n  \n\nA: He said Liz sent Aldous Huxley and Alan Watts over here to destroy us with\nOriental religions and drugs, so England could become the top Super-Power\nagain. If you took Liz and England out and put Fu Manchu and the Third World\nin her place, it would make a great matinee thriller. I think Bozo lives in\nthat film with Mickey and Goofy and Osama bin Laden and Darth Vader.\n\n  \n\nQ: What’s the most bizarre conspiracy theory you’ve come across?\n\n  \n\nA: A group called Christians Awake claims Ronald Reagan was a Gay freemason\nand that he filled the government and courts with other Gay freemasons. I\nsuppose they let Clarence Thomas in as a concession to the Gay Prince Hal\nlodge.\n\n  \n\nQ: And what would be the least known conspiracy theory — I mean, that you know\nof?\n\n  \n\nA: The Church of Positive Accord believes — and I think they make a damned\ngood case — that the God of the Bible is corporeal, not spiritual. In udder\nwoids, he eats and shits just like you and me. And, contrary to my 1959\nheresies, he definitely has a penis. He even has boogers: they proclaimed that\nin an interview with [SubGenius Church reverend] Ivan Stang. They point out\nthat all \"spiritual\" ideas of God derive from Greek philosophy, not the Bible,\nand claim that gaseous Greek god has been promoted by a conspiracy of\nintellectuals. Just re-read the Bible with that grid and it makes sense, in a\nStone Age sort of way. He walks, He talks. He loves the smell of beef cooking.\nHe hates Gay people and shellfish. He’s a serial killer. And in the sequel He\neven knocks up a teen-age chick.\n\n  \n\nQ: Your readers can’t always discern — when you write about the Illuminati,\nfor example — whether you’re sharing information or satirizing reality. Does\nit make any difference?\n\n  \n\nA: To quote Madonna, \"I’m only kidding — not.\" Add my Celtic sense of humor to\nNiels Bohr’s model agnosticism and out comes my neo-surrealist novels and\n\"post-modern\" criticism.\n\n  \n\nQ: I’ve had many occurrences of satirical prophecy, where something I invented\nturned out to become reality. Has that happened with you?\n\n  \n\nA: Well, in Illuminatus! (published 1975), terrorists attack the Pentagon and\nonly succeed in blowing a hole in one of the five sides. Sound familiar? Also,\nin Schrödinger’s Cat (published 1981), terrorists blow up Wall Street. I don’t\nregard either of those \"hits\" as precognition or even \"intuition,\" just common\nsense. It seemed obvious to me that the TSOG could not run amok around the\nplanet, invading and bombing damned near everybody, without somebody firing\nback eventually.\n\n  \n\nQ: Here’s a confession. In my article on the conspiracy convention in High\nTimes, I did a reverse of satirical prophecy. I had once asked Mae Brussell,\nthe queen of conspiracy researchers, why the conspirators didn’t kill her, and\nshe explained that agents always work on a need-to-know basis, but they would\nread her work and show up wherever she spoke, in order to get a peek at the\nbig picture, because it was \"a safety valve for them,\" she said, \"on how far\nthings are going.\" I asked, \"Are you saying that the intelligence community\nhas allowed you to function precisely because you know more than any of them?\"\nAnd she replied, \"Exactly.\" Well, in my High Times satire, I put those words\ninto the mouth of somewhat fraudulent conspiracy researcher David Icke.\nAnyway, my question is, do you think the conspirators allow you to live\nbecause you know too much?\n\n  \n\nA: I doubt it. I don’t think they’ve ever heard of me. They don’t read books.\n\n  \n\nQ: After my High Times column on the Prophets Conference, in which I referred\nto you as \"the irreverent bad boy at this oh-so-polite conference,\" why were\nyou disinvited from speaking at future Prophets Conferences?\n\n  \n\nA: A lot of my fans think I got booted for lack of respect for His Royal\nFraudulency George II. I take that as an assertion beyond proof or disproof.\nThe managers said it was for finding a Joycean epiphany in a Spike Lee movie.\nI take that as an assertion beyond even comprehension.\n\n  \n\nQ: I’d like to hear about your — perhaps psychotic? — experience with higher\nconsciousness and the resulting epiphany.\n\n  \n\nA: I have had not one but many seeming encounters with seemingly non-human\nintelligences. The first was a Christmas tree that loved me — loved me more\nthan my parents or my wife or my kids, or even my dog. I was on peyote at the\ntime. With and without other drugs — for instance by Cabala — I have seemingly\ncontacted a medieval Irish bard, an ancient Chinese alchemist, an\nextraterrestrial from the Sirius system, and a giant white rabbit called the\npook or pookah from County Kerry. I finally accepted that if you already have\na multi-model ontology going into the shamanic world, you’re going to come out\nwith multi-model results. As Wilson’s Fourth Law sez, \"With sufficient\nresearch you will find evidence to support your theory.\" So I settled on the\nmagick rabbit as the model nobody could take literally, not even myself. The\nreal shocker came when I discovered that my grandmother’s people, the\nO’Lachlanns, came from Kerry and allegedly have a clan pookah who protects us\nfrom becoming English by adding periodic doses of weirdness to our lives.\n\n  \n\nQ: The dedication in my book, Murder At the Conspiracy Convention and Other\nAmerican Absurdities, reads: \"This one is for Robert Anton Wilson — guerrilla\nontologist, part-time post-modernist, Damned Old Crank, my weirdest friend and\nfavorite philosopher.\" Since these are all terms you’ve used to label\nyourself, would you explain what each one means?\n\n  \n\nA: Well, I picked up \"guerrilla ontology\" from the Physics/Consciousness\nResearch Group when I was a member back in the 1970’s. Physicists more usually\ncall it \"model agnosticism,\" and it consists of never regarding any model or\nmap of Universe with total 100% belief or total 100% denial. Following\nKorzybski, I put things in probabilities, not absolutes. I give most of modern\nphysics over 90% probability, the Loch Ness Monster around 50% probability and\nanything the State Department says under 5% probability. As Bucky Fuller used\nto say, \"Universe is non-simultaneously apprehended\" — nobody can apprehend it\nall at once — so we have no guarantee that today’s best model will fit what we\nmay discover tomorrow.\n\nMy only originality lies in applying this zetetic attitude outside the hardest\nof the hard sciences, physics, to softer sciences and then to non-sciences\nlike politics, ideology, jury verdicts and, of course, conspiracy theory.\nAlso, I have a strong aversion, almost an allergy, to Belief Systems, or B.S.\n— a convenient abbreviation I owe to David Jay Brown [Virus: The Alien Strain\nand Brainchild, New Falcon Publications]. A neurolinguistic diet high in B.S.\nand low in instrumental data eventually produces Permanent Brain Damage, a\nlurching gait, blindness and hairy palms like a werewolf.\n\nThen I started calling myself a post-modernist after that label got pinned on\nme in two different books, one on my sociological works and one on my science-\nfiction. Then I read some of the post-modernists and decided they were only\nagnostic about other people’s dogmas, not their own. So then I switched to\nDamned Old Crank, which seems to suit my case better than either of the\nprevious labels. Besides, once my hair turned snowy white, some people wanted\nto promote me to a Sage, and I had to block that. It’s more dangerous to a\nwriter than booze. By the way, Congress should impeach Bozo and impound\nRumsfeld.\n\n  \n\nQ: Since you believe that the universe is indifferent, why are you an\noptimist?\n\n  \n\nA: It may have genetic origins — some of us bounce up again no matter what we\nget hit with — but as far as I can rationalize it, nobody knows the future, so\nchoosing between pessimism and optimism depends on temperament as much as\nprobabilities.\n\nPsychologist John Barefoot has studied this extensively and concludes that\noptimists live about 20% longer than pessimists. When the outcome remains\nunknown, why should I make the bet that keeps me miserable and shortens my\nlife? I prefer the gamble that keeps me high, happy, and creative, and also\nincreases life span. It’s like the advantage of pot over aspirin. Pot not only\nkills pain better, but the High boosts the immune system. High and happy moods\nprolong life, miserable and masochistic moods shorten it.\n\n  \n\nQ: Recently, when I spoke at a college campus, a student asked what I wanted\nmy epitaph to be. I replied, \"Wait, I’m not finished.\" What do you want your\nepitaph to be?\n\n  \n\nA: I have ordained in my will that my body will get cremated and the ashes\nthrown in Jerry Falwell’s face. The executor of my will should then shout one\nword only: \"Gotcha!\"\n\n\nPART V\n\n\n### ON MY WAY OUT\n\n  \n\nBelieve nothing, no matter where you read it, or who said it, no matter if I\nhave said it, unless it agrees with your own reason and your own common sense.\n\n  \n\n\\- Gotama Buddha\n\n\nEscape From CNN\n\n  \n\nNo fakes or deceits:\n\n  \n\nBay, clouds, birds, trees: All\n\n  \n\nDoing what they do.\n\n\n#### Cheerful Reflections on Death and Dying\n\n  \n\nI wrote this c. 2001 for some online zine that quickly went kerflooey.\n\n  \n\nWavy Gravy told me about a guy who asked a Zen Master, \"What happens after\ndeath?\"\n\nThe roshi replied, \"I don't know.\"\n\n\"But, you’re a Zen Master!\"\n\n\"Yes, \" said the roshi, \"but I’m not a dead Zen Master.\"\n\n  \n\nI don’t understand why people fear death — although of course I see good\nreasons to fear the process of dying.\n\nDying often involves a great deal of prolonged pain, and in this country at\nleast may drain your life savings into the bank accounts of the A.M.A. Both\nprospects seem equally terrifying — especially if you hoped to leave a decent\nestate to your children.\n\nOne can avoid these deplorable conditions, however, by moving to a civilized\ncountry with a national health plan and legal help to assist you in suicide if\nyou have reached a condition where you can’t do it yourself. I personally\nintend to move to Nederland in the event that a painful, expensive and\nprolonged death seems inescapable. The medical banditos have made enough money\nout of me already; I refuse to enrich them further on my way out.\n\nBut as for death, and what — if anything — comes after death, I see no cause\nfor apprehension whatsoever.\n\nI consider the alternatives in order:\n\n  \n\nMost people through most of history have believed that after death comes\nrebirth (reincarnation). I think most people, planet-wide, still believe that.\nIt fails to terrify me. If I get reborn as a cockroach, I intend to hide in\nthe vicinity of somebody’s computer and write poems on the keyboard at night,\nlike Archy, the famous roach who left his verse in the typewriter of Don\nMarquis. If I get reborn as a human, I might meet my wife Arlen again and love\nher again and marry her again. That sounds great to me.\n\nOther rebirths, as a tree, say, or a blue whale, also seem more entertaining\n(and educational) than frightening.\n\nUnfortunately, I have no good reasons to believe in reincarnation, although\nI’d sort of like to. I include it only for the sake of completeness.\n\nA sinister rumor, widely believed in the Occident, holds that after death we\nmay go to a place called Heaven. From all the descriptions I’ve read, it\nsounds dreadful to me. It seems to have a population made up entirely of some\ngang of Christians; the experts on Heaven disagree about which conglomeration\nof Christians will qualify, but they always seem to think that they personally\nbelong to that elite group. An eternity with people that conceited seems\nintolerable to me, but fortunately I am not a Christian so I won’t be\nconsigned to such a boring place.\n\nAn even more nefarious report appears in the United States Marine Corps hymn:\n\n  \n\nIf the Army and the Navy\n\never looked on Heaven’s scenes\n\nthey would find the streets were guarded\n\nby the United States Marines\n\n  \n\nA place where every street is guarded by Marines sounds like a particularly\nvicious police state, especially if Christians run it, and I definitely don’t\nwant to go there, even for a visit. I wouldn‘t even wish it on my worst enemy,\nif I had any enemies. (Some people hate me for the books I write, but I refuse\nto hate them back, so they don’t count as enemies.)\n\nFortunately, as noted, I don’t qualify for Heaven, with all its harps and\nfanatic Christians and martial law by Marines.\n\nAn equally terrible idea, which has terrified millions, claims that some of us\nwill go to a place called Hell, where we will suffer eternal torture. This\ndoes not scare me because, when I try to imagine a Mind behind this universe,\nI cannot conceive that Mind, usually called \"God,\" as totally mad.\n\nI mean, guys, compare that \"God\" with the worst monsters you can think of —\nAdolph Hitler, Joe Stalin, that sort of guy. None of them ever inflicted more\nthan finite pain on their victims. Even de Sade, in his sado-maso fantasy\nnovels, never devised an unlimited torture. The idea that the Mind of Creation\n(if such exists) wants to torture some of its critters for endless infinities\nof infinities seems too absurd to take seriously.\n\nSuch a deranged Mind could not create a mud hut, much less the exquisitely\nmathematical universe around us.\n\nIf such a monster-God did exist, the sane attitude would consist of practicing\nthe Buddhist virtue of compassion. He seems very sick in His head, so don’t\ngive way to hatred: try to understand and forgive Him. Maybe He will recover\nhis wits some day. (I wrote \"He\" instead of the fashionable \"He or She\"\nbecause only male Gods appear to have invented Hells. I can’t think of a\nsingle Goddess who ever created a Hell for people who displeased Her.)\n\nA fourth alternative after-death scenario involves merger with \"God\" or with\n\"the Godhead\" (the latter term seems more popular). This idea, which seems\nHindic in origin, currently enjoys vast popularity with New Agers.\n\nI see nothing terrifying here; in fact, I suspect I would enjoy it, based on\nmy previous experiences in which this merging/melting seemed to take place on\nLSD. An infinite Acid Trip in which the whole universe seems like your body:\nwho could fear that (except Republicans)?\n\nThe fifth and, as far as I know, the last thinkable alternative holds that\nafter death comes total oblivion. This has either terrorized or angered many\nintelligent writers (e.g., Bertrand Russell and Jean Paul Sartre, who seem to\nhave hated \"life after death\" for not existing, just as they remained\npermanently pissed off at \"God\" for not existing). Sorry: it doesn’t seem\nterrible to me at all. If I become totally oblivious, I won’t know about it\n(by definition of oblivion). How can you feel, terrified of something you\ncan’t experience?\n\nBesides oblivion means freedom from \"all the ills the flesh is heir to,\" from\nbleeding piles to cancer, including even bad reviews of my books.\n\nLiving in New York or Los Angeles seem much worse than not living in Oblivion.\n\nAlthough I have a few opinions, or hunches, I have no dogma about what happens\nafter death. But none of the above alternatives seem really unpleasant, except\nthe ones that seem too absurd to take seriously.\n\nAs some Roman wrote:\n\n  \n\nNothing to clutch in life.\n\nNothing to fear in death.\n\n\nOn My Way Out\n\n  \n\nBozo and the TSOG\n\n  \n\nboth seem far far away from\n\n  \n\nmy bay and my clouds\n\n\n#### AFTERWORD\n\n  \n\nby Paul Krassner\n\n  \n\nFilmmaker Luis Bunuel once said that he made movies to give himself something\nto do between birth and death. So, then, Robert Anton Wilson's final published\nbook — diverse topics in Email to the Universe — serves as a documentary of\nhis multi-dimensional imagination and genius. He died on January 11, 2007 at\nthe age of 74. The prolific author and countercultural icon had been suffering\nfrom post-polio syndrome. Caregivers at his bedside read aloud all of his late\nwife Arlen’s poetry, and e-mailed to me that “He was quite cheered up by the\ntime we left. He definitely needed to die. His body was turning on him in ways\nthat would not allow him to rest.”\n\nIn his final blog on January 6, Wilson wrote: “I don’t see how to take death\nseriously. I look forward without dogmatic optimism, but without dread. I love\nyou all and I deeply implore you to keep the lasagna flying.” Actually, it was\nexpected that he would die seven months earlier. On June 19, 2006, he sent\nthis haiku (with one syllable missing) to his electronic cabal:\n\n  \n\nWell what do you know?\n\nAnother day has passed\n\nand I’m still not not.\n\n  \n\nBob Wilson and I originally became friends in 1959, when his first published\narticle graced the cover of my irreverent magazine, The Realist. It was titled\n“The Semantics of God,” in which he suggested that “The Believer had better\nface himself and ask squarely: Do I literally believe that ‘God’ has a penis?\nIf the answer is no, then it seems only logical to drop the ridiculous\npractice of referring to ‘God’ as ‘he.’” Incidentally, Bob’s byline in that\npiece was the first time he used Anton as if it was his middle name. He then\nbegan writing a regular column, “Negative Thinking.”\n\nIn 1964, I ran another front-cover story by him, “Timothy Leary and His\nPsychological H-Bomb,” which began: “The future may decide that the two\ngreatest thinkers of the 20th Century were Albert Einstein, who showed how to\ncreate atomic fission in the physical world, and Timothy Leary, who showed how\nto create atomic fission in the psychological world. The latter discovery may\nbe more important than the former; there are some reasons for thinking that it\nwas made necessary by the former. Leary may have shown how our habits of\nthought can be changed.”\n\nWilson took that notion as his personal marching orders, altering the\nconsciousness of countless grateful readers of his 35 books — from Sex, Drugs\n& Magick to Everything Is Under Control: An Encyclopedia of Conspiracy\nTheories — all written with the aid of that good old creative fuel, marijuana.\nHe once told me about his creative process: “It’s rather obsessive-compulsive,\nI think. I write the first draft straight, then rewrite stoned, then rewrite\nstraight again, then rewrite stoned again, and so on, until I’m absolutely\ndelighted with every sentence, or irate editors start reminding me about\ndeadlines — whichever comes first.”\n\nBob originally became a dedicated pot-head in 1955. But, a few years before\nhis death, he told the audience at a Prophets Conference, “I haven’t smoked\npot in about twelve . . . hours, and I want you to know it’s great to be\nclean.” He enjoyed peppering his presentations at such distinguished New Age\nevents with “motherfuckers” and “cocksuckers,” and was disinvited from\nparticipating in future Prophet Conferences because, said the organizers,\n“What we feel to be important to your insights are being lost to the audience\nwhen packaged in hard and harsh language.”\n\nWilson once described his writings as “intellectual comedy.” He told an\nInternet database, Contemporary Authors: “If my books do what I intend, they\nshould leave the reader feeling that the universe is capable of doing\nsomething totally shocking and unexpected in the next five minutes. I am\ntrying to show that life without certainty can be exhilarating, liberating, a\ngreat adventure.” He called his philosophy “Maybe Logic,” which became the\ntitle of a documentary about him.\n\nStephen Gaskin, founder of The Farm commune, wrote, “I had the good fortune to\nvisit with Robert at his house and meet his wife. When I saw the beautiful\nrelationship between them, I understood why the sex scenes in his books are so\nnicely written that they stand out above everyone else’s sex scenes that I’ve\nread.\n\n“One of my next encounters with him was standing on the sidewalk of a cold\nNovember day in Amsterdam waiting for a taxi. He didn’t have enough of a coat,\nand he was standing in the cold with his collar turned up and his hands stuck\nin his pockets. It was a while after his wife had died and he looked quite\nforlorn. We collected him up, put a warm coat on him, and put a joint in his\nmouth. It was a real hoot to get to be friends with one of my very favorite\nwriters. His Illuminatus! trilogy is a benchmark in science-fiction and\ncontemporary paranoia.”\n\nWilson wrote his own obituary in an autobiography, Cosmic Trigger: “According\nto reliable sources, I died on February 22, 1994 — George Washington’s\nbirthday. I felt nothing special or shocking at the time, and believed that I\nstill sat at my word processor working on a novel called Bride of Illuminatus.\n\n“At lunch-time, however, when I checked my voice mail, I found that Tim Leary\nand a dozen friends had already called to ask to speak to me, or — if they\nstill believed in Reliable Sources — to offer support and condolences to my\ngrieving family. I quickly gathered that the news of my tragic end had\nappeared on the Internet: ‘Noted science-fiction author Robert Anton Wilson\nwas found dead in his home yesterday, apparently the victim of a heart attack.\n[He] was noted for his libertarian viewpoints, love of technology and off the\nwall humor. Mr. Wilson is survived by his wife and two children.’”\n\nR. U. Sirius, co-author of Counterculture Through the Ages, writes, “Robert\nAnton Wilson enjoyed his first death so much, he decided to try it again. As\nthe result of medical expenses and problems with the IRS, he found himself in\na financial squeeze towards the end of his life. Word went out and the\nInternet community responded by sending him $68,000 within the first couple of\ndays. This allowed him to die with the comfort, grace and dignity that he\ndeserved.\n\n“He taught us all that ‘the universe contains a maybe.’ So maybe there is an\nafterlife, and maybe Bob’s consciousness is hovering around all of us who were\ntouched by his words and his presence all these years. And if that’s the case,\nI’m sure he’d like to see you do something strange and irreverent — and yet\nbeautiful — in his honor.”\n\nIn 1974, I stopped publishing The Realist because I ran out of money and\ntaboos. In 1985, I re-launched it in a newsletter format. For a feature story\nin the born-again Realist, I contacted Bob Wilson. There was a one-inch news\nitem about a convention in Italy of the Married Roman Catholic Priests\nAssociation, representing 70,000 priests who had married in defiance of the\nVatican. I gave the clipping to him.\n\n“Bob, should you choose to accept this assignment, I’d like you to cover this\nevent as though you had actually been there.”\n\nWilson wrote his report, and even I almost believed that he had actually gone\nto the married priests convention. Next, there was a tiny news item about the\nfirst International Orgasm Conference, and I assigned him to cover that event\ntoo, as though he had actually been there. The Realist was back in apocryphal\nbusiness. This time I published the final issue in 2001. But Robert Anton\nWilson is still alive in the form of his literary legacy. May he rest in\nlasagna.\n\n  \n\nPaul Krassner is the author of Confessions of a Raving, Unconfined Nut:\nMisadventures in the Counterculture\n\n  \n\nThe first version of this essay was published on boingboing.com. Paul rewrote\na little and made some additions to the essay for this edition of Email to the\nUniverse.\n\n#### What Critics Say About\n\n#### Robert Anton Wilson\n\n  \n\nA SUPER-GENIUS . . . He has written everything I was afraid to write\n\nDr. John Lilly\n\n  \n\n￼\n\n  \n\nOne of the funniest, most incisive social critics around, and with a positive\nbent, thank Goddess.\n\nRiane Eisler, author of The Chalice and the Blade\n\n  \n\n￼\n\n  \n\nA very funny man . . . readers with open minds will like his books.\n\nRobin Robertson, Psychological Perspectives\n\n  \n\n￼\n\n  \n\nRobert Anton Wilson is a dazzling barker hawking tickets to the most thrilling\ntilt-a-whirls and daring loop-o-planes on the midway of higher consciousness.\n\nTom Robbins, author of Even Cowgirls Get the Blues\n\n  \n\n￼\n\n  \n\nSTUPID\n\nAndrea Antonoff\n\n  \n\n￼\n\n  \n\nThe man's either a genius or Jesus\n\nSOUNDS (London)\n\n  \n\n￼\n\n  \n\nA 21st Century Renaissance Man . . . funny, wise and optimistic . . .\n\nDENVER POST\n\n  \n\n￼\n\n  \n\nThe world's greatest writer-philosopher.\n\nIRISH TIMES (Dublin)\n\n  \n\n￼\n\n  \n\nHilarious . . . multi-dimensional . . . a laugh a paragraph.\n\nLOS ANGELES TIMES\n\n  \n\n￼\n\n  \n\nRanting and raving . . . negativism . . .\n\nNeal Wilgus\n\n  \n\n￼\n\n  \n\nOne of the most important writers working in English today . . . courageous,\ncompassionate, optimistic and original.\n\nElwyn Chamberling, author of Gates of Fire\n\n  \n\n￼\n\n  \n\nShould win the Nobel Prize for INTELLIGENCE.\n\nQUICKSILVER MESSENGER (Brighton, England)\n\n  \n\n￼\n\n  \n\nWilson managed to reverse every mental polarity in me, as if I had been\ndragged through infinity. I was astounded and delighted.\n\nPhilip K. Dick, author of Blade Runner\n\n  \n\n￼\n\n  \n\nOne of the leading thinkers of the modern age.\n\nBarbara Marx Hubbard, World Future Society\n\n  \n\n￼\n\n  \n\nA male feminist. ..a simpering, pussy-whipped wimp.\n\nLou Rollins\n\n  \n\n￼\n\n  \n\nSEXIST\n\nArlene Meyers\n\n  \n\n￼\n\n  \n\nThe most important philosopher of this century . . . scholarly, witty, hip and\nhopeful.\n\nTimothy Leary\n\n  \n\n￼\n\n  \n\nWhat great physicist hides behind the mask of \"Robert Anton Wilson?\"\n\nNEW SCIENTIST\n\n  \n\n￼\n\n  \n\nDoes for Quantum Mechanics what Durrell's Alexandria Quartet did for\nRelativity, but Wilson is funnier.\n\nJohn Gribbin, physicist\n\n  \n\n￼\n\n  \n\nOBSCENE, blasphemous, subversive and very, very interesting.\n\nAlan Watts\n\n  \n\n￼\n\n  \n\nErudite, witty and genuinely scary.\n\nPUBLISHER’S WEEKLY\n\n  \n\n￼\n\n  \n\nDeliberately annoying.\n\nJay Kinney\n\n  \n\n￼\n\n  \n\nMisguided malicious fanaticism.\n\nRobert Sheafer, Committee for Scientific Investigation of Claims of the\nParanormal\n\n  \n\n￼\n\n  \n\nThe man's glittering intelligence won't let you rest. With each new book, I\nlook forward to his wisdom, laced with his special brand of crazy humor.\n\nAlan Harrington, author of The Immortalist\n\n  \n\n￼\n\n  \n\n#### Mosbunall* Books By Robert Anton Wilson\n\n  \n\n1972 Playboy's Book of Forbidden Words\n\n1973 Sex, Drugs and Magick: A Journey Beyond Limits\n\n1973 The Sex Magicians\n\n1974 The Book of the Breast (now 'Ishtar Rising')\n\n1975 ILLUMINATUS! (with Robert Shea)\n\nThe Eye in the Pyramid\n\nThe Golden Apple\n\nLeviathan\n\n1977 Cosmic Trigger I: Final Secret of the Illuminati\n\n1978 Neuropolitique (with T. Leary & G. Koopman)\n\n1980 The Illuminati Papers\n\n1980-1 The Schrodinger's Cat Trilogy\n\nThe Universe Next Door\n\nThe Trick Top Hat\n\nThe Homing Pigeon\n\n1981 Masks of the Illuminati\n\n1983 Right Where You Are Sitting Now\n\n1983 The Earth Will Shake (Historical Illuminatus Trilogy–vol. 1)\n\n1983 Prometheus Rising\n\n1985 The Widow's Son (Historical Illuminatus Trilogy–vol. 2)\n\n1986 The New Inquisition\n\n1987 Natural Law or Don't Put a Rubber on Your Willy\n\n1987 Wilhelm Reich in Hell\n\n1988 Coincidance: A Head Test\n\n1988 Nature's God (Historical Illuminatus Trilogy–vol. 3)\n\n1990 Quantum Psychology\n\n1990 Cosmic Trigger II: Down to Earth\n\n1991 Chaos and Beyond\n\n1993 Reality Is What You Can Get Away With\n\n1995 Cosmic Trigger III: My Life After Death\n\n1997 The Walls Came Tumbling Down\n\n1998 Everything Is Under Control\n\n2002 TSOG: The Thing That Ate the Constitution\n\n2005 Email to the Universe\n\n  \n\n*Adaptation of “sombunall” – see reference\n\n  \n\n  \n\n￼\n\n![Hilaritas-Press-Logo-eBook-440.jpg](../Images/image-OM3VJPDD.jpg)\n\n  \n\nPublishing the Books of Robert Anton Wilson\n\nand Other Adventurous Thinkers\n\n  \n\n[www.hilaritaspress.com](http://www.hilaritaspress.com/)\n\n",
    "book_id": "email_to_the_universe",
    "book_title": "Email to the Universe and Other Alterations of Consciousness",
    "book_author": "Robert Anton Wilson",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 723
  },
  {
    "chunk_full": "",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 724
  },
  {
    "chunk_full": "Reality\nTransurfing\nVOLUME I\nTHE SPACE OF\nVARIATIONS\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 725
  },
  {
    "chunk_full": "First published by O Books, 2008\nO Books is an imprint of John Hunt Publish-\ning\nLtd., The Bothy, Deershot Lodge, Park Lane,\nRopley, Hants, SO24 0BE, UK\noffice1@o-books.net\nwww.o-books.net\nDistribution in:\nUK and Europe\nOrca Book Services\norders@orcabookservices.co.uk\nTel: 01202 665432 Fax: 01202 666219 Int.\ncode\n(44)\nUSA and Canada\nNBN\ncustserv@nbnbooks.com\nTel: 1 800 462 6420 Fax: 1 800 338 4550\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 726
  },
  {
    "chunk_full": "Australia and New Zealand\nBrumby Books\nsales@brumbybooks.com.au\nTel: 61 3 9761 5535 Fax: 61 3 9761 7095\nFar East (offices in Singapore, Thailand,\nHong\nKong, Taiwan)\nPansing Distribution Pte Ltd\nkemal@pansing.com\nTel: 65 6319 9939 Fax: 65 6462 5761\nSouth Africa\nAlternative Books\naltbook@peterhyde.co.za\nTel: 021 555 4027 Fax: 021 447 1430\n© Вадим Зеланд, 2004\n©\nИздание\nна\nрусском\nязыке.\nИздательская\nгруппа «Весь», Россия, 2004\n4/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 727
  },
  {
    "chunk_full": "© Vadim Zeland, 2004\n© Russian edition. Ves Publishing Group,\nRussia,\n2004\nDesign: Stuart Davies\nISBN: 978 1 84694 122 1\nAll rights reserved. Except for brief quota-\ntions in\ncritical articles or reviews, no part of this\nbook\nmay be reproduced in any manner without\nprior\nwritten permission from the publishers.\nThe rights of Vadim Zeland as author have\nbeen\nasserted in accordance with the Copyright,\nDesigns and Patents Act 1988.\n5/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 728
  },
  {
    "chunk_full": "A CIP catalogue record for this book is avail-\nable\nfrom the British Library.\nThis first volume translated by Gregory\nBlake\nFirst published in Russian under the title\nТрансерфинг реальности Ступень I:\nПространство вариантов by Ves Publish-\ning,\n197101, 6 Mira St. Petersburg, Russia\nPrinted by Digital Book Print\nO Books operates a distinctive and ethical\npublishing philosophy in\nall areas of its business, from its global net-\nwork of authors to\nproduction and worldwide distribution.\n6/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 729
  },
  {
    "chunk_full": "Reality\nTransurfing\nVOLUME I\nTHE SPACE OF\nVARIATIONS\nVadim Zeland\nTranslated by Natasha Micharina\nBooks in the series\nReality Transurfing 1:\nThe Space of Variations\nReality Transurfing 2:\nA Rustle of Morning Stars\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 730
  },
  {
    "chunk_full": "Reality Transurfing 3:\nForward to the Past\nWinchester, UK\nWashington, USA\n8/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 731
  },
  {
    "chunk_full": "FOREWORD\nDear Reader!\nI have no doubt, that like most people, you\nwant to lead a comfortable and wealthy life\nthat is free from diseases and traumas.\nHowever, it may often seem that your life de-\ncides otherwise and it is instead toying with\nyou, as if you were a paper boat in stormy\nwaters. In the pursuit of happiness, you have\nprobably already tried many well-known\nmethods. However, have you managed to\nachieve great success this way?\nThis book talks about some very strange and\nunusual things. This may all be so shocking\nto you that you would not want to believe it.\nHowever, it will not be necessary for you to\nbelieve. You will receive all the tools you\nneed to test the claims made in this book.\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 732
  },
  {
    "chunk_full": "Having done that, your ordinary view of life\nwill change completely.\nTransurfing is a powerful method that will\nallow you to do the most impossible things\n(impossible from a normal point of view) –\nnamely, to manage your destiny just the way\nyou like. There will not be any miracles. So-\nmething greater is awaiting you. You will be\nconvinced that the unknown reality is much\nmore incredible than any magic.\nMany books teach people how to become\nrich and happy. It is all, of course, very\ntempting. I mean, who would not want to be\nrich and happy? But when you open the book\nthere are exercises and meditations that re-\nquire hard effort. It is rather depressing,\nreally. Life is practically a test in itself, and\nyet they suggest you push and pull even\nharder, squeezing out whatever is left inside\nyou.\n10/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 733
  },
  {
    "chunk_full": "They try to convince you that you are not\nperfect and therefore you must change.\nOtherwise, do not count on anything good\nhappening to you. Now, it may be the case\nthat you are not quite satisfied with yourself.\nYet, somewhere deep inside you feel that you\ndo not really want to change. And you are\nright. Do not believe anyone who says that\nyou are not perfect. How can anybody know\nhow you are supposed to be? You don’t have\nto change yourself. You are looking for the\nway out in all the wrong places.\nWe won’t be doing any exercises, medita-\ntions or soul digging. Transurfing is not a\nnew self-improvement technique, but it is an\nentirely different way of thinking and acting\nso that you can get exactly what you want.\nNot to strive for things you want in your life\nbut to get what you want. And not by chan-\nging yourself but by returning to yourself.\n11/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 734
  },
  {
    "chunk_full": "We all make many mistakes in life, and then\nwe dream about how great it would be to be\nable to go back to our past and make\neverything right. I’m not promising you “a\nsweet ride back to your childhood”,1 but mis-\ntakes can be fixed, almost as if you’ve been\nback to your past. Or rather “ahead to the\npast”. The true meaning of these words will\nbe unveiled towards the end of this book.\nYou couldn’t have heard or read anywhere\nelse what I am about to tell you. Thus, be\nprepared for surprises that are as incredible\nas they are pleasant.\n12/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 735
  },
  {
    "chunk_full": "CHAPTER I\nTHE MODEL OF\nVARIATIONS\nThis chapter will introduce you to\nthe\ntheoretical\nbackground\nof\nTransurfing.\nThe\nmethod\nof\nTransurfing is based on the Model\nof Variations, which offers a new\nand fundamentally different view\non how the world works. Humanity\ndoes not know that it is possible to\nsimply get what he desires, instead\nof striving for it. So how is this\npossible?\nDreams do not come true.\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 736
  },
  {
    "chunk_full": "The\nRustling\nof\nthe\nMorning Stars\nThe barking of my neighbor’s dog woke me\nup. That vile creature is always waking me\nup. God, I hate the dog! Why do I have to\nwake up from the noises that ugly thing is\nmaking? I need to go for a walk, calm down a\nbit, and somehow try to suppress the intense\ndesire to burn down my neighbor’s house.\nLike dog, like master. There are always bas-\ntards breaking into my life and trying to get\nto me. I’m getting dressed, upset and angry.\nGreat, my damn slippers have disappeared\nagain. Where the hell are you, you slick suck-\ners? Wait until I find you…I’ll throw you\naway!\nIt’s wet and foggy outside. I was walking\nalong the slippery trail, passing through the\ngloomy forest. Most of the leaves have\nalready fallen off, exposing the gray trunks of\n14/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 737
  },
  {
    "chunk_full": "the half-dead trees. Why do I live in the\nmiddle of this depressing swamp? I take out\na cigarette. I don’t really want to smoke, but\nold habit is forcing me. Forcing me? Since\nwhen has a cigarette become a necessity for\nme? Yeah, it’s rather disgusting, smoking on\nan empty stomach in the morning. Once\nupon a time, when I was at a party or among\nfriends, I liked smoking and got pleasure\nfrom it. The cigarette was then a symbol of\nfashion, freedom and style. But parties end.\nGray and rainy everyday life takes over, with\npuddles full of messy problems. And each\ntime, I smoke away these problems by light-\ning up, telling myself – “OK, now I’ll have a\nlittle smoke, catch my breath, and plunge\nback into this hateful routine.”\nSmoke from the cigarette gets in my eyes and\nI cover them with my hands, like a hurt\nchild. I am so sick and tired of all of this!\nAnd then, as if echoing my thoughts, a\nbranch of a birch tree, bent in a particularly\n15/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 738
  },
  {
    "chunk_full": "insidious way, hits me painfully in the face.\nDamn it! In a rage, I break the branch and\nthrow it away. It hangs on the tree and then\nstarts bobbing up and down, back and forth,\nlike the head of a jack-in-the-box, as if\ndemonstrating my inability to change any-\nthing in this world. Depressed, I drag myself\nfurther along the path.\nEvery time I try to fight this world it gives in,\ncreating hope, only to flick my nose very\nhard later. It’s only in the movies you’ll see\nheroes going towards their goal, destroying\nall obstacles on their way. That doesn’t hap-\npen in real life. Perhaps life is similar to roul-\nette. Maybe you win one time, a second or\neven a third. Already, you see yourself as the\nwinner, and it seems to you that the whole\nworld is in your pocket, but in the end, you\nalways lose. You are nothing but a Christmas\ngoose being fattened up, so that you can be\nroasted and eaten to the sound of beautiful\nmusic\nand\nlaughter.\nYou\nhave\nmade\na\n16/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 739
  },
  {
    "chunk_full": "mistake, because this is not your party. You\nhave made a mistake…\nWallowing in these unhappy thoughts, I\ncome out to the sea. Little waves were vi-\nciously biting at the sandy shore. The un-\nfriendly sea was forcing a cold and wet wind\non me. Fat seagulls were lazily waddling\nalong the shore, pecking at something rotten.\nTheir eyes had a cold and black emptiness to\nthem. As if the world surrounding me was\nreflected in those eyes. A world that was just\nas cold and hostile.\nSome bum was collecting empty bottles on\nthe beach. Just get the hell out of here, you\nslob. I want to be alone. No, looks like he’s\nheading my way - he’s probably going to beg.\nI had better head off home. Not a moment of\npeace. God, I’m so tired. I’m always feeling\ntired, even when I’m resting. It is almost as if\nI’m doing time in prison. It seems that very\nsoon, everything will change, a new era will\n17/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 740
  },
  {
    "chunk_full": "begin and I will become a different person\nand will be able to enjoy my life. But that is\nall in the future. For now, I’m stuck in the\nsame miserable sweatshop. I’m always wait-\ning, but the future never comes. Now, as al-\nways, I eat a tasteless breakfast and drag my-\nself off to my boring job, where I once again\nwill have to squeeze out some sort of result\nthat is needed by someone else but me. Yet\nanother day of a burdensome and purpose-\nless life…\nI woke up from the rustling of the morning\nstars. What was this depressing dream? As if\na fragment of my previous life returned to\nme. Thankfully, it was only a dream. Re-\nlieved, I stretch myself just like my cat does.\nThere he is that lazy-bones, sprawled out on\nthe bed. You can tell by the way his ears are\npointing that he is aware of my presence. Get\nyour whiskered muzzle up, and let’s go for a\nwalk. I’ve ordered a sunny day today, and so\nI’m off to the sea.\n18/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 741
  },
  {
    "chunk_full": "The path was going through a forest, and the\nrustling of the morning stars gradually faded\naway into the multi-voiced choir of the bird\ncommunity.\nOver\nthere,\nin\nthe\nbushes\nsomeone is making an extra effort trying to\nsing – “Food! Food!” Ah, there he is, the\nlittle good-for-nothing! How can a fluffy\nlittle bundle like you be chirping away so\nloudly? Incredible, it never occurred to me\nbefore that each bird has its own unique\nvoice, and yet, not one false note is sung, and\nthe many voices produce a wonderful me-\nlodious symphony, something a skilled or-\nchestra could never match.\nThe sun stretches its rays amidst the trees.\nThis magical illumination brings the huge\ndepths and rich beauty of the forest to life,\ntransforming the woods into a wonderful\nhologram. The path leads me gently to the\nsea. Emerald waves are quietly whispering,\ntalking with the warm wind. The shore\nseems endless and empty, but I feel calm and\n19/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 742
  },
  {
    "chunk_full": "comfortable, as if this overpopulated world\nhas created a secluded little space just for\nme. Some people think that our surround-\nings are just an illusion that we ourselves\ncreate. Well, no. I’m not arrogant enough to\nthink that all this beauty is nothing but the\nproduct of my imagination.\nStill under the oppressive influence of my\ndream, I started to remember my former life,\nwhich in fact was just as gloomy and hope-\nless as the dream. Very often I’ve tried, like\nmany others, to demand from this world\nwhat I felt it owed me. In return, the world\nindifferently turned its back on me. Experi-\nenced people told me that the world doesn’t\ngive in that easily, you have to fight it in or-\nder to conquer it. Therefore, I would try do-\ning that, but to no avail. I just wound up\nwearing myself out. However, the experi-\nenced people had an answer to this too - you\nare a bad person, so you have to change\nyourself and only then demand something\n20/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 743
  },
  {
    "chunk_full": "from the world. I tried to fight myself, but it\nturned out to be even harder.\nThen one night I had a dream: I found my-\nself in some kind of a nature reserve. Un-\nspeakable beauty surrounded me, and I was\nwalking and admiring this splendor. Then\nsuddenly an angry old man with a gray beard\nappeared. As I understood, he was the\nOverseer of the reserve. He began to silently\nobserve me. I moved towards him and as I\nopened my mouth to speak, he silenced me.\nHis voice was cold when he told me that he\ndoesn’t want to hear anything, that he’s tired\nof the cranky and greedy visitors, who were\nnever\nsatisfied,\nalways\ndemanding\nsomething, making a lot of noise and leaving\npiles of garbage behind. I silently nodded my\nhead in agreement and moved on.\nThe\nmagnificent\nnature\nof\nthe\npreserve\nsimply astounded me. Why haven’t I been\nhere before? Entranced, I wandered around\n21/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 744
  },
  {
    "chunk_full": "with no particular aim, staring in awe. No\nwords could describe how incredibly won-\nderful the nature surrounding me was. Thus,\nI felt exalted, without a single thought in my\nmind.\nSoon enough, the Overseer appeared again.\nThe austere look on his face has eased. With\na gesture, he asked me to follow him. We\nclimb onto the top of a green hill, where a\nspectacular view of a picturesque valley\nopens in front of us. Down in the valley, you\ncan see a village or a settlement of some\nkind. Little toy houses, overflowing with\nplants and flowers...it was just as a picture\ntaken from a fairy tale. You could have stud-\nied the scenery in amazement for a very long\ntime, if only it didn’t seem so unreal. I star-\nted to suspect that such things could only be\nexperienced in dreams. I looked question-\ningly at the Overseer, but he only smiled into\nhis beard, as if he wanted to say, “You\nhaven’t seen anything yet!”\n22/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 745
  },
  {
    "chunk_full": "We were walking down to the valley, when I\nbegan to realize that I couldn’t remember\nhow I got to the reserve in the first place. I\nreally wanted to get some kind of explana-\ntion from the old man. I think I made a silly\nremark about how lucky and happy the\npeople are that can afford to live amidst this\nbeauty. The Overseer answered, irritated\n“And who stops you from being one of those\npeople?”\nI replied with the same old story that not\neverybody is born rich, and that you cannot\ncontrol your destiny. The Overseer ignored\nmy words and said, “That’s exactly the point,\nevery man is free to choose any destiny he\nlikes. The only freedom we have is the free-\ndom\nto\nchoose.\nAnybody\ncan\nchoose\nwhatever he wants.”\nHis ideas were beyond my comprehension\nand my philosophy of life, so I wanted to ar-\ngue against him. But the Overseer didn’t\n23/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 746
  },
  {
    "chunk_full": "want to hear any of it, as he said, “You fool!\nYou have the right to choose, but you don’t\nuse that right. You simply don’t understand\nwhat this means – to choose.” This is all in-\nsane, I thought. What does he mean by that I\ncan choose anything I want? As if everything\nin this world was allowed! Then suddenly I\nunderstood that all was just a dream! I was\npuzzled, because I had no previous experi-\nence of waking up in a dream and thus,\ndidn’t know how to act in such a strange\nsituation.\nAs far as I remember, once I realized I was\ndreaming I hinted to the old man that in a\ndream, as in waking life, he can say all the\nnonsense he wants, and that is all there is to\nhis freedom. But my comment didn’t seem to\nbother the Overseer at all - he only laughed\nat me. Realizing the absurdity of the situ-\nation (why even bother starting a discussion\nwith a character from my own dream?), I\nstarted thinking maybe it would be better to\n24/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 747
  },
  {
    "chunk_full": "simply wake up. The old man probably read\nmy mind. “Well, enough,” he said. “We don’t\nhave a lot of time. I never thought they’d\nsend me an idiot like you. But nonetheless, I\nwill have to complete my mission.”\nI started asking him what this “mission” was\nand who “they” are. He ignored my ques-\ntions, but gave me a riddle, which seemed\nsilly to me at the time: “Everyone can ac-\nquire the freedom to choose anything they\nwant. Here is your riddle: how do you get\nthis freedom? If you solve the riddle, your\napples will fall into the sky.”\nHow did apples get into this? I started to lose\nmy patience and so, I told the old man that I\nhad no intention of guessing any riddles.\nOnly in dreams and fairy tales could you see\nall kinds of wonders, while in reality, apples\nalways fall to the ground. To which he\nanswered, “Enough! Let’s go, I have to show\nyou something.”\n25/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 748
  },
  {
    "chunk_full": "When I woke up, I realized that sadly I could\nnot remember what happened next in my\ndream. However, I had a strong feeling that\nthe Overseer had somehow put information\nin my head, information that I could not ex-\npress with any words available to me. Only\none strange word remained in my memory –\nTransurfing.\nThe\nonly\nthought\nspinning\naround in my head was that there was abso-\nlutely no need to furnish my world by myself\n– everything was created a long time ago\nwithout my participation, but for my well-be-\ning. It’s also not worth struggling with the\nworld for your place under the sun, because\nthat’s the least effective method. Apparently,\nno one is keeping me from simply choosing\nthe world I would like to live in.\nAt first, the idea seemed absurd to me. And\nmost probably I would have forgotten all\nabout\nthis\ndream.\nBut,\nto\nmy\ngreat\namazement, I soon discovered that I could\nremember specific details about what the\n26/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 749
  },
  {
    "chunk_full": "Overseer meant by the expression to choose\nyour own world, and how one could go about\ndoing that. The solution to the Overseer’s\nRiddle came to me on its own - out of\nnowhere. Every day I discovered something\nnew, and each time I got very surprised and\nalmost a little bit afraid. I cannot explain ra-\ntionally where all this knowledge came from.\nI can only say one thing for sure – there is no\nway it could have come from me.\nEver since I discovered Transurfing (or\nrather, ever since I was allowed to discover\nit), my life was filled with a new joyful mean-\ning. Anyone who has ever done any creative\nwork knows how much joy and satisfaction\nsomething made with your own hands brings\nyou. But this is nothing compared to the pro-\ncess of creating your own destiny. Although,\nthe expression “creating one’s destiny” in its\nordinary meaning is a little out-of-place\nhere. Transurfing is the method for literally\nchoosing\none’s\nown\ndestiny,\nmuch\nlike\n27/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 750
  },
  {
    "chunk_full": "choosing an item at the supermarket. What\nthis all really means is exactly what I want to\ntalk to you about. You will find out why\napples can “fall to the sky,” what it means to\nhear “the rustling of the morning stars”, and\nthere are many other very strange things that\nare only waiting for you to discover them.\nThe\nRiddle\nof\nthe\nOverseer\nThere are many different theories about the\nnature of destiny. One of them says that des-\ntiny is the same as fate, something that is\npredetermined. No matter how you try, you\ncan’t escape your destiny. On the one hand,\nsuch an interpretation can be depressing in\nits hopelessness. If a person’s destiny is not\none of the better ones, then there’s no hope\nat all for improvement. But, on the other\nhand, there are always people who are\n28/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 751
  },
  {
    "chunk_full": "content with such a state of affairs. After all,\nit’s reliable and comforting when the future\nis more or less predictable and doesn’t scare\nyou with uncertainty.\nAnd yet, the fatal inability to escape own des-\ntiny can evoke feelings of discontent and in-\nner protest. One feels cheated, out of luck\nand so, one starts complaining: why is life so\nunfair? One person has everything in excess,\nwhile\nthe\nother\nis\nconstantly\nin\nneed.\nEverything comes easy to one person, while\nanother runs round and round like a mouse\nin a wheel, getting absolutely nowhere. One\nperson is gifted with beauty, intelligence and\nstrength, whereas another, unaware of what\nsin he is paying for, is labeled as a second-\nclass citizen throughout his entire life. Why\nthis injustice? Why does life, with its infinite\nvariety, put limitations on certain groups of\npeople? Why are those that are less fortunate\nat fault?\n29/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 752
  },
  {
    "chunk_full": "A deprived person would feel resentment\nand would certainly try to find some sort of\nexplanation to why things are the way they\nare. And then all kinds of teachings pop up,\nlike the one where they teach you that you\nhave bad karma and that you are paying for\nterrible sins committed in your past lives. As\nif, the Lord has nothing better to do than to\nfoster his careless children! Nevertheless, it\nappears that despite His almighty power, He\nexperiences difficulties with this particular\nmethod of fostering. Instead of punishing\npeople for sins in this life, God for some un-\nknown reason, postpones retribution until\nlater. However, one might wonder what\npoint there is in punishing someone for\nthings they do not remember.\nThere is another version that tries to explain\nwhy there are inequalities in the world. This\nversion gives hope, as it promises almost im-\nmediate compensation to those that are suf-\nfering and that are in need. Yet, again, you\n30/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 753
  },
  {
    "chunk_full": "will be rewarded somewhere in heaven or in\nanother life. No matter how you look at it,\nexplanations like these are not entirely satis-\nfying. It is not even important whether these\npast and future lives exist or not, because a\nperson is only aware of and remembers this\none particular life. Thus, in a sense it is his\nonly life.\nIf you believe that your fate is predeter-\nmined, then the only way to avoid depression\nwould be to surrender and accept your fate\nas it is. And, as always, there will be new ex-\nplanations to why you just cannot be suc-\ncessful “You want to be happy? Be happy!”\nRemain an optimist, and be satisfied with\nwhat you have. Certain people make it clear\nto you that you are unhappy because you are\nalways dissatisfied and because you simply\nwant too much. In addition, you can only be\nhappy by definition - that is you are happy\nbecause you are happy. You need to take joy\nin life. So, you kind of agree, but at the same\n31/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 754
  },
  {
    "chunk_full": "time it’s a bit awkward to meet gray reality\nwith joy and happiness. Do you really have\nno right to want something more out of life?\nWhy force yourself to be happy when you’re\nnot? It’s just as impossible as it is forcing\nyourself to love.\nSo-called “enlightened” individuals that are\nbusy calling for universal love and forgive-\nness constantly surround us. If you want to\navoid harsh reality, you can put this illusion\non like a blanket over your head, and sure\nenough, you will feel a little better. But deep\ndown inside, you wouldn’t be able to under-\nstand completely, why you should be forgiv-\ning people you hate or loving those you are\nindifferent to? What’s the use? After all, it\nwouldn’t be a natural happiness, but a forced\none. As if joy should not be coming to you by\nitself, but rather it should be squeezed out of\nyou, like toothpaste out of the tube.\n32/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 755
  },
  {
    "chunk_full": "Of course, there are people who don’t believe\nthat life is so boring and primitive that it\nleads to one predetermined fate. They don’t\nwant to be satisfied with what they have, and\ninstead prefer to take joy in their achieve-\nments and not in the situation they are in.\nFor these people, there is yet another con-\nception of fate: “Man forges his own happi-\nness.” Well, and as we know, we have to\nstruggle to achieve happiness. And how\ncould it be any other way? “Smart” people\nsay that nothing comes easy. It would seem\nlike an irrefutable fact: if you don’t want to\naccept the happiness as it is, then you need\nto elbow your way to your own happiness.\nHistory lessons tell us of how bravely the\nheroes have fought and how they were sacri-\nficing themselves, fighting day and night,\novercoming\nunthinkable\nobstacles.\nThose\nthat won the battle were greatly rewarded,\nbut only after enduring immense burdens\nand great losses of constant struggle. But,\n33/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 756
  },
  {
    "chunk_full": "that’s not the whole story. Millions fight and\ntoil, but only a handful actually succeed. You\ncould waste your entire life on a desperate\nstruggle for a place in the sun, and all could\nstill be in vain. Why is this life so cruel and\nhopeless?\nWhat a heavy requirement it is – to have to\nfight the world so that you can make your\nown happiness. And if the world doesn’t give\nin, then you have to fight yourself. If you’re\nso poor, sick, ugly and unhappy – it’s your\nown fault. You have many flaws and there-\nfore, you must change. Man is faced with the\nfact that from the very beginning of his life,\nhe was nothing but an assortment of flaws\nand defects, which require constant and hard\neffort, if he is to even dream of happiness. A\ndepressing picture, is it not? It would seem\nthat if a man didn’t get lucky from the begin-\nning and he was not born in a wealthy and\nhappy family, then his lot is either to humbly\nbear his cross or dedicate his whole life to a\n34/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 757
  },
  {
    "chunk_full": "never-ending struggle. Somehow, it doesn’t\nfeel right rejoicing in a life like that. Is\neverything really that hopeless and is there\nno light in sight?\nAnd yet, there is a way out. The way out is as\nsimple as it is pleasant, unlike all the altern-\natives listed above, because it is to be found\nin another plane. The notion of destiny with-\nin Transurfing is based on an entirely differ-\nent view of the world. Now, don’t go waving\nyour hands in the air and shouting in disap-\npointment that this is just another attempt to\nfeed you a bunch of nonsense. You’ll agree\nthat every known idea of destiny is based\nupon a specific world-view which is in turn\nbased on a few premises that cannot be\nproved completely.\nFor instance, materialism is founded on the\nidea that matter came first and then came\nconsciousness, whereas idealism claims the\nexact opposite. And yet, it is not possible to\n35/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 758
  },
  {
    "chunk_full": "prove any of the two. Nonetheless, both ideas\nhave been used to construct convincing\nworld models that have acquired many faith-\nful advocates. The two schools, each in their\nown way, are able to explain the nature of\nthe world philosophically, scientifically, and\nfrom a religious point of view. And they are\nboth right and wrong at the same time. We\nwill never be able to define the absolute\ntruth, because of the relative nature of the\nconcepts we use to do so. The well-known\nparable of the three blind men describes how\none of them felt the elephant’s trunk, the\nsecond felt his foot, and the third the ele-\nphant’s ear. Based on their perceptions each\nof them came to a different conclusion about\nwhat the animal looked like. Therefore, try-\ning to prove that one way of looking at things\nis truer than the other is pointless. The im-\nportant thing is that a particular way of look-\ning at things works for you.\n36/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 759
  },
  {
    "chunk_full": "You’re\nprobably\nfamiliar\nwith\nthe\nwell-\nknown idea that reality is an illusion we cre-\nate ourselves. Yet, no one has really ex-\nplained where this illusion comes from.\nSo are we just watching a “movie”? That is, of\ncourse, very unlikely, but in a sense there is a\ngrain of truth in that statement. There is also\nthe opposite opinion - the material world is\njust a mechanism that operates under strict\nlaws. In a world like that, minds are unable\nto determine anything.\nNevertheless, the mind of man is constantly\nstriving to resolve ambiguities. It really\nwants to shatter one theory to pieces, only to\nidealize another. Basically, this is what sci-\nentists do, centuries after centuries. But after\neach struggle for the truth, one fact remains\non the battlefield: Any theory is nothing but\na separate piece of the manifestation that is\nour multifaceted reality.\n37/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 760
  },
  {
    "chunk_full": "Each theory is supported by the time during\nwhich it was developed, and therefore, it has\nthe right to exist. Any view of life works in\nthe same way. If you have decided that fate is\nsomething predetermined, something that\nyou are not in a position to change, then it\nwill be that way. In that case, you are will-\ningly putting your life into someone else’s\nhands, and it doesn’t really matter in whose.\nThe thing is that you turn into a little paper\nboat that follows the waves of the sea, bend-\ning to their will. If, on the other hand, you\nbelieve that you shape your own destiny,\nthen you consciously take responsibility for\neverything that happens in your life. You are\nstruggling with the waves, trying to take con-\ntrol of your little boat. Keep in mind that\nyour choice is always made into reality.\nWhat you choose is what you get. Whatever\nworldview you adopt, it will be a right one.\nHowever,\nyou\nshould\nknow\nthat\nothers\nwould disagree and argue with you simply\n38/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 761
  },
  {
    "chunk_full": "because they are also right in whatever\nworld-view they adopt.\nIf you take any phenomenon in our reality,\nand make it the point of reference, you will\nbe able to create an entire field of science.\nThis field would have no contradictions with-\nin itself and it would therefore, successfully\nreflect one of the manifestations of reality.\nTo create an entire knowledge system like a\nfield of science, it’s enough to take a couple\nof facts that don’t even have to be fully un-\nderstood, but which nonetheless have a place\nin the system.\nFor example, quantum physics is based on\nseveral improvable truths, called postulates.\nThey cannot be proved, because they are the\ninitial points of reference of quantum phys-\nics. In quantum physics, a micro object will\nact as a particle in some cases and as a wave\nin others. Scientists were unable to interpret\nsuch dualism unambiguously, and so, they\n39/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 762
  },
  {
    "chunk_full": "simply accepted that this is the way things\nwere. The postulates of quantum physics are\nable to accommodate the immense variety of\nshapes and forms through which our reality\ncan be manifested. Almost as if, the blind\nmen in our parable would agree upon the\nfact that an elephant sometimes behaves as a\npole and sometimes as a snake.\nIf, when describing a micro object, we choose\nto see it as a particle, we would get a model\nof an atom first built by the famous physicist\nNiels Bohr. In the given model, electrons re-\nvolve around the nucleus much as planets re-\nvolve around the sun in our Solar System. If,\non the other hand, we take a wave as the mi-\ncro object’s fundamental characteristic, then\nthe atom will look like a blurred stain. Both\nmodels work, they just reflect different and\nseparate forms of the ways in which reality\ncan be manifested. Therefore, once again we\nget whatever we choose.\n40/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 763
  },
  {
    "chunk_full": "Basically, any manifestation of reality can be\na point of reference, creating a knowledge\nsystem, and it will certainly function and\nhave a place in the world. While chasing the\ntruth, people always wanted to understand\nthe nature of the world they were living in.\nThey tried to accomplish that by studying\nparticular features. The massive scientific\nknowledge was created by describing and ex-\nplaining specific natural phenomena. This is\nhow separate branches of knowledge came to\nbe. Interestingly enough, these are often con-\ntradicting each other.\nThe world is a whole by its nature and yet, it\nis always taking on different appearances.\nWhile people try hard to examine and ex-\nplain one appearance, another one enters the\nstage and is contradictory to the previous\none. Scientists try to unite different mani-\nfestations of reality so that contradictions\ncan be removed. However, that is an ex-\ntremely hard thing to do. There is only one\n41/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 764
  },
  {
    "chunk_full": "single fact that is not subject to any doubt, a\nfact that is able to unite and reconcile all\nbranches of knowledge - the immense variety\nof forms through which our reality can ap-\npear to us. The diversity of variations is the\nforemost and fundamental quality of our\nworld.\nDistracted by the attempts to explain the\nseparate manifestations, adherents of differ-\nent schools of thought avoid the fact of the\nmultiplicity of variations. Indeed, what else\ncould you extract from this fact? The multi-\nplicity serves as a beginning of the story or\neven a point of origin. Any departing points\nof different branches of knowledge are sec-\nondary in relation to it. However, no one\nbothers with the point of origin, as if it con-\ntains no information at all. But, oh yes, it\ndoes.\nIt\ncontains\nthe\nmost\nincredible\ninformation.\n42/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 765
  },
  {
    "chunk_full": "We will have to use the multiplicity of vari-\nations as our starting point, in order to solve\nthe Riddle of the Overseer. In other words,\nwe will claim that reality can be manifested\nin an infinite number of ways. Despite the\ngeneral nature of our claim, we will find that\nit will reveal the most interesting and unex-\npected knowledge.\nLet’s start with the fact that all forms\nthrough which our reality is manifested must\nhave an origin, a place where the multitude\nof variations exists. Where are the “laws” of\nour world recorded? The world reveals itself\nas matter moving through space and time.\nAnd moving matter is subject to certain laws.\nAs you know, points are distributed on a\nfunction graph according to a specific math-\nematical formula. We could say that the\nmovement of a point on a graph is governed\nby a defined function. However, the formulas\nand laws are just abstract inventions of our\nminds,\ncreated\nto\nfacilitate\nour\n43/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 766
  },
  {
    "chunk_full": "understanding and to explain what we per-\nceive with our senses. It’s highly unlikely\nthat nature is keeping these formulas and\nlaws hidden somewhere.\nHow else can we fix points on a graph? Well,\nwe could of course store the exact coordin-\nates for each point, which is already a prob-\nlem because there is an infinite amount of\nthem. Our memory is only that big and can-\nnot handle such a massive amount of in-\nformation. But, to nature - infinity is not a\nproblem. There is no need for nature to gen-\neralize the location and movement of points\non a graph by using a formula. If we were to\nbreak up a linear function into an infinite\nnumber of small points, then each point\ncould be considered a cause and each con-\nsecutive point could be considered an effect.\nThus, the movement of any material point in\nspace and time can be viewed as an infinitely\nlong and continuous chain of infinitely small\ncauses and effects.\n44/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 767
  },
  {
    "chunk_full": "In our knowledge, we represent the motion\nof matter using laws, while nature contains\nthis motion in its pure form – as an infinite\nnumber of causes and effects. Broadly speak-\ning, data about every possible material ob-\nject, and its path along the infinite number of\npoints, is stored in a field of information,\nwhich we will refer to as the space of vari-\nations.\nIt\ncontains\ninformation\nabout\neverything that was, that is and that will be.\nThe space of variations is an informational\nstructure has a rather material basis. This in-\nfinite field of information contains all pos-\nsible variations to any event that could take\nplace. We can say that the space of variations\ncontains all information. Let’s not try to\nguess how this information is preserved –\nthat’s not at all important. The essential\nthing to remember is that the space of vari-\nations works as a template, a coordinate\nnetwork for moving matter through space\nand time.\n45/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 768
  },
  {
    "chunk_full": "Hence, each point in the space of variations\ncontains its own variation of a particular\nevent. To make it easier to understand, let’s\npretend that a variation consists of a script\nand decorations. The decorations represent\nthe external view or form of manifested real-\nity, while the script is the path along which\nmatter is transported. To make things even\nmore convenient, we can divide the space of\nvariations into sectors, each of which would\nhave its own script and decorations. The\nmore space there is between sectors, the\ngreater are the differences in scripts and dec-\norations. Your destiny is also represented by\na multitude of variations.\nTheoretically, there are no limitations to the\nnumber and type of scripts and decorations\nthat could exist in a person’s life. That is be-\ncause the space of variations is infinite in\nnature. The least significant event could have\nan impact on a person’s future destiny. A\nperson’s\nlife\nis\njust\nlike\nany\nother\n46/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 769
  },
  {
    "chunk_full": "transportation of matter, it is nothing but a\nchain of causes and effects. In the space of\nvariations, effect and its cause are closely\nlocated. One follows the other, and thus, the\nsectors of one’s destiny form a life track. The\nscripts and decorations on one such track are\nmore or less of the same nature. The life of a\nman flows evenly along one direction until\nan event takes place that changes the scripts\nand decorations. Then destiny takes a turn\nand starts to move along a different life\ntrack.\nImagine that you’ve been watching a play.\nYou go back to the theater the next day, to\nwatch the very same play. Yet, the play is\nnow performed with different decorations.\nThe two plays you’ve seen are life tracks that\nare rather close to each other in the space of\nvariations. During the next theatrical season,\nyou watch a play with the same actors, but\nthis time around, the script has been signific-\nantly changed. This life track is located\n47/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 770
  },
  {
    "chunk_full": "further away from the original one, where\nyou went to see the play for the first time.\nAnd finally, the same play could run in a dif-\nferent theatre, and you would therefore, ex-\nperience a new and unusual interpretation of\nthe play. Therefore, this life track is already\nquite far away from the first life track.\nReality manifests itself in all its multiplicity\nprecisely because the number of variations\nis infinite. Any point of origin will flow into\nthe chain of causes and effects. Having\nchosen your point of origin, you will get a\ncorresponding manifestation of reality. We\ncan say that reality unfolds itself along a life\ntrack, depending on the selected point of ori-\ngin. Everyone gets what he or she chooses.\nYou have the right to choose just because the\ninfinity of variations already exists. Nobody\nprevents you from selecting whatever destiny\nyou like. Mastering your destiny comes down\nto one simple thing – making a choice.\n48/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 771
  },
  {
    "chunk_full": "Transurfing gives you the answer to the\nquestion of how to make that choice.\nThus, an informational structure contains an\ninfinite multitude of potential possibilities –\nvariations, each with its own script and dec-\norations.\nThe\nprocess\nof\nmaterialization\ntakes place in accordance with what informa-\ntion is contained within this structure. The\nprocess of moving matter through the space\nof variations can be demonstrated by the fol-\nlowing mental experiment.\nPicture a water pipe. A freezing ring is slowly\nmoving along the pipe, so that water in the\npipe freezes only at the location of the ring.\nHence, ice crystals are traveling in the water\nalong the pipe. Water molecules remains in\ntheir places in a relatively loose state. When\nthe freezing ring passes along a particular\nspot, water molecules inside the pipe are\nfixed frozen into ice crystals. But then the ice\nmelts and the water molecules are released\n49/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 772
  },
  {
    "chunk_full": "again. The ice crystal itself doesn’t move in\nthe water, through the pipe. It is the struc-\nture of ice - the frozen state - that is moving\nthrough the pipe.\nSo, metaphorically speaking the water in the\npipe represents the space of variations, while\nthe crystal of ice represents the material\nmanifestation of variations. The water mo-\nlecules represent people and their position in\nthe crystal structure is manifested as a pos-\nsible variation of destiny. There is no definite\nanswer to what the freezing ring represents.\nIn other words, how and why can an inform-\national structure be transformed into mat-\nter? In the micro-world of quantum physics,\nmatter can take form of a bundle of energy.\nWe know that micro particles are being born\nand destroyed repeatedly in vacuum space.\nSo, in a way matter exists, but at the same\ntime it doesn’t really have a proper material\nsubstance. There’s only one thing that is\n50/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 773
  },
  {
    "chunk_full": "clear – everything tangible is based on intan-\ngible energy.\nI hope I haven’t tired you too much with\nphysics. We are only at the starting point of\nTransurfing. But what you are about to find\nout from this book can be relatively shock-\ning. Therefore, it’s inevitable that I present\nyou with some theoretical background, so\nthat your mind doesn’t get too confused. Just\nbear with me a little while longer.\nAn ocean’s wave can serve as yet another\nanalogy to illustrate manifestation in the\nspace of variations. Let’s suppose that as a\nresult of an earthquake, a wave was formed\nout on the sea. It travels along the ocean’s\nsurface as a large hump, but the water itself\nremains in place. It is not the mass of water\nthat is moving, but rather the manifestation\nof its energy potential. Only around the\nshore does the water splash onto the dry\nland. All other waves are acting the same\n51/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 774
  },
  {
    "chunk_full": "way. In this analogy, the sea is the space of\nvariations, while the wave is the material\nmanifestation.\nSo what do we get here? On the one hand,\nmaterial manifestation moves in space and\ntime. Yet on the other hand – variations re-\nmain in their places and continue to exist\nforever? This means that everything was, is,\nand will be? Well, why not? Time is just as\nstatic as space. You can only feel the flow of\ntime when the film is running and the frames\nfollow one another. Now unfold the film and\nlook at all frames at once. Where did the\ntime go? All frames exist simultaneously.\nTime remains static only until we begin to\nlook sequentially at one frame after another.\nThis is exactly what happens in real life, and\nthat’s why the idea that everything comes\nand\ngoes\nis\nfirmly\nembedded\nin\nour\nconsciousness.\n52/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 775
  },
  {
    "chunk_full": "In fact, everything that is written in the in-\nformation field has been there forever and\nwill always remain there. Life tracks exist\nlike film reels. Everything that has happened\ndoes not disappear for good, but continues to\nexist. Everything that is about to happen is\nhappening now. The present is just the ma-\nterial manifestation of a given sector in the\nspace of variations on your particular life\ntrack.\nMany people might wonder: “How is it pos-\nsible that all possible variations to my des-\ntiny exist permanently? Who would need this\ninformation? God? Nature? And why would\nanyone\nneed\nthis\ninformation\nanyway?”\nThen try to imagine a point on a coordinate\nplane. In school, we learned the following: a\ngiven point on a coordinate plane can have\nany x and y coordinates, (note: any!) from\nnegative to positive values of infinity. Why\ndid no one ever ask the question: How come\na point can have any coordinates? Now,\n53/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 776
  },
  {
    "chunk_full": "picture a point moving along a linear func-\ntion, asking itself: “How come the path I’ve\nalready walked has always been there and\nwill continue to be there forever? And how\ncome my future journey and its path are\nalready predetermined?” Yet, you are looking\nat the point and its path from above and\ntherefore, there is nothing amazing about its\ntravel.\nThe space of variations works as a template,\nit determines in what way things should be\nmanifested in reality. Imagine a dark forest\nand a man with a flashlight. The man walks\nthrough the forest, and wherever he points\nwith his flashlight, he is illuminating a small\npart of the forest. Realization2 manifests it-\nself like a spot of light. The entire dark forest\nis the space of variations, while the illumin-\nated part is the realization of a variation of a\ngiven sector. What then is this “light?” In\nother words, what “lights up” or materializes\na variation in the template?\n54/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 777
  },
  {
    "chunk_full": "To answer to this question, we must pick yet\nanother starting point. In our time, there’s\nalready no doubt that thoughts are material.\nReality appears to us in two shapes: on the\none hand, our existence is defined by our\nconsciousness, and yet, on the other hand,\nthere is plenty of indisputable evidence to\nthe contrary. Our thoughts do not only func-\ntion as a motivation to action, they also have\na direct impact on our reality. For example,\nour worst fears tend to come true. Of course,\nyou could argue that we are not really talking\nabout materialization of our thoughts, but\nrather of an ominous premonition. Sure\nenough, most paranormal phenomena tend\nto be unexplained and ambiguous. But this\ndoesn’t mean that we can ignore this given\nform of manifested reality. There is plenty of\nevidence to support the fact that thoughts\ncan have a direct influence on reality.\nIn one way or another, a person’s conscious-\nness forms his destiny. This book talks\n55/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 778
  },
  {
    "chunk_full": "specifically about how such things are pos-\nsible. Let’s make the following statement our\nstarting point: waves of thought energy ma-\nterialize a potential variant. This statement\nis correct, because reality can be manifested\nin any form defined by consciousness. You\ncan find evidence supporting this hypothesis\nnot only from your daily life but also from\nexperiments in quantum physics. For our\npurposes, it is not really important to know\nexactly how thoughts interact with the space\nof variations. It is still not clear how the pro-\ncess of information transfer takes place –\nwhether it has an energy basis or a basis of\nsome other kind. To make things easier, we’ll\nsimply assume that the wave of thought en-\nergy “highlights” a certain sector of the space\nof variations and as a result, the variation\ngets\nits\nown\nmaterialization.\nWaves\nof\nthought will find their corresponding sector\nin the space of variations. The variation of\nthat particular sector is then materialized.\n56/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 779
  },
  {
    "chunk_full": "Hence, in this chain of events consciousness\nis able to define reality.\nYou should just keep in mind that this is only\none way of manifesting reality. It’s not pos-\nsible to form your own reality the way you\nlike it just by pure meditation. Although,\nthere are people who can make objects ma-\nterialize out of thin air. But these people are\nrarely seen, and they don’t advertise their\nabilities. Nonetheless, thoughts have the\nsame impact on a man’s destiny, as his spe-\ncific actions. People are accustomed to the\nidea that their actions attract visible con-\nsequences that are easy to explain. The influ-\nence of thoughts is usually unnoticed and\ntherefore, you cannot explain nor predict it.\nIt may seem that establishing an obvious\ncausal link between thoughts and their sub-\nsequent events is relatively difficult. But you\nare about to see that a person’s thoughts\nhave a direct influence on the form of his\nreality. People get exactly what they choose.\n57/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 780
  },
  {
    "chunk_full": "Someone could object: “Are you trying to say\nthat all these oceans, mountains, planets,\ngalaxies – they are all nothing but the\nproduct of my thoughts?” The tendency of\nman to sometimes consider himself the cen-\nter of the Universe is part of human nature.\nActually, man occupies a tiny niche in this\ninfinite space. Our world is populated with\nmillions of living organisms, and each and\nevery one of them makes its own contribu-\ntion\nto\nthe\nformation\nof\nreality.\nEach\ncreature has its own parameters of thought\nwaves. If you’re not comfortable viewing\nplants as thinking objects, you may name the\nprocess differently. It won’t change the main\nidea. We can’t even say for sure that non-liv-\ning things don’t have anything similar to the\nthoughts of living organisms. Not to mention\nthe Spirit that penetrates everything in exist-\nence and which we call God. Each creature\nhas its own consciousness and forms the lay-\ner of its own world. We can say that\n58/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 781
  },
  {
    "chunk_full": "everything in this world carries a particle of\nGod, and in this way, He rules the world.\nEach person travels along his own life track.\nBut at the same time all people live in one\nand the same world. The material world is\none for everybody, but each person has his\nown manifestation of reality. Let’s suppose\nthat you are a tourist and you are visiting a\nbeautiful city. You are admiring the sights\nand the architectural beauty; you see the\nflower gardens, fountains, parks with little\npaths and the smiling faces of the wealthy\ntownspeople. When you pass the garbage\ncan, you see a homeless person. He is just\nlike you, in the same world and in the same\ndimension. However, he does not see what\nyou see. He sees an empty bottle in the can,\nthe dirty wall, another bum that’s out to get\nthe empty bottle, the police, looking suspi-\nciously at him and so on. You live on one life\ntrack, and he lives on another. Your life\ntracks\nhave\ncrossed\nin\nthe\nspace\nof\n59/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 782
  },
  {
    "chunk_full": "variations. Therefore, this world, as a materi-\nalization of reality is one for both of you.\nAll material manifestations have an energy\nbasis. The field of energy is primary, whereas\nall other physical manifestations are second-\nary. Scientists try to bring together different\nmanifestations of energy into one single the-\noretical framework and we’ll soon see res-\nults. But then they’ll have to add more things\nto the theory, because reality can manifest it-\nself in an infinite number of ways. Without\ngoing into much detail, let’s look at energy as\nsome kind of abstract and invisible force that\nnonetheless, exists in reality. For our pur-\nposes, it will be enough to acknowledge the\nfact that the energy of a person’s thoughts is\nentirely material. The energy of thought isn’t\nlocked in a person’s head, circulating there\naimlessly. Rather, it is dispersed into space\nwhere it interacts with the surrounding en-\nergy field. Nowadays very few people would\nargue against this fact.\n60/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 783
  },
  {
    "chunk_full": "For convenience, as a parameter of thought\nwaves, we can take their frequency, just as\nwe measure radio waves. Whenever you are\nthinking about something, the frequency of\nyour thought energy is tuned to a certain\narea in the space of variations. When energy\nfalls within a sector of the space of vari-\nations, the sector’s specific variation starts to\nmaterialize. Energy has a complex structure\nand penetrates everything in this world.\nPassing through a man’s body, energy is\nmodified by his thoughts, and upon exiting,\nenergy acquires parameters that correspond\nto these thoughts (a radio transmitter works\nin a similar way). Energy parameters absorb\nthe characteristics of thoughts. That way the\nenergy that is going out is transformed into\nthought waves, which in turn convert a sec-\ntor of the space of variations into a material\nmanifestation. When you think of something\neither good or bad, you radiate thought en-\nergy into the space of variations. Modified\n61/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 784
  },
  {
    "chunk_full": "energy is applied to a specific sector and this\ninteraction results in corresponding changes\nin your life.\nSituations in our life are formed not only by\nspecific actions, but also by the nature of a\nperson’s thoughts. If you have a hostile atti-\ntude towards the world, it will treat you the\nsame way. If you are always whining, ex-\npressing your dissatisfaction with the world,\nthere will be more and more reasons for you\nto be dissatisfied. If your attitude towards\nthe world is predominantly negative, then\nthe world will be a terrible place to live in.\nThe opposite is, of course, also true – a posit-\nive attitude is the most natural way of chan-\nging your life for the better. You get what you\nchoose. That is reality, whether you like it or\nnot.\nWhile your thoughts have more or less the\nsame direction, you will find yourself on the\nsame life track. As soon as your attitude to\n62/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 785
  },
  {
    "chunk_full": "reality changes, in one way or another, the\nparameters of your thought waves acquire\nnew characteristics, and the material mani-\nfestation of your world moves from the old\ntrack to a new one. On that track, events fol-\nlow a completely different script, in agree-\nment with the parameters of your radiation.\nIf for some reason you don’t like the script,\nyou’ll struggle, trying to change the situation.\nEvery\nperson,\nwhen\npresented\nwith\nobstacles, reacts negatively, expressing dis-\nsatisfaction or becoming depressed. Thus,\nyour thought waves relocate themselves onto\na track where there will be even more\nobstacles. As a result, life will roll faster and\nfaster downhill.\nThe process described above may seem bey-\nond your control, but in fact, you are the one\nresponsible for directing your energy of\nmanifestation into problematic areas of the\nspace of variations. You believe that by doing\nwhat\nyou\nare\ndoing\nyou\nare\neffectively\n63/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 786
  },
  {
    "chunk_full": "overcoming obstacles. While in reality, you\nget exactly what you chose. If you choose to\nfight obstacles – then you will have more\nthan enough of them to fight. If you are pre-\noccupied with thinking about problems, then\nthey will always be there in your life. You are\ndirecting your actions so that you can change\nthe situation on your current life track, but\nyou can never change a script in the space of\nvariations. You are only able to choose an-\nother script . While trying to change unpleas-\nant events in the script within the space of\nvariations, you will be thinking precisely of\nthings that you don’t like. In this very way,\nyour choice is successfully materialized, and\nyou get exactly what you don’t want.\nIt’s not possible to change anything on your\ncurrent life track. Just as if you went to an\nart gallery, you wouldn’t be able to remove or\nrebuild an exhibition that you don’t like.\nYou’re not the one in charge here. But\nnobody is stopping you from turning around\n64/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 787
  },
  {
    "chunk_full": "and walking into another room, to look at\nsomething that you would like better. Of\ncourse, crossing over to another life track,\nwhere everyone gets whatever he or she de-\nmands, doesn’t happen by simply wanting it.\nNot all thoughts can be manifested, and not\nall desires are fulfilled. And that is not be-\ncause of the content of the thoughts, but\nrather because of their nature. Simply to\ndream or to wish for does not yet mean to\nchoose. Dreams don’t come true. It’s neces-\nsary to fulfill certain conditions in order for\nyour dreams to come true. You will find out\nwhat those conditions are and how you fulfill\nthem in this book.\nThere are an infinite number of life tracks,\ndestinies, for each person in the space of\nvariations. We have no reason to resent our\ndestiny because we have been given the right\nto choose. Our only problem is that we don’t\nknow how to do this. The world appears to us\nin its multitude of possibilities, as if it was\n65/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 788
  },
  {
    "chunk_full": "created to satisfy any possible need. Anyone\ncan find everything they ever wanted in this\nworld. Even in different areas of knowledge,\nthe world appears to us just the way we want\nto see it. For example, idealism claims that\nthe world is an illusion, and the world\nagrees. Materialism claims the opposite, and\nthe world again has nothing against that\nopinion. People argue among themselves,\nimposing their opinions on each other, while\nthe world shows that they are all right in\ntheir opinions. Well, isn’t this great?! The\nspace of variations is a so-called illusion,\nwhile the material manifestation is the same\nthing as the “material world.” We always get\nwhat we choose.\nWhoever is acquainted with the principles of\nIslam knows the meaning of the following\nexpression “the fate of a man is recorded in\nThe Book”. Basically, it means that fate is\npredetermined and you can’t run away from\nit. Similar statements can be found in the\n66/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 789
  },
  {
    "chunk_full": "context of other religions. It is true that the\nfate of a man is already predetermined. The\nreligious claims are wrong only in the fact\nthat there is not one variation of a person’s\nfate, but rather an infinite number of vari-\nations. You can’t hide from your destiny. And\nto some degree that’s true, because you can’t\nchange the script of a variation. Fighting the\nworld around you so that you can change\nyour destiny is a very difficult and unreward-\ning task. Don’t try changing the script, it is\npointless. You can simply choose the vari-\nation that you like the most.\nOf course, this is all very strange and raises\ncertain doubts. However, I never thought\nyou’d readily believe in the Model of Vari-\nations. I didn’t believe it either until I was\nconvinced that Transurfing works, and it\ndoes so to one hundred percent. There is no\npoint in favoring a specific model if your only\ngoal is to find some kind of absolute truth.\nThe model itself is of little significance, the\n67/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 790
  },
  {
    "chunk_full": "important thing is the practical result you get\nout of using a particular model. Different\nmathematical models are able to represent\nthe same physical phenomenon in different\nways. Wouldn’t it be funny if experts in ana-\nlytical geometry suddenly took up arms\nagainst mathematical analysis and started\narguing that geometry is the only true math-\nematical\ndiscipline?\nMathematicians\ncan\ncome to some sort of agreement amongst\nthemselves, but philosophers and religious\nfigures? Never.\nWhere is it located, this space of variations?\nIt’s very difficult to answer this question.\nGiven our three-dimensional perception, we\ncould say that the space of variations is\neverywhere and nowhere at the same time.\nImagine an infinite plane that does not have\na beginning or an end, and on that plane live\ntiny two-dimensional people. They don’t\neven suspect that there is such a thing as a\nthird dimension. It seems to them that this\n68/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 791
  },
  {
    "chunk_full": "flat plane is the world and they cannot un-\nderstand how anything could ever exist bey-\nond its boundaries. Yet, nevertheless, we\nknow that we need only to add a third di-\nmension to this world model, and suddenly\nan infinite number of such flat planes can be\ncreated. So, don’t worry about the fact that\nwe are not able to imagine in great detail\nhow an infinite number of worlds can co-ex-\nist with our own.\nIt’s hard to believe that parallel worlds actu-\nally exist. But on the other hand, is it easy for\nyou to believe in the theory of relativity,\nwhich claims that an accelerating body in-\ncreases its mass, reduces its size and slows\ndown the passage of time through which the\nbody moves? It is yet impossible to test this\nclaim first hand. The important thing is not\nwhether we understand the theory or not,\nbut the practical use that can be gained from\nthis theory.\n69/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 792
  },
  {
    "chunk_full": "It is rather absurd and trivial to argue about\nthe advantages of a given model in infinite\nspace. Try to picture the infinity of increas-\ning distances, like outer space for instance.\nThere, far off in the distance, are no bound-\naries. The infinity of decreasing distances,\nstrange as it may sound, has no limits as\nwell. We can only observe a limited part of\nthe visible Universe. Both the telescope and\nthe microscope have their limitations. Infin-\nity on a micro-level is not any different from\ninfinity on a macro-level.\nThere is a theory that the visible universe\nwas created because of “The Big Bang.” And\never since, according to the theory, the uni-\nverse is constantly expanding in all direc-\ntions. Bodies move through the cosmos at\ngreat speeds. But if we would change our\npoint of view and take into account the\nenormous distances involved in the process,\nit would seem to us that this expansion is\n70/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 793
  },
  {
    "chunk_full": "happening very slowly and over an extremely\nlong period of time.\nIt’s also a known fact that in a vacuum space,\nat any given moment in time, elementary\nparticles appear out of nowhere and disap-\npear just as suddenly as they appeared. Con-\nsidering the relativity of space and time, we\nare able to consider each particle as a separ-\nate Universe, similar to our own. After all, we\ndon’t know anything about how elementary\nparticles are being made. According to physi-\ncists, elementary particles can sometimes ap-\npear as waves and sometimes as particles. By\nmoving further into the micro-world, the rel-\native distances become similar to those in\nouter space, and the passage of time for the\ninner observer slows down once again. To an\nexternal observer, our Universe exists for\none moment only, just like a particle that is\nborn and extinguished into emptiness within\nseconds, whereas to us, the inner observers,\nour Universe has existed for billions of years.\n71/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 794
  },
  {
    "chunk_full": "When you are having your next sip of coffee,\nthink about this: how many Universes have\nyou just swallowed? You’ve just swallowed\nan infinite number of universes, because in-\nfinity cannot be divided into parts. It’s as far\nand takes just as much time to “fly” into the\nmicro-world, as it would if you were to fly to\nthe endless expanses of outer space. Time,\nlike space, is infinite. This goes for time that\nruns forward and for time that runs back-\nward. Fragments of time can be as infinitely\ntiny, as they can be infinitely huge. Any point\non a time fragment can be considered a point\nof origin, on both sides of which lies infinite\ntime. Moving the point of origin along the\nfragment of time won’t change anything that\nis ahead or behind that point.\nThis infinity of worlds within worlds exists\nsimultaneously. The center of the universe is\nlocated at any given point at any given mo-\nment, because the very same infinity sur-\nrounds each point from every possible side.\n72/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 795
  },
  {
    "chunk_full": "And all possible events exist simultaneously\nfor the very same reason the center of the\nuniverse is located at any given point. This is\ndifficult to imagine. But then again, it is im-\npossible to take one look at the universe and\nsee it all. No matter how far you imagine\nyourself moving in the universe, the same in-\nfinite space will surround you. There are, of\ncourse, even more confusing theories about\nthe structure of our universe, according to\nwhich our visible universe is transformed in-\nto a finite sphere in fourdimensional space.\nBut this doesn’t make things easier, because\nonce again there can be an infinite number\nof dimensions. Not being able to imagine all\nof this, we are forced to be satisfied with our\nown narrow point of view, pretending that\nwe understand something.\nOverall, there are many incomprehensible\nand inconceivable things in modern science,\nbut this doesn’t stop us from using the fruits\nthat science has reaped. Using the principles\n73/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 796
  },
  {
    "chunk_full": "of Transurfing, you will get astonishing res-\nults. Just let’s agree that you won’t be tor-\nmenting yourself with questions about ex-\nactly why and how Transurfing works. It\nwould be as if a child asks a physicist, “Why\nare bodies drawn towards each other?” The\nphysicist would answer, “Because of the law\nof gravity.” But then the child would ask an-\nother question “Why does the law of gravity\nexist? But how come physical bodies are\ndrawn towards each other?” There are no an-\nswers to these questions. So let’s leave this\nfruitless task of trying to explain something,\nand let’s just use the outcome of the model of\nvariations. It’s clearly beyond us to know and\nunderstand everything.\nBased on the model of variations, man cre-\nates his own destiny. And nonetheless, the\nidea of destiny in Transurfing differs from\nthe generally accepted view. So what is the\ndifference then? The difference is that you\ncan choose your own happiness, without\n74/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 797
  },
  {
    "chunk_full": "having to fight for it. Don’t rush to either ac-\ncepting or rejecting the model of variations\nonce and for all. Just ask yourself this ques-\ntion: have you achieved much by fighting the\nworld for your own happiness? Everyone has\nto decide for himself, whether to continue\nacting in the same way or try a different ap-\nproach. After all, you can spend your whole\nlife fighting and struggling and get absolutely\nnowhere. Wouldn’t it be easier if the world\ncame to you on its own? After all, all it ever\ndoes is manifesting your choices.\nWhatever order you’ll choose to place, it will\nalways be delivered to you, no matter what.\nBut making a choice is not the same as wish-\ning something, it is something quite differ-\nent, and you are about to discover what it is.\nWishes are granted only in fairy tales. It’s no\ncoincidence there is a strong belief that ful-\nfilling wishes is either extremely difficult or\nimpossible. As of yet, we’ve only taken the\nfirst\nstep\ntowards\nthe\nsolution\nof\nthe\n75/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 798
  },
  {
    "chunk_full": "Overseer’s Riddle. Soon, you’ll find out why\nwishes are never granted and dreams never\ncome true.\nSummary\nReality can be manifested in an infinite\nnumber of ways.\nThe diversity of variations is the foremost\nand fundamental quality of our world.\nAny world model represents but a fraction\nof the multiple ways in which reality can\nappear.\nAny branch of knowledge is based on a\nchosen aspect of the manifested reality.\nYour choice is always made into reality.\nWhat you choose is what you get.\n76/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 799
  },
  {
    "chunk_full": "The space of variations is an information\nfield of what was, what is, and what will be.\nThe information field contains potential\nvariations for any event.\nA\nvariation\nconsists\nof\na\nscript\nand\ndecorations.\nThe space of variations can be divided into\nsectors, each of which contains its own\nvariation.\nThe larger the distance between sectors, the\ngreater the difference in variations.\nSectors with roughly similar parameters\nalign themselves to form one specific life\ntrack.\nMaterial realization moves in space like a\ndense mass.\n77/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 800
  },
  {
    "chunk_full": "Waves of thought energy materialize poten-\ntial variations.\nEach organism makes its own contribution\nto the formation of material realizations.\nWhen the parameters of thought energy\nchange, an organism moves to another life\ntrack.\nYou can’t change the script of a variation,\nbut you are able to choose another one.\nDon’t fight for happiness – you can simply\nchoose a variation that you like.\n78/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 801
  },
  {
    "chunk_full": "CHAPTER II\nPENDULUMS\nGroups of people thinking in the\nsame direction create information\nbased energy structures called pen-\ndulums. These structures will even-\ntually begin to develop independ-\nently. Pendulums create their own\nlaws and make people obey them.\nWhat people don’t realize is that\nthey are unwillingly acting in the\ninterests of these pendulums. How\ndo we get out of the suggestion that\nsticks to us like glue?\nRent yourself out.\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 802
  },
  {
    "chunk_full": "Destructive Pendulums\nEver since we were kids we’ve been taught to\nsubmit ourselves to someone else’s will: per-\nforming our duties, serving our country, our\nfamilies, the political party, the company we\nwork in, the government and even serving\nideas…We’ve been taught to submit to every-\none else’s will, as long as our own will had\nthe lowest priority. Everybody has more or\nless a sense of obligation, responsibility, ne-\ncessity and guilt. Everybody in one way or\nanother “serves” in various groups and or-\nganizations like one’s family, society, educa-\ntional institutions, one’s working place, one’s\npolitical party, and the government and so\non. All these structures are born and start to\ndevelop, when a separate group of people\nstarts thinking and acting in the same way.\nThen, new people join the organization/\ngroup\nand\nthe\nstructure\ngrows,\ngaining\nstrength,\nforcing\nits\nmembers\nto\nfollow\n80/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 803
  },
  {
    "chunk_full": "established rules until it reaches a point,\nwhere the structure is able to subjugate large\nsocial groups to its will.\nOn the level of material realization, energy\nstructures consist of people (united by com-\nmon goals) and material objects such as\nbuildings, constructions, furniture, equip-\nment, technology and so on. But what is the\nprocess that enables structures, such as\nthose mentioned above, to be formed? A\nstructure is created when thoughts of a\ngroup of people are focused in one direction.\nThus, the parameters of their thought energy\nbecome identical. Thought energy of inde-\npendent individuals merges into one flow.\nHence, in the middle of the energy ocean, an\nindependent\ninformation\nbased\nenergy\nstructure is created that is called the energy\npendulum. This structure starts living its\nown life, and makes those that took part in\nits creation obey its laws.\n81/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 804
  },
  {
    "chunk_full": "But why are these structures called pendu-\nlums? Because the higher and faster a pen-\ndulum swings, the more people – adherents\n– feed it with their energy. Every pendulum\nhas its own characteristic frequency of vibra-\ntions. For example, you can make the swings\ngo high up in the air only by applying a force\nof a certain frequency. That type of fre-\nquency is called resonance. If the number of\na pendulum’s adherents decrease, the pen-\ndulum’s swinging will slow down and even-\ntually its swinging motion will be extin-\nguished. When there are no more adherents\nto swing the pendulum, it will stop and as an\nentity, it will die. Here are several examples\nof “dead” pendulums: ancient pagan reli-\ngions, stone tools and ancient forms of\nweaponry, old fashion trends and vinyl re-\ncords – in other words, everything that exis-\nted before and is no longer in use.\nYou’re probably surprised – can all these\nthings\nreally\nbe\npendulums?\nYes,\nany\n82/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 805
  },
  {
    "chunk_full": "structure, whose particular features were\nshaped by people’s thought energy, is a pen-\ndulum. You could say that in general all liv-\ning beings that are able to radiate energy in\none direction will eventually form an energy\npendulum. Here are examples of pendulums\nthat exist in nature and wildlife: colonies of\nbacteria,\npopulations\nof living\ncreatures,\nschools of fish, herds of animals, woodlands,\nprairies, ant colonies and so on. Any struc-\ntures consisting of living organisms that are\nof a relatively homogenous and well-ordered\nnature can form pendulums.\nAnd since every living organism represents\nan energy unit, it can also be considered a\npendulum. So, when these pendulum units\ngroup together and start swinging in unison\nthey create a group pendulum. It stands over\nits adherents like a separate and independ-\nent superstructure. It will make up rules for\nits adherents, in order to keep them together\nbut also to attract new ones. Such a structure\n83/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 806
  },
  {
    "chunk_full": "is self-governing in the sense that it develops\nindependently, according to its own laws. Its\nadherents don’t know that they are acting by\nthe laws of the pendulum, and not of their\nfree will. For example, a bureaucratic appar-\natus develops as a self-governing structure,\nindependent of the will of its separate offi-\ncials. Influential officials could, of course,\nmake certain independent decisions, but\nthese decisions cannot be in conflict with the\nlaws of the system. Otherwise, such an ad-\nvocate would be rejected. Even a single per-\nson, who is already a pendulum by himself,\nisn’t always aware of his own motivations.\nOne example of such a person is the energy\nvampire.\nAny pendulum is destructive by its nature.\nThis is because it takes energy from its ad-\nherents and establishes power over them.\nThe destructiveness of a pendulum is evident\nin the fact that it doesn’t care about the fate\nof its individual adherents. The pendulum\n84/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 807
  },
  {
    "chunk_full": "has only one goal – to maintain a constant\nflow of energy from its individual adherents,\nand whether this will benefit or harm an in-\ndividual adherent is of no concern to the\npendulum. If a person is under the influence\nof a system, he has to live his life in accord-\nance with the system’s laws. Otherwise, the\nsystem will chew him up and spit him out.\nBeing under the influence of a destructive\npendulum can easily ruin one’s life. To break\nfree from the pendulum and not suffer any\nlosses as a result is usually a very difficult\nthing to do.\nIf a person is lucky, he will find his own place\nin the system, where he will feel like a fish in\nthe water. Being an adherent, the person\ngives his energy to the pendulum, and the\npendulum, in return, provides him with an\nenvironment where this person is able to\nlive. But as soon as an adherent starts break-\ning the rules of a given structure, the fre-\nquency of his thought energy is no longer in\n85/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 808
  },
  {
    "chunk_full": "sync with the resonance frequency of the\npendulum. The pendulum is no longer get-\nting any energy from this adherent. This res-\nults in the pigheaded adherent being thrown\nout of the system or even destroyed.\nIf a person is brought to a place that is far\naway from his most favorable tracks, then\nlife in the structure of an alien pendulum\nturns into a living hell or simply into a de-\npressing and boring existence. Such a pendu-\nlum is nothing but destructive to the adher-\nent, and the person falling under its influ-\nence loses his freedom. He has to live by the\nlaws forced upon him and serve as a cog in a\nhuge machine whether he likes it or not.\nYet, a man can be under the patronage of a\npendulum and achieve outstanding results.\nNapoleon, Hitler, Stalin and other similar\nfigures were all favorites of destructive pen-\ndulums. Nonetheless, the pendulum doesn’t\ncare about the welfare of its adherents, and it\n86/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 809
  },
  {
    "chunk_full": "uses them solely for its own purposes. When\nNapoleon was asked if he had ever been truly\nhappy, he was able to number only a few\ndays out of his entire life.\nPendulums use refined methods to attract\nnew adherents that fly to them, like moths to\na flame. How often do people, seduced by a\npendulum’s advertising tricks, wander away\nfrom their happiness that was all the time\nright in front of them! People join the army\nand perish there. People enroll in education-\nal institutions and, in vain, master profes-\nsions that are not really theirs. People find\njobs that feel alien, but that are supposedly\nprestigious. They work and find themselves\nswamped\nwith\nproblems.\nThey\nbring\nstrangers\ninto\ntheir\nlives\nand\nend\nup\nsuffering.\nSo, a pendulum’s activity very often leads to\nthe destruction of destinies of its individual\nadherents. Although, the pendulum is trying\n87/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 810
  },
  {
    "chunk_full": "to hide its true motives, pretending to be vir-\ntuous and goodhearted. The most dangerous\nthing for a person who has fallen under the\ninfluence of a destructive pendulum is the\nfact that the pendulum takes its victim away\nfrom those life tracks where he would find\ntrue happiness. Let’s outline the defining\ncharacteristics of a pendulum:\nA pendulum feeds on the energy of\nits adherents and thereby amplifies\nits swinging.\nA pendulum tries to attract as many\nsupporters as possible, so that it can\nreceive as much energy as possible.\nA pendulum sets its group of adher-\nents against all other groups (Look\nat us! We are better than they are).\nA pendulum is aggressive in blaming\nall those that don’t want to become\n88/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 811
  },
  {
    "chunk_full": "its adherents, and it tries to win\nthem over, neutralize them or re-\nmove them all together.\nA pendulum puts on good-looking\nand attractive masks, it covers itself\nup with noble aims and plays on\npeople’s emotions, in order to justify\nits own actions and win over as\nmany adherents as possible.\nOne\ncould\nsay\nthat\na\npendulum\nis\nan\n“egregor”3 by nature, but that is a rather nar-\nrow definition, of course. The concept of an\n“egregor” does not reflect the entire spec-\ntrum of possible interactions between man\nand energy based information structures -\npendulums. Pendulums play a much greater\nrole in people’s lives than it is customary to\nbelieve.\nIt is possible to illustrate how a pendulum\nconsumes energy from its adherents by using\n89/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 812
  },
  {
    "chunk_full": "the following example. Imagine a full stadi-\num, where a dramatic game of soccer is tak-\ning place, things are getting tense, fans are\nraging... Suddenly, one player makes an un-\nforgivable mistake and because of that his\nteam loses the game. A storm of anger des-\ncends from the fans upon the player - they’re\nready to tear him apart. Can you imagine\nwhat a huge mass of negative energy lands\non the head of this unfortunate player? You’d\nthink that having suffered such a monstrous\nblow, he would die right there on the spot.\nBut that doesn’t happen. Instead, he’s alive\nand healthy, although somewhat crushed by\nfeelings of guilt. Then where did all the neg-\native energy go? Well, the pendulum harves-\nted it. If it had not done so, the person at\nwhom the crowd aimed its anger would have\ndied, while the glorified star would have flied\nup to the sky.\nI won’t be the judge of whether the pendu-\nlum is an animated being or simply an\n90/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 813
  },
  {
    "chunk_full": "energy form. Whatever the case, it is of no\nimportance to the Transurfing method. The\nimportant thing is to be able to recognize a\npendulum and to avoid participating in its\ngames, unless there is something you can\ngain from such an interaction. It is very easy\nto recognize a destructive pendulum, as it\nhas one defining feature. It is always compet-\ning with other energy structures just like it-\nself, fighting for control over people. A pen-\ndulum has only one goal – to capture as\nmany adherents as possible, in order to get\nas much energy as possible. The more ag-\ngressive a pendulum acts in its fight for ad-\nherents, the more destructive it is, meaning\nthat it poses a threat to the fate of an indi-\nvidual person.\nSomeone might object that there are, after\nall, charitable organizations, societies for\nnature preservation, animal welfare organiz-\nations and others. What is so destructive\nabout them? The fact is that they, no matter\n91/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 814
  },
  {
    "chunk_full": "how you see it, feed on your energy and do\nnot care about somebody else’s happiness or\nwelfare, and this is destructive for you per-\nsonally. They ask you to be merciful to others\nwhile they remain indifferent to your wel-\nfare. If this is okay with you, and you feel\ntruly happy doing charity work, then this\nmight be your calling, and you have found\nyour pendulum. But, please, be honest with\nyourself. Perhaps you are just wearing the\nmask of a charitable giver. Are you actually\ngiving your energy and money away for the\nwelfare of others and doing it with all your\nheart, or are you just putting on a charity\nshow, so that you will seem like a better\nperson?\nDestructive pendulums have taught people\nnot to choose their own destiny. After all, if a\nperson was truly free in his choice he would\nbe independent. Then he wouldn’t be attrac-\nted to pendulums and wouldn’t become one\nof their adherents. Our mind is so used to the\n92/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 815
  },
  {
    "chunk_full": "idea that our fate is our lot in life, making it\nvery hard for us to believe that it is possible\nto choose the fate that we would like to have.\nIt is very advantageous for pendulums to\nkeep their adherents under control. There-\nfore, they come up with all sorts of ways to\nmanipulate their adherents. The following\npassages give clear examples of how this is\ndone.\nIf you make a cult, movement or a school out\nof Transurfing it could also become a pendu-\nlum. Different pendulums vary, of course, in\ntheir degree of destructiveness. Transurfing,\neven in a worst-case scenario would be much\nless destructive than its counterparts would.\nThis is because it does not serve some ex-\nternal and general goal, but rather it exists\nexclusively for the good of every single indi-\nvidual. Therefore, such a pendulum would be\nvery unusual, kind of like an individualist so-\nciety with people who are busy focusing ex-\nclusively on their own individual destinies.\n93/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 816
  },
  {
    "chunk_full": "By the way, here is a homework assignment\nfor you: what pendulums could be called\nconstructive?\nBut why on Earth am I telling you all of this?\nI am doing this because I have to explain to\nyou what it means to choose your fate and\nhow to actually do that. Have patience, dear\nReader, some of the things we’ve been talk-\ning about are not that easy to get your head\naround, but gradually a clear picture will\nemerge.\nThe\nBattle\nof\nthe\nPendulums\nThe main defining feature of a destructive\npendulum is that it aggressively seeks to des-\ntroy other pendulums, so that it can drag\npeople over to its side. To accomplish this,\nthe pendulum will always try to set its adher-\nents against adherents of other pendulums:\n94/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 817
  },
  {
    "chunk_full": "“We are good, while they are not like us!\nThey are bad!” People who are drawn into\nthis battle lose their way and start following\nfalse goals, which they mistakenly believe to\nbe their own. This is how the destructiveness\nof pendulums becomes apparent. Fighting\nother adherents is fruitless and ruins lives,\nthose of people you “fight” and your own.\nLet’s take an extreme example of the battle\nfor adherents – war. In order to convince its\nown adherents to go to war, the pendulum\nwill put forward arguments that correspond\nto the specific historical era. The most prim-\nitive method, often used in history, was to\nsimply order people to get back what was\n“rightfully” theirs by force. As societies be-\ncame more civilized, arguments acquired\nforms that were more refined. One nation\ndeclares itself the most progressive and de-\nveloped, while others are declared to be\nbackwards. A noble aim is then to bring\nthese undeveloped people to a higher level,\n95/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 818
  },
  {
    "chunk_full": "and if they object - apply force. And modern\nconceptions of war appear to go along the\nfollowing lines: a beehive hangs on a tree in\nthe forest. Wild bees live there, producing\nhoney and raising their young. But then a\npendulum approaches the hive, and an-\nnounces to its own adherents: “These are\nwild bees, they are very dangerous and there-\nfore they must be destroyed or, at least, we\nhave to destroy their hive. You don’t believe\nme?\nJust\nwatch!”\nThe\npendulum\npokes\naround inside the hive with a stick. The bees\nfly out and start stinging the pendulum’s ad-\nherents. And the pendulum triumphantly ex-\nclaims: “See, I told you so! Look how ag-\ngressive\nthey\nare!\nThey\nhave\nto\nbe\ndestroyed.”\nIt does not matter what kind of slogans are\nused to justify wars and revolutions, their\npurpose is always the same – to serve in the\nbattle of pendulums for adherents. These\nbattles can take on different forms, but their\n96/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 819
  },
  {
    "chunk_full": "sole goal is basically to get as many adher-\nents as possible. New energy is a vital neces-\nsity for the pendulum. Without it, the pendu-\nlum will stop, and thus cease to exist as an\nentity. Therefore, the battle of the pendu-\nlums is a natural and unavoidable battle for\ntheir existence.\nRight after wars and revolutions follow other\nforms of battle that may be less aggressive\nbut which are severe nonetheless. Examples\nof such battles are: the struggle for market\ndomination, the rivalry of political parties,\neconomic competition, all possible forms of\nmarketing, advertising campaigns, ideologic-\nal propaganda and so on. The living environ-\nment is made out of pendulums. Therefore,\nyou will find competition in every possible\ndomain of modern living. There is competi-\ntion everywhere, on all possible levels, start-\ning with political and governmental disputes\nand ending with competition between clubs\nand among single individuals.\n97/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 820
  },
  {
    "chunk_full": "The new, the unusual, the incomprehensible\nalways paves its way with difficulty. Why is\nthat? Is it simply because new concepts take\ntime to settle in our head? The main reason\nis that the old pendulums would be at a loss\nif a new pendulum and another rival would\nenter the stage and start dragging people to-\nwards him. For instance, internal combus-\ntion engines make a significant contribution\nto pollution in the cities and they could have\nbeen replaced a long time ago. After all,\nmany alternative and pollution-free engines\nhave been developed throughout the years,\nand should be used instead. However, this\nwould be a threat to the existing pendulums\nof oil corporations, and these are still very\nstrong. Therefore, they won’t allow some in-\nventors to take them off the stage. So, it\ncomes down to that these monstrous pendu-\nlums, which represent large oil corporations,\nare literally buying up patents of alternative\nengines only to keep them secret. At the\n98/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 821
  },
  {
    "chunk_full": "same time, they are trying to convince the\nworld of the low efficiency of these new\ninventions.\nWhen building their structure on the materi-\nal plane, pendulums strengthen their posi-\ntion with financial means, buildings, equip-\nment, and, of course, with human resources.\nAt the top of these human pyramids, pendu-\nlums place their favorites. These are leaders\nof all ranks and functions, anyone from juni-\nor managers to presidents of governments.\nThey do not have to possess any special or\noutstanding qualities at all. Usually, those\nadherents are made leaders whose combina-\ntion of traits fits perfectly within the pendu-\nlum’s structure. The chosen favorite may be-\nlieve that he has achieved great things in life\nonly because of his personal qualities. It is\ntrue, but only to a certain degree. The self-\norganizing structure of the pendulum plays\nthe greatest role in promoting its favorites. If\nthe parameters or traits of the favorite no\n99/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 822
  },
  {
    "chunk_full": "longer correspond to the needs of the sys-\ntem, then the favorite will be removed with\nno regard for his welfare.\nThe battle of the pendulums is destructive\nfor their adherents, because as they are\nserving a higher goal they think that they are\ndoing it because they really believe in it. Per-\nsonal beliefs of adherents tend to be in the\ntight grip of a pendulum. As soon as a person\ntunes into the pendulum’s frequency, an in-\nteraction takes place on the energy level\nbetween him and the pendulum. The fre-\nquency of an adherent’s thought energy is\nfixed and maintained by the pendulum’s own\nenergy. The person is now trapped in a feed-\nback loop. The adherent transmits thought\nenergy on the pendulum’s frequency, while\nthe pendulum in turn grants a little bit of en-\nergy to the adherent, as to maintain the pen-\ndulum’s influence over the person.\n100/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 823
  },
  {
    "chunk_full": "On the level of material realization, such\npendulum-adherent interactions can be seen\nin everyday life situations. For example, the\npendulum of a political party starts an elec-\ntion campaign, catches on to an adherent\nand feeds him with a little energy delivered\nin the shape of good feelings such as appreci-\nation, satisfaction, dignity and importance.\nThe adherent believes that he has the situ-\nation under control and that he can make his\nown choices. But, as a matter of fact, he was\nchosen by the pendulum that now has con-\ntrol over him. On the surface, however, this\nsituation has a different appearance – the\nadherent believes that he is doing what he\nwants to do. Nevertheless, in this case, the\nadherent’s will has been invisibly and artifi-\ncially forced upon him by the pendulum. The\nadherent is thus placed in the pendulum’s in-\nformation field, where he is spending time\nwith others like him, discussing “hot” topics\nand\nso\non.\nIn\nthat\nway\nthe\nadherent\n101/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 824
  },
  {
    "chunk_full": "establishes energy connections with the pen-\ndulum and fixes his own energy within the\nstructure. Eventually, the adherent may real-\nize that the pendulum’s activity does not live\nup to his expectations, so he starts to resent\nor doubt his former idol and thus, his fre-\nquency slips out of the pendulum’s grip. The\ntightness of the pendulum’s grip depends on\nhow powerful the pendulum is. In some\ncases, the pendulum will simply allow its ad-\nherent to leave, while in other cases, such a\nheretic will be deprived of his freedom or\neven his life.\nHow a pendulum traps the frequency of its\nadherents can be illustrated by the following\nexample. Say, you’re singing to yourself.\nThen all of the sudden, somebody starts\nplaying a different song on high volume. So,\nas you are hearing this new melody, it will be\nvery difficult for you to continue singing your\nsong to yourself.\n102/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 825
  },
  {
    "chunk_full": "For the purposes of Transurfing, the specific\ndetails\nbehind\nthe\ninteraction\nprocess\nbetween a pendulum and his adherent are\nnot important. We’ll investigate this interac-\ntion, using a simplified model and everyday\nsituations as examples. This will be quite suf-\nficient for our purposes. Nobody will be able\nto explain to us in great detail and with a\nhigh degree of accuracy how things really\nhappen, because then one could ask the\nquestion: and what does really actually\nmean? And this discussion could go on\nforever, just like the infinite process of ac-\nquiring knowledge. It’s an unrewarding task\nall together. So, we will have to settle for\nsomething smaller. We should be happy that\nwe are nonetheless capable of understanding\nat least something. Now, let’s see how pen-\ndulums manipulate their adherents.\n103/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 826
  },
  {
    "chunk_full": "Puppet Strings\nLet’s ask ourselves a question: how can pen-\ndulums force their adherents to freely give\nup their energy? Big and powerful pendu-\nlums can, for example, force their adherents\nto act according to specific rules. But how do\nweaker pendulums do it? When a person\ndoesn’t have the power to force another to do\nsomething, he presents valid argument and\ntries to convince and persuade the other per-\nson by promising a desirable outcome. These\nare all rather weak methods of persuasion\nthat can only be found in a human society,\nwhere people are removed from the forces of\nnature. Pendulums also use these methods\nsometimes, but they have a weapon that is\nmuch more powerful than that. Pendulums\nare energy based information structures.\nTherefore, they obey the powerful and indis-\nputable laws of existence and act in accord-\nance with these.\n104/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 827
  },
  {
    "chunk_full": "In order for a person to give away his energy\nto a pendulum, his thought energy must be\nof the same frequency as the pendulum’s res-\nonance frequency. For this to happen, it’s not\nnecessary for a person to consciously direct\nhis thoughts towards the pendulum. As you\nprobably know, a great deal of what people\nthink and do happens unconsciously. And\nthis particular property of the human mind\nis what pendulums often take advantage of.\nHence, pendulums manage to get energy not\nonly from their adherents but also from their\nmost enthusiastic opponents. You can prob-\nably guess by now how that works.\nImagine a group of elderly sitting on a park\nbench, complaining and criticizing their gov-\nernment. They are not adherents of the gov-\nernment’s pendulum, because they hate the\ngovernment for many reasons. But what is\nhappening? The elderly are cursing the gov-\nernment, saying how incompetent, corrupt,\ncynical and stupid it is. So, what they are\n105/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 828
  },
  {
    "chunk_full": "actually doing is that they are producing a lot\nof thought energy at the frequency of this\npendulum. To be honest, the pendulum\ncould not care less from which side you push\nit to make it swing. Both positive and negat-\nive energy will do, as long as the frequency of\na person’s thought energy is resonant with\nthe pendulum’s frequency.\nThus, a pendulum’s biggest problem is to get\nto people, to hit them where it hurts in\nwhatever way possible, as long as the pendu-\nlum or anything related to it occupies their\nmind. Once the concept of mass media was\ndeveloped, the methods of pendulums have\nbecome increasingly refined. People become\nquite addicted to mass media. Have you no-\nticed how they mostly mention bad things in\nthe news? These programs give rise to strong\nemotions like agitation, fear, irritation, anger\nand envy. It is the journalists’ job to attract\nyour attention. The means of mass media,\nbeing pendulums themselves, are serving\n106/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 829
  },
  {
    "chunk_full": "pendulums that are even more powerful. The\nsupposed purpose is free access to any in-\nformation. The actual purpose is quite differ-\nent – it is to tune in as many people as pos-\nsible\nto\nthe\nfrequencies\nof\nspecific\npendulums.\nOne of a pendulum’s most favorite methods\nof getting access to your energy is to get you\noff balance. If you are off balance, you begin\nto “swing” on the frequency of the pendulum,\nby so doing you will be swinging the pendu-\nlum itself. Let’s suppose that the prices have\ngone up. You don’t like it, so you react in a\nnegative way – you would feel annoyed, and\nyou would probably complain and talk about\nit with your friends. And that would be a per-\nfectly normal reaction. But this is exactly\nwhat the pendulum wants. You are radiating\nnegative energy at the pendulum’s frequency\ninto the world. The pendulum will harvest\nthis energy, which will only make the pendu-\nlum swing higher, resulting in the situation\n107/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 830
  },
  {
    "chunk_full": "with the prices getting increasingly worse in\nthe real world.\nAt this point, the pendulum is controlling\nyou like a puppeteer is controlling its puppet,\nand the firmest string to pull you by is fear,\nthe most ancient and strongest feeling there\nis. It does not really matter what it is you are\nafraid of exactly, but if your fear is somehow\nconnected to an aspect of the pendulum, the\npendulum will get your energy. Anxiety and\nbeing nervous are somewhat weaker threads,\nbut they are nonetheless strong enough to\npull at and get you jumping. These feelings\nare very good at fixating thought energy radi-\nations\non\na\npendulum’s\nfrequency.\nIf\nsomething is bothering you, it would be hard\nfor you to get our mind off it and focus on\nsomething entirely different.\nFeeling guilty would be another very efficient\nway for a pendulum to pump energy out of\nyou. Feelings of guilt are forced on us already\n108/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 831
  },
  {
    "chunk_full": "in our childhood. It’s a very convenient\nmethod of manipulation. “If you’re guilty,\nthen you have to do as I tell you.” It is very\nunpleasant to live with guilt, and therefore\npeople try to get rid of these feelings. But\nhow? You redeem your fault by either ac-\ncepting your punishment or working off your\ndebt. Both alternatives imply submission,\nobedience and a specific way of thinking. The\ncall of duty is a particular form of guilt. To\nhave a duty means that one is obliged to do\nsomething. As a result, “the guilty”, both the\ntrue ones and the ones that are made to be-\nlieve that they are guilty, are walking around\nwith their heads hanging, bringing the pen-\ndulums their energy on a plate. Inducing\nfeelings of guilt by suggestion is the most fa-\nvorite weapon of manipulators, and we shall\nreturn to it at a later point in this book.\nAll possible human psychological complexes\nshould be noted in particular. The inferiority\ncomplex: I am not attractive, I don’t have\n109/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 832
  },
  {
    "chunk_full": "any abilities or talents, I am not particularly\nbright or clever, I don’t know how to com-\nmunicate with people or how to be around\nthem, I’m not worthy etc. The complex of\nguilt: I’m guilty of something, everyone is\njudging me and I have to bear my cross. The\nwarrior complex: I have to be cool, I declare\nwar on myself and on everybody else, I will\nfight for my place under the sun, I will take\nwhat is mine by force. The truth-lover com-\nplex: I will show that I am right and everyone\nelse is wrong, whatever it takes. These and\nother complexes are personal keys to the en-\nergy of separate individuals. A pendulum, by\nhitting on a vulnerable spot, is zealously\npumping the energy out of this person.\nYou can continue naming the strings by\nwhich the pendulums control their puppets:\njustice,\npride,\nvanity,\nhonor,\nlove,\nhate,\ngreed, generosity, curiosity, interest, hunger,\nas well as other feelings and needs. Your feel-\nings and interest allow the flow of thoughts\n110/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 833
  },
  {
    "chunk_full": "to be fixed in one direction. If a particular\nsubject doesn’t provoke any interest or emo-\ntion, then it’s very hard to focus on it. There-\nfore, pendulums are able to capture the flow\nof thoughts by pressing the right buttons like\nthe particular feelings and needs of a specific\nperson.\nAs a rule, people have a standard way of re-\nacting to negative external sources of irrita-\ntion. Negative news provokes discontent,\nalarming news provokes a reaction of worry\nor fear, having been offended provokes dis-\nlike and so on. Habits function as the switch\nthat sets the mechanism of capture in mo-\ntion. For example, the habit of getting irrit-\nated or worried with little cause is the same\nas reacting to a provocation. Basically, it is\nthe same as reacting negatively to a negative\nsource of irritation. A person could be aware\nof the fact that negative thoughts and actions\nwon’t lead to anything good, however he\n111/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 834
  },
  {
    "chunk_full": "would still make the same mistakes out of\nhabit.\nIn this way, habits often create problems and\nforce us to act inefficiently, and yet they are\ndifficult to get rid of. Habits are illusions of\ncomfort. One has more trust in what is famil-\niar. Anything new causes worry and fear. The\nold and familiar has already been proven to\nwork through experience. It is like an old\narmchair, in which you sit down to relax\nafter work. Maybe a new one would be bet-\nter, but the old one is more comfortable.\nComfort is characterized by such concepts as\nconvenience, trust, positive experience and\npredictability.\nNew\nthings\npossess\nthese\nqualities to a much lower degree, thus it\ntakes a lot of time for a new habit to turn into\nan old one.\nSo, we’ve looked at the methods of influence\nthat pendulums use on people. Can a man\nescape from the influence of a pendulum?\n112/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 835
  },
  {
    "chunk_full": "We’ll be talking about methods of escape fur-\nther on. Still, it often happens that someone\nstands up to the pendulum that has enslaved\nhim and openly opposes it. In any battle\nbetween a man and a pendulum, the man\nwill always suffer a defeat. A pendulum can\nonly be defeated by other pendulums. One\nman can’t do anything. If a man is no longer\nobeying the pendulum and he gets into a\nfight with it, he will only lose energy. In the\nbest case, the man will be thrown out of the\nsystem, while in the worst case – he will be\ncrushed. An adherent that had the guts to\nbreak the rules set by the pendulum, will be\nproclaimed an outlaw. On the surface of the\nreal world, the man will be convicted or con-\ndemned for his actions. In reality, it is not\nthe man’s action that makes him guilty, but\nrather the fact that he has gone out of control\nand is no longer a source of energy for the\npendulum.\n113/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 836
  },
  {
    "chunk_full": "Why is it that “a fault confessed is half re-\ndressed”? Because the man who accepts the\nfeeling of guilt is completely ready to submit\nhimself to the pendulum’s rule. For the pen-\ndulum, the actual remorse of the adherent\nfor the act committed doesn’t mean any-\nthing. Only the restored control over the ad-\nherent is of any importance. The pendulum\nwill immediately be much nicer to you, if you\ngive it the opportunity to manipulate you.\nAnd if the guilty one does not submit to the\npendulum, then he can be removed, because\nthere is nothing more to gain from him. The\ntrue motives of the pendulum are usually\nveiled by moral principles, saying that a per-\nson that has shown remorse is not such an\nevil person after all. You can easily distin-\nguish whether moral principles are at work\nor the interests of the system have been in-\nfringed upon, if you only keep in mind what\npendulums look like and what their true\ngoals are.\n114/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 837
  },
  {
    "chunk_full": "You\nAlways\nGet\nWhat\nYou Don’t Want\nAs mentioned before, pendulums can get en-\nergy from their adherents as well as from\ntheir opponents. But loss of energy is only\nhalf the trouble. If a pendulum is destructive\nenough, both the adherent’s welfare and fu-\nture fate will get damaged.\nEvery person is from time to time confronted\nwith negative information or undesirable\nevents. All of this is just a provocation of the\npendulums. A man doesn’t want these things\nin his life, but always reacts in one of two\nways. If the information doesn’t affect him\nvery much, he won’t pay much attention to\nit, and will forget about it soon enough. But\nif the provocative information irritates or\nfrightens him, that is there is something very\nrelevant to him in this information, then a\ncapture of thought energy takes place: the\n115/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 838
  },
  {
    "chunk_full": "man is caught in the pendulum’s noose and\nis\ntuned\nto\nthe\npendulum’s\nresonance\nfrequency.\nYou probably know what happens next. The\nman starts feeling angry, he is outraged, wor-\nried, afraid, vigorously expressing his dissat-\nisfaction. Basically, he is actively radiating\nenergy on the frequency of the destructive\npendulum. The pendulum does not harvest\nall of the energy. Some of it goes to particular\nsectors in the space of variations. The para-\nmeters of the man’s thought energy are such\nthat he is transported to the sector in the\nspace of variations where everything he\nwants to avoid exists in abundance. As you\nmight remember, if a man’s thought energy\nis fixed on a certain frequency, he is trans-\nported to the corresponding life track. In this\ncase, the pendulum is destructive to his ad-\nherent, because it is fixating his frequency,\nusing the noose of capture.\n116/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 839
  },
  {
    "chunk_full": "Let’s say that you turn a deaf ear to any in-\nformation regarding catastrophes and natur-\nal disasters. After all, if you are not affected\nby it, why the unnecessary stress? Usually in\nthis case, a natural disaster will happen\nsomewhere else, but you will personally be\non a life track where you are not a victim of a\ndisaster, but an observer. The track, where\nyou would be a victim, is left behind. And the\nopposite is true as well, if you allow informa-\ntion about disasters and unfortunate events\nto affect you, you will moan and talk about it\nwith your friends. In that case, it is very pos-\nsible that you will soon be transferred onto a\nlife track, where you will be a victim of a dis-\naster yourself.\nIt turns out that the stronger your desire to\navoid something, the greater the risk that\nyou will get it. Actively fighting what you do\nnot want is the same as doing your best to\nmake this very thing a part of your life. You\ndon’t even have to do anything special in\n117/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 840
  },
  {
    "chunk_full": "order to transport yourself to the undesirable\nlife tracks. It is quite enough to think negat-\nive thoughts and add emotions to them. For\nexample, you don’t want bad weather, and so\nyou think about how you don’t like the rain.\nNoisy\nneighbors\nare\nbothering\nyou\nand\nyou’re constantly fighting with them or you\nquietly despise them in your heart. You are\nafraid of something and this makes you very\nanxious. You’re sick and tired of your day job\nand so you savor the feeling of hatred to-\nwards your job.\nWhat you actively don’t want, like things\nthat you are afraid of, things that you hate or\ndespise, will follow you everywhere. There\nare, of course, many other things you would\nlike to avoid, but those things don’t bother\nyou as much at the moment. In that case,\nthose things won’t crawl into your life, they\nsimply won’t happen. But as soon as you al-\nlow the undesirable affect, feeling hatred and\nstarting to cherish the negative feeling, the\n118/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 841
  },
  {
    "chunk_full": "unwanted will definitely materialize in your\nlife.\nThe only way to remove the unwanted from\nyour life is in freeing yourself from the influ-\nence of the pendulum that has trapped your\nthought energy. And from now on resist its\nprovocations and not be a part of this game.\nThere are two methods of escaping a pendu-\nlum’s grip: making it fall through or extin-\nguishing it. Let’s look in more detail at how\nthis is done.\nThe\nFall\nThrough\nof\na\nPendulum\nFighting a pendulum is useless. As has been\nmentioned above, fighting it means feeding\nit with your energy. The first and most im-\nportant condition for success is refusal to\nfight with it. First, the more you are trying to\nfight off the annoying things in your life, the\n119/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 842
  },
  {
    "chunk_full": "more actively they will pursue you. You could\nforever keep saying, “Just leave me in peace!\nEveryone, leave me alone!” You think that\nyou are defending yourself against the an-\nnoying pendulums, but you are actually feed-\ning them with your energy and thus, they\nstick to you even more.\nSecond, you don’t have the right to condemn\nor change anything in this world. You have to\naccept everything like you would accept an\nartwork at an exhibition, no matter whether\nyou like it or not. There may be many pic-\ntures at the exhibition that may not seem too\nappealing to you. However, it would never\noccur to you to demand that they would be\ntaken away. Once you’ve recognized the right\nof the pendulum to exist, you have the right\nto leave it alone, to resist falling under its in-\nfluence. But the main thing is to avoid get-\nting into a fight with it – don’t blame it, don’t\nget angry with it, don’t lose your temper, be-\ncause all this would mean your participation\n120/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 843
  },
  {
    "chunk_full": "in the pendulum’s game. Do the exact oppos-\nite,\nquietly\naccept\nthe\npendulum\nas\nsomething given, as an unavoidable evil, and\nthen leave. If you show any aversion, you will\nbe giving your energy to the pendulum.\nBefore exploring what it means to choose, we\nhave to learn how to say no. People, in gen-\neral, have a vague idea of what they want.\nBut everyone knows for sure what they don’t\nwant. Striving to free themselves from un-\ndesirable things or events, many act in such\na way that they get the exact opposite. In or-\nder to say no, it’s necessary to accept. The\nword “accept” in this context does not mean\nthat you should embrace it and make it a\npart of yourself, but rather that you should\nadmit to yourself that everyone has the right\nto exist, and then pass by indifferently. To\naccept and to let go means to let things pass\nthrough you and to wave goodbye to them as\nthey leave. The opposite would be to accept\nthings and to keep them close by, and then to\n121/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 844
  },
  {
    "chunk_full": "become attached to them or try to resist\nthem.\nIf you are being pestered by thoughts about\nthings you dislike, those very things will find\ntheir way into your life. Imagine that some-\nbody doesn’t like apples. He simply hates\nthem, they make him sick. This person could\njust ignore them, but he cannot come to\nterms with the thought that there are such\ndisgusting things as apples in his world.\nThey irritate him every time he lays eyes on\nthem, and he actively talks about his aver-\nsion. This is what happens on the material\nplane. However, on the energy plane, the\nman is greedily pouncing on the apples,\nstuffing his mouth with them, chewing nois-\nily, and trying to scream how much he hates\nthem, he is stuffing his pockets full of apples,\nhe is choking on them and again starts com-\nplaining about how sick he is of them. It does\nnot occur to the man that he can simply\n122/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 845
  },
  {
    "chunk_full": "throw the apples out of his life if he doesn’t\nwant them.\nWhether you love or hate something has no\nmeaning. The main thing is that if your\nthoughts are preoccupied with the object of\nyour feelings, the energy of your thoughts\nwill fix on a certain frequency and you will\nthus, be captured by a pendulum and trans-\nported to a corresponding life track, where\nthe\nloved\nor\nhated\nobject\nexists\nin\nabundance.\nIf you don’t want to have a certain thing in\nyour life, then stop thinking about it, pass\nthis particular thing by indifferently, and it\nwill disappear from your life. To throw\nsomething out from your life does not mean\nyou should avoid it, but simply ignore it. To\navoid something means to allow it passage\ninto your life, but at the same time actively\ntry to free yourself from it. To ignore\nsomething means not to react to it in any\n123/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 846
  },
  {
    "chunk_full": "way and, consequently, not to have it in your\nlife.\nImagine that you are a radio receiver. Every\nday you wake up and listen to a station that\nyou really hate that is the world around you.\nSo,\njust\ntune\nyourself\ninto\na\ndifferent\nfrequency!\nIt can appear that, placing an iron curtain\nbetween you and the world would protect\nyou from undesirable pendulums. This is\nnothing but an illusion. When you are in this\niron shell, you are telling yourself: “I am a\nblank wall. I don’t see anything, I don’t hear\nanything, I don’t know anything and I don’t\nspeak to anyone. There is no access to me.”\nIn order to maintain such a protective field,\nit’s necessary to spend energy and quite a lot\nof it actually. A person that is intentionally\ntrying to shut himself off from the world is\nconstantly on the edge. Besides everything\nelse, the energy of a protective field is tuned\n124/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 847
  },
  {
    "chunk_full": "into the frequency of that pendulum, against\nwhich your protection was built in the first\nplace. And this is exactly what the pendulum\nwants. It does not care at all whether you\ngive him your energy with pleasure or with\nanger, as long as you give it to the pendulum.\nWhat could then serve as protection against\na pendulum? Emptiness. If I am empty, no\npendulum will be able to catch on to me. I\nam not joining the pendulum’s game, but I\nam not trying to defend myself against the\npendulum either. I simply ignore it. The en-\nergy of the pendulum flies past me, without\ntouching me and disappears into space. The\npendulum’s\ngame\ndoesn’t\nbother\nme,\nit\ndoesn’t affect me. In relation to the pendu-\nlum, I am empty.\nThe pendulum’s main objective is to attract\nas many adherents as possible to get their\nenergy. If you ignore a pendulum, it will\nleave you alone and switch over to other\npeople. This is because the pendulum can\n125/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 848
  },
  {
    "chunk_full": "only affect someone that accepts its game, in\nother words, someone who starts radiating\nthought energy on the frequency of the\npendulum.\nLet’s take the most basic example. A barking\ndog is chasing you. If you turn around to face\nit, the dog will bark even louder. If you will\ntake the dog seriously and start to wrangle\nwith it, the dog will continue running after\nyou for quite a while. After all it is the dog’s\naim to find someone to have a row with. But\nif you simply ignore the dog, it will look for\nanother object. And do notice that it will nev-\ner occur to the dog to feel insulted because\nyou wouldn’t pay any attention to it. The dog\nis too absorbed with its goal of getting energy\nthat it can’t possibly think about something\nelse. Now, you could substitute the dog with\na troublemaker, and the given model would\nwork the same way.\n126/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 849
  },
  {
    "chunk_full": "If someone is annoying you, try the model of\na destructive pendulum on him. He’ll prob-\nably be a perfect match. If you cannot quiet\nthe “troublemaker”, then simply refrain from\nreacting to his provocations – ignore him.\nHe won’t leave you alone until you stop giv-\ning him your energy. You can give the energy\ndirectly to him by getting into a fight with\nhim, or indirectly by silently hating him. To\nstop giving away your energy means to stop\nthinking at all about the troublemaker. Just\nthrow him out of your head. Simply tell to\nyourself: “Oh, never mind him!” – and he\nwill be gone from your life.\nHowever, it is often the case that you simply\ncan’t ignore the pendulum. For example, the\nboss calls you on the carpet. Simply refusing,\nor trying to defend yourself would in both\ncases mean a loss of energy, because in both\nsituations you would be fighting the pendu-\nlum. In such cases, you can act as if you are\ntaking part in the pendulum’s game. The\n127/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 850
  },
  {
    "chunk_full": "main thing is to keep in mind that you are\njust pretending to play the pendulum’s game.\nImagine a burly fellow raising his sledge-\nhammer at you and striking a blow. You have\nnothing against it, you are not defending\nyourself and you are not attacking him. In\nthis moment, you simply step aside and the\nbig fellow, along with his sledgehammer, hits\nan empty spot. This means that the pendu-\nlum can’t catch on to you and thus, it falls\nthrough empty space.\nThe same principle lies at the heart of aikido\n– a type of martial arts. The following is what\nliterally happens in aikido: the attacker is\ntaken by the arm and brought along with the\ndefender, as if the defender is casually seeing\nhim off, and then the attacker is released\nwithout any force from the defender, and is\nsent flying in the same direction in which he\nwas aiming in the first place. The whole\nsecret is that the defender has nothing\n128/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 851
  },
  {
    "chunk_full": "against the attack. He agrees with the attack-\ner’s way, walks together with him for a while,\nand then lets go of him. The energy of the at-\ntacker falls through into empty space, be-\ncause if the defender is “empty” there is\nnothing to catch on to.\nSo, what is the technique behind this soft ap-\nproach? Basically, you respond to the pendu-\nlum’s first attack with agreement, and then\nyou diplomatically step aside or unobtrus-\nively direct the pendulum’s movement to\nwhere you want it. For example, your eager\nboss wants to load you with work and de-\nmands, all excited, that you do it exactly the\nway he wants it to be done. You know that it\nneeds to be done differently or you even be-\nlieve that this task is not your responsibility\nin the first place. If you will start objecting,\narguing and defending yourself, your boss\nwill, in the strictest way, ask for your obedi-\nence. After all, he has made a decision, and\nyou’re defying him. Do the exact opposite.\n129/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 852
  },
  {
    "chunk_full": "Listen carefully to what your boss is saying,\nagree with everything he says, let the pendu-\nlum exhaust its first impulse. Then gently\nstart discussing the details of the job with\nhim. At this moment, you have accepted the\nenergy of your boss and radiate at his fre-\nquency. His impulse has not met any opposi-\ntion and will therefore subside for the time\nbeing. Don’t tell him that you know better\nhow this job should be done, don’t say no to\nthe job and don’t argue with him. Just ask\nfor his advice, ask him how you could do the\njob faster and better or how perhaps another\nemployee could do it even better. By doing\nthis, you are swinging along with the pendu-\nlum, but you are doing it consciously, not\nparticipating in its game, but as if observing\nit from the outside. The pendulum swings,\ncompletely absorbed with the game. And it is\nthe pendulum’s game – it is making the de-\ncision, and people agree with it and consult it\nfor\nadvice.\nYou’ll\nsee\nthat\nthe\nenergy,\n130/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 853
  },
  {
    "chunk_full": "previously directed at you, will be turned\naway from you, towards another solution or\ntowards somebody else, who will do the job.\nHence, for you personally, the pendulum will\nfall through.\nExtinguishing\na\nPendulum\nThere can be situations where you cannot\nmake the pendulum fall through. That is, you\ncannot simply ignore or escape it.\nI had a friend once that was this really nice\nand good-hearted guy, but he was also gifted\nwith incredible physical strength. So we were\ngoing on a tram one night, and there was this\ngroup of bullies looking for trouble, – a real\ndestructive pendulum. There was quite a few\nof them, all as one, feeding each other with\nnegative energy and all convinced that they\nare above any law. In order for their energy\n131/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 854
  },
  {
    "chunk_full": "to multiply, they would constantly need to\nbother other people that would react to their\nprovocations\nand\nthus,\ngive\nthem\ntheir\nenergy.\nSo, this angry looking bunch started bother-\ning my friend, probably because the kind and\npeaceful expression on his face suggested he\nwouldn’t be too much trouble. They tried in\nevery way to pick a fight with him, insulting\nand taunting him, but he remained silent\nand didn’t react to any of the provocations –\nin other words, he tried to make the pendu-\nlum fall through. Neither did I interfere, be-\ncause I knew that he had nothing to fear, but\nthe bullies were really out on a limb. Finally,\nmy friend couldn’t stand it any longer, so he\ngot up and headed for the exit, but the most\nimpudent adherent blocked his way. Then\nmy\nfriend,\nwho\nby\nnow\nwas\ncornered,\ngrabbed the punk by the scruff of the neck,\nand delivered a hideous blow to his head.\n132/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 855
  },
  {
    "chunk_full": "The victim’s face was instantly made into a\nbloody mess. The remaining heroes were\ndumbfounded with amazement and fear. My\nfriend turned and grabbed the next one, but\nthat one started mumbling with a trembling\nvoice:\n“Tha-a-t’s\nenough,\nman…..enough…..dooon’t.” The energy of the\npendulum was instantly extinguished, and\nits adherents, still taken aback, were slowly\nmoving backwards, and finally tumbled out\nof the tram.\nOf course, lucky are those that can stand up\nfor themselves. But if you are not one of\nthem, what then? If you have nowhere to\nrun, then you can stop the pendulum by do-\ning\nsomething\nout\nof\nthe\nordinary,\nsomething that no one would expect from\nyou.\nSomebody told me of a case like that. Once, a\npack\nof\n“fearless”\nstreet\ngang\nmembers\ncornered a fellow and were about to beat him\n133/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 856
  },
  {
    "chunk_full": "up. Then he approached the leader of the\ngang, staring at him with an insane look in\nhis eyes, and said, “So what should I break:\nyour nose or your jaw?” A question like that\nwas clearly out of context (it did not fit the\nscript) and the gang leader was for a moment\ntaken aback. Then the fellow cried out with\nunhealthy enthusiasm “Or maybe I’ll just\ntear your ear off!” and grabbed him by the\near with his hand. The leader of the gang\ngave out an agonizing cry. The entire show\nthat the gang was so used to putting on was\nnow ruined. The gang leader was now not\neven thinking about beating somebody up,\nonly one thought was tormenting him – how\nto free his ear from the tight grip of the mad-\nman. The gang let the guy go, as they thought\nhim to be a nutcase, and the guy in return es-\ncaped the bloodshed.\nSo there you go, if you ever find yourself in a\nsituation where you know the usual course of\nevents, do something surprising – no matter\n134/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 857
  },
  {
    "chunk_full": "what – something that does not fit into the\nstandard development of events. The pendu-\nlum will be extinguished. The thing is, as\nlong as you are acting according to a given\nscenario, you accept the pendulum’s game\nand give away your energy on that frequency.\nBut if your frequency is very different from\nthat of a pendulum, you and the pendulum\nwill be in dissonance, and thus, you’ll throw\nit off rhythm.\nAt the same time, you shouldn’t be asking for\ntrouble if you are dealing with a pendulum\nthat has nothing to lose. If you are attacked\nby a person that is trying to rob you, it’s bet-\nter to give him the money right away. Some\npeople even carry a ten-dollar bill for occa-\nsions such as this. For instance, if the robber\nis a drug addict or he is mentally ill, he could\neasily end your life, even if you are a master\nof the martial arts. Therefore, you are much\nbetter off not dealing with people like that at\nall, as you wouldn’t with a rabid dog.\n135/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 858
  },
  {
    "chunk_full": "Otherwise, your death would be unwarran-\nted and absurd.\nHaving a sense of humor and a creative ima-\ngination can be very helpful in extinguishing\na pendulum. Turn your irritation into a\ngame. For example, you are annoyed with\nthe massive amount of people on the street\nor on the bus, and everyone is in a hurry and\nmakes it difficult for you to make your way.\nNow imagine that you are at a bird bazaar in\nAntarctica. All these people around you are\nactually penguins, waddling, fussing and\npottering about in a very funny way. And\nwho would you be? You would be penguin as\nwell. After this transformation, the people\naround you would instill liking and curiosity\nin you, rather than annoyance.\nOf course, it’s hard to control yourself when\nyou are mad with rage. At these moments,\nthe hardest thing of all is to remember that\nthis is only a pendulum trying to draw\n136/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 859
  },
  {
    "chunk_full": "energy from you. Don’t give in to its provoca-\ntions. The pendulum is like a vampire, it uses\nits own form of anesthesia that is your habit\nof reacting negatively to a nuisance. Even\nnow, having read these lines, you could in a\ncouple of minutes get distracted and answer\nan unwanted phone call with an irritated\nvoice. But if you make it your aim to acquire\nthe habit of remembering about the pendu-\nlum, soon enough you will develop immunity\nagainst its provocations.\nNotice that when you come across annoying\nsituations and react to them with irritation,\ndissatisfaction and other negative emotions,\nthe negative situation that provoked these\nemotions will instantly get worse and you are\nin for more trouble. This is how the pendu-\nlum swings higher and higher. And you are\nthe one pushing it. So, do the exact opposite\n– either don’t react at all or react in an inap-\npropriate way. For example, you can meet\nannoyances with false enthusiasm or even\n137/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 860
  },
  {
    "chunk_full": "with moronic delight. This is how you extin-\nguish a pendulum. You’ll see that the pendu-\nlum will not continue its provocations.\nAs you remember, the habit of negatively re-\nacting to annoying situations is the lever that\nsets the pendulum’s capture mechanism in\nmotion, so that the pendulum can get to your\nthought energy. Such a habit will fade away if\nyou play your own game, in which you delib-\nerately make the following substitutions: fear\n– confidence, gloom – enthusiasm, resent-\nment – indifference, irritation – joy. At least\ntry to react “inappropriately” to small nuis-\nances. What do you have to lose? It might be\na ridiculous thing to do, but if you play the\ngame this way the pendulum will not stand a\nchance. This gaming style seems ridiculous\nonly because the pendulums have trained us\nto play the games that are of benefit only to\nthem. Now, try forcing the pendulum to play\nyour game - you will enjoy the game and you\nwill discover to your great surprise what a\n138/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 861
  },
  {
    "chunk_full": "powerful technique it is. The working prin-\nciple is this: radiating thought energy at a\nfrequency different from the resonance fre-\nquency, you get in dissonance with the pen-\ndulum. Thus, for you personally, the pendu-\nlum is extinguished and therefore leaves you\nin peace.\nThere\nis\nanother\ninteresting\nmethod\nof\ngently\nextinguishing\nthe\npendulum.\nIf\nsomeone is bothering you, making a problem\nfor you, try to determine what that person\nneeds. Now imagine this person having what\nhe needs. This could be health, confidence or\npeace of mind. If you think about it, these\nare the three main things that we all need, in\norder to feel satisfaction. So think about,\nwhat does this person really need right now?\nSuppose that your boss shouted at you.\nMaybe he’s tired or he is having problems at\nhome? Then he needs some peace of mind.\nImagine him relaxing in an armchair in front\n139/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 862
  },
  {
    "chunk_full": "of the TV, or by a fireplace, fishing with a rod\non the river, or maybe having a beer with his\nfriends. Do you know what he likes to do?\nPerhaps his bosses have been pushing and\npressing him, and he is afraid of taking on\nmore responsibility? Then he needs some\nconfidence. Imagine him skiing like a pro,\ndriving around in a sports car, or being at a\nparty where he is the centre of attention.\nPerhaps he is ill and in pain? Imagine that he\nis happy and healthy, swimming in the\nocean, riding a bicycle, playing football. Of\ncourse, it’s better to imagine him doing what\nhe likes to do. But you don’t have to guess,\ndon’t worry. It’s quite enough to imagine this\nperson in a situation where he is satisfied.\nSo what is actually happening here? Your\nboss suddenly appears on the scene and has\nonly problems in hold for you. (Instead of\nyour boss, it could be a robber or anyone else\nthat means trouble). Distract yourself from\nwhatever trouble he is bringing you. Thus,\n140/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 863
  },
  {
    "chunk_full": "from the very beginning, you refrain from\nputting your head into the frequency-captur-\ning noose. Now imagine this person getting\nexactly what he needs. (What does a robber\nwant; to eat, to drink or to get high?) Visual-\nize an image where this person gets his satis-\nfaction. If you’re successful, you can consider\nyour troubles gone. After all, the pendulum\ndidn’t simply begin to swing on its own. So-\nmething got it out of balance. The pendulum\nis, consciously or unconsciously, looking for\nsomething that will restore its balance. And\nsuddenly the energy of your thoughts on a\ncertain frequency restores, although indir-\nectly, the pendulum’s balance. It will in-\nstantly substitute its aggression with good-\nwill. What? You find it hard to believe? Go\non and test it!\nSo, basically what happens when you apply\nthe above technique is that you extinguish\nthe pendulum. A pendulum-man approaches\nyou with a problem and you solve the\n141/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 864
  },
  {
    "chunk_full": "problem, not in an obvious way, but on the\nenergy plane. You gave the pendulum your\nenergy, but only a tiny piece of it, in compar-\nison to what you could have lost. In addition,\nyou’ve done a good deed – you’ve helped\nsomeone in need, if only temporarily. The in-\nteresting thing is that this person will later\nhave a different, friendlier attitude towards\nyou. He will never be able to guess why he is\nfeeling comfortable in your company. Let\nthat be your little secret.\nThis technique can be successfully used in\nsituations when you need to get something\nfrom somebody, and that particular person is\nbusy with his own problems and isn’t really\nkeen on giving you whatever it is that you\nwant. You need a signature from the local of-\nficial? First, “feed” him a little of your nice\nvisualization, and he’ll do anything for you.\nJust one last thing; where do you think the\nenergy of a dampened pendulum goes? It is\n142/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 865
  },
  {
    "chunk_full": "actually transporting back to you. Having\novercome your problem, you get stronger.\nAnd the next time something like this hap-\npens it will be very easy for you to find the\nright solution to the problem. Isn’t that the\ncase? But if you try to fight the problem,\nyou’ll be giving your energy to the pendulum\nthat created the problem in the first place.\nThe techniques of making a pendulum fall\nthrough or extinguishing it, are also well-\nknown by both psychologists and psychiat-\nrists as professional methods. So, really\nthese methods are nothing new. However, to\nsomebody who is not acquainted with the\nmethods of practical psychology, these tech-\nniques would be valuable, as they bring clar-\nity and understanding to what psychological\ndefense is and how it works.\n143/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 866
  },
  {
    "chunk_full": "Simple\nSolutions\nto\nComplicated Problems\nIf you were able to extinguish a pendulum or\nmake it fall through, you would as well be\nable to solve all kinds of possible problems.\nThis problem could be a complicated life\nsituation, a conflict, an unfavorable circum-\nstance, a difficulty or simply a task. There are\nsimple solutions to all complicated prob-\nlems. The key to solving a problem is always\nsomewhere on the surface, the only question\nis how to spot it. The pendulum that has cre-\nated the problem for you will get in the way\nof you seeing the key to the problem.\nThe goal of a destructive pendulum is to get\nenergy from you. In order to accomplish this,\nit has to fix the frequency of your radiating\nthoughts on the problem. This is very easy to\ndo, if you are convinced that the problem is\ndifficult. If you accept these rules of the\n144/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 867
  },
  {
    "chunk_full": "game, the pendulum will easily take you by\nthe hand and lead you into an intricate\nlabyrinth. Only later will you realize the an-\nswer was right there in front of you the whole\ntime.\nIf you scare a person, worry him, confuse\nhim or play on his fears, saying how difficult\nthe problem is, then he will easily agree to\nthings being complicated and so he’ll be\nhooked. But you don’t really have to scare\npeople to achieve the same effect. The public\nopinion is already such that many problems\nare considered to be difficult in nature and\nthus, lack simple solutions. Throughout life,\nevery one of us is constantly confronted with\ndifficulties of some kind, especially when it is\nsomething new and unfamiliar. As a result,\neveryone has a strongly rooted habit of fa-\ncing problems with anxiety and sometimes\neven with reverential fear. In addition, one\nalways weighs his abilities to handle a prob-\nlem on the scales of doubt. Consequently, the\n145/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 868
  },
  {
    "chunk_full": "tendency to face problems with fear is trans-\nformed into a puppet string.\nThe pendulum can act either through its ad-\nherents, namely people associated with a\nparticular problem, or it can act through\nnon-living objects as well. The pendulum\nfixes the radiation of thought energy on a\ncertain frequency and is busy sucking the en-\nergy, while the person is preoccupied with\nthe problem. One would think that fixing fre-\nquency on the subject would help concentra-\ntion. How could that possibly interfere with\nsolving the problem?\nThe thing is that the pendulum fixes our\nthoughts on a very narrow sector in the in-\nformational field, while the solution may\nvery well be outside this sector. As a result, a\nperson is thinking and acting within the lim-\nits of the narrow corridor and doesn’t really\nhave the possibility to see the bigger picture.\nUnusual and intuitive solutions appear to\n146/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 869
  },
  {
    "chunk_full": "you precisely when you free yourself from\nthe pendulum and get the freedom to think\nin another direction. The whole secret of be-\ning a genius is being free from the influence\nof the pendulums. While pendulums capture\nthe\nordinary\npeople’s\nfrequencies\nof\nthoughts, geniuses’ frequencies of thoughts\ncan\nreorganize\nthemselves\nindependently\nand may enter unexplored areas of the in-\nformation field.\nThen how should you act in order to avoid\ngetting into the pendulum’s capture noose?\nDon’t get absorbed with the problem and\ndon’t allow the pendulum to ensnare you in\nits game. Rent yourself out. Act as you nor-\nmally would in such situations, but not as a\nparticipant in the game, but rather as an ex-\nternal observer. Try looking at the situation,\nas if it didn’t concern you at all. Remember\nthat the pendulums want to take you by the\nhand and lead you into a labyrinth. Don’t let\nthe problem scare you, grab hold of you,\n147/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 870
  },
  {
    "chunk_full": "worry or confuse you. Just remember that\nthere is a very simple solution to any prob-\nlem. Do not accept the “difficult” interpreta-\ntion imposed on you by the pendulums.\nIf you have been confronted with a problem\nor a tricky situation, catch yourself on your\nattitude towards it. The problem could give\nrise to confusion, fear, resentment, despair\nand so on. You need to change your usual at-\ntitude towards the problem to the exact op-\nposite, and the problem will either disappear\nall by itself or you will quickly find a very\nsimple solution to it. In spite of your stereo-\ntypes and habits, see any problem not as an\nobstacle that you have to overcome, but\nrather as a part of the road you have to walk\non. Don’t leave any space in yourself for the\nproblem. Be empty to the problem.\nIf you have to solve a problem that requires a\ncertain amount of thinking, don’t rush into\nlogical\nreasoning\nright\naway.\nYour\n148/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 871
  },
  {
    "chunk_full": "subconscious is directly linked to the field of\ninformation. The solution to any possible\nproblem is already there. Therefore, you\nshould first relax, and then cast away any\nfear and anxiety that you may have regarding\nthe solution. Because you do know that the\nsolution is out there. Let go of yourself, stop\nthe train of thoughts and try to contemplate\nthe emptiness. It is very likely that the solu-\ntion will come to you instantly, and it will\nprobably be a very simple one. If that didn’t\nwork, don’t get upset and turn on your think-\ning device. It will work the next time. This\nexercise is very useful in developing the abil-\nity to obtain intuitive knowledge. The only\nimportant thing is to make it your habit.\nThis method really does work, if you are able\nto free yourself from the pendulum and “rent\nyourself out”. However, this is easier said\nthan done. Later in this book, you’ll discover\nnew methods for dealing with pendulums.\nThis is truly only the beginning. Doesn’t it\n149/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 872
  },
  {
    "chunk_full": "seem to you that I have taken you by the\nhand and I am about to lead you into a\nlabyrinth? That’s right, be free even of the\npeople\nthat\npreach\nto\nyou\nabout\nyour\nfreedom.\nThe Suspended State\nHaving freed yourself from the influence of\ndestructive pendulums, you acquire freedom.\nBut freedom without a goal – is a suspended\nstate. If you are preoccupied with making the\nsurrounding pendulums fall through or ex-\ntinguishing them, you are running the risk of\nfinding yourself in a vacuum. Previous con-\nflicts have gone somewhere else, concerns\nthat have been annoying you have receded,\narguments occur more and more rarely,\nanxiety and worry have disappeared. All of\nthis happening is hardly noticeable, as if the\nstorm is slowly quieting down.\n150/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 873
  },
  {
    "chunk_full": "However, soon you will find out that there is\na downside to it. If you were in the centre of\nevents before, now they seem to be happen-\ning somewhere else. To the people around\nyou, you are no longer of the same import-\nance as you used to be before and they pay\nless and less attention to you. You have fewer\nand fewer concerns, but there are no desires\neither. The pressure from the external world\nweakens, but that doesn’t bring you any ad-\nvantage. You have fewer problems, but no\nnew achievements.\nWhat is happening here? The thing is that\nthe entire world of man is built on pendu-\nlums. Therefore, if a man isolates himself\nfrom them completely, he will find himself in\na desert. The suspended state is not much\nbetter than being dependent on the pendu-\nlum.\nFor\nexample,\nchildren\nwho\nhave\neverything pine away, because “there’s noth-\ning more to want.” They are suffering them-\nselves and they pester everyone around them\n151/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 874
  },
  {
    "chunk_full": "with their whining. Humankind is made in\nsuch a way that he always needs something\nto strive for.\nYour freedom is being free from the pendu-\nlums of others. But there are pendulums that\nwill be of use to you personally. These are\nyour pendulums. In other words, it’s neces-\nsary to recognize goals that have been forced\non you, and in the pursuit of which you walk\nfurther and further away from your life track\nof happiness. The task is, while being free, to\nchoose those life tracks where true success\nand happiness await you.\nPendulums are not an absolute evil to a per-\nson, if he is aware of his actions and the situ-\nation. You can never be entirely free from\npendulums. The only question is how to\navoid putting yourself under the influence of\npendulums, and to consciously use them for\nyour own purposes. Transurfing offers spe-\ncific tools for doing this. To free oneself from\n152/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 875
  },
  {
    "chunk_full": "the influence of pendulums completely is not\npossible, but it’s not even necessary. On the\ncontrary, it is exactly the pendulums that\nare, in the end, responsible for turning a\nman’s dreams into reality.\nSummary\nA pendulum is created by the energy of\npeople\nwho\nare\nthinking\nin\nthe\nsame\ndirection.\nA pendulum is an energy-based information\nstructure.\nA pendulum fixes thought energy of an ad-\nherent onto its own frequency.\nA heavy battle for adherents is going on\nbetween pendulums.\nA destructive pendulum forces goals onto its\nadherents that are alien to them.\n153/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 876
  },
  {
    "chunk_full": "A pendulum plays on people’s feelings, at-\ntracting them into its net.\nIf you actively do not want something, it\nwill be in your life.\nTo free yourself from a pendulum means to\nthrow it out of your life.\nTo throw something out of your life means\nnot to avoid it, but to ignore it.\nTo stop a pendulum, it’s necessary to violate\nthe script of the game.\nPositive visualization will gently extinguish\na pendulum-man.\nThe energy of an extinguished pendulum is\ntransferred to you.\nProblems are solved by the fall through or\nextinguishing of pendulums, which created\nthe problems in the first place.\n154/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 877
  },
  {
    "chunk_full": "In order to solve problems – rent yourself\nout.\nTo avoid a suspended state, you must find\nyour own pendulums.\nYou must develop the habit of remembering\nall of this.\n155/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 878
  },
  {
    "chunk_full": "CHAPTER III\nTHE WAVE OF\nSUCCESS\nMetaphors such as “The Blue Bird\nof Happiness” and “The Wheel of\nFortune”\nhave\nquite\na\nmaterial\nbasis. It is well known that success\nand failure follow one another, like\nbad days and good days. How do\nwe exclude bad days from our lives?\nYour thoughts are coming back to\nyou like a boomerang.\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 879
  },
  {
    "chunk_full": "The\nAntipode\nof\na\nPendulum\nNow it’s time to check your homework. What\npendulums could be called constructive? The\nanswer is - none. It may sound like a para-\ndox, but that is really the case. Don’t be of-\nfended, dear Reader, the question was meant\nto be provocative. The main and only goal of\nany pendulum is to get energy from its ad-\nherents. If it can’t get any energy, it will stop.\nA pendulum can only be constructive to it-\nself, but never to you. What is so constructive\nor creative about something that takes en-\nergy from you? Of course, different pendu-\nlums are destructive to different degrees. For\nexample, it’s hard to imagine that a beach\nvolleyball club would take up arms against a\nclub of ice swimming enthusiasts. Then\nagain, a volleyball membership could never\nreally ruin your life. However, the pendulum\n157/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 880
  },
  {
    "chunk_full": "of the volleyball club is also feeding on en-\nergy from its adherents, and if they get bored\nwith playing beach volleyball, the club will\ndie. But this is nothing compared to being a\ngang member, where your freedom and even\nyour life could be taken away.\nYou could object: if I go to a fitness club\nwhere I am only focusing on myself, then\nhow can I be giving away energy to the pen-\ndulum? It doesn’t matter if you are only fo-\ncused on yourself or not, you are still re-\nquired to follow certain rules in the fitness\nclub. You can do whatever you want back at\nyour own place, but at the fitness club, all\nmembers are acting in the same way by fol-\nlowing the rules established by the system,\nand thus they give away collective energy to\nthe pendulum of the fitness club. If all mem-\nbers of the club would run away, the pendu-\nlum would no longer receive any energy, and\nso it would stop.\n158/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 881
  },
  {
    "chunk_full": "You could ask the question in a different\nway: are there energy structures that don’t\nneed your energy? Actually, there are. One of\nthem is the wave of success or a coincidence\nthat is fortunate for you personally. Every\nperson has his own waves of success. It is of-\nten the case that you have a little luck and\nthen comes an entire wave of other pleasant\nand unexpected events. As if you’re having a\nrun of good luck in your life. Waves such as\nthis don’t appear every day, only if you were\npleasantly surprised and got into a good\nmood the first time.\n“The Wheel of Fortune” and “The Blue Bird\nof Happiness” are not just abstract meta-\nphors. The wave of success is basically an ac-\ncumulation of life tracks. Everything can be\nfound in the space of variations, including\nthese gold veins. If you’ve found the outer\nline of such a gold vein and caught some\nluck, you could automatically glide on to oth-\ner lines of accumulated fortune, where new\n159/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 882
  },
  {
    "chunk_full": "lucky circumstances await you. But if, after\nyour first success, bad luck rears its ugly\nhead again, it means a destructive pendulum\nhas led you away from the gold vein.\nThe\nwave\nof\nsuccess\nbrings\nhappiness\nwithout taking any of your energy. It can be\ncompared to an ocean wave that carries an\nexhausted swimmer to the shore. The wave\nof success transfers you to your happy life\ntracks. The wave, just like a pendulum,\ncouldn’t care less about your fate, but it\ndoesn’t need your energy either. If you want\nto – get on the wave and swim with it, if you\ndon’t want to – the wave will pass you by\nwithout feeling sorry for you. The wave of\nsuccess is a temporary structure, as it doesn’t\nfeed on the energy of others. Therefore, it\nwill eventually fade out, kind of like the\nocean waves crashing on the shore.\nThe wave of success could appear in the form\nof good news. It carries information from\n160/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 883
  },
  {
    "chunk_full": "other life tracks. These echoes are inter-\npreted on the current life track as good news.\nYour task is to grab on to this fine thread and\npull yourself up to the life track where the\ngood news came from. That life track will\nnow not only have good news for you, but\nfortunate circumstances as well.\nIt may seem that the wave of success comes\nand goes. In fact this wave doesn’t move at\nall, it doesn’t gather any energy and it\ndoesn’t get weaker. We adopted the term\n“wave” in our model just to make it easier to\nunderstand. As mentioned, the wave of suc-\ncess is static in the space of variations, as an\naccumulation of favorable tracks. You are the\none moving from one life track to another, so\nto you this “vein” appears as a wave because\nyou grab it, by letting it into your life, or you\nget further away from it, carried away by the\npendulums.\n161/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 884
  },
  {
    "chunk_full": "The wave is not interested in you and it is\ntherefore easy to miss - it will pass you by\nand won’t come back. This has given rise to\nthe general belief that the blue bird of happi-\nness is difficult to catch. In reality, you don’t\nhave to make any effort in order to surf this\nwave. It’s all only a matter of choice. If you\nwelcome the wave into your life, it will be\nwith you. If you give in to the influence of de-\nstructive pendulums and get yourself imbued\nwith their negative energy, you will move\naway from the wave of success. That is how\npeople always act: “we don’t treasure what\nwe have until it’s gone”. The bird of happi-\nness doesn’t mind at all pecking seeds from\nyour hand. You don’t have to catch it. As long\nas you don’t chase it away, it will be more\nthan enough.\nThis is one of the most paradoxical features\nof the freedom of choice. People can actually\nchoose happiness and success for them-\nselves. And at the same time they’re not free\n162/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 885
  },
  {
    "chunk_full": "from pendulums that carry people away from\nthe wave of success. We are yet again return-\ning to our previous topic. In order to get the\nfreedom of choice for yourself, it is necessary\nto reject dependence on pendulums . We\nhave also the right to be free from the influ-\nence of pendulums that are not “ours”. Only\none thing remains - to find out how we can\nobtain these rights.\nThe Boomerang\nMost people have thoughts constantly run-\nning around in their head. If the thinking\nprocess\nis\nnot\ncontrolled\nthen\nnegative\nthoughts and worries will prevail. The things\nwe are most worried about are things that we\nfear; things that we find irritating or upset-\nting and things that make us feel depressed\nor dissatisfied. This is how destructive pen-\ndulums have been influencing the shape of\nthe human psyche over thousands of years.\n163/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 886
  },
  {
    "chunk_full": "These pendulums maintain fear in man, in\norder to successfully manipulate him. This is\nexactly why people are vaguely aware of what\nthey want, while they know exactly what they\ndo not want.\nAllowing the negative “thought-mixer” to\ntake over (that is when you are mulling over\neverything that is bad, complaining and hav-\ning generally pessimistic thoughts) means to\njoin the game of a destructive pendulum, and\nto radiate energy at its frequency. This is a\nrather unfavorable habit. It would really be-\nnefit you to replace it with another habit –\nhaving conscious control over your thoughts.\nWhenever your mind is not occupied with\nanything in particular – for example, when\nyou are on a train or a bus, or when you are\nout taking a walk, or doing something that\ndoesn’t require special concentration or at-\ntention – put positive thoughts in your head.\nDon’t think about what you were not able to\n164/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 887
  },
  {
    "chunk_full": "get – think about what you want to get, and\nyou will get it.\nSuppose that you don’t like the house you\nlive in. You are telling yourself: “I’m fed up\nwith this place. Everything about this place\nirritates me. But once I move to a new home,\nthen I’ll be happy. Meanwhile, I just can’t\nhelp myself….oh, how I hate this place!”\nKeep in mind that with thoughts like that it’s\nimpossible to get what you want. Even if you\nare about to move to a new and better place,\nyour\nnew\nhouse\nwill\nbring\nyou\nmany\ndisappointments.\nFair enough, you’ll say, but I’m leaving this\ndump and moving to a luxurious villa! What\ndisappointments could be waiting for me\nthere? You don’t have to worry about that.\nThe more despise you feel towards the little\nhouse that has given you shelter these many\nyears, the more unpleasant surprises will\nawait you in your new quarters. And these\n165/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 888
  },
  {
    "chunk_full": "unpleasant surprises will be of the most var-\nied kind. The taps won’t work, the paint will\nstart to peel, walls will start caving in, the\nneighbors will annoy you – in short, all those\nthings will happen that need to happen in or-\nder to maintain the parameters of your neg-\native radiation. Whether it’s the new house\nor the old one – what difference does it\nmake? There will always be life tracks with\nall possible conveniences where you will be\njust as dissatisfied as before. The space of\nvariations has many luxurious houses where\nyou will nonetheless feel like you are in hell.\nAnd if you don’t have anywhere to move to\nyet, then you will remain in this hated situ-\nation for sure. After all, you’re not tuned to\nthe frequency of the life track where the\nhouse of your dreams awaits you. At the mo-\nment, you’re thinking about what you don’t\nlike, so you’re giving off negative energy and\nthis energy fits perfectly with the life track\nyou are at now. Therefore, you’re stuck there\n166/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 889
  },
  {
    "chunk_full": "until\nthe\nfrequency\nof\nyour\nradiations\nchanges. And this is not too difficult to do.\nFirst of all, accept your present situation as it\nis and get rid of your dissatisfaction and re-\nsentment. You can always find something\ngood in everything and in any situation.\nEven the smallest things in life can be a\nsource of joy. So, you don’t like the house\nyou’re living in, but you can at least be grate-\nful to it. After all, it has sheltered you. It is\nrainy and windy outside, and the house is the\none to endure that, while keeping you safe\nand warm. Doesn’t this deserve some kind of\nrecognition? If you are grateful for what you\nhave now, if you experience love towards all\nthose things surrounding you, things that\nmake your life easier, then you will be giving\noff positive energy. Then, if you want to, you\ncould count on an improvement of your liv-\ning conditions. And when you are moving\naway, be sure to thank everything that sur-\nrounded you before in your old house. Even\n167/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 890
  },
  {
    "chunk_full": "things that you throw away deserve your\ngratitude. In these moments, you are trans-\nmitting positive vibrations to the surround-\ning world, and these vibrations will definitely\ncome back to you.\nSecond of all, start thinking about the house\nthat you would like to have. This is more dif-\nficult to do than to get irritated with things\naround you. But then, it’s also more useful.\nWhat is a better thing to do? To react as usu-\nal, like an oyster to external irritants, or to\nmake a little effort and change your habits?\nLook at real estate advertisements that fea-\nture photographs and prospects of potential\nfuture homes, visit interior design stores and\nlook for furniture that you would like to have\nin your house. In other words, let all your\nthoughts be preoccupied with what you wish\nto have. We always possess things and en-\ncounter situations that have a powerful grip\non our thoughts. Our thoughts always re-\nturn to us like a boomerang.\n168/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 891
  },
  {
    "chunk_full": "There are so many examples that could illus-\ntrate how a negative attitude can ruin one’s\nlife. Let’s say you are planning a vacation in a\nwarm country. But where you live now, the\nweather is absolutely terrible. You’re walking\nthe streets, the cold wind is making you\nshiver and the rain is soaking your clothes. It\nis, of course, hard to be overly joyous in such\nweather. So, at least try to be neutral, ignor-\ning this destructive pendulum. If you are act-\nively expressing your dissatisfaction with the\nweather, then you are accepting the pendu-\nlum and you are making it swing higher.\nYou are telling yourself: “Well, soon I’ll be\ngoing to a warm country and I’ll be so happy\nin the sun and in the warm sea. But as for\nnow, damn this swamp!” Thus, with such an\nattitude you’re not tuned to the life track\nwhere heavenly relaxation is waiting for you.\nYou won’t get there. You already have your\nplane ticket, you say? Well, so what? You’ll\nonly get to your destination, but either bad\n169/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 892
  },
  {
    "chunk_full": "weather or some other misfortune will be\nwaiting for you there. However, everything\nwill be great if you only get tuned into a pos-\nitive frequency.\nIt’s obviously not enough to prevent negative\nenergy from getting to you. You yourself\nneed to avoid radiating such energy. For ex-\nample, you were very annoyed and you yelled\nat someone. You can be sure that as a result\nsome sort of problem will follow. In the\npresent situation, the parameters of your ra-\ndiation match the life track where you are\nannoyed. So, that’s exactly where you will be\n“transported”. On these tracks, the density of\nunpleasant situations is higher than average.\nDon’t try to calm yourself with the justifica-\ntion that this unpleasant situation was actu-\nally unavoidable. I don’t need to try to con-\nvince you or to prove anything to you. Just\nwatch how new unfortunate events seem to\nfollow any negative reaction that you have.\n170/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 893
  },
  {
    "chunk_full": "The conclusion from all of this is very simple\nand clear: you will always find yourself on\nthe life tracks that correspond to your energy\nradiation. If you let negative energy in, un-\npleasant things will happen in your life. If\nyou radiate negative energy, it will return to\nyou like a boomerang, only this time as\nproblems.\nThe Transmission\nInstead of accepting a game with destructive\npendulums, look for pendulums where the\ngame will be of use to you. This means ac-\nquiring\na\nhabit\nof\npaying\nattention\nto\neverything that is good and positive. As soon\nas you see, read or hear something good,\npleasant, or reassuring – attach this to your\nthoughts and feel happy. Imagine that you\nare walking in a forest: there are pretty\nflowers, but there are also poisonous thorns.\nWhich do you choose? If you picked some\n171/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 894
  },
  {
    "chunk_full": "elderberry flowers, brought them home and\nput them in a vase, you’ll soon have a head-\nache. Why would you ever need that? It’s just\nas harmful reacting to destructive pendu-\nlums. It would be better to pick some jas-\nmine blossoms, enjoy them and take in their\npleasant aroma. Bring everything positive in-\nto your life, and soon you’ll have more and\nmore good news and nice opportunities.\nSo you’ve been inspired and felt joy, but then\neveryday life dragged you down once again.\nThe holidays are over and working days are\napproaching. How to keep the festive feel-\ning? First, remember it. Out of habit, we\nplunge into colorless everyday life, forgetting\nabout the nice things in life and so it stops\nbringing us pleasure. This is a bad habit.\nPendulums make us forget.\nWe need to maintain the little flame of celeb-\nration in us and we have to cherish that feel-\ning. Simply observe how life changes for the\n172/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 895
  },
  {
    "chunk_full": "better, grasp for the tiniest straw of joy, look\nfor good signs everywhere and in everything.\nThis is, at least, not a boring thing to do. You\nneed to remember that every minute that\nyou spend with Transurfing, you are con-\nsciously moving closer towards your dream,\nand that means you are controlling your own\ndestiny. This notion alone will instill you\nwith calm, confidence and joy, and thus\nyou’ll always be on holiday. Once the feeling\nof being on holiday has become a habit, then\nyou will always find yourself on top of the\nwave of success.\nBe happy with everything you have in the\npresent moment. I am not simply asking you\nto be happy by definition. Sometimes cir-\ncumstances are such that it’s very difficult to\nbe satisfied with life. But from an entirely\npractical point of view, expressing your dis-\nsatisfaction with something is a pretty un-\nconstructive thing to do. After all, wouldn’t\nyou really want to be on the life tracks where\n173/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 896
  },
  {
    "chunk_full": "everything is working out perfectly for you?\nHow will you ever get there if your radiation\nis full of discontent? The frequency of such\nradiation corresponds exactly to the life\ntracks that are bad for you, so the situation\nwill be quite the opposite of what you really\nwanted. The good tracks are characterized by\nthe fact that when you are on them you feel\ngood and your thoughts are filled with joy\nand satisfaction.\nGood news is not too exciting and is soon\nforgotten. Bad news, on the other hand, stirs\nup quite a response because it informs about\na potential threat. Don’t let bad news into\nyour heart and hence, into your life as well.\nShut yourself off to bad news and open your-\nself to good news. Any positive change\nshould be recognized and carefully cher-\nished. These are the forerunners of the wave\nof success. As soon as you hear even the\nsmallest piece of encouraging news, don’t\nforget about it immediately, as you used to\n174/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 897
  },
  {
    "chunk_full": "do, but do the exact opposite - savor it, talk\nabout it, pursue it. Think over this piece of\nnews from all possible angles, take joy in it,\nbuild hypotheses on it and expect a positive\ndevelopment. In this way, you will be think-\ning on the frequency of the wave of success,\ntuning into its parameters. As a result, there\nwill be more and more good news and life\nwill get better. This is not mysticism and this\nis not a quality of the human psyche to filter\ninformation in different ways, like when a\npessimist looks at the world through dark\nglasses, while an optimist looks at the world\nthrough rosecolored glasses. This is reality:\nyou are moving to the life track that corres-\nponds to the parameters of your thoughts.\nBeing on good terms with yourself and the\nsurrounding world, you are transmitting\nharmonious emanations to the surrounding\nworld. You are creating around yourself an\narea\nof\nharmonious\nvibrations\nwhere\neverything is turning out successfully. A\n175/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 898
  },
  {
    "chunk_full": "positive attitude always leads to success and\ncreation.\nNegativism, on the other hand, is always de-\nstructive and is always aimed at devastation.\nFor example, there’s a category of people\nwho are looking for problems but not for\ntheir solutions. They are always ready to dis-\ncuss difficulties in a lively manner and find\nall kinds of new problems. Such people usu-\nally have trouble actually suggesting a real\nway out, because from the very beginning\nthey are tuned not to the solution itself, but\nto the search for more difficulties. Their fixa-\ntion on the hunt for problems brings these in\nabundance, but the situation remains un-\nsolved. The readiness to look for and criticize\nthe bad sides of things always brings the cor-\nresponding fruits: a great deal of harm but\nno benefit. Look around and you’ll definitely\nfind people like that. They’re not especially\ngood people or especially bad people. They\n176/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 899
  },
  {
    "chunk_full": "are simply sitting firmly on the hook of de-\nstructive pendulums.\nMost people treat any unwanted event in\ntheir lives with hostility. Usually, an un-\nwanted event to us is an event that is not\npart of our own original script. And the op-\nposite\nis\nalso\ntrue\n-\nwe\nonly\nbelieve\nsomething to be successful if it corresponds\nto our expectations. Let’s say that a man\nmisses his plane and is very upset about this.\nLittle does he know that the plane is going to\ncrash. But it can also be the other way\naround, when a man misses out on a fantast-\nic opportunity just because it was not part of\nhis plan or it was simply inconceivable.\nThe worse a person thinks about the sur-\nrounding world, the worse this world gets, at\nleast for this person. The more he gets upset\nover his lack of success, the more failures\nwill come his way. “As a man sows, so shall\nhe reap.” If a person chooses to live his life\n177/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 900
  },
  {
    "chunk_full": "with a pessimistic view on things, then every\nday he’ll be practicing Transurfing in re-\nverse: he is sliding along the life track, where\nreal hell is waiting for him. Assume the posi-\ntion that is the exact opposite: rejoice in your\nmisfortunes just out of spite, try to find\nsomething useful in your problems – this is\nalways possible. A glass is not half-empty, it\nis half-full. There is a trivial saying, “It’s all\nfor the best” and it works like a charm, if that\nis what you really believe. You have to be\nstubborn in maintaining your positive atti-\ntude, refusing old habits of always getting\nupset and depressed for any reason.\nEvery misfortune is, at the very least, a good\nlesson that makes you stronger and more ex-\nperienced. Take joy in everything good that\nis happening in your world, and it will turn\ninto pure paradise. Of course, this is a very\nunusual way of behaving. But your goal is\nalso very unusual – to become a genie that\n178/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 901
  },
  {
    "chunk_full": "grants his wishes. How can you achieve this,\nusing ordinary methods?\nReacting positively is a difficult thing to do at\nfirst, because the old habit of reacting negat-\nively to the undesired is strongly rooted in\nus. The main thing is to learn to remember\nthat whenever an unfortunate event hap-\npens, it is a pendulum trying to hook you. As\nsoon as you remember that you are able to\nmake a conscious choice: to give away your\nenergy to the pendulum, having splashed out\nall of your negative emotions, or leave it\nemptyhanded and thereby gain a victory.\nIf you did remember, the fall through or ex-\ntinguishing the pendulum will already be\neasy. We always unconsciously give away our\nenergies to the pendulum. As was already\nmentioned, pendulums pull us by the strings\nof our feelings, and our habits form the lever\nthat sets in motion the thought capture\nmechanism. Even after having read this\n179/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 902
  },
  {
    "chunk_full": "chapter and having set the goal to remember\nthe foul game of the pendulum, you will\nagain react negatively to the unwanted.\nThen, of course, you will realize that in that\nmoment you simply forgot about it and were\nacting unconsciously, out of habit. Nonethe-\nless, as soon as you have remembered in\ntime, the situation will be entirely under\nyour control. You’ll smirk to yourself: “Ah,\nit’s you, pendulum? Well, it won’t be that\neasy for you to hook me up this time.” You’re\nno longer a puppet on a string. You are free\nto make the conscious decision of either ac-\ncepting or rejecting the pendulum.\nIf you use this method with a high level of\npersistence and determination, eventually\nthe new habit will replace the old. But mean-\nwhile, pendulums will try to get to you in\nevery possible way. You’ll notice how, as if on\npurpose, a whole lot of annoying little nuis-\nances will start popping up in your life. Don’t\ndespair, because the problems will mostly be\n180/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 903
  },
  {
    "chunk_full": "of a petty kind. If you won’t give up and if\nyou will learn to remember, your victory will\nbe very impressive, you’ll see.\nAnd this is what could happen: next time you\nencounter the wave of success, a pendulum\nwon’t be able to carry you away from it.\nHence, the bird of happiness will stay in your\nhands. And in order to lure it in, you must\ngive off positive energy all around you. That\nis, you should not only be an exclusively pos-\nitive receiver, but a positive transmitter as\nwell. As a result, the world around you will\nbe changing very quickly for the better. You\nwill be able to glide easily onto more and\nmore successful life tracks. In the end, the\nwave of success will come to you, sweeping\nyou along with it and bringing you directly to\nsuccess. But don’t be thinking that Transurf-\ning is only limited to gliding on the wave of\nsuccess. These are only the first steps. Many\nmore extraordinary discoveries are waiting\nahead.\n181/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 904
  },
  {
    "chunk_full": "Magic Rituals\nIn conclusion of this chapter, let’s look at one\nparticular example where the method of tun-\ning into the frequency of the wave of success\nis used. In various situations, people some-\ntimes unknowingly try to tune into the\nwave’s frequency. For example, in the begin-\nning of the day, sellers are prepared to give\nthe first customer a significant discount.\nThey intuitively feel that the first customer is\nvery important – it’s necessary to get things\ngoing, to initiate the trade and once the first\nsale has been made this can be achieved. In\nthe language of Transurfing, it means tuning\ninto the frequency of a track for successful\ntrading. It would be difficult to simply focus\none’s thoughts on the frequency. But the first\ncustomer gives real hope and faith, and the\ntuning thus happens on its own. The seller\ngets on the wave of successful trading and\nemanates\nthought\nenergy\nwith\n182/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 905
  },
  {
    "chunk_full": "corresponding parameters. He himself be-\nlieves that his goods will sell out quickly and\nhe needs only mention this to a customer,\nwho then immediately gets “caught” by this\nradiation and obediently makes the pur-\nchase, convinced that he got really lucky\ntoday.\nLet’s take one more example. Market sellers\noften perform a peculiar magic ritual – they\ntouch their merchandise with money. Of\ncourse, this action on its own is absolutely\ndeprived of power, therefore there is no real\nmagic taking place. However, if the seller be-\nlieves in the power of the ritual, his belief\nalone will help him tune into the frequency\nof successful trading. The actual tuning oc-\ncurs on a subconscious level. The seller’s\nmind is only aware of what is happening on\nthe outside: the ritual works but for some\nunknown reason. And it actually does work,\nnot by itself, but as stage props. The main\npart is played by the actor’s thought energy.\n183/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 906
  },
  {
    "chunk_full": "Almost\nevery\nprofession\nhas\na\nsimilar\n“magic” ritual for different situations. People\nbelieve in these rituals and use them success-\nfully, in order to tune into the frequency of\nsuccessful life tracks and to get on top of the\nwave of success. Actually, it’s not important\nwhat people believe in – in the magic quality\nof the ritual or in the tuning process. As you\nknow, the only important thing is the prac-\ntical result.\nSummary\nThe wave of success is an accumulation of\nfavorable tracks in the space of variations.\nThe flow of fortunate events follows only if\nyou have been inspired by the first success.\nDestructive pendulums take you away from\nthe wave of success.\n184/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 907
  },
  {
    "chunk_full": "Having freed yourself from the pendulums,\nyou get the freedom of choice.\nReceiving and transmitting negative en-\nergy, you create your own hell.\nReceiving and transmitting positive energy,\nyou create your own heaven.\nYour thoughts always return to you like a\nboomerang.\nPendulums won’t throw you off the wave, if\nyou have the habit of remembering.\nThe\nhabit\nof\nremembering\nis\nformed\nthrough a systematic practice.\n185/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 908
  },
  {
    "chunk_full": "CHAPTER IV\nTHE BALANCE\nPeople create their own problems\nand obstacles, and then waste time\nand energy on overcoming them.\nContrary\nto\npopular\nbelief,\nTransurfing shows that the reasons\nto all of our problems lie on a differ-\nent plane. How can we eliminate\nproblems\nfrom\nour\nlives?\nCare\nwithout worrying.\nExcess Potential\nEverything in nature strives towards a state\nof balance. Drop in atmospheric pressure is\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 909
  },
  {
    "chunk_full": "balanced out by the wind. Differences in\ntemperatures are compensated for by heat\nexchange. Everywhere, where there could be\nan excess potential of any energy, balancing\nforces appear, directed at eliminating the im-\nbalance. We’re so used to this being the nor-\nmal state of affairs that we don’t even ask\nourselves: but why is it exactly this way and\nnot another? Why does the law of balance\nwork? There is no answer to this question.\nOverall, laws do not explain anything - they\nonly state the obvious. All laws of nature are\nonly secondary to the law of balance. It is the\nprimary law (or at least so it seems). There-\nfore, it is not possible to explain why balance\nshould exist in nature. To be more precise, it\nis impossible to explain where balancing\nforces come from and why they exist at all.\nAfter all, just because we are used to some\nphenomena, it does not mean that is exactly\nhow things happen. We can only guess what\nthe world would be like without the law of\n187/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 910
  },
  {
    "chunk_full": "balance: would it turn into some kind of\nformless jelly or into aggressive scorching\nheat? However, the inappropriateness of\nsuch a strange world cannot be the reason to\nwhy the law of balance exists. So, we simply\nhave to accept the law of balance as a fact,\nand stare in amazement at how perfect the\nspace around us is. At the same time,\nhowever, we would not have any idea about\nwhat the driving force behind all of this is.\nWe’re used to having good and bad luck in\nlife. We are also used to the idea that success\nis always followed by failure. These are all\nmanifestations of the law of balance. After\nall, both failure and success upset the bal-\nance. Absolute balance is when there is abso-\nlutely nothing going on, but there are no ab-\nsolutes. In any case, no one has yet been able\nto observe an absolute state of balance. The\nworld is full of constant fluctuations: day –\nnight, high tide – low tide, birth – death and\n188/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 911
  },
  {
    "chunk_full": "so on. Even in vacuum, elementary particles\nare constantly dying and being reborn.\nThe entire world could be viewed as a collec-\ntion of pendulums where some are swinging\nhigher, others are being dampened and all\nare interacting with each other. Each pendu-\nlum receives impulses from its neighbors\nand gives them its own in return. One of the\nfundamental\nlaws\ncontrolling\nthis\nentire\ncomplex system is the law of balance. In the\nend, everything strives towards balance. You\nyourself are also a kind of pendulum. If you\none day decide to upset the balance and\nmake a sudden swing in one direction, you\nwill affect neighboring pendulums and create\nannoyance around you, which will then turn\nagainst you.\nThe balance can be upset not only by actions,\nbut also by thoughts, and not only because\nthoughts usually precede actions. As you\nknow, thoughts radiate energy. Even in the\n189/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 912
  },
  {
    "chunk_full": "material world, everything is based on en-\nergy. And everything that happens on the in-\nvisible energy level is reflected in the world\nof visible material objects. It may seem that\nthe energy of our thoughts is too small to be\nable to have any effect on the world around\nus. But if that was the case, things would be\nso much easier.\nNevertheless, let’s not try to guess what’s ac-\ntually happening on the energy level, so we\ndon’t get completely confused. For our pur-\nposes, it is quite enough to accept the simpli-\nfied model of balance: if an excess energy po-\ntential appears, balancing forces arise to\neliminate this potential.\nThought energy gives rise to excess potential\nwhen some kind of object is given too much\nsignificance. For instance, let’s compare two\nsituations: in one situation you’re standing\non the floor in your room, and in the other -\nyou’re standing on the edge of a cliff. The\n190/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 913
  },
  {
    "chunk_full": "first alternative doesn’t bother you at all. Yet,\nin the second alternative, the actual situation\nbecomes very significant to you – take one\nwrong step, and something irreversible will\nhappen. On the energy level, the fact that you\nare simply standing has the same signific-\nance in the first case as in the second. But,\nbeing as you are on the edge of a cliff, fear\narouses tension in you, and so you create an\nirregularity in the energy field. The balancing\nforces will appear immediately, directed at\neliminating this excess potential. You might\neven be able to feel their effect: on one side, a\nmysterious force is pulling you down, while\non the other side, a different force is pulling\nyou away from the edge. After all, for the ex-\ncess potential of your fear to be eliminated,\nbalancing forces either have to pull you away\nfrom the edge or throw you off the cliff and\nput an end to it. So it is the action of these\nforces\nthat\nyou\nare\nexperiencing,\nwhile\nstanding on the edge of a cliff.\n191/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 914
  },
  {
    "chunk_full": "On the energy level, all material objects have\nthe same significance. We are the ones that\ngive them specific qualities: good – bad,\nhappy – sad, attractive – repulsive, good –\nevil, simple – difficult and so on. Everything\nin this world is subject to our evaluation. By\nitself, evaluation does not create any irregu-\nlarity in the energy field. Sitting an armchair\nall by yourself, you evaluate the situation:\nsitting here is safe, but standing on the edge\nof a cliff is dangerous. Yet, in the current mo-\nment, it does not concern you. You simply\nevaluate the situation and therefore the bal-\nance is not upset in anyway. An excess po-\ntential only arises if unreasonably great sig-\nnificance is given to an evaluation.\nThe magnitude of excess potential grows if\nan evaluation, having a great significance, is\ngreatly distorting reality as well. In general,\nif the subject is very important to us, we are\nunable to evaluate its quality objectively. For\nexample, an object of worship is always\n192/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 915
  },
  {
    "chunk_full": "overwhelmingly full of virtues, whereas an\nobject of hate is always full of flaws, and an\nobject of fear is always full of terrifying qual-\nities. It turns out that thought energy is arti-\nficially trying to create a certain quality that\nwas never there in the first place. In such\ncase, excess potential is created, which stirs\nup the wind of balancing forces.\nDistorting reality, evaluation can be dis-\nplaced in two ways: by giving the object\neither excessively negative characteristics or\nexcessively positive characteristics. However,\njust by itself a mistake in evaluation plays no\nrole whatsoever. Again, notice the following\n– a displaced, incorrect evaluation will create\nan excess potential only if your evaluation is\nof great significance to you. Only the things\nand situations that are of importance to you\nspecifically will provide your evaluation with\nenergy.\n193/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 916
  },
  {
    "chunk_full": "Excess potential, although invisible and in-\ntangible, nonetheless plays a significant and\neven treacherous role in peoples’ lives. The\nactions of balancing forces in eliminating\nthis potential give rise to the lion’s share of\nproblems. The perfidy lies in the fact that a\nman often gets a result that is quite the op-\nposite of his intentions. Moreover, nobody\nunderstands what is actually happening.\nHence, we get the feeling that there is some\nkind of mysterious evil force at work, a kind\nof “Murphy’s law”. We have already touched\nupon this question when we were discussing\nwhy we always get what we really don’t want.\nLet’s take a look at the next example that will\nshow us why the things we wish for always\nslip away.\nThere is an erroneous opinion that if we\nwholly and completely devote ourselves to\nour job, we can achieve outstanding results.\nFrom the balance’s point of view, it’s be-\ncomes\ncompletely\napparent\nthat\nto\nget\n194/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 917
  },
  {
    "chunk_full": "immersed in your work means to put this\nvery same work on a scale and weigh it\nagainst everything else. The balance is dis-\nturbed and you won’t have to wait long for\nthe consequences. The result will be the dir-\nect opposite of what was expected.\nIf working harder to you is making more\nmoney or raising your qualifications, then of\ncourse, you would have to make an effort,\nand nothing terrible will happen because of\nthat. But you’ve also got to know when to\nstop. If you are constantly feeling exhausted\nand work has become a nightmare to you,\nthen it means you need to slow down or\nchange your job altogether. Excessive efforts\nwill definitely have a negative outcome.\nLet’s take a look at how this all happens.\nBesides work, you have many other things\nthat you value: your house, your family, en-\ntertainment, your spare time and so on. If\nyou have put your job above everything else,\n195/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 918
  },
  {
    "chunk_full": "then you have created a very strong excess\npotential. Everything in nature strives to-\nwards balance. Therefore, regardless of your\nwill, forces will be manifested, taking care of\nthe excess potential. And they can act in the\nmost varied ways. For example, you get sick\n– there can be no talk about work until you\nget better. Maybe you would even get de-\npressed, and why not? After all, you are for-\ncing yourself to do something that has be-\ncome a burden to you. Your mind keeps\ntelling you: “Come on, you have to get up, go\nto work and earn some money!” But your\nsoul (the subconscious) is wondering: “Is\nthat really why I came into this world, to suf-\nfer and endure all kinds of pains? What do I\nneed all of this for?” Finally, you’ll end up\nwith the chronic fatigue syndrome, which\nwill put an end of any possibility of doing a\njob. It’s like pulling the devil by the tail –\nthere is no point.\n196/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 919
  },
  {
    "chunk_full": "At the same time, you may notice how other\npeople around you achieve greater results\nand they do so without much effort. It turns\nout that, having reached a certain level, the\nsignificance that you attribute to your job\nstarts maxing out. The more weight your\nwork has for you, the more problems you will\nget. It will seem to you that having all these\nproblems is just the normal way of things,\n“it’s all in working order”, so to speak. The\ntruth is that you would have much fewer\nproblems if you only lowered your “bar of\nimportance.”\nThere is only one conclusion we can draw\nfrom all of this: in order to eliminate any ex-\ncess potential you need to consciously review\nyour attitude to work. It is necessary for you\nto have some time off when you can do what\nyou like, besides your job. Those who don’t\nknow how to relax don’t know how to work\neither. Once you are at work, rent yourself\nout. Give your job your head and your hands,\n197/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 920
  },
  {
    "chunk_full": "but not your heart. The pendulum of work\nneeds all your energy, but you came into this\nworld not just to work. You will be much\nmore productive and efficient at work if you\neliminate your excess potential and free\nyourself from pendulums.\nWhile renting yourself out, make sure to act\nimpeccably. Don’t let yourself make even the\nsmallest blunders, which may allow others to\naccuse you of recklessness. The impeccable\nbit concerns your performance at work.\nRenting yourself out does not at all mean to\nbe a slacker and take no responsibility for\nyour actions. It means to act detached, not\ncreating excess potential, but at the same\ntime do everything that is asked of you down\nto the smallest detail. Otherwise, you may be\nin for a bumpy ride. For example, there are\nalways people around you who, unlike your-\nself, really bury themselves in their work.\nThey will sense subconsciously that you are\nrenting yourself out; that is you are no longer\n198/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 921
  },
  {
    "chunk_full": "working extremely hard but still manage to\nget a lot of things done. These diligent souls\nwill intuitively start looking for an opportun-\nity to catch their rival making a mistake. As\nsoon as you make a mistake, they will imme-\ndiately throw themselves on you. Whatever\nmistake you have made, it will probably be\ninsignificant,\nand\ntherefore\nhumiliating,\nwhen your colleges point it out. Something\nlike you being late for work, forgetting\nsomething or having missed something. If\nyou were engrossed in your work, they would\noverlook your mistakes. But now they accuse\nyou of not caring enough about your job.\nSimilar situations could arise not only at\nwork, but also in your family or among\nfriends. Therefore, when you are renting\nyourself out, whatever situation it may be,\nit’s necessary to perform your duties flaw-\nlessly.\nLet\nyour\ninner\nobserver\n–\nthe\nOverseer -come to your aid in this task .\nOtherwise, you will soon plunge into the\n199/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 922
  },
  {
    "chunk_full": "game\nonce\nagain.\nYour\ninner\nWatcher\ndoesn’t have anything to do with a split per-\nsonality. You’re simply noting to yourself, in\nthe background, what you are doing and how\nyou are doing it. We’ll return to this in sub-\nsequent chapters.\nYou could object to the above reasoning: if\nyou should not be working excessively and\nconsequently, avoiding any excess potential,\nhow can we then understand the expression,\n“putting your heart and soul into it”? It de-\npends on the task at hand. “Burying yourself\nin your work” could only be justified in one\nsituation, when the work itself is your goal.\nWe’ll discuss later the topic what it means to\nhave a goal and what your goal is. So, in the\ncase where your work is your goal, it serves\nas a kind of tunnel leading you to success. In\ncontrast to the job you are doing for some-\nbody else, such work pumps you with energy\nand fills you with inspiration and satisfac-\ntion. If you’re among those rare happy souls\n200/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 923
  },
  {
    "chunk_full": "whose work is exactly like that, then you\nhave absolutely nothing to worry about.\nEverything mentioned above is completely\ntrue for studying as well. Later in this\nchapter, we will look at other life situations\nwhich create excess potential. We will also\nlook at the consequences that follow the ac-\ntions of balancing forces.\nDissatisfaction\nand\nJudgment\nLet’s begin with the topic of being dissatis-\nfied with oneself. You could be, for example,\ndissatisfied with your personal achievements\nand qualities, but you could also be dissatis-\nfied with yourself, refusing to accept your\nflaws and weaknesses. You can be aware of\nthem but you shouldn’t be developing com-\nplexes because of them. But if your flaws\nreally bother you and become of great\n201/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 924
  },
  {
    "chunk_full": "significance to you, excess potential will be\ncreated. The balancing forces will quickly get\nto work eliminating this potential. Their ac-\ntions can be aimed at the development of\nsomeone’s virtues or at the struggle with\ntheir weaknesses. Consequently, a person\nwill be more inclined to do one or the other.\nMost often, the person will choose the\nstruggle, and having assumed such a posi-\ntion, it will turn against him. It’s pointless\ntrying to hide one’s imperfections, but elim-\ninating them is difficult too. So, you get the\nexact opposite result and the situation be-\ncomes worse. For example, trying to hide his\ntimidity a man gets even shyer or he be-\ncomes unduly familiar with strangers.\nIf a man is dissatisfied with his achievements\nonly to the degree where it serves as a push\nfor self-perfection, the balance is not dis-\nturbed. The world around him is not affected\nby this relative dissatisfaction, but the inner\nchange in balance is compensated for by\n202/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 925
  },
  {
    "chunk_full": "positive actions. But if a man starts wallow-\ning in self-reproach and resentment towards\nhimself or, even worse, he starts punishing\nhimself for whatever it is he doesn’t like in\nhimself, then a dangerous situation will take\nform, where soul and mind are in conflict.\nYet, the soul didn’t deserve this kind of treat-\nment. The soul of any person is perfect and\nself-sufficient. All flaws and weaknesses that\nyou have acquired are the flaws and weak-\nnesses of mind, not of the soul. However,\nthis is such a large and complicated subject\nthat it is worth writing a separate book about\nit. Here we’ll only make a note of the fact\nthat being in conflict with oneself is an ex-\ntremely bad thing to do. The soul will with-\ndraw into itself, while “reason will prevail”\nand this could result in a complete devasta-\ntion of one’s life. Just so that you do not have\nto look for a psychoanalyst later – start with\nletting yourself go and forgive yourself for all\nof your flaws and weaknesses. If you are\n203/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 926
  },
  {
    "chunk_full": "unable to love yourself right now, then at\nleast stop fighting with yourself and accept\nyourself as you are. This is the only way your\nsoul will be an ally to your mind. And it is a\nvery powerful ally indeed.\nAlright, you say, I’ll leave all my flaws and\nweaknesses in peace, then how do I acquire\nvirtues? You don’t expect me to stop devel-\noping as a person, do you? Of course, not!\nYou are free to develop your virtues as much\nas you want. We’re only talking about stop-\nping the war with your flaws and weak-\nnesses. In a war like that you waste energy,\nnot so much on supporting something use-\nless, but rather on supporting a very harmful\nexcess potential. Once you’ve finally turned\naway from this struggle, the released energy\nwill be directed at developing your virtues.\nEven though all of this may sound extremely\nsimple, lots and lots of people waste an\nenormous amount of energy on the struggle\n204/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 927
  },
  {
    "chunk_full": "with themselves, trying to cover up their im-\nperfections. They are like titans that have\ndoomed themselves to bear this burden all\ntheir life. If only they allowed themselves to\nget rid of this heavy burden and be just the\nway they are, life would get so much simpler\nand easier. Their energies would be redirec-\nted away from the struggle with flaws and\nweaknesses to the development of virtues.\nMoreover, the parameters of such radiation\nwould correspond to the life tracks where\nvirtues triumph over flaws and weaknesses.\nThink about it. For example, how can you\never move to the life track where you are in\ngood physical shape, if all your thoughts are\nfocused on your physical flaws? You get what\nyou actively don’t want.\nWhen you are unhappy with yourself, you get\ninto a conflict with only your soul – but\nwhen you are unhappy with the world, you\nget into a conflict with a large number of\npendulums. You know by now that there is\n205/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 928
  },
  {
    "chunk_full": "nothing good in being under their spell. And\nwhen it comes to waging war with them –\nwell, it is better not to think about it at all.\nDissatisfaction is an entirely material radi-\nation. Its frequency goes well with those life\ntracks where whatever it is that you don’t\nlike about yourself is pronounced even more.\nWhen you feel that you are being pulled to-\nwards these tracks, you become even more\ndissatisfied, and this continues until you get\nto the track where you are old, sick and in-\ncapable of changing anything. The only thing\nleft for you is trying to find some comfort in\nwhining about this world together with oth-\ners who are just like you, and in memories of\nhow good everything was back in the old\ndays.\nEvery generation is convinced that life is\nworse now. No, life is worse only specifically\nfor those in a given generation who are used\nto wallowing in their dissatisfaction with this\n206/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 929
  },
  {
    "chunk_full": "world. Otherwise, humankind (after a num-\nber of generations) would simply have rolled\ndown into a living hell. A rather depressing\npicture, isn’t it? This is the first aspect of be-\ning dissatisfied with the world, which leads\nto life getting increasingly worse.\nHowever, there is another aspect to this\nharmful habit of showing dissatisfaction –\nand that is upsetting the state of balance.\nRegardless of whether your dissatisfaction is\njustified or not it is creating an excess poten-\ntial in the energy space around you. This po-\ntential gives rise to balancing forces, which\nwill strive to restore the balance. It would be\ngreat if these forces worked in a way that\nwould make things better. But, unfortu-\nnately, things usually happen the other way\naround. The balancing forces will try to be-\nsiege you, so that your complaints about this\nworld will be of as little weight as possible.\nThis is much easier for them to do than to\nchange everything that you are displeased\n207/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 930
  },
  {
    "chunk_full": "with. Imagine what would happen if a ruler\nstarted actively expressing his dissatisfaction\nwith everything that was happening in his\nstate. It’s not even important whether his\nmotives were good or bad. Such a ruler\nwould be removed or even physically des-\ntroyed. The entire history of humankind\nserves as a confirmation of this.\nBasically, the action of the balancing forces\nwill be directed at decreasing the influence\nyou have on the world around you. This is\nextremely easy to do and it can be done using\nall possible methods, like for instance by re-\nlieving you of your obligations, your job,\nyour salary, your home, your family, your\nhealth and so on. Can you see now how the\nolder generations end up with a life that is\n“worse than back in their days”?\nNow let’s examine this question from a dif-\nferent angle. One could argue that since the\nbalancing forces act to diminish the excess\n208/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 931
  },
  {
    "chunk_full": "potential of dissatisfaction, which is a negat-\nive feeling, the opposite should be true as\nwell. In other words, it would seem that if\nyou were very happy with the world around\nyou, then the balancing forces would do\nwhatever it takes to ruin your party or to\npush you back to wherever you came from.\nHowever, it does not happen unless, of\ncourse, your joy turns into a “wide-eyed en-\nthusiasm.” Firstly, according to the law of\nTransurfing, you are transmitting creative\nenergy that transports you to positive life\ntracks. Secondly, such energy is unable to\ncreate the destructive excess potential, which\nthe balancing forces strive to eliminate. It’s\nnot by accident that different philosophical\nand religious interpretations of life have all\ncome to the same conclusion that love is the\ncreative force responsible for the existence of\nour world. “Love” in this context is referred\nto in its general sense. Of course, the balan-\ncing forces were created by the same power\n209/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 932
  },
  {
    "chunk_full": "that has shaped the world. They strive to\nsupport the order in this world and they can-\nnot be turned against the energy that has\ncreated them.\nFrom Transurfing’s point of view, our habit\nof expressing dissatisfaction with smallest of\nthings is a really bad one and it stops us from\ngetting what we want. And the opposite is\ntrue: the habit of constantly experiencing\nlittle joys, for the most varied and insignific-\nant reasons, is a very good habit and will get\nus what we want. There is only one conclu-\nsion to be made - we must substitute our old\nhabit with the new one.\nHow do you do this? Well, it is all very\nsimple. First of all, as trivial as it may sound,\nany misfortune is a blessing in disguise. If\nyou make it your goal to find something good\nin things that appear negative to you – you\nwill reach your goal without further effort.\nTurn it into a game. If you play it constantly,\n210/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 933
  },
  {
    "chunk_full": "your old habit will quickly be replaced by a\nnew one. This habit will be of great use to\nyou and a total nightmare to destructive\npendulums.\nSecond of all, if something really terrible\nhappens and the very thought of feeling any\nkind of joy seems completely unnatural and\ninappropriate, do as the old King Solomon\ndid. He used to wear a ring with an inscrip-\ntion on the inside that was not visible to oth-\ners. When something bad happened or when\nSolomon\nwould\nfind\nhimself\nin\nserious\ntrouble, he would read the inscription inside\n“This, too, shall pass.”\nThe habit of expressing dissatisfaction has\nbeen developed in humankind much due to\nthe influence of destructive pendulums. With\nnew habits, you’ll be generating positive en-\nergy which will carry you to positive life\ntracks like the flow of a powerful stream.\n211/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 934
  },
  {
    "chunk_full": "Let’s suppose that, having become inspired\nwith the possibilities, you’ve started practi-\ncing the technique of substituting habits.\nWell, I have to tell you that soon you will no-\ntice how you’re practicing this less and less\nregularly and from time to time you simply\nforget that you wanted to change your habits\nin the first place. This is unavoidable because\nthese old habits are deeply rooted in you. As\nsoon as you start slacking off, the pendulum\nwill immediately find a way to upset you, and\nyou won’t even notice that you’ve just fed it\nyour energy. Don’t despair! If your intention\nis strong, you’ll achieve whatever you want\nand the destructive pendulums will, in the\nend, leave you in peace. You just need to re-\nmind yourself about your intention more\noften.\nWe are all guests in this world. Nobody has\nthe right to be the judge of what he himself\ndidn’t create. This affirmation should be un-\nderstood in the light of your relationships\n212/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 935
  },
  {
    "chunk_full": "with the pendulums. As mentioned earlier, if\nyou start acting against the destructive pen-\ndulums that made you dissatisfied in the first\nplace, then you will only be making things\nworse for yourself. You don’t have to be a\nmeek little sheep, but you don’t have to\nopenly confront the world around you either.\nIf the pendulum is acting against you per-\nsonally, you can apply the method of fall\nthrough or try to extinguish it. When it tries\nto get you into a battle with other pendu-\nlums, try to find out whether you really need\nto or not.\nLet’s once again get back to the example with\nthe gallery where an exhibition was not to\nyour liking. Act as if you were at home, but\ndon’t forget that you are just a visitor.\nNobody has the right to judge, but we all\nhave the freedom of choice. The pendulum\nbenefits from you expressing your dissatis-\nfaction, whereas you would benefit from\nsimply\nleaving\nthe\nroom\nand\nchoosing\n213/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 936
  },
  {
    "chunk_full": "another exhibition to look at. I can already\nhear your question: and what if there is\nnowhere to go? Pendulums made you believe\nthat that is the case. This very book is actu-\nally dedicated to the topic of how to get rid of\nthis false limitation.\nDependent Relationships\nIdealizing the world is the other side of dis-\nsatisfaction. Looking at the world through\nrose-colored glasses will make many things\nseem better than they really are. As you\nknow,\nwhen\nyou\nthink\nthat\nthere\nis\nsomething somewhere, when in fact there is\nnot, excess potential is created.\nTo idealize means to overrate, to put on a\npedestal, to worship, to create an idol. Love\nis the force that is creating and directing the\nworld, and it is different from idealization\nbecause it remains passionless in essence, no\n214/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 937
  },
  {
    "chunk_full": "matter how paradoxical this may sound. Un-\nconditional love is a feeling without the right\nof ownership, admiration without worship.\nIn other words, it does not create a depend-\nent relationship between the one that loves\nand his object of affection. This simple for-\nmula will help to determine where the feel-\ning ends and idealization begins.\nImagine that you are walking around in a\nmountain valley that is overflowing with\ngreen plants, lustrous trees and flowers. You\nare admiring this wonderful landscape, tak-\ning in the aroma of this fresh, vibrant air and\nyour soul is completely happy and peaceful.\nThis is love.\nThen you start picking the flowers: you tear\nthem out from their beds and you crush\nthem with your hands, without thinking that\nthey are alive. Then the flowers slowly die.\nLater on it occurs to you that you could make\nperfume and cosmetics out of flowers, or that\n215/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 938
  },
  {
    "chunk_full": "you could simply sell them to others, or\nmaybe you decide to create a cult of flowers\nand worship them as idols. This is idealiza-\ntion, because in every case, dependent rela-\ntionships are created between you and the\nobject of your former love – the flowers.\nNothing is left from the love that you once\nfelt when you were simply enjoying the\nscenery, back there in the mountain valley.\nCan you feel the difference between these\ntwo situations?\nSo, love generates positive energy that car-\nries you to a corresponding life track, while\nidealization creates excess potential, giving\nrise to the balancing forces that then strive to\neliminate this excess potential. The action of\nthe balancing forces is different in each case,\nbut the result is the same. Basically, it can be\ncharacterized as “removing the halo”. This\nalways happens, if you idealize something or\nsomeone. And, depending on the object and\nthe level of idealization, you get a strong or a\n216/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 939
  },
  {
    "chunk_full": "weak result – but it will always be a negative\none. Thus, the balance will be restored.\nIf love turns into a dependent relationship,\nthen an excess potential is unavoidable. The\ndesire to have what you do not have will cre-\nate a “change of energy pressure”. Depend-\nent relationships are identified by set condi-\ntions like “if you do this… - then I will do\nthis…” You can find plenty of similar ex-\namples. “If you love me, then you’ll abandon\neverything and come away with me to the\nworld’s end. If you won’t marry me, then it\nmeans that you don’t love me. If you praise\nme, then I’ll be friends with you. If you won’t\ngive me your toy shovel, then I’ll kick you out\nof the sandbox.” And so on.\nThe\nbalance\nis\nalso\ndisturbed\nwhen\nsomething is compared or contrasted to\nsomething else. “We are in this way, and they\nare in a different way!” For example, nation-\nal pride: comparing the nation – with what\n217/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 940
  },
  {
    "chunk_full": "nations? The feeling of inferiority: compar-\ning yourself – to whom? If something is put\nin contrast to something else, then the balan-\ncing forces will most definitely start elimin-\nating the potential – positive or negative, it\ndoesn’t matter. Because you are the one cre-\nating the potential, the action of these forces\nwill first of all be directed against you. Action\nis directed either at “pulling apart” the con-\ntradicting parts, or at uniting them in a com-\nmon agreement or confrontation.\nAll conflicts are based on comparisons and\ncontradictions. At first, fundamental declara-\ntions are made: “They’re not like us.” Further\non, it develops on its own. “They have more\nthan us – we need to take it away from\nthem.” “They have less than us – we must\ngive it to them.” “They are worse than us –\nwe must change them.” “They are better than\nus – we have to wrestle with ourselves.”\n“They act in a different way than we do – we\nneed to do something about that.” All of\n218/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 941
  },
  {
    "chunk_full": "these different comparisons will one way or\nanother lead to a conflict – starting with per-\nsonal, emotional discomfort and ending with\nwars and revolutions. The balancing forces\nwill strive to eliminate the emerged contra-\ndiction with the help of reconciliation or con-\nfrontation. But, because in the latter case\npendulums can always get a chunk of energy,\nthey try to manipulate things so that a con-\nfrontation will take place.\nAnd now, let’s look at some examples of\nidealizations and their consequences.\nIdealizing\nand\nOverestimation\nOverestimation is the attribution of personal\nqualities to someone who does not have\nthese qualities. On a mental level, this ap-\npears in the shape of illusions that seem\nharmless at first. But on the energy level,\n219/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 942
  },
  {
    "chunk_full": "excess potential is created. Potential is cre-\nated everywhere where there is an overflow\nof some kind of quantity or quality. Overes-\ntimation is exactly that – creating mental\nmodels of qualities that are not there. There\nare two possible alternatives here. The first\nalternative is when the place is filled. That is\nwhen there is a specific individual who has\nqualities attributed to him that are not his\nown. In order to eliminate this discrepancy,\nthe balancing forces must produce a counter-\nweight.\nFor example, a romantic and dreamy young\nman imagines his beloved to be “an angel of\npure beauty.” But in reality it turns out that\nshe is quite the material girl, she likes party-\ning and is not at all interested in sharing the\ndreams of the young man in love. In any oth-\ner case when a man creates an idol and puts\nit onto a pedestal, eventually, the halo will\ncome off.\n220/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 943
  },
  {
    "chunk_full": "In connection with our topic, let me intro-\nduce the remarkable story about Karl May,\nan author of several books about the Wild\nWest and the creator of such heroes as Old\nShatter-hand, Winnetou and others. Karl\nMay wrote all his novels in first person,\nwhich made the reader believe that the au-\nthor has actually been to the Wild West and\nhas taken part in all of the events that he ac-\ncounts for in the book, therefore he must be\na truly remarkable person worthy of admira-\ntion. The works of Karl May are so real and\nvivid that an illusion is created so complete\nthat it seems to the reader that only someone\nthat has actually participated in described\nevents could have written about them. You\nread the books of Karl May and it is as if you\nare watching a movie. The stories in his\nbooks are so compelling that Karl May has\nbeen called “The German Dumas4”.\nThe many fans of Karl May were totally con-\nvinced\nthat\nhe\nwas\nthat\nsame\nfamous\n221/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 944
  },
  {
    "chunk_full": "cowboy, the Old Shatter-hand, just as he had\nintroduced himself in his books. His fans\nwouldn’t allow any other conclusions to be\nmade. After all, they have found an object of\nadmiration and imitation and the fact that\ntheir idol was living in the vicinity made it\neven more interesting. Imagine their sur-\nprise when it became known that Karl May\nhad never been to America and, what’s more,\nhe wrote several of his books while sitting in\njail. Thus, the halo came off and Karl May’s\ngreatest fans became his worst enemies.\nWell, and who is the guilty one here? After\nall, they created their idol and established a\ndependent relationship – “You can be our\nhero, only as long as everything in the book\nis true.”\nThe second alternative, when there is no ob-\nject to attribute the artificially created illu-\nsions to, an idealizing person will make up\ncastles in the sky and pretty daydreams. The\ndreamer has his head in the clouds, trying to\n222/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 945
  },
  {
    "chunk_full": "escape the unattractive reality. By doing so,\nhe is creating an excess potential. The balan-\ncing forces in this case, in attempt to destroy\nthe castles in the sky, will constantly be con-\nfronting the romantic with the harsh reality.\nEven if he could attract a mass of people with\nhis ideas and create a pendulum, nonetheless\nhis utopia is doomed, because an excess po-\ntential has been created on an empty spot,\nand sooner or later the balancing forces will\nmake this pendulum stop.\nOne more example of when the object of\noverestimation exists only in the ideal world.\nLet’s suppose a woman is drawing up a pic-\nture of the ideal husband in her mind. The\nmore convinced she is that he must be ex-\nactly in this way or that, the greater the ex-\ncess potential will be. And only a guy with\nthe opposite qualities to those of the perfect\nhusband will be able to destroy this excess\npotential. And then the woman can only\nwonder “What in the world was I thinking?”\n223/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 946
  },
  {
    "chunk_full": "The opposite is true as well. If a woman act-\nively hates drunkards and rude people, it is\nalmost as if she falls into a trap, getting to-\ngether with an alcoholic or a rude fellow. You\nget what you really cannot stand, and this is\nbecause you are radiating thought energy on\nthe frequency of the disliked object, creating\non top of it all an excess potential. Life often\nbrings together completely different people\nthat really seem to be unsuitable for each\nother. This is how the balancing forces are\ntrying to extinguish the excess potential, by\nmaking the opposites of excess potential\nattract.\nThe action of the balancing forces is espe-\ncially evident in children, because children\nare more sensitive than adults are to any\nchanges on the energy level, and thus they\nact naturally. If a child is given too much\npraise, he will immediately start acting up\nout of spite. And if you begin to ingratiate\nyourself with him, he will start despising you\n224/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 947
  },
  {
    "chunk_full": "or, at least, he will never respect you. If you\nuse all your strength in an attempt to raise\nthe toddler to be a well-behaved and obedi-\nent boy, then most probably he will end up\nhanging out with some dodgy street gang. If\nyou were to try to make some kind of genius\nout of him, he’ll probably lose all interest in\nschool and studying. And the more you keep\ndragging your child to all kinds of after\nschool activities and societies, the more\nlikely it is that he’ll grow up to be a dull\nperson.\nThe very best way of bringing up and relating\nto children (and not only to children), which\nwon’t result in any excess potential, is to\ntreat them like guests. In other words, you\nshould be attentive to them, show them re-\nspect and give them freedom of choice, but\nyou shouldn’t allow them walking all over\nyou either. As much as you are a guest in this\nworld, so you should treat the children as\nguests. If you accept the rules of the game\n225/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 948
  },
  {
    "chunk_full": "and don’t run from one extreme to another,\nyou are allowed to choose anything this\nworld has to offer.\nHaving a positive attitude towards others is\nas widespread as having a negative attitude.\nThere is some balance in this case. There is\nlove and there is hate. A smooth positive atti-\ntude will not result in any excess potential. A\npotential is formed when there is a notice-\nable displacement relative to the nominal\nvalue. Unconditional love can be considered\na zero on the scale of displacement. As you\nknow, unconditional love doesn’t give rise to\ndependent relationships and it doesn’t create\nany excess potential. But that type of love in\nits purest form is rare. Basically, a dash of\neach of the following is added to pure love:\nthe right of possession, dependence and\noverestimation. It’s hard to refuse the right\nof possession, because possessing your ob-\nject of love is completely natural and rather\n226/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 949
  },
  {
    "chunk_full": "normal, as long as it doesn’t lead to either of\nthe following two extremes.\nThe first extreme is the desire to have some-\nbody you love who doesn’t belong to you at\nall and who doesn’t even suspect your desire.\n(You understand, of course, that I am not\nonly talking about the physical aspect of pos-\nsession.) This is a classic case of unreciproc-\nated love. Unanswered love has always given\nrise to a lot of suffering. However, the mech-\nanism behind this is not as simple as it may\nseem. Let’s go back to the example with the\nflowers. So you love walking among them,\nadmiring them and it probably never oc-\ncurred to you whether or not they love you.\nTry to imagine – what do the flowers think of\nyou? Several not too pleasant suggestions\nmight appear in your mind, such as: fear,\ndanger, hostility or indifference. And why\nshould they love you, after all? Or say, you’re\nburning with desire to hold them in your\nhands, but it’s forbidden – they grow in a\n227/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 950
  },
  {
    "chunk_full": "public\nflower-bed\nor\nare\ntoo\nexpensive.\nThat’s it. Love is already out of the picture,\nbut what remains is a dependent relationship\nand negative emotions that have already\nstarted creeping in on you.\nAnd so, the object of your love is in one place\nwhile you are in another and you want to\npossess the object of your love. In other\nwords, you are creating an excess energy po-\ntential. You could assume that this potential\nwould pull the desired object towards you,\njust like air masses, which move from areas\nof high pressure to areas of low pressure. Far\nfrom it! The balancing forces don’t care in\nwhich way a balance is achieved. Thus, they\ncan pick a different way of doing things –\nlike moving the object of your love further\naway and neutralizing you - that is, breaking\nyour heart. In addition to everything else,\neven when you’ll be experiencing small fail-\nures, you will be more and more prone to\ndramatize the situation (“she/he doesn’t love\n228/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 951
  },
  {
    "chunk_full": "me!”). Therefore, such thoughts will drag\nyou over onto a life track where mutual love\nwill almost be impossible.\nThe stronger the desire to possess someone\nyou love, or for your feelings to be reciproc-\nated, the stronger will be the actions of the\nbalancing forces. Of course, if they choose an\noption that brings you closer to your loved\none, then the story will have a “happy end-\ning”. It is easy to determine the direction of\nthe balancing forces when you’ve only star-\nted to realize that you are in love: if you are\nreally worried about whether your love will\nbe reciprocated or not, and if something isn’t\nright from the beginning of the relationship,\nthen you know that you need to radically\nchange your tactics. More precisely, you\nneed to start loving without demanding a re-\nward in return. Only then, the unstable fluc-\ntuations of the balancing forces could be\npulled over onto your side and thus, begin to\nwork for you. Otherwise, the situation will\n229/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 952
  },
  {
    "chunk_full": "break out of control like an avalanche, and\nthen it will be almost impossible to change\nanything.\nThere is only one conclusion: if you want\nyour tender feelings to be reciprocated, then\nyou simply need to love and not try to be\nloved. Thus, firstly no excess potential will be\ncreated, which means you would not have to\nworry about the fifty percent chance that the\nbalancing forces will work against you. Se-\ncondly, if you won’t strive for reciprocity, you\nalso won’t have those uncontrollable dramat-\nic thoughts about unanswered love – and\nyour radiation won’t drag you to the corres-\nponding life tracks. On the contrary, if you\nsimply love without the right of possession,\nthen the parameters of your radiation will fit\nthose life tracks where reciprocity exists.\nAfter all, there are no dependent relation-\nships in reciprocated love. If you already\npossess something, there is no point in get-\nting upset about the right of possession. Just\n230/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 953
  },
  {
    "chunk_full": "imagine how much your chances of reciproc-\nated love will increase, simply because you\nhave refused the right of possession! Besides,\nunconditional love is extremely rare, and\nthat alone is already intriguing and attract-\nive. Wouldn’t it be nice if someone loved you\njust like that without demanding anything in\nreturn?\nThe second extreme of the right of posses-\nsion is, of course, jealousy. Even in this case,\nthe balancing forces have two ways of acting.\nIf the object of love belongs to you already,\nthen the first alternative is to bring you even\ncloser. In fact, some people even like it when\ntheir partner is jealous, to a certain degree of\ncourse. However, the balancing forces have\none more alternative, and that is to ruin that\nwhich gave rise to jealousy in the first place\n– namely love. Furthermore, the stronger the\njealousy, the deeper will be the grave of your\nlove. It would be like going from enjoying the\n231/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 954
  },
  {
    "chunk_full": "aroma of fresh flowers to producing perfume\nfrom them.\nEverything we’ve talked about here relates to\nboth men and women. But this is not the end\nof it. We’ll return to the question of overes-\ntimation and idealization when we’ll be look-\ning\nat\nother\nconcepts\nof\nTransurfing.\nEverything is so simple and, at the same\ntime, so complicated. Complicated, because\nsomebody in love is unable to reason logic-\nally and these recommendations will prob-\nably be useless. Well, I in turn won’t get up-\nset because of that, as I refuse the right to\npossess your gratitude.\nContempt and Vanity\nJudging other people is one of the more ef-\nfective ways to upset the balance, in particu-\nlar if in your judgment you despise other\npeople. On the energy plane, there are no\n232/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 955
  },
  {
    "chunk_full": "good or bad people. There are only those\nwho obey the laws of nature and those who\nupset “the status quo”. In the end, the latter\nwill always fall under the influence of forces\nthat strive to restore the disturbed balance.\nOf course, there are many situations where a\nperson deserves a certain judgment. Does it\nhave to be yours? This is not an idle ques-\ntion. If a man has brought harm specifically\nto you, then above all, by so doing, he has\ndisturbed the balance and therefore you are\nnot the source of an unhealthy potential, but\nan instrument of the forces that strive to re-\nstore the balance. Thus, the disturber of the\npeace will get what he deserves if you tell\nhim everything you think of him, or even do\nsomething specific about the situation (with-\nin reason, of course). However, if the object\nof your judgment has not done anything\nwrong, then you do not have the right to lay\nany blame on him.\n233/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 956
  },
  {
    "chunk_full": "Let’s look at this question from a strictly\nbusiness point of view. You’ll agree that it’s\ncompletely pointless feeling hatred towards a\nwolf that tore a sheep to pieces, if you are\nwatching it on TV. The sense of justice is\nconstantly pushing us towards judging dif-\nferent people. However, this quickly be-\ncomes a habit and many people over the\nyears turn into professional prosecutors. In\nthe majority of cases, you don’t have a clue\nwhat made the person behave the way he\ndid. Maybe you would have acted even\nworse, if you were in his place?\nSo, as a result of such condemnation, you are\ncreating excess potential around yourself and\nwhy not? After all, that the worse the accused\none, the better must you be. Since he has\nhooves and horns, you must be an angel.\nWell, since you don’t have any wings yet,\nforces will get involved, striving to restore\nthe balance. The methods of these forces will\nbe different depending on the situation. But,\n234/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 957
  },
  {
    "chunk_full": "basically, the result will always be the same:\nyou get a flick on the nose. Depending on the\nforce and type of your judgment, this hit\nmight be either barely noticeable, or so\nstrong that you subsequently find yourself on\none of the worst life tracks.\nYou can probably come up with a long list of\npossible\ncondemnations\nand\ntheir\ncon-\nsequences but for clarity’s sake, I’ll list a few\nexamples.\nNever despise people, no matter what. This\nis the most dangerous form of condemna-\ntion, because you could find yourself in the\nplace of the despised person, due to the ac-\ntion of the balancing forces. To them, this is\nan easier and more direct method of restor-\ning lost harmony. Do you despise bums and\npoor people? You could lose your home and\nyour money and then the balance would be\nrestored. Do you despise people who have a\nphysical disability? Not a problem – an\n235/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 958
  },
  {
    "chunk_full": "accident can be arranged for you too. Do you\ndespise alcoholics and drug addicts? You\ncould easily find yourself in their place. After\nall, these people are not born that way – dif-\nferent circumstances in life have forced them\ninto becoming who they are now. So why\nshould these circumstances escape you?\nNever condemn your colleagues at work for\nwhatever reason. In the best case, you’ll\nmake the very same mistakes. In the worst\ncase – a conflict may spring up that won’t\nbring you anything good. You could be fired,\neven if you are absolutely right.\nIf you condemn another person just because\nyou don’t like him or the way he is dressed,\nyou will find yourself on the ladder of “good\nand bad”. Only you will be one step below\nhim, because you are emanating negative\nenergy.\n236/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 959
  },
  {
    "chunk_full": "If a person prides himself in his successes or\nis in love with himself there’s nothing wrong\nwith that. A general love for oneself is self-\nsufficient and therefore doesn’t bother any-\none. The balance is disturbed only in the case\nwhen someone with an inflated selfesteem\nhas a scornful attitude towards the weak-\nnesses of others, their flaws or simply their\nmodest achievements. Then love and pride\nin oneself turns into vanity. And again the\nresult will be a flick on the nose by the balan-\ncing forces.\nContempt and vanity are human vices. An-\nimals don’t know what these are. They are\nguided by expedient intention and thus, ful-\nfill the will of perfect nature. Wild nature is\nmore perfect than is the thinking man. A\nwolf, like all predators, does not feel hatred\nor contempt toward its prey. (Try to feel\nhatred or contempt towards a hamburger.)\nBut people do build their relationships to\none another mainly on excess potential. The\n237/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 960
  },
  {
    "chunk_full": "greatness of plants and animals consists in\nthe fact that they are not aware of their\ngreatness.\nConsciousness\nhas given\nman\nmany useful advantages, but also harmful\ngarbage such as vanity, contempt, the com-\nplexes of guilt and inferiority.\nSuperiority\nand\nInferiority\nThe feelings of superiority or inferiority are\nboth dependent relationships in their purest\nform. Your qualities are being compared to\nthe qualities of others, thus inevitably an ex-\ncess potential is created. On the energy level,\nit’s not important whether you express your\nsuperiority publicly or simply congratulate\nyourself in secret. There is no need for me to\ntry to prove that public display of superiority\nwon’t bring you anything, except resentment\nfrom the people around you. When you are\n238/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 961
  },
  {
    "chunk_full": "comparing yourself to others to your advant-\nage,\nthen\nyou\nare\nstriving\ntowards\nan\nartificial self-assertion at the expense of oth-\ners. Such a striving always creates a poten-\ntial, even if it is simply a shadow of the ar-\nrogance that isn’t fully expressed. The action\nof the balancing forces in this case will al-\nways be a flick on the nose.\nIt’s obvious that when comparing oneself to\nthe surrounding world, a man is trying to\nprove his importance. But the actual sel-\nfassertion you get by comparing yourself to\nothers is illusory. In a similar manner, a fly\nwould try to beat its way through a window\nglass, while there is an open window right\nbeside it. When a man strives to tell the\nworld of his importance, energy is spent on\nsupporting\nan\nartificially\ncreated\nexcess\npotential. Self-perfection, on the other hand,\ndevelops real virtues – the energy is not\nspent in vain and a harmful excess potential\nis not created.\n239/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 962
  },
  {
    "chunk_full": "It may appear to you that the energy spent\non comparing yourself with others is quite\ninsignificant. In reality, there is enough en-\nergy to support a rather strong potential.\nHere, the intention to direct one’s energy in\none way or another plays the main part. If\none’s aim is the wish to acquire virtues, then\nthis intention will move the person forward\ntowards the aim. If, however, one’s aim is to\ndemonstrate all his “regalia” to the world,\nthen the person will be like a car stuck in the\nmud – pushing and tugging and not getting\nanywhere, thus creating an irregularity in the\nenergy field. The world will be “stunned”\nwith the display of regalia and as a result, the\nbalancing forces will come into play. They do\nnot have much choice: they could either liven\nup the fading colors of the surrounding\nworld, or extinguish the shine of an inappro-\npriate star. The first alternative is, of course,\ntoo labor consuming. Only the second altern-\native remains. The balancing forces have a\n240/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 963
  },
  {
    "chunk_full": "number of ways of doing this. For them, it’s\nentirely unnecessary to deprive the ambi-\ntious person of his regalia. It’s enough to\npresent him with an annoying nuisance, in\norder to knock the stuffing out of him.\nWe often perceive all nuisances, problems\nand obstacles to be the integral parts of this\nworld. No one is surprised that all of these,\nbeginning with the tiniest problem and end-\ning with very serious ones, are necessary\ncompanions of every person throughout his\nlife. We are all used to thinking that this is\nour world. In fact, having trouble is an an-\nomaly, an abnormal phenomenon. Where\ntroubles come from and why they happen to\nyou are things that are often impossible to\nfigure out using pure logic. It turns out that\nthe majority of troubles, one way or another,\nare brought forth by the actions of balancing\nforces, which are working at eliminating ex-\ncess potential that you or people around you\nhave created. You don’t realize that you have\n241/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 964
  },
  {
    "chunk_full": "created this excess potential and accept your\nproblems as an unavoidable evil and don’t\nunderstand that this is simply the work of\nthe balancing forces.\nYou can free yourself from most of your\nproblems if you free yourself from the im-\nmense efforts that you are directing at sup-\nporting excess potential. A huge amount of\nenergy is not only spent in vain, but it is also\nused to turn the balancing forces in such way\nthat the result becomes directly opposite to\nyour intentions. Therefore, you must simply\nstop beating your head against the window\nglass, like the fly above, and re-direct your\nintention to developing your virtues instead,\nwithout worrying about your position on the\nladder of superiority. Having freed yourself\nfrom the heavy preoccupation with your own\nimportance, you will also free yourself from\nthe influence of the balancing forces. You\nwill have fewer problems and become more\nand more confident in your own powers.\n242/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 965
  },
  {
    "chunk_full": "However, you must keep away all thoughts\nabout you being able to control or manipu-\nlate the world. Regardless of your position\non the social ladder, having taken the place\nof the “almighty” you will definitely lose. An\nattempt to change the surrounding world\nwill disturb the balance. Active interference\nwith the workings of the world will always af-\nfect the interests of a majority of people to a\ncertain degree. Transurfing allows you to\nchoose a destiny without stepping on the\ntoes of others. This is much more effective\nthan to forge ahead, trying to overcome all\nobstacles in your path. Fate is truly in your\nhands, but only in the sense that you were\ngiven the ability to choose it and not to\nchange it. Many people have suffered defeat\nwhen acting as if they were the creators of\nfate in the literal sense. There is no place for\nbattles in Transurfing. Thus, with a sigh of\nrelief, you can “bury the hatchet of war.”\n243/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 966
  },
  {
    "chunk_full": "On the other hand, refusing superiority has\nnothing to do with self-destruction. Belittling\none’s virtues is the other side of the superior-\nity complex. On the energy level, whether\nyou create an excess potential with a plus or\na minus sign is not important. The size of the\ncreated potential is directly proportional to\nhow much a person’s evaluation of the world\ndiffers from reality. Once the balancing\nforces encounter somebody’s attributed im-\nportance, they will act in such a way as to re-\nmove it from its pedestal. In the case of low\nself-esteem, they would force a person to try\nto raise his falsely underestimated virtues.\nThe balancing forces usually act in a straight-\nforward way and they do not really care\nabout the subtleties of human relationships.\nThus, a man starts behaving unnaturally,\nwhich all the more highlights what he is try-\ning to hide.\nFor example, teenagers can behave in a defi-\nant and disrespectful way, and by doing so,\n244/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 967
  },
  {
    "chunk_full": "they are simply trying to make up for their\ninsecurity. Shy people could be acting overly\noutgoing or impudently, in order to hide\ntheir shyness. People with low self-esteem,\nwanting to show the better sides of them-\nselves, can behave in an inhibited or affected\nmanner. And so on. In any case, fighting\nyour hang-ups will bring consequences that\nare by far more unpleasant than the hang-up\nitself.\nAs you understand by now, all these at-\ntempts to fight one’s weaknesses and flaws\nare in vain. It’s hopeless trying to fight low\nself-esteem. The only way of avoiding its\nconsequences is to eliminate the hang-up it-\nself. However, it’s actually quite difficult to\nget rid of it. Trying to persuade yourself that\neverything is great with you is also pointless.\nYou won’t be able to fool yourself. The meth-\nod of using “slides” will help you in this task,\nand we will get acquainted with it a little bit\nlater.5\n245/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 968
  },
  {
    "chunk_full": "At this point, it’s enough to simply under-\nstand that a preoccupation with one’s own\nweaknesses and flaws, in comparison to the\nvirtues of others, works in the same way as\nthe desire to show off one’s relative superior-\nity. The result will be the opposite of your in-\ntention. Don’t be imagining that everyone\naround is attributing the same significance to\nyour deficiencies as you do yourself. Actu-\nally, everyone is preoccupied only with them-\nselves, therefore you can easily throw this gi-\nant weight off your back. Excess potential\nwill then disappear, the balancing forces will\nstop aggravating the situation, and energy\nwill be released.\nIt is not a question of fighting your flaws or\ntrying to hide them, but rather of compens-\nating for them with other qualities. Lack of\nbeauty can be compensated with charm.\nThere are people who are physically quite\nunattractive, but as soon as they start talk-\ning,\ntheir\nlistener\nbecomes\ncompletely\n246/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 969
  },
  {
    "chunk_full": "enthralled. Physical flaws are compensated\nwith self-confidence. Just remember how\nmany great people in history were rather un-\nattractive physically! Inability to communic-\nate with others can be replaced with the abil-\nity to listen. There is a saying: “Everyone is\nlying, but it doesn’t matter, because no one is\nlistening to anyone anyway.” Your eloquence\nmight interest people, but only as a last re-\nsort. Everyone, just like you, is preoccupied\nexclusively with themselves and their own\nproblems – therefore, a good listener to\nwhom you could pour your heart out, is a\ntrue find. I can give one piece of advice to\nshy people: protect this quality of yours, like\nyou would a treasure! Believe me shyness\nhas a hidden charm to it. Once you decide to\nstop fighting your shyness, it will no longer\nbe a clumsy quality of yours and you will no-\ntice how people will start liking you.\nHere is another example of compensating for\nyour less flattering sides. The imagined need\n247/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 970
  },
  {
    "chunk_full": "to “be cool” often pushes people to imitate\nothers who have achieved the status of a\n“cool guy”. Mindless imitation of somebody\nelse’s script creates nothing more than a par-\nody. Everyone has his or her own script. You\njust need to choose your own credo and live\nby it. To imitate others in an attempt to gain\nthe “cool” status is just like using the method\nof a fly beating against the window glass. For\nexample, the leader in a group of teenagers is\nthe one that lives according to his credo. The\nleader could only have become one because\nhe freed himself from the obligation to ask\nothers about how he should act. He doesn’t\nneed to imitate anyone, he simply has a\nworthy opinion of himself, he knows what he\nis doing, he doesn’t need to suck up to any-\none and he doesn’t need to prove anything to\nanybody. Hence, he is free from excess po-\ntential and gets the deserved advantage. In\nany group, the individuals that become lead-\ners are the ones that live according to their\n248/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 971
  },
  {
    "chunk_full": "own credo. If a person has freed himself\nfrom the weight of excess potential, he has\nnothing more to defend – he is internally\nfree, self-sufficient and has more energy than\nthose around him. These advantages, in\ncomparison to other members of the group,\nmake him a leader.\nCan you see where the open window is loc-\nated? Maybe you’re thinking, “none of this is\nabout me, I don’t suffer from any hangups”.\nDon’t try to fool yourself. Every person to a\ngreater or lesser extent tends to create excess\npotential around his persona. But if you fol-\nlow the principles of Transurfing, superiority\nand inferiority complexes will simply disap-\npear from your life.\n249/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 972
  },
  {
    "chunk_full": "The Desire to Have and\nNot to Have\n“If you want a lot – you’ll only get a little.”\nThis little children’s taunt has some truth to\nit. Only, I would re-phrase it this way: “The\nmore you want, the less you’ll get.” When\nyou want something so much that you are\nready to risk everything you have in order to\nget it, you are creating a huge excess poten-\ntial, which upsets the balance. The balancing\nforces will throw you onto a life track where\nthe desired object doesn’t exist at all.\nIf we were to describe what the behavior of a\nman that is obsessed with desire looks like\non the energy level, it would be something\nlike this. A wild boar is trying to catch a blue\nbird. He wants the bird so badly that he is\neven drooling just thinking about it, loudly\nsnorting\nand rootling about impatiently.\nNaturally, the bird flies away. If the hunter\n250/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 973
  },
  {
    "chunk_full": "had simply been strolling nearby the bird,\nnot paying any attention to it, he would have\nhad a pretty good chance of grabbing it by\nthe tail.\nWe could highlight three forms of desire. The\nfirst form is when a strong desire turns into a\nstrong determination to have what is desired\nand to act accordingly. Then the desire is ful-\nfilled. Moreover, the potential of the desire\ndisperses into space, because its energy is\nspent on performing the action. The second\nform\nis\nthe\ninactive,\ntormenting\ndesire,\nwhich represents excess potential in its\npurest form. It hangs there in the energy\nfield and, in the best case, it is simply wast-\ning the energy of the sufferer, while in the\nworst case, attracts all kinds of problems.\nThe third form of desire, when a strong de-\nsire turns into dependence from the object of\nthat desire, is the most insidious one. Attach-\ning great significance to the desired object\n251/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 974
  },
  {
    "chunk_full": "automatically creates a dependent relation-\nship, which gives rise to a strong excess po-\ntential. And a strong excess potential will\nautomatically summon balancing forces just\nas strong to extinguish it. Usually, people\nmake up following conditions: “If I achieve\nthis, my situation will improve dramatically”,\n“If I don’t achieve this, my life will lose all\nmeaning”, “If I do this, I’ll show myself and\neverybody else what I’m worth”, “If I don’t\ndo this, I’m worthless”, “If I could get this, it\nwould be great”, “If I don’t get this, it will be\nvery bad”. And so on.\nOnce you become dependent of the object of\nyour desire, you are drawn into such a viol-\nent whirlpool that you would simply get ex-\nhausted struggling to possess that object. In\nthe end, you will not achieve anything and\nyou will just abandon your desire. The bal-\nance is restored and the balancing forces are\nabsolutely indifferent to your suffering in\nthis situation. And all of this happened just\n252/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 975
  },
  {
    "chunk_full": "because of your strong need to have that de-\nsire fulfilled. The desire remained on one\nside of the scales while everything else was\non the other.\nYour wish can be granted only if it takes on\nthe first form, when the desire is trans-\nformed into pure intention, free from excess\npotential. We are all used to paying for\neverything in this world nothing is free. But,\nin reality, we are only paying off our debts\nfrom\nexcess\npotential\nthat\nwe\ncreated\nourselves. Everything is free in the space of\nvariations. Since we are already using these\nterms, then we can treat the absence of im-\nportance and dependent relationships as a\nkind of payment. You can only buy “fulfilled\nwishes” using this payment. To transfer to a\nlife track where the desired object is trans-\nformed into reality, the only thing necessary\nis the energy of pure intention. We’ll talk\nabout intention later. Now, we’ll only note\nthat pure intention is the desire and action\n253/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 976
  },
  {
    "chunk_full": "combined into one without any excess im-\nportance. For example, your unrestricted in-\ntention to go down to the local newspaper\nstand for a magazine is pure intention.\nThe more you value a certain event, the more\nlikely it is that things will fail or go wrong. If\nyou attribute great importance to what you\nhave, and cherish it dearly, then the balan-\ncing forces will most probably take it away. If\nwhat you want to have is way too important\nfor you, then don’t be hoping to get it. It’s ne-\ncessary to lower the bar of significance, the\nbar of importance.\nFor example, you’ve got a brand new car and\nyou’re absolutely crazy about it: you blow off\nlittle specks of dust, you take care of it, pro-\ntect it carefully, you’re terrified of any pos-\nsible little scratch – basically, you adore and\nworship your car. As a result, an excess po-\ntential is created. After all, you were the one\nto attribute such great importance to your\n254/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 977
  },
  {
    "chunk_full": "car. But in fact, its importance is equal to\nzero on the energy plane. And unfortunately,\nas a result, the balancing forces will soon\nfind some schmuck to smash up your car. Or,\nbeing overly careful yourself, you will bump\ninto something or other. Once you simply\nstop worshiping your car and start treating it\nlike an ordinary object then the risk of\nsomething happening to it will be signific-\nantly minimized. Treating something like an\nordinary object doesn’t at all mean to neglect\nit or to be careless. You could be taking per-\nfect care of your car, without making an idol\nout of it.\nThe desire to have something has yet another\naspect to it. There is the opinion that if you\nwant something very badly, then you can get\nwhatever you want. It could seem that a very\nstrong desire would bring you onto a life\ntrack where it would be fulfilled. However,\nthat is not the case. If your desire has trans-\nformed into dependence, into some kind of\n255/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 978
  },
  {
    "chunk_full": "psychosis or you are hysterically striving to\nobtain something, regardless of the cost,\nthen somewhere deep down inside you, you\ndon’t believe in the fulfillment of your desire.\nConsequently, you are transmitting thought\nenergy with “strong interference.” If you\ndon’t believe in the fulfillment of your desire,\nyou will try as hard as you can to convince\nyourself that the opposite is true. Hence, you\nare forcing the excess potential even higher.\nThere is a risk of spending your entire exist-\nence on your “life-work”. The only thing to\nbe done in this case is to reduce the signific-\nance of your aim. Go for it, in the same way\nas if you would go to a newspaper stand for a\nmagazine.\nA strong desire to avoid something is a logic-\nal continuation of your dissatisfaction with\nthe\nsurrounding\nworld\nor\nyourself.\nThe\nstronger the need, the more powerful the ex-\ncess potential will be. The more you don’t\nwant something, the more likely it is that you\n256/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 979
  },
  {
    "chunk_full": "will be confronted with it. The balancing\nforces are indifferent to the way the balance\nis achieved. And there are two ways of\nachieving the balance: one is to either get\nyou away from whatever it is you are trying\nto avoid, the other way is to force you to get\ninto contact with it. It’s better to consciously\nstop trying to avoid it, so that no excess po-\ntential is created. But that’s not all there is to\nit. When you are thinking about what you\ndon’t want, you are emanating energy on the\ntrack where it will definitely happen. You al-\nways get what you actively don’t want.\nHere is an example to illustrate what actually\nhappens\nwhen\nyou\nactively\ndon’t\nwant\nsomething. A man is attending a grand re-\nception at the embassy, where everything is\npompous, refined and delicate. Then sud-\ndenly the man begins waving his hands\nwildly about, stamping his feet and scream-\ning desperately that he doesn’t want to be\ntaken\nout\nof\nhere\nthis\nvery\nmoment.\n257/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 980
  },
  {
    "chunk_full": "Naturally, security guys appear and grab the\nweird fellow, who is resisting and crying, but\nhe is nonetheless escorted out immediately.\nThis is, of course, a rather exaggerated pic-\nture of reality, but on the energy level this is\nexactly what happens, down to the intensity\nand proportions of the forces involved.\nLet’s look at one more example. Suppose that\nin the middle of the night you wake up from\nthe noise your neighbors are making. You\nreally want to sleep, you have to go to work\ntomorrow, but it seems like your neighbor’s\nparty is just getting started. The more you\nwould want them to shut up, the more likely\nit is that the party will go on. The angrier\nyou’ll get the more violent and noisy the\nparty will become. If you start hating them to\na certain degree, it’s guaranteed that such\nnights will be more and more frequent. To\nsolve this problem, you can apply the meth-\nod of making the pendulum fall through or\nextinguishing it. You will extinguish the\n258/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 981
  },
  {
    "chunk_full": "pendulum if you’ll see the situation as ironic.\nAnd you could also simply ignore the situ-\nation, without displaying any emotion or in-\nterest in it. Then the pendulum will fall\nthrough and no potential will be created.\nTake comfort in the awareness that you have\na choice and you know how to use it. Soon\nthe neighbors will settle down. This is how it\nall works, so you can go ahead and test it.\nNow you are able to analyze any past situ-\nation and determine whether you overestim-\nated the significance of something and what\nproblems you’ve gotten as a result. If things\nare absolutely terrible, never mind the over-\nestimated significance for now, shake off\nyour dependent attitude and start persist-\nently transmitting some positive energy. The\nworse it is now, the better. This is how you\ncould assess the situation if you feel that\nyou’ve suffered a great defeat. Be happy! In\nthis situation, the balancing forces are on\nyour side because their job is to compensate\n259/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 982
  },
  {
    "chunk_full": "bad with good. It can’t be bad all the time,\njust as it can’t be good all the time. No one\ncan spend their whole life flying on the wave\nof happiness. So, this is what a really bad\nsituation would look like on the energy level,\nif you started to make some conscious\nchanges:\nyou\nwere\nattacked,\ncursed\nat,\neverything you had on you was taken, you\ngot beaten up, then all of the sudden you\nwere given a bag full of money. The greater\nyour loss was, the more money you’ll find in\nthe bag.\nFeeling Guilty\nFeeling guilty is an excess potential in its\npurest form. The thing is that concepts such\nas good or bad don’t exist in nature. To the\nbalancing forces, good or bad deeds are equi-\nvalent to each other. The balance will be re-\nstored in every case, whenever an excess po-\ntential is created. You’ve done something\n260/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 983
  },
  {
    "chunk_full": "bad, you become aware of the nature of your\ndeed, you then feel guilty (“I should be pun-\nished”) – an excess potential is created.\nYou’ve done something good, you become\naware of the nature of your deed, you then\nfeel proud of yourself (“I should be rewar-\nded”) – an excess potential is also created.\nThe balancing forces don’t have an idea of\nwhy someone has to be punished or rewar-\nded. They only eliminate the produced irreg-\nularities in the energy field.\nThe payment for feeling guilty will always be\npunishment of one kind or another. If you\ndon’t feel guilty then the punishment may\nnot be coming. Unfortunately, being proud\nof yourself when you have done something\ngood will also lead to punishment and not re-\nward. This is because the balancing forces\nhave to eliminate the excess potential of\npride, while a reward would only reinforce it.\n261/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 984
  },
  {
    "chunk_full": "When other “proper” people are making you\nfeel\nguilty,\nthe\nexcess\npotential\nwill\nbe\nsquared. It is enough that your conscience\nbothers you, but now there is the wrath of\nthe “righteous ones” to bear as well. And fi-\nnally, an unwarranted feeling of guilt that is\nrelated to the innate tendency of “always be-\ning to blame for everything,” creates the\nbiggest excess potential. In this case, it is\nquite pointless to be conscience-stricken.\nAfter all, the reason for your guilt was made\nup. Having a guilty conscience can really ru-\nin your life, because you would constantly be\nunder the influence of the balancing forces.\nIn other words, you would always be pun-\nished in various ways for your imagined\nwrongdoings.\nThat’s why there is a saying: “Impudence is\nthe second happiness”6. In general, the bal-\nancing forces won’t do anything to people\nthat are not conscious-stricken. Nonetheless,\nwe would really want God to punish those\n262/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 985
  },
  {
    "chunk_full": "scoundrels. It would seem that justice has to\nprevail and evil must be punished. Even so,\nnature doesn’t know anything about a sense\nof justice, as sad as it may be. On the con-\ntrary, the decent people with an inherent\nfeeling of guilt are the ones to constantly face\nmisfortunes. Whereas shameless and cynical\nscoundrels get away with almost anything\nwithout being punished, and what’s more,\nthey often get rewarded for their “efforts”.\nSo, feeling guilty will always produce a pun-\nishment script and it does so even without\nyour knowledge. By following the script, your\nsubconscious will make you pay. In the best\ncase, you will get a few cuts or bruises, or\nmaybe you’ll have some kind of problem.\nAnd in the worst case, you could have an ac-\ncident that will have serious repercussions.\nThis is what the feeling of guilt does for you.\nIt brings only destruction, and there is noth-\ning useful or creative about it. You don’t\nneed\nto\ntorture\nyourself\nwith\na\nguilty\n263/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 986
  },
  {
    "chunk_full": "conscience – it won’t be of any help to you.\nIt’s better to act in such a way so that you\nwon’t feel guilty later. And once you’ve done\nthat, it is meaningless to continue torturing\nyourself in vain, as it won’t make anyone feel\nbetter.\nThe Bible’s Ten Commandments are not\nmorals in the sense that you have to behave\nyourself, but they are rather recommenda-\ntions about how one should act in order not\nto disrupt the balance. We are the ones who\naccept the commandments with our basic\nchildlike mindset, as if our mother told us\nnot to be naughty, or we would have to go\nand stand in the corner. On the contrary, no\none is going to punish those who are up to a\nlittle mischief. By disturbing the balance,\npeople create their own problems. And the\ncommandments only warn us of that.\nAs we already talked about earlier, the feel-\ning of guilt serves as a string by which a\n264/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 987
  },
  {
    "chunk_full": "person can be pulled by pendulums and, in\nparticular, by manipulators. Manipulators\nare people who act according to the formula:\n“You should do whatever I say because\nyou’re guilty” or “I’m better than you are, be-\ncause you are wrong”. They are trying to im-\npose a feeling of guilt onto their “charges”, so\nthat they’ll have power over them, or for\ntheir own self-assurance. On the outside,\nthese people appear “proper.” Their concep-\ntions of what is good and what is bad were\nestablished long ago. They always speak true\nwords, thus they are always right. All their\nactions are also flawless and entirely proper.\nHowever, we must say that not all proper\npeople have a tendency to manipulate. So\nwhere do the manipulators get their need to\nlecture and guide their charges from? It is\nconditioned by the doubts and uncertainties\nthat are constantly tormenting their hearts.\nThey skillfully hide this inner struggle from\nthe world around them as well as from\n265/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 988
  },
  {
    "chunk_full": "themselves. The lack of an inner core of\nstrength, which the truly proper people pos-\nsess, forces the manipulator to seek self-as-\nsurance at the expense of others. The need to\nlecture and to direct others stems from the\ndesire to strengthen their own position, and\nthey are doing so by belittling their charges.\nThus, dependent relationships are created. It\nwould be wonderful if the balancing forces\ngave the manipulators what they deserve.\nHowever, an excess potential will only arise\nwhere there is tension, but no moving en-\nergy. In this case, a charge would give the\nmanipulator his energy. Thus there is no po-\ntential and the manipulator is free to act as\nthey like and get away with it.\nAs soon as somebody shows that he is ready\nto take on the feeling of guilt, the manipulat-\nors will immediately stick to this person and\nstart sucking his energy. In order to avoid\ntheir influence, you simply have to refuse\nfeeling guilty. You’re not obliged to justify\n266/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 989
  },
  {
    "chunk_full": "yourself in front of anybody and you don’t\nowe anything to anybody. If you are at fault,\nyou can bear the punishment, as long as you\ndon’t remain the guilty one. Don’t you owe\nyour loved ones something? Again the an-\nswer is no. After all, don’t you care about\nthem because you are convinced that it is the\nright thing to do, and not because you have\nto? This is a different matter entirely. If you\nare prone to justifying yourself, you have to\nstop doing that. Then the manipulators will\nknow that there is no way they can hook on\nto you, and so they will leave you in peace.\nBy the way, the feeling of guilt is the primary\ncause of the inferiority complex. If you feel\ninferior in something that means this inferi-\nority is created when you are comparing\nyourself with others. The investigation can\nbegin, in which you will be the judge of your-\nself. However, it would only seem that you\nare the judge. Actually, something entirely\ndifferent is going on. From the beginning,\n267/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 990
  },
  {
    "chunk_full": "you are predisposed to take on the blame –\nit’s not even important for what exactly.\nBasically, you agree to be the guilty one. And\nif that is the case, you’ll also agree to the fact\nthat you can be found guilty and punished.\nWhen you are comparing yourself to others,\nyou are giving them the right to be superior\nto you. Do note that you handed them this\nright yourself, you were the one to allow the\nothers to think that they are better than you\nare! More than likely, they probably don’t\neven think so in the first place, but you do.\nYou have decided to be judge of yourself, in\nthe name of others. So, of course, that is\nwhat you get, namely people will start\njudging you, because you put yourself on\ntrial.\nTake back your right to be yourself and get\nup from the chair of the defendant. No one\nwill dare to judge you if you don’t consider\nyourself guilty. Only you, by your own good\nwill, give the privilege of being your judge\n268/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 991
  },
  {
    "chunk_full": "and jury to another person. It may seem that\nI am simply appealing to your emotions, dis-\ntorting facts in order to win you over. After\nall, if someone has substantial and real flaws,\nthen won’t there always be people who will\npoint that out? Yes, most certainly there will\nbe. But, they will only do so if they feel that\nyou are predisposed to taking on the blame\nfor your flaws. If for only a second you will\nconsider yourself guilty of being worse than\nothers are, they will definitely feel it. And the\nopposite, if you are free from the feeling of\nguilt, nobody would think of selfasserting\nthemselves at your expense. You can see\nthat, in this situation, an excess potential can\nhave a very subtle impact on the surrounding\nenvironment. This is hard to believe using\nonly common sense. However, I won’t be\nable to prove anything using only words. So\nif you don’t believe it – put it to the test!\nThere are two more interesting aspects to\nfeeling guilty: power and courage. People\n269/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 992
  },
  {
    "chunk_full": "who feel guilty always subject their will to\nthe will of people who don’t feel guilty. If I\nam potentially ready to admit to being guilty\nof at least something, subconsciously I’m\nready to endure punishment and thus, I’m\nready for subordination. And if I never feel\nguilty, but I have the need to assert myself at\nothers’ expense, I’m ready to become a ma-\nnipulator. I am definitely not trying to say\nthat the world is divided into manipulators\nand string puppets only. I just want you to\nhave a look at the pattern. Rulers and leaders\nhave the very least developed sense of guilt,\nif it exists at all. Feeling guilty is a foreign\nconcept to cynics and other people, deprived\nof a conscience. Their method is to wade\nthrough slaughter and to walk over other\npeople. It’s not surprising that unscrupulous\nindividuals very often come to power. Again,\nthis doesn’t mean that power is bad or that\nall people in power are bad. Maybe your hap-\npiness also lies in becoming a favorite of the\n270/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 993
  },
  {
    "chunk_full": "pendulum. Everyone decides for himself or\nherself what to do with their conscience – no\none else has the right to tell you what you\nshould do. In any case, however, you must\nsay no to the feeling of guilt.\nThe other aspect of feeling guilty is boldness\nand it is a sign of an absent feeling of guilt.\nThe essence of fear lies in the subconscious,\nand fear is not only caused by the frightening\n“unknown” but also by a dreaded punish-\nment. If I am “guilty,” I theoretically agree to\nbear punishment, and therefore I am afraid.\nIndeed, brave people are never tormented by\ntheir conscience and they don’t even suffer\nfrom the least sense of guilt. They have noth-\ning to be afraid of, because their inner judge\nhas declared that they are right. Quite the\nopposite is true for the timid victim: I’m not\nsure that I’ve acted correctly, I could be con-\nsidered guilty and everyone has the right to\npunish me. Even the tiniest, weakest and\nmost deeply hidden feeling of guilt will open\n271/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 994
  },
  {
    "chunk_full": "the subconscious gates for punishment. If I\nam feeling guilty, it means I agree in theory\nthat all sorts of robbers and bandits have the\nright to attack me, and therefore I am afraid.\nPeople have come up with one interesting\nway of dissolving the excess potential of\nguilt, namely, asking for forgiveness. This ac-\ntually does work. If a person is carrying the\nfeeling of guilt inside, he is striving to retain\nnegative energy and is thus pumping up the\nexcess potential. Having asked for forgive-\nness, a person releases the potential and al-\nlows the energy to dissipate. Asking for for-\ngiveness, admitting one’s mistakes, praying\nfor one’s sins, confession – all these are\nmethods for getting rid of the excess poten-\ntial of guilt. Writing a pardon, a man would,\nin a way, free himself of his own accusation,\nand he would thus, feel better. The only im-\nportant thing is to make sure that one’s re-\nmorse doesn’t turn into a dependence on\nmanipulators. They are just waiting for this\n272/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 995
  },
  {
    "chunk_full": "to happen. Having asked for forgiveness, you\nhave admitted your own mistake in order to\nthrow the potential off. Manipulators will\nstrive to remind you of your mistake many\ntimes in the future, trying to provoke so that\nyou maintain this feeling of guilt. Don’t give\nin to their provocations - you have the right\nto ask for forgiveness but only once and nev-\ner more.\nRefusing to feel guilty is the most effective\nmeans of survival in an aggressive environ-\nment: in jail, in a gang, in the army, on the\nstreet. It’s not an accident that the criminal\nworld has the following\nunspoken\nrule:\n“Trust no one, fear nothing, don’t ask for\nanything.” This rule urges you to avoid creat-\ning excess potential. Guilt lies at the heart of\nall potential that won’t be of any good to you\nin aggressive environments. You could pro-\ntect yourself by demonstrating your strength.\nIn a world, where the strongest survives, it\nwill work. But this is a rather general method\n273/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 996
  },
  {
    "chunk_full": "of dealing with things. There is a much more\neffective way – the elimination of any idea of\npotential punishment from your subcon-\nscious. The following example illustrates\nwhat I mean. In the former Soviet Union,\npolitical prisoners were intentionally jailed\nwith common criminals, to break their spir-\nits. But what happened was that many of the\npolitical prisoners, all being remarkable indi-\nviduals, did not become victims of the har-\nassment and persecution, and not only that,\nbut they also earned respect and authority\namong the criminals. The thing is that indi-\nvidual independence and dignity are valued\nmore than strength. Many people have phys-\nical\nstrength,\nbut\nto\npossess\nindividual\nstrength of character is a rare phenomenon.\nThe key to one’s personal dignity lies in the\nabsence of any feelings of guilt. Genuine in-\ndividual strength does not lie in the ability to\ngrab someone by the throat, but in the extent\n274/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 997
  },
  {
    "chunk_full": "to which a person can allow himself to be\nfree from the feeling of guilt.\nAnton Pavlovich Chekhov, the renowned\nRussian writer once said: “Drop by drop I am\nsqueezing the slave out of me.” This phrase\nhighlights an ambition to get rid of any feel-\ning of guilt. To get rid of means to fight it.\nHowever, in Transurfing, there is no place\nfor\nstruggle\nor\nforcing\nyourself\nto\ndo\nsomething. The other way is more prefer-\nable: to say no. That is, to choose. You don’t\nhave to squeeze the feeling of guilt out of\nyourself. It’s enough to simply live in accord-\nance with your own credo. No one has the\nright to judge you. You have the right to be\nyourself. If you allow yourself to be you, the\nneed to justify yourself will no longer be rel-\nevant and the fear of being punished will\nfade away. This is when a truly remarkable\nthing will happen: no one will ever again\ndare to offend you. Moreover, it will still be\nvalid regardless of your location – in prison,\n275/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 998
  },
  {
    "chunk_full": "in the army, in a gang, at work, on the street,\nin a bar or wherever. You will never again\nend up in a situation where somebody will\nthreaten you with violence. From time to\ntime, others will be subjected to violence in\none way or another, but you will not, because\nyou’ve thrown out the feeling of guilt from\nyour subconscious and hence, on the present\nlife tracks, scripts for violence simply don’t\nexist. That is the way it is.\nMoney\nIt’s hard to love money without trying to pos-\nsess it. Therefore, in this case it’s practically\nimpossible to avoid dependent relationships.\nWe can only try to keep them to a minimum.\nBe happy if you have money. But don’t ever\nbe killing yourself over not having enough\nmoney or over spending it, otherwise you\nwill have less and less of it. If a person\ndoesn’t earn much money, then his typical\n276/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 999
  },
  {
    "chunk_full": "mistake will be moaning about how there is\nnever enough money. The parameters of\nsuch a radiation correspond to financially\npoor life tracks.\nIt is especially dangerous to give in to the\nanxiety that you have less and less money.\nFear appears to be one of the most energetic-\nally rich emotions. Thus, by experiencing\nfear of losing money or being afraid of not\nearning enough, you will be most effectively\ntransferred to a track where there actually\nwill be less and less money for you. If you\nhave fallen into this trap, it’s won’t be easy to\nget out, but it’s possible. So, in order to es-\ncape the “money trap” it’s necessary to elim-\ninate the cause of the excess potential, which\nyou have created yourself. And what causes\nthis excess potential is usually an extreme\ndesire to have money or to be dependent on\nit.\n277/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1000
  },
  {
    "chunk_full": "For starters, accept what you have and be\nsatisfied with it. Remember that it could al-\nways be a lot worse. You don’t have to reject\nthe desire to have money. You just have to\naccept the fact that money is not flowing to\nyou like a river for the moment being. Ap-\nproach it as a player, who can at any moment\nbecome incredibly rich or lose everything he\nhas.\nMany pendulums use money as a universal\nmeans for paying off their adherents. It is the\nactivity of pendulums that has specifically\nled to the widespread money fetish. Money\nhelps us to have a good life in the material\nworld. Almost everything can be bought and\nsold. All pendulums pay with money – no\nmatter which one you pick. But there is a\nhidden threat here. Having bitten the falsely\nglittering bait, you could very easily make a\nturn onto the life tracks that are located far\naway from your happiness.\n278/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1001
  },
  {
    "chunk_full": "Pursuing their own interests, pendulums\nhave created the myth that in order to get\nanything you need to have means. In this\nway, the aim of each individual person is re-\nplaced with an artificial substitute – money.\nThe person can get money from different\npendulums, thus he is not thinking about his\nown aim, but about money and thus, he falls\nunder the influence of a pendulum that is ali-\nen to him. The man no longer understands\nwhat he personally wants from his life, and\ninstead he joins the useless race for money.\nIt is very profitable for the pendulums when\nthings work this way, but man becomes de-\npendent on money and pendulums, and thus\nloses his way. Working for an alien pendu-\nlum, he will never get much money because\nhe is serving somebody else’s goal. Many\npeople find themselves in a situation like\nthat. Hence, the myth that wealth is a priv-\nilege of the few. But in fact, any person could\n279/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1002
  },
  {
    "chunk_full": "get rich, as long as he is pursuing his own\ngoal.\nMoney is not the goal and it is not even a\nmeans for reaching the goal. It is only an ac-\ncompanying attribute. The goal is what a\nperson wants out of life. Here are a few ex-\namples. To live in one’s own house and grow\nroses; to travel around the world, to see\nfaraway places; to catch trout in Alaska; to go\nskiing in the Alps; to raise horses at one’s\nown farm; to enjoy life on one’s own island\nout in the ocean; to become a movie star or\nan artist.\nIt’s\nobvious\nthat\ncertain\ngoals\ncan\nbe\nachieved only if you have a bag of money. So\nthe majority of people do exactly that – they\nare trying to get this bag. They think about\nmoney, leaving the goal itself in the back-\nground.\nAccording\nto\nthe\nprinciples\nof\nTransurfing, they are trying to get to a life\ntrack where the bag of money awaits them.\n280/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1003
  },
  {
    "chunk_full": "But, working for somebody else’s pendulum,\nit’s very hard to get the bag of money or\nrather, it is impossible. So what happens is\nthat you won’t get any money nor will you\nreach your own goal. It can never be in any\nother way, because your thought energy is\ndirected at an artificial replacement and not\nat your true goal.\nIf you believe that your goal can only be\nachieved if you are rich – send that require-\nment to hell. Let’s suppose you want to travel\naround the world. It’s obvious that in order\nto do that you need a lot of money. To get\nwhat you want you need to think about the\ngoal itself and not about money. Money will\ncome by itself, because it is a complementary\nattribute. It’s that simple. It sounds im-\npossible, doesn’t it? However, that is the case\nand soon you will see that for yourself. Pen-\ndulums, pursuing their own benefit, turned\neverything upside down. It’s not the goal that\nis achieved with the help of money, but it is\n281/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1004
  },
  {
    "chunk_full": "money that will come to you on your way to\nyour goal.\nYou know now how strong the influence of a\npendulum can be. This influence gave birth\nto a whole heap of deceiving facts and myths.\nAnd even now, reading these lines, you could\nobject: but it is obvious that first a man has\nto become a major industrialist, or a banker,\nor a movie star, and only then can he become\na millionaire. Exactly! However, only those\npeople became millionaires, who did not\nhave wealth on their mind, but their goal.\nMost people act in a completely opposite\nway: they either serve somebody else’s goal,\nor they replace their goal with an artificial\nsubstitute, or they reject their goal com-\npletely because they simply don’t have the\nmoney and thus do not fulfill the condition\nof being wealthy.\nIn reality, there are no limitations to wealth\nand\nriches.\nYou\ncould\nwant\nabsolutely\n282/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1005
  },
  {
    "chunk_full": "anything. If it is truly yours, you will get it. If,\non the other hand, the goal of having\nsomething has been imposed on you by a\npendulum, you will get nothing. We’ll look\nmore closely at goals later.7 I’m getting a\nlittle ahead of myself here, as otherwise it\nwouldn’t make sense, because there is prac-\ntically nothing more I could say about\nmoney. Again, I repeat that money is nothing\nbut a complementary attribute on the way to\nyour goal. Don’t worry about the money. It\nwill come to you automatically. The main\nthing now is to lower the importance of your\ncapital to a minimum, so that no excess po-\ntential will be created. Don’t think about the\nmoney – think only about what you want to\nget.\nAt the same time, you should not ignore\nmoney but instead you should treat it care-\nfully. If you see a minor coin on the street\nand you are too lazy to pick it up, then you\ndon’t\nvalue\nmoney\nat\nall.\nThe\nmoney\n283/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1006
  },
  {
    "chunk_full": "pendulum will probably not be very predis-\nposed towards you, if you treat its attributes\ncarelessly.\nYou don’t have to worry when you are spend-\ning money. The money is fulfilling its mis-\nsion when you are buying something. If you\nhave made the decision to spend some\nmoney, don’t regret it later. Striving to save\nup a tidy sum of money and spend as little as\npossible will only produce a strong potential:\nthe money is accumulating in one place and\ndoesn’t go anywhere. In that case, it’s very\nlikely that you will lose everything. Money\nshould be spent sensibly, so that there is\nsome movement in the energy field. In a\nplace where there is no movement, a poten-\ntial will appear. It is not a coincidence that\nwealthy people get involved in the work of\ncharitable organizations. That is how they go\nabout reducing the excess potential from\ntheir accumulated wealth.\n284/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1007
  },
  {
    "chunk_full": "Perfection\nSo, let’s finally look at the most ambiguous\nand paradoxical case of disrupted balance.\nEverything starts small, but can end up with\nthe heaviest of consequences. Usually, ever\nsince\nchildhood\nwe\nwere\ntaught\nto\ndo\neverything thoroughly, carefully, doing our\nbest. As children, we are taught to be re-\nsponsible but we are also taught what is good\nand right and what is bad and wrong.\nWithout a doubt, this is the way it should be\n– otherwise there would be an entire army of\nslobs and slackers. But all of these notions\nthat were fostered in us since we were chil-\ndren are so deeply rooted in the hearts of the\nmost zealous pendulum adherents, that they\nmake these notions a part of their persona.\nStriving for perfection in everything can be-\ncome an obsession to some people. Their life\nis a constant struggle. Guess what they are\n285/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1008
  },
  {
    "chunk_full": "struggling with? The balancing forces, of\ncourse. Having the aim for everything every-\nwhere to be perfect creates certain complica-\ntions on the energy level. And this is because\nthe evaluations those people make are dis-\nplaced and hence, excess potential is created.\nThere is nothing bad about always trying to\ndo your best in everything. But if you make it\noverly important, then the balancing forces\nwill be right there. They will simply ruin\neverything. In addition, this will create a\nbackward loop and you will get more and\nmore obsessed with perfection. You want\nperfection, but get the opposite, so you’ll\ndesperately try to fix everything, but then\neverything will get even worse. In the end,\nstriving for perfection turns into a habit, and\nit could also develop into a mania. The life of\na perfectionist would turn into a constant\nstruggle, and this would automatically pois-\non the life of those around him, because a\nperfectionist\nis\nnot\nonly\ndemanding\nof\n286/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1009
  },
  {
    "chunk_full": "himself, but also of others. This is evident in\nhis intolerance for the habits and tastes of\nothers, which is often the cause of small con-\nflicts that sometimes turn into big ones.\nIf you were not involved in the situation\nyourself, you would probably appreciate the\nwhole absurdity of someone trying to be per-\nfect\nin\neverything,\nterrorizing\neveryone\naround him. However, the perfectionist has\ngrown so much into his role that he starts\nthinking that he is the one without sin, flaw-\nless and right in everything he does. In a\nsense, he is telling the rest of the world “In\nmy striving to be a role model, I am a role\nmodel already.” The perfectionist might not\neven admit to it, because he knows that a\nsense of one’s own excellence doesn’t sit well\nwith the generally accepted idea of perfec-\ntion. However, “the feeling of being right\nabout everything” is rooted very deeply in\nthe subconscious of such a perfectionist.\n287/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1010
  },
  {
    "chunk_full": "At this point, the perfectionist is dangerously\nclose to the temptation of appearing before\nhumanity as the supreme judge, deciding\nhow and what all the other lost souls should\nbe doing. Of course, the perfectionist will\neasily give in to this temptation. After all, the\nfeeling that he is always right would justify\nhis actions, while his righteous desire to set\neverybody on the right path would give him\nenough motivation to embark on his crusade.\nFrom this moment on, “the destiny maker”,\nhaving wrapped himself in a mantle, gives\nhimself the right to judge and condemn oth-\ner people. In reality, such a trial, of course,\ndoesn’t go beyond common preaching and\naccusation making. However, on the energy\nlevel, the most powerful excess potential\ntakes form. “The judge” takes on a mission,\ndeciding how these foolish, useless beings\nshould behave themselves, what they should\nbe thinking, what they should value, what\nthey should believe in and what they should\n288/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1011
  },
  {
    "chunk_full": "strive for. If some puny creature suddenly\ndecides that he has his own opinion on the\nsubject, then he needs to be put back in his\nplace, and if he shows any resistance – then\nhe has to be put on trial, sentenced and\nlabeled, so that everyone will know who is\nwho.\nI’m confident that your portrait, dear Read-\ner, is very far from the one drawn of the\nidealist here. This book wouldn’t fall into the\nhands of a fool, who is convinced that he is\nalways right. He knows already how every-\none should live his or her life, so in this re-\nspect he never doubts. However, if you meet\na person like that, have a closer look at this\nspecimen. It may be rather interesting, as be-\nfore you will be a case of the grossest dis-\nturbance of balance. We are all guests in this\nworld, everybody is free to choose their own\npath, but no one has the right to judge oth-\ners, to sentence them or to put labels on\nthem (we’ll leave aside criminal law).\n289/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1012
  },
  {
    "chunk_full": "That’s the way it is. Everything seemed so in-\nnocent in the beginning, a simple strive for\nperfection, but it ends with someone claim-\ning privileges of a master. Therefore, even\nthe resistance of the balancing forces, that\nearlier manifested themselves in the shape of\nminor problems, will grow stronger. If the\ndisturber of balance is under the protection\nof a pendulum, then for the time being, he\ncould get away with his perfectionism. But\neventually the time will come to pay the bills.\nWhen a guest forgets that he is only a guest,\nand pretends to be the host, he can be\nthrown out.\nImportance\nFinally, let’s look at the most common type\nof excess potential – importance. This poten-\ntial arises when excessive importance is at-\ntributed to something. Importance repres-\nents an excess potential in its purest form.\n290/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1013
  },
  {
    "chunk_full": "Eliminating this potential, the balancing\nforces make up problems for the person who\ncreated this potential.\nTwo forms of importance exist – inner and\nouter. Your inner or individual importance\ncan be the overestimation of your virtues or\nflaws. The formula of inner importance goes\nalong the lines of: “I am an important per-\nson” or “I do important work”. When the ar-\nrow of importance of your persona goes off\nthe scale, the balancing forces get to work,\nand the “big cheese” gets a flick on the nose.\nHe who “does important work” will also be\ndisappointed – either his work won’t be\nneeded at all, or it will be very poorly done.\nBut puffing up and having your nose in the\nair is only one side of the coin. There is an-\nother side to it – belittling your own virtues\nand self-humiliation. What this all leads to,\nyou already know. As you can see, the\namount of the excess potential is the same in\n291/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1014
  },
  {
    "chunk_full": "both cases, the only thing different is its dir-\nection – positive or negative.\nSomeone, who attributes great importance to\nan object or an event in the world, is also ar-\ntificially creating outer importance. The for-\nmula of outer importance goes something\nlike this: “To me, such-and-such is of great\nimportance” or “It is very important to me to\ndo this and that”. An excess potential is thus\ncreated and everything will be ruined. If you\nare still able to somehow curb your feelings\nof inner importance, then the deal with ex-\nternal significance is much worse. Imagine\nthat you have to walk on a log that is on the\nground. There is probably nothing easier.\nBut now, you have to walk on that same log,\nonly this time it is placed between the roofs\nof two skyscrapers. The position of the log is\nnow of great importance to you, and you\ncan’t convince yourself of the opposite. The\nonly way of eliminating outer importance in\nthis case would be some kind of insurance\n292/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1015
  },
  {
    "chunk_full": "(for example, a parachute when you are\nwalking on the log). In each individual case,\nthe insurance will be different. The main\nthing is not to put everything on one side of\nthe scale. There must be some kind of coun-\nterweight, some protection. In other words,\nan escape route or plan B.\nI don’t have anything more to say about this.\nBasically, everything there was to say about\nimportance has already been said. Have you\nfigured it out? Everything we’ve talked about\nin this chapter is a variation on the subject of\nimportance, inner or outer. All imbalanced\nfeelings or reactions – indignation, discon-\ntent, irritation, anxiety, worry, depression,\npanic, despair, fear, pity, attachment, admir-\nation,\nexaggerated\naffection,\nidealization,\nworship, glee, disappointment, pride, arrog-\nance, contempt, disgust, resentment and so\non – these are nothing but a manifestation of\nimportance in one form or another. An ex-\ncess potential is created only when you\n293/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1016
  },
  {
    "chunk_full": "attribute excessive importance to a quality,\nobject or event – either inside yourself or in\nthe external world.\nImportance creates an excess potential by\nsummoning the wind of balancing forces. In\ntheir turn, they create many problems, and\nlife is transformed into one single struggle\nfor existence. Now you can judge for yourself\nto what extent inner and outer importance is\ncomplicating your life.\nBut this is not all. Remember the puppet\nstrings? Pendulums hang onto your feelings\nand reactions: fear, anxiety, hatred, love,\nworship, call of duty, guilt and others. As you\nsee, all these things are the consequences of\nexcessive importance. The following scenario\ndescribes what is literally taking place. Say\nthere is a certain object in front of you. On\nthe energy level, it’s neutral: neither good\nnor bad. You approached the object, you put\nit in your box of importance, and then you\n294/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1017
  },
  {
    "chunk_full": "stepped aside, looked at it – and gasped.\nNow you are ready to give away your energy\nto the pendulum, because now you have\nsomething to hook on to. A little donkey will\nobediently drag himself along, following the\ncarrot. Importance represents that very same\ncarrot. A pendulum will use this carrot to\ncapture the frequency of your radiation, to\nsuck your energy out of you, and get you\nwherever it wants.\nHence, in order to be in harmony with the\nrest of the world and to relieve yourself of\npendulums, it’s necessary to reduce any ex-\ncessive importance. You always have to keep\nwatch over how much importance you attrib-\nute to yourself or to the world around you.\nYour inner Overseer shouldn’t be sleeping.\nHaving reduced the importance, you will im-\nmediately enter the state of balance and pen-\ndulums won’t be able to establish any control\nover you – after all, you can’t hook on to\nemptiness. You could object: so what are you\n295/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1018
  },
  {
    "chunk_full": "saying, we should all just become lifeless\nstatues? I’m not in any way urging you to re-\nfuse all kinds of emotions or even to reduce\ntheir intensity. Overall, it is useless and not\neven necessary to fight emotions. If you are\nalways trying to keep yourself together and\nstay calm on the outside, while your inner\nworld is boiling over, the excess potential\nwill grow bigger. Emotions stem from atti-\ntudes, therefore you should change your atti-\ntude in the first place . Feelings and emo-\ntions are nothing but consequences. They are\ncaused by one single thing – importance.\nSuppose that someone in my family has been\nborn, has died, or recently had a wedding or\nsome other kind of important event. Is this\nimportant to me? No. Should I be indifferent\nto it? Again, no, I shouldn’t. Do you see the\ndifference? I just don’t make a problem out\nof it and don’t torture myself or the people\naround me. Well, and what about compas-\nsion? I think I am not mistaken if I say that\n296/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1019
  },
  {
    "chunk_full": "compassion and helping those truly in need\nnever hurt anyone. But even in the case of\nhelping others you need to monitor your im-\nportance. I made a slip, when I said you\ncould only help those who are truly in need.\nWhat if a person really wants to suffer? He\nlikes it this way, and your compassion is a\nmeans for him to get self-assurance on your\nbehalf. Or, for example, you saw a poor\ncripple begging and you gave him some\nmoney. But as you were walking away he\ngave you an evil smirk – he’s not a cripple at\nall but a professional beggar.\nIn the animal world, in the world of plants as\nwell as in nature in general, there is no such\nthing as importance. There is only expedi-\nency, from the point of view of the balancing\nforces. Pets are probably the only ones that\ncould experience a sense of their own im-\nportance. Yes, it appears that they too can be\ninfluenced by society. Other animals are only\nguided by their instincts in anything they do.\n297/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1020
  },
  {
    "chunk_full": "Importance is a human invention that is of a\ngreat pleasure to pendulums. Strong devi-\nations in outer importance make fanatics.\nAnd what do you think deviations in inner\nimportance make? They make petty tyrants.\nYou could get the impression that with\nthings being this way, one would be too\nscared to do anything. Fortunately, it is not\nall that bad. The balancing forces will start\nmaking serious changes in your life only if\nyou are really attached to your ideas of how\nthings should be, if you are obsessed and\nhave really gone too far. The situation with\nthe pendulums is also clear. We are all under\ntheir influence. The main thing is to realize\nhow they are getting hold of you and how far\nyou will let them take you.\nReducing importance doesn’t just signific-\nantly decrease the number of problems in\nyour life. Having refused internal and outer\nimportance, you will obtain such a treasure\n298/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1021
  },
  {
    "chunk_full": "as the freedom of choice. “ What are you\ntalking about?” you ask, “According to the\nprimary principle of Transurfing we already\nhave the right to choose.” Well, you do have\nit, but you are unable to use it. The balancing\nforces and pendulums are in the way. Be-\ncause of excessive importance, our entire\nlives are spent in a struggle with balancing\nforces. There’s simply not enough energy left\nfor the actual choice, let alone for thinking\nabout what you personally want from life.\nMeanwhile, the pendulums are constantly\ntrying to establish control over us and im-\npose someone else’s goals on us. Where is\nthe freedom in that?\nAny form of importance, either inner or out-\ner, is simply made up. None of us is of any\nimportance in this world. But at the same\ntime, we have access to all of the riches in the\nworld. Imagine how the children, when they\nare on the beach, are splashing, playing and\nhaving lots of fun in the water. Suppose that\n299/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1022
  },
  {
    "chunk_full": "none of them imagines himself to be either\ngood or bad, that the water is good or bad,\nthat the other children are good or bad. As\nlong as the situation remains this way, the\nchildren are happy – they’re in harmony\nwith nature. Similarly, any person has come\ninto this world as a child of nature. If he\ndoesn’t disturb the balance, he can have the\nbest there is. But as soon as he starts making\nup importance, problems will appear imme-\ndiately. He does not see the causal link\nbetween his importance and his problems.\nThus, it seems to him that the world is basic-\nally a hostile environment, where it’s not that\neasy to get what you want. In fact, artificially\ncreated importance is the single obstacle on\nthe path to fulfillment of your desires. It’s\npossible that I haven’t convinced you of this\nyet. However, I am far from running out of\narguments.\n300/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1023
  },
  {
    "chunk_full": "From Struggle to Balance\nIs there any way of resisting the balancing\nforces? That’s exactly what we are doing\nevery day. Our entire life is a struggle with\nbalancing forces. All difficulties, nuisances\nand problems are connected to the actions of\nthe balancing forces. In any case, trying to\nresist the balancing forces is meaningless, as\nthey will continue doing their thing no mat-\nter what. Efforts aimed at removing con-\nsequences won’t do any good. On the con-\ntrary, the situation will only get worse. The\nonly remedy against the balancing forces is\nto eliminate the reason for their actions –\nnamely, reducing the excess potential of im-\nportance. Life situations are so different\nfrom one another that it’s impossible to give\na universal solution to all problems. At this\npoint,\nI\ncan\nonly\ngive\nsome\ngeneral\nrecommendations.\n301/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1024
  },
  {
    "chunk_full": "The only thing everyone is busy doing is\nbuilding a wall on the foundation of his im-\nportance, and then trying to climb over it or\nget through it by beating his head against the\nwall.\nInstead\nof\novercoming\nobstacles,\nwouldn’t it be better to take a brick out of the\nfoundation, collapsing the wall? All of us can\nclearly see the obstacles on our way. But to\nsee what foundation they are all built upon is\noften not easy at all. If you’ve encountered a\nproblematic\nsituation,\ntry\nto\ndetermine\nwhere you’ve gone too far, what you became\nattached to and to what you attributed ex-\ncessive significance. Identify any excessive\nimportance, and then reject it. The wall will\ncome crashing down, the obstacle will be\neliminated and the problem will be solved\nwithout your help. Don’t overcome obstacles\n– start reducing importance instead.\nReducing importance doesn’t mean fighting\nyour feelings and trying to suppress them.\nExcessive emotions and feelings are the\n302/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1025
  },
  {
    "chunk_full": "consequences of importance. You should\neliminate the cause, which is your attitude to\na certain event or object. I could advise you\nto take as philosophical an approach to life\nas possible, although this appeal is probably\nalready worn out. It’s necessary to realize\nthat importance won’t bring you anything\nbut trouble. And once you’ve done that, in-\ntentionally reduce any importance.\nReducing outer importance doesn’t have\nanything to do with negligence or underes-\ntimation. On the contrary, neglect is import-\nance with a minus sign. You need to have a\nsimpler attitude towards life. Don’t be care-\nless, but don’t be exaggerating either. Don’t\nthink so much about whether people are\ngood or bad. Accept the world in its everyday\nform.\nReducing inner importance doesn’t have\nanything to do with resignation or self-humi-\nliation. To repent one’s mistakes and sins is\n303/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1026
  },
  {
    "chunk_full": "the same as showing off one’s virtues and ac-\ncomplishments. The difference between the\ntwo is only the sign – plus or minus. Your re-\nmorse is only useful to the pendulums that\nwant to establish control over you. Accept\nyourself as you are. Allow yourself the luxury\nof being you. Do not exalt and do not belittle\nyour virtues and flaws. Strive toward inner\npeace – you are not important nor are you\nworthless.\nIf your situation very strongly depends on\nsome kind of event, find an alternative solu-\ntion. In order to stay calm when you are\nwalking on the log, you have to find insur-\nance. In each individual case, the insurance\nwill be something different. Simply ask your-\nself the question, what could serve as insur-\nance in the present situation. Remember, it\nis useless to struggle with balancing forces.\nYou can’t suppress fear or excitement. You\ncan only reduce the importance. And this can\nonly be done if you have insurance or a plan\n304/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1027
  },
  {
    "chunk_full": "B. Never put all your eggs in one basket, no\nmatter how safe the basket looks!\nThe only thing that doesn’t create any excess\npotential is a sense of humor, being able to\nlaugh at yourself and at others, without of-\nfending either you or them. This thing alone\nis enough to prevent you from turning into a\ndummy without feelings. Humor is the same\nas denying importance, in other words, it is a\ncaricature of importance.\nIt is necessary to follow one golden rule,\nwhen you are solving problems. Before you\nactually start solving problems, you would\nneed to reduce their importance. Then the\nbalancing forces will not bother you and the\nproblem can be solved quickly and easily.\nIn order to reduce importance, it’s necessary\nto first remember and realize that the prob-\nlem is present as a consequence of excessive\nimportance. Until you explain to yourself, as\n305/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1028
  },
  {
    "chunk_full": "in a dream, that every single problem is cre-\nated because of excessive importance, and\nwill continue burying yourself in this prob-\nlem, you will be completely in the grip of the\npendulum. Stop, shake off the delusions and\nrecall what it means to attribute excessive\nimportance. Then intentionally change your\nattitude to the object in question. That will\nnot be a difficult thing to do. You already\nknow that excessive significance is only in\nyour way. The main difficulty is to remember\nin time that you are wallowing in inner and\nouter importance. To help you remember,\nyou will need to activate your Overseer, your\ninner observer that will always keep track of\nall of your inner values.\nA man’s thoughts are captured by import-\nance in exactly the same way as muscles in-\nvoluntarily get strained. For example, when\nsomething is bothering you, the muscles of\nyour back and shoulders are in a tight spasm.\nYou don’t notice this tension until you start\n306/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1029
  },
  {
    "chunk_full": "feeling the pain that is associated with it. But\nif you would have remembered in time and\npaid attention to your muscles, you could\nhave released this tension.\nCatch yourself at attributing excess import-\nance each time you are getting ready for\nsome event. If whatever it is you are about to\ndo is really important to you, don’t blow it up\neven further. The best recipe for success is –\nspontaneity, improvisation and a light atti-\ntude. If you are preparing for something then\ndo it only as insurance. You should definitely\nnot be “preparing seriously and carefully” –\nthis will only boost the importance. If you\nare worrying about something without actu-\nally doing anything about it, then you are\nfurther boosting importance. The potential\nof importance evaporates with action. Don’t\nthink…..act! If you can’t act, then don’t think.\nDirect your attention to something else and\nlet go of the situation.\n307/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1030
  },
  {
    "chunk_full": "You’ll be most effective in everything you do\nif you take the focus of attention off yourself\nas the person executing the action and off the\nend goal, and move this focus onto the pro-\ncess of performing the action. In this case “I\nam not doing important work” and “the work\nis not important”. Thus, the excess potential\nis eliminated and the balancing forces will\nnot\ninterfere.\nThe\naction\nis\ncompleted\nwithout any zeal, but in no way carelessly or\nlight-heartedly. You might be having doubts:\nwhy do I need to take the focus of attention\noff the end goal? How can you do any work,\nif you are not thinking about the end goal?\nYou will understand the meaning of this not\nvery obvious fact more clearly, having read\nthe upcoming chapters of this book.8\nWhy does it sometimes happen that you are\nvery worried about an event, you fear it, you\nconstantly think about it and imagine all\nkinds of difficulties and problems that could\nhappen because of that event, but in the end,\n308/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1031
  },
  {
    "chunk_full": "everything still turns out okay? And then we\nhave the opposite situation, sometimes you\ndon’t care much about a future event, but as\na result you get unforeseen trouble. In the\nfirst case, your evaluation of the event went\noff scale in a negative direction, while in the\nsecond – it went off scale in a positive direc-\ntion. What you receive in the end is the accu-\nmulated action of the balancing forces. The\nforces have to balance the artificial excess\npotential that you have created and that is\nwhat they do.\nThus, it’s possible to assume that if I inten-\ntionally picture the worst possible scenario\nof what might happen before an exam, then I\nam most likely to get the highest grade. It\ndoesn’t work that way, because your inten-\ntion to “assume” the worst is artificial. Such\nintention is a product of the mind and not\nthe soul. You can try fooling yourself. Non-\netheless, it will only be a sham, as it won’t\nhave any energy basis. Only the intention\n309/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1032
  },
  {
    "chunk_full": "coming from your soul can have an energy\nbasis. This is exactly why you can’t achieve\nthe desired result by simply visualizing it.\nBut this is a topic of a later discussion.\nNever ever, under any circumstances, boast\nwith what you have, even if you’ve earned it\nfair and square. And you definitely should\nnot brag about what you haven’t achieved\nyet. This is extremely unprofitable, because\nin this case the balancing forces will always\nact against you.\nMake yourself at home, but don’t forget that\nyou are a guest.9 If you are in harmony with\nthe surrounding pendulums, that is, you are\nswinging with them in unison, then your life\nwill pass with ease and pleasure. You are\nnow in a kind of resonance with the world -\nyou get energy from it and achieve your goal\nwithout further effort.\n310/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1033
  },
  {
    "chunk_full": "If you’ve got yourself in a situation where it’s\npractically impossible to live in balance with\nthe world around you (for example, your\nhusband is beating you), then you ought to\nthink about how to take that crucial step and\nchange your surroundings to something dif-\nferent.\nMaybe\nyou\nfeel\nthat\nyou\nhave\nnowhere to go? If so, you’ve got that idea\nfrom a pendulum that is trying to entrance\nyou, so it can continue to keep you under its\ncontrol, sucking your energy. There is always\na way out, and not only one. Remember the\nfly on the glass that didn’t see the open win-\ndow? Just avoid any abrupt actions that have\nnot been carefully thought through. The per-\nfect solution will come to you, as soon as you\nreduce excessive importance and free your-\nself from the influence of the destructive\npendulum that is bothering you. You are now\nfamiliar with the ways of freeing yourself\nfrom a pendulum – make it fall through or\nextinguish it.\n311/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1034
  },
  {
    "chunk_full": "On that note, I am concluding the large and\ncomplicated topic of balance. Now that you\nunderstand the mechanism behind the ac-\ntions of the balancing forces, you can easily\ndetermine the reason behind any problem or\nfailure. We’ve come to the conclusion that\nit’s necessary to observe the principle of bal-\nance in everything you do. Now I have to\nwarn you of following this principle all too\nvigorously. If you become attached to it or\ntry to pursue it fanatically, then by doing so\nyou will disturb this very principle. If we ex-\nplain to a centipede, in every detail how it\nshould walk, it will end up so confused that it\nwon’t be able to move at all. Everything in\nmoderation; allow yourself to disturb the\nbalance sometimes. Nothing awful will hap-\npen. The main thing is to keep the arrow of\nimportance from going off the scale.\n312/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1035
  },
  {
    "chunk_full": "Summary\nAn excess potential is created only if signi-\nficance is attributed to an evaluation.\nOnly importance that is specifically yours\nwill provide your evaluation with your\nenergy.\nThe magnitude of a potential will grow if an\nevaluation is distorting reality.\nThe action of balancing forces is directed at\neliminating excess potential.\nThe action of balancing forces is often the\nopposite of the intention that created the\npotential.\nWhen giving yourself out for rent, activate\nyour inner Overseer to look after you, so\nthat you do everything impeccably.\n313/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1036
  },
  {
    "chunk_full": "Discontent and condemnation will always\nturn the balancing forces against you.\nIt is necessary to replace the habitual negat-\nive reactions with a positive transmission.\nUnconditional love is admiration without\nthe right to possess or worship.\nSetting terms and comparison produces de-\npendent relationships.\nDependent\nrelationships\ncreate\nexcess\npotential.\nIdealization and overestimation always end\nin debunking the myth.\nIn order for your love to be reciprocated, it’s\nnecessary\nto\nabandon\nthe\nright\nof\npossession.\nOne will definitely have to pay for contempt\nand vanity.\n314/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1037
  },
  {
    "chunk_full": "Free yourself from the need to confirm your\nsuperiority.\nStriving to hide one’s flaws creates the op-\nposite effect.\nAny inferiority is compensated for by your\nvirtues.\nThe higher the importance of the goal, the\nless likely it is that you will reach it.\nDesires that are free from the potentials of\nimportance and potentials of dependence\nwill be fulfilled.\nSay no to any feeling of guilt and to the need\nto justify yourself.\nIn order refuse the feeling of guilt, it is\nenough to allow yourself to be you.\nNo one has the right to judge you. You have\nthe right to be yourself.\n315/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1038
  },
  {
    "chunk_full": "Money comes on its own, as an accompany-\ning attribute on the way to your goal.\nGreet money with love and attention, and\npart with it without regret or worry.\nHaving said no to inner and outer import-\nance, you get the freedom of choice.\nImportance is the only obstacle on the path\nto fulfilling your desire.\nDo not overcome obstacles – reduce their\nimportance.\nCare without worrying.\n316/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1039
  },
  {
    "chunk_full": "CHAPTER V\nAN INDUCED\nTRANSITION\nWhy does every new generation\nthink life was better before? How\nmany\ngenerations\nhave\nalready\npassed since the beginning of his-\ntory! And each generation is con-\nvinced that the world has become\nworse than before. Does the world\nhave a tendency to degenerate? But\nif that really was the case, then a\nfew dozen generations would have\nbeen enough for our civilization to\nend up in pure hell. What is going\non here?\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1040
  },
  {
    "chunk_full": "Don’t let any negative information\nget to you.\nThe Shift of Generations\nIn all times, people have been thinking:\n“Those were the good old days!” As a person\ngets older, life seems to him worse and\nworse. He is remembering when he was\nyounger, when colors were rich, impressions\nwere bright and vivid, dreams were attain-\nable, the music was better, the climate was\nmore favorable, people were more approach-\nable, even the hot dogs were tastier back\nthen, and not to mention how much better\none’s health was. Life was full of hope, and\nbrought joy and satisfaction. Now, after so\nmany years, the same events do not make the\nman as happy as before. For example, a pic-\nnic, a party, a concert, going to the movies, a\ncelebration, a date or a holiday by the sea – if\nwe look at it objectively, everything has more\n318/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1041
  },
  {
    "chunk_full": "or less the same quality. The party is fun,\nmovies are interesting and the sea is warm.\nBut nonetheless – something is missing. The\ncolors have faded, experiences have become\ndull and the interest has simply died out.\nSo how come everything was so great back in\nour youth? Can it really be the case that our\nperceptions get duller as we grow older? But\na man doesn’t lose the ability to laugh or to\ncry, to perceive tastes and colors, to distin-\nguish truth from deception, to tell the differ-\nence between good and bad just because he\nis getting older. Or is the world really going\ndown the drain? Actually, the world on its\nown is not degrading nor is it getting worse.\nIt gets worse only for each individual person.\nRunning in parallel with the negative life\ntrack the person is on now, there are life\ntracks which he left at some point in his life,\nand where everything is fine, just like it was\nin the good old days. By expressing dissatis-\nfaction, the man tunes himself into life tracks\n319/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1042
  },
  {
    "chunk_full": "that are actually worse. And in that case, he\nis really being drawn into them.\nAccording to the principle of Transurfing,\nthe space of variations has everything for\neverybody. For example, there is a sector,\nwhere for a given individual the colors of life\nhave completely faded, while for others life\nremains as it was. A man, radiating negative\nthought energy, enters a sector where the\ndecorations of his space have changed. At the\nsame time, the world remains the same to\neverybody else. And we don’t even have to go\ntoo far, looking at radical cases where a man\nbecame an invalid, lost his home, lost his\nloved ones or became an alcoholic and\nruined his life. In the flow of life, this man is\nsliding, slowly but surely, on the track where\nall the colors of his surrounding decorations\nare fading. That is when he starts remember-\ning how vivid and fresh everything was long\ntime ago.\n320/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1043
  },
  {
    "chunk_full": "When you are born and later when growing\nup, you accept the world as it is. A child\nsimply doesn’t know whether things could\nget worse or better. Young people are not\npicky and haven’t been spoiled yet. They are\nsimply discovering this world for themselves\nand take joy in life, because they have more\nhopes than complaints. They believe that\neverything here and now is not too shabby,\nand will get even better. But then there are\nmisfortunes and failures, a man begins to\nunderstand that not all his dreams will come\ntrue, that other people are better off and that\nhe has to fight for his place under the sun. As\ntime goes by, the man has more complaints\nthan hopes. Discontent and whining become\nthe moving forces, pushing the man towards\nunsuccessful life tracks. If one were to ex-\npress it in Transurfing terms, the man is ra-\ndiating negative energy, which is transferring\nhim onto the life tracks that correspond to\nthese negative parameters.\n321/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1044
  },
  {
    "chunk_full": "The worse you think of the world, the worse\nit will get. In childhood, nobody was particu-\nlarly contemplating whether one’s childhood\nwas good or not. As children, we took\neverything for granted. You had only started\nto discover the world and had not yet begun\nabusing it with your criticism. The greatest\nresentment you felt was in the direction of\nyour relatives that, for example, didn’t buy\nyou a toy. But then you really started to re-\nsent the world around you. The world satis-\nfied you less and less. And the more you were\ncomplaining about it, the worse the results\nwere. Everyone who has experienced youth\nand lived to maturity knows that a lot of\nthings were better before.\nSo it’s a harmful paradox: you are confronted\nwith annoying circumstances, you express\nyour discontent, and as a result, the situation\ngets even worse. Your discontent comes back\nto you three-fold, as a boomerang. Firstly,\nthe excess potential of your discontent turns\n322/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1045
  },
  {
    "chunk_full": "the balancing forces against you. Secondly,\nyour discontent serves as a channel through\nwhich a pendulum is able to pump your en-\nergy. And thirdly, when radiating negative\nenergy, you are moving to corresponding life\ntracks. That is, to negative life tracks.\nThe habit of reacting negatively is so deep-\nseated in us that people have lost their ad-\nvantage over the lower living creatures in-\nhabiting this planet. That advantage is con-\nsciousness. An oyster would react negatively\nto an external irritant as well. But, unlike the\noyster, a man is able to consciously and in-\ntentionally manipulate his relationship to the\nexternal\nworld.\nNevertheless,\nhe\ndoesn’t\nmake use of this advantage and instead re-\nsponds to the slightest inconvenience with\naggression. He mistakenly interprets his ag-\ngression to be his strength, while in fact he is\nsimply helplessly quivering in the pendu-\nlums’ spider web.\n323/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1046
  },
  {
    "chunk_full": "You believe that life has gotten worse.\nHowever, those who are young now think\nthat life is wonderful. How come? Maybe, be-\ncause they don’t know how good it was when\nyou were their age? But back then there were\nalso people who were older than you, who\nwere\ncomplaining\nand\nremembering\nthe\ngood old days, just as you do now. The reas-\non is not just the ability of a man’s psyche to\nerase all bad memories and leave only the\ngood ones. After all, your discontent is aimed\nat the present, because the present is sup-\nposedly worse than the past.\nIt appears that, if one were to accept the fact\nthat life is getting worse and worse with each\nyear, the world should have simply fallen\napart a long time ago. How many genera-\ntions have already passed since the begin-\nning of human history? And everybody be-\nlieves that the world has gotten worse! For\nexample, any old man would tell you with\nabsolute certainty that Coca-Cola was better\n324/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1047
  },
  {
    "chunk_full": "before. However, Coca-Cola was invented in\n1886. Imagine how awful it must be now!\nMaybe the ability to taste gets duller with\nage? That is hardly the case. After all, the old\nman considers any other quality to be worse\nnow, like the quality of furniture or clothes.\nIf the world was one and the same for every-\nbody, then after the passing of several tens of\ngenerations, it would simply have turned in-\nto a living hell. How should we understand\nthis paradoxical statement that the world is\nnot the same for everybody? We all live in\none and the same world of material mani-\nfestations of variations. But the world’s vari-\nations are different for everybody. On the\nsurface, you can see clear differences in des-\ntinies: the rich, the poor, the successful, the\nunsuccessful, the happy and the unhappy.\nThey all live in one world, but it is different\nfor each and one of them. This is seems obvi-\nous, just as it is obvious that there are\nwealthy and poor neighborhoods.\n325/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1048
  },
  {
    "chunk_full": "However, not only do the scripts of destinies\nand roles differ, but the individual decora-\ntions do that too. This difference in decora-\ntions is not as obvious. One man looks out on\nthe world from the window of his luxurious\nautomobile, while another from a garbage\ncan. One is having fun at a party, while an-\nother is troubled with his own problems at\nthe same party. One sees a cheerful group of\nyoung people, while another sees a wild gang\nof troublemakers. Everybody is looking at\nthe same thing, but the pictures are as differ-\nent as a movie in color and a black-and-\nwhite film. Every person is tuned to his sec-\ntor in the space of variations, thus everyone\nis living in their own world. All of these\nworlds are placed on top of each other, in\nlayers, forming what we understand to be\nthe space we live in.\nThis may be hard for you to understand. It’s\nimpossible to separate one layer from anoth-\ner. Each person forms his own reality with\n326/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1049
  },
  {
    "chunk_full": "his own thoughts, and at the same time this\nreality intersects and interacts with the sur-\nrounding world.\nImagine\nEarth\nwithout\na\nsingle\nliving\ncreature. Winds blow, rain falls, volcanoes\nerupt, rivers flow – the world is there and it\nexists. Then suddenly a man is born and he\nstarts observing all of this. The energy of his\nthoughts produce a material manifestation in\na certain sector in the space of variations –\ncreating the life of this given man in this giv-\nen world. His life represents a new layer of\nthis world. Another man is born – yet anoth-\ner layer appears. A man dies – a layer disap-\npears, or maybe he is transformed in accord-\nance with what happens there, beyond the\nthreshold of death.\nHumankind is vaguely aware of the fact that\nthere are other living creatures, which sup-\nposedly live in parallel worlds of some kind.\nBut let’s suppose for a minute that there are\n327/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1050
  },
  {
    "chunk_full": "no living creatures in the world whatsoever,\nat least yet. Then what kind of energy gave\nbirth to the material manifestation of space\n(that is creating things and phenomena in\nthe world), where there is not a single living\ncreature to radiate any thought energy and\nthus make the material manifestation of a\ncertain sector happen? We can only guess\nwhat energy was responsible for the creation\nof the world before man or any living\ncreature was born. And perhaps, once the\nlast living creature dies, then the world itself\nwill disappear? Who can prove that the\nworld exists, if there is nobody in it? For if\nthere is no one around who can say that the\nworld (in our understanding) exists, then\nthere is no world to speak of.\nWell, that’s enough for now – let’s not get\nbogged down with this any further. We’ll\nleave it at that. Don’t forget that Transurfing\nis only one of many models. All the theories\npeople have about the surrounding world\n328/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1051
  },
  {
    "chunk_full": "and the life in it are nothing but models.\nKeep the notion of importance in mind and\ndon’t make up any external importance for\nthe model of Transurfing. Otherwise, you\ncould become an apologist of useless ideas\nand try to show everyone that your particular\nsubjective world-view is the truth and es-\nsence. Truth is an abstraction. We can only\nget to know certain laws and manifestations\nof truth. Our goal is only this - how to make\npractical use of our model.\nLet’s return to the worlds of generations.\nEach person throughout his life is moving\nfrom one sector of the space of variations to\nanother and in so doing transforms the layer\nof his world. Due to the fact that he is more\nreadily expressing discontent and is radiat-\ning larger quantities of negative than positive\nenergy, there is a tendency for the quality of\nlife to get worse. A man could acquire mater-\nial prosperity with age, but he won’t be any\nhappier because of that. The colors of his\n329/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1052
  },
  {
    "chunk_full": "decorations fade, and life is less and less en-\njoyable. A representative of the older genera-\ntion and a youngster both drink the same\nCoca-Cola, both swim in the same ocean, ski\non the same mountain slopes – everything is\npretty much the same as it was many years\nbefore. However, the older man is convinced\nthat everything was better before, while the\nyoungster thinks that everything is just great\nnow. And when the youngster will grow old,\nthe story will repeat itself again.\nThere are deviations from this tendency,\nboth for better and for worse. It happens that\na man only starts to develop a taste for life as\nhe gets older, and it can also happen that an\nentirely successful young man starts rolling\ndownhill, hitting rock bottom. But genera-\ntions, overall, agree on the fact that life is\ngetting worse the older you get. This is how a\nshift in layers of generations takes place.\nThis means that the layer of the older gener-\nation is moving to the worse side, while the\n330/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1053
  },
  {
    "chunk_full": "layer of youth is lagging behind, but it is ba-\nsically moving in the same direction. This\nshift takes place gradually, each time starting\nfrom an optimistic point of view. This is ex-\nactly why the world as a whole does not ever\nturn into hell. Everyone has their own layer,\nwhich they have chosen themselves. Human-\nkind does have the possibility to choose a\nlayer for itself and that is what it does. It is\nalready somewhat clearer to you how human\nbeing could go about choosing a harmful lay-\ner for themselves.\nIn previous chapters, we have talked about\nhow to avoid creating hell in your layer. But\nhow do you return to the world that was be-\nfore, to the tracks where life was full of colors\nand hopes, just like it was in your childhood\nand youth? This can also be done with the\nhelp of Transurfing. But for starters, we must\nfigure out how we have gone from the tracks\nso successful and full of hope, to the tracks\n331/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1054
  },
  {
    "chunk_full": "where someone could ask us, “Well, and how\nin the world did you end up like this?”\nThe\nFunnel\nof\nthe\nPendulum\nThe psyche of a man works in the following\nway – it reacts more to negative irritants.\nThese could be undesired information, hos-\ntile actions, danger or simply negative en-\nergy. Of course, positive influences can also\nstir up strong emotions. But fear and rage by\nfar excel joy and happiness in strength. The\nreason for this inequality comes from an-\ncient times, when fear and rage were the cru-\ncial factors for survival. What is useful about\njoy in a context like that? It won’t help to de-\nfend oneself nor will it help to avoid danger\nor to get food. And then, of course, life was\nfilled with burdens and hardship throughout\nthe entire history of man, and brought more\n332/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1055
  },
  {
    "chunk_full": "grief and fear than joy and happiness. This\nwas the origin of man’s tendency to more\neasily yield to gloomy thoughts and depres-\nsion, while joy and happiness vanishes rather\nquickly. Have you ever heard, for example, of\na normal person suffering from too much\njoy? However, people suffer from stress and\ndepression quite often.\nPendulums and, in particular, the mass me-\ndia, actively make use of these peculiar fea-\ntures of human perception. You rarely hear\nanything good in the news. Usually, in a\nnews program, it works something like this:\nyou get hold of a negative fact, you follow up\non the story with extra coverage, new details\nemerge,\nand\neverything\nis\nthoroughly\nsavored and dramatized in a number of\nways.\nBy the very same principle, we are presented\nwith other news: catastrophes, natural dis-\nasters, terrorist acts, armed conflicts and so\n333/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1056
  },
  {
    "chunk_full": "on. Notice the pattern at work here. Events\ndevelop in a spirallike manner: in the begin-\nning there is the plot, then the story is un-\nraveled, exposing further details, the tension\nis rising, then there is a culmination, emo-\ntions are already flaring to their maximum,\nand finally, the story comes to a conclusion –\nall of the energy is dissolved into space, and\na temporary calm descends upon the view-\ners. Remember how the waves beat against\nthe shore. The endless numbers of TV series\nare made by the very same principle. From\nan objective point of view, there is nothing\nspecial about them, all the “drama” is liter-\nally created out of thin air. Nevertheless, all\nyou have to do is watch two or three epis-\nodes….and you’re hooked. Why? After all,\nnothing particularly interesting ever happens\nin these soap operas. But you’re hooked be-\ncause the frequency of thought radiation is\ncaught by the pendulum of the TV series, and\n334/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1057
  },
  {
    "chunk_full": "your attention is becomes fixed on a given\nsector.\nLet’s look at the mechanism that is respons-\nible for the unwinding of the above-men-\ntioned spiral. At the beginning, a man is con-\nfronted with the fact that could theoretically\nupset him – or not. Let’s suppose that it’s a\npiece of news about a negative event that\ntook place somewhere in another country.\nThis is the first push of the destructive pen-\ndulum. If the news somehow affects the per-\nson, he starts responding to the stimulus: he\nexpresses his attitude to it, he lives through\nit. Meaning that in response, he is radiating\nenergy of the same order and on the very\nsame frequency as the first push of the pen-\ndulum. This person, just like many thou-\nsands of others, answered the pendulum\nwith interest and participation. The radiation\nenters into resonance with the pendulum\nand thus, its energy has increased. The mass\nmedia continues its campaign. The man\n335/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1058
  },
  {
    "chunk_full": "follows further development of events with\ninterest, so the pendulum once again re-\nceives nourishment. This is how the pendu-\nlum entices adherents into its own net and\nkeeps pumping energy from them. People\nthat were interested in this piece of news al-\nlow negative energy to get to them, and thus\nthey get involved in the game, as observers\nfor the time being.\nAt first glance, nothing extraordinary has\nhappened, it’s an everyday matter. So what if\na man gives a bit of his energy to feed a de-\nstructive pendulum? It practically hasn’t af-\nfected his health. However, in reality, radiat-\ning energy at the frequency of negative\nevents, a man is moving to the life tracks\nwhere similar events will take place closer\nand closer to him. He takes part in the cre-\nation of the plot and finds himself in the ac-\ntion zone of the spiral, which is unwinding,\nspinning faster and faster, drawing him in,\nlike a funnel. The interaction between the\n336/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1059
  },
  {
    "chunk_full": "man and the pendulum becomes tighter and\ntighter, and the man already accepts the\nabove mentioned event to be an unavoidable\npart of his life. His attention becomes select-\nive and everywhere new facts about similar\nevents in different countries start popping\nup. The man discusses this news with his\nclose friends and relatives, and they react\nwith interest and compassion. The energy of\nthe pendulum is growing, while the man is\ngetting closer, by the frequency of his radi-\nation, to the tracks where he is no longer an\nobserver, but a direct participant in the\nevent.\nLet’s\ndefine\nthat\nphenomenon\nof\nbeing\ndrawn into the funnel as an induced trans-\nition to a life track where the adherent be-\ncomes a victim of the destructive pendulum.\nThe following process can be identified as an\ninduced transition: you respond to the push\nof a destructive pendulum, the pendulum\npushes back giving you a little energy from\n337/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1060
  },
  {
    "chunk_full": "its swinging, and you get further and further\ninvolved, giving more and more energy to\nthe pendulum. Consequently, an induced\ntransition has been initiated, taking you to a\nlife track that is by its frequency close to the\nswings of the pendulum. As a result, the neg-\native event is included in the layer of this\nperson’s life.\nDisaster\nMany people, in one way or another, would\nagree that there is a theoretical possibility for\nthem to be in a disaster10. But not all of them\nallow this possibility to enter the layer of\ntheir world. There are people who don’t\nwatch TV series, who aren’t interested in the\nnews, who aren’t bothered by every little\nevent\nthat\nhappens\nsomewhere\nand\nto\nsomeone. They live in their own layers and\nthey are adherents of other pendulums. They\ndon’t worry when they hear that an airplane\n338/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1061
  },
  {
    "chunk_full": "crashed somewhere in the world. They listen\nto the news about events like that, while\ncalmly chewing away at their dinner. They\nhave enough of their own problems.\nPeople are more vulnerable to an induced\ntransition if they are interested in disasters,\nif they get concerned and worry about dis-\nasters\nthat\nhappen\nelsewhere\nto\nother\npeople. If the life of a man is not too packed\nwith problems and worries, then he tries to\nfill this void by turning his attention to\nevents in the layers of other people. Such a\nperson\nregularly\nreads\nthe\ntabloids\nor\nwatches TV series, or is waiting for new in-\nformation about catastrophes and natural\ndisasters. The tabloids and TV series repres-\nent the activity of small and harmless pendu-\nlums. Adherence to them only makes up for\ndeficiency of information, emotions and feel-\nings. But getting interested in the destructive\npendulums\nof\ncatastrophes\nand\nnatural\n339/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1062
  },
  {
    "chunk_full": "disasters poses a real threat. They are strong\nand very aggressive.\nIf a man pays attention to events like that\nthen the frequency of thought radiation is\ncaptured in the same way as in the case with\nTV series. Having expressed an interest in\nnegative information, one will always get it\nin abundance. At the beginning, he accepts\nthe harmless role of an observer. He is, as if\nsitting on the stands, watching a soccer\ngame. He gets more and more captivated by\nthe game until he becomes an active fan.\nThen he runs onto the field and starts run-\nning after the ball but does not get it yet.\nGradually and unnoticeably, he is drawn fur-\nther into the game and finally he will even\nget to kick the ball. The observer has been\ntransformed into a player, and in this case,\ninto a victim of disaster.\nAnd how could it be otherwise? After all, dis-\nasters have become a part of the man’s life,\n340/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1063
  },
  {
    "chunk_full": "he let them into his layer himself and he un-\nwillingly accepted the destiny of a victim.\nConsequently, he materialized an unfortu-\nnate variation. Of course, he didn’t want to\nbe a victim, but that’s not important. Once a\nman accepts the game of the pendulum, the\nroles are defined by the pendulum and not\nby the man. Therefore, if for many other\npeople the given disaster is only a fatal coin-\ncidence, then to our victim it is a natural and\nlogical end. The probability of our hero being\nin the wrong place at the wrong time is\nalready higher than average.\nIf you ignore the shoves of destructive pen-\ndulums, then you will never find yourself in\nthe middle of a disaster. Let’s put it this way,\nthe probability of you being in a disaster will\nbe close to zero. You could object: but why\ndo thousands of people die in catastrophes\nor natural disasters? Does this mean that\nthey are all thinking about catastrophes at\nthe same time? The thing is that you are not\n341/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1064
  },
  {
    "chunk_full": "the only one living in this world. You are sur-\nrounded by lots and lots of people, who are\nactively working on destructive pendulums\nand emanate energy in the range of these\npendulums. No one can completely isolate\nhimself from this radiation. The field of radi-\nation captures you and you start emanating\nenergy on the same frequencies, without\neven being aware of it yourself. This behavior\nstems from ancient times, when herd instinct\nand\ngroup\ndynamics\nhelped\nindividuals\navoid danger. That is exactly why the energy\nfield of induced transition grows, reaching a\nsnowballing effect, and draws you in, as into\na funnel.\nThe objective is to be as far away as possible\nfrom the center of the funnel. This means –\ndon’t let information about catastrophes and\ndisasters get to you, do not become inter-\nested in them, do not live through them emo-\ntionally, as if they have happened to you, do\nnot\ndiscuss\nthem.\nBasically,\nlet\nany\n342/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1065
  },
  {
    "chunk_full": "information concerning disasters pass you\nby. Note the difference: don’t avoid informa-\ntion just don’t let it get to you. As you know\nfrom the previous chapters, avoiding any en-\ncounters with a pendulum is the same thing\nas to look for encounters with it. When you\nare against something, or you really don’t\nwant it, or express aversion to it, you are act-\nively emanating energy on the frequency of\nwhat\nyou\nwant\nto\navoid.\nNot\nletting\nsomething get to you means to ignore it, not\nto react to any negative information on the\nsubject. Just shift your attention to harmless\ntelevision programs and books.\nIf you can’t refrain from reacting, then you\ncan at least rely on your Guardian Angel. For\nexample, if you are afraid of flying on air-\nplanes, don’t fly. If there is fear in the first\nplace, then it means that in the range of your\nradiation, there is a frequency which reson-\nates with the life track on which a disaster in\nthe air is marked out. It does not mean in\n343/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1066
  },
  {
    "chunk_full": "any way that you will certainly get on this\ntrack, but nonetheless there is a probability\nof this happening. If you simply don’t think\nabout any danger on an airplane, then there\nis nothing to be afraid of. On the contrary, if\nyou experience unusual anxiety before get-\nting on a plane, it would be wise to skip that\nflight. If it’s simply impossible for you not to\nfly, then you need to learn how to listen to\nthe rustling of the morning stars. What it is\nand how it is done, you have yet to discover.\nWar\nWar breaks out in basically the exact same\nway as a simple fight. At first, one side tells\nthe other its opinion on something. The oth-\ner has the opposite view on things, and the\nopinion first expressed thus serves as a push\nof a destructive pendulum. The second party\nresponds to the first push with somewhat\nhigher amplitude. In reply to this, the first\n344/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1067
  },
  {
    "chunk_full": "party again responds with more aggression.\nAnd so it keeps growing, until it finally\ncomes down to a physical conflict.\nThus, before us we have a simple and graphic\nimage of two fighting pendulums that are,\nwhile hitting against each other, swinging\nhigher and higher. There are many factors\nresponsible for the outbreak of war and re-\nvolutions, but the essence is the same. At\nfirst, people are told that they are living a\nmiserable life. Everyone quickly agrees – the\nfirst action of the pendulum has been accep-\nted. Then the following explanation appears\n– other people are in the way of our people’s\nwelfare. This stirs up righteous anger – the\npendulum is now swinging. Then comes a\nprovocation from one or the other side,\nwhich stirs up a storm of resentment – the\npendulum has gathered force and thus, the\nwar or revolution can begin. Each strike of\nthe pendulum gives rise to a response, which\nonly\nfurther\nstrengthens\nthe\nswinging.\n345/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1068
  },
  {
    "chunk_full": "Hence, the people that take part in this game\nare experiencing a avalanche-like transfer\nonto a life track where tension is mounting.\nYou can only change the situation in the be-\nginning of a conflict. Once the conflict is es-\ntablished, the situation is already out of con-\ntrol. When the spiral is only starting to coil,\nyou could respond to the first lunge of the\npendulum amicably or by simply stepping\naside, and the pendulum will fall through or\nit will be extinguished. Consequently, there\nwill be no transfer to a new branch – that is,\nto a new life track. However, if you accept\nthe pendulum’s swings, then your frequency\nof radiation will approach the parameters of\nthe spiral’s new branch – the new life track.\nUnfortunately, if an individual participant\ndoesn’t react to the pendulum, this does not\nyet guarantee that he will not be drawn into a\nwar or a revolution. If you’ve stepped into a\npowerful whirlpool, then no matter how you\n346/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1069
  },
  {
    "chunk_full": "try, it will be almost impossible to get out of\nit. However, if the participant doesn’t accept\nthe pendulum’s game, he will at least get ad-\nditional chances to remain alive and come\nout of the conflict with the smallest possible\nlosses. At this point you should have a good\nunderstanding of what it means to not accept\nwar. You could hate it or be actively against\nit, fighting it. But whether you are for or\nagainst war, it’s all the same to the pendu-\nlum. It gets energy from either side. If the\nenergy emanates at the frequency of war, a\ntransfer takes place onto the corresponding\ntrack. You acknowledge the war, participate\nin it – you are on the field of battle. You fight\nagainst the war – it will consume you\nnonetheless.\nTo not accept the pendulum means to ignore\nit. Of course, you can’t always ignore it – that\nis the danger of an induced transition. Well,\nit would at least be useful not to take any po-\nsition, be that of an advocate or an opponent\n347/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1070
  },
  {
    "chunk_full": "of war. In all times, neutral governments\nhave existed that have been standing aside,\nobserving how entire nations destroyed one\nanother. Look at the demonstrations and\nmeetings\nwhere\npeople\nfuriously\nprotest\nagainst war activities. For the pendulum, try-\ning to unleash the fight with its own rivals,\nthese opponents of war are just as commit-\nted and desired adherents, as supporters of\nthe conflict. Active protest is the very same\nas support of war, although naive adherents\nare convinced of the contrary. Peaceful sug-\ngestions and exposing the true face and\nmotives of the pendulum – these are the ac-\ntions that can put war out. Do you remember\nthe allegory with the nest of wild bees? The\npendulum tells its adherents that the bees\nare dangerous and therefore must be des-\ntroyed. But what does the pendulum really\nneed, maybe their honey?\n348/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1071
  },
  {
    "chunk_full": "Unemployment\nAs we’ve already mentioned, there are differ-\nent ways in which you can participate in the\ngame of a pendulum – both by supporting it\nand by trying to reject it. The latter is, per-\nhaps, even more dangerous, since the desire\nto avoid a pendulum creates an excess poten-\ntial that will draw you into the funnel of\ntransition. Everybody or almost everybody is\nnowadays afraid of losing their jobs. An in-\nduced transition to the state where you live\nout on the streets is very insidious indeed.\nEverything begins with the smallest and\nmost harmless thing. This could be a rather\nweak first sign: you overhear that your com-\npany is not doing as good now as it did be-\nfore. Or someone you know has lost his job,\nor there are rumors going around about re-\ndundancies, or something like that.\n349/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1072
  },
  {
    "chunk_full": "On a subconscious level, invisible to you, a\nred light has gone off. Shortly thereafter, an-\nother signal comes – for example, inflation is\non the rise. This is already putting you on\nyour guard and, incidentally, the same is\nhappening to others. People are starting to\ntalk and the pendulum of unemployment is\nalready being fed with energy. There is\nalready news about a dip in the stock market\nand the general tension is mounting. Worry\nis quickly replaced with anxiety, and then by\nfear. You’re already vigorously generating\nenergy on the frequency of a life track where\nyou see yourself without a job.\nWhen you are carrying around the fear of be-\ncoming unemployed, you can count on it be-\ning as obvious as wearing a sign around your\nneck that said “I can be fired.” If you think\nthat you can hide this fear, you are very mis-\ntaken. Passing gesticulations, certain intona-\ntions and inflections in your voice, can some-\ntimes tell more than words. Having lost\n350/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1073
  },
  {
    "chunk_full": "confidence in yourself, you are already not as\neffective a worker as you were before. Things\nthat were a piece of cake to you before are\nnow not going too well. There is tension in\nyour interactions with coworkers, who are in\nthe same position as you are. You bring your\nnervousness home to the family and instead\nof supporting you, they begin to accuse and\ncriticize you. That’s it, stress is developing\nand you are no longer a worker – there is a\nsign around your neck with the following\nwords: “Ready to be fired.”\nThe feeling of guilt is what causes your fear\nof being fired. This feeling of guilt is either\nsmoldering or burning with a bright flame in\nyour subconscious. Who do they usually fire\nfirst? That’s right, the worst ones. If you have\nallowed yourself to think that you could be\nworse than others, then that assumption by\nitself has put you on the black list. Turn away\nfrom the feeling of guilt. Allow yourself the\nluxury of being you. And if you’re not\n351/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1074
  },
  {
    "chunk_full": "successful, start looking for another job. The\nexcess potential of emotional worries is\nscattered\nand\ndissolved\nthrough\naction.\nSome people start looking for a new job, as\nsoon as they are employed. They are not do-\ning this because they intend to change jobs\nimmediately. Insurance brings confidence:\njust in case, there is an alternative option. If\nyou are calm about your future, the action of\nthe balancing forces won’t touch you.\nEpidemic\nYou are probably thinking that no….we can’t\nbe talking about life tracks, when talking\nabout contagious diseases. Somebody gets ill\nsimply because he’s been infected. And you\nwould be right, but only in that a person al-\nlowed himself to get infected. I certainly\ndon’t mean to say that someone who gets ill\nshould have walked around with a mask on –\nthat wouldn’t have saved him anyway. You\n352/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1075
  },
  {
    "chunk_full": "don’t believe me? Well, I won’t be able to\nprove it to you by using theoretical argu-\nments – just as I would not be able to prove\nanything that’s being said in this book.\nHowever, you wouldn’t be walking around\nwith a mask on during a flu epidemic, just to\ntest whether the mask is working or not.\nTherefore, I’ll just tell you what I know.\nWhether you believe it or not is up to you.\nSo, let’s uncover the history of disease. The\nreason for your illness is your voluntary\nagreement to take part in the game called\n“Epidemic.” Everything begins with hearing\nthat there is an epidemic – let’s say the flu is\nalready going around somewhere. Every nor-\nmal person knows that the flu is transmitted\nthrough\nthe\nrespiratory\nsystem.\nCon-\nsequently, you, like all normal people, com-\npletely allow the possibility that this could\nhappen to anybody. Immediately, your mind\nstarts playing the being-sick movie: you have\na fever, you’re sneezing and coughing. That’s\n353/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1076
  },
  {
    "chunk_full": "it – from this moment on, you are already in\nthe\ngame,\nbecause\nyou\nare\nemanating\nthought energy at the frequency of a de-\nstructive pendulum.\nYou’re already subconsciously looking for\nconfirmation that an epidemic is actually\nhere, and your attention becomes selective.\nSneezing people are all around you. They\nwere always there, you simply didn’t notice\nthem before. At work and at home, from\ntime to time, someone will raise the subject\nof the flu. Your assumption that an epidemic\napproaches is being confirmed by more and\nmore evidence. Even if you’re not particu-\nlarly looking for confirmation, and the sub-\nject doesn’t particularly worry you. Some-\nhow, confirmation takes place by itself.\nIf, from the very beginning of the game, you\nhave tuned yourself to the frequency of the\ndestructive pendulum, your bonds to it will\nbecome stronger and stronger, regardless of\n354/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1077
  },
  {
    "chunk_full": "your conscious participation. Well, and if you\nwouldn’t mind getting sick or if you feel that\nyou’re destined to get sick, it means that you\nare already the most active adherent of the\npendulum. Or no, you’ve decided not to get\nsick and you keep telling yourself that you\nare absolutely healthy and will not get sick. It\nwon’t work. You are thinking about the ill-\nness, so you are emanating on the frequency\nof this illness. The direction of thoughts – for\nor against – is not important. In other words,\nif you try to convince yourself that you will\nnot get sick, then from the beginning, you\nare allowing the possibility of getting sick,\nand no persuasion on your part will help you\nstay healthy.\nWords pronounced out loud are simply ren-\ndering air, words said to oneself are nothing\nat all – but belief is a powerful energy, even\nif it is not audible. You will not save yourself,\neven if you’ll run and get vaccinated. It\ndoesn’t matter, because you are going to be\n355/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1078
  },
  {
    "chunk_full": "ill for a period of time, one way or another.\nThe first symptom of your illness gives you a\nchoice: will you, after all, be sick or not? You\nmake weak attempts to resist and finally, you\nface the fact that you are getting ill. This\nbrings the final adjustment in your radiation\nand you move to a life track where illness as-\nsumes full control.\nThe induced transition started from the mo-\nment the pendulum was accepted. If you\ntruly don’t care at all about this epidemic,\nthe transition won’t take place. Or if you are\non vacation, haven’t been talking to anyone,\nhaven’t heard any news, and know nothing\nabout the epidemic, the pendulum won’t\ntouch you. It will simply fall through, as if in-\nto empty space.\nHave you ever wondered why doctors don’t\nbecome\ninfected?\nMany\nare\neven\nbold\nenough to work without protective masks.\nIt’s\nnot\nbecause\nthey\ngive\nthemselves\n356/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1079
  },
  {
    "chunk_full": "vaccines. You can’t vaccinate yourself against\nall illnesses. The thing is that doctors are also\nactively playing the game of the illness pen-\ndulum, but they have an entirely different\nrole. By analogy, when you get the chance,\nwatch\nthe\nstewardesses\non\nan\nairplane.\nThese good fairies insistently recommend\nthat all passengers fasten their seat belts,\nwhile they themselves fly about the cabin, as\nif in the event of a crash, they would simply\nhover in the air like hummingbirds.\n“Well, and what about babies, infected with\nAIDS?” – a meticulous Reader would ask.\n“What, they also radiate energy of trans-\nition?” First of all, here we are only looking\nat the question of an epidemic as a tendency.\nSecond of all, I am not trying to show that in-\nfections in general don’t exist and that there\nis only radiation of thought energy on the\nfrequency of illness. Transurfing is not a\ndogma and nor is it the last stop on the way\nto the truth. One should not take any idea to\n357/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1080
  },
  {
    "chunk_full": "be the absolute truth. We can only be looking\nat patterns and regularities. Truth is always\n“somewhere real close”, but where exactly –\nnobody knows.\nPanic\nThis is the most intensive and quickly in-\nduced transition. Panic among people is the\nmost able phenomenon to highlight all the\ndistinctive features of an induced transition.\nFirstly, the spiral coils very strongly when\nyou panic, because a signal of real danger al-\nways sounds very convincing and a man\nwould immediately be drawn into the game\nof a destructive pendulum. For that same\nreason, the pendulum increases its swinging\nmuch faster, practically like an avalanche.\nSecondly, when panicking, a man almost\ncompletely loses control over himself, which\nmeans that he turns into a sensitive receiver\n358/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1081
  },
  {
    "chunk_full": "and at the same time into an active re-trans-\nmitter of the pendulum’s swings. And finally,\nthe pendulum itself finds an ideal way to ma-\nterialize itself, in the form of a crowd. Unfor-\ntunately, all these factors make it very diffi-\ncult to make a pendulum fall through or to\nextinguish\nit.\nIn\nmoments\nof\npanic,\nit\nwouldn’t even occur to a person to think\nabout ways of struggling with a pendulum.\nHowever, if you can get a grip on yourself\nand not give in to panic, then you have a very\ngood chance of saving your own life and the\nlives of those close to you. For example, on a\nsinking ship, there’s always a scuffle around\none of the ship’s rescue boats, while the\nboats nearby are empty. If one would only\ntake a moment to look around, he would no-\ntice the empty boats. But this is precisely the\ninsidious quality of an induced transition in\nthat\nit\nworks\nlike\na\nfunnel,\nsucking\neverything around it into itself, making you\nlose sight of possible alternatives.\n359/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1082
  },
  {
    "chunk_full": "Poverty\nIf we are to think logically, how can a simple\nman who was born in the slums get rich? We\nwon’t look at the criminal way of doing it or\nat beautiful stories about people becoming\nmillionaires overnight. So, reasoning based\non common sense won’t lead us to any co-\nherent conclusion. Then what is the use of\nordinary logic to you? Transurfing can’t be\nput into the frame of common sense; but\nthen again, it allows you to do what appears\nto be impossible.\nActing logically, people get the correspond-\ning result. If a man was born in poverty, he\nwill find himself in poor surroundings. Thus,\nhe is accustomed to it and is tuned to the en-\nergy radiation at the frequency of his own\nmiserable life. It will be very difficult to move\nover onto a track of prosperity, if you feel\nonly hatred toward your own poverty, envy\n360/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1083
  },
  {
    "chunk_full": "toward the wealthy, and your own desire to\nbecome well-off. Or actually, no, I would say\nthat having only these three things at your\ndisposal, moving over to a track where you\nare wealthy would be practically impossible.\nLet’s take a look at why that is.\nProbably one of the first discoveries all chil-\ndren make, when coming into this life, is the\nfollowing: the fact that you don’t want\nsomething, doesn’t yet mean that you will be\nfree of it. Sometimes, the soul simply cries\nout in despair: “But I don’t want that! I\nsimply hate it! Why won’t it leave me in\npeace? Why is this always happening to me?”\nIn a fit of indignation, not only children, but\nalso adults ask themselves a similar ques-\ntion. It is really difficult to accept the follow-\ning situation: if you don’t want something, it\nwill nonetheless happen. And if you hate it,\nthen it will follow you wherever you go. You\ncan hate your poverty, your work, your\n361/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1084
  },
  {
    "chunk_full": "physical flaws, your neighbors, the bums on\nthe street, alcoholics, drug addicts, dogs,\nthieves, criminals, the impudent young, the\ngovernment….The more you hate something,\nthe more you will encounter it in life. And\nyou already know why. It gets to you, you\nthink about it, and that means you emanate\non the frequency of a life track where the\nthing you don’t want exists in abundance. It’s\nnot important what polarization this radi-\nation takes: “like it” or “don’t like it.” The\nsecond is even more effective, because the\nemotions are stronger. On the other hand,\neverything that is unpleasant to you would\nbe to you a destructive pendulum, and that’s\nwhy you swing the pendulum even higher\nwith your own emotional suffering. And fi-\nnally, if you actively hate it, it means you are\ncreating an excess potential. The balancing\nforces will be directed against you, because\nit’s easier for them to eliminate one oppon-\nent than to change the world that doesn’t suit\n362/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1085
  },
  {
    "chunk_full": "someone. See how many harmful factors\nthere are in a negative attitude towards life!\nLet’s return to the man who was born in\npoverty. He has a dream to get rich. But one\ndesire alone, as you know, won’t change any-\nthing. You could be lounging on your sofa\nand lazily thinking: “It would be nice with a\nbowl of strawberries. But where can I get\nsome? It’s impossible, because it’s winter\nnow.” In practically the same way, a poor\nperson is dreaming of getting rich.\nIf a man is not ready to act in order to get\nwhat he wants, he won’t get it. And he\ndoesn’t act, because he is convinced that it\ndoesn’t matter, because nothing good will\ncome of it. That’s a vicious circle for you.\nDesire itself doesn’t have any power. It can’t\neven lift a finger. It is your intention, your\nreadiness to act that is responsible for lifting\nthe finger. Intention also includes the readi-\nness to have. A man could say, “Well, I’m\n363/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1086
  },
  {
    "chunk_full": "really ready to have some riches! It is so\nsimple after all, I do want to become rich!”\nNo. Again, there is a deep abyss between “to\nwant” and “to be ready to have”. For ex-\nample, a poor person feels “like a fish out of\nwater” in a rich environment or in an ex-\npensive shop, even if he tries with all his\nmight to convince himself and others of the\nopposite. In the depths of his soul, he feels\nthat he is not worthy of any of this. Riches\ndon’t enter the poor fellow’s zone of comfort,\nand not because being rich is uncomfortable,\nbut because he is too far away from all this. A\nnew armchair is better, but then the old one\nis more comfortable.\nA poor person only sees the external side of\nwealth: luxurious houses, expensive cars,\ndecorations, clubs… If you were to put a poor\nperson in such an environment, he would\nfeel uncomfortable. And if you were to give\nhim a suitcase full of money, he would start\n364/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1087
  },
  {
    "chunk_full": "doing all sorts of stupid things and in the\nend, he would lose everything. The frequency\nof energy, which he transmits, is in sharp\ndissonance with a wealthy life. And until the\npoor person puts the attributes of wealth in\nhis comfort zone, until he learns how to feel\nas the owner of expensive things, he will re-\nmain poor, even if he finds buried treasure.\nYet another obstacle on the way to wealth is\nenvy, because, as you know, to envy someone\nmeans to be annoyed with his or her success.\nIn this sense, there is nothing constructive\nabout envy. Moreover, envy has one very\nstrong, destructive element. A man’s psyche\nworks in the following way: if he envies\nsomething that he would want to have, then\nhe tries to devalue it in every possible way.\nHere is the logic behind the concept of “be-\ning green with envy”: “I envy what he has. I\ndon’t have it and I’ll probably never have it.\nBut how am I worse than him? So, the thing\n365/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1088
  },
  {
    "chunk_full": "he owns is lousy and I need it like a fish\nneeds a bicycle.”\nThis is how desire to have becomes a psycho-\nlogical defense and then turns into rejection.\nRejection takes place on the subtle level, be-\ncause\nthe\nsubconscious\nunderstands\neverything literally. Consciousness devalues\nthe object of envy only for show, to calm it-\nself, while the subconscious takes everything\nseriously. And here it does more harm than\ngood, doing everything in its power so that\nthe man won’t get the devalued and rejected\nthing.\nThus, you can see what tenacious forces hold\na person on a poor life track. Events unfold\neven more dramatically during an induced\ntransition of a prosperous person to a poor\nlife track. It does happen that a completely\nsuccessful individual loses everything and\nfinds himself on the street. The most insidi-\nous thing about this induced transition to\n366/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1089
  },
  {
    "chunk_full": "poverty is that the spiral begins to unwind\nvery slowly and then faster and faster, until it\nis impossible to stop.\nThis spiral starts off with temporary finan-\ncial difficulties. Observe - temporary finan-\ncial difficulties can happen at any moment\nand to anybody. It’s such an ordinary, un-\navoidable thing as, say, the rain on the day\nwhen you wanted to have a picnic. If you\ndon’t fall into rage, depression, agitation or\ntake offense at life because of this difficulty,\nthen the swings of the destructive pendulum\nwill die out because you did not give your en-\nergy away to the pendulum. An induced\ntransition begins only in the case of you hav-\ning grabbed onto the end of the spiral. In or-\nder for the spiral to start spinning, your re-\nsponse to the pendulum is needed.\nYour first reaction to the pendulum’s push is\ndiscontent. This is for now too weak of a sup-\nport for the pendulum, and if your emotions\n367/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1090
  },
  {
    "chunk_full": "end here, the pendulum will die out. Another\nreaction is indignation, and this feeling is\nstronger, so the pendulum will regain its\nspirit, sending you information that someone\nis to blame for your financial difficulties. To\nthis second push, you’ll respond with negat-\nive comments or actions towards the guilty\nparty. At this moment, the destructive pen-\ndulum has already become fully animated\nand thus, a new branch of the spiral is taking\nform: your next salary will be smaller, or\nprices will shoot up, or someone will sud-\ndenly demand that you repay your debt.\nNotice that, at the current stage, you don’t\nyet realize that a process is going on. It could\nsimply be an unfortunate event. But in fact\nthis is a directed process, which you induced\non your own, being responsible for the\nswings of the pendulum. The frequency of\nyour energy radiation is further rearranging\nitself from the track where you are prosper-\nous, to the track where you are deprived and\n368/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1091
  },
  {
    "chunk_full": "annoyed. Therefore, you move to the tracks\ncorresponding to these new parameters.\nAnd thus, your situation is getting more and\nmore serious. Bad news start pouring in on\nyou from everywhere: prices are rising, your\ncompany is not going well. You begin to act-\nively discuss this negative news with close\nfriends and relatives. These discussions are,\nusually, of a destructive sort – that is, they\nconsist of complains, discontent and aggres-\nsion towards the supposed guilty parties.\nThis is especially pronounced in companies\nwhere business is indeed bad. At a company\nlike that, the day begins with the postulate\nthat “there’s no money”, as if it were a morn-\ning prayer.\nAt this point you have already been captured\nby the spiral, and your radiation is tuned to\nthe frequency of the destructive pendulum.\nBecause things are constantly getting worse,\nyou’ll get ridden by anxiety. The energy of\n369/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1092
  },
  {
    "chunk_full": "anxiety, despite its small size, is very well as-\nsimilated by the pendulum, making the pen-\ndulum bolder and bolder. In the state of\nanxiety, you will unavoidably be creating an\nexcess potential all around you: discontent,\naggression, depression, apathy, resentment\nand so on. Now, when the destructive pendu-\nlum has been joined by balancing forces, the\nsituation gets out of control and starts to de-\nvelop in a snowballing manner. You feel fear\nand let yourself run amok.\nIt’s as if someone took you by the hands and\nstarted spinning you round and round, only\nto let go of you suddenly and quickly. You fly\noff to the side, fall down, and remain lying in\nshock.\nThat’s\na\nterrifying\npicture.\nBut\neverything started with small financial diffi-\nculties. The pendulum doesn’t need your\nmoney, because it is only interested in the\nnegative energy you are emanating when\nyour money is melting away. As a result,\nwhen\nthe\nspiral\nhas\nunwounded,\nthe\n370/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1093
  },
  {
    "chunk_full": "unfortunate person, in the best case, loses\nquite\na\nlot,\nand\nin\nthe\nworst\ncase\n–\neverything. He is no longer of interest to the\ndestructive pendulum – there is nothing\nmore to take from him. Further on, events\ncan be unfolding in several ways: either the\nunfortunate remains laying on the unsuc-\ncessful track, or he tries with difficulty to pull\nhimself out. Such an induced transition can\nhappen with individual persons as well as\nwith large groups of people. In the latter\ncase, as you can imagine, the spiral is not a\nspiral anymore, but a real whirlpool from\nwhich it’ll be very difficult to get out.\nThe only way to avoid an induced transition\nis not to grab onto the end of the spiral, not\nto get involved in the game of the destructive\npendulum. It’s not enough to simply know\nhow this mechanism works. You need to con-\nstantly keep it in mind. Your Overseer must\nnot sleep. Pull yourself together every time\nyou accept a pendulum’s game by habit, as if\n371/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1094
  },
  {
    "chunk_full": "in a dream – that is, when you show discon-\ntent, indignation, anxiety, when you take\npart in destructive discussions and so on. Re-\nmember: everything that makes you react\nnegatively is the provoking action of de-\nstructive pendulums. The exact same thing\nhappens in dreams: until you realize that it is\na dream, you are a puppet in someone else’s\nhands, and you could be tormented by night-\nmares. As soon as you wake up, shake off\nthese delusions and realized the true nature\nof the game – that’s it, you’re the master of\nthe situation. You won’t become a victim of\ncircumstances, while everyone around you is\nin a zombie-like state.\nSummary\nEach man creates a separate layer of the\nworld, where he lives.\n372/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1095
  },
  {
    "chunk_full": "The world of people as a whole consists of\nindividual layers, placed on top of each\nother.\nWhen emanating negative energy, a person\nis making the layer of his world worse.\nAggression is mistakenly taken to be a sign\nof strength and dissatisfaction is seen as a\nnormal reaction.\nA response to a negative event induces the\ntransfer to negative life tracks.\nAn induced transition includes a negative\nevent in an individual person’s layer.\nDon’t allow any negative information into\nyour layer.\n“Don’t allow” means not to avoid, but to in-\ntentionally ignore and not become inter-\nested in certain kinds of information.\n373/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1096
  },
  {
    "chunk_full": "CHAPTER VI\nTHE FLOW OF\nVARIATIONS\nWhere do the following come from -\npremonitions, intuition, prophecies\nand discoveries, as well as master-\npieces of art? Is it true that the hu-\nman mind is the one which invents\nand creates? The flow of variations\nis a luxurious gift for the mind, but\nman does not have the least suspi-\ncion about it. And what are omens\nand why do they work?\nWhen you go with the flow, the\nworld comes out to meet you.\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1097
  },
  {
    "chunk_full": "The Information Field\nThe space of variations represents an in-\nformation field or an energy matrix – a mod-\nel of what must happen and how it must\nhappen. Energy tuned to a particular sector\nof the matrix “illuminates” it, and the model\nis then realized in material form. Hence, the\nquestion: can this information be used while\nit is still in unrealized form? In other words,\ncan we “see” into the future?\nOne could say that we do this every day. Our\nconsciousness doesn’t know how to get in-\nformation from the space of variations. But\nthe subconscious has free access to the in-\nformation field. This is precisely where pre-\nmonitions,\nintuition,\npredictions,\nproph-\necies, discoveries and masterpieces of art\ncome from.\n375/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1098
  },
  {
    "chunk_full": "Information enters the consciousness either\nfrom the outside world, as an interpretation\nof external data, or from the subconscious,\non the intuitive level. Data that is written in\nthe field is, roughly speaking, truth in its\npurest form. In other words, it is objective\ninformation that is free from any interpreta-\ntions. When truth passes through the filter of\nmind, it turns into an interpretation –\nnamely, into knowledge. All living creatures\nperceive truth through their interpretations.\nA chicken perceives and understands the\nworld in a very different way than that of a\nman. Even different people can perceive and\nunderstand\nthe\nsame\nthings\ndifferently.\nTherefore, knowledge is nothing but a more\nor less distorted form of the truth.\nData in the information field has the form of\ncomplex energy structures. These structures\ncontain everything that makes matter move\naccording to certain laws. At first, data from\nthe information field is received by the\n376/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1099
  },
  {
    "chunk_full": "subconscious (the soul) then consciousness\n(the mind) translates it into a verbal or sym-\nbolic description. This is how discoveries\ncome to be or how something new is created\n–\nlike\nmusic,\nworks\nof\nart\n–\nthat\nis,\neverything that a man couldn’t see or know\nabout directly. This is also how intuitive\nknowledge and premonitions appear.\nAll of this is possibly shocking to you and\nfills you with distrust. So are we saying that\nmind by itself can’t create anything new, but\nis only able to receive data from the informa-\ntion field? Not quite. The mind can construct\na new item or solve a problem, using familiar\nobjects or logical configurations. In other\nwords, the mind can make a new house out\nof\nold\nbricks.\nBut,\nto\ncome\nup\nwith\nsomething entirely new, something that can-\nnot be made out of the old, this the mind\ncannot do.\n377/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1100
  },
  {
    "chunk_full": "Fundamental scientific discoveries do not\ncome as a result of logical reasoning, but as\nflashes of inspiration, like knowledge taken\nout of nowhere. The same is true for great in-\nventions. Good music is not just composed\nfrom a collection of notes, but comes as if on\nits own. Masterpieces of art are created not\nas a result of mastering a professional tech-\nnique, but are born out of inspiration. A\nwork of art that has been painted by some-\nbody who masters a particular technique will\nnot necessarily become a masterpiece. It be-\ncomes a masterpiece because of what lies\noutside the boundaries of excellent technical\nperformance. Poetry that moves the soul is\nnot a result of a logical assorting of rhymes,\nbut comes from the same place – from the\ndepths of the soul.\nArt that is based on inspiration and enlight-\nenment has nothing to do with the mind. It is\nonly later that the mind makes the products\nof such creation its own. For example, the\n378/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1101
  },
  {
    "chunk_full": "mind is able to make a perfect copy of an old\nmasterpiece. But it is not capable of creating\na new one. The mind analyzes data received\nby the subconscious from the field of inform-\nation, and wraps this data in symbolic inter-\npretation – in the form of a melody, a pic-\nture, a poem, a formula, a diagram etc.\nSo far, we are unable to understand how the\nsubconscious gets access to the field of in-\nformation. We can only witness the mani-\nfestation of this access. An example of this is\nclairvoyance – the ability to perceive events\nthat have either happened before, that are\nabout to happen, or that are happening bey-\nond the limits of the clairvoyant’s visual per-\nception. We don’t understand the mechan-\nism of these phenomena and so we call them\nparanormal. The pendulums of fundamental\nscience, not wanting to admit to their power-\nlessness, don’t take paranormal phenomena\nseriously. However, the fact that we can’t\n379/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1102
  },
  {
    "chunk_full": "explain things doesn’t mean they are not\ntrue, and we can’t just simply wave them\naway.\nThere are people who see events in the in-\nformation field as clearly as if they were hap-\npening before their very eyes in the material\nworld. Such people have the ability to tune\nthemselves to a specific sector in the space of\nvariations that has already been manifested.\nFor example, in order to tune oneself into\nthe sector of a missing person, a clairvoyant\nmust\nlook\nat\nhis\nphotograph\nor\ntouch\nsomething of his. Even the police sometimes\nuse the services of such clairvoyants.\nNot everyone can see so clearly, and there-\nfore, mistakes are made. There are two reas-\nons for these mistakes. The first reason is re-\nlated to the fact that clairvoyants can be\ntuned to a sector that has not and will not be\nrealized. Different sectors can, depending on\ntheir relative distances from each other,\n380/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1103
  },
  {
    "chunk_full": "differ either greatly or barely at all in scripts\nand decorations. The second reason why a\nclairvoyant can make a mistake is the inter-\npretation of data by the psychic himself. For\nexample, ancient foretellers and prophets,\nwhen looking at unfamiliar and strange\nscenes from the future, interpreted them in\ntheir own way, deriving from their level of\nknowledge. Therefore, prophecies are some-\ntimes imprecise.\nWhether you believe all this or not is your\nown choice. Keep in mind that Transurfing is\nbut a model, allowing us to use the laws of\nthe world for our own interests. It is not\nmeant to be the description of the world’s\nstructure. Transurfing is also not a stone\nmonument with the inscription “Here is ex-\nactly where the heart of the problem is”.\nTruth, as you know, is always somewhere\nclose. The notion that man is capable of syn-\nthesizing anything new using his mind is also\nonly a mindset. It’s just that we have been\n381/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1104
  },
  {
    "chunk_full": "accustomed to this model for a long time and\nit is suitable for us. It should be noted that\nthis familiar diagram of life is as impossible\nto prove as the Transurfing model. So,\nwhether things happen this way or another is\nnot very important for us, in principle. The\nfact remains that the information from the\nspace of variations somehow reaches our\nears in the form of various hints, visions, en-\nlightenment, signs, and if possible we must\ntry and grasp their meaning.\nKnowledge\nout\nof\nNowhere\nOnly a very small and select number of\npeople are able to clearly read the data from\nthe field of information. The majority of\npeople get only echoes of this data in the\nform of passing premonitions and vague\nknowledge. People involved with science and\n382/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1105
  },
  {
    "chunk_full": "art get enlightened after many days or years\nspent in contemplation. It’s difficult to dis-\ncover something new because it is much\neasier for your thought frequency to tune in-\nto sectors that have already been realized in\nthe space of variations. Something that is\nfundamentally new is always in the unreal-\nized sectors. But how do you tune into them?\nThis is beyond us for now.\nWhen the search for new solutions doesn’t\ngive any results in the realized sectors, the\nsubconscious somehow gets out into an un-\nrealized sector. Such data is not enveloped in\nthe usual symbolic interpretations. There-\nfore, consciousness perceives it as vague and\nunclear information. If the brain is able to\ngrasp the essence of this information, you get\nenlightened and obtain a clear understand-\ning of things.\nThere are many ambiguities and contradic-\ntions in the workings of our consciousness\n383/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1106
  },
  {
    "chunk_full": "and the subconscious. We won’t address all\nthese problems, but will only consider a few\nseparate aspects. For simplicity, so we won’t\nget lost in terminology and semantics, we’ll\nrefer to everything related to consciousness\nas ‘mind,” and everything related to the sub-\nconscious as “soul.”\nIf our mind understood everything that the\nsoul wanted to tell it, humankind would have\nreceived direct access to the field of informa-\ntion a long time ago. It’s hard to imagine\nwhat heights our civilization would have\nreached if that was the case. But it’s not only\nthat the mind doesn’t know how to listen, it\ndoesn’t even want to. A man’s attention is\nconstantly preoccupied with either objects of\nthe external world or with inner thoughts\nand emotional feelings about these objects.\nThe inner monologue almost never stops,\neven though it is under the mind’s control.\nThe mind doesn’t listen to the weak signals\nof the soul, but in an authoritarian voice it\n384/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1107
  },
  {
    "chunk_full": "repeats over and over again whatever it is\npreoccupied with. When the mind “thinks”,\nit operates in categories, classifying qualities\nof visible objects in the materialized sectors.\nIn other words, it thinks with the help of\nwell-established labels: symbols, words, con-\ncepts, diagrams, rules and so on. It tries to\nplace\nall\ninformation\ninto\nappropriately\nlabeled files.\nThere are labels for everything that exists in\nthis world: the sky is blue, water is wet, birds\nfly, tigers are dangerous, winter is cold and\nso on. If information from unrealized sectors\ndoesn’t yet have mental labels, the mind per-\nceives it as some kind of incomprehensible\nknowledge. If a new label can be put on a\npiece of knowledge or it can be explained in\nthe framework of old explanations, then\nthere you go – a discovery has been made.\nIt’s always very difficult to come up with an\nexplanation\nfor\nsomething\nentirely\nnew.\n385/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1108
  },
  {
    "chunk_full": "Imagine a man who hears music for the first\ntime. Music is also information in the form\nof sounds. When the mind receives this in-\nformation, it knows, but doesn’t understand.\nThere is yet no name or label for it. Under-\nstanding comes later, when the mind hears\nmusic many times and all designations and\nobjects associated with music are demon-\nstrated to it: musicians, instruments, notes,\nsongs. But when the mind heard music for\nthe first time, it was totally real and actual\nknowledge and, at the same time, an incom-\nprehensible mystery. In other words, the\nmind knew it was experiencing something\nand that something was in existence, but the\nmind\ncould\nnot\nidentify\nwhat\nit\nwas\nexperiencing.\nTry to explain the following definition to a\nsmall child: “milk is white.” The child is only\njust starting to use abstract categories, thus\nhe’ll ask you a bunch of questions. Well, he\ndoes know what milk is. But what is “white?”\n386/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1109
  },
  {
    "chunk_full": "It’s a color. And what is a color? It’s a prop-\nerty of objects. And what’s a property? And\nwhat’s an object? And so on, forever and\never. It would be easier not to explain what\ncolor is, but to show objects of different col-\nors. Then the child’s mind would be able to\nlabel the parameter where the various ob-\njects differ, using the abstract category of\ncolor. This is how he puts labels and defini-\ntions on everything around him, and then he\nthinks, using these definitions. In contrast to\nthe mind, the soul doesn’t use labels. How\ncan the soul then explain to the mind that\n“milk is white?”\nFrom the time when the mind began to think\nusing abstract categories, its connection to\nthe soul slowly began to die off. The soul\ndoesn’t use these categories. It doesn’t think\nand doesn’t talk, but it feels and knows. It\ncannot express what it knows with words or\nsymbols. Therefore the mind can never agree\nwith the soul. Suppose that the soul is tuned\n387/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1110
  },
  {
    "chunk_full": "to an unrealized sector and has found out\nsomething that does not yet exist in the ma-\nterial world. How can it bring this informa-\ntion to the mind?\nMoreover, the mind is constantly busy with\nits chatter. It thinks that everything can be\nintelligently explained, and is constantly\nkeeping all information under control. The\nmind is only receiving vague signals from the\nsoul, signals that it cannot always identify\nwith the help of its categories. The soul’s am-\nbiguous feelings and knowledge are drowned\nout by the loud thoughts of the mind. When\nthe mind’s control weakens a little, then in-\ntuitive feelings and knowledge can break\nthrough into consciousness.\nThis breakthrough can appear in the form of\na vague premonition, which is also called the\ninner voice. The mind has been distracted\nand in this moment you sensed a feeling or\nsome knowledge of the soul. This is what is\n388/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1111
  },
  {
    "chunk_full": "called the rustling of the morning stars –the\nvoice without words, thoughtfulness without\nthoughts; sound with no volume. You under-\nstand something, but vaguely. You are not\nthinking, but you feel it intuitively. Everyone\nhas at some point in their life experienced\nfor themselves what intuition is. For ex-\nample, you feel that someone’s coming right\nnow, or something is about to happen or you\nsimply know something without being able\nto explain it.\nThe mind is constantly busy generating\nthoughts. The voice of the soul is literally\ndrowned out by this “thought-mixer,” thus\nintuitive knowledge is hard to access. If we\ncould stop this course of thoughts and simply\ncontemplate emptiness, we would be able to\nhear the rustling of the morning stars – the\ninner voice, wordless. The soul can find the\nanswers to many questions, if we would only\nlisten to its voice.\n389/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1112
  },
  {
    "chunk_full": "Teaching the soul to purposefully tune itself\nto unrealized sectors and forcing the mind to\nlisten to what the soul wants to tell it is diffi-\ncult enough. Let’s start out small. The soul\nhas two rather distinct feelings: a sense of in-\nner peace and a sense of inner discomfort.\nThe mind has interpretations for these feel-\nings: “I feel good” and “I feel bad”, “I’m con-\nfident” and “I’m worried”, “I like” and “I\ndon’t like”.\nWith every step you take in life, decisions\nmust be made – to do something or to do\nsomething else. Material manifestation is\nmoving through the space of variations, and\nas a result of this we get what we call “our\nlife”. Depending on our thoughts and ac-\ntions, particular sectors are being realized.\nThe soul has access to the field of informa-\ntion. Somehow it sees what lays ahead in the\nnot yet realized, but approaching sectors. If\nthe soul has tuned in to a sector that has not\nyet been made into reality, it would know\n390/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1113
  },
  {
    "chunk_full": "what is waiting there if it were to be realized:\nsomething nice or something bad. These\nfeelings of the soul are perceived by the mind\nas vague sensations of inner peace or inner\ndiscomfort.\nThe soul very often knows what is expecting\nit. And it tries with a weak voice to notify the\nmind about this. However, the mind almost\nnever listens to the soul or at least doesn’t at-\ntach any significance to these vague gut feel-\nings. The mind is trapped by pendulums. It\nis too busy solving problems and is con-\nvinced that its actions are rational. The mind\nmakes resolute decisions, governed by logic-\nal reasoning and common sense. However,\nit’s a well known fact that sensible reasoning\nin no way guarantees the right solution. The\nsoul, in contrast to the mind, doesn’t think –\nit feels and knows. Therefore, it doesn’t make\nany mistakes. How often do we hear people\nsuddenly remember: “But, I knew that noth-\ning good would come of it!”\n391/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1114
  },
  {
    "chunk_full": "The task is to learn to determine what your\nsoul is telling your mind in the decision mak-\ning moment. It is not that difficult to do. You\njust have to tell your Overseer to pay atten-\ntion to the state your soul is in. Say, you are\nmaking some kind of decision. Your mind is\ncompletely trapped by the pendulum or pre-\noccupied with solving a problem. In order to\nhear the rustling of the morning stars, you\nonly have to remember in time that you need\nto pay attention to your soul’s condition.\nThis is so trivial that it is not even interest-\ning. But that is the case. The only problem is\nin paying attention to your own feelings.\nPeople are more prone to trust reasonable\narguments than their own feelings. Therefore\npeople have forgotten how to pay attention\nto the state of their soul.\nLet’s say you are mentally viewing one of the\npossible solutions. At this point the mind is\nnot guided by feelings but by sensible reas-\noning – and is not at all likely to perceive any\n392/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1115
  },
  {
    "chunk_full": "feelings. If you have been successful in re-\nmembering, then take notice of what you are\nfeeling. Did something about the situation\nput you on alert or upset you? Was there\nsomething that feels dangerous or something\nthat you don’t like? You make a decision.\nNow order the mind to be quiet for a mo-\nment and ask yourself, “Do you feel good or\nbad?” Then pick a different solution and\nagain ask yourself the question “Do you feel\ngood or bad?”\nIf you don’t have an explicit feeling, it means\nthat your mind is still a very poor listener.\nLet your Overseer force you to pay attention\nto the state your soul is in more often.\nHowever, it is possible that the answer to\nyour question is ambiguous itself. In that\ncase, you shouldn’t rely on such imprecise\ndata. The only thing remaining then is to act\naccording to the suggestions your mind is\nmaking. Or you would have to simplify the\nquestion.\n393/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1116
  },
  {
    "chunk_full": "If you were able to get an explicit answer,\n“Yes, this is good for me” or “No, this is bad\nfor me,” that means you have listened to the\nrustling of the morning stars. Now you know\nthe answer. It doesn’t mean that you will act\nin accordance with the dictates of the soul.\nWe are not always free to act the way we\nwish. But at least you will know what you can\nexpect in the unrealized sector.\nThe Asker, the Offended\nand the Warrior\nThere are two extremes of human behavior\nin life situations: to go with the flow, like a\nlittle paper boat with no will of its own, or to\nrow against the flow, stubbornly insisting on\nyour own way.\nIf somebody is just sitting around, not taking\nany initiative or striving to get anywhere, but\njust being there, then life will be directing\n394/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1117
  },
  {
    "chunk_full": "him. In that case, that somebody becomes a\npuppet of the pendulums, and they determ-\nine his fate at their own discretion. When\ntaking a stand like that, the man is refusing\nto choose his own destiny. His choice is to\nhave a predetermined destiny: “let it be\nwhatever it is” - will be. Agreeing to such a\ncondition, the man is claiming that you can’t\nescape your fate. And he is entirely correct,\nbecause for him, there just happens to be a\ndestiny like that in the space of variations.\nHaving made this choice, a man can only\nhelplessly complain about his fate and set his\nhopes on higher powers.\nHaving put his destiny in others’ hands, a\nman moves through life on one of two paths.\nMoving along the first path, he can submit\nhimself to asking for charity for living his\nlife, appealing either to pendulums or to\nsome sort of higher power. Pendulums force\nthe Asker to work, and he spends his whole\nlife cringing before them, getting only a few\n395/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1118
  },
  {
    "chunk_full": "crumbs to live on in return. The Asker na-\nively appeals to higher powers, but they don’t\ncare about him.\nThe Asker has given away any responsibility\nfor his own destiny, saying, “Everything is in\nGod’s hands”. And if that is the case, then all\nyou need to do is ask nicely, and as God is\nmerciful, He will give it to you. “Mountains\nand valleys! Rivers and oceans! Oh, the sky!\nOh, the earth! I bow before your power! I am\nfilled with reverence and belief. I believe that\nyou will help me buy my morning newspa-\nper!” What, was this too exaggerated of an\nexample? Not at all, because to great higher\npowers, there is no difference between a\nmorning newspaper and a grand palace –\nanything is possible for them. And if you\ndidn’t get what you wanted that means, you\nobviously didn’t ask nice enough! Well then,\ncarry on asking.\n396/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1119
  },
  {
    "chunk_full": "There is a Russian joke that goes like this. A\nman is lying on his couch, praying. “Oh God,\nhelp me to get rich. I know you can do it! I\nbelieve in your greatness! I put my hopes in\nyou and your mercy!” and the Lord tells him,\nin vexation: “Listen, dude, you could at least\nbuy a lottery ticket!” That is a comfortable\nsituation: decline all responsibility for your-\nself and at the same time wallow in your own\ninner importance. What is importance doing\nhere? The man has imagined himself to be\nsuch an important figure that he believes\nthat God in all his majesty and mercy cares\nabout that one person’s well-being. God has\nalready given man too much – freedom of\nchoice, but, due to his infantile nature, man\nwon’t accept this gift and is thus constantly\ndissatisfied.\nAn infantile nature finds its justification in\nthe fact that the way towards the goal is\nstrewn with many obstacles. In fact, there is\nalways something in the way of a man’s goal.\n397/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1120
  },
  {
    "chunk_full": "And that something is balancing forces and\npendulums that are the result of the man’s\nhandmade excess potential of importance.\nIt’s like in that children’s game11, “Hello\nthere geese - geese!” – “Honk! Honk! Honk!”\n- “Are you hungry?” – “Yes, yes, yes!” –\n“Well, fly on then!” – “We can’t! The gray\nwolf by the mountain won’t let us get home!”\nIf the role of the Asker doesn’t suit, the man\ncan choose a second path: taking the role of\nthe Offended. That is, expressing dissatisfac-\ntion and demanding something that is sup-\nposedly his by right. The Offended, by ex-\npressing his demands, is bringing even more\nharm to his destiny. Let’s look at another al-\nlegory as an example of this. A man comes to\na picture gallery, he doesn’t like the exhibi-\ntion on display, and he considers himself to\nhave the right to express dissatisfaction. He\nstarts stamping his feet, making threats, de-\nmanding that they take the exhibition down,\nand\nmaybe\nhe’ll\neven\nstart\ndestroying\n398/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1121
  },
  {
    "chunk_full": "everything around him. Naturally, there will\nbe some kind of reprisal following his ac-\ntions. The man then gets even more offended\nand continues to actively rant and rave:\n“What! They should be bending over back-\nwards for me!” It doesn’t occur to him that\nhe is only a guest in this world.\nFrom the Transurfing point of view, both the\nfirst and the second path seem completely\nabsurd. Transurfing suggests an entirely new\npath: don’t ask and don’t demand, but\nsimply go and take.\nSo what’s new about that? After all, this is\nexactly how somebody acts, having made yet\nanother choice: my destiny is in my own\nhands. He begins to struggle with the world\nfor his place under the sun. Taking a hard\nstand, a man is at war with the pendulums,\nbeing drawn into ongoing competition and\nelbowing his way forward. Basically, his en-\ntire\nlife\nis\na\ncontinuous\nstruggle\nfor\n399/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1122
  },
  {
    "chunk_full": "existence. The man has chosen a struggle,\nand this alternative exists in the space of\nvariations as well.\nWe already know that both humbleness as\nwell as dissatisfaction makes us dependent\non pendulums. Remember what we were\ntalking about in the chapter about potentials\nof importance, and everything will become\nclear to you. The Asker creates a potential\nthrough his guilt and is voluntarily giving\nhimself away into the hands of the manipu-\nlators. He who asks already believes that he\nis condemned to ask and wait – maybe\nsomeone will give him something. The Of-\nfended creates a potential of dissatisfaction,\nturns the balancing forces against himself,\nand is actively ruining his own fate.\nThe Warrior, having chosen the battle, has\ntaken a more productive stand, but his life is\nhard and takes a lot of his power. No matter\nhow much the man tries to resist, he is only\n400/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1123
  },
  {
    "chunk_full": "getting himself more and more enveloped in\nthe spider web. It seems to him that he is\nstruggling for his own destiny, while in fact\nhe is only spending his energy in vain. Some-\ntimes a man would gain a victory. But to\nwhat price! His victory is there for all to see,\nand everyone is once again convinced that it\nis definitely not easy to win the crown of vic-\ntory. This is how society’s opinion on how to\nattain goals is shaped and strengthened: in\norder to achieve something, you have to be\npersistent and work hard for it, or fight for it\ncourageously.\nSocial opinion is actually formed by pendu-\nlums. Potentials of importance serve as a\nbuffet for pendulums. If the aim is difficult to\nreach it is the external importance talking. If\nonly someone, who possesses outstanding\nqualities, can attain it then it is the inner im-\nportance talking. On the way to his aim, the\nman will be fleeced. Possibly, he will be al-\nlowed to get to the finish line. And he will be\n401/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1124
  },
  {
    "chunk_full": "very satisfied, without understanding that he\nspent his energy mostly on fulfilling de-\nmands of the pendulums, and not so much\non reaching his goal.\nWe get the following rough picture. To reach\nhis goal, a man must wade through a crowd\nof beggars. They make a hubbub, block his\nway, and keep grasping him by the hands.\nThe man tries to justify himself, excuse him-\nself, give them money, push them aside,\nforce his way through and fight them. Fin-\nally, with great difficulty, he gets to his goal.\nThe energy that was spent on the actual\nachieving of his goal is but a small part and\ngoes only towards moving his feet in the dir-\nection of the goal. The remaining mass of en-\nergy was spent on the struggle with the per-\nsistent beggars.\nHaving broken the chains of pendulums the\nman will get his freedom. The beggars will\nleave him in peace and bother other people.\n402/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1125
  },
  {
    "chunk_full": "As you remember, in order to free yourself\nfrom the pendulums, you have to abandon\ninternal and external importance. If you do\nthis, obstacles on the way to your goal will\nsimply self-destruct. Then you will be able to\nnot ask, not demand, and not struggle, but\nsimply to go and take.\nNow there is the question of how are we to\nunderstand the phrase “to go and take” –\nand what has to be done so that we can “go\nand take” whatever it is we want? All of the\nremaining parts of the book are dedicated to\nthis\nquestion\nand\nyou\nwill\nsoon\nknow\neverything about it. So far, we have only out-\nlined the general strategy for choosing one’s\ndestiny. The roles of the Asker, the Offended,\nand the Warrior don’t suit us. What do you\nthink, what role does Transurfing gives the\nmaster of his destiny to play in the game\ncalled life? This is your homework.\n403/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1126
  },
  {
    "chunk_full": "For now, let’s look at tactical ways of behav-\ning in life situations.\nGoing with the Flow\nThe Asker and the Offended unwillingly go\nwith the flow of life. The Warrior, on the oth-\ner hand, tries to fight against the flow. Of\ncourse, there are no pure types of these\npeople. From time to time, everybody to a\ncertain degree takes on one of the roles.\nPlaying these parts, a man is acting ex-\ntremely inefficiently. But if we can’t struggle,\nnor go with the flow, what is there left for us\nto do?\nEarlier we saw how the mind authoritatively\ndictates its own will, based on common\nsense. Many people reason very sensibly, but\nat the same time get nowhere in solving their\nproblems. What is then the great use of such\ncommon sense? The mind cannot guarantee\n404/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1127
  },
  {
    "chunk_full": "that its solution will be foolproof. The mind\nonly thinks that it is reasoning sensibly,\nwhen in fact it is actually offering itself to\npendulums. There can be no talk of freedom\nin moving along the flow while a man is play-\ning the part of the Asker, the Offended, or\nthe Warrior. Even the Warrior has the same\namount of freedom to express his will as has\na little paper boat.\nHow does the Warrior move with the flow of\nlife? Pendulums provoke him into a fight\nwith them, and he swims against the current,\nnot understanding that it would be easier\nand more advantageous to use the flow. His\nmind is captured by pendulums, but the\nWarrior is resolutely set for battle and, by\nmaking resolute decisions, he is whipping\nthe water with all his might, when calm and\nsmooth\nmovements\nwould\nhave\nbeen\nenough.\n405/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1128
  },
  {
    "chunk_full": "And now imagine that you are not resisting\nthe flow and you are not causing any extra\nturbulence, but neither are you going with\nthe flow without any will like a little paper\nboat. You are intentionally moving in agree-\nment with the flow, you note the shoals on\nthe way, the barriers and dangerous areas,\nand only by using smooth movements are\nyou able to keep your chosen direction. You\nare the one standing at the steering wheel.\nBut can we actually look at life as a flow?\nAnd why can we neither swim without any\nwill, nor resist the flow? On the one hand,\nthe information that lies in the space of vari-\nations is stationary, like a matrix. But at the\nsame time, the information’s structure is or-\nganized\ninto\nchains\nof\ncause-and-effect.\nThese give birth to the flow of variations –\nand that is the flow we are about to discuss.\nThe main reason it is not worth actively op-\nposing the current, is that it is a massive,\n406/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1129
  },
  {
    "chunk_full": "useless, and even harmful waste of energy.\nBut can one rely on the flow of variations?\nAfter all, it can lead you not only to a peace-\nful lagoon, but also to a waterfall. This is pre-\ncisely why, to avoid unpleasantness, you\nmust correct your movements with calm,\neven strokes. Of course, to begin, you must\ncorrectly choose the general direction of this\nflow. The direction is determined by your\nchosen goal and the means for its attain-\nment. After the direction has been chosen,\nyou must rely on the flow as much as pos-\nsible and not allow any sudden movements.\nEveryone pretty much knows the general dir-\nection of his or her flow – in other words,\nwhere they are going. For example, now I am\nstudying, later I will get a job, have a family,\nwork my way up the employment ladder,\nbuild my house and so forth. Many make a\nlot of mistakes on their way and complain,\nwhen looking back. But you can’t do any-\nthing about it, what’s done is done. The flow\n407/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1130
  },
  {
    "chunk_full": "has moved you far away from your desired\ngoal. Your reasoning mind cannot save you.\nIt only remains to regret that “if I had only\nknown where I would fall, I would have put\nthere something soft to land on”.\nEveryone wants to know what is waiting for\nhim or her after the next turn. Not everyone\nis seriously going to see fortune-tellers or as-\ntrologers, but many are interested in them,\nat least out of curiosity. An optimistic astro-\nlogical forecast or prediction lights a spark of\nhope. And when you get unwanted predic-\ntions, you can always wave them away. The\nTransurfing model does not contradict astro-\nlogy. Predictions have a real foundation to\nthem – the space of variations. Astrology ex-\nists not only because people are curious\nabout the future. If the hit rate was too low,\nno one would rely on these short-lived pre-\ndictions. However, the fact that the flow of\nvariations exists in accordance with certain\npatterns,\nallows\nus\nto\nglance\nat\nthe\n408/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1131
  },
  {
    "chunk_full": "unrealized sectors of space. It is quite anoth-\ner matter that astrological calculations are,\nof course, unable to guarantee their predic-\ntions to be a hundred percent accurate and\nthe same goes for clairvoyants.\nEverybody\ndecides\nfor\nthemselves,\nhow\nmuch they should rely on forecasts and as-\ntrological predictions. Respectfully, we will\nleave this subject aside and we’ll look at the\nuseful points that can be extracted from\nknowing about the flow of variations. The\nmain question is how much we can sur-\nrender ourselves wholly to the flow, if we\nhave chosen the main direction correctly,\nand why should we surrender ourselves to\nthe flow at all?\nAs previously shown, the mind is constantly\nunder the pressure of artificially created im-\nportance and, therefore, it cannot make any\nefficient decisions. Internal and external im-\nportance is, in essence, the main source of\n409/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1132
  },
  {
    "chunk_full": "problems. The action of balancing forces\nmanifests itself as rapids and whirlpools on\nthe way through the flow. If you throw off\nimportance, the flow will turn into a much\ncalmer river-bed. The question of whether\none should surrender oneself to the flow is\nalso a question of importance. External im-\nportance forces the mind to look for complic-\nated solutions to simple problems. Inner im-\nportance convinces the mind that it is reas-\noning soundly and that it is making the only\npossible correct decision.\nIf we were to throw importance away, the\nmind could breathe freely, because it would\nbe released from the influence of pendulums\nand the pressure of artificially created prob-\nlems. It could make more objective and ad-\nequate decisions. But the whole beauty of\nthis lies in the fact that the mind won’t need\ngreat intellect, once it is freed from import-\nance. Of course, for solving everyday prob-\nlems\nyou\nwould\nneed\nlogical\nthinking,\n410/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1133
  },
  {
    "chunk_full": "knowledge and analytical ability. But all of\nthis won’t require as much energy. The fact\nthat the flow of variations exists is a luxuri-\nous gift for the mind, which hardly ever uses\nit.\nThe flow of variations already contains the\nsolutions to all problems. And what’s more,\nthe majority of all problems are artificially\ncreated by the mind anyway. The restless\nmind is constantly experiencing the shoves\nof pendulums and takes on solving all of the\nproblems at the same time, while trying to\nkeep the situation under control. Its strong-\nwilled decisions are in most cases just point-\nless slapping of the water. The majority of\nproblems, especially the small ones, solve\nthemselves, if we don’t disturb the flow of\nvariations.\nA great intellect is of no use, if the solution\nalready exists in space. If we don’t go into a\nmaze and don’t interfere with the flow of\n411/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1134
  },
  {
    "chunk_full": "variations, a solution will come by itself. And\nwhat’s more, it will be the most optimal solu-\ntion. Optimality already lies in the structure\nof the information field. The thing is that\ncause-andeffect\nchains\ncreate\nseparate\nstreams in the flow of variations. These\nstreams appear to be the most optimal ways\nin which causes and effects move. Everything\nexists in the space of variations, but only the\noptimal or the least energy-consuming vari-\nations are more likely to be realized. Nature\ndoes not waste energy for nothing. People\nwalk on legs and not on ears. All processes\nstrive to go along the way of least energy ex-\npenditure. Therefore, the streams of vari-\nations are organized along the path of least\nresistance. And it is precisely there the most\noptimal solutions lie. The mind, captured by\npendulums, acts in their interests and is con-\nstantly getting out of the optimal streams. In\nother words, the mind is getting into a maze\n412/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1135
  },
  {
    "chunk_full": "– it is looking for complicated solutions to\nsimple problems.\nAll this reasoning may appear to you as be-\ning excessively abstract. But you could test\njust how real these streams are, by applying\nsome of the principles described in this\nchapter. It is truly a luxurious gift for the\nmind. Any problem contains coded keys to\nits solution. The very first key is to move\nalong the path of least resistance. People\nusually look for complicated solutions, be-\ncause they perceive problems as obstacles.\nAnd obstacles, as you know, must be over-\ncome with a great amount of effort. We must\ncultivate the habit of choosing the simplest\nsolution to the problem that comes up.\nWe all have to either learn something new,\nor to do something that is already familiar\nand customary to us. The question is how\ncan we do both the one and the other in the\nmost effective way? The answer is so simple,\n413/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1136
  },
  {
    "chunk_full": "that it’s really hard to believe: in accordance\nwith the principle of going with the flow,\nyou must try and do everything in the easi-\nest and simplest way possible.\nThe most optimal variations of any actions\nare organized in streams. Chains of optimal\ncause-and-effect links form these streams.\nWhen you are making the decision to take\nthe next step in your action, you are choosing\nthe next link in the chain. You just need to\ndetermine which link belongs to the stream.\nWhat does a person usually do in a case like\nthat? He makes a logical decision, which\nfrom the point of view of common sense and\neveryday experience appears to be the most\ncorrect one.\nThe mind makes a strong-willed decision. It\nthinks it is able to calculate and explain\neverything. However, this is not the case –\nyou can probably confirm yourself, how\nmany times you suddenly remembered that\n414/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1137
  },
  {
    "chunk_full": "something could be done differently, only\ntoo late. The problem is not that the mind is\ninattentive or it isn’t sharp enough. The\nmind cannot always choose the optimal vari-\nation because the cause-and-effect chains of\nthe flow don’t always match the mind’s logic-\nal constructions.\nNo matter how hard you try, you will rarely\nchoose the optimal action if you only use lo-\ngical conclusions. The mind is usually under\nthe pressure of stress, troubles, depression\nor increased activity. In other words, pendu-\nlums are constantly pulling at it. Therefore,\nthe mind is always acting forcefully and\nmounts a frontal attack upon the external\nworld.\nIn order to choose the next chain of the flow,\nwe need only to free ourselves from the\nstrings of the pendulum and just obediently\nfollow that stream. That is, we should take\nthe balanced position and not create excess\n415/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1138
  },
  {
    "chunk_full": "potential. In order to not create excess po-\ntential, we need to constantly monitor the\nlevel of importance.\nWhen you are in a state of balance with the\nsurrounding world, simply go with the flow.\nYou will see a multitude of signs that will\nguide you. Let go of the situation, don’t be-\ncome\na\nparticipant,\nbut\nthe\nobserving\nbystander. Not a slave, and not the master,\nbut simply someone who performs actions.\nOrder\nyour\nOverseer\nto\npull\nyou\nback\nwhenever\nyour\nmind\ntries\nto\nmake\na\n“reasonable”\nstrong-willed\ndecision.\nRent\nyourself out as a performer, while observing\nthe work from the sidelines. Everything is a\nlot easier than it seems. Yield to this simpli-\ncity. It is the mind that brings you to a wa-\nterfall, not the flow of variations.\nFor example, you have to find something you\nreally need in a shop. But you don’t know ex-\nactly where this thing is. The mind will\n416/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1139
  },
  {
    "chunk_full": "suggest the most reasonable, but often the\nmost complicated option. You’ve gone round\nhalf the city, but in the end you find that\nitem in a shop close to your house. If the im-\nportance of the problem had been lower, the\nmind would not have looked for a complic-\nated solution.\nHere’s another example. There is an entire\nto-do list in your hands. What should you\nchoose to do first and what later? You don’t\nhave to think about it. If following a specific\norder is not a principle you have – simply do\nthe things you feel like doing. Move together\nwith the flow; untie your mind from the in-\nfluence of the pendulums. We’re not talking\nabout turning into a spineless little paper\nboat on the waves, but we’re talking about\nnot slapping the water with your hands,\nwhen it is quite enough with strokes that are\nsmooth, light and easy.\n417/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1140
  },
  {
    "chunk_full": "I won’t continue the list of examples. You’ll\nmake a lot of useful and amazing discoveries,\nif you at least for the course of one day try to\ngo with the flow. Each time, as soon as you\nneed to find some sort of solution, ask your-\nself: what’s the simplest way of looking for\nthe solution? Choose the simplest method of\nlooking for any solution. Whenever someone\nor something distracts you or leads you\nastray, don’t be in a hurry to actively resist or\navoid it. Try to rent yourself out, and watch\nwhat happens next. Every time you need to\ndo something, ask yourself: what is the\nsimplest way to do this? Allow things to hap-\npen in the simplest way. Every time, when\nsomeone suggests something to you or shows\nyou their point of view, don’t be in a hurry to\nreject it or have an argument. Maybe your\nmind doesn’t understand its advantages and\ndoesn’t see any alternatives. Activate the\nOverseer. At first, observe – and only then,\nact. Go down to the auditorium and don’t be\n418/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1141
  },
  {
    "chunk_full": "in a hurry to establish control over the situ-\nation. Allow the game to develop as much as\npossible on its own, under your observation.\nDon’t go slapping the water with your hands.\nDon’t prevent your life from going with the\nflow, and you will see how much easier it\ngets.\nGuiding Signs\nBut how do you distinguish approaching\nshoals or a waterfall from a normal turn in\nthe flow? We can orient ourselves in the sur-\nrounding world with the help of quite tan-\ngible signs. The world is constantly giving us\nthese signs.\nThe most well-known and widely-distributed\nform of signs is omens. There are good\nomens and there are bad omens. If you’ve\nseen a rainbow – it’s a good omen. If you see\na black cat – misfortune awaits. These are\n419/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1142
  },
  {
    "chunk_full": "examples of established superstitions. Gen-\nerally accepted omens have been formed as a\nresult of many observations and comparis-\nons. If a high enough percentage of the\nomens predict what they should, a certain\npattern is determined, which then becomes a\npart of the public opinion, because people\nare always talking with one another about\nstrange phenomena. However, omens don’t\nalways come true, far from it. Why?\nWhat\nhappens\nwhen\na\nman\nforgets\nsomething and he has to go back and get it?\nHe is thinking: returning is a bad omen12.\nHe doesn’t necessarily have to believe in\nomens, but the stable, social stereotype non-\netheless throws a shadow onto his subcon-\nscious. In his thoughts, he is expecting some\nkind of unpleasant event. Or never mind it,\nthe man is thinking, I won’t go back. But that\nwon’t be of any help either, because the even\nflow has already been disturbed and the man\nhas already been thrown off balance to some\n420/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1143
  },
  {
    "chunk_full": "degree. Expecting misfortune brings certain\nchanges into the parameters of thought radi-\nation, and the man is put onto a life track\nthat corresponds to these parameters. He\ngets exactly what he is afraid of. He himself\nallowed this possibility in his script. This ex-\nplains why the percentage of “working”\nomens grows higher.\nAs you see, generally accepted omens cannot\nby themselves serve as laws or even as rules.\nWhy is it that a black cat in particular is a\nstandard bad sign to everybody? Or, put it\nthis way, how in the world could a black cat\nhave any kind of influence on our lives? The\ninfluence is not the cat, but your attitude to\nthe particular omen. If you believe in omens,\nthey will help shape the events of your life. If\nyou don’t believe in omens, but have doubts,\nthe influence of omens is weakened, but it is\nthere nonetheless. If you don’t believe in\nthem and don’t pay any attention to them,\nthey will not have any influence whatsoever\n421/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1144
  },
  {
    "chunk_full": "on your life. It’s all very simple: you get what\nyou allow into your script. A man who views\nomens to be superstitions doesn’t have any\nindication of their validity in the layer of his\nworld. Omens work in the layers of other\npeople’s worlds because those people find\nproof for their belief in omens, but our skep-\ntic does not.\nIf omens themselves don’t have any influ-\nence on the events in our lives, then what\nguiding signs are we talking about? The\nblack cat cannot have any influence, no, but\nit can serve as a sign, warning you of an\nevent that will take place further on your way\nin the flow of variations. The question is then\nonly: what signs could be considered guiding\nsigns? After all, if you have made up your\nmind to monitor everything around you,\nthen you could see signs everywhere. But\nhow do we interpret them? We won’t con-\ncern ourselves with interpretations. This is a\nrather\nunrewarding\ntask,\nas\nit\nis\ntoo\n422/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1145
  },
  {
    "chunk_full": "unreliable and incomprehensible. The only\nthing you can do is to take the sign into ac-\ncount, increase the Overseer’s level of aware-\nness and be more careful.\nThe guiding signs are signs that indicate a\npossible turn in the flow of variations. In\nother words, a guiding sign serves as a herald\nof an event that will bring rather substantial\nchanges into the flow of life. If you expect\nsome sort of turn, even a very insignificant\none, then a sign could appear that would sig-\nnal its coming. If an unexpected turn is com-\ning up in the near future, some kind of a\ncharacteristic sign could appear as well.\nWhat do I mean by “characteristic”?\nThe point is that when the flow of variations\ntakes a turn, you move over to a different life\ntrack. It will be recalled that a life track ap-\npears to be more or less homogeneous, as far\nas the quality of life is concerned. A stream\nin the flow of variations can intersect various\n423/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1146
  },
  {
    "chunk_full": "life tracks. These differ in their parameters.\nChanges that have taken place can be insig-\nnificant, but you would nonetheless feel that\nsomething is different. And it is this qualitat-\nive difference that you’ll notice, either con-\nsciously or subconsciously: as if something is\nnot quite the same as it was a minute ago.\nThus, guiding signs appear only in those\ncases when a transfer onto another life track\nis initiated. You could ignore a separate phe-\nnomenon. For example, a crow croaked but\nthat didn’t put you on alert, you didn’t feel\nany qualitative difference - that means you\nare on the same life track as before. But if\nyou did pay attention to the phenomenon,\nhaving felt something unusual, something\nodd about the whole episode - it could be a\nsign.\nA sign is different from an ordinary phe-\nnomenon in that a sign always signals that\nthe ongoing transition to a substantially\n424/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1147
  },
  {
    "chunk_full": "different life track is going on. The phenom-\nena that usually put us on alert are those that\nhappen right after a completed transfer onto\na different life track. This is because life\ntracks are qualitatively different from each\nother. These differences can be of various\nkinds and it is often hard to explain or put a\nfinger on the actual difference: you just have\na feeling that something is not quite right.\nWhen the transfer has been completed, we\nfeel it intuitively and sometimes even notice\nobvious changes in how the signs look. As if\nfrom the corner of our eye we see, or suspect,\nthat something new has appeared in the\nflow. Signs act as pointers, they say to us:\nsomething\nhas\nchanged,\nsomething\nhas\nhappened.\nUsually, a phenomenon that takes place on\nthe current life track doesn’t put us on alert.\nIt has the same quality as other phenomena\non the given track. However, if a man is ig-\nnoring everything that happens around him,\n425/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1148
  },
  {
    "chunk_full": "he won’t be able to notice the obvious signs\nas well. The transfer to a substantially differ-\nent\ntrack\nnormally\nhappens\ngradually,\nthrough intermediate tracks. Signs on these\ntracks could appear as warnings having vari-\nous degrees of severity. Sometimes a man ig-\nnores the first warning. The transfer contin-\nues, then the second warning appears, then\nthe third and if after this he doesn’t stop,\nthen what was meant to happen on the final\ntrack happens.\nAs we have already discussed, it’s very diffi-\ncult to interpret signs unambiguously. You\ncannot even be sure whether a phenomenon\nthat attracted your attention is a sign or not.\nWe can only take into consideration that the\nworld is trying to tell us something. We are\nmostly interested in the approaching shoals\nand rapids. Sometimes it would be nice to at\nleast get a hint of what is waiting ahead. In\nmost cases, you could phrase the question so\nthat there would be two possible answers:\n426/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1149
  },
  {
    "chunk_full": "yes or no. For example, will it work out or\nnot, will I be successful or not, will I be able\nto do it or not, will it be good or will it be\nbad, will it be dangerous or not and so on.\nAny interpretation of a sign should be\nbrought down to one question, the answer\nto which is either “positive” or “negative”.\nIt’s not worth counting on a greater degree of\naccuracy.\nThe sign carries in itself a hint to the quality\nof the up-coming turn. If you associate the\nsign with unpleasant sensations and it fills\nyou with misgivings, distrust, unpleasant\nsurprise, worry, discomfort, then it means\nthat the sign is signaling a negative turn of\nevents. If the sensation is ambiguous, then\nthere’s no point in trying to interpret the sign\n– the evaluation would be unreliable. In any\ncase, you shouldn’t be worrying too much\nabout this sign or attributing too much signi-\nficance to it. However, if you have already\npaid attention to the sign, then you shouldn’t\n427/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1150
  },
  {
    "chunk_full": "disregard it either. Maybe the sign brings a\nwarning - that you need to be more careful or\nthat you ought to change your behavior or\nstop doing something in time, or choose an-\nother direction for your actions.\nSigns can take on the most varied forms. You\nonly need to distinguish what meaning they\ncarry – positive or negative. For example, I\nam in a hurry, but an old little lady with a\ncrutch is blocking my way. There is no way I\ncan go around her. What does this mean?\nMore than likely, I will be late. Or there goes\nmy bus, which ordinarily doesn’t go very fast,\nbut today for some reason it is speeding like\ncrazy. Apparently, I’ve gone too far in some\nsituation and I should be more careful.\nAnother example could be that I am trying to\ndo something that is not really going too\nwell, no matter what I do. There is always\nsomething or other in the way and the whole\nthing is simply not running as smoothly as it\n428/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1151
  },
  {
    "chunk_full": "should. Maybe it’s a dead-end and I don’t\nneed to go down that way at all?\nThe main good thing about signs is that they\nare able to wake you up from a waking sleep\nin time. In addition, they make you realize\nthat you are possibly acting in the interests\nof a destructive pendulum and to your own\ndisadvantage. Humankind often makes fatal\nmistakes when under the pendulum’s zombi-\nfying spell, and only later remembers that\nthey weren’t at all aware of their actions, not\non their guard. In such cases, it would be\nuseful to interpret even the harmless signs as\nwarnings. It’s never wrong maintaining a\nsense of caution, being aware of what is go-\ning on and having an overall sensible view of\nthings. It is important to keep cautiousness\nfrom turning into anxiety and suspicion. You\nhave to care about things without worrying\nabout them. Give yourself out to rent, and be\nimpeccable in everything you do.\n429/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1152
  },
  {
    "chunk_full": "Strange as it may seem, the clearest and\nmost precise guiding signs are phrases spon-\ntaneously uttered by other people, something\nthat was mentioned in passing, without put-\nting much thought into it. If somebody is\nclearly and intentionally trying to impose\ntheir opinion on you – don’t pay much atten-\ntion to it. But if someone spontaneously\nmentions something to you about what you\ncould in a specific situation – take it very\nseriously.\nSpontaneous phrases are those which people\nsay without really thinking about it. You can\nprobably easily recall a similar situation,\nwhere you answered something immediately,\nalmost automatically and without thinking.\nIt seems as if the answer is already there\nsomewhere deep down inside your con-\nsciousness, and it falls from your lips, sur-\npassing the analytical mechanism of your\nmind.\nIn\na\nsimilar\nfashion,\nthoughtless\nphrases are mentioned when your mind is\n430/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1153
  },
  {
    "chunk_full": "slumbering\nor\nwhen\nit\nis\nbusy\nwith\nsomething else. When the mind slumbers,\nthe soul speaks and the soul, after all, is dir-\nectly connected to the information field.\nFor\nexample,\nsomeone\nsays\nto\nyou\nin\npassing, “Take a scarf with you, you’ll catch a\ncold otherwise.” If you don’t take the advice,\nyou’ll regret it later for sure. Or say, you’re\nconcerned with some kind of problem and\nsomeone\nincidentally\nrecommends\nsomething that is of little importance to you.\nDon’t be in a hurry to wave it away. Consider\ntheir opinion instead. Or, in another case,\nyou’re convinced you’re right, when someone\nby accident shows you that it is not the case\nand you are wrong. Don’t be stubborn. Take\na look – maybe you are beating water with\nyour hands?\nInner discomfort is also a very clear sign,\nonly we don’t pay much attention to it in\nmost cases. If you have to make a decision,\n431/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1154
  },
  {
    "chunk_full": "no one knows better than your own soul how\nto make it. It’s often very difficult to under-\nstand what exactly the soul wants to tell us.\nBut, as was shown above, we can quite un-\nambiguously determine whether the soul\nlikes the mind’s decision or not. Say, you\nhave to make some kind of decision. Stop\nand listen to the rustling of the morning\nstars. But if your mind has already made a\ndecision and you remembered about the\nrustling a little too late, try to recall what you\nwere feeling when you made the decision.\nThese feelings can be described as “I feel\ngood” or “I don’t feel good.” If you made the\ndecision reluctantly, if it didn’t really feel\nright, then you clearly “don’t feel good”\nabout it. In that case, if the decision can be\naltered, go ahead and do it.\nTo determine the level of your inner discom-\nfort is not too difficult. It’s only difficult to\nremember in time to listen to one’s feelings,\nsince the mind believes to have authority in\n432/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1155
  },
  {
    "chunk_full": "its reasoning and thus, it doesn’t want to\nlisten to anyone but itself. The loud roar of\ncommon sense does not only drown out the\nwhisper of the soul. Your mind is always try-\ning to substantiate and prove its case in\nevery way. Here you stand before a choice:\n“yes” or “no.” The soul tries to timidly object:\n“no”. The mind realizes that the soul is say-\ning “no,” but pretends that it didn’t hear the\nsoul’s whisper. So, the mind puts forward\npersuading arguments to support its “yes”,\nbased on “sensible reasoning”. Having read\nthese lines, put them away in a separate file\nin your memory and the next time when you\nare making a decision, remember them.\nYou’ll see that everything takes place exactly\nas described above.\nI suggest you keep in mind this simple and\nreliable formula for determining when you\nsoul is saying “no”: if you have to convince\nyourself and talk yourself into saying “yes”,\nthen that means your soul is saying “no.”\n433/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1156
  },
  {
    "chunk_full": "Remember, when your soul is saying “yes”,\nyou don’t have to talk yourself into any-\nthing. We’ll return to this formula later on.\nYou have to always pay attention to what\nsigns your world is showing you. Having said\nthat,\nyou\nshouldn’t\nlook\nfor\nsigns\nin\neverything. “Look, the birds are flying high\nin the sky. What could this mean?” Well,\nthey’re not afraid of heights so that is why\nthey are flying so high. You need only to take\nsigns into consideration and keep in mind\nthat they might be guiding signs. As soon as\nyou forget about this, the pendulums will\ntake you by the hand and you could become\na victim of circumstances.\nSpecial attention should be paid to those de-\nsires and actions that are able to change your\nlife dramatically. If your desire makes you\nfeel some discomfort and there is the possib-\nility of refusing that desire - then do exactly\nthat. In this case, the desire is not coming\n434/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1157
  },
  {
    "chunk_full": "from the soul, but from the mind. The mind’s\ndesires are always imposed by pendulums.\nThe very same is true of actions. If you ig-\nnore the inner discomfort you are feeling, in\nthe majority of cases nothing awful will hap-\npen, but sometimes you’ll be very sorry.\nTherefore, if possible, it is better to refuse\ndesires and actions that evoke discomfort,\ndoubts, apprehension or feelings of guilt.\nThis will greatly simplify your life and free\nyou from a lot of problems.\nHowever, there is one “but.” If a series of in-\ncorrect actions have tied an intricate knot\nthen the method of simply refusing desires\nand actions won’t always be appropriate. In\nsome cases, you will have to do “uncomfort-\nable” things, like not telling the truth or go-\ning to your much hated work. However, once\nthese knots are untied, you can go right\nahead and apply the method of refusing de-\nsires and actions.\n435/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1158
  },
  {
    "chunk_full": "That’s about all that can be said about guid-\ning\nsigns\nwithin\nthe\nframework\nof\nthe\nTransurfing model. Only you can notice and\ninterpret your own signs. And you don’t have\nto take a course on how to do it. You will un-\nderstand everything on your own, if you’ll\npay attention to yourself and the world\naround you. Just keep in mind that you\nshouldn’t give too much importance and sig-\nnificance to ambiguous signs, as in doing so\nyou could activate negative interpretations in\nthe script of your life. In order to not run\naground and to not drift into the rapids in\nthe flow of variations, you only have to re-\nfrain from creating excess potential. Then\nyou could get by without any signs. After all,\nit is beyond us to clearly understand their\ntrue meaning. The only sign which you\nshould pay particular attention to is you\nstate of inner comfort, every time you are\nabout to make a decision. It’s really worth\nlistening to the rustling of the morning stars.\n436/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1159
  },
  {
    "chunk_full": "Letting\nGo\nof\nthe\nSituation\nStreams in the flow of variations relieve the\nmind of two overwhelming burdens: the ne-\ncessity to rationally solve all problems and to\nhave all situations under constant control. Of\ncourse, the burdens will be lifted only if the\nmind is willing to relieve itself of them. In or-\nder for this to happen, the mind needs a\nmore or less rational explanation to why it is\na better option not to carry these two bur-\ndens around. As you’ve probably noticed,\nthere are a lot of irrationalities in this book, a\nlot of things that do not conform to common\nsense. And even though Transurfing is not\naimed at explaining the structure of this\nworld, I still have to, in one way or another,\npresent arguments to support all of these\nconclusions that appear shocking to the\nmind.\n437/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1160
  },
  {
    "chunk_full": "How else? To shake the solid wall of com-\nmon sense is very difficult. The mind is not\nused to accepting proof, based only on faith.\nIt demands facts to be based on real evid-\nence. You can get real evidence yourself, if\nyou test the principles and methods of\nTransurfing in real world situations. I can\nonly present you with certain arguments, so\nas to calm the suspicious mind. In the worst\ncase, not only would you not begin to verify\nany of these principles, but you would read\nno further. And yet, this is really only the be-\nginning. There are many more discoveries\nwaiting for you ahead.\nThe two overwhelming burdens that our\nmind is carrying around were laid upon it\nback in our childhood. We were constantly\nbeing trained: “Use your head! Are you\naware of what you’re doing? Explain your ac-\ntions! Do your homework, because only if\nyou learn to use your mind will you ever be\nable to achieve anything in life. You dumb\n438/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1161
  },
  {
    "chunk_full": "head, you! Will you ever learn?” Our teachers\nand life circumstances have made a “soldier”\nout of our mind, a soldier ready at any mo-\nment to find an explanation, to give an an-\nswer to any question posed, to evaluate a\nsituation, to make a decision, to maintain\ncontrol over what is happening. The mind is\ntaught to act rationally, with common sense.\nJust don’t be thinking that I am so full of my-\nself that I am ready to sweep common sense\naway all together. It is actually quite the op-\nposite - common sense is a minimal collec-\ntion of necessary rules, which tell you how\nyou should behave yourself in the surround-\ning world in order to survive. The mind is\nmaking only one mistake – it is following\nthis set of rules too literally and too strictly.\nObsession with common sense prevents the\nmind from looking around and seeing that\nwhich doesn’t agree with these rules.\n439/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1162
  },
  {
    "chunk_full": "And there are so many things in the world\nthat diverge from common sense. The proof\nof this is the inability of our mind to explain\neverything, or to protect us from trouble.\nThere’s a very easy way out of this situation:\nto rely on the streams in the flow of vari-\nations. The basis of this logic is also very\nsimple: as it happens, expediency lies in\nthese streams, and that is exactly what the\nmind is looking for. As you know, streams\nfollow the way of least resistance. The mind\nstrives to reason sensibly and logically, rely-\ning on the links of cause and effect. But the\nfact that mind is not perfect keeps it from\ncorrectly orienting itself in the surrounding\nworld, and from finding only the correct\ndecisions.\nBut nature is in essence perfect, thus there is\nmore expediency and logic in the streams\nthan in the very wisest argumentation. And\nno matter how much the mind is convinced\nof the fact that it is thinking sensibly, it will\n440/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1163
  },
  {
    "chunk_full": "be mistaken nonetheless. Yet, the mind will\nmake mistakes in any case, but there will be\nfewer of them if the mind will moderate its\nzeal and, if possible, will let problems be\nsolved on their own without actively interfer-\ning with the process. That is what we call to\nlet go of the situation. In other words, you\nmust loosen your grip, lower the amount of\ncontrol, not disturb the flow and give more\nfreedom of action to the surrounding world.\nYou already know that pressing and pushing\nthe world is not only useless but also harm-\nful. When not agreeing with the flow, the\nmind is creating excess potential. Transurf-\ning proposes an entirely different way. First\nof all, we create our obstacles ourselves by\npumping up excess potential. If you were to\nlower importance, obstacles would eliminate\nthemselves. Second of all, if an obstacle\ndoesn’t give in to your efforts, you should not\nfight it. Just go around it. The guiding signs\ncan help you.\n441/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1164
  },
  {
    "chunk_full": "The mind’s problem also lies in its tendency\nto perceive events that do not fit in its script\nas obstacles. The mind usually plans and cal-\nculates\neverything\nin\nadvance,\nwhile\nif\nsomething unforeseen suddenly happens,\nthe mind starts actively fighting it, in order\nto fit events to its own script. As a result, the\nsituation becomes even worse. Of course, the\nmind is not in a condition to plan events\nideally. At this point, more freedom has to be\ngiven to the flow. The flow is not interested\nin ruining your fate. It would, again, be un-\nadvisable. It is the mind which ruins your\nfate with its unreasonable actions.\nExpediency, from the mind’s point of view, is\nwhen everything is running according to the\npredesigned script. Everything that doesn’t\nagree with the script is perceived as an un-\ndesired problem. And problems have to be\nsolved. Thus the mind takes on this mission\nwith great diligence, creating new problems.\n442/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1165
  },
  {
    "chunk_full": "In this way, the mind itself is piling up a\nwhole lot of obstacles on its way.\nThink about it: when do people feel happy,\nwhen do they experience satisfaction, when\nare they satisfied with themselves? When\neverything goes according to plan. The least\ndeviation from the script is perceived as a\nfailure. Inner importance won’t allow the\nmind to accept the possibility of deviations.\nThe mind thinks, “After all, I’ve planned and\ncalculated everything in advance. I should\nknow better, what is good and what is bad\nfor me. I’m being sensible.” Life often gives\ngifts to people, which they reluctantly re-\nceive, only because these gifts are not part of\ntheir plan. “I wanted a different toy!” Reality\nis such that we hardly ever get just the toys\nwe were planning to have. Thus, we are all\nwalking around gloomy and dissatisfied. And\nnow imagine how much more enjoyable life\nwould be, if only the mind were to lower its\n443/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1166
  },
  {
    "chunk_full": "importance and recognize the right of devi-\nations to exist in the script!\nEveryone can regulate the level of their own\nhappiness. Most people set the lowest bar of\nhappiness much too high, and thus do not\nconsider themselves happy. I am not preach-\ning that you should be happy with what you\nhave. The doubtful formula of the type “if\nyou want to be happy – then just be happy”\nisn’t suitable for Transurfing. You will get\nyour toy, but we’ll talk about that later, in\nparts two and three. Now we are talking\nabout how to avoid unpleasant events and\nhow to decrease the number of problems.\nThe mind cannot use the ready solutions to\nproblems in the streams of the flow of vari-\nations. This is only because the mind is not\nwilling to allow any deviations in its script.\nThe\nmind’s\nmanic\ntendency\nto\nkeep\neverything under control turns life into a\nconstant battle with the flow. The mind\n444/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1167
  },
  {
    "chunk_full": "couldn’t really allow the flow of variations to\nmove on its own without submitting to its\nwill now, could it? Thus, we’ve come to the\nmind’s main mistake. The mind is not striv-\ning to control its movement along the flow,\nbut the flow itself. This is one of the major\nreasons why problems and unpleasant events\nappear.\nThe expedient stream, moving along the path\nof least resistance, cannot create problems or\nobstacles – they’re created by the muddle-\nheaded mind. Activate the Overseer and, at\nleast for the course of one day, observe how\nyour mind is trying to control the flow. So-\nmething is proposed to you, and you refuse.\nSomebody is trying to tell you something -\nyou wave it away. Somebody expresses their\nopinion, and you argue against it. Somebody\ndoes something his own way, and you set\nhim on the right path. You are offered a solu-\ntion, and you refuse. You wait for one thing,\nbut get something completely different and\n445/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1168
  },
  {
    "chunk_full": "express your dissatisfaction. Someone inter-\nferes with you, and you lose your temper. So-\nmething goes against your script, and you\nlaunch a full frontal attack to direct the flow\ninto the needed channel. Maybe for you per-\nsonally, it all happens somewhat differently,\nbut there is a grain of truth in all of this. Am\nI right?\nAnd now try to loosen you grip of control\nand grant more freedom to the flow. I am not\nsuggesting that you agree to everything or\nthat you accept everything that is handed to\nyou. Simply change your tactics: move the\ncenter of gravity away from control to obser-\nvation. Strive to observe more than to con-\ntrol. Don’t be in a rush to wave things away,\nto object, to argue, to push forward your own\nopinions, to interfere, to control or to criti-\ncize. Give the situation a chance to resolve it-\nself without your active interference or res-\nistance. You’ll be, if not dumbfounded, then\nat least amazed, that’s for sure. And what\n446/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1169
  },
  {
    "chunk_full": "will happen is a completely paradoxical\nthing. Having refused control over situ-\nations, you will gain even more control than\nyou had before. A detached observer always\nhas a greater advantage than a first-hand\nparticipant. This is why I am constantly re-\npeating: rent yourself out.\nWhen you look back, you’ll become con-\nvinced that your control was against the\nflow. The suggestions of others made a lot of\nsense arguing with them was completely use-\nless. Your interference was in vain. What you\nsaw as obstacles were not obstacles at all.\nProblems resolve themselves quite fine even\nwithout your knowledge. Everything you got\nthat you didn’t plan for wasn’t that bad after\nall. Incidental phrases that were mentioned\nin passing were actually quite valid. Your in-\nner discomfort served as a warning. You\ndidn’t waste any excess energy and remained\nsatisfied. This is that magnificent gift of the\nflow to the mind I spoke of in the beginning.\n447/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1170
  },
  {
    "chunk_full": "And of course, in addition to everything\nmentioned\nbefore,\nlet’s\nremember\nour\n“friends.” To move in agreement with the\nflow is made difficult by pendulums. They\nmake up provocations at every step a person\ntakes, forcing him to violently beat the water\nwith his fists. Pendulums don’t like the exist-\nence of streams in the flow, for one simple\nreason - the stream moves in the direction of\nthe minimal expenditure of energy. Energy\nspent by a man who struggles with the flow\ngoes to creating excess potential and to feed\npendulums. The only control worth talking\nabout is control over the level of internal and\nexternal importance. Remember that it is\nimportance in particular that interferes with\nany attempt the mind makes to let go of the\nsituation.\nTo let go of a situation is in many cases much\nmore effective and useful, than insisting on\none’s own way. People’s striving for self-as-\nsurance gives rise to the habit of proving\n448/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1171
  },
  {
    "chunk_full": "one’s significance already from childhood.\nFrom this stems the tendency, that is harm-\nful in all senses, to prove that “I’m right”, no\nmatter the costs. This striving creates an ex-\ncess potential and enters into conflict with\nthe interests of others. Often people try to\nprove that they are right, even when the ver-\ndict for one side or the other doesn’t directly\naffect their interests.\nThere are some people, whose feeling of in-\nner importance is so exaggerated that they\nstrive to get their own way even when it\ncomes down to the smallest of details. Inner\nimportance develops into a mania to keep\neverything under control. “I’ll prove I am\nright to everybody, whatever it may cost.” It\nis a harmful habit. It really complicates one’s\nlife, in particularly the life of the defender of\nthe truth.\nIf your interests won’t suffer too much from\nit, then go ahead and let go of the situation.\n449/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1172
  },
  {
    "chunk_full": "Allow others the right slapping the water\nwith their hands. If you do this with full\nawareness, then immediately you will feel so\nrelieved and simply wonderful – even more\nthan if you had proved your point. You will\nfind satisfaction in the fact that you’ve\nmoved up to the next step: you didn’t uphold\nyour importance, as you would usually do,\nbut you have acted like a wise parent with\nunreasonable children.\nLet’s look at one more example. Excessive\nzeal at work is also as harmful as a careless\nattitude. Let’s suppose that you’ve managed\nto get that prestigious job you’ve been\ndreaming about for a long time. You make\ngreat demands on yourself because you think\nthat you have to show your best. This is true.\nBut, if you too zealously seize the bull by the\nhorns, most probably you won’t be able to\ntake the pressure, especially if the job is diffi-\ncult. In the best case, your work will be inef-\nfective, while in the worst case, you’ll have\n450/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1173
  },
  {
    "chunk_full": "gotten yourself a nervous breakdown. You\ncould even arrive at the false conclusion that\nyou aren’t capable of dealing with this job.\nAnother option is also possible. You stir up a\nvigorous activity at your new job and in this\nway disturb the established order of things.\nIt would seem that there are quite a few\nthings at work that could be made perfect,\nand you’re absolutely certain that you’re act-\ning correctly. However, if your innovations\nbring destruction to the usual way of life at\nthe work place, don’t expect anything good\nto come of it. This is the case when the initi-\native is punishable. You were put into a slow,\nbut peaceful and even flow, and you started\nwith all your might be slapping the water\nwith your hands, trying to swim faster.\nSo what, does this mean that you are not al-\nlowed to say a word and shouldn’t stick out\nat all? Well, it is not quite that tough. Ap-\nproach this question with a business mind\n451/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1174
  },
  {
    "chunk_full": "set. You can only become annoyed and scold\nsomeone who is directly bothering you, and\nonly in the case when your criticism can\nchange something for the better. Never criti-\ncize what has already happened and what\ncannot be changed. In everything else, you\nneed to go with the flow – but not literally,\nagreeing with everything and everybody, but\nonly by moving the center of gravity from\ncontrol to observation. Observe more and\ndon’t be in a hurry to control situations,\npeople and so on. The feeling of moderation,\nhow and when to interfere, will come to you\nby itself. Don’t worry about that.\nSummary\nThe mind interprets information using a\ncollection of well-established labels.\nThe soul doesn’t think and doesn’t speak, but\nit feels and knows.\n452/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1175
  },
  {
    "chunk_full": "The mind is only able to create a relatively\nnew version of a house made out of old\nbricks.\nEntirely new discoveries come from unreal-\nized sectors.\nThe soul serves as a mediator between en-\ntirely new information and the mind.\nThe soul accepts unrealized information as\nknowledge without interpretations.\nIf the mind is successful in interpreting the\nsoul’s information, a discovery is made.\nThe mind is capable of unambiguously de-\ntermining the state of inner comfort.\nTrain yourself to pay attention to inner\ncomfort.\nHaving refused importance, you will get the\nfreedom to choose your destiny.\n453/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1176
  },
  {
    "chunk_full": "Freedom of choice allows you to stop ask-\ning, stop demanding, and to stop struggling.\nIt allows you to go and take whatever you\nwant.\nThe structure of information is arranged in-\nto chains of cause and effect links.\nCause and effect links give rise to the flow of\nvariations.\nThe paths of least resistance are arranged\ninto separate streams.\nStreams in the flow of variations already\nhave in themselves the solutions to all\nproblems.\nInternal and external importance throw the\nmind out of the optimal stream.\n454/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1177
  },
  {
    "chunk_full": "It is the mind which leads you to a waterfall,\nand\nnot\nthe\nstreams\nin\nthe\nflow\nof\nvariations.\nEverything is a lot easier than it seems. Give\nin to this simplicity.\nIt is not the omen that works, but your atti-\ntude to it.\nGuiding signs point at possible turns in the\nflow of variations.\nLife tracks differ qualitatively from one\nanother.\nSigns put us on alert, because they appear\nduring a transfer to another life track.\nSigns can be distinguished by their ability to\ncreate a sensation that something is not\nquite right.\n455/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1178
  },
  {
    "chunk_full": "Spontaneous phrases can be perceived as\nclear instructions which you may act on.\nThe condition of inner discomfort is a clear\nsign.\nIf you have to talk yourself into something,\nit means the soul is saying “no.”\nIf you have the possibility to refuse an un-\ncomfortable decision – refuse it.\nIt’s necessary to loosen the grip and accept\nunforeseen events in your script.\nImportance gets in the way of your accept-\ning the possibility of deviations in your\nscript.\nThe mind strives to control, not its own\nmovement along the flow, but the flow itself.\nMove the center of gravity from control to\nobservation.\n456/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1179
  },
  {
    "chunk_full": "Having relinquished control, you will get\nreal control over a situation.\nIf you move along the flow of variations, the\nworld will come out to greet you.\n457/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1180
  },
  {
    "chunk_full": "NOTES\n1 A reference to the lyrics from a popular\nRussian song - “City of Childhood” (tr.)\n2 Realization – to make something real. In\nthe context of this book - turning a particular\nsector in the space of variations into material\nreality. (tr.)\n3 “Egregor”, is a relatively recent word bor-\nrowed from the Greek, egeiro, which means\n“to be awake, to watch”. Egregor, as a word,\nis now being used in psychological and eso-\nteric literature when referring to a “thought\nform” or “collective group mind”. For more\ninformation\nsee\nBernstein,\nL\n“Egregor”\nonline.\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1181
  },
  {
    "chunk_full": "4 Alexandre Dumas (1802 – 1870), most\nfamous for his literary classic “The Three\nMusketeers” (tr.)\n5 For more information on how to use\n“slides”, see Chapter II, in The Rustling of\nthe Morning Stars, the Second Book in the\nTransurfing series.\n6 Russian proverb (tr.)\n7 For more information on goals, see chapter\nIV in the second book in the Transurfing\nseries “The Rustling of the Morning Stars”.\n8 “Transurfing Reality” is a series of five\nbooks. (tr.)\n9 Russian saying (tr.)\n10 In this case, the author is not referring to a\npersonal disaster but rather to a global one\n459/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1182
  },
  {
    "chunk_full": "like an airplane crash, natural disasters, fire,\nterrorist attacks, etc.\n11 Russian children’s game – the equivalent\nof several Western chasing games e.g. “The\nGame of It”. The point in the game is to\navoid the big bad wolf. In this context, the\nwolf, of course, represents the obstacles on\nthe way to one’s goal. (tr.)\n12 Russian superstition\n460/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1183
  },
  {
    "chunk_full": "O is a symbol of the world, of oneness and\nunity. In different\ncultures it also means the “eye,” symbolizing\nknowledge and\ninsight. We aim to publish books that are ac-\ncessible, constructive\nand that challenge accepted opinion, both\nthat of academia and\nthe “moral majority.”\nOur books are available in all good English\nlanguage\nbookstores worldwide. If you don’t see the\nbook on the shelves\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1184
  },
  {
    "chunk_full": "ask the bookstore to order it for you, quoting\nthe ISBN number\nand title. Alternatively you can order online\n(all major online\nretail sites carry our titles) or contact the dis-\ntributor in the\nrelevant country, listed on the copyright\npage.\nSee our website www.o-books.net for a\nfull list of over 500\ntitles, growing by 100 a year.\nAnd tune in to myspiritradio.com for our\nbook review radio show,\nhosted by June-Elleni Laine, where you can\nlisten to the authors\ndiscussing their books.\n462/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1185
  },
  {
    "chunk_full": "463/463\n",
    "book_id": "reality_transurfing",
    "book_title": "Reality Transurfing",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1186
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1187
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1188
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1189
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1190
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1191
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1192
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1193
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1194
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1195
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1196
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1197
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1198
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1199
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1200
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1201
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1202
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1203
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1204
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1205
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1206
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1207
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1208
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1209
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1210
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1211
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1212
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1213
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1214
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1215
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1216
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1217
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1218
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1219
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1220
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1221
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1222
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1223
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1224
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1225
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1226
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1227
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1228
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1229
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1230
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1231
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1232
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1233
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1234
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1235
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1236
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1237
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1238
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1239
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1240
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1241
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1242
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1243
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1244
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1245
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1246
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1247
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1248
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1249
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1250
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1251
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1252
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1253
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1254
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1255
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1256
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1257
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1258
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1259
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1260
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1261
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1262
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1263
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1264
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1265
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1266
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1267
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1268
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1269
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1270
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1271
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1272
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1273
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1274
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1275
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1276
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1277
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1278
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1279
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1280
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1281
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1282
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1283
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1284
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1285
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1286
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1287
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1288
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1289
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1290
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1291
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1292
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1293
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1294
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1295
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1296
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1297
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1298
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1299
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1300
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1301
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1302
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1303
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1304
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1305
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1306
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1307
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1308
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1309
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1310
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1311
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1312
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1313
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1314
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1315
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1316
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1317
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1318
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1319
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1320
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1321
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1322
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1323
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1324
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1325
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1326
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1327
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1328
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1329
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1330
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1331
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1332
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1333
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1334
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1335
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1336
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1337
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1338
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1339
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1340
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1341
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1342
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1343
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1344
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1345
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1346
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1347
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1348
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1349
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1350
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1351
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1352
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1353
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1354
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1355
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1356
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1357
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1358
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1359
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1360
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1361
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1362
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1363
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1364
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1365
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1366
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1367
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1368
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1369
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1370
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1371
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1372
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1373
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1374
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1375
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1376
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1377
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1378
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1379
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1380
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1381
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1382
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1383
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1384
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1385
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1386
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1387
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1388
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1389
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1390
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1391
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1392
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1393
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1394
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1395
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1396
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1397
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1398
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1399
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1400
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1401
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1402
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1403
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1404
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1405
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1406
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1407
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1408
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1409
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1410
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1411
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1412
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1413
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1414
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1415
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1416
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1417
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1418
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1419
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1420
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1421
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1422
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1423
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1424
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1425
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1426
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1427
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1428
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1429
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1430
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1431
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1432
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1433
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1434
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1435
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1436
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1437
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1438
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1439
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1440
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1441
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1442
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1443
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1444
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1445
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1446
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1447
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1448
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1449
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1450
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1451
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1452
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1453
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1454
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1455
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1456
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1457
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1458
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1459
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1460
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1461
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1462
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1463
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1464
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1465
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1466
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1467
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1468
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1469
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1470
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1471
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1472
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1473
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1474
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1475
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1476
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1477
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1478
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1479
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1480
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1481
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1482
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1483
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1484
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1485
  },
  {
    "chunk_full": "",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1486
  },
  {
    "chunk_full": " \n",
    "book_id": "simulations_of_god",
    "book_title": "Microsoft Word - modello -- 3.0 scrn.doc",
    "book_author": "Quick Silver",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1487
  },
  {
    "chunk_full": "1\nOctober 2024 edition\nA quick-start handbook \nfor effective prompts\n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1488
  },
  {
    "chunk_full": "2\nWriting effective prompts \nFrom the very beginning, Google Workspace was built to allow you to collaborate in real time with other people. \nNow, you can also collaborate with AI using Gemini for Google Workspace to help boost your productivity and \ncreativity without sacrificing privacy or security. The embedded generative AI-powered features can help you \nwrite, organize information, create images, accelerate workflows, have richer meetings, and much more, all \nwhile using your favorite apps like Gmail, Google Docs, Google Drive, Google Sheets, Google Meet, Google \nSlides, and Gemini Advanced (the standalone chat experience available at gemini.google.com with enterprise-\ngrade security). Gemini is accessible right where you are doing your work — with access to your personal \nknowledge base in Drive, Docs, Gmail, and more — so you can enhance and create powerful workflows across \nthe Workspace apps with less tab switching and interruption.\nThis guide provides you with the foundational skills to write effective prompts when using Gemini for Workspace. \nYou can think of a prompt as a conversation starter with your AI-powered assistant. You might write several \nprompts as the conversation progresses. While the possibilities are virtually endless, you can put consistent \nbest practices to work today. \nThe four main areas to consider when writing an effective prompt are:\n•\t  Persona \n•\t  Task \n•\t  Context \n•\t  Format \n \nHere is an example of a prompt using all four areas that could work well in Gmail and Google Docs: \n You are a program manager in [industry].  Draft an executive summary email to  [persona] based on [details \n about relevant program docs].  Limit to bullet points. \nYou don’t need to use all four in every prompt, but using a few will help! Always remember to include a verb or \ncommand as part of your task; this is the most important component of a prompt.\nContact sales to get started with \nGemini for Workspace today.\n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1489
  },
  {
    "chunk_full": "3\nHere are quick tips to get you started with Gemini for Google Workspace: \n1.\t Use natural language. Write as if you’re speaking to another person. Express complete thoughts in  \nfull sentences.\n2.\t Be specific and iterate. Tell Gemini what you need it to do (summarize, write, change the tone, create). \nProvide as much context as possible.\n3.\t Be concise and avoid complexity. State your request in brief — but specific — language. Avoid jargon.\n4.\t Make it a conversation. Fine-tune your prompts if the results don’t meet your expectations or if you believe \nthere’s room for improvement. Use follow-up prompts and an iterative process of review and refinement to \nyield better results.\n5.\t Use your documents. Personalize Gemini’s output with information from your own files in Google Drive.\n6.\t Make Gemini your prompt editor. When using Gemini Advanced, start your prompts with: “Make this a \npower prompt: [original prompt text here].” Gemini will make suggestions on how to improve your prompt. \nEnsure it says what you need, and then paste it back into Gemini Advanced to get an output.\nPrompting is a skill we can all learn. You don’t have to be a prompt \nengineer to use generative AI. However, you will likely need to try a few \ndifferent approaches for your prompt if you don’t get your desired \noutcome the first time. Based on what we’ve learned from our users \nso far, the most fruitful prompts average around 21 words with relevant \ncontext, yet the prompts people try are usually less than nine words.\nGenerative AI and all of its possibilities are exciting, but it’s still new. Even \nthough our models are getting better every day, prompts can sometimes \nhave unpredictable responses. \nBefore putting an output from Gemini for Workspace into action, review it \nto ensure clarity, relevance, and accuracy. And of course, keep the most \nimportant thing in mind: Generative AI is meant to help humans but the \nfinal output is yours.\nThe example prompts in this guide are meant for illustrative purposes.\n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1490
  },
  {
    "chunk_full": "4\nTable of contents\nWriting effective prompts.. . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Page 2 \nIntroduction.. . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Page 5\nAdministrative support.. . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Page 7\nCommunications.. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Page 11\nCustomer service.. . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Page 15\nExecutives... . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Page 20\nFrontline management.. . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Page 28\nHuman resources.. . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Page 32\nMarketing. . . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Page 37\nProject management.. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Page 46\nSales. ....... . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Page 50\nSmall business owners and entrepreneurs.. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Page 58\nStartup leaders . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Page 62\nLeveling up your prompt writing... . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Page 67\n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1491
  },
  {
    "chunk_full": "5\nIntroduction\nGemini for Google Workspace: Prompting 101\nGemini for Workspace is your AI-powered assistant integrated into the apps you use every day — Gmail, Google \nDocs, Google Sheets, Google Meet, Google Slides, and Gemini Advanced (the standalone chat experience \navailable at gemini.google.com with enterprise-grade security). This means the apps you know and use will work \ntogether smoothly so you can collaborate with Gemini right where you are. You can have fewer interruptions to \nyour focus and workflow, helping you complete tasks and do things you might not have initially known how to do. \nYou can access the features of Gemini for Workspace in multiple ways. Engaging with Gemini in the side panel \nof your Workspace apps allows you to create highly personalized generative AI outputs that are based on your \nown files and documents — even if they aren’t Google Docs. You can generate personalized emails in seconds \nreferencing your own Docs to pull in relevant context, generate Slides that are based on information directly  \nfrom your own briefs or reports, and so much more. \nUnderstanding what makes an effective prompt and learning to craft prompts on the fly can boost your \nproductivity and creativity. Gemini for Workspace can help you:\n•\t Improve your writing\n•\t Organize data\n•\t Create original images\n•\t Summarize information and surface insights \n•\t Have better meetings with automatic note taking\n•\t Research unfamiliar topics easily\n•\t Spot trends, synthesize information, and identify business opportunities \nFor 25 years, Google has built helpful, secure products that give users choice and control over their data. It’s a \nbedrock principle for us. This was the case back when we first launched Gmail in 2004, and it remains true in the \nera of generative AI. This means your data is your data and does not belong to Google. Your data stays in your \nWorkspace environment. Your privacy is protected. Your content is never used for targeting ads or to train or \nimprove Gemini or any other generative AI models.\n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1492
  },
  {
    "chunk_full": "6\nHow to use this prompt guide\nThis guide introduces you to prompting with Gemini for Workspace. It includes \nstrong prompt design examples to help you get started. Additionally, it covers \nscenarios for different personas, use cases, and potential prompts.\nYou will notice a variety of prompt styles. Some prompts have brackets, which \nindicate where you would fill in specific details or tag your own personal files by \ntyping @file name. Other prompts are presented without variables highlighted to \nshow you what a full prompt could look like. All of the prompts in this guide are \nmeant to inspire you, but ultimately they will need to be customized to help you \nwith your specific work.\nTo get started, use the role-specific suggested prompts as inspiration to help you \nunlock a new and powerful way of working.\nNext, learn how you can get \nstarted with different features  \nby visiting g.co/gemini/features.\n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1493
  },
  {
    "chunk_full": "7\nAdministrative \nsupport\nAs an administrative support professional, you \nare responsible for keeping teams on track. \nYou’re required to stay organized and efficient \n— even under pressure — while juggling many \npriority tasks. \nThis section provides you with simple ways to \nintegrate prompts in your daily tasks. \nGetting started \nFirst, review the general prompt-writing tips on page 2 and the Prompting 101 section at the beginning  \nof this guide.\nEach prompt below is presented with an accompanying scenario to serve as inspiration for how you can \ncollaborate with Gemini for Google Workspace. The prompt iteration example shows how you could write  \nfollow-up prompts to build on the initial generated response.\nPrompt iteration example\nUse case: Plan agendas (offsite, meetings, and more)\nYou’re planning a three-day offsite meeting. To build an agenda, you brainstorm with Gemini Advanced. \nYou type:\n I am an executive administrator to a team director.  Our newly formed team now consists of content  \n marketers, digital marketers, and product marketers. We are gathering for the first time at a three-day  \n offsite in Washington, DC.  Plan activities for each day that include team bonding activities and time for  \n deeper strategic work.  Create a sample agenda for me.  (Gemini Advanced)\nNEW\n•\t  Persona \n•\t  Task \n•\t  Context \n•\t  Format \n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1494
  },
  {
    "chunk_full": "8\nThis is a helpful start to your planning. You need to generate specific ideas for the team bonding activities.  \nYou type:\n Suggest three different icebreaker activities  that encourage people to learn about their teammates’  \n preferred working styles, strengths, and goals. Make sure the icebreaker ideas are engaging and can be  \n completed by a group of 25 people in 30 minutes or less.  (Gemini Advanced)\nYou are happy with the agenda as a starting point. You now want to reformat Gemini’s response into a table.  \nYou type:\n Organize this agenda  in a table format.  Include one of your suggested icebreakers for each day.  \n(Gemini Advanced)\nGemini Advanced\nGemini Advanced\n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1495
  },
  {
    "chunk_full": "9\nYou select Export to Docs. You open the newly created Doc. Now, you want to bring in detailed summaries \nfor the strategy sessions using your existing files in Google Drive to provide more context for what will be \ndiscussed. You prompt Gemini in Docs and tag your relevant files by typing @file name. \n Use @[2024 H2 Team Vision]  to generate a summary for the opening remarks on Day 1 of this agenda.  \n(Gemini in Docs)\nExample use cases\nExecutive administrators and executive business partners\nUse case: Manage multiple email inboxes\nAfter returning from vacation, you have many unread, unsorted emails. You prompt Gemini in the Gmail side \npanel. You type:\nSummarize emails from [manager] from the last week. (Gemini in Gmail)\nGemini returns short summaries of each message. To directly access a message, you click on Sources and see \ntiles that bring you to specific emails. You select the most important one. Once the email thread opens, you see \nthat many messages were exchanged. You prompt Gemini in Gmail:\nSummarize this email thread and list all action items and deadlines. (Gemini in Gmail)\nNEW\nGemini Advanced\n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1496
  },
  {
    "chunk_full": "10\nYou owe a response to a question, which you believe is best answered by a document in your Drive. You prompt \nGemini in the Gmail side panel. You type:\nGenerate a response to this email and use @[file name] to describe how the [initiative] can complement \nthe workstream outlined in [colleague’s name]’s message. (Gemini in Gmail)\nGemini in Gmail returns a suggested email that pulls directly from your own Doc. After reading it over, you select \nthe Copy icon in the side panel and paste it directly into your message. \n \nUse case: Plan business travel\nYour manager has an upcoming meeting that is out of town. You are responsible for booking travel \narrangements and creating a personalized itinerary. You need to research places to eat. You brainstorm with \nGemini Advanced. You type:\nI am an executive assistant. I need to create an itinerary for a two-day business trip in [location] during \n[dates]. My manager is staying at [hotel]. Suggest different options for breakfast and dinner within a \n10-minute walk of the hotel, and find one entertainment option such as a movie theater, a local art show, \nor a popular tourist attraction. Put it in a table for me. (Gemini Advanced)\nYou continue your conversation until you are happy with the itinerary. Before you make reservations, you want \nto share the draft with your manager. You select Share & export and select Draft in Gmail. Once the drafted \nemail is created, you put the final touches on the message and send. \nUse case: Track travel and entertainment budget \nYou want to create a spreadsheet to keep track of all of the travel expenses incurred. You open a new Google \nSheet and prompt Gemini in the Sheets side panel. You type:\nCreate a budget tracker for business travel. It should include columns for: date, expense type (meal, \nentertainment, transportation), vendor name, and a description. (Gemini in Sheets)\nGemini returns a tracker that is now ready for you to enter data. \nNEW\nNEW\n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1497
  },
  {
    "chunk_full": "11\nCommunications\nAs a communications professional, you are \nresponsible for ensuring your business is well \nunderstood by the public. You have to stay up to  \ndate with the trends, communicate clearly and \neffectively with many stakeholders, and build \ncompelling narratives. \nThis section provides you with simple ways to \nintegrate prompts in your daily tasks. \nGetting started\nFirst, review the general prompt-writing tips on page 2 and the Prompting 101 section at the beginning of  \nthis guide.\nEach prompt below is presented with an accompanying scenario to serve as inspiration for how you can \ncollaborate with Gemini for Google Workspace. The prompt iteration example shows how you could write  \nfollow-up prompts to build on the initial generated response.\nPrompt iteration example\nUse case: Create a press release\nYou are in charge of public relations at a company in the personal care industry. The company you work for has \njust acquired a smaller brand, and you need to craft a press release. You’ve completed interviews with your \ncompany’s CEO, CFO, and the acquired company’s CEO. You’ve stored all of the most important quotes in one \nDoc. You also have a Doc with all of the information about the acquired brand, its vision, how it got started, and \nstats. You open a new Doc and prompt Gemini in the Docs side panel and type @file name to reference your \nrelevant files. You type:\n I’m a PR manager.  I need to create a press release with a catchy title.  Include quotes from \n @[VIP Quotes Acquisition].  (Gemini in Docs)\nNEW\n•\t  Persona \n•\t  Task \n•\t  Context \n•\t  Format \n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1498
  },
  {
    "chunk_full": "12\n[Gemini returns a response]\nNow you have a starting place for the press release, but you want to include more details about the brand that is \nbeing acquired and its founder. This information is stored in your Drive in another file. In the press release Doc,  \nyou prompt Gemini in the Docs side panel. You type:\n Use @[Biography and Mission Statement]  to add more information about the company that is being \nacquired, its mission, and how it got started.  (Gemini in Docs)\nGemini in Docs\nGemini in Docs\nThe generated paragraphs are a good starting place, so you select Insert to add them into your draft, and you \nbegin making edits to the press release.\n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1499
  },
  {
    "chunk_full": "13\nExample use cases\nAnalyst and public relations\nUse case: Prepare for analyst or press briefings\nYou need to create a brief to prepare a spokesperson for an upcoming meeting with analysts and the media  \nfor a new product launch. You open a new Doc and prompt Gemini in the Docs side panel. You type:\nGenerate a brief template to prepare [spokesperson] for an upcoming media and analyst briefing for  \n@[Product Launch]. Include space for a synopsis, key messages, and supporting data. (Gemini in Docs)\nThis gives you a starting point to pull in additional information from your files. You prompt Gemini in the Docs \nside panel and tag your relevant files by typing @file name. You type:\nCraft a synopsis of the product launch in three main points using @[Product Launch - Notes]. \n(Gemini in Docs)\nYou click Insert before repeating the process to fill out the rest of the briefing document. Next, you need to \ncreate a spreadsheet of media and analyst contacts. You open a new Google Sheet and prompt Gemini in the \nSheets side panel. You type: \nOrganize my media and analyst contacts from @[Analyst and Journalist Contact Notes] for a new product \nbriefing. I need to keep track of their names, type of contact (analyst or journalist), focus area, the name \nof the outlet, agency or firm that they work for, and a place where I can indicate the priority level of their \nattendance at this briefing (low, medium, high). (Gemini in Sheets)\nGemini in Sheets returns a spreadsheet, and you can go through and indicate priority level for each contact. \nNext, you want to create a slideshow to use during the briefing. You open a new Google Slide and prompt Gemini \nin the Slides side panel. You tag relevant files by typing @file name in the prompt. You type:\nCreate a slide describing what [product] is from @[Product Launch - Notes]. Make sure it is short and \neasily understood by a broad audience. (Gemini in Slides)\nGemini returns a Slide. You continue to build your presentation by using this method to generate  \nadditional Slides.\nNEW\n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1500
  },
  {
    "chunk_full": "14\nUse case: Create mock interview questions to prepare spokespeople\nNow, you need to prepare your company’s spokesperson for interviews that will follow the briefing. To generate \na list of mock interview questions, you decide to chat with Gemini Advanced. You type:\nI am a [PR/AR] manager at [company name]. We just launched [product] and had a briefing where we \ndiscussed [key messages]. I am preparing [spokesperson and role/title] for interviews. Generate a list of \nmock interview questions to help [spokesperson] prepare. Include a mixture of easy and hard questions, \nwith some asking about the basics of [product] and some asking about the long-term vision of [product]. \n(Gemini Advanced)\nGemini returns a list of questions that can help you prepare your company’s spokesperson. You refine the \nsuggested questions by continuing the conversation with Gemini. Then you select Share & export and Export \nto Docs. You open the newly created Doc, prompt Gemini in the Docs side panel, and tag relevant files by typing \n@file name. You type:\nUse @[Product Launch Notes] to write suggested answers for these questions. Write the talking points  \nas if you are [title of spokesperson] at [company]. (Gemini in Docs)\nGemini in Docs returns suggested talking points, and you select Insert to add them into your draft. Now you’re \nready to continue tweaking the interview prep for your spokesperson.\nCommunications manager\nUse case: Craft internal communications\nYour company has redesigned its intranet to be more user friendly. You’re in charge of internal communications \nfor the launch. You want help drafting this message. You open a new Google Doc and prompt Gemini in the Docs \nside panel. You type:\nI need to draft a company-wide memo unveiling our relaunched intranet. The [new page] addresses \n[common feedback we heard from employees] and aims to create a more user friendly experience.  \nDraft an upbeat memo announcing [the new site] using @[Intranet Launch Plan Notes]. (Gemini in Docs)\nGemini in Docs returns a drafted memo. You refine and edit the text to be exactly as you need it. \nNEW\nNEW\n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1501
  },
  {
    "chunk_full": "15\nCustomer service\nAs a customer service professional, you strive \nto deliver service that’s effortlessly efficient, \nconsistently delightful, and powered by a \nproactive, helpful team. This section provides  \nyou with simple ways to integrate prompts in  \nyour daily tasks.\nGetting started\nFirst, review the general prompt-writing tips on page 2 and the Prompting 101 section at the beginning of  \nthis guide.\nEach prompt below is presented with an accompanying scenario to serve as inspiration for how you can \ncollaborate with Gemini for Google Workspace. The prompt iteration example shows how you could write  \nfollow-up prompts to build on the initial generated response.\nPrompt iteration example\nUse case: Draft customer communications\nYou’re a customer service representative, and you’re responsible for responding directly to customer inquiries \nand concerns. You just received an email from a customer who received damaged goods. You open a new \nGoogle Doc and click on Help me write to prompt Gemini in Docs. Type the following:\n Help me craft an empathetic email response.  I am a customer service representative,  and I need to  \n create a response to a customer complaint.  The customer ordered a pair of headphones that arrived  \n damaged. They’ve already contacted us via email and provided pictures of the damage. I’ve offered a  \n replacement, but they’re requesting an expedited shipping option that isn’t typically included with their  \n order.  Include a paragraph that acknowledges their frustration and three bullet points with potential  \n resolutions.  (Gemini in Docs) \n•\t  Persona \n•\t  Task \n•\t  Context \n•\t  Format \nGemini in Docs: [Drafts email copy]\n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1502
  },
  {
    "chunk_full": "16\nYou like the email that Gemini in Docs created so you select Insert. But you want to brainstorm ways to resolve \nthe issue without offering expedited shipping. You prompt by selecting Help me write. You type: \n Suggest 10 alternative options  in place of expedited shipping to resolve the customer’s frustration about  \n receiving the damaged package.  (Gemini in Docs) \nGemini in Docs: [List of alternative solutions] \nGemini in Docs\nGemini in Docs\nThese 10 suggestions are helpful. You click Insert to add the text into your draft.\n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1503
  },
  {
    "chunk_full": "17\nExample use cases\nCustomer Service Manager or Representative \nUse case: Respond to complex customer issues using FAQ documents\nA customer has reached out with a multi-part, complex question. You need to find and use information that is \nspread across multiple documents in order to respond accurately. You prompt Gemini in the Drive side panel. \nYou type:\nSummarize information about [product name] including the product’s specific [return policy], \n[ingredients], and [certifications]. (Gemini in Drive)\nGemini returns a summary and links to relevant files, which you can directly click into from the side panel.  \nYou read the information before returning to your email to generate a response to the customer. You open the \nmessage and prompt Gemini in the Gmail side panel and tag relevant files by typing @file name. You type:\nGenerate a response to the customer question about our [return policy] and [product certifications] \nbased on @[Customer FAQ Document]. Use a helpful and professional tone. (Gemini in Gmail) \nUse case: Standardize communication frameworks \nYou’re a customer service team manager. You need to create scalable resources to standardize your team’s \ncommunications. You open a new Google Doc. You brainstorm by prompting Gemini in the Docs side panel.  \nYou type: \nDraft templates for three different types of customer communication. Create templates for apology \nemails, order confirmation messages, and thank you notes for loyal customers. Keep each template to  \none paragraph and use a friendly tone. (Gemini in Docs) \nThe suggested templates offer a starting point for you to begin editing and personalizing with elements \nconsistent with your company’s brand and policies. Now you want to outline your team’s communication best \npractices for onboarding. You open a new Doc and prompt Gemini in Docs. You type:\nCraft a list of customer communication best practices that can be used to train new team members. \nOutline three sections, including how to handle happy customer inquiries, neutral customer inquiries,  \nand dissatisfied customer inquiries. (Gemini in Docs) \nNEW\n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1504
  },
  {
    "chunk_full": "18\nYou also want to support the team with standardized language that they can use when interacting with \ncustomers on phone calls. You prompt Gemini Advanced:\nI am a [customer service manager]. I am trying to create standardized language that the team can \nuse when interacting with customers on phone calls. Generate templates for common call openings, \ngreetings, and closures for a customer service representative at a retail store. These templates should \nallow for personalization with customer details. The goal is to ensure consistency and professionalism \nwhile allowing for differentiation with specific customer information. (Gemini Advanced) \nUse case: Improve customer service\nYou’ve noticed an uptick in customer complaints. You need to collaborate across departments to address \nrecurring issues. You prompt Gemini in Gmail. You type: \nDraft an email to my colleagues proposing a meeting to discuss customer experience improvement \ninitiatives. Request that marketing, sales, and product stakeholders meet in the next week to get a clear \nsense of roles and responsibilities. (Gemini in Gmail) \nYou edit the email and send it to your colleagues. Now you want to create a spreadsheet that you can use to \ntrack progress on this cross-departmental initiative. You open a Google Sheet and prompt Gemini in the Sheets \nside panel. You type: \nCreate a table to track the progress and impact of different customer experience improvement tactics \nusing relevant metrics, including support ticket volume and priority level (high, medium, low). \n(Gemini in Sheets)\nCustomer Support Specialist\nUse case: Analyze customer feedback\nYou have a spreadsheet that tracks customer feedback. You want to analyze it and brainstorm potential reasons \nfor the trends. You chat with Gemini Advanced. You upload the file and type:\nI am a customer support specialist. Using the attached spreadsheet, identify trends and patterns in our \n[customer feedback] by [category] over [time period]. Identify areas where [customer outreach] has \nincreased significantly and investigate potential reasons. (Gemini Advanced)\nNEW\n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1505
  },
  {
    "chunk_full": "19\nUse case: Enable customer self-service\nCustomer feedback has consistently said your return policy guidelines are unclear. You open a Doc that states \nthe return, refund, and store credit policies. You prompt Gemini in Docs by selecting Help me write. You type: \nSummarize this content to write a clear and concise product return policy and outline 5 steps for \ncustomers to take in sequential order. (Gemini Docs) \nYou like how simple the steps are. You repeat the process for your refund policy and store credit policy. Now, \nyou want to use the newly simplified content to create a blog post for customers. Using your Google Doc with \nthe newly written guidance, you prompt Gemini in Google Docs. You type:\nTake this content and turn it into a short blog with the title “Resolve Common Issues Without Agent \nAssistance.” Have separate sections for our return policy, our refund policy, and our store credit policy. \n(Gemini in Docs)\nNow you want to create an email template that the team can use when they receive customer questions around \nthese three areas. You open a new Google Doc and prompt Gemini in Docs using Help me write. You type: \nDraft an email template to a customer that highlights self-service resources referencing [blog link] for \n[support issues]. Thank the customer for their business and assure them of our commitment to meeting \ntheir needs. (Gemini in Docs)\nUse case: Conduct voice of the customer research \nYou want to email a dissatisfied customer to attempt to make things right. You open an email that includes a \ncustomer complaint. You prompt Gemini in Gmail by selecting Help me write. You type:\nRequest a follow-up conversation on [date] at [time] with this customer who provided negative feedback \nto understand their concern and offer resolutions. Include example solutions. (Gemini in Gmail) \nThe drafted response is a nice start, but you want to refine the language. You iterate by prompting Gemini  \nin Gmail using Refine and Elaborate. Next, you want to create a short survey that you can send after each  \nfollow-up customer call. You open a new Google Doc and prompt Gemini in Docs. You type: \nCreate five different questions to customers who have just spoken to an agent on the phone. Questions \nshould gauge how effective the call was, if the customer’s concern was addressed, and if they would \nrecommend our business to others. (Gemini in Docs) \n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1506
  },
  {
    "chunk_full": "20\nExecutives\nAs an executive, your time is incredibly \nconstrained. Every decision you make can impact \ngrowth, innovation, and the trajectory of your \nbusiness. Understanding your market and making \ninformed, strategic decisions is paramount, and \nso is getting urgent tasks done while you’re on \nthe go.\nThis section provides you with simple ways to \nintegrate prompts in your daily tasks. \n \nGetting started\nFirst, review the general prompt-writing tips on page 2 and the Prompting 101 section at the beginning of  \nthis guide.\nEach prompt below is presented with an accompanying scenario to serve as inspiration for how you can \ncollaborate with Gemini for Google Workspace. The prompt iteration example shows how you could write  \nfollow-up prompts to build on the initial generated response.\nPrompt iteration example\nUse case: Communicate on the go\nYou are an executive about to board a long flight, and you just received an invitation for the next board meeting \nwith an agenda. You have a couple of comments, and you want to propose adding a few topics to the agenda. \nYou open Gmail, and you prompt Gemini in Gmail. You type: \n Draft an email  confirming that I will be at the board meeting.  Ask if we can adjust the agenda to give 15  \n minutes to [urgent topics].  (Gemini in Gmail)\n•\t  Persona \n•\t  Task \n•\t  Context \n•\t  Format \nGemini in Gmail: [Drafts an email]\n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1507
  },
  {
    "chunk_full": "21\nThe email looks good, but you want to make sure the tone is as formal as possible. You select Refine  \nand Formalize.\nGemini in Gmail: [Formalizes tone]\nGemini in Gmail\nGemini in Gmail\nYou read the email and select Insert. Before sending it, you make a light edit to thank the team for keeping you \non track while traveling.\n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1508
  },
  {
    "chunk_full": "22\nExample use cases\nChief Executive Officer\nUse case: Enhance personal productivity and time management\nYou have important email threads that have numerous responses. You need to quickly catch up. You open \nthe message in Gmail and read the automatically generated summary from Gemini in the Gmail side panel. To \nrespond, you prompt Gemini in the Gmail side panel and tag relevant files by typing @file name. You type: \nGenerate a response to [person] about [topic]. Include details on [deliverable] and [timeline] using \n@[Project A Status Report]. (Gemini in Gmail)\nUse case: Create outlines of presentations in seconds \nYour team will pull together a presentation for you, and you want to provide an outline to get them started. You \nwant to generate an outline using Gemini Advanced. You select the microphone icon and use your voice to \nprompt. You say: \nI’m the CEO giving a presentation to [audience] at [event], and I want to create a detailed outline for my \nteam to get started. I want to include a few important topics, including [areas of focus] and how our \ncompany is innovating with [company initiatives]. I’m envisioning time for a customer Q&A to end the \npresentation. Include suggested questions we could ask of a customer from the [industry] industry about \nhow they are using our [product] to achieve [business outcome]. (Gemini Advanced)\nChief Operating Officer\nUse case: Prepare challenging employee communications \nYou’re hosting a quarterly town hall meeting with the entire company. You want to write uplifting remarks to open \nthe meeting. You open a new Doc and prompt Gemini in the Docs side panel. You type: \nWrite two uplifting paragraphs for employees who have just finished a challenging quarter. Acknowledge \n[difficulties] and emphasize [positives] for the upcoming quarter. Use a tone that is motivating, optimistic, \nand fosters a sense of unity and collaboration. (Gemini in Docs) \nNEW\nNEW\n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1509
  },
  {
    "chunk_full": "23\nYou want to brainstorm and practice how you will respond empathetically to potentially tough questions. You go \nto Gemini Advanced and type:\nI’m the COO of a mid-sized company. I am hosting a quarterly town hall meeting with the entire \ncompany. I want to brainstorm and practice how I will respond to potentially tough questions. Help me \nwrite challenging questions that employees may ask at the upcoming town hall about [URL of company \nannouncement]. Generate potential answers for each question that use a confident but firm tone. The \nresponses should acknowledge the concern and let the employees know that we are striving to do our \nbest for the entire company. (Gemini Advanced) \nUse case: Streamline responses on the go \nYour plans have changed, and you can’t attend a meeting. You need to provide the team with answers on a  \nfew key items. You open Gmail and use a voice command to prompt Gemini in Gmail. You say:\nDraft an email to [project lead] letting them know I will not be in the meeting due to an urgent matter.  \nAsk them to take detailed notes and to ensure the team arrives at a decision on [key topic] in addition  \nto assigning ownership of the postmortem report to [colleague]. (Gemini in Gmail) \nChief Marketing Officer\nUse case: Perform market research and campaign planning\nYou’re starting annual planning. You want to conduct research on your target audience. You chat with Gemini \nAdvanced. You type:\nI’m a marketing leader conducting analysis in preparation for next year’s [launch]. Define my target \naudiences [audiences], for my new line of [product]. Include interests, relevant marketing channels, and \ntop trends that drive their consideration and purchase behavior. (Gemini Advanced)\nNext, you export your findings to a Doc by selecting Share & export and Export to Docs. Now, you want to pull \nin relevant data from your own files by typing @file name. You prompt Gemini in the Docs side panel. You type:\nBrainstorm value props for my [target audiences] based on features from @[Product Requirements \nDocument]. Include a section on campaign learnings from @[Campaign Performance]. (Gemini in Docs)\nNEW\n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1510
  },
  {
    "chunk_full": "24\nUse case: Brainstorm content and thought leadership \nYou finished a meeting with your social media team leads. You took notes in a Doc about what resonates with \nyour audience, trending topics, target audience data, and keywords that are effective in driving engagement \nwith your brand. You want to brainstorm potential thought leadership pieces using these insights. You prompt \nGemini in the Docs side panel. You type: \nGenerate a list of four relevant and engaging thought leadership blog post ideas for [company] based on \ntrending topics, target audience analysis, and brand keywords. (Gemini in Docs) \nDuring the same conversation, the team discussed launching a new brand campaign. You know that your \ncustomers value your reliable and unique services, and your company has a long history of delivering for \ncustomers. You need help getting started with ideas on a new campaign tagline. You open a new Google Doc \nand select Help me write. You type:\nGenerate three options for a new slogan emphasizing reliability, innovation, and a long history of \npopularity for [company]. (Gemini in Docs) \nThe slogans help you get started with the creative process. You have upcoming events that could be the perfect \nplace to test elements of a new campaign. You want to mock up ideas for booth graphics for your events team. \nYou open a new presentation in Google Slides and select Create image with Gemini. You type: \nCreate an image of a trade show booth using orange and blue colors. The booth should be modern and \nshowcase interactive computer stations. (Gemini in Slides)\nUse case: Conduct competitive analysis\nYour team is considering expanding into a new line of business. To research, you go to Gemini Advanced, and \nyou type:\nI am a CMO conducting a competitive analysis. My company is considering expanding into [a new line of \nbusiness]. Generate a list of the top five competitors in the [industry] industry and include their pricing, \nstrengths, weaknesses, and target audience. (Gemini Advanced) \nAfter going deeper in your research, you decide to create a five-year strategy to see what this could look like for \nthe company. You type:\nOkay, I am going to try to convince my CEO that we should expand into [line of business]. Draft a concise, \ncompetitive strategy outline for the next five years for the [industry] industry across North America \nmarkets with potential goals, strategies, and tactics. (Gemini Advanced) \n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1511
  },
  {
    "chunk_full": "25\nAfter iterating to generate an appropriate outline, you fill in additional details and thoughts to make the \ndocument your own. \nChief Technology Officer\nUse case: Summarize emerging technology trends \nYou need to catch up on emerging technology trends as the landscape is shifting quickly. You open Gemini \nAdvanced, and you type:\nI am the CTO of [company] in [industry]. I want to understand emerging technology trends. Summarize \nthe top five emerging technologies with the most significant potential impact on [industry]. For each \ntechnology, list its potential benefits and challenges, and suggest how it could impact [company] in the \nnext two to three years. (Gemini Advanced) \nYou want to dig deeper on specific topics, so you continue the conversation by typing: \nRecommend three areas where [my company] can take proactive steps to stay ahead of the curve on \n[specific areas]. (Gemini Advanced)\nChief Information Officer\nUse case: Communicate technical topics to non-technical audiences\nYou’re making the case to digitally transform your company by adopting generative AI solutions. You need to \npresent to the CEO and other leadership. You want help in communicating technical topics to non-technical \naudiences. You chat with Gemini Advanced. You type:\nI am the CIO at [company], and I am trying to build the case to [adopt generative AI solutions]. I need to \nexplain the technical concept of generative AI to a non-technical audience (the CEO and board). Help me \nwrite talking points that will help me convey what generative AI is, ways it could help us digitally transform, \nand why it’s important to our growth as a company. Include details about how it could potentially refocus \nour technical talent on more strategic work, help enhance our workforce’s productivity, and help us better \nserve our global workforce and customers. (Gemini Advanced)\nGemini provides suggested ways to discuss the topic. You continue your brainstorm and then export your \nconversation by clicking Share & export and Export to Docs. Then, to build a presentation, you open a new \nGoogle Slide and prompt Gemini in the Slides side panel and tag relevant files by typing @file name. You type:\nI need to build a presentation to explain a technical topic to a non-technical audience. Generate  \nan [introduction slide] that [describes what generative AI is] using @[Gen AI Explanation Notes].  \n(Gemini in Slides)\nNEW\n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1512
  },
  {
    "chunk_full": "26\nYou continue to use the same prompt, adjusting the topic to generate more slides for your presentation based \non your notes. \nUse case: Research vendor products, services, and features\nYou’re working on a report to make a vendor recommendation. You visit Gemini Advanced and type:\nI am the CIO at [company]. We are currently evaluating vendor options to [replatform our intranet]. Right \nnow, we use [vendor], but we are looking to switch because [we are unhappy with limited functionality and \naccount support]. Suggest additional vendor options to consider and include descriptions of their product \nand services and key features. (Gemini Advanced)\nUse case: Develop technical summaries \nYour team just provided a lengthy technical report. You need to summarize it for your CEO. You open the Google \nDoc with the full report, and you prompt Gemini in the Docs side panel. You type: \nSummarize the key findings and implications of this report for [audience]. Focus on the main \n[vulnerabilities] identified and the recommended actions to address them. Use a formal tone. \n(Gemini in Docs)\nYou make light edits to the summary and include it as an executive summary. \nUse case: Track IT assets\nYour company needs a quick way to track software access for new hires. You open a new Google Sheet and \nprompt Gemini in the Sheets side panel. You type: \nCreate a tracker of software licenses for employees and include columns for license types, usage rights,  \nand renewal dates. (Gemini in Sheets)\nChief Human Resources Officer\nUse case: Demonstrate employee appreciation \nYou want to set up a new program to help everyone feel included, appreciated, and acknowledged across the \norganization. To brainstorm, you open a new Google Doc and prompt Gemini in the Docs side panel. You type:\nBrainstorm 10 employee appreciation ideas based on diverse employee interests such as cooking, \ngardening, sports, reading, and traveling. (Gemini in Docs) \nNEW\n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1513
  },
  {
    "chunk_full": "27\nGemini in Docs kick-starts your creativity, and now you have ideas for employee interest clubs and events.  \nYou also want to ensure your leadership team is regularly encouraging managers to recognize talent on their \nteams, so you create email templates they can use as inspiration. You prompt Gemini in Docs by selecting  \nHelp me write, and you type:\nDraft an email template that thanks [employee] for their hard work and [recent accomplishments]. Offer \nthem an extra perk for their dedication, such as [a coffee gift card]. Use an upbeat and professional tone. \n(Gemini in Docs)\nUse case: Assess employee satisfaction\nYou want to draft an anonymous survey that allows people to openly and honestly assess how they are feeling. \nTo draft questions, you open a new Google Doc and prompt Gemini in the Docs side panel. You type: \nDraft an anonymous employee satisfaction survey with questions and answer options that touch upon \nkey areas like workload, work-life balance, compensation, and career growth opportunities. Ensure the \nquestions are clear, concise, and avoid leading answers. (Gemini in Docs) \nYou received feedback from 15 senior leaders, and you’ve gathered all of the anonymous results in a Doc.  \nYou want to create a summary that you can use in your next call. You prompt Gemini in the Docs side panel.  \nYou type:\nSummarize the results of the employee feedback to identify key themes. (Gemini in Docs) \n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1514
  },
  {
    "chunk_full": "28\nFrontline \nmanagement\nAs a frontline worker manager, your team’s work \nis indispensable to your organization — your team \nmay not primarily complete its day’s work on a \ncomputer, but communication and collaboration \nremains key. \nThis section provides you with simple ways to \nintegrate prompts in your daily tasks. \nGetting started\nFirst, review the general prompt-writing tips on page 2 and the Prompting 101 section at the beginning of  \nthis guide.\nEach prompt below is presented with an accompanying scenario to serve as inspiration for how you can \ncollaborate with Gemini for Google Workspace. The prompt iteration example shows how you could write  \nfollow-up prompts to build on the initial generated response.\nPrompt iteration example\nUse case: Find accurate information quickly \nA customer just approached you with a question about an ongoing sale. You could use help navigating the \nnumerous files you have access to so that you find the right information quickly. You prompt Gemini in the Drive \nside panel. You type:\n Find the document  that details the [company name]’s  [holiday] sale details.  (Gemini in Drive)\nNEW\n•\t  Persona \n•\t  Task \n•\t  Context \n•\t  Format \n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1515
  },
  {
    "chunk_full": "29\nGemini in Drive returns suggested relevant files. From the side panel, you can directly summarize the files or you \ncan click into a specific document. You open a suggested Doc to help answer the question. You prompt Gemini \nin the Docs side panel. You type:\n How much can customers save on [product type] during this sale?  (Gemini in Docs)\nGemini in Docs\nGemini in Drive\nGemini returns a response, which helps you answer your customer’s question in a timely manner.\n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1516
  },
  {
    "chunk_full": "30\nExample use cases\nRetail associate\nUse case: Improve team collaboration by finding \nand sharing information easily\nYour store recently updated its return and exchange policies. To find the information, you prompt Gemini in the \nDrive side panel. You type: \nFind the document that discusses our new return and exchange policies. (Gemini in Drive) \nGemini returns suggested files that are related to the new policies. You directly click into the relevant file. Now, \nyou want to send an email summarizing the document for your colleagues’ future reference. You open your \nemail and prompt Gemini in the Gmail side panel. You type:\nWrite an email to my new colleagues summarizing @[Updated Return and Exchange Policy H2 2024]. \n(Gemini in Gmail) \nYou select Insert and further personalize the message before sending it. \nUse case: Streamline task management\nYou have a list of opening and closing duties that you must perform depending on what shift you are working. \nYou want to keep yourself organized, so you create a tracker using the duties listed in your onboarding Doc. You \nopen a new Google Sheet and prompt Gemini in the Sheets side panel and tag relevant files by typing  \n@file name. You type: \nI am a retail manager and I need to create a checklist for my opening and closing duties. Create a \ntemplate with columns for [opening and closing duties] from @[Onboarding New Hire Information]. \n(Gemini in Sheets) \nGemini creates a spreadsheet. As you go through your day, you mark different tasks as complete. You have to \nleave your shift early, but you first need to communicate to the rest of the team what still needs to be done. You \nopen your Gmail and prompt Gemini in the Gmail side panel and tag the spreadsheet you just created. You type:\nWrite an email to the team telling them what still needs to be done from the AM shift from @[Opening and \nClosing Duties Tracker]. (Gemini in Gmail)\nNEW\nNEW\n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1517
  },
  {
    "chunk_full": "31\nWarehouse worker\nUse case: Manage inventory\nA customer wants to place a bulk order. You need to check the store’s inventory to see if you have enough to \nfulfill it. You open your inventory spreadsheet that tracks this information and prompt Gemini in the Sheets side \npanel. You type:\nHow many [units] of [product] do we have left in our inventory? (Gemini in Sheets)\nUse case: Manage audits\nYour warehouse is undergoing an inventory audit, and you’re in charge of verifying any numbers that are \nmisaligned between your inventory tracker product total and what was counted during the audit. You prompt \nGemini in the Sheets side panel. You type:\nCreate a formula that helps me calculate the difference between two columns. Which items have a \ndiscrepancy in [the total number counted] versus [the quantity on hand]? (Gemini in Sheets)\nYou verify Gemini’s response that there are only a few items whose count did not align to your inventory \ntracker’s total. You need to write a message to your supervisor telling them that you’re looking into the issue. \nYou open your Gmail and prompt Gemini in the Gmail side panel. You type:\nI’m a warehouse worker managing an audit. Write a message to my supervisor to let them know that I am \nlooking into the products whose counts are incorrect. (Gemini in Gmail)\nThe drafted email looks good to go, so you hit send after reviewing.\nNEW\nNEW\n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1518
  },
  {
    "chunk_full": "32\nHuman resources\nAs an HR professional, you’re the backbone \nof your organization, and you deal with a large \nvolume of confidential and sensitive information. \nYou shape company culture, find and nurture \ntalent, and ensure a positive employee \nexperience. These are no small feats.\nThis section provides you with simple ways to \nintegrate prompts in your day-to-day tasks.\nGetting started\nFirst, review the general prompt-writing tips on page 2 and the Prompting 101 section at the beginning of  \nthis guide.\nEach prompt below is presented with an accompanying scenario to serve as inspiration for how you can \ncollaborate with Gemini for Google Workspace. The prompt iteration example shows how you could write  \nfollow-up prompts to build on the initial generated response.\nPrompt iteration example\nUse case: Welcome new employees\nYou’re an HR manager working on a presentation script. You have a Google Doc full of notes, bullet points, and \ntopics that you would like to cover. You begin by opening your Google Doc with notes, and you prompt Gemini  \nin Docs.\n I am an HR manager,  and I am developing a script for my presentation for new hires.  I need to create the  \n script for an onboarding presentation about our company’s commitment to employee development and  \n well-being.  Help me draft talking points that showcase why employee mentorship and development are  \n core values for our company using @[Mission Statement and Core Values].  (Gemini in Docs)\n•\t  Persona \n•\t  Task \n•\t  Context \n•\t  Format \nGemini in Docs: [Drafts talking points] \n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1519
  },
  {
    "chunk_full": "33\nGemini in Docs\nYou select Insert. Now, you want to add more targeted talking points. You type:\n Add four talking points  for a new section of the presentation script that explains how we support our  \n employees’ development.  Mention our training and certification programs and mentorship opportunities  \nusing  @[Learning and Development Paths],  and write a strong closing statement  about our expectation \nthat everyone contributes to a respectful and welcoming workplace.  Use a professional tone.  \n(Gemini in Docs) \nGemini in Docs: [Adds talking points]\nYou add in more details and then you’re ready to create a draft of the Google Slides that will accompany your \ntalking points.\nExample use cases\nRecruiter\nUse case: Report on recruitment metrics \nThe business is growing, and you have a large hiring effort underway. You want to see a holistic view of how your \nhiring efforts are going. You open your Google Sheet and prompt Gemini in the Sheets side panel. You type:\nHelp me create a formula to calculate the total total number of [hires] by [department]. \n(Gemini in Sheets)\nNEW\n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1520
  },
  {
    "chunk_full": "34\nYou continue your conversation by prompting additional questions. You type:\nIn what month did we hire the most people? (Gemini in Sheets)\nYou continue with your line of questions until you feel ready to write your report.\nUse case: Manage the recruiting process \nYou want to brainstorm potential ways the company can better manage the recruiting process. You open the \nteam’s Google Doc with recruiting strategies. You prompt Gemini in the Docs side panel. You type: \nCreate a list of strategies our recruiters can use to improve our existing recruiting process and identify \npotential job candidates. (Gemini in Docs) \nAfter creating a short recommendation for leadership on how the team will improve existing recruiting \nprocesses, the team receives guidance for a job opening for a content marketing manager. You open a new  \nDoc and prompt Gemini in Docs. You type:\nI am opening a new job position on the marketing team. Write a compelling role description for a content \nmarketing manager. Highlight key responsibilities [insert] and requirements, including B2B and B2C \ncontent creation, a minimum of five years experience, and a portfolio of writing examples. \n(Gemini in Docs)\nUse case: Manage the interview process\nYou want to prepare questions for phone screen interviews. You decide to prepare by using Gemini Advanced. \nYou upload the relevant file and type: \nI am a recruiter, and I am preparing for candidate interviews. Using the job description in the file I’m \nuploading, write a list of 20 open-ended interview questions that I can use to screen candidates. \n(Gemini Advanced) \nUse case: Communicate with candidates\nThe team has made its hiring decisions. You open the Google Doc with notes on each candidate. You prompt \nGemini in Docs by selecting Help me write. You type:\nI am writing an email to a job candidate who just finished the interview process. Create a template for \nan offer letter for the [selected candidate] for the [position] with a request to schedule a call to discuss \nbenefits, compensation, and start date. (Gemini in Docs) \n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1521
  },
  {
    "chunk_full": "35\nNow, you want to generate personalized, empathetic email copy to send to the job candidates who will not \nreceive an offer. You prompt Gemini in Docs by selecting Help me write. You type: \nI am writing an email to job candidates who finished the interview process, but who were not selected. \nHelp me write a rejection letter for [candidate] for the [position]. Use an empathetic tone. \n(Gemini in Docs)\nHR Manager\nUse case: Conduct employee engagement and satisfaction surveys\nYou are in charge of building a survey that will go out to all employees. You want to brainstorm ideas on \nquestions to ask. You visit Gemini Advanced and type:\nI am an HR manager in charge of running our enterprise-wide survey at [company] to gauge employee \nengagement and satisfaction. Generate a list of questions I can use to build the survey. \n(Gemini Advanced)\nYour company has completed its annual employee engagement and satisfaction survey. Now, you want to clean \nup the data before you analyze it. You go to Gemini Advanced, upload the relevant file, and type:\nHelp me clean my employee survey spreadsheet. Specifically, fill any blank values in the name column with \n“Anonymous,” and if the region column shows Headquarters, replace that with HQ. Finally, remove any \nrows where the satisfaction column is blank. Please generate a new file for me with my cleaned data. \n(Gemini Advanced)\nUse case: Create individualized learning and development plans\nYou have all of your company’s learning resources stored in your Google Drive. For each new hire, you want to \ncreate a tailored learning and development plan. To do this, you prompt Gemini in the Drive side panel. You type:\nCreate a personalized learning and development plan for a new hire who needs to learn about [topic]. \nOrganize it by day and suggest relevant files. (Gemini in Drive)\nUse case: Onboard employees\nThe recruiters have just filled the company’s two open roles. Now, you’re in charge of ensuring the candidates \nhave a smooth onboarding experience. You need help in structuring information for the new hires, so you open  \na Google Sheet and prompt Gemini in the Sheets side panel. You type: \nCreate a table that outlines a new employee’s first-week schedule, including key meetings, training \nsessions, and introductions. Provide a column for key contacts and priority level (low, medium, high) for \neach activity. (Gemini in Sheets)\nNEW\nNEW\n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1522
  },
  {
    "chunk_full": "36\nGemini in Sheets returns a formatted Google Sheet that you can now fill in with key contacts, meetings, and \nactivities. The conditional formatting makes it easy for you to sort tasks by priority level with color-coded visual \ncues. Next, you need to create ways for the team to bond. You open a new Google Doc and prompt Gemini in \nthe Docs side panel. You type:\nDesign a team-bonding activity, such as an office scavenger hunt, to have team members work together \nduring their team meeting. (Gemini in Docs) \nGemini in Docs provides suggestions that help you brainstorm about the scavenger hunt. You tweak the outputs \nand get the idea approved by the team lead. Now, you need to communicate with the new hires about their first \nday when they will meet the team. You open Gmail and prompt Gemini in Gmail by selecting Help me write.  \nYou type:\nDraft an email to the new employees on the [team] to meet the rest of their team and explain the team-\nbuilding purposes of the meeting. (Gemini in Gmail)\nUse case: Communicate key findings and draft follow-up surveys\nNow that you’ve finished onboarding new employees, you need to focus on ensuring that the latest company \nresearch data is easily understood by leadership. You’re committed to creating a welcoming environment for all \nemployees where they can develop their skills. You open the Google Doc with the finalized report. You prompt \nGemini in Docs by selecting Help me write. You type: \nDraft an email to senior leadership that summarizes the key findings from our [report]. Include a short \nintroductory paragraph with bullet points on the most important findings. (Gemini in Docs) \nGemini in Docs returns a summary with bullet points. You edit it and then use it to email the leadership team. \nAs a follow-up action, you want to understand how changes made to company policies impact the employee \nexperience. You open Gemini in Docs to begin drafting a survey. You select Help me write and type: \nDraft an anonymous employee survey with questions and answer options to monitor company progress on \n[topics]. (Gemini in Docs)\n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1523
  },
  {
    "chunk_full": "37\nMarketing\nAs a marketing professional, you’re the creative \nforce behind captivating campaigns, brand \nexperiences, lead generation, and more. You \nunderstand the power of data-driven insights, \ncompelling messaging, and connecting with your \naudience on a deeper level.\nThis section provides you with simple ways to \nintegrate prompts in your day-to-day tasks. For \nchief marketing officer (CMO) use cases, visit the \nExecutives section of the guide.\nGetting started\nFirst, review the general prompt-writing tips on page 2 and the Prompting 101 section at the beginning of  \nthis guide.\nEach prompt below is presented with an accompanying scenario to serve as inspiration for how you can \ncollaborate with Gemini for Google Workspace. The prompt iteration example shows how you could write  \nfollow-up prompts to build on the initial generated response.\nPrompt iteration example\nUse case: Develop a visual identity\nYou own your own consulting business and are often hired to function as a brand manager for your clients.  \nYou help businesses in a variety of industries. Your customer is getting ready to launch a coffee shop and video \ngame cafe, and you need to kick-start the creative process by developing a visual identity. You want to ideate \nand provide early thoughts to the rest of the team. You decide to chat with Gemini Advanced. You type:\n Generate ideas for a creative and eye-catching logo  for my new business, a coffee shop combined with \n a video game cafe. Generate a logo considering  the following: \n Dual Concept: The logo needs to clearly signal both  the coffee and gaming aspects of the business  \n without being too cluttered. \n Target Audience: Appeal to a wide range of gamers (casual and enthusiast), as well as coffee lovers  \n seeking a unique hangout spot.\n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1524
  },
  {
    "chunk_full": "38\n Style Options: I’m open to these approaches — let’s get a few examples in each of these three styles to \n compare: Modern and Playful: Bold colors, fun graphics, maybe a pixel art aesthetic. Retro-Cool: Think  \n classic arcade style — chunky lettering, neon color inspiration. Sleek and Minimalist: Clean lines,  \n geometric shapes, a more subtle nod to both themes.  (Gemini Advanced) \n•\t  Persona \n•\t  Task \n•\t  Context \n•\t  Format \nYou like the retro-cool options. You continue your conversation and you type: \n I like the retro-cool options.  Can you provide three more  in that same style?  (Gemini Advanced) \nNow that you have a sense of what the logo could look like, you want to brainstorm names. You type: \n Write a tagline and 10 potential names  for the business to go with these logos.  (Gemini Advanced) \nGemini Advanced\nGemini Advanced\n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1525
  },
  {
    "chunk_full": "39\nExample use cases\nBrand Manager\nUse case: Develop brand strategy \nYou are working to refresh your company’s brand architecture and messaging frameworks. To get started,  \nyou visit Gemini Advanced and type:\nI am a brand manager at [company]. Help me define a clear and effective brand architecture for \n[company], considering its diverse products and service portfolio. For additional context, here is our \ncurrent brand portfolio: [List all existing brands, products, and services]. Here is our company mission \nand vision: [Provide a brief overview of the company’s mission and vision]. And these are our target \naudience(s): [describe target audience(s)]. Our desired brand positioning is [explain how the company \nwants to be perceived in the market]. (Gemini Advanced)\nUse case: Brainstorm brand partnerships \nYou are working on a new brand campaign. You want to identify influencers or complementary brands you could \npartner with as part of the social amplification plan. You visit Gemini Advanced and type:\nI am a [brand manager] at [company] working to launch a new campaign focused on [topic]. Identify \npotential types of influencers and complementary brands that [company] could partner with to amplify \nthe [campaign] on social media channels. The goal is to reach a wide audience of [audiences], while \nbuilding credibility and driving engagement. (Gemini Advanced)\nNEW\nNEW\nGemini Advanced\n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1526
  },
  {
    "chunk_full": "40\nUse case: Conduct market research and identify trends \nThe landscape in your industry is rapidly changing, and you need to conduct market research to better identify \nand understand emerging trends. You go to Gemini Advanced, and you type: \nI need to do market research on [industry] industry to identify new trends. Use [URLs] to uncover \nemerging trends and shifting consumer preferences. (Gemini Advanced)\nAfter completing your research, you and the team have new messaging that you want to A/B test. You want to \ngenerate multiple variations of ad copy using Gemini Advanced. You type:\nI need to A/B test new messaging. Here is our messaging: [messaging]. Generate three different variations \nof ad copy. (Gemini Advanced)\nUse case: Create and manage content and distribution \nA customer has exciting organizational changes underway. You need to create content to shape the brand \nnarrative of the company as it enters its next era. You open a Google Doc to get started on a blog draft.  \nYou prompt Gemini in Docs by selecting Help me write. You type: \nCreate a blog draft announcing that [name] is joining [company] as [position]. [Share two or three \ndetails from their bio, such as their previous position and company, their involvement in professional \norganizations, etc.]. (Gemini in Docs)\nYou also want a way to efficiently track how and where this content is amplified, so you open a Google Sheet.  \nYou prompt Gemini in the Sheets side panel. You type: \nCreate a project tracker for content amplification and include columns for channel, owner, URL,  \nand priority level (low, medium, high). (Gemini in Sheets) \nMarketing Specialist\nUse case: Improve collaboration with customers, agencies, and teams\nYou are hosting a meeting discussing an upcoming project with multiple teams and an agency that will complete \nthe project’s design work. You use Gemini in Google Meet and select Take notes with Gemini so that all \nparticipants can give their undivided attention to the conversation. After the meeting, Gemini provides a \nsummary of the discussion and pulls out action items to keep the team on track. (Gemini in Meet)\nNEW\n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1527
  },
  {
    "chunk_full": "41\nFrom the generated Doc with call notes, you want to create a spreadsheet to help keep the team on track.  \nYou open a new Google Sheet and prompt Gemini in the Sheets side panel and tag relevant files by typing  \n@file name. You type:\nGenerate a project tracker using the action items from @[Meeting Notes from Gemini]. \n(Gemini in Sheets)\n \nUse case: Analyze social media trends and other data to reduce \ntime to market\nYou want to analyze different data sources and collate findings to help you reduce your time to market.  \nYou open Gemini Advanced and type:\nI am a [marketing specialist] at [company]. We are working on our [go to market] plans for [type of \nproduct]. Help me research social media trends around [topics]. Be specific about trending keywords,  \ntop influencer voices, and common themes in popular content. (Gemini Advanced)\nYou verify Gemini’s response by selecting the Double-check response option beneath Gemini’s response.\nNow, you want to review a report you’ve commissioned that surveyed customers from different industries.  \nYou continue your conversation with Gemini. You upload the relevant file and type:\nAnalyze the findings in this [report]. I am especially interested in any common themes about [topic] that \nstand out to you that will help me better position [marketing materials] for [product] for [target audience]. \n(Gemini Advanced)\nUse case: Perform audience research and develop personas \nYou need to refresh your audience research and persona development as the team updates webpage copy, \npitch decks, and other marketing assets. You brainstorm and research using Gemini Advanced. You type:\nI am a marketing specialist focused on [area] at [company]. I need to conduct in-depth audience \nresearch so that I can develop convincing marketing artifacts for [personas]. To start, help me generate \na comprehensive profile of [target audience]. Include core demographics and psychographics, online \nplatforms they frequent, key pain points [product] could solve, and language and messaging that \nresonates with them. (Gemini Advanced)\nNEW\nNEW\n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1528
  },
  {
    "chunk_full": "42\nDigital Marketing Manager\nUse case: Create and optimize copy for search engine marketing (SEM)\nYou want to create a robust list of keywords and long-tail keywords and phrases to uncover new opportunities \nfor SEM targeting. You go to Gemini Advanced and type:\nI am a digital marketing manager at [company]. I am working on SEM ads for [product]. Here are my seed \nkeywords: [list keywords]. Help me generate a list of additional keywords and long-tail keywords and \nphrases that can help me maximize ad performance. (Gemini Advanced)\nAfter you finish brainstorming your keywords list, you want to generate a few variations of ad copy. You type:\nFor my SEM campaign, use these keywords as inspiration to generate multiple ad copy variations  \nwith different headlines, descriptions, and calls to action for [product]. Use a [tone] tone in the copy. \n(Gemini Advanced)\nYou want to further refine the text according to different audiences, so you type:\nDo the same thing, except write new options for [audience], adjust the tone to be [tone] and focus  \nthe copy on highlighting [feature] of [product]. (Gemini Advanced)\nUse case: Draft customer acquisition communications \nEmail is one of your company’s main channels of direct communication with prospects and customers. You want  \nhelp getting started with copy for a new email campaign. You open a new Google Doc, and you prompt Gemini in \nDocs by selecting Help me write. You type: \nWrite three different email subject lines that reference [audience segments] and our [product]. Make them \ncatchy but professional. (Gemini in Docs) \nNow you want to share the proposed email subject lines with the copywriting team. You open Gmail, and you \nselect Help me write. You type:\nWrite an email proposing [suggested email subject lines] to the copywriting team. Keep the email short \nand simple and request feedback by the end of week. Thank them for their help. (Gemini in Gmail) \nNEW\n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1529
  },
  {
    "chunk_full": "43\nUse case: Generate inbound marketing campaigns \nThe team created a new ebook on best practices for executives using our new solution. You’re creating a landing \npage to house the gated asset, and you need engaging copy. You open a new Google Doc and select Help me \nwrite. You type:\nCreate compelling copy for a landing page promoting a new [ebook/webinar/free trial and details] \ndesigned for an executive target audience. Highlight key benefits and encourage conversions with \npersuasive calls to action. (Gemini in Docs) \nThe webpage launched, and you’re now running an inbound marketing campaign. You need to nurture the leads \nthat downloaded your latest ebook. You open a new Google Doc, and you prompt Gemini in Docs by selecting \nHelp me write. You type:\nGenerate copy for a sequence of five automated emails to nurture leads after they download the ebook \non [topic]. Personalize emails and encourage further engagement [with other valuable resources or \noffers]. (Gemini in Docs)\nContent Marketing Manager\nUse case: Deliver personalized content to customers at scale\nYou want to create copy for a five-step email nurture cadence for your new product. You open a new Google \nDoc and prompt Gemini in the Docs side panel and tag relevant files by typing @file name. You type:\nCreate a 5-step nurture email cadence to [prospective customers] who have signed up for [our \nnewsletter], with the goal of getting them to [purchase] [product] using @[Product Specific Notes]  \nand @[Product FAQ]. (Gemini in Docs)\nUse case: Create visuals for ad campaigns \nYou want to create visuals to help your creative agency better understand the team’s direction for an upcoming \ncampaign. You open a new Google Slide and prompt Gemini in Slides. You type:\nHelp me create inspirational images for a marketing campaign for [type of product]. Images should use \n[colors] and [natural elements, such as clouds]. Use a [photorealistic] style. (Gemini in Slides)\nNEW\nNEW\n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1530
  },
  {
    "chunk_full": "44\nUse case: Generate inspiration for your blog \nYou work for a travel company as the content marketing manager for the company’s blog channel. You need \nto kick-start the brainstorming process for a new blog post. You decide to gather ideas by collaborating with \nGemini Advanced. You type:\nSuggest blog post topics that would be interesting for people passionate about travel and the tourism \nindustry. Here’s what I want you to focus on: Make the topics unique. There are lots of tourism blogs out \nthere — let’s come up with fresh angles that would stand out. Keep the topics relevant. Tap into current \ntrends or recent challenges/innovations within the tourism industry when brainstorming. I’d like each topic \nto include:\nTarget audience: Who would this topic specifically appeal to?\nContent outline: A few bullet points with the main ideas the blog post would discuss.\nCall to action: Suggest one way to engage the reader at the end of the post. (Gemini Advanced) \nYou love the initial ideas you were able to create. You also need to focus on generating creative imagery to \naccompany the copy in the blog. You type:\nCreate an image of a plane flying above the clouds over mountains and rivers during sunrise that I can use \nin the marketing campaign to promote my travel company. (Gemini Advanced) \nUse case: Create social media posts\nYou’re focused on creating content that is optimized for social media channels. You need to gather ideas for \ncontent targeted to distinct audiences. You open a new Google Doc and prompt Gemini in Docs by selecting \nHelp me write. You type:\nWrite three engaging social media posts about [product/service/topic] that would appeal to [target \naudience]. Keep each social media post to two sentences and include a call to action to visit [our website]. \n(Gemini in Docs)\nYou also need to craft social media posts to drive registration for an upcoming event targeting recent grads.  \nYou open a new Google Doc and you prompt Gemini in Docs by selecting Help me write. You type: \nCreate a social media post promoting our upcoming [event name]. Include attention-grabbing language \nand relevant hashtags for [audience]. (Gemini in Docs) \n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1531
  },
  {
    "chunk_full": "45\nUse case: Create a strategic marketing plan \nYour company is launching a new app. You need a robust marketing plan, but you want ideas to get started.  \nYou chat with Gemini Advanced. You type: \nI’m developing a marketing plan for a new app that provides [functionality]. My target audience is \n[audience]. Help me create a plan with a focus on [marketing channels]. Here’s what I’d like you to cover: \ncompetitor analysis, ideal marketing channel mix with rationale, budget recommendations, key messaging \nideas, and proposed campaign timeline with KPIs. (Gemini Advanced) \nThe responses from your chat are helpful in shaping your marketing plan. You need to get the high-level details \nto your chief marketing officer (CMO). You open Gmail and prompt Gemini in Gmail by selecting Help me write. \nYou type:\nDraft an email to the CMO telling them that I will provide a one-pager with a strategic marketing plan for \nthe new app launch project by [date], and it will include an executive summary, overview of the competitive \nlandscape, top marketing channels, and the target demographic for all South American markets. \n(Gemini in Gmail)\n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1532
  },
  {
    "chunk_full": "46\nProject \nmanagement\nAs the conductor of complex, ever-evolving \nprojects, your mission is to navigate timelines, \ncoordinate teams, and ensure your programs \ndeliver the intended impact.\nThis section provides you with simple ways to \nintegrate prompts in your daily tasks. \nGetting started\nFirst, review the general prompt-writing tips on page 2 and the Prompting 101 section at the beginning of  \nthis guide.\nEach prompt below is presented with an accompanying scenario to serve as inspiration for how you can \ncollaborate with Gemini for Google Workspace. The prompt iteration example shows how you could write  \nfollow-up prompts to build on the initial generated response.\nPrompt iteration example\nUse case: Generate user acceptance tests\nYour team completed the registration form for a new website, and now you need to generate user acceptance \ntests (UATs). To start, you visit Gemini Advanced and type: \n Create a table with 10 user acceptance tests (UAT)  for the website registration form.  (Gemini Advanced)\n•\t  Persona \n•\t  Task \n•\t  Context \n•\t  Format \nGemini Advanced\n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1533
  },
  {
    "chunk_full": "47\nYou think the results are a helpful starting point, so you copy the results to a Google Sheet before drafting an \nemail to your colleague who is running the UATs. You want to explain what they need to do. You continue your \nconversation with Gemini Advanced. You type: \n Draft an email  to [my colleague] who is running this UAT and explain what they need to do next.  \n(Gemini Advanced)\nThe drafted email provides a helpful starting point, so you export the results to Gmail, and you make edits \ndirectly before sending the message to your colleague.\nExample use cases\nProject Manager\nUse case: Report on project status\nYou just had a lengthy call with all of your project stakeholders, and now you want to summarize what was discussed \nand follow up with assigned action items. In the Google Doc with the meeting transcript, you prompt Gemini in Docs. \nYou type: \nSummarize this call transcript in a short paragraph. In bullet points, highlight the action items, decisions \nmade, and owners for each item based off of [call transcript]. (Gemini in Docs) \nGemini Advanced\n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1534
  },
  {
    "chunk_full": "48\nYou need to update your manager based on the activity from the last call. You want to templatize how your \nproject status updates are delivered. You open a new Google Doc, and you prompt Gemini in Docs by selecting \nHelp me write. You type:\nDraft a project status update email template to send to my manager. Include sections for a summary of \nkey accomplishments this week, any challenges faced, and the top three priorities for next week. \n(Gemini in Docs)\nThe team just hit its key milestones an entire week early. It’s been a challenging project, so you want to gather \neveryone to celebrate together. You open Gmail and prompt Gemini in Gmail by selecting Help me write.  \nYou type:\nWrite an invitation for a team lunch to celebrate the progress made on a project and include [date, time, \nand location]. Thank them for all of their hard work and acknowledge that this has been a challenging \nproject. (Gemini in Gmail)\nUse case: Create a project retrospective \nYou’ve just wrapped the project, and your senior leadership team needs a project retrospective. To kick-start \nthe process of gathering feedback, you open a Google Doc and prompt Gemini in Docs by selecting Help me \nwrite. You type: \nI need to write a report detailing the successes, failures, and lessons learned from [project]. Draft a list \nof 20 questions to guide a cross-team process investigation. Include questions to uncover what worked, \nwhat didn’t, specific process breakdowns, technical issues, communication gaps, or any other potential \ncontributing factors to the problem or success of the project. (Gemini in Docs) \nThe questions give you a great starting place. You edit them before sharing with the team for their input. After \nyou gather everyone’s feedback, you want help structuring the report. You prompt Gemini in Docs by selecting \nHelp me write. You type: \nSummarize this document in two paragraphs. Include high-level information about the project’s goals,  \nthe main contributors, the outcomes of the project, and any key successes or failures. (Gemini in Docs)\nUse case: Develop an issue tracker and related communications \nYou need to create a project issue tracker to keep track of risks and solve them in a timely manner. You want  \nto create a template quickly, so you open a new Google Sheet and prompt Gemini in the Sheets side panel.  \nYou type:\nCreate a spreadsheet to track project issues, including descriptions, status, assigned owner, and action \nitems for resolution. (Gemini in Sheets) \n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1535
  },
  {
    "chunk_full": "49\nBefore the project fully kicks off, you want to have standardized communication templates at your disposal.  \nFor example, you want an email that can be used if an issue arises. You open a new Google Doc and prompt \nGemini in Docs by selecting Help me write. You type: \nDraft an email template to announce when an issue arises and include causes, solutions, and timelines  \nto resolve it. (Gemini in Docs)\nYou like the template that Gemini in Docs creates, and you want to create an additional, slightly different email \ntemplate. In the same Google Doc, you prompt Gemini in Docs by selecting Help me write. You type: \nDraft an email template to a stakeholder to escalate a critical project issue, outlining the impact and \nproposed solution. (Gemini in Docs)\nTechnical Project Manager\nUse case: Create a workback schedule\nYou are the technical project manager for a software release. You already have the scope of the project \ndocumented. Now, you want to get started on building a workstream tracker and workback schedule.  \nYou go to Gemini Advanced and type: \nI am a [technical project manager] at [company] overseeing [project and brief project description].  \nThe project has the following scope: [scope]. Our project goals are: [project goals]. Our project \ndeliverables are: [project deliverables]. Our budget is [budget], and our delivery date is [delivery date]. \nHelp me create a workback schedule to keep the team on track. Include dates for key milestones and \ndemos. (Gemini Advanced)\nNEW\n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1536
  },
  {
    "chunk_full": "50\nSales\nUnderstanding your customers inside and out \nis your ticket to success. You’re in charge of \nmaintaining critical relationships, deciphering \nbuying signals, crafting tailored solutions, driving \nrevenue for the business, and more.\nThis section provides you with simple ways to \nintegrate prompts in your daily tasks. \nGetting started\nFirst, review the general prompt-writing tips on page 2 and the Prompting 101 section at the beginning of  \nthis guide.\nEach prompt below is presented with an accompanying scenario to serve as inspiration for how you can \ncollaborate with Gemini for Google Workspace. The prompt iteration example shows how you could write  \nfollow-up prompts to build on the initial generated response.\nPrompt iteration example\nUse case: Conduct customer research \nYou’re an account executive, and you’ve just been assigned to a new customer. You need a research assistant. \nYou will need to get to know key contacts at the account to begin building trust between your teams, but first, \nyou want to send an introductory email, so you open Gmail and prompt Gemini in Gmail by selecting Help me \nwrite. You type:\n Write an email to [name], the new [title] at [company].  Congratulate them on their new role. Introduce me  \n as their contact point at [company name]. Invite them to lunch next week and check if they prefer Monday \n or Tuesday.  (Gemini in Gmail)\n•\t  Persona \n•\t  Task \n•\t  Context \n•\t  Format \nGemini in Gmail: [Drafts email]\n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1537
  },
  {
    "chunk_full": "51\nThis provides a helpful starting point, but you want to try getting an even better response. You click Refine  \nand Formalize.\nGemini in Gmail: [Generates refined email suggestions] \nGemini in Gmail\nYou’re happy with the email, so you click Insert. You read the message one last time, make final light edits \ndirectly, and then send the message. Now, you want to learn more about the customer and how it markets itself. \nTo research, you visit Gemini Advanced and type: \n I am an account executive in charge of a new account, [customer name].  I need to do initial research.  \n What is the market strategy of [customer]?  (Gemini Advanced) \nGemini in Gmail\n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1538
  },
  {
    "chunk_full": "52\nGemini provides you with useful information to get started in your research. You continue your research by first \nfocusing on news announcements. You gather a list of URLs, and you paste them into your conversation with \nGemini Advanced. You type: \n [URLs]  Summarize these articles.  Provide key insights and contextualize why these announcements are \n important.  (Gemini Advanced)\nNow you have a clear summary of what was announced, why the news is important, and additional insights. Next, \nyou want to better understand the executive who will be your main point of contact. You find a recorded interview \nfeaturing the executive. You paste the YouTube URL into your conversation with Gemini Advanced and type:\n [YouTube URL]  Summarize this interview and tell me more about [executive name].  What does [executive] \n care about?  (Gemini Advanced)\nYou continue the conversation with additional lines of questioning to build familiarity with your key contact and \nthe account. You prompt: \n Tell me how [company] can help [customer company] with achieving their goals.  (Gemini Advanced) \nOnce you wrap up your conversation, you export your results into a Google Doc. You open the Google Doc and \nprompt Gemini in Docs. You type:\n Create an email draft  for [customer] explaining why [your company] is the perfect partner for them to \n achieve their market goals.  (Gemini in Docs) \nGemini Advanced\n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1539
  },
  {
    "chunk_full": "53\nExample use cases\nCustomer Success Manager\nUse case: Map customer journeys \nIt’s your first time onboarding a new customer, and you realize you could benefit from creating custom-tailored \nassets. You open a new Doc and prompt Gemini in the Docs side panel and tag relevant files by typing @file \nname. You type:\nCreate personalized onboarding materials for [customer]. Use @[Standard Onboarding Documents] and @\n[New Customer Migration Notes] to personalize the assets. (Gemini in Docs)\nSales Manager\nUse case: Manage the request for proposal (RFP) process\nYou’ve just received an RFP, and you want to quickly ingest the request as part of your information gathering \nprocess. First, you want to do basic research on the company that issued the request. You visit Gemini \nAdvanced and you type:\nI just received an RFP from [company]. Before I dive into the RFP, I want your help in conducting research. \nGive me a business profile of the company including all of the basics (where they are located, what they \nprovide for customers, who their target audience is, any recent news from the company). Be as detailed \nas possible as I want to see a full view of [the company]. (Gemini Advanced)\nOnce you finish your research on the company, you want to summarize the RFP. You continue your conversation \nwith Gemini. You type:\n[URL or uploaded file] I am a sales manager at [company], and this is the RFP we’ve received from \n[company]. Summarize this content in a few paragraphs. What is the customer seeking, what is the \nbudget, and when is a response due by? (Gemini Advanced)\nUse case: Access information and tools on your phone while on the go\nYou are working remotely from your phone. From the mobile app, you open a thread in Gmail and select the \nGemini chip to Summarize this email. Gemini quickly provides you with a summary of the back and forth so \nthat you can focus on the most important points. (Gemini in Gmail)\nNow, you want to generate a response acknowledging the latest developments. You prompt Gemini in Gmail.  \nYou type:\nWrite a response to this email letting [them] know that I’ve received the message and will take [action]  \nby [Friday]. (Gemini in Gmail)\nNEW\nNEW\nNEW\n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1540
  },
  {
    "chunk_full": "54\nUse case: Develop customer relationships \nYour annual conference is coming up, and your most important prospects will be there. You want to personally \ninvite them to a happy hour. You open Gmail and prompt Gemini in Gmail by selecting Help me write. You type:\nWrite an email inviting people interested in [focus area] to our happy hour taking place on [date, time] at \n[trade show event]. Include that we specialize in [focus area]. (Gemini in Gmail)\nNow that the event is over, you want to follow up with customers who came to the happy hour. You open Gmail  \nand prompt Gemini in Gmail by selecting Help me write. You type: \nDraft an email thanking customers for their time at the happy hour on [date, time, location]. End with an \ninvitation to continue the conversations in the next few weeks. Use a friendly tone. (Gemini in Gmail) \nYou want to check in with the customers who attended workshops at the conference because their early \nfeedback is important. You prompt Gemini in Docs. You type:\nDraft 10 questions that I can use to survey customers about their recent experience with our [product/\nservice]. Include questions to gauge how useful [the product] is, what they liked, and what they thought \ncould use improvement. (Gemini in Docs) \nUse case: Support the sales team\nYou need to contact all of your team leads in the Southeast region to provide immediate guidance on how to \nproactively reach out to customers about an ongoing issue. You open Gmail and prompt Gemini in Gmail by \nselecting Help me write. You type: \nDraft an email to all Southeast region sales leads. Inform them of [issues]. Advise them to communicate \nwith their teams to contact their customers and offer a 20% discount on a future order as an apology. \n(Gemini in Gmail)\nNow, you need to email all of the regional team members. You open Gmail and prompt Gemini in Gmail by \nselecting Help me write. You type: \nDraft an email to the regional sales representatives about an urgent meeting that needs to take place next \nweek about the [issues]. Ask them to provide availability on Monday or Tuesday. (Gemini in Gmail) \nUse case: Coach and train the sales team \nYou’ve heard from many team members that they want more learning opportunities. You’re organizing a half-day \nlearning program to support this request. You need to create a schedule, so you open a new Google Doc and \n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1541
  },
  {
    "chunk_full": "55\nprompt Gemini in Docs by selecting Help me write. You type: \nCreate a half-day agenda for an educational session on our latest technology [products] for sales teams. \nInclude time for the product development team to present and include time for lunch. (Gemini in Docs) \nAs a follow up to the team meeting, you want to highlight different learning opportunities available. You open \nGoogle Sheets and prompt Gemini in the Sheets side panel. You type:\nCreate a spreadsheet that tracks online courses for sellers. Include columns for the course’s main topic, \nprice, duration, and priority level. (Gemini in Sheets) \nAccount Manager and Account Executive\nUse case: Improve collaboration and execution by customizing \nsales materials\nYou are having an important meeting with a customer. From Google Meet, you turn on Transcription and \nactivate Gemini in Meet by selecting Take notes with Gemini. The transcript provides an unedited Doc of \nwhat was said. The Take notes with Gemini file will generate notes recapping the meeting, important topics \ndiscussed, and action items. Now, you can fully engage with the customer conversation. (Gemini in Meet)\nAfter the call, you want to send a recap message to the customer. You open a new message and prompt Gemini \nin the Gmail side panel and tag relevant files by typing @file name. You type:\nWrite a message to [customer] thanking them for their time at our last [meeting]. Provide a quick  \nsummary of the meeting and acknowledge any pain points discussed. Ask for additional time to  \ndiscuss our [solution] using @[Customer Meeting Gemini Notes]. (Gemini in Gmail)\nIn preparation for your next meeting, you want to use the transcript and your existing sales materials to generate \na customized asset that showcases how your company’s product solves the customer’s pain points mentioned \nduring the call. To do this, you open a new Doc and prompt Gemini in the Docs side panel and tag relevant files \nby typing @file name. You type:\nI am an [account manager] and I just finished a call with [customer]. I want to summarize the [pain points] \nmentioned by [customer] during our last meeting. Provide a list of direct quotes from @[Customer Call \nTranscript] where [customer] discusses what they are trying to solve. (Gemini in Docs)\nYou read through the summary of pain points and see that they capture what was discussed. You click Insert \nfrom the side panel. Then, you want to use your existing files to generate custom responses to each of their pain \npoints. You prompt Gemini in the Docs side panel again and tag relevant files. You type:\nI need to create convincing reasons why [customer] should adopt [product] to solve for [their pain points].  \nWrite specific reasons why [product] from [company] could help them achieve their [business goals] using \n@[Product Sales Kit Full Assets]. (Gemini in Docs)\nNEW\n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1542
  },
  {
    "chunk_full": "56\nUse case: Build customer relationships\nYou just had a great call with a customer and now you want to use the notes you took from the meeting in \nGoogle Docs to draft an email to the customer. In the Google Doc with your notes, you prompt Gemini in Docs  \nby selecting Help me write. You type:\nCompose a personalized follow-up email to [client] following an initial conversation. Summarize the key \npoints we discussed and address any outstanding questions. (Gemini in Docs) \nThe account has just adopted one of the company’s service offerings and you need to ensure that they feel \nsupported during the onboarding process. You want to make sure you check in on how things are progressing \nonce a week, but you want to explore what the emails could look like. You open a new Google Doc and prompt \nGemini in Docs by selecting Help me write. You type: \nDraft four email templates to check in on my customer weekly now that they have purchased our new \n[service]. Use one value proposition (cost, ease of use, security, availability, and customization) as the \nmain topic for each email, and include [call to action] in each message. (Gemini in Docs) \nUse case: Prepare for new customer calls \nYou have an upcoming call with a prospect. This is a brand new use case for you, and you need help preparing \nfor the call. You visit Gemini Advanced, and you type: \nDraft a customized script for me to follow during my sales call with a prospect. The call will happen over \na video call and is set to last 30 minutes. Make sure to add the following in the script: how [company \nproducts/solutions] can help address potential customer’s pain points, how [company]’s delivery system \nguarantees seamless and timely delivery, competitive pricing and volume-discount table, and space for  \na customer reference in the [customer’s industry] industry. (Gemini Advanced) \nNow that you’ve done initial research, you export your findings to a new Google Doc. You open the Google Doc \nand continue working. Now, you want to create a tailored pitch. Using the Google Doc with all of your research \nnotes, you prompt Gemini in Docs by selecting Help me write. You type: \nGenerate an elevator pitch for [product name] and include key benefits, competitive points of \ndifferentiation, and the pain points that [product name] solves for. (Gemini in Docs) \n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1543
  },
  {
    "chunk_full": "57\nYou have a great start to your elevator pitch and short talking points. You want to use this to further anticipate \nhow the customer call might go. You resume your meeting preparation by returning to Gemini Advanced.  \nYou type:\nI have an upcoming call with a prospect. [Use case] is a new use case for me, and I need help preparing for \nthe call. List the most likely objections [customer] might have for me during a sales call, with suggestions \non how to respond to them. I work in [industry], and I am trying to sell [product]. Also provide ideas on how \nto handle objections and suggest ways to respond. (Gemini Advanced) \nBusiness Development Manager\nUse case: Nurture relationships, personalized outreach, and  \nthought leadership \nYou’re hoping to build deeper relationships with prospective customers that you recently met. You want to draft \na template that you can customize for multiple contacts. You open a new Google Doc, and you prompt Gemini in \nDocs. You type: \nDraft an outreach email template to industry influencers. Express gratitude that we connected at [event], \nand propose collaboration opportunities such as [opportunities]. (Gemini in Docs) \nAfter having a successful call with prospective customers, you want to follow up with thought leadership content \nfrom your founder that they may find interesting. You open the Google Doc with the blog post, and prompt \nGemini in Docs by selecting Help me write. You type: \nSummarize this blog content in bullet points and generate three ideas for follow-up questions I can ask my \ncustomers about their thoughts. (Gemini in Docs) \nUse case: Generate personalized customer appreciation materials \nYou want to personally thank your customers and check in. You open Gmail and prompt Gemini in Gmail by \nselecting Help me write. You type:\nGenerate a personalized email for [customer] on their one-month anniversary working with [company]. \nThank them for being a customer. Ask them if they have any questions. Include information about [other \nproduct]. (Gemini in Gmail)\nYou also want to send these customers a gift to thank them. You open a Google Sheet and prompt Gemini in the \nSheets side panel. You type: \nGive me a list of gifts to send new clients that are under $200 and can be shipped to offices. \n(Gemini in Sheets)\n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1544
  },
  {
    "chunk_full": "58\nSmall business \nowners and \nentrepreneurs\nAs the owner of a business, getting the most \nout of your working hours is critical when you’re \njuggling multiple roles and responsibilities. \nUnderstanding your market, delivering for \nyour customers, and staying on top of many \ncompeting priorities is critical.\nThis section introduces you to AI prompts designed to simplify complex choices with AI data analysis,  \nstreamline your email inbox, and help you stand out with creative marketing tactics. Discover how Gemini for \nGoogle Workspace can help you unlock deep insights, foster collaboration, and help propel your company to \nnew heights.\nGetting started\nFirst, review the general prompt-writing tips on page 2 and the Prompting 101 section at the beginning  \nof this guide.\nEach prompt below is presented with an accompanying scenario to serve as inspiration for how you can \ncollaborate with Gemini for Workspace. The prompt iteration example shows how you could write follow-up \nprompts to build on the initial generated response.\nPrompt iteration example\nUse case: Create pricing comparison\nYou are the owner of a local spa. You are evaluating offers you’ve received from two different cleaning \ncompanies. You want to find a company with the right price, flexibility, and level of service. You open a new Doc \nand prompt Gemini in the Docs side panel and tag relevant files by typing @file name in your prompt. You type:\n I’m a business owner  and I’m trying to determine the right cleaning vendor using \n @[Company A Proposal] and @[Company B Proposal]. I need someone to come twice a week,  \n and I want them to vacuum, mop, dust, clean the windows, and wipe down all surfaces. If available,  \n include information about the booking and cancellation policy.  Create a comparison table between  \n the two companies’ proposals.  (Gemini in Docs)\n•\t  Persona \n•\t  Task \n•\t  Context \n•\t  Format \n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1545
  },
  {
    "chunk_full": "59\nGemini in Docs\nGemini returns a formatted table comparing the two proposals. After you make your decision, you go to your \nemail and prompt Gemini in the Gmail side panel. You type:\n Write an email to Company A  thanking them for their time and their proposal.  Ask for a few times  \n to meet to schedule cleanings.  (Gemini in Gmail)\nGemini in Gmail\n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1546
  },
  {
    "chunk_full": "60\nExample use cases\nOwner\nUse case: Enhance personal productivity\nYou have many important email messages to catch up on. You open your email and select an important thread. \nYou open Gemini in the Gmail side panel, and it automatically summarizes the content. (Gemini in Gmail)\nUse case: Brainstorm and generate marketing content\nAs the business owner, you are also responsible for marketing your services via your social channels,  \nyour email-based newsletter, and email marketing. You aren’t sure where to start, so you chat with  \nGemini Advanced. You type:\nI own a [type of business] in [location]. I am working on marketing materials to advertise [event/sale] on \n[services]. I want to focus on using this sale to bring in repeat customers who haven’t purchased in a while \nand new customers alike. I want the social posts to feel [inspirational] and [fun]. Suggest some social copy \nI can use on [social platform] with relevant hashtags, suggested newsletter copy, and two email drafts \n(one for existing customers and one for new customers). (Gemini Advanced)\nYou like the suggestions Gemini provided, so you select Share & export and Export to Docs. You want to \ncontinue your brainstorm, so you ask Gemini:\nWhat are some other effective [event/sale] tactics I can use to bring in new customers? I don’t always want \nto offer discounts. Are there other incentives I am overlooking? (Gemini Advanced)\nYou continue your conversation with Gemini and are able to create a solid list of marketing tactics to try. \nUse case: Develop a competitive analysis \nYou started a company, and your online business is gaining traction. You have always dreamed of opening a \nbrick-and-mortar store, and now might be the perfect time. You want a thought partner to help you better \nunderstand the current landscape. You open Gemini Advanced, and you type: \nI am an online business owner. I am considering opening a brick-and-mortar store. Conduct an analysis \ninto the competitive landscape focusing on [focus area]. Provide the strengths and weaknesses of  \n[key competitors] in this area, including their specific strategies, tactics, and results. Identify actionable \ninsights and recommendations for how [my company] can improve its approach and gain a competitive \nadvantage. (Gemini Advanced)\n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1547
  },
  {
    "chunk_full": "61\nYou gathered useful information from your discussion with Gemini Advanced. You want to go deeper in your \nbrainstorming around two competitors in particular. You type: \nGenerate a competitive analysis of [company] versus [competitor] within the current market landscape. \n(Gemini Advanced)\nYou select Share & export and Export to Docs.\nUse case: Conduct fundraising and investor relations \nYou’re ready to reach out to potential investors to make your brick-and-mortar store a reality. You want help \ngetting started on an email to investors, so in the same Google Doc with your competitive analysis research, you \nprompt Gemini in Docs. You type:\nDraft a personalized email template to potential investors, highlighting [company’s] unique value \nproposition and recent progress on [initiatives]. Request a time to meet to discuss opportunities to \ncollaborate in the next month. (Gemini in Docs)\nThe email template gives you a starting place. You tweak the draft and continue to add a few personal touches \nbefore sending the email to the potential investors. After a successful meeting with them a month later, you want \nto draft a thank you message. You open your Google Doc with the meeting transcript and notes. You prompt \nGemini in Docs to help you write an email draft. You type: \nDraft an email thanking a potential investor for the call and ask for time to schedule a follow-up meeting to \naddress [questions and concerns]. (Gemini in Docs) \nUse case: Manage time off policies and tracking \nYou have a lengthy handbook detailing all of your company’s policies and procedures. You want to make the \ntime-off request policy easily digestible for new hires. You open the Google Doc with the handbook. You prompt \nGemini in Docs by selecting Help me write. You type: \nGenerate a step-by-step checklist summarizing the company’s time-off request policy. Ensure it is written \nin plain language and easy for employees to understand. (Gemini in Docs) \nYou need a quick way to track staffing each week because many of your employees are shift-based. You open \nGemini in the Sheets side panel. You type: \nCreate a table that tracks weekly staffing. Create columns for date, name, shift (AM or PM), and notes. \n(Gemini in Sheets)\n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1548
  },
  {
    "chunk_full": "62\nStartup leaders\nYou thrive in fast-paced, dynamic environments \nwhere you can wear many hats and make a \ntangible impact. You’re driven by a passion \nfor innovation, a desire to learn and grow, and \na tolerance for risk. Your work is unique in its \nvariety, its potential for high reward, and its direct \nconnection to the company’s success. You’re not \njust executing tasks; you’re building something \nfrom the ground up, shaping the future of  \nyour company, and potentially disrupting  \nentire industries.\nGemini for Google Workspace can help you redefine productivity and foster meaningful connections with \ninvestors, customers, and coworkers. This section provides practical prompts and real-world use cases \ndesigned specifically for you and your team. Learning to write effective prompts with Gemini for Workspace  \nwill help improve your productivity and streamline your everyday tasks, giving you more time to focus on \nstrategic work.\nGetting started\nFirst, review the general prompt-writing tips on page 2 and the Prompting 101 section at the beginning  \nof this guide.\nEach prompt below is presented with an accompanying scenario to serve as inspiration for how you can \ncollaborate with Gemini for Workspace. The prompt iteration example shows how you could write follow-up \nprompts to build on the initial generated response.\nPrompt iteration example\nUse case: Brainstorm business and strategy \nYou just had a productive planning and strategy brainstorming session with colleagues and you took many notes \nphysically on a whiteboard. You snap a quick image with your phone and upload it directly to Gemini Advanced. \nYou type:\n I am a founder at a startup focused on [industry].  I was brainstorming with colleagues about [topic], and  \n we took notes on this whiteboard.  Turn these notes into text.  (Gemini Advanced)\n•\t  Persona \n•\t  Task \n•\t  Context \n•\t  Format \n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1549
  },
  {
    "chunk_full": "63\nGemini Advanced\nNow you want to proactively continue brainstorming before you recap all of the ideas and notes for the group in \na follow-up email. You continue the conversation and type:\n Suggest follow-up items we could discuss for our [topic of brainstorm session].  What was not covered  \n that could have been, and what are we potentially missing?  (Gemini Advanced)\nGemini Advanced\n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1550
  },
  {
    "chunk_full": "64\nYou save all of your notes by clicking Share & export and Export to Docs. You are ready to send the recap \nmessage to the team, so you open your email and prompt Gemini in the Gmail side panel and tag the relevant \nfile of notes by typing @file name. You type:\n Use @[Brainstorm Notes and Ideas 9/1/24]  to write a meeting recap to the team  using an upbeat and  \n friendly tone.  Share some of the ideas I have for our next meeting to discuss [topic].  (Gemini in Gmail)\nGemini in Gmail\nExample use cases\nFounder \nUse case: Create an elevator pitch (speech to text)\nYou’re scheduled to present to a group of prospective investors. This will be your first time discussing your \nbusiness with this audience. You need to work on your elevator pitch, so you chat with Gemini Advanced using \nyour voice to prompt. You select the microphone icon and say:\nI’m the founder of [startup] in [industry], and I need help creating a short elevator pitch for [company  \nand product description]. I need to make the pitch relevant to [audience] and I want to especially highlight  \n[key features of product] because I want them to [take this action]. Include a compelling hook and \nanticipate questions an investor might have. Make the tone professional but relaxed and confident.  \n(Gemini Advanced)\n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1551
  },
  {
    "chunk_full": "65\nUse case: Develop your personal brand\nAs your company grows, you’re working on increasing your social media presence, so you want to define and \nhone your personal brand. To brainstorm, you turn to Gemini Advanced. You type:\nHelp me grow my personal brand. I am the founder of [a startup] in [industry]. I am passionate about \n[topics]. I want to inspire [audience] with business tips and lessons I’ve learned from starting my own \ncompany. My goals are to build a following so that I can [generate more media] for the business.  \nWhat are some ideas you have for how to accomplish this? (Gemini Advanced)\nGemini returns insights into how you can begin to build messaging and content that aligns to your personal \nbrand and that can help you achieve your goals.\nHead of Operations\nUse case: Communicate and negotiate with vendors\nYou’ve received a quote from two different manufacturers to create packaging for the company’s new product. \nYou want to compare and contrast the offers before you negotiate. You open a new Doc and prompt Gemini in \nthe Docs side panel and reference relevant files by typing @file name. You type:\nI need to make a vendor decision for packaging manufacturing. Create a table that compares the two \nproposals I’ve received @[Company A’s Proposal] and @[Company B’s Proposal]. (Gemini in Docs)\nGemini creates a table comparing the two different proposals. You make a decision, but now you want to see \nif you can negotiate with your preferred vendor. You go to your inbox and start a new email draft. You prompt \nGemini in the Gmail side panel. You type:\nCreate an email draft to [selected vendor] telling them that I’ve decided to move forward with them as the \n[packaging] vendor, but I would like to negotiate [a bulk pricing discount]. Use a collaborative tone.  \n(Gemini in Gmail)\nGemini in Gmail returns a drafted message that is ready to send. You select Insert and send the email.\nUse case: Plan and track budgets\nYou’re in planning mode and you first want to understand where previous years’ budgets were spent. You have \nall of this data in a Sheet. You decide to chat with Gemini Advanced. You upload the Sheet and prompt Gemini  \nby typing:\nUsing the attached spreadsheet, identify trends and patterns in our expenses by category over the last \nthree years. Identify areas where costs have increased significantly and investigate potential reasons. \n(Gemini Advanced)\n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1552
  },
  {
    "chunk_full": "66\nGemini returns a response that helps inform your budget proposal for next year. \nHead of Product\nUse case: Develop a product launch plan\nYour team is creating a new product, and you want to conduct research to inform your launch plan in \ncollaboration with the marketing team. Using Gemini, you want to simulate different launch scenarios based on \nfactors like pricing, marketing strategies, and target audience. You go to Gemini Advanced to conduct research \nand type:\nI am head of product at [startup] in [industry] industry. We are building a product launch plan for \n[product]. I want to brainstorm a few different scenarios. We are considering offering the [product] at two \ndifferent price points [A and B] and we are considering launching in [December or January]. Provide pros \nand cons of each scenario and suggest different ideas we may not have considered. (Gemini Advanced)\nYou want to continue market research brainstorming. You type:\nHow do these prices compare to [competitor products’] prices? Detail what pricing strategies \n[competitors] use for [products], and list any common tactics they use (such as free trials, discounts, etc.). \nSummarize how they position the product to [audience]. Cite your sources. (Gemini Advanced)\nYour research helps you refine your pricing structure and go-to-market strategy for your most important  \ntarget audience. \nUse case: Develop product strategy and roadmap\nYou want to refine your product strategy and roadmap. You’ve collected user feedback in a spreadsheet, and \nyou want to clean it up so that it is ready for deeper analysis. You chat with Gemini Advanced and upload a file. \nYou type:\nHelp me clean my [user feedback] survey spreadsheet. Specifically, fill any blank values in the name \ncolumn with “Anonymous,” then if the [recommend] column shows [Yes], replace that with [Y]. Finally, \nremove any rows where the satisfaction column is blank. Please generate a new file for me with my \ncleaned data. (Gemini Advanced)\n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1553
  },
  {
    "chunk_full": "67\nGemini returns a clean file for you to conduct deeper analysis on, and from this file, you notice a few trends. \nYou have alignment from the team on features to address recurring user feedback, and now you want to build a \nhigh-level roadmap that you can use as a starting point. You continue your conversation with Gemini Advanced. \nYou type:\nI am head of product at [startup] in the [industry] industry. We are adding [features] to our [product] to \naddress recurring user feedback, including [feedback trends]. Build a high-level roadmap that will keep us \non track for a Q4 delivery. Put it in a table format. (Gemini Advanced)\nGemini returns a helpful starting point. You want to save the work so you click Export to Docs.\nLeveling up your prompt writing\nThis guide is meant to serve as inspiration, and the possibilities are nearly endless with Gemini for Google \nWorkspace. Build on your prompt-writing skills using these tips.\n•\t Break it up. If you want Gemini for Workspace to perform several related tasks, break them into  \nseparate prompts.\n•\t Give constraints. To generate specific results, include details in your prompt such as character count limits \nor the number of options you’d like to generate.\n•\t Assign a role. To encourage creativity, assign a role. You can do this by starting your prompt with language \nlike: “You are the head of a creative department for a leading advertising agency …” \n•\t Ask for feedback. In your conversation with Gemini Advanced, tell it that you’re giving it a project, include all \nthe relevant details, and then describe the output you want. Continue the conversation by asking questions \nlike, “What questions do you have for me that would help you provide the best output?”\n•\t Consider tone. Tailor your prompts to suit your intended audience. Ask for outputs to have a specific tone, \nsuch as formal, informal, technical, creative, or casual.\n•\t Say it another way. Fine-tune your prompts if the results don’t meet your expectations or if you believe \nthere’s room for improvement. An iterative process of review and refinement often yields better results.\n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1554
  },
  {
    "chunk_full": "68\nGenerative AI and all of its possibilities are exciting, but it’s still new.  \nEven though our models are getting better every day, prompts can \nsometimes have unpredictable responses.\nBefore putting an output from Gemini for Workspace into action, review \nit to ensure clarity, relevance, and accuracy. And of course, keep the \nmost important thing in mind: Generative AI is meant to help humans,  \nbut the final output is yours.\nThe example prompts in this guide are meant for illustrative purposes.\nStay up to date \nworkspace.google.com  \nworkspace.google.com/blog\nHappy prompting!\n",
    "book_id": "gemini-for-google-workspace-prompting-guide-101",
    "book_title": "gemini-for-google-workspace-prompting-guide-101",
    "book_author": "Unknown",
    "topic_id": "ai_prompt_engineering",
    "topic_label": "prompt engineering",
    "chunk_index": 1555
  }
]